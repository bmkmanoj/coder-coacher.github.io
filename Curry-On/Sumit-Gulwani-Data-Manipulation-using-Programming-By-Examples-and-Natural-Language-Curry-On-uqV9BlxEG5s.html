<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sumit Gulwani - Data Manipulation using Programming By Examples and Natural Language - Curry On | Coder Coacher - Coaching Coders</title><meta content="Sumit Gulwani - Data Manipulation using Programming By Examples and Natural Language - Curry On - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sumit Gulwani - Data Manipulation using Programming By Examples and Natural Language - Curry On</b></h2><h5 class="post__date">2015-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uqV9BlxEG5s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay hello everyone so I am Smith good
money from Microsoft and I'm going to be
talking about test cases being more
interesting than code itself no compared
to what the pitch in the last talk was
so so this is the paradigm where people
are going to write test cases and the
code is going to be automatically
generated so the traditional customer
for our community has been a software
developer but today there is a new
opportunity or rather should I say a new
responsibilities that presents itself to
our community is to serve the needs of
end users who are two orders of
magnitude more than the number of
software developers in this world so it
turns out that 99% of people who have
access to computational devices do not
know programming and they want to be
able to write small scripts to automate
repetitive tasks that they come across
so one option is to insist that they be
trained to become programmers or the
other option is fleshly provide them
some domain-specific expert systems that
can help them with their tasks so what
is it that these people typically
struggle with so in order to say this I
actually went then looked at hell forums
so this is for instance what I figured
out on spreadsheet help forums where a
person asks and expert on the community
to give them a script that can for
instance transform this input string on
the left side of the arrow to the output
on the right side the expert looks at
the example and tries to conjecture what
their intent is and gives them back a
macro to automate this so in this case
the expert things that the user wants to
extract two characters starting with the
fifth one so the user takes this macro
run sit on their data in the spreadsheet
and figures out that it does not do a
good job on this other input and sends
this example back to the expert the
expert looks at it again in conjectures
that may be what the user wants to do is
to extract
the first substring that occurs between
underscore characters and this is the
macro that he gives them back so the
user tests face and is happy with the
result in sensor thank you to the expert
now this interaction takes place or a
course of several days and we can
actually automate it we can automate the
part of the expert where this
interaction can actually take place in a
few seconds and this is the technology
that we built which was the paper that
appeared in popular 2011 and this is a
feature that X updates in Excel 2013 so
I'm going to show you a demo of this
feature so here I have a collection of
Social Security numbers in the first
column suppose you want to format them
by inserting hyphens as you see in the
second column so if you do not know
programming then you will have to do
this manually which can be very
time-consuming and error-prone and even
if you know programming you will have to
know the excel programming model but now
Excel 2013 carries a feature called
flash fill which can be used to automate
such tasks so all that you have to do is
to give an example as I have given n
press ctrl E which will invoke this tool
which will look at this example generous
it into a program and run that program
on the rest of the data and the
spreadsheet to give you the output that
you want now the Excel team I think did
a good job at the user interface here so
suppose I want to expect the last name
and I give an example and imagine you do
not know that this feature exists so you
would not remember to press ctrl e so
all that you do is to start typing the
second output and the moment we do that
the computer guesses that you have a
repetitive intent in mind and it auto
fires this feature what is too good to
be true to read the mind of the user
from just one example so sometimes you
might need to provide more examples as
the scenario would illustrate so here I
on a bunch of medical billing codes some
of which have the right bracket at the
end like row 62 row 10 and some of which
don't if your goal is to clean this data
by inserting right brackets wherever it
is missing so let's see how the computer
tries to guess your intent so if you
give one example then the computer comes
up with the simplest explanation which
is to add a right leg it everywhere
maybe this is what you wanted but
otherwise you would observe that row 62
row 10 are incorrectly transformed so
you can fix any one of these rows and
the moment I fix the second row it is
like giving a second example to the tool
and the tool can better converge to the
intent that I have in mind so you can
use this to extract let us say the
element feels from huge strings in
column a so all they need to do to give
an example each I imagine how much time
will take you to think about the logic
and the excel programming program that
will have to otherwise right so the tool
can also learn quite sophisticated
programs so in this case I am learning a
loopy program you may or may not have a
spaces you may put them in reverse order
you may use dots and so on
so this is something that we did few
years ago and since then we have been
studying this space of data wrangling
which is the process that is used to
transform data from a semi structured
format to more something more structured
so turns out that data is locked up
inside various kinds of formats such as
text files log files web pages PDF
documents xml formats so all these
documents make it easy to visualize the
data but they do not make it easy to
manipulate and analyze this data so
typical data renewing workflow involves
extracting data from its existing semi
structured format maybe possibly
transforming it which is the kind of
thing that I just showed your demo off
then querying it and maybe reformatting
it so data scientists typically spends
eighty percent of their time doing these
kinds of data wrangling tasks and we
hope that programming by example can
provide a much easier and faster route
to doing these as opposed to writing
scripts so here is what they teach in a
data science class a famous data science
class which is offered as a book from
Brown University suppose you have a
document like this which is taken from
Wikipedia and the goal is to convert it
into a CSV format on the right so as
part of an assignment the instructor
provides people with a script to begin
with and to build on top of this script
to do this transformation now let me
show you a better way to do this
so I've loaded up that file inside this
tool and all that i will do is to
actually give examples of the data that
i want to extract so i will give a
couple of examples of the name of the
championship and when i do that the
system now tries to learn a program
which men run on this text file will
output a list such that the first two
elements inside that list will be the
examples that I provided
so usually it's very fast so I don't
know why the computer is having a bit
too slow now now let's say I want to
extract the air so in this case I will
need to give only one example and the
system will learn my intent because in
the previous interaction there was
already a model of the document that it
started building maybe let's say I want
to extract the venom score now in this
case when I give an example the system
tries to identify other such winning his
course but didn't get the third one
right because it turns out that there is
different kind of dash or hyphen being
used here so again all that I have to
give is to fix this example and when I
do that then the system can better
converge on to the intent that I have in
mind so this is a tool called flash
extract and it is shipping as part of
PowerShell in this new version of
Windows and this technology was
described in a paper that appeared in
pldi last year so how does these
techniques actually work so at the heart
of all of these tools we have a search
algorithm which tries to find a program
that is consistent with the examples as
the user has actually provided now what
is it that the user is providing me the
user is providing some form of example
so let us try to understand what is the
notion of examples here so canonically
examples are supposed to mean some pairs
of input stage elect responding output
value that you want to generate so this
is a canonical notion of examples that
is used in the programming by examples
community but our notion is something
more general than this so we generalize
the notion of examples in two ways so
one generalization is that the user is
not giving me the concrete output on a
given input state the user is specifying
some property of the output because
output properties are often easier to
specify then giving the full output so
for instance look at this address file
that I have a bunch of adverse records
so I would like to ideally be able to
highlight let's say the names of two
people and I would like this table to be
constructed on the right side by the
tool so we can do this inside of a dude
so in this particular case what is it
that the user has Floyd it so the input
to the program that is generated is the
entire text file and the output is
actually the table on the right side so
the user were to provide with the exact
output there is nothing else for the
computer to do so what I user is telling
me by means of highlighting to green
records is some elements that belong to
the output list in fact the system might
learn a program which might go and
highlight elements that are not desired
in which the case the user can also
provide negative examples in fact the
user can assert something more the user
can say that the examples that I have
provided to you are actually a
contiguous subsequence of the output
list or even more precisely a prefix of
the output list so these are all the
properties that we can very easily
exploit inside the search algorithm then
the other generalization is that the
user simply does not provide
conjunctions of these constraints but
but sometimes we might also be able to
want to handle some boolean combination
of these kinds of constraints that in a
given input state certain output
property should be true this usually
arises as part of how we actually
approach or solve this problem so I will
leave more leave out any further
discussion on this particular topic so
this is a column definition that we have
that the user provides us an inductive
specification which is a boolean
combination of pairs of the form on some
input state the output should have
certain property and our goal is to find
a program that needs such an inductive
specification so now this search if i
want to start let's say eliminating all
possible programs of increasing size is
just not going to work because the
number of state space of programs is
infinite so what we do is we provide or
we search for these programs or
well-crafted domain-specific language
and then the search space is much
relatively much smaller so this domain
specific languages have to be defined or
designed very carefully so on one hand
they need to be expressive enough to
capture a wide variety of tasks that the
user wants to do in that particular
domain on the other hand they need to be
quite restricted so as to be able to
enable to a swingable efficient
search for the load they should have
operators which should have a small set
of inverses and I will explain this
further when I talk about the search
algorithm and these patterns that the
domain specific language allow it should
also be quite natural because this
language is not just for the computer to
program in the users might even want to
look at the programs that have been
synthesized this can help increase users
confidence we can also have user
interaction models where the user can
select between different programs or the
user can even take a program that has
been synthesized and edited and I will
show you a demo of such a user
interaction model later so let us look
at the domain-specific language that we
use inside the first tool that I had
demoed to you which was flashed with or
even inside flash extract so in case of
flash fill one of the core tasks that
arises is to be able to extract the
substring out of a string and in case of
flash extract you want to be able to
extract a list of substrings out of this
huge listing which was a text file now
you might think that a regular
expression might actually suffice but
the problem is that such a regular
expression would actually be quite
difficult to synthesize in the first
place and also be very difficult to
explain to the user so we have come up
with some high-level computational
patterns to be able to do these kinds of
tasks which are a good replacement for
regular expressions our abstractions
actually involve using much simpler reg
ex is to do the task so for instance in
case of flash fill the domain-specific
language that we use is that we try to
compute a position inside the input
string and another position inside that
input string and take the substring that
is between those two positions in fact
we can also do a relative offset so the
first position might be computed using
some language which I am going to show
you and the second position can be
computed as a relative offset of the
first position and you can make this
domain specific language even richer now
the position expression which computes
an index into the string can either be a
constant offset all it is specified by
this cause construct which takes as
input to regular expressions
integer K with the following meaning so
it evaluates to that position inside the
string s such that the left side of that
position matches with leg x1 and the
right side of that position matches with
regex two and it is that Kate such match
so don't let me actually show this
visually to you what what is happening
here so let's say I have this substring
operator which takes as input to
position expressions in each other
position expressions let's say is not a
constant index into the string but is
specified by these regular expressions
or the pause operator that I just
demonstrated then visually it looks like
this so I will assist ring is then p is
such a position such as some the left
side of T matches with r1 and the right
side of P matches with r 2 and similarly
P prime is such that its context
stretches with our one primary auto
crime and w is the substring in between
so this kind of substring language has
so many interesting properties so there
are two very special cases so if the X's
on the corners are epsilon that is they
don't constraint anything about this
context then you are really describing
the properties of the substring that you
want to express what to expect on the
other hand if r2 and r1 prime r epsilon
then you are really describing the
boundaries between which you want to
extract the substrate and in general we
can have all of these 4 x's being used
and you have a very powerful substring
extraction operator now let us take a
look at the domain-specific language
that we use for the second task which
arises in flash expect where you don't
want to extract one substring we want to
actually extract a list of substrates so
common abstraction is in the case of txt
file at least is to split the file by
lines and then select some set of lines
using a filter operator then you map
those selected set of lines to sub
strings within those lines using a map
operator and the domain-specific
language for the filter expression then
for instance say that I want those lines
that have a certain targets or I want
those lines such as the previous line
that is a certain their gates and the
language for the function inside the map
operator can be the same substring
language that I just showed you earlier
the same substance operator so there is
an art to actually defining this domain
specific languages such that they remain
expressive on one hand and on the other
hand they also allow for efficient
search but even this restriction to do
many specific languages is usually not
enough to build the efficient search
experiences like the demos that I was
showing you so what we need to do is to
model or exploit the properties of the
operators in the zoom in a specific
language in order to build smart search
algorithms so what search algorithm is
basically build on the philosophy of
divide and conquer so the problem of
synthesizing our top level expression in
a domain-specific language is reduced to
the problem of synthesizing its sub
expressions and it is a top-down
strategy as opposed to a bottom-up
enumerative search which can try to
construct all expressions in increasing
order of their size and trying to figure
out which expression works so this
innovative search is not going to work
in this setting and the idea in this
divide and conquer which constructs
these subproblems from the original
problem the way you reduce the problem
original problem two subproblems depends
upon the inverse semantics of the
operators that occur inside these
expressions I am going to show you two
instances of this so consider this task
of extracting these yellow regions
within this address file and the user
has given me two examples of these
yellow records or yellow fields and I
want to figure out more such yellow
fields so in order to synthesize a
program that can do this task I reduce
this specification for the top-level dsl
expression which can maps as string to a
list of some strings to constraints on
the boolean function and on the
substring function so as you can see
there is no many specific language of
clash extract really involves splitting
the file into a bunch of line
and then selecting some lines within
those so what we want this boolean
function to be able to do is to select
goes to a specific lines which are
bordered by these red rectangles and
then the substring operator that is used
inside map should be such that it should
map these red lines to the yellow
regions inside them so this is the kind
of divide and conquer strategy that is
at work here similarly if you figure out
how do we try to generate a substring
program which can map the string redman
comma wa to redmond we split this into
subproblems and the sub problem here is
to learn a position expression inside a
string so the first constraint for the
first position expression is that in the
string redmond comma wa it should
evaluate to the index 0 and in the end
the constraint for p2 is that in the
string redmond comma WI it should
evaluate to the position just after d of
redmond now the second challenge in
designing such algorithms is that the
intent that the user has a specified is
highly ambiguous because examples are a
nebulous form of internets are under
specification so now if you insist the
garbage in garbage out philosophy these
systems are not going to be very usable
so the challenge here is to really guess
what is it that the user is trying to
say by giving very few examples so the
study that we use is that instead of
generating or synthesizing one program
we synthesize lots of programs and we
rank them so this ranking function is
based upon defining a partial ordered
over expressions in the underlying
domain-specific language the two basic
principles that we use are that we
prefer smaller programs so that when the
user gives examples of the form I 1
comma 0 1 I 2 comma 0 2 then we don't
just end up learning a conditional which
says if the input is i 1 then the output
is 0 1 and so on but learning the
shortest program also will not always
suffice because if you remember the
flash fill demos I was often able to
learn the intern
just one example so the user gives me I
comma 0 I can learn the shortest program
print 0 which is also not going to work
so you want to prefer programs without
constants so this is a simple basic
ranking scheme it turns out that this is
still not good enough for usability we
need something much more sophisticated
where we use a linear function linear
weighted function over some program
features and these weights are learned
using some machine learning techniques
and when we use this more complicated
ranking functions then we are able to
bring down the average number of
examples that are required in the basic
ranking scheme from almost 42 1.5 and
this is what was very important for the
Excel team to be able to make a decision
to ship out this technology so let me
show you how good our ranking scheme
really is here so what do you think I am
trying to extract in column B the first
character right what would be your guess
here plus 2 and building on what you
said you know here you probably think
the first three but what do you think I
am trying to extract here the first name
right and this is what a system does but
if I really wanted the first four
characters all that I have to do is to
give one more example and in the system
will actually fix it Here I am trying to
extract the initial and the system gets
it right so it figures out that the
lower f here does not come from this
lower case F but it is a lowercase
versioning of this capital F in the
system sure
could you repeat the question into the
microphone yes so if i can find do those
things I'll repeat the question what if
you try to extract the second letter of
each word does that work let's see if it
works but uh both words so it seemed to
us okay perfect so I can try a more of
this task right but the good question to
ask is you know for what kinds of tasks
for the system be able to do any will
not be able to do it as the boundary
line so underneath this system there is
a domain-specific language and if the
task that you want to do fits within the
domain specific language the guarantee
of the search algorithm is that it will
ultimately find that program with
sufficient number of examples and we try
to use good ranking schemes to make the
number of examples is small if the task
that you want to do does not fit the
domain-specific language that we have
then a system will try to fail until say
solid the program is not possible to be
synthesized from the constraint so is
what is the training set for the machine
learning algorithm is it the users
program or is it so much you you've
developed some heuristics and they ship
with the program so the latter so
machine learning is not being used here
so here we use a technology called
program synthesis which searches for
programs using the search algorithm that
I described in this divide and conquer
manner there is no machine learning
being used machine learning is used to
construct these magic weights over the
program features and these weights have
been learned in an offline phase and
that training data for that machine
learning system look like something like
this Oh on this particular input file if
the user gives me these three examples
then these are the other things that I
want to extract so that becomes our
training data so i want the ranking
function to be such that i can quickly
get a program from in one example
instead of three examples me looking at
health forms finding because could you
repeat the question yes so the question
is where did that train data come from I
spent three weeks building an initial
prototype of this tool I spent three
months trying to figure out the pain
that in end users have buy anything at
Hell forums
here's the microphone okay I have one
more question about the limitations
because all you'll show here was some
kind of extraction of data what about
operation of Honor data so i don't know
with example that you would you show for
example if i want to let's say change
some names and surnames or just spell it
in different you know from left to right
so we have been with 10 different tools
of this kind each tool has its own
domain specific language that is
specialized to doing tasks in their
domain the first demo that i showed you
was more towards transformation tasks it
generates functions whose signature is
string arrow string or more precisely a
couple of links to a string we have also
done some work in the space of XML
transformations which i think is very
powerful in general the demo that i
currently the next even that i showed
you was an extraction related task and
if time permitting i'll show you another
demo as well for a tool that that we
formats the data inside the spreadsheets
so ranking is a good mechanism to reduce
the number of examples in the user user
needs to provide but it is still not a
foolproof mechanism and we have to
really think firsthand about what is the
debugging experience that we will
provide in this new programming paradigm
so John a walkin watch who is one of the
famous authors of this Excel textbook
actually warned about this that you
might think by looking at few cells that
the system got the right transformation
but let's say if you're working over a
sensitive spreadsheet and a few cells
actually have the wrong entries then it
would be quite bad so we have invested
into building some good user interaction
models for resolving the ambiguity that
the user has in their specification so
one is that of course we make it easy
for the user to inspect the output of
the tool so that they can provide more
examples but even more interestingly we
actually show programs that has been
synthesized to the user and we convert
these programs into English because this
people probably will not know
programming we let people select between
different programs that we have
synthesized in fact we also have an
active learning model where we ask
questions to the user did you mean this
or did you mean that so let me quickly
show you a demo of these capabilities
so here I have a bunch of citations that
I have copied and pasted from a PDF
document and suppose my goal is to
figure out who is the most cited author
in this list of references so as you can
see that each reference consists off
list of authors followed by the paper
title followed by the year in which the
paper occurred in after giving two
examples of top-level blue regards the
system goes in extracts other such blue
records and you can see this pane on the
right side this is supposed to make it
easy to this gives you a bird's eye view
of the document and supposed to make it
easy to figure out where things went
wrong so there are two white regions
here which are unexpected because the
courts are supposed to be contiguous and
so the system didn't get it right but if
you fix one of them then the system will
go and also fix the other one so now let
us say I want to extract the list of all
authors and I give one example and the
system then goes and highlights other
such entries and the system did not get
it right in the second regard now if I
give one more example then the system
will get it right but what if this error
occurred somewhere in the middle of the
document so let's see what is it that
the computer is thinking so the computer
says to extract the green field from the
blue record you extract the substring
starting after the first white space so
when I hover over white space it shows
me where the right spaces in the
document which looks right because each
record has a number at the beginning and
a white space after which I the list of
authors start and then it says that the
green record should end at that camel
case in the second line which happens to
be the case of camel case is uppercase
followed by lower case so it happens to
be the case for the first record but it
need not be the case for every record
which is something that I know from my
higher level knowledge of what this
document is so I know that this part of
the program is actually incorrect the
ending logic of substring is actually
incorrect if I click on this arrow then
I can ask the computer to actually show
me other highly ranked alternatives that
it had generated in fact the next highly
gang alternative is the correct one
which says the first dot after camel
case and when I click on it then the
system shows me the right
now when I look at this task as a
programmer i thought this task was not
possible to do because i kind of guessed
that the green region should end at a
dot but there are lots of dots inside
the green region there are lots of dots
outside the green green region inside
this blue record but the system was able
to figure out one such logic that works
which is the it is the first dot after
camel case because these dots that
occurred inside that we feel are
actually after upper case now I can go
further and let's say figure out here
and if I give one example then the
system things that I want to extract the
first number before a dot which is not
really correct because this is the ph
number if I just click on it it is a
signal to the system that this is not
correct the system then goes and tries
to get the next highly-ranked program
and uses that and not change the program
to last term well before a dot which is
that I think I can even go and extract
nested data so let's say I want to
extract these list of authors
individually so by giving a couple of
examples the system will now be able to
generate this structure data which you
can easily transform into JSON or any
kind of other format that you want and
in a tabular form we display it like
this so we have developed lots of here
so we have developed lots of tools along
this model I showed you two demos then
we have developed tools which can
understand semantics of strings like if
three is march then 40 to be a bill and
so on the version inside Excel will not
be able to do such transformations we
can do other kinds of transformations
such as rounding and formatting numbers
now imagine whatever language you are
programming in you have to remember the
format characteristics of even
formatting listen numbers or dates but
examples are a natural way of expressing
intent we can even do much more
complicated tasks like text
normalization we also have developed a
programming by natural language
technology for doing wearing such as how
many people make more than average in a
given payroll spreadsheet you can ask
where is like that we have also done
some technology on reformatting tables
on automating repetitive tasks let's say
inside your PowerPoint slides
but i'm going to show you an another
demo of something which is more
significant which helps you extract data
or reformat data within spreadsheets so
after some kind of non-trivial more
normal processing from the extraction
citation extraction demo that I showed
you I might you might end up in a
situation like this where I have the
number of citations for each other in a
given conference and let's say I have
this data for multiple conferences here
and now I want to figure out who is the
most cited author across all of these
conferences now if this data was in a
proper structure tabular format i can
use tools like power bi or right right
sequel queries but the data is not
really like that so i can actually tell
the tool to construct me a table with
three columns and i can give examples of
entries that should be there inside this
column so this is my first example and
then i can give an example somewhere
down below to make it more
representative and then the tool will
try to learn a program which can
generate a table which is going to have
tuples of the kind that i have provided
and now i can do queries over this
structure table so this is the tool
called flash late it appeared in pldi
and this year this one does not ship yet
and we need to figure out the right way
to actually put this out so a note of
thanks to my collaborator so Alex
philosoph is the one who has built this
framework or which we have constructed
these different synthesizers this is the
divide and conquer search algorithm that
I have I showed you then the leap and
the chef have worked on flash fill who
worked on flash extract and the rest of
the authors here worked on flash too
late and miquelon was power really build
is nice UI that actually showed you I
didn't have time to talk about natural
language processing though which is
something that marked late you might
imagine applying this technology to
other domains I think in a couple of
decades when household robots become
more common this will be a fantastic
technology program robots you can
imagine integrating this inside existing
programming environments because this
can be useful even for developers and
ideally the intent should be expressed
using combination of examples in natural
language because sometimes tasks are
easy especially
by using natural language such as
reduction tasks like average filtering
and so on well conclude here and I will
actually just have the sales page that
we are hiding and we have time from
quite for questions one more time this
is amazing stuff what is the patent
status of this work so microsoft owns
all the patterns in this space i've been
doing this work at microsoft research
for the past five years and we do have
patterns on most of it microsoft owns it
more questions here you go
are you going to give this as some kind
of library to be used for example the
dotnet or something like this or would
be only for yes so the flash extract and
slightly reduced form of flash fill also
ships as part of PowerShell and
different MVPs have created their own UI
experiences on top of it we hope to be
able to release more such a p is that
can be pluggable inside different user
experiences that people have the other
question to ask here is that what is the
kind of programs that we generate so
generate these programs in our cute
little functional languages but these
programs are easily translatable into
any other language that you want and
that's a much easier task it says simply
it's integrated translation but if you
care about producing the smallest
program the putative program inside
Python then it is going to be more
sophisticated problem and we'll have to
do a proper search over those programs
quick we have a few more minutes what
about performances and much big data
when you sure yes so the pool works much
faster than what I what I was able to
demo here unfortunately there's
something wrong in my machine if you
want to so there is a team that is also
shipping out this technology that cares
about analyzing log files parsing and
analyzing log log files which is
important for ensuring agile software
development and there are the scripts
that we generate need to be done on
gigabytes of data the programs that we
generate are typically they run in size
time linear in the size of the data we
can even generate even generated
streaming programs so the real cost is
in synthesizing those programs which
fortunately only depends on the amount
of data or which you give examples which
fits in a screen and that is quite real
time as the demo showed here you go
you've mentioned analyzing Glocks and
that's why I have another question
because the other thing that I would
what comes to my mind when I analyzing
log and some machine learning gets at
some time at the same time would be a
apache spark with spark streaming and
machine learning based on spark so how
did you add tested how is going the
performance what's the difference in
performance in visto approaches yours
approach and apache spark so i do not
really know what they do but is the
difference between using machine
learning to draw insights and analytics
on your data and what these tools do is
to help massage the data into a form in
which more easier machine can be applied
in a more easy manner so in a typical
life of a data scientist they are
spending eighty percent of the time in
just massaging this data from one format
to another format and bringing it into
form that can be easily consumer machine
during a good okay but what's with the
situation in which you know you get new
data over time and at some point the
program might for example think okay
although i was doing it wrong maybe i
should do is different way so let me
answer that question by asking you a
question how would you write a program
in such a setting well i'm not sure i
think it's how do your program is
correct you write test cases and here
you only write these cases and however
you can do better once we extract data
or do any kinds of transformations we
can actually analyze the data that is in
extracted so the functions that we
synthesized are partial functions to
start with so for instance the function
might be extract the third word inside
the string and then I get a system which
has no third word so i can raise an
exception at that point of time or i can
let us say but all the strings have
third word but let's say i get a
different kind of a string which seems
to extract alphabetic characters as
opposed to years and if i have some
semantic knowledge of data types i can
again raise the morning and these are
the things that we are planning to
invest in do now but debugging is a very
important thing for this programming
modern take away and we have to think
about first
statement for debugging I don't think so
I have a perfect answer to that question
but we are starting to invest more and
more into this just a small question on
the UI is there a way for the user to
prevent the adjustment on the second
example for example let's say everything
is correct but just one thing is off and
you don't want the system to learn from
your second adjustment is that possible
today in the UI so the user can correct
the examples right if they override any
one other highlighted examples it will
undo the assumption of the original
highlighting right but what I'm saying
is let's say you make one example and
the system has learned and then filled
the rest in the flash for example let's
say every every row it guessed correctly
except for one you can then one manually
fix it but if you manually fix will is
their chance of system will learn from
your second fix and make adjustments
then case off flash fill the way this
technology has been exposed is that once
you do the learning thing there is no
memory of what happened before it is as
if you just type that data yourself but
you can imagine other user interaction
models which is watching for any data to
change and then refire that would be a
different kind of user interaction model
okay thank you thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>