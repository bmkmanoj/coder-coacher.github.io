<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Zach Tellman - Some Things That Macros Do - Curry On | Coder Coacher - Coaching Coders</title><meta content="Zach Tellman - Some Things That Macros Do - Curry On - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Zach Tellman - Some Things That Macros Do - Curry On</b></h2><h5 class="post__date">2015-07-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/o69H0MXCNxw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so quick show of hands how many of you
have written some closure at a book
written a few lines how many of you have
written a code in another less common
scheme bracket okay so that's most of
you
so I'm gonna just go very quickly over
all the introductory material that I
prepared and sort of the worst case
scenario this was made of best
expressions they're delimited by
parentheses the first term is always the
function the remainder of the terms are
the arguments of function these are some
expressions here we see the addition of
one two and three using the plus sign
which is always a prefix notation we can
also create a list of one two and three
by calling the list function we can
quote that and get a similar effect we
can also pull the addition in this case
the plus sign is a symbol not the actual
addition operator in order to figure out
what that means we need to resolve it
which is what eval does when we evaluate
that quoted form this is a Homo iconic
language or a family of home iconic
languages the Wikipedia definition here
that could be taken in a very literal
sense to apply to any language which has
a primitive string and so the key thing
here is to think about not what the
source code is for you but what the
compiler sees the source code as right
and so we're talking about not the
source representation but the ast there
participation
macros are a compile-time AST
transformation and so the key thing here
is that this happens after reading the
before the code is actually emitted and
it is scoped it is not a pervasive
transform of all the code it is
something that occurs within a given
scope of your program a very simple
example a common sort of introductory
example is the unless macro which is the
complement of the if form here we take a
predicate and a body and we generate a
list that represents an if statement
where we have the predicate and we move
the body into the else clause so these
two expressions here are equivalent and
this seems a little bit trivial but it's
important to realize that this has
conditional execution of the body which
should not be true if we had an unless
function I would have to pass in the
body have this side effect if we had
just a function here and so this is a
crucial thing to have if you're in an
eager language if we're in Haskell it's
a completely different story but it's
sort of out of scope so Paul Graham back
in his sort of patron saint of lisp days
talked a lot about Lisp and a lot about
macros as sort of the thing that made
Lisp a language worth using right he
talked about it as this thing that if
you were in a sort of lesser language
you might not even realize that you
wanted it but you know once you sort of
wrap your head around it you couldn't
imagine life without a macro conversely
I know a number of people who have been
using closure in production for to good
effect for a number of years and they
have effectively disallowed the creation
of new macros and their code base their
existing macros in closure you can use
them but you better have a damn good
reason for adding a new one and I think
that this is a crucial disagreement
because whatever you think about Paul
Graham in his sort of you know latter
day investor sort of persona his
qualifications the qualifications of my
unnamed acquaintances are pretty much
the same they've used Lisp commercially
to good effect
and so this talk is not about macros in
terms of what they can do or macros in
terms of how we can sort of
theoretically make a better way to
define code form something like this
this is a very sort of practical
pedestrian exploration of what macros
have been used for and the way that
we're going to look at that is looking
at macros which are written in closure
which is a particular dialect of Lisp
which is sort of concerned with the dual
sort of goals of being immutable by
default and having seamless Interop with
Java which is not immutable by default
and most of these macros are ones that
I've written because when we're talking
about macros it's not again a question
of what is possible because anything's
possible we can make any piece of code
mean anything that we want to the
question is sort of what is in good
taste and that is very sort of mired in
the problem that we're trying to solve
and I can speak most authoritative lis
on the problems that I destroy himself
so the first closure project I ever
wrote was an OpenGL library
it was a library called penumbra I was
very pleased with it until it got kind
of large and out of control
it was a layer over a Java library
called oh yes maybe I can ask a question
so you say we can make any program mean
what we wanted to mean but can you
overwrite the existing meanings I mean
so what we're getting I mean so let's
say if there's a special form in closure
if within the scope of our macro we see
an if symbol we can transform that to
mean something else right these are the
code is coming in as something without
semantics it's just these sort of
symbols and we can go and make every if
mean the complement of if we want to
it's not so you could really say at the
start of the program you open your macro
and at the end you close it and then
inside you do whatever you like you do
whatever you please and and so we're not
we're not sort of controlled by what we
can do it's by what we should
or what is sort of reasonable today okay
so the the locker that I wrote was a
layer / LW jgl which is a java library
that has FFI bindings to the c library
which is a spec by the Chronos committee
which is a collection of game developers
and hardware vendors and when we have
these sorts of powers of abstractions
all of which are trying to be helpful
right all trying to be idiotic in their
own particular language we have this
sort of veering effect away from these
sort of essence of what we're trying to
do right they try to present it away
which is nice for them but it's less
nice for whoever's trying to sort of
build atop them and so I as a closure
developer and sort of building on top of
this leaning tower and so when you look
at OpenGL as it's done in C and pretty
much actually quite literally Java you
might do something that looks like this
where you enable a the lighting and then
you call push matrix which is a way of
defining a scope for spatial
transformations right everything that is
within this pushed matrix will transform
to the moment we pop the matrix back off
we return to our original state and so
then we translate along the z-axis by
negative ten units and then we begin to
draw a series of quads or in this case
just one rectangular shape and then we
end our draw and then we pop our matrix
back off and it's worth noting that
there's a lot of balancing here manual
balancing of calls and we have indented
the code because that helps us sort of
reason about it but that's only because
C and Java
don't give us any better way to deal
with this right we hope that we won't
have an unbalanced call because what
will happen will be inexplicable and so
you know if you had a language construct
like pythons width this would be sort of
something that you could solve but
neither see nor Java has and neither
does closure but the nice thing is that
we can just sort of make one for
ourselves and so equivalent code in
closure looks like this which does
exactly the same thing but notice that
both in the case of the push matrix and
the draw call we don't need to close
this off that is implicitly sort of
described by the scope
because we defined the macros and so the
push matrix macro is pretty simple we
just want to take whatever the body is
whatever these sort of series of calls
are and push them inside this sort of
initial call and the closing call and
you know here we push the matrix and
then we within a try finally Clause run
the body because of the body you know
for some reason throws an exception we
want to make sure that we as that sort
of exception pushes up the stack clean
up after ourselves right make sure that
we're always in a balanced State and so
if we use the same mechanism that we use
for the unless macro we get something
like this which works right but sort of
only kind of resembles the code form
that we're trying to do here we're
trying to do a bunch of things we have a
manual list we have some quoted forms
since the body has multiple arguments we
have to concatenate everything together
and this is far from ideal because we're
trying to represent code and it's very
easy to have nesting one level too deep
or one level too shallow and then the
code might work it might not and it's
going to be very hard to sort of
visually debug this and so it's in our
interest to have our definition of the
sort of templated code that we want
resemble the code that's generating as
closely as possible and so in pretty
much every list under the Sun there's
something called a quasi quote or syntax
quote and it's again just a form of sort
of code template and here we see that
where we have these sort of ellipses
audio we've replaced that with a tilde
act symbol which is basically splicing
in the code and then saying I want to
splat it out and so this is very simple
right this is a big win because what
we've done is we've taken something that
was sort of incidental busy work for the
programmer we've made the compiler just
to do it for us right and we've created
this linguistic extension which makes no
sense outside of the scope of drawing
things for the OpenGL API specifically
but that's okay right it's not something
that anyone else will ever have to use
a more sort of thorny issue is how we go
and actually create closure equivalents
for all the existing Java functions we
have a GL push matrix function that's
expose by the Java API you don't want
that to be GL - push - matrix because we
like our kebab case rather than the
camel case and one sort of quirk of the
Java library is that it wraps all of its
objects in this one big class that is
tied to whatever version of the opengl
spec it's from - so you've a GL one one
object to GL one to object to GL - o
object and on and this is sort of useful
from a bookkeeping perspective but it's
not interesting to me right I just want
to kind of get at the functions that I
have and there's not duplicate sort of
definitions of these two functions and
so from my perspective sort of having to
specify which object this is contained
in is needless effort right it's it's an
answer that the computer can give to me
so there's no need for me to specify it
and so we can imagine a version of this
which is lacks that right it's just via
reflection goes and kind of scans over
all the possible computers and finds it
for me but if we go that far we can
imagine going one big step further right
having a batch import thing something
that just goes scans over the object or
all the objects and just sort of imports
them all one by one and this is not
something that I did and the reason for
this is debatable but basically we want
to consider our audience the people who
are reading the code right because
inevitably they will call a function
incorrectly they will get an exception
there stacktrace will take them to this
thing this GL import all whose behavior
is not defined by the code is defined by
some weird nexus of my code the sort of
implementation for the underlying Java
library which is tied to the underlying
expectancy and so this poor person using
my library now in order to understand
any one part of my code has to
understand the entire opengl spec which
is unkind I think
and so when we think about this we look
at macros right this thing with which we
can do anything one of the key
distinctions that we want to make is
between sort of compression in the
information theoretic way right golfing
our code down to the least possible
number of terms and concision which is
to say going down to the essence of what
we're doing but not taking away anything
further than that and these sort of
controlling force of where on that
spectrum we fall is our audience who
needs to be able to read our code and
her audience includes us now us three
months from now when we've kind of no
longer think that we are quite as clever
as we were and anyone else you might
read it right which is a audience that
you may or may not be able to completely
predict right you may know that this is
some sort of deep implementation detail
and you can get away with a lot more
compression a lot more cleverness than
you might otherwise another sort of
example of this trade-off is a library
recently wrote called manifold which has
a deferred pipe also known as a promise
or a future these are sort of a dime a
dozen and all the other languages and
one of the sort of frustrating aspects
of this construct is that if it gets
into an exception state but that's never
consumed if they were sort of grounded
out it just vanishes right eventually
the GC gets it and you never know that
anything failed and so if I went and I
posted something to a server and never
actually paying attention to what the
response was that might have just failed
it might have done something wrong but I
assumed happily that everything sort of
went as expected because nothing was
logged and so one way to kind of address
this within the jvm ecosystem is to
define a finalized method which just
before the garbage collector does its
thing examines it sees whether it's in
an error state sees whether anyone has
ever actually paid attention to the fact
that it's an error state and if not it
logs zero and this doesn't have any sort
of temporal coherency right an error
occurs a bunch of time passes Jason
happens and all sudden boom there's an
air of the law but at least it's
something
right it's some sort of evidence that
something went wrong and this was a
great idea up until the point where I
realized that
a finalized method adds a tremendous
amount of overhead did you see I I'm not
entirely honest just the presence of an
empty finalize method adds a lot of
overhead and I think they go into
different queues or something I'm not
sure but it was clear that I could not
get away with this and so what I needed
to do was to create two different
objects that very closely resemble each
other but for this one finalize method
and I have an error logging deferred
which one time an N in my case every
thousand instantiations will create this
unduly expensive version of the deferred
and this means that there are a lot of
errors that are obviously going to go
missing but if we're operating at scale
and this is sort of a pervasive error
there will be evidence right there will
not be a complete sort of swallowing up
of this error but of course now I'm in
the business of having to duplicate all
the other code here and this is because
death type its API is syntactic right I
can't pass it a map I can't give one a
map that has a finalize method and one a
map that doesn't have the finalize
method I can't do anything at sort of a
data level to address this I have to
give both of them this sort of expanded
out syntactic representation of this
class and so I use a macro and I want
something that looks kind of like this I
have a both macro that wraps this and at
various places within this I have some
either clauses right which says first
what I want in the one class and then
what I want on the other class and so at
the top here I have deferred an error
logging deferred and I have nothing and
I have the finalize method and this is a
very big win for me because the both
macro and I'm not going to go into the
implementation very deeply but it's very
simple writes about ten lines of code
and has something that scans over the
top level of the form and looks for
these either's and first expands that
with the first term and then expands out
with the second term and so I have gone
and used ten lines of code to save
myself hundreds of lines of code and
hundreds lines of code that need to be
kept sort of manually in line with each
other
right you could get these drifts where I
make a change in one but not the other
and that would be almost invisible to me
that would be impossible to track down
until someone reports some sort of weird
quirk
and worse you got a bird park that only
happens one time in a thousand but this
is good in a way that be sort of batch
import case was not good in that it's
sort of respect to the code that was
handed to it right it is a transparent
for the most part macro we have these
little sort of quirks these little
either clauses but unless someone is
looking at particularly the finalize
method they might not even notice that
this is a thing might have not notice
that there is this little bit of
cleverness there and if it is something
that they notice they can go and look at
the macro and it's it's reasonably
apparent what it is that it's doing and
so this is more respectful to our
audience right the proportion of our
audience that is ever going to even come
across this is much smaller than it was
when we were in defining every single
function via this sort of opaque macro
so macros are useful right they give us
these sorts of degrees of freedom that
we wouldn't otherwise have and so it's
worth asking like why are all these
people avoiding them why why is the
closure community sort of gun-shy and I
think that one answer is that you know
as I've articulated there's a balance
here right there's sort of balance
between trying to reduce the amount of
code that you're writing and still
having it be something which is legible
that's a difficult line to walk it's
something that I've failed to walk
correctly a number of times but there's
actually something a little bit deeper
at work here and look at that I'm going
to return back to graphics in this case
the sierpinski triangle which is a sort
of simple fractal shape and it's
generated by taking a triangle and
shrinking it by half and then doubling
it or rather tripling it then shrinking
that by half and then copying it twice
again and on and on right and we look at
this we see that there's sort of this
nested regularity and we realize that
you can use macros we can define a
sierpinski macro right that takes
somebody you don't really know what it
is we don't care we put it in a function
and we then define a sort of local
context about the transforms and we
shrink everything that we draw within
this context by half and then we render
it three times first in the bottom left
then the bottom right
above and we can nest sierpinski macros
for heart's content we can do it twice
we can do it ten times but at some point
this gets sort of tedious and so we
decide that we want to stop having to
type this over and over again and so we
define another macro which allows us to
just give a number of sierpinski's and
it goes and wraps it for us because you
know the computer is better at that than
we are and this works we can go and we
can you know do five levels deep we can
do fifteen levels deep at some point the
code that's being expanded here will
make the JVM a little bit cranky but
like it's because we are not copying the
code three times we're just copying it
once into this function it's sort of a
linear relationship it's not too bad
right we can actually get away with this
a lot longer than you would expect but
there are some definite problems here
one of which is that this is imperative
code right we're drawing something and
then we're done and you know closure
purports to be a functional language and
this is not really in line with that
right we have no ability to use all of
the tools that sort of closure can bring
to bear and the other problem is that
you know as we saw when we wanted to
have sort of a higher order of
abstraction over this macro that we
defined we had to define another macro
right because the API is the syntax we
have to provide the syntax in the way
that it sort of expects it and so macros
beget other macros it's kind of
unavoidable so maybe we should use
functions right maybe that's that's
better and we can do this actually very
simply we can just simply call our draw
triangle function something else you can
call it a renderer if you can choose not
to immediately render it we have a
function called render which invokes it
and based upon this we can begin to
create these sort of higher-order
functions like this one which goes and
takes a function and returns a function
which renders it somewhere else right
and be using this and other sort of
similar tools we can find a sierpinski
function which takes a function and
shrinks it and renders it three times
and then we can do something that is
much more closely resembling sort of
functional programming we can define an
infinite lazy sequence of all the
sierpinski shapes and we can choose one
of them to render it and this is
significantly better it's a small change
but it's a very meaningful one because
closure is at its heart of data oriented
language
it takes data it transforms data and
functions are not a very rich form of
data but they are something right there
is a separation between describing what
you want to have happen and actually
having it happen and that's a really
important sort of separation right that
actually enables a whole host of things
that you wouldn't expect sort of
intuitively even as someone who is an
experienced closure programmer so why do
we avoid macros right why is there this
hesitation there's a sort of truism when
people talk about lists let's say code
is data and data is code and the first
of these is certainly true but code is a
very small subset a very narrow subset
of data there's a lot of data that is
not valid code and even small around
that is syntactically or rather
semantically valid and macros as their
API requires syntax right which is again
this narrow subset this thing which is
harder for us to generate hence all
these sorts of affordances these syntax
quote sort of templating mechanisms and
because macros sort of beget these other
macros this has this tendency to sort of
affect the surrounding code it makes it
kind of fragile it makes it sort of
calcified and so the reason that people
avoid macros is because they've been
bitten by this one time too many
right they have gotten sort of shy of
driving off the cliff after they did it
the first five times but there are some
really good reasons to use macros which
are closely related to the reasons not
to macros use syntax not data and syntax
has the enormous benefit of having well
understood semantics right data doesn't
have semantics data is data we have to
describe what the semantics are we have
to document it in exhaustive detail we
can write something that is not quite
closure but closely resembles it and
people will understand intuitively how
it is meant to be used that is
invaluable it is also the only way we
have to create control flow of
abstractions right it's the only way
that we can have conditional execution
of code this is not strictly true we can
go and wrap everything in functions but
in practice you don't really want to do
that and we can solve problems at
compile
otherwise we would have to solve at
runtime repeatedly and when we're able
to do that we should always try to so
one fairly well-known version or use of
macros is the core async library which
takes most of the things that go has for
concurrency and steals them and puts
them in a library without any sort of
changes to the core compiler it has
channels and it has this macro called go
which will walk all the code and sort of
allow it to be used in a lightweight
thread context and it does this by
examining the code for all the places
where it might have a pause which in
this case are when it's reading in a
message from the end channel and channel
might be empty
what's writing out a message to the out
channel and the out channel might be
full and in each of these cases it may
need to pause might need to wait for
that sort of condition to change and in
order to sort of allow for this it takes
this one function this one code form and
sort of rips it apart of the seams turns
it in this case into three different
functions which are linked together as a
sort of finite state machine and this
allows for multiple sort of go routines
to be swapped in on the same thread
whenever a particular go routine is
parked waiting for something to happen
it will go and just sort of seed control
to something else and the core a sync
and more specifically the the go macro
is a really impressive piece of
engineering right it is an enormous
example of the power of macros it's
something that you know anyone could
write in practice it was the people who
created closure that wrote it but anyone
could have written it and it works both
in JVM and JavaScript which allows for
both of those environments have a shared
concurrency model which is actually
tremendous and sort of unprecedented and
it has the identical flow of execution
to the existing sort of java model right
which is when i cannot proceed
I will just stop and wait and again this
sort of falls into the need for macros
to resemble the things that they're
emulating right we can't just sort of
needlessly go away from what people
expect at the same time there are some
problems all right the go macro is a
very impressive piece of engineering it
took about a year and a half for it to
get right it is about a thousand lines
of code plus about 2,000 lines of syntax
analysis that got sort of factored out
into another library there are some
issues even though it tries to sort of
transform everything all possible code
forms it cannot transform within a
closure because that function may escape
that scope and they can't control how
it's being executed and there is a
another problem here which is that it
does actually very closely resemble the
Java thing it has this sort of
sequential flow of execution anytime any
piece of data is not allowed available
it'll just park itself and wait and when
we consider how most back-end servers
work most back-end servers are a
front-end to other back-end servers
right a database any other sort of
service you have micro services galore
and so we might have a request come in
and that gets sort of farmed out to a
bunch of other backends and then we take
the responses from the a and B services
and feed those into requests to the D
service then finally when all of those
are done we feed the responses from DNC
into some function that gives our
response right this is far from you know
an unfamiliar situation and if we have
this sort of sequential flow we have to
be very careful about separating when we
send a request and then when we wait on
its response right we have to wait or
sort of dereference these responses in a
very particular order and if we fail to
do this our program will not be wrong it
will not respond with an incorrect
result it will just be needlessly slow
and this is a very difficult thing to
debug we often have no tools that will
give us a gigantic chart or something
like that I can do what you see in a
JavaScript console that will sort of
show us when we have this sub optimal
sort of behavior and so that's not
necessarily something which is
our fault because the computer knows
what the dataflow dependency is right
the code is a unambiguous representation
of what relies on what and if we imagine
a macro that is not trying to do the
whole core icing not going sort of full
chorusing but is just trying to look at
a particular left binding and understand
what the relative dependencies between
all the different terms are we can do
this right we can take this and kind of
look at what the different dependencies
are and because we don't want to spend a
year and a half trying to get this right
we might try to do something a little
bit simpler and you know as a sort of
naive first approach we can imagine just
looking inside these terms right we look
inside the sort of definition of D to
see what do you rely on and we can see
that there are both a and B symbols in
there and we see that there's some and E
symbols are not binding and you know
success right except if we have
something a little bit more complicated
we kind of be get led astray because
here we have an a symbol right and we
see this a symbol again but this is not
the same a symbol right the fact that
they're simply the same thing they say
have the same name doesn't mean that
they are the same value and so one
problem is that these two ways are not
the same because this a below it has
been shadowed right we have a new
lexical binding a new lexical scope
that's being defined the other one is a
little bit more subtle right we don't
have a new lexical scope here so it said
the a above and the a below are not
actually expressions they're not
references to some sort of computation
that's going on right this is just a
lexical definition and when we're trying
to scan for what is being used what is
being computed on that is not the same
as what are all the symbols in my code
right the expressions are a subset of
the s expressions in our sort of code
from a runtime perspective and so what
we need is a way of understanding our
lexical context right we can't we don't
really want to have to compute it but
you know if we have to then we will and
we need a way of avoiding these sorts of
non expressions if we're just trying to
understand what is being computed right
and so I actually ended up writing a
library to do this because there wasn't
a particularly good way to accomplish
this and one of them is a thing that
simply walks over all the expressions
right very straightforward and then
there's another thing which is a little
bit more subtle which is as we were
walking the expressions we are feeding
this code into the closure compiler into
a sort of sandboxed instance of it and
at any point while we're walking we can
ask what is my lexical scope what are
the terms that I have access to and
because closure allows you to apply
metadata to symbols when we define our
sort of outermost scope we can apply a
metadata that says I'm the a that you
care about and then when we go and see
an A and we match it up we say is this
something that I care about and within
this sort of shadowed context the answer
is no and so this is not hard this
doesn't actually require any sort of
deep understanding of the compiler or
even the language right this is just the
visitor pattern if you're into that sort
of thing and that is powerful right it
means that we are able to sort of
differentiate between this by simply
examining the code in a particular way
right and so let flow is not in any way
an attempt you can keep with what the go
macro does it is a sort of different way
of just kind of addressing this problem
but it's very small it's only about
forty lines of code and there's about
200 miles of code in the sort of code
walking library that it leverages and
it's able to do this not because it's
better but because it just leans very
very heavily on the existing
implementation of the compiler right it
does not need to take a pyramid and then
build an identical pyramid next to it
with one stone askew right it can just
take that existing pyramid and sort of
add something another sort of slightly
ridiculous thing that you can do in this
vein was a library wrote kind of just to
play around with this idea yes oh five
minutes okay
was a library called Proteus which just
defines a lek mutable macro because
closure of course is an immutable
language you cannot overwrite a value
which has been let bound but now you can
and so all it does is it allows you to
use the set bang method inside of its
scope to overwrite a particular value
and how it does this is not particularly
complicated it just expands does
something like this it takes whatever
the value is it wraps it in a container
object it looks for every instance of
this X and it doesn't get wherever it is
whenever you have set bang it does a set
but this actually has a nice property
which is because this value is
constrained to this lexical scope it's
safe right this is not unsafe mutability
there is no race condition that can
occur only one thread will ever see this
and because it has this lexical
guarantee there it needs we know runtime
checking no nothing and so this actually
ends up being faster than any other
state container that closure provides
because closure makes much more
pessimistic assumptions about who can
see this particular value the only sort
of wrinkle here is that if we try to
close over the value that it can't
escape and it is unsafe and so we have
to make sure that what's being closed
over is not the container but the value
at the time that it got closed over and
so this is again very simple it's about
one code it's kind of a joke but people
use it and this and these sort of let
flow and any of the other things that
I've sort of talked about here are not
meant to be sort of the apex of what's
possible as I said I'm actually trying
to go for fairly pedestrian examples
here that are not going to necessarily
inspire you and go you know yes macros
they're amazing these are experiments
but I think that when people talk about
macros there tends to be this sort of
dichotomy between the very simple sort
of push matrix style macros which are
just templating code and these sort of
core async macros which are rewriting
the code are basically a compiler in
their own right and these are ends of
the spectrum but there's a rich sort of
vein of stuff in between right and one
way to sort of get there is to leverage
the existing sort of compiler implement
because that means that not only do we
not have to do as much work but there's
a lot less chance of a strain needlessly
from the semantics of the language right
because that's what makes our macro
useful is the fact that it is intuitive
to the potential users apartment users
and so there is a adoption curve that I
use often in a sort of business context
or more sort of enterprise conferences
in this one but it is that with any sort
of new idea you have this sort of peek
as people get super excited about it
and this is quickly followed by this
trough when people realize that it's not
exactly what they were hoping for and I
think in at least the closure community
were about here right we had to be sort
of Paul Graham rush of Lisp euphoria and
not everything that was promised turned
out exactly as we thought it would but I
think that there's a lot of stuff that
remains to be sort of unearthed here
there's a lot of interesting things to
be done and some of the examples I've
given may or may not end to be
resembling what is done but I sort of
look forward to what the future holds
and so with that I'll leave the four
open questions
so a question is about a flow macro so
we took the explainin is pretty hard to
reason about lexical context encoder and
macros the sync is caused by the fact
that closure has a very simplistic macro
system unlike more advanced than
Microsystems like racket where this kind
of stuff is built in functionality like
so III I am NOT expert enough in rackets
mechanism I would point out that sort of
the DEF syntax style templates do not
allow you to do code walking consistence
like sort of transformations and a lot
of the machinery that exists in other
lists that I'm aware of is usually
concerned with this so you have the
question of hygiene how can we safely
insert a bundle of code into the middle
of some other template and that is
qualitatively different than what the
flow macro is doing which is doing a
pervasive transform that is sort of has
to be aware of the context has to
actually walk over and transform the
body that's being passed it does that
okay
hi thanks for the talk
so you've been telling us how interested
in how many interesting possibilities
closure macros open up so and you
mentioned such that sometimes macros
they are not the right choice
so mmm I have some similar question so
what would you like to improve in
closures macro system if you had a
chance sure okay so I do wish we got
something more similar to the deficit
pact thing that racket provides I think
that there are a number of things that
are more aggressive sort of macros that
I've written which end up being really
ungainly because you just have an
enormous number of these sort of nested
syntax quotes which are far less
readable than sort of code as it is and
if you had sort of a better the sort of
the the flaw or the the sort of weakness
of this index code is that it's read
time so it has no sense of any of these
sort of context that it's being done if
the templates were compiled time then
they could use lexical scope and other
sorts of things to check and you
wouldn't have to have they really
aggressive sort of Jennison mechanism
and everything like that and I I don't
think that that's a weakness with
closures macro system per se so much as
maybe just the tooling in the closure
ecosystem like this is something that
would not have to be a core part of the
language but I do think that there is a
definite need for better tools for sort
of complex code generation Thanks do you
think that s-expressions are the right
representation for code and binding
structures I don't have a better idea I
mean so I wouldn't list for a number of
years because it looked weird and so I'm
not thinking about surface index I'm
thinking about the underlying syntax you
used to write transformations you know
regardless of what the surface index is
I don't know I guess I haven't seen
anything better right I mean you know
there's always going to be some sort of
ast representation
superficially sort of resemble
s-expressions because that's just how
it's done and I think that you know for
instance having a decent pattern
matching mechanism enclosure would make
some of this easier but that's not
really a an indictment of the
s-expression representation so much it's
again the tools that we have to sort of
deal with it so I don't know I mean I
could certainly if someone said that
they had a better way I would certainly
pay attention because I think it's
possible I just don't know what it would
be
any more questions well thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>