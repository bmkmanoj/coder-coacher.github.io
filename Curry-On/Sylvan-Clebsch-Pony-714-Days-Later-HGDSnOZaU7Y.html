<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sylvan Clebsch - Pony: 714 Days Later | Coder Coacher - Coaching Coders</title><meta content="Sylvan Clebsch - Pony: 714 Days Later - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sylvan Clebsch - Pony: 714 Days Later</b></h2><h5 class="post__date">2017-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HGDSnOZaU7Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone I'm Sylvan clutch and I've
just received an absolutely magnificent
present just everyone and so I'm going
to talk about pony but hopefully I'm
going to talk about pony in a way where
you guys are driving the discussion much
more than I am because if not I'm going
to be punished severely
so the first pony talked in public that
I did was 714 days ago in Prague at
Korean oh sorry
I'll talk into the mic that'll probably
be better and since then we've both made
a lot of progress and been pleasantly
surprised about how much we actually had
right in the first place so let's start
with what is pony so first of all has
anyone heard of pony Wow
okay that's unusual and very gratifying
thank you
so it's an actor/model capability
secured general-purpose native language
it's also an object-oriented language
under the hood although a lot of people
treated as a functional language there's
a lot of functional concepts but I'm
going to gloss over that a little bit so
actor main you create end end right
that's our version of public static void
main strength and string array args from
Java and all that means is that we have
some actor called main which is our
asynchronous type and actors in
asynchronous type once a class is a
synchronous type and it's got a
constructor on it a named constructor
create and there's syntactic sugar that
says when you construct an object and
it'll provide a name for the constructor
well you meant create and it's going to
pick up an environment and here it's
going to look in the environment for the
actor that represents standard out and
it's going to send it a print message
and that print message in this case is
composed of an immutable string and I'll
touch on that a little bit more as we go
isolation and immutability are
first-class concepts in Pony that's main
that's our pony so our goals with Pony
are these and the first one influences
all of the others which is static data
race freedom but with mutability it's
pretty straightforward to have static
data race freedom in
language that has only immutable types
but we wanted to make sure that we
retained mutability both locally inside
an actor and also being able to pass
mutable data structures safely with no
runtime overhead between actors so
that's what a lot of this work relies on
but we also want to leverage that type
system for other properties like no stop
the world garbage collection and I
really mean no stop the world where
every actor can independently collect
its heat without coordination its
formally specified it's not formally
verified but it is formally specified it
comes from building the type system and
the operational semantics first rather
than building the language first so we
wanted to make sure single node
performance is competitive with C and
C++ and it is which is very exciting we
take advantage of very aggressive
register coloring we don't necessarily
follow the C API inside pony world code
and it means that we can actually do a
little bit better than C on a lot of
numeric algorithms eventually
distributed computing but I'm not going
to talk about that today some good
domains for pony here they are okay this
is not a great slide because what does
this mean it means general-purpose
computing but actually there's something
in this a little bit shows you the
weaknesses of plumbing this isn't saying
it's good for scripting languages
because it's not it's ahead of time
compiled statically type language so far
people really aren't using it on the
client-side like the video games work is
all server back-end stuff and a lot of
this stuff is you know much more
back-end non user facing code maybe
it'll grow into that space that that
hasn't happened yet
there's a lot in pony I'm not going to
talk about most of it today right so
today I'm going to be talking about a
little bout data race freedom a little
about native code optimization
work-stealing message queues GC I'm not
really going to be talking about the
type system past reference capability so
not much on nothing on generics or
intersection types nominal structural
typing pattern matching distributed
semantics capability security and
capability Security's actually in some
ways at the heart of Pony I'm gonna
leave it out today bye if there's
something in there that you're
interested in that I'm not touching on
just speak up and I'll change the talk
and we'll cover
I'm perfectly happy to dive into any of
those subjects instead of one all right
so data race freedom if I can write to
it nobody else can read from it which
means if I can read from it nobody else
can write to it that's the core idea
behind ponies type system but it's also
the core idea behind ponies run time
because the runtime is co-designed with
the type system and the idea is to
leverage the guarantees that the type
system makes to have work that would
otherwise be expensive at run time
dynamic work be alighted entirely stuff
that we just never had to check so for
example the entire Pony runtime is lock
frame that's pretty fun all right so I'm
in five minutes that means y'all have to
jump in and ask questions now there's a
lot of existing data race freedom work
that has been extremely influential on
pony the one at the top is may be extra
special influential but they all have
had a huge impact on pony
so ponies reference capabilities unlike
well first of all let me talk a little
about reference capabilities and what
they mean they're a type qualifier right
they're an annotation on a type that
tells you a little bit more about the
type as its viewed through that specific
alias that you're dealing with so an
object capability is anyone familiar
with object capability security anyone
hey that's pretty good
so object capabilities you have data and
the methods express the things you can
do on that data a reference capability
says the methods that I can use through
this alias are further constrained right
so ponies reference capabilities unlike
some of the other some other work are
based on deny reasoning rather than
allow reasoning it's based on what other
aliases cannot possibly exist because
this one exists rather than saying
there's a set of permissions that we're
allowing the programmer to have on the
object at this point and that means that
we develop the capabilities from those
basic deny properties rather than coming
up with a set of operations that we
wanted to encompass and this is the
matrix that we ended up with all right
so
we have the first column here which is
when we've denied global read and write
aliases what does that mean and that
means that global execution is all
actors in the system local execution is
the current actor that is dealing with
the alias at this time so if we've
denied all global read and write aliases
then we go back to that initial
proposition right if no one else can
read from it then I can write right to
it that's what these are these aliases
are mutable so everything in that first
column is mutable but they're different
kinds of mutable one at the bottom
doesn't deny any local aliases so there
may be any other local alias that might
read from or write to this and we don't
know about it its existence we can't
track it there's nothing we can do so
these are we call ref their references
you can mutate the object you can read
from the object but you have a strong
guarantee that no other actor will have
an alias to that object true which can
read from or write to that object so
it's concurrency safe but then we have a
stronger guarantee here with transition
that says that there are no local write
aliases so it is write unique but it is
not read unique initially we didn't
think there was any use for this then we
discovered some uses for it and actually
it appears in a few places in the
standard library now as an interesting
pattern but by far the more common use
is the top one they're isolated there
are no read or write aliases at that
point yeah and if if I correctly
understand why do you need ref if you
can do anything with it ah you sorry
so ref is you can you can read from it
and you can write to it what you can't
do is share that object with another
actor so it's an object for which there
is no possibility for concurrency so I
can't send that object to another actor
nor could I have received that object
from another actor in that form although
interestingly that's where isolated
comes in because when you have read
excuse me you have local alias denies
that are the same as global alias denies
then you have the same properties in
both global and local execution and that
means that this these on the diagonal
here are what is called sin double those
are the reference capabilities that it
is possible to send to another actor all
right so that leads into the second
column here those are aliases for which
we've denied global right but not global
reading so they're immutable we can read
these but we can't write to them because
we can't be certain that no other actor
isn't also reading from them and if we
mutated them we would have inconsistent
data but there's two different kinds of
mutability here we have immutability
where we haven't made any guarantees
locally so it's locally immutable it's
only immutable through that reference
the act the current actor might also
hold a mutable reference to that object
but it might not and the other one is
where we've actually made the global
guarantee that's an actual deep deeply
immutable object it is not now nor could
it ever be in the future mutable and
that's safe to share with lots of actors
but there's a big difference here
between vow which is safe to share with
lots of actors and ISO which is really
only safe to share one actor to tongue
one actor I can have it you can pass it
to another actor but that's all right
because you had more than one that could
read from a write to it you'd have a
problem and the last one is tag opaque
means you can't read from it or write to
it does anyone have any idea what that
could be useful for why would you want
no Paik alias
yeah absolutely um and a classic example
of that in the standard library is
timers where in order to set up
hierarchical timing wheels you use
opaque aliases as to the timing
information as your canceled token for
that timing information and that gives
you really fast cancel behavior because
what do you do with climbers has anyone
written high-performance Network
applications anyone all right so the
people who have what do you do with the
timer check it who checks timers they
fire you check timers all I ever do is
cancel timers it's the only thing I ever
do with them
you set up zillions of timers and then
you cancel them right because you're
doing let's say you're doing IP packet
reassembly because you're doing network
monitoring or something like that and
what you're mostly looking for is
detecting time out windows and canceling
stuff so that's the super high
performance use case that you want is to
just get rid of the thing the other
thing interesting that you can
interestingly that you can do with tag
that is maybe not immediately obvious is
you can use it to send asynchronous
messages because an asynchronous message
neither reads from nor writes to the
target and that means actors themselves
are in are incorporated into the
reference capability type system which
is pretty fun it means that an actor
might fulfill the structural interface
in the same way an object would an
asynchronous class might fulfill a
structural interface in the same way as
a synchronous class and you'd have a
reference capability that guaranteed
that that would stay safe that's pretty
fun okay this is about reference
capability compatibility ifs anyone read
the morning paper anyone ever heard of
that okay I'm a huge fan of Adrienne
Collier and the morning paper he was
very kind and covered a couple of Pony
papers awhile ago and he drew and drew
this capability graph and I loved it and
I asked him if I could reuse it he said
yes for which I'm still thankful and
what this expresses is the programmers
view as opposed to the type system's
view of what it means for an alias to
exist
what other aliases could possibly exist
so if I have something over here what
could possibly
and my favorite one part of this whole
thing is this part here because he
summed up so nicely why we have local
immutability when you have a locally
immutable reference either under the
hood it's mutable but by the current
actor or under the hood it's immutable
and might be shared by many actors you
don't know what you don't care but it
couldn't possibly be both and it turns
out that's mostly what programmers do in
ponies they write Box methods on on
objects that they just need to read from
it's all you ever really need to do for
for most code to the point where it's
the default all right so that's a really
quick survey through my fact let me back
up that's a really quick survey through
reference capabilities this gets much
more complicated in the presence of
sorry yeah oh great what is the path
that you can go the transitions you can
follow fantastic question so one of the
nice things about the matrix that means
that I still think of this in terms of
matrix even though it's not necessarily
the way most Pony programmers think of
it is that it expresses that directly in
the matrix which is a capability can
decay down and it can be decay to the
right it cannot go up and it cannot go
to the left now I'm a little bit lying
because it's possible to create an
isolated scope called a recover
expression and in that recover
expression you only have access to
things in the lexical scope from outside
that little recover scope there sin
double and that means that inside a
recover expression the result of that
expression can move up you can recover
capabilities this turns out to be really
powerful and really useful because
instead of having a situation where you
can only do isolated things with
isolated objects you can actually have a
recover expression do very complex
initialization of isolated or immutable
things return it through the recover
recover capabilities and now you back to
an isolated or immutable object so you
can for example set up cyclic immutable
structures really easily and tribulus by
as if you were writing normal mutable
inside a recover expression does that
answer your question
cool awesome so um there's a lot more
that goes into this in terms of things
like viewpoint adaptation what does it
mean to read a field out of an object
with a particular reference capability
I'm not really going to cover that
unless people are particularly
interested it gets even more complex in
terms of alias tracking where you need
to under have inherent in the type
system the idea of an ephemeral type
does anyone know what I mean by an
ephemeral type like what's the type yeah
go on Paul Hartford there's no hope
sorry it's a reference that is only
exists as a temporary and there's no
stable alias nowhere so there's no
there's no way to name that without that
reference exactly so it's like the
return value for example exactly so
let's say you you've just created an
object and you return it from a
constructor
there is no named alias to that thing
and that turns out to be really powerful
because that's the process by which you
can pass isolated things around it can
consume aliases so that there are none
left and so that when you create one you
statically no with no no runtime
overhead that that's the only one all
right so now let's trips which ears a
little bit here and talk about a native
code optimization so as anyone worked
with native GC languages before all
right what native GC language is able to
work with yeah what native GC languages
have you worked with sorry D okay that's
an excellent example so um
D provides both manual memory management
and GC on top of native compilation so
it wasn't that long ago that that was
considered really weird combining ahead
of time native compilation with GC
nowadays fortunately that's not
considered quite so weird so it's a GC
language but not interpreted or JIT it
it's an LVN back-end we're gonna be
using the LVM linker soon and we really
try to push the boundaries as much as we
can with
of time optimization so we can pile the
whole thing as a single LLVM module
which allows whole program optimization
which is pretty nice now most of the
advantage of that comes in some of these
other things because it sure it allows a
lot of cross function optimization a lot
of inlining all this stuff but it's the
other stuff that really helps on that
for example reification the whole
language is fully reified when you
compile stuffs did anyone see why that
might be problematic though anyone
related question well yeah your question
there is a synchrony between the two
processes do you ever get programs
they're too big to compile with LVM
because of the whole program thing or
what's the story there the story there
is not yet and oh boy I love the pony
community
so yeah I'm constantly worried that
we're going to run into a situation with
a program that just exceeds useful
available memory and start swapping like
crazy the biggest codebase I know of is
a fin tech application out of a company
in New York and it's pretty serious it
up to a couple hundred thousand lines of
pony and they still have no problem
compiling but only because there's been
constant work in the pony community to
reduce memory usage and now there's a
nice effort by Benoit V to actually add
separate compilation to this strategy I
don't really know where he's going with
that and I'm really curious to see what
he's doing but it looks like he's mostly
going to be focusing on getting a STS as
far along as possible before you do the
code generation and saving on all that
memory but it is a persistent problem in
the back of my head about this this
compilation strategy is that it's
intensive its resource intensive on the
other hand asking for an 8 gigabyte
compiler machine these days it's sort of
okay and we've been able to compile very
useful programs on raspberry PI's where
that compiler is actually running on the
PI as well as the executable on the PI
and you know we've been able to run
programs that are 30 40 50 thousand
lines of code on a PI and no real
problem at all so maybe it's okay yeah
all right
so back to the bit about reification
does anyone see a problem with with
reifying all your types
does anyone worked with Java for example
anyone yeah maybe a little bit so Java
doesn't do this Java knows full well
that code reuse is incredibly important
right dotnet does as well yeah well if
you redefine everything you're going to
have like 50 copies of your list class
yeah so that increases your code size
yeah also you can't reify types of
infinite
sighs which doesn't really matter in
practice I think so
I think maybe it does and I think it's
actually a shortcoming in pony and
that's really important so you can
pretty trivially write a type that
generates new types in a way that if you
were able to generate those new types
dynamically you would have no trouble
with and so dotnet has no trouble with
it or Java has no problem trouble with
it the pony can't compile it and right
now all it can do is detect that you're
in an infinite loop and bail out of the
compiler that yeah go ahead so I mean
sorry reification here means basically
instantiation right whereas you could be
not instantiating and keeping a single
method and passing type parameters as
actual parameters that's another
approach right so it's not specifically
that verification is a problem it's just
that the approach you're taking is a
problem right you're absolutely right
that's a really good point if we took
the dynamic approach to that then we
could do this yeah that's really good
point I think under the hood and pony
because of type descriptors are so
important to what for the way the
runtime works we would have difficulty
in synthesizing a type descriptor that
was distinct from the other from type
descriptor for a class with different
dynamic type parameters if that makes
any sense but there's probably a way we
can do it yeah that's really good point
all right so one of the things that we
do a little bit to try and recover this
is leverage LVM so LVM is a really nice
merge function pass that does a better
job than you might expect in detecting
identical functions and eliminating them
and that turns out to be really helpful
so there's also no function level API
which means we can do register coloring
and really aggressive he to stack
allocation optimization so instead of
saying okay there are certain calling
convention on Pony functions now we're
just going to lunge it all up and
there's really no useful way to call it
the pony from any other programming
language and as a result it means that
we also generate on demand when you use
Pony as a library for a C or C++ program
we generate on demand headers and
separate entry points that follow this
davi so that we can get around this
alright right so there's actually a note
here on separate compilation which is
nice also probably should include that I
lie a little bit when I say that pony
isn't chick compiled the compiler now
actually JIT compiles test cases in Pony
when it tests the compiler and there's a
chance that that might spread a little
bit through through the language so we
talked a little bit about reach ability
and reification here and the only thing
I'm going to mention off here is that
binary sizes seem to be okay an HTTP
server and 312 kilobytes on a 64 byte a
64-bit machine it's okay so one of the
things that we do in run time too as
part of our optimization is something
called selector coloring as anyone heard
of selector coloring yon invented
selector coloring so this is a lovely
lovely trick that you can do which is
you can try and figure out in so much
the same way that you do register
coloring you can try and figure out a
nice contained sets of selectors that
exist on types and so that every method
of a certain name or possibly even
entire signature depending on you
implement it has the same vtable index
and that's nice right you don't have to
do something like what go does where you
generate alternate v tables or anything
like that but what could that be amazing
for that hand going up yeah yeah
if there's no ABI how do you debug the
binary when I doesn't know what he wants
in question that's a super good question
so the way that we deal with that is
quite fun so we generate a full set of
dwarf information and we print right now
we pretend to be C++ when we generate
dwarf information hopefully we're going
to get beyond that but in order to do
that we're going to have to write a
language plug into ll DB and possibly
for gdb but by pretending to be C++ and
generating dwarf information it turns
out both ll DB and gdb can cope with the
fact that we are not following a
particularly behind they can cope with
it really well
so we can debug Pony at with gdb and ll
DB which is pretty neat now what we
can't do yet is Parrs Pony expressions
in the debugger so what you end up with
is this is funny skill set as a pony
programmer where you're debugging your
program and you break and then you start
expressing Pony as see expressions the
debugger can parse and execute over your
pony data so that's not very good that's
not a very good story but at least we
can get to the point where we're doing
binary debugging and that's a really
good point and actually that raises the
larger question of tooling in general
and profilers for example it turns out
violating the ca VI also doesn't matter
to profilers because as long as you've
got these you know elf style entry
points depending on your platform it's
okay so you can run instruments over it
you can run vtune over it and you'll get
all the same data you get out over C or
C++ program which is a really big deal
right to have that kind of tooling
support it's not really first-class I
don't want to oversell it right because
it doesn't understand that it's
debugging or profiling Pony it just sees
something with with a bunch of function
calls that look like they're on a C
stack and so it gives you some
information that's pretty useful
ah yeah that's an excellent question do
you want to ask it in I don't know if
everybody heard okay so there's no API
but does it at least respect the frame
pointer register yeah it does in fact it
it keeps the exact same stack approach
to stacks as C does and that turns out
to have other benefits as well which is
that we can have incredibly cheap CF fi
right to call C we just call the
function there's no marshalling there's
nothing now if you want long lived data
inside of a C function you might have to
deal with pinning because of your juice
of the GC but that's really it all right
that said we have been looking at moving
to perfect hashing for method dispatch
and that's to deal with rebels basically
and loadable code maybe so I'm not sure
if we are going to go down this route
and if we do I'm not sure if it's going
to be for all possible compilations of
pony but it's a way that is a bit slower
than selector coloring but it allows you
to load code right it allows you to
expand the set of methods because if you
have structural types that you're doing
selector coloring over you have an open
world type system so as soon as you add
more types your selector covering might
be out of date all right switch tracks
again and go to work stealing so actors
are essentially a lightweight threading
mechanism right okay sure they're a lot
more complicated and as an actor/model
person it kind of makes me feel for
people it makes me crazy when people say
that but it's true and so under the hood
what we do is we have scheduler threads
that are bound to force and a scheduler
thread has a queue of actors and an
actor has a queue of messages so while a
scheduler thread is executing an actor
behavior that's it that's all that that
stack is used for is executing that
behavior right this is quite different
from other approaches where you have
cooperative scheduling of actor
behaviors and things like that so right
now we don't do any cooperative
scheduling anyone think that's a problem
anyone no one thinks not having only
cooperative scheduling endo pre-emptive
scheduling from yeah exactly
yeah so because of the work stealing it
means that other threat scheduler
threads pick up those actors and and run
them so you'd have to have long-running
behaviors across your scheduler threads
in order to provoke a problem and if we
run into that we're we're gonna add
assistant the runtime of spawning up new
scheduler threats but that's a little
bit more complex so scheduling actors on
scheduler threads is a bit tricky
has anyone ever dealt with Erlang
alright good so are you familiar with
how Erlang schedules actors across cores
yeah okay it's a little problematic it's
it's it's difficult okay someone is
definitely dealt with it because they're
laughing
so pony takes an approach that is trying
to emphasize cash over everything so if
you send a message to an actor that is
currently has an empty queue we'll
schedule that actor on the current
scheduler thread because the message
itself is more likely to be in cash than
the actors working set right but if you
send a message to an actor that's
already scheduled on some scheduler key
we leave it in place it is more likely
that it's working set is in cash and
would owe the size of that working set
is likely to be bigger than the message
not necessarily them all right so let's
look at schedule accused here's the
claim zero atomic operations two in
queue at as loop to DQ single single
producer multi consumer queue to allow
for works do anyone believe me
no excellent I love that so actually
given that let's just go to the code
here we go
so this is push single right here is
that readable no let's make it bigger
and let's change the font a little bit
here
here we go who sees a problem with that
anyone on push single we have a load
explicit that's non-atomic on x86 store
explicit atomic on x86 yep
without having to it's not atomic we
still get meat on behavior
alright it's a trick because the problem
comes when you're popping and popping
takes a little bit of code there we go
on the scheduler case so what I'm gonna
instead I'm going to show you is how we
do it on a message queue because a
little simpler to grok so let's talk
about fast Azir copy message passing so
I know I promise I'll explain the queues
as we go so reference capabilities allow
us to pass and share functions without
copying right because it makes all these
lovely data arrays freedom guarantees
but that's not good enough
we need crazy fast queues so here we're
going to have one atomic exchange with
no loops to in queue and zero atomic
operations to DQ on a multi producer
single consumer queue alright anyone
believe me
good here's thank you and this one's a
little simpler to understand now this is
taken straight from the runtime so you
know it's got like if def use eval
ground in there and stuff like that but
try and get past that so what we're
doing is we're storing a null pointer to
the next now I have to warn you that I'm
a runtime writer and as a result when we
have a queue obviously we push to the
head and we read from the tail okay I
it's I'm sorry that's just how we write
queues so we're going to change the next
pointer to no and then we're going to do
an atomic exchange this is I want to
known the atomic operation there's no
Kaz loop there's no nothing here and I'm
going to change the queue head for our
new pointer what's the problem not only
that we're doing with a relaxed memory
ordering what's the problem here anyone
sorry yeah
what the hell you didn't change the tail
did we right so this is an inconsistent
queue at this point
the next operation is we take that
previous pointer which was the thing
that was formerly the head and we fix up
its next pointer down here what that
means is there's a period of time in
which the queue is non-empty and a
reader may see an empty queue and as
long as you're willing to accept that
right that there's certain kinds of
linearise ability that you can't really
Express with this now you can have a
crazy fast queue there's also some stuff
in here to detect empty queues
atomically and things like that and
that's for scheduling so that gives you
a DQ that looks like this what's the
problem
anyone used to reading this kind of code
so we're reading the tale that's good
we're finally reading that damn tale now
we're loading next off the tail the
thread fence is actually compiled down
to a no op on x86 that's it for the arm
implementation we change the tail to the
next pointer we free the previous tail
you return next there are two problems
here any one now okay so when we return
what we're returning is something that's
still on the queue and that's for memory
management the other interesting one is
that we can read next that's null for
out of that inconsistent queue and the
only reason that's ok is because
messages in Pony are causally ordered
and this enforces that at zero cost in
the runtime and the nice advantage is
this kind of enforcement means that
you'll come back and read the next
message eventually so it's fine all
right yeah
one atomic 2d hue or NQ I can't remember
which one yeah but that's on Intel and
you like seem to take advantage of the
Intel memory model how like how does
that change on our more other places and
like what's your cost there excellent
question
so Atomics store explicit here from
relaxed memory order on arm this does
mean that you're going to set up
possibly I'm not familiar enough with
the arm instruction set to know exactly
the cost there unfortunately but you are
going to set up a load LSC and I can
never remove the ll store conditional
and not only that but you're going to
pay possibly a little bit more cost here
on the store explicit and on DQ the most
important cost of this whole thing those
costs are pretty minor that's the one
that kind of hits you is that you need
to thread pence on arm to take care of
this if anyone wants to volunteer their
skills with low-level arm Atomics I
would be eternally grateful I suspect
that there are optimizations that we
could be making on arm it's a really
good point
all right I'm out of my time for this
stuff
does anyone have more questions on this
yeah excellent
yeah I guess it obviously does raise a
question here for me you know like x86
and arm yeah yeah I guess you know they
are the big players okay yeah but it
does make me wonder how tied you are to
these architectures and if we have some
new architectures come along are you
gonna be able make Pony run as well on
those machines that's an excellent
question
so right now there's a guy in the
community that are nsoos doing a mips
port it's gone pretty well for him
unfortunately he's keeping it for
himself at the moment because he has a
start up and down in London but
hopefully that'll heal open source that
soon but he's using it in in the code
that he's supplying to his customers or
does work all of our atomic operations
are encapsulated in a single header file
that is essentially the file to be
ported
for the low-level runtime if we've done
it right which is an open question
porting just that header file to your
new platform is sufficient at the atomic
operation level to cope with a new
platform there can be some other issues
that you might need to cover too that
have to do with whatever your C runtime
is and stuff like that but architectural
issues should theoretically be confined
to one header file that needs alteration
and we're using concepts that are pretty
well-established so if a new
architecture will come along and have
drastically different concepts in terms
of what atomic operations look like and
what memory ordering looks like we would
probably have to be examining but if
someone wanted to do a PowerPC port for
example that would be trivial right
because it has pretty close to the same
atomic semantics as an arm but that's a
really good question and actually that
is related to another problem that we
have is that we originally wrote this as
a 64-bit only language and the theory
that ah who needs 32-bit computation
well lots of people need 32-bit
computation and we had to backtrack
really quick and so we have native types
to express things like a pointer with
integer which we really thought we
weren't going to have to do fortunately
we're a little more strict about it than
C in terms of what what you have to do
after you explicit conversions of bit
widths so this Pony code doesn't need
porting when you move between 32 and
64-bit only the runtime does which is
pretty good yeah I have a question it's
not related to the internals of the
language or what plans do you have for
for the language ecosystem or tooling or
things to make the developer experience
more productive as a fabulous question I
think in many ways that's more important
than the language itself so the answer
is we're trying not to dictate to the
community is and that's kind of a
cop-out and kind of a good thing so so
far we've talked a lot on github issues
primarily about package management for
example and the different approaches to
package management and there is a
package manager out there called stable
which is pretty good it deals with a lot
of stuff it does not deal with
everything the author wants it
deal with Joe McIlvain but it deals with
everything I want out of a package
manager so I'm pretty happy with it but
I think it spreads beyond that so we
have an RFC process that we shamelessly
stole from rest they have an excellent
RFC process that we copied it and that's
meant that the community has had a
pretty big impact on the language so far
that's meant things like editor support
has gone really well one of the things
we're really looking forward to is
there's a project to build a back-end
for type checking and compiling that
follows a particular protocol the name
of which I escapes me that sorry thank
you that's the one so light and follows
language server protocol so you can plug
into lots of different editors and get
all kinds of really neat features out of
that that's in progress right now
debugger support as we were talking
about earlier I think is a core part of
this and we're going to need better
debugger support I'm particularly
interested in actor model debugging
because it seems to be a little
different what if I want to trace an
asynchronous message instead of a
synchronous function call and it would
be really cool to move towards debugger
support that can treats that as a first
class problem are there any other kinds
of developer ecosystem type issues that
you were thinking of all right I
actually finally we are running out of
time so I think we have two thanks Allen
and go for a break and then meet here in
ten minutes thank you
and just a quick note if you do want to
talk about garbage collection I will
happily waste all your time thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>