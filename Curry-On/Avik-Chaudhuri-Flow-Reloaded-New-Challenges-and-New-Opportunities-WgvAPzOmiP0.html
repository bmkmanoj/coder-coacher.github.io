<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Avik Chaudhuri - Flow Reloaded New Challenges and New Opportunities | Coder Coacher - Coaching Coders</title><meta content="Avik Chaudhuri - Flow Reloaded New Challenges and New Opportunities - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Avik Chaudhuri - Flow Reloaded New Challenges and New Opportunities</b></h2><h5 class="post__date">2017-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WgvAPzOmiP0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">really large room there's a larger room
than we've had for any of the Koreans
before
so Mike running is going to be a little
bit difficult so if you have questions
for the end of the session you should
line up at the center Mike and that will
work a little bit better than having a
steamed bun tears run the mic around
okay all right so take us away all right
thanks can you guys hear me all right so
my name is Alek Chaudhary I work at
Facebook
you joined Facebook around four years
back on this when we said this project
got flow it's been around for a while
today I'm going to talk about us where
we're going in the future
so what's flow though is a static type
checker for JavaScript we've been using
it for facebook for the past three years
or so it's it's fairly widely used we
have lots of JavaScript at Facebook
running in the millions of lines of code
and it's all new JavaScript code is
written flow at Facebook and most legacy
code is also being covered by flows at
this point we are we're at around 70%
coverage of the code base and we are
doing pretty well there it's also open
source it's not the only type checker
for JavaScript that you can use there is
also typescript it's pretty popular
outside types rip has been designed
mostly of to do a Productivity through
an ID flow I would argue is more
technically interesting it's not
blatantly unsound for example like
typescript is it's more principled on
the other hand it's not as polished so
some number of developers choose to go
put go with die spread a typescript at
Facebook what we value is catching as
many as many bugs as possible without
necessarily adding annotations
everywhere that is needed so flow works
pretty well for the
use case it has a lot of type inference
built-in so usually I've given when I've
given a talk on flow I've described how
flow works internally both in terms of
the type system and how we scale it to
Facebook's needs this talk is going to
be slightly different we're going to
talk about the future so even though
Facebook flow has been scaling at
Facebook pretty well I'm going to talk
through some of the scalability
challenges that you're facing as the as
our code bases are exploding in size I'm
also going to talk about soundness which
is something that flow has always been
very soundness has been very important
for flow from the beginning but we have
not really started exploiting it it's
still an optionally type system where we
apply sound inference rules but you can
also have uncovered code that I just
mentioned so I'm going to go into more
detail there so before we start let's
begin with some code just just to give
you a flavor of how flow works I'm not
going to go into too much detail but it
is necessary to understand what I mean
by scalability so this is a simple
function that takes a parameter and
doubles it and we call it with a number
and we try to access its it's length
property or call length method on it so
the wave flow works is it translates
this program to a bunch of constraints
and the constraints describe what what
the behavior of the program is is very
abstract it's at the level of types but
it still captures very faithfully what
the set of values that might flow
through every part of the program is so
here n describes the type of small n
which is unknown at this point but what
we know is that is being used as a
number when we are trying to multiply it
by two the result of that multiplication
is going to be a number and that flows
too
let's say this this thing called D which
stands for double which is the return
value of the function this whole thing
that is describes the function itself
can be described as a with a function
type that goes from n to D and that
flows to the type of foo meanwhile fools
being used as a call with passing in the
argument which is a number the result
type is unknown which is the type of the
expression that surrounds for Cory - and
then we are going to we are calling the
length method on it which can also be
described as constrained like this and
the result of the the length call is
unknown right so this basically gives
you a flavor of how flow translates a
program a JavaScript program into a
bunch of constraints and then it can
solve it using very very standard
techniques where it applies these rules
and transitively closes the rules so by
applying those two by by combining those
two lose you get that the function type
goes to this kind of call constraint and
because we know from subtyping how the
flow should work the argument goes to
the parameter in a kind of contravariant
direction and the return goes to the
result so we have two new constraints
and then we can keep combining these two
these constraints over and over again
and eventually we hit a constraint like
that which says that we are trying to
call the length method on a number and
this is an error so this just gives you
a flavor of how flow cat catches errors
and programs of course in JavaScript not
everything is a huge huge you know file
with a bunch of Coronet and you don't
typically stick stick that all of that
code into your web page otherwise your
page loads really slowly so you break
everything into modules and typically
these modules are very small to keep the
dependencies very fine so here I've
shown you how I split the program
that we just showed you where the
function is defined in one one file and
it's exported and we import the the
function from a different file and the
constraints that we generated exact more
or less exactly the same except that
they're generated in two different files
and the way they are connected is that
this fool goes to this this thing called
e which is let's say describes exports
of file 1 and I describes the imports of
file 2 so we add constraint that says
that well e flows to I the exports flow
to the imports and then we we can do
whatever we already did in the previous
slide so so I'm going I said I'm going
to talk about scalability right so the
thing is this this algorithm that I
described is an order and K algorithm
where K is not 1 K is greater than 1 K
is not too large it falls somewhere
between 1 and 3 typically the kind of
analysis that I showed you is so-called
subset based inference and it's cubic on
the other hand if we chose to use
unification it's kind of quasi linear
what we do is is a combination of both
we have mostly subset based inference
however because some of the subtyping
rules that we apply are invariant so it
is essentially the talking about
equalities and not not inequalities we
can use some some unification as well
but it's still not 1 right and we will
see how that that could be a problem
arisen so n is for for one of our
largest code bases it's already ten
million lines of code and growing very
fast I'll show you a graph later on the
talk to show you exactly how this this
amount of code is increasing so if we
dive deeper into what n is n is more or
less some constant which describes the
maximum size of a file and typically
this is something in JavaScript that
kind of
promotes this the style of programming
but files are individually not that big
and we kind of exploit that fat each
file is more or less something around
100 200 lines of code
there will be the occasional outlier
that's the some kind of generator
JavaScript file there will be 10,000
lines of code but but mostly it is
around this this number and then the
remaining number is the number of files
that we have our code base right so
essentially this is order of F to the K
where F is the number of fives the code
base so it's essentially order
because F is pretty huge all right so
the first thing we do which we did right
off the bat right so that we kind of
discovered right when we were getting
started that a whole program in Asus is
not going to work so we broke this thing
with chunks and did modular analysis and
annotations were the things that came to
a rescue so what we decided is that we
are going to ask for annotations add on
your exports and that gives us instead
of F to the K it gives us more or less F
multiplied by some constant some large
constant but still constant more or less
so if C is again the number of lines in
a typical file and s is the size of the
type of exports which is kind of order
of the the same kind of lines of files
it's a bit more it can be a bit bit
larger but it can still be bounded by a
reasonable number so so we have analysis
that is not F to the K it grows linearly
with with the size of the number of
files and that worked well for us for a
while today I'm going to describe why
that even that is not going to work for
us in the future
so the way flow does this analysis and
more detail is that it has a dependency
graph between all the files this this
graph graph can be pretty very large but
we also have a lot of power in our
machines nowadays a lot of developers at
Facebook who are developing on the
website for example
they they use pretty powerful dev
servers with a lot of parallelism a lot
of people also code on laptops and even
laptops have around 8 processors or more
nowadays so we use all of that sometimes
laptops catch on fire while while
they're running flow but but even then
we have that parallelism to exploit and
the way we do this is as follows we have
typically more more files to process
many more files to process than
processes so we assign a bunch of files
to the to the processors and these are
these get started with with kind of the
leaf files which don't depend on
anything else and then there is some
number some queue of files that are
waiting to be scheduled and these are
files that don't have any dependency
there they just blocked because there
are no processes on which they can be
processed and the rest of the files are
still live in the in the dependency
graph right so at some point one of
those files gets done and then we
inspect the dependency graph and we
discover that some number of other files
were blocked on this file being
processed some of the files that are
blocked might have other dependencies
that are still churning so they they are
out of luck but for example the the file
on the right this this file that that
got done was was its last dependency so
it's no longer block it becomes glue is
added to the queue we also get get some
more files off the queue and then we
assign them to these processes so so the
way this execution works is it picks
some sort of topological sort at runtime
depending on what the load of these
processes are typically the processes
are always fully utilized because a lot
more files and processes and even even
if some some files are blocked on other
files or other files can make progress
so this kind of works really well so
this is so the architecture here is that
we
we take a bunch of files and we spend a
lot of time analyzing all of the files
and then we recall that the
initialization phase and at the end of
it we know everything about the codebase
typing wise and then we wait for other
files to be touched and then we recheck
them on demand so suppose that we we
touch a file somewhere in the middle and
we want to recheck some-some number of
files at least that one but potentially
other files that depend on these files
as well so we lend them rechecking a
bunch of files if you touch a file that
is very high up in the dependency graph
then then this might take some time but
still it's it's far less than the number
of files that were initially in your
code base so this is can be bounded by a
few seconds at worst so but but that was
you know at some point that desktop
scaling as well because people were
building a huge inheritance varieties
for example or they had long chains of
dependencies in the in the graph
abstraction / abstraction abstraction
sometimes these we just took really long
so you can't just mark the dependent
files for for each I think because the
set of files that you end up rechecking
every time you touch a file can become
really large very soon so then the next
idea is that we sired hashing and
comparing the types of exports o file
and if if those exports did not change
then we stop we cut the reach X this is
also very very reasonable very simple
idea but the exact mechanics of how what
how this action works
is a little tricky everyone say it's too
tricky at the least you have to make
sure that the hash is not sensitive to
irrelevant fresh IDs or variables that
you might be creating but but beyond
that you
this kind of if you're really lucky you
you will stop right at them
the first step let's say you kind of add
a character or two typically are not
changing the type of exports and your
dependents note don't need to be
rechecked sometimes you are less lucky
you might end up actually substantially
changing something you add a line and
your exports go down one line even that
might cause you to recheck some number
of files because we care about because
of error reporting we care about
locations of where things reside because
because we want to point back blame to
correct locations so you might end up
rechecking some number of files but but
you tend to stabilize after after a few
levels so this optimization works this
was implemented some time in end of last
year I think however the big problem is
this even though all of this works at
the at the rate of set of files that you
have in your code base that number is is
increasing exponentially so when we got
started around four years or three years
back we had around 10,000 files that we
had to check in three years we and we
now have 100,000 files right so that the
10 million lines of code are divided by
100 it's around hundred thousand files
and more at every time I look at the
number of files it keeps growing so that
kind of corresponds to this kind of
curve which is really exponential we are
hiring a lot of people they're writing a
bunch of code so scaling linearly does
not work as well so at some point a lot
of people in the company had this aha
moment that our tools should scale not
with this size of the repositories but
the size of the working set of an
individual developer which is far more
constant right so even though we hire a
bunch of people and
they might be working on different
products and even though maybe we might
be using a mano a mano repo with with
all of their projects and one repository
typically the the number of files that a
particular developer might be touching
in any given week is is not that large
even if you count all of his
dependencies and dependents it's not a
large number so you want to scale with
that rate otherwise the productivity of
each individual engineer is going to
have every year so which is which is not
good
so what how do we do this well the
actual implementation of what we do is
not very difficult we just become
completely lazy and don't do anything to
begin with so remember I told you about
this initialization phase where we look
at all the files and we try to
understand what all of them do before we
start waiting for files to be touched
and then rechecked now as of as of a
week back in our very last release we
kind of released extramural support for
a so called
lazy mode of type checking which does
nothing at the beginning and then now
when you touch a file this is a
disappoint at which actual type checking
starts this is not a real check there is
a check for the first time so not only
do we have to check its dependencies our
dependents but also its dependencies so
the purple ones are the things that are
required for for this file to be checked
even for the first time so that's that's
what this involves however given that we
have a huge number of files at any given
point if you start doing not start by
doing nothing and then slowly add to to
your world as as you touch different
files you bring their dependencies into
your world and type check them that that
number per our measurements are does not
grow very quickly it kind of stabilizes
after a point
and we we can have achieved that that
kind of sub linear pretty constant
looking scaling factor so we're kind of
excited about this we see how this goes
for the euro so maybe next time I give a
talk I have to talk about yet yet
something else that we have to do for
scalability so let's switch switch gears
a little bit and talk about the next
thing which is soundness all right and
here I want to give you some context
which is a website cells that flow is a
static type checker for JavaScript and
that's how we tend to market ourselves
but when we design flow it was already
clear to us that is not just a type
checker the real picture of what flow
does is more or less like this it's a
huge box full of gears there lots of
static noises going on with one goal in
mind which is type checking but it's
like proving a theorem right so as often
you end up proving a theorem but prove
proved a really big lemma before you can
get to the theorem and the theorem is
just you know combining some building
blocks but you end up end up doing a lot
more work to carry along the necessary
invariance around so we have some points
to an ass's built-in inside we have some
alias enhancers built in all of these an
s3 for for flow because javascript is is
a tiny bit complicated and we have to
support a lot of idioms that javascript
has however what what comes out at the
end is just this you know in a post and
looking message which is saying it says
most of the time it says nowhere else
sometimes it gives you a bunch of errors
so you might think that nothing much is
happening inside flow so one of the ha
moments we had at some point when when
people started complaining about okay
why why does flow behave in this manner
and why is fluid flow kind of burning my
laptop we kind of poked some holes in
this box and they become real became
really happy and this is what type
script as well does it kind of
poses more of the gearbox whew well so
now programmers even though they may not
have any errors in the code base they
are getting some some information out of
the type system right so so they can say
they can they can discover what the type
of a particular expression is or a
particular method call is they might
want to know which which definitions you
a particular reference is pointing to a
whole bunch of other information that we
can expose through an ID all right so
this was what we did maybe a couple of
years back and that kind of really
turned around the perception of flow
inside the company but why stop here it
had been a dream all along to kind of
expose more of this stream box as I this
is this box of gears and kind of try to
exploit all of the information that flow
has for even more things things like
transforming your program automatically
for performance optimizations and
whatnot so this is what we want to do in
the future and we assign some work in
this area we want to do things like
constant inlining and property renaming
things that are more in the compiler
directory more in the territory of
transforming JavaScript programs and to
equivalent JavaScript programs that
potentially load faster or better in
different ways so you might think that
these optimizations are really kind of
simple and you know they may not get you
much but in JavaScript they do matter so
for example what is constant lining well
we have a bunch of files that define a
bunch of constants these are typically
these represent actions that a
particular part of your product
might make we have a bunch of enums enum
like situations we have a bunch of
strings that define cases in a kind of a
disjoint Union type something like what
you would do if you had if you were
writing an algebraic data type and ml
and kind of switch on stuff
of these kinds so we have lots of
constants in our code base and they
define these huge files and sometimes
when they're used the entire file that
defines these huge bag of constants has
to be loaded and before that particular
code that is using one of the one or two
of these constants can be executed right
so in JavaScript this is a big deal
because you tend you know loading
loading huge modules it takes takes up a
lot of time parsing time to begin with
but also other things so if you inline
the constants it means that you do not
you cut those dependency I just say you
so you don't have to you don't have to
load these huge files at runtime and you
get the same behavior right so this is
not very hard for flow to do because
flow already has a concept of single
internet types so a literal a string
literal or a number literal has exactly
that type and we already use it to play
check these these patterns that people
write at Facebook so constant lining is
not a big deal because it's just a type
that we propagate from one place to
another place property renaming is
another big big deal as you might have
heard that JavaScript gets minified
before it gets shipped on a browser or
wherever else this minification process
is is a process by which code is so
variables get renamed for example two
shorter names you might for for software
engineering purposes you might have
really long names in your code base and
that's good but if they can be
transformed automatically into short
names like a and B and C then that just
means less bytes to to ship over the web
if you have to rename variables that's
really simple a lot of minifiers do that
if you have to rename properties of
objects that's much harder because you
need to track where objects flow
throughout a code base and you have to
rename their properties in sync
everywhere otherwise your code is going
to break so that that requires some sort
of like flow and assets the kind of
analysis that flow is good at so the
point is that there's a lot of
information in there
we want to expose these things and
become more of a compiler to drive
performance optimizations in the future
so this is all well and good it seems
like flow has the power to do this but
there's a big problem with this I told
you at the beginning that flow also is
optionally typed so at the least it
involves this type called any which is a
dynamic type through which you can
interact and so the question is which
types in your codebase can you really
trust so this is a really a big elephant
in the room a lot of people who talk
about flows potential and kind of
entering the compiler space I really
worried about this problem and my
typical response to that is that it's
not a big elephant that we have to deal
with it's it's really more of a chicken
it's hard to you know catch chicken but
but it's really harmless and I'm going
to use this word cause sound II which
some of the people here in the room kind
of invented it I would like to see that
term formalize because I think there's
something there
so flow was designed to be sounding in
the same sense as this this manifesto
that I'm mentioning described it to be
which is it's mostly sound unsoundness
is limited to corners they're really
there for reason and you can you can try
to segregate those those unsound parts
so the plan for the flow and this area
is that well there's also a bunch of
bugs that we didn't pay a lot of
attention to because all we had was the
ID use case up to the up to this point
but that's that's fine we can we can fix
those then we add this thing called
trusted types and the main thing here is
that we do not want to do to make flow
to make a different kind of flow that is
that is a stricter mode of flow now we
don't want to do that you want to evolve
flow to the
still smart by default and then we can
take advantage of all the checking that
we already do in our code base and not
have to retype check everything and and
have yet another set of rules that the
people have to abide by this is an
important point because some people from
Microsoft Richard research had tried to
make type scripts safe by posing
something called CF type script that
essentially takes the set of rules the
type script has and throws them away and
then replaces them by kind of new rules
fixing a lot of the unsound rules so we
do not plan to do that we basically want
to take the same rules and attach some
some additional information that will
allow us to to know which types you can
trust and which types you cannot trust
let me touch on bugs for for a little
while there there are lots of known bugs
in flow which which we plan to fix but
there is a long tail of unknown bugs and
we are kind of really worried about
these bugs and I do not know what the
correct solution is to find unknown bugs
in a really large production system
other than these things which is like
really stare at the rules hard we have
some some ideas on how to do a random
destination to you know fine find more
bugs and there's an intern who's who's
doing some good work here so maybe
something will come up he's actually
trying to manage to find some of the
bugs we already know about if if we keep
manage to not find unknown bugs maybe
there are no unknown bugs I don't know
we're also trying to formalize various
parts of the code base as are various
parts of the rules and maybe maybe we'll
catch them both from there but the thing
that I want to focus on is this again
this idea of trusted types so typically
when people talk about gradual type
systems not optional type systems with
gradual type systems where anything that
interacts with a dynamic type code has
to actually add runtime checks too to
kind of
assert that these these types are sound
we are not there yet and I claim that we
can kind of segregate the problem and
first try to mark types as trust and
untrusted before we get to the point
where we are actually changing program
behavior inserting runtime checks and so
on so the picture is as follows you have
an untyped code and types flow from
there to code that is covered so so
aren't really untrusted parts are read
the things that look like types but is
still untrusted or orange and actually
people already write dynamic checks and
flow has enough power to to refine types
based on dynamic checks so it can
recognize after these runtime checks for
example if you check that something is
actually number at runtime by checking
the tag of a tag of value we can promote
an untrusted value to a trusted type so
briefly the rules that we are thinking
of look like followers also in an
optional type system any is the main
source of and soundness because all
types are subtypes of any and any is a
subtype of any other type which is you
know very very easily exploitable so
what we want to do is like color the
rules a little bit with trusted and
trusted so trusted on trusted things can
can go to any no problem at least for
primitives but on the other hand any can
be considered to be a number only of
that number is marked as untrusted for
functions and objects things are
slightly more complicated because
imagine that you have written a function
and it escapes to one type code you
actually do not know what where the
parameter can any parameter type can be
trusted because untyped code can can
call your function with arbitrary
arguments so but the
kind of the B we were thinking of
function types is kind of captures this
in a very very elegant form so P if you
have a type a function type that is
escaping to any all you do is do what
other gradual type systems also do which
is treat any as the function type any to
any and then you have your normal
subtyping rules that kick in and try to
mark your parameter types as untrusted
which is exactly what we want in this
scenario same on the other direction
this is just you know pure typing going
on for objects then we can we can extend
the same idea it looks like you know
this kind of painting is sensitive to
polarities so we can just you know apply
the right rules when we have objects if
you have read-only properties or right
only properties or read/write properties
we kind of do the tainting in the proper
directions and they should work out
however this is not that simple
in with objects you also typically have
a bit subtyping rule that allows you to
lose some information this is the basis
of abstraction in a lot of languages so
if you have an object with with an X
property and a Y property of different
types you can forget that it had a
particular property so you can cast it
to this smaller type which is X colon T
and now you have you forgotten that you
had a Y property however if you leak
this object to untyped code then type
code can do anything with this object in
particular it can actually muck with you
Y you can override your Y property and
then this invade this invariant that Y
is type of s is in danger
so it should really be marked as
untrusted so so just you know applying
these rules blindly it's not going to
work so it's still a bit tricky and we
have some ideas on how this can be
solved but is still work in progress I
did not claim that I have all the
answers here today I just wanted to talk
about challenges and Here I am right so
this is done so this is my last slide I
just wanted to summarize that
you know this is really I consider this
to be kind of chapter two and Flo's
lifetime up to now we have been proving
that we capture a lot of common
javascript idioms we have fairly precise
we scale pretty well
however for for Facebook's unique needs
we need to do some really cool things to
kind of scale much faster and just
delivered on that but soundness is is
where you want to go in the future so in
six months or so we hope to make more
progress here
that's it so we have a little time for
some questions again just because of the
size of the room if you could step to
the center Mike that would be really
great
I think I managed to do so I had
actually have two questions for those
stones one may be a lot of people won't
ask so what tip what's your plan on
moving on with type systems like what
what features are you considering to it
do consider some features to the type
system to make it's more expressiveness
like G IDs or maybe dependents please
type something and so on okay so we
actually don't plan to add a lot of
features we consider like the design is
mostly stabilized however it's easy to
add features and people keep asking for
features all the time so what we
typically do is look at what patterns
are imagining new patterns are emerging
in a code base or from outside from
github and and then we try to like you
know respond to those things so one of
the things that we are working on now is
this es7 feature which is like a feature
that's going to come in next year
probably but we already started using it
in facebook which is object spreads
which allows you to take an object like
spread it into another object this is
very good for like object composition
and kind of moves in the opposite
direction as inheritance so is we
consider that it's a good thing so we we
kind of are trying to support that and a
lot of people also ask about some some
kind of weird kind of types which are
more higher higher conduct types the
idea here is that you have a lot of
frameworks which take particular shapes
of objects and then transform them to
other shapes of objects and transform
them in a very regular way so we need
types to kind of express these things
these kind of transformations and the
tape types to other types so we have
some support for that and more support
is planned because some people are
writing some new frameworks that will
exploit those things but yeah all of
these are kind of directed to use cases
and not really say if we don't find a
use case a very common use case where
GID T's will be useful we will probably
not add three entities and if I may the
second question it seems that
efficiently typed JavaScript program
flow type can be compiled to some more
bare metal thing like I don't know maybe
knots like native code with something
like that yeah or some other language
because now it's it's trans to compile
everything to JavaScript but here
sometimes it seems like it's a good idea
to compile JavaScript to something here
I do you like flow seems to be a good
fit for such tasks do you plan on doing
something or make sure one wants a
better time like let's let's try to
think what what crusty ties will look
like and experiment with a few less
ambitious things but Andrea Strasbourg
was just here pitching his talk at PL di
where they are talking about web
assembly and it's quite conceivable that
one day flow type JavaScript can be
compiled to as a bass inghean and run
much faster than JavaScript sure yeah
thanks hey Sebastian eiectric from the
Technical University of dubstep I have a
question about the scalability section
of your talk so you presented this
approach where you use laziness to only
check parts of the real check ups of the
files but how long do you do it like
until you reach a transitive closure
where everything that's reachable has
been rechecked or so so no so that
that's the whole point of it because the
reason we are being lazy is that one
particular developer given the lifetime
of the server the summit server might
crash for different reasons but
typically a particular developer keeps
the server life maybe for one week or so
and in that week you will take a you
know touch only only a subset of files
and it's enough to just type check that
subset of files including the
dependencies independence now the key
assumption that I missed I didn't say is
that you need to start from a state
where there are no errors and we already
have that built in so so every commit
that is there is chap 10 into and to our
trunk is is flow clean so which means
that we can start off from an arbitrary
commit after
after the program like programmer you
know rebuses is kind of local work on a
particular commit we can assume that
that commit has no errors and then we
can just look at the files that were
touched after that and if that turns out
to be no errors then then it's easy to
see why you know it's safe to check in
that code we look at the immediate
dependencies independence yeah
immediate actually transitive yeah
because we there's some amount of
inference going on that goes through
annotations sometimes you have to look
at yeah thanks okay let's thank the
speaker
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>