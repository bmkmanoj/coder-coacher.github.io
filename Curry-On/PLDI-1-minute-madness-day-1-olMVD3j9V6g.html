<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>PLDI 1 minute madness (day 1) | Coder Coacher - Coaching Coders</title><meta content="PLDI 1 minute madness (day 1) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>PLDI 1 minute madness (day 1)</b></h2><h5 class="post__date">2017-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/olMVD3j9V6g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">just don't go okay so my name is Jen
long so in PR di this year we have a
one-minute speech session the idea is
that each PR di speaker we spend one
minute to convince you to come to their
talks and today we have 24 excellent
papers so we are going to start on the
first one just if just before we start
so the break is is opening now
especially for the Korean folks because
right after the pitches will go on with
the Korean sessions so if you want to
have coffee you have to try to schedule
dynamically and also after the pictures
we'll go directly for ple I to the
parallel sessions on our master and
civil engineering thank you Hey so first
part of the first session demo match API
discovery tool so the big question is
how do you help somebody discover
functionality in a complicated API when
they can't even name what they want so
the demo match solutions you let them do
a demonstration of the desired
functionality on some other application
that uses the same framework and so what
we're able to do is take that
demonstration match it against the
database of program behaviors and from
that give you a code snippet that tell
you how to use the functionality if you
want to know how it works come to the
talk
hi everyone so I'll be talking about
similarity of binary procedures why you
should come well if you're in the
developer who's interested in what's
happening when you reuse code in the
binary or if your security researcher
who looks for possibly vulnerable
procedures in stripped binaries and you
need help doing that then I will talk
about how we find similarity we use some
crazy ideas like we applying optimizers
on lifted binary code and we also use
statistical reasoning to find what is
the important part of the procedure
which avoids false positives so we have
some nice accurate results with scaling
over millions of binaries so come check
it out thank you hi everyone I'm Oscar
and today I'll be talking about
synthesizing program input grammars so
if you've ever had a program that takes
structured inputs such as XML and you
want to do something like grammar based
fuzzing or create a whitelist of valid
program inputs to improve security or
reverse engineer the program's
functionality but then you realize that
you don't have the program input grammar
so you can't do any of these things well
then I'm going to tell you about an
algorithm that will solve all your
problems so this algorithm just needs
access to an input example and also
black box access to the program and then
it'll use active learning to learn a
grammar that approximates the program
input grammar and if you want to know
how this works come to my talk
right so this talk is about making
machine learning easier by applying
programming language technology so the
main problem is that probabilistic
inference is analytically intractable in
general and consequently this means in
practice we have to design and implement
approximate inference algorithms and
notably these algorithms can often take
a really long time you're on so come to
my talk you want to figure out how to
build a compiler for a process of query
language thanks well so my my talk talks
about how to optimize the cache locality
of a recursive program so oftentimes you
may have a divide-and-conquer program
maybe a stencil that's written in a
recursive way a lot of fork/join
programs are like this and you want to
improve the locality by performing a
very powerful analysis like time tiling
so traditionally polyhedral compilers
would be used which require the code to
be very analyzable and affine and for
recursive programs is a lot harder you
need IPA analysis so in this paper we
look at a new approach that actually
does this fully dynamically at runtime
so we have the user specify data effects
and then use that to dynamically
interleave recursive programs to accrue
significant locality benefits and we
find this is competitive with other
strategies
so pipelines of comprehensions over
streams updates are common in data
analysis workloads and these can include
functional comprehension that don't have
any states and affect full comprehension
that incorporate some load carried
States so we want to allow module
development of these pipelines that can
include both functional and effect for
components and then we want to fuse them
into a single representation from which
we can generate efficient code we
compile or unset languages into writing
symbolic transducers and the function
fusion procedure we have developed for
these uses an SMT solver for pruning and
it's also exposes some additional
opportunities for further reductions we
have developed after fusion we generate
sufficient code and the evaluations have
shown large speed ups over handwritten
and traditionally fused code on a
variety of benchmarks so I hope to see
you at my talk to get all the details on
how we achieve these beers so my work is
about how to generalize strength
reduction with triangular in quality and
one key to my work is about how to make
faster comparison without changing the
final result for example you will want
to know like which country is for the
way from Japan Germany or Greece one way
to get it is to one way 2008 issue to
get the exact distance and do the
comparison but in this case we have the
rap bands are already enough to draw the
right conclusion and our work is about
how to automate evening replace those
expensive distance and vector product
computations with pounds in debt and
Olympics and our result shows that we
could achieve magnitudes of speedups
for those machine learning and data
mining algorithms so if you are
interested about how we achieve this a
huge speed up please come to my talk
thank you
so you've written a peephole
optimization because you want your code
to go faster and you found a common
pattern that shows up a lot that could
be written better but you tried it out
and it works for all your test cases but
you weren't able to prove that it was
correct
because there's some other cases where
it was wrong so you need a precondition
that'll indicate to when the pre commend
the optimization can be applied and that
could be real hard to do real annoying
you need to specify when it's valid but
you don't it to be too strong and you
don't want it to be too complicated and
so our tool can help with that it infers
precondition automatically for a people
optimization that's specified in the
alive language and it will find the
predicates that it needs in order to
write your precondition and will make
sure that your pre Commission doesn't
try to divide by 0 and crash the
compiler if you're interested see me at
the talk
yeah hi I'm Andrea Strasbourg and I'm
going to talk about web assemblies so
web assembly is a new portable code
format the purpose of which is to a
bring new native code performance to the
web and be also to to break the monopoly
of JavaScript that's the only executable
code format on the web and this might be
remarkable for two reasons first of all
it's the first time I think some some
technology like this was defined
developed in collaboration between all
the major browser vendors so it's coming
out to all of them almost simultaneously
and also as far as we know it's the
first industrial-strength language that
was published and defined along with the
complete formal specification and I go
and talk about that a little bit so and
finally you probably gonna stumble over
this technology in the future maybe even
outside the web context so if you come
to my talk now you may be among the the
ones who say i whistle among the first
ones to be able to Rend about okay thank
hello everybody so when writing
compilers there is a common conflict
between writing and modular compile and
writing a fast compiler in my talk I'll
introduce a new method that we've used
to build dota compiler the future Scala
3 compiler to write a compartment to
write the compiler which is easy to
maintain while also being fast the
metonic allows to speed up the per the
resulting compiler by 35% and reduce the
GC promotion rate by 50% in the talk
will also include a very interesting
very interesting evaluation of
performance and very interesting
artifacts which to the best of my
knowledge have never been shown for
caliper compilers in particular and
compilers in general so please come if
you're interested in low level
performance dude thank you hello
everyone we have built a new programming
language for energy we're programming
that encourages programmers to take a
active role in the energy management of
their software on that programming
language is called en't and we have a
proactive side that programmers will use
to annotate program components with
expected energy behavior and then we
regulate that what we believe our
consistent communications across those
program components we also have an
adaptive side that allow certain
decisions to be delayed until runtime
and the centerpiece to this is a type
system that combines both static and
dynamic typing and if you're interested
please come to our talk
hello everyone and couple was Ronnie and
my talk in the afternoon today is about
the very high cost that we all pay by
using garbage collection to get memory
safety in highly performance critical
systems and this is a cost that's going
to increase as we build applications
that consume several hundreds of
gigabytes of memory in the spirit of
brexit I claim that they need a GC exit
so I claim that we need to leave the
garbage collector behind an instant take
in the instead take back control over
memory management and we propose to do
that by adding a very simple delete
primitive to us starting with the safe
language adding a delete primitive and a
dangling reference exception and I'll
show you that if you do these then we
can get back high performance and safety
without compromising on the simplicity
of the programming language and if you
are not still not convinced about GC
exit then come attend my talk
thank you hi so just like CPU programs
GPU programs have data rises and the way
to find the laser etches in a precise
way is using effective clock algo based
algorithm but Kjetil clocks don't scale
that well on GPU programs that have
hundreds of thousands or even millions
of Sledge so to find out how to build
algorithm for citation on GPU as it's
precise based on vehicle but
scales well to those count spread while
supporting the entire memory hierarchy
of GPUs and the different locking
insulation mechanism GPUs counter talk
today thank you hi I'm Steve friend from
Williams College for the last number of
years my colleagues and I have been
working on improving the performance of
precise dynamic race detection we've
designed a number of analyses to do this
including fast-track red card and slim
state the key starting point for this
work was identifying redundancy in early
analyses like digit that could be
eliminated without compromising strong
precision guarantees for the analysis
despite our work these analyses can
still have fairly high overhead this
afternoon I'll present be presenting a
new analysis called
Bigfoot which eliminates over 50% of the
overhead from our earlier approaches the
inside behind Bigfoot is that we can use
a fairly sophisticated static analysis
to optimize exactly where and how a
dynamic analysis will check for racism
the target program we're really excited
about this work and I look forward to
telling you more about it this afternoon
hello al traditional sound face
detection techniques based on happens
before relation are known to miss a lot
of races other techniques that try to
overcome this shortcoming often tend to
not scale because they're not linear
time is happening before it and they
have to resort to what is called been
doing that is not desirable because that
can also miss happens before races our
contribution is this new partial order
called week gossip residence it is
probably more general than happens
before or CP further it sound it doesn't
detect any it doesn't raise any false
alarms the most important part being
that it has a linear time vector clock
algorithm and that is the source of all
the efficiency we show that algorithm is
optimal in terms of space and time and
further experiments are promising we
show that we can handle really huge
traces and still have running times
comparable to happens before so for more
details please come to my talk at 250
thank you hi my name is marina Burris
and our topic is systematic blackbox
analysis of collaborative web
applications so we are looking at
distributed web applications where there
are several clients where web browsers
run and different users make include
changes to a shared document in a
collaborative editor which are then
synchronized by a notion of eventual
consistency we want to find concurrency
bugs in these kinds of applications and
the challenges for finding concurrency
bugs are the huge state space that needs
to be explored and the of our complex
and distributed nature of the
application we present our approach and
we show some results of some bugs we
found for
sadly in Google Docs thank you hello
everyone so this book is about to
achieve high courage for testing
floating point to programs so our goal
here is to generate a tester input to
cover problems with those complicated
constructed such as floating-point
arithmetic or some complicated nonlinear
properties or even with some unknown
external functions so what we have is a
magic transformation of converting the
intensification testing problem to a
mathematical optimization problem and
our result is actually very promising so
we our tool can achieve about 90%
branches in its unmatched library
interested in only seven seconds and
compared with no well no AFL father we
can achieve 80% more branches and for
the for the runtime we can improve the
runtime by almost the 10 times and a
compared with UCL's Alstine testing tool
we can achieve 44% ground branch
coverages and bring about several orders
three orders of freedoms so if you would
like to know more about in this magical
transformation please join me in the
afternoon thank you very much
hi everyone I'm Boudicca and I'm going
to talk about instruction time quite a
funny name so what do profilers
debuggers and JIT compilers have in
common so they all use programming
instrumentation so with instrumentation
we can like gather statistics or even
diner to optimize running our
applications but we need to limit the
overhead of instrumentation in order to
keep the in order to minimize the
observe effect and also when debugging
we need to be able to attach probes
anywhere in the application but current
techniques in couch overhead when you
attach probes to the application and
when running them so we propose this new
technique called instruction funny which
can instrument at any instruction of the
application and more importantly our
technique is like several thousand times
cheaper than the current state of the
art so if you are interested in this
come see me at my talk Thanks
hello I'm a Manny dentist so mph comes
with two instruction sets the new 64-bit
instruction set and the old 32-bit
instruction set now supporting 32-bit
instruction set it has several costs in
power area performance and processor
development time so what if we got rid
of eights the problem is nobody's going
to buy your chip if you can't run all
the legacy applications so one solution
would be just translate of this legacy
32-bit code into 600 code and software
using bi neutralization but when
translation is don't have runtime
overheads
well does it really we disagree
so we created my work 64 a dynamic
binary translator which trend which has
such low overheads that you on the same
processor with the same 32-bit binary we
can run spec CP 2 that 2006 faster under
the translator then it would run
natively if you want to see how we do
this come see our talk at 5
hello I'm here again to present another
work on compiler testing so in this work
we consider the program enumeration
problem for compiler testing so the
problem is that give you a program how
do you enumerate all the this program's
variants the key inside of this
enumeration is that by enumeration by in
enumerating the program's it is possible
to exploit all the usage use a variable
usage patterns by exploring that it is
possible to trigger multiple compiler
optimization passes and to find bugs and
the technical challenges for our problem
is that we how do efficiently enumerate
in the program and our algorithm
achieves about six orders of size
reduction so our result is again very
important and of in half a year
we are able to find about the 200 bucks
in two main string C compilers and we
are able to able to find the question
boxing concerts from and and also to
research scholar compilers and see you
in the afternoon thank you
compositional recurrence analysis is a
static analysis that infers numerical
loop invariance by computing recurrence
relations that are implied by a loop
body and then computing that closed
forms the question is how do we apply
composition recurrence analysis in an
inter procedural setting or more
generally suppose that we have some
method for approximating the transitive
closure of loops how do we apply that to
compute summaries of recursive
procedures at first glance this seems to
be impossible because the set of paths
of a recursive program correspond to a
context-free grammar and the tools we
have for analyzing these paths
essentially corresponds to regular
operations right we have something like
a clean each star operation so this
afternoon I'll explain one method that
makes this possible possible and also
practical so it's implemented an
abstract interpreter that has comparable
precision to software model checkers but
is much faster
hi my talk is about context-sensitive
pointer analysis in a context string
based approach to contour analysis data
full facts are tagged with strings that
I described how the methods the method
is invoked the problem with this
approach is that local data flow facts
or facts that are invariant with respect
that its caller is enumerated
redundantly borrowing ideas from the
context free language reach ability
based formulation of pointer analysis i
present unifying abstraction called
context transformation that is more
efficient in addition to the efficiency
evaluations I'll present the precision
differences if you're interested
complement talk Thanks morning everyone
int n time this afternoon I will present
our paper efficient and precise moisture
analysis modeling the hip by merging the
current automata X 30 analysis station 5
p.m. in this paper we proposed merger a
new hip abstraction four points to
analysis we target type the dependent
clients such as co graph construction
our goal is to improve the efficiency of
points to analysis while preserving the
precision for these clients we propose
type consistent objects and our key idea
is to merge these objects by checking
the equivalents of sequential automata
our results are promising for three
objects sensitivity the most precise
analysis we use we can achieve the
spirit of 131 times while causing the
precision lose of owning one tenth
percent and for the all analysis views
we can achieve a speed-up of fifteen
point four times while the precision
lose is only a hundred percent if we
want to know more details please come to
my talk thank
hi Annie Road I'll be telling you about
deadlock detection for asynchronous
ishaak programs you've probably heard of
async/await it's either in your favorite
language or coming there soon if you've
always wondered what the hell this is
about you should come to this talk and
developers are heeding the call of
precedence everywhere to create more
jobs so they're very kindly use this
feature to create deadlocks in their
programs to create jobs for us in the
program analysis community so we will
tell you about this new program
representation that we have devised to
catch these deadlocks and hopefully
you'll be able to use it in your
analysis of asynchronous programs too
and finally we will tell you a little
bit about our tool that found 43
deadlocks in c-sharp libraries that
developers care about they fixed 40 so
clearly they've - the last talk of the
day so please justify your funding
agencies and be there thank you now we
have the coffee break outside and the
next pair of session star at 10:50 Thank
You Joan so please take take a moment to
recharge after the great keynote and all
this madness that I think that was
exciting so we are starting at ten fifty
shop and it takes five minutes to get
there so recharge but be aware of the
time
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>