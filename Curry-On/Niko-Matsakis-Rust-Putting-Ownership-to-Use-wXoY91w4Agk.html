<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Niko Matsakis - Rust: Putting Ownership to Use | Coder Coacher - Coaching Coders</title><meta content="Niko Matsakis - Rust: Putting Ownership to Use - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Niko Matsakis - Rust: Putting Ownership to Use</b></h2><h5 class="post__date">2017-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wXoY91w4Agk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">started so okay so my name is Nicolas
misaki's and I work on rust and I'm here
to tell you about it I some of you may
have heard of rust some of you may not
so I thought I would start with a kind
of quick elevator pitch for what rust is
all about and basically what rust is
about is kind of can we have our cake
and eat it too like so many projects
that's what we want to do but in
particular we want the feeling of a
really high-level language like nice
nice features closures and so forth but
we also want really strong safety
guarantees in particular for parallel
programming so we want to make sure we
eliminate data races but we want to do
all of that without any kind of run time
and with basically C++ level performance
and the reason is we want to be able to
write programs like particularly I work
at Mozilla so particularly Firefox but
these kind of large system scale
software that needs to really make the
most of the machine we want to do it in
the most productive way that we can and
I mean productive kind of over the whole
scale of development so it starts with
being able to quickly write a code that
will kind of do what you want and at the
performance level that you want and here
we're basically stealing techniques from
C++ that they pioneered which work
really well all right so we want to be
able to write high-level things like
this loop here which this is a function
that tests if something is whitespace or
not so when you call text cars you get
back an iterator which will yield up a
sequence of characters and then when you
call dot all so that iterator is lazy
nothing actually happens until you call
all in this case which will iterate over
them applying this closure that's what
the parallel bars are one by one and
chattin testing if those characters are
whitespace but when this this kind of
looks nice it looks like high-level code
but when it compiles down you just get a
little loop with a pointer just like you
haven't see kind of bumping along right
this particular example is kind of cute
because it turned out that there was a
Ruby function doing the same
functionality
that turned out to be a major
performance stumbling block for Ruby on
Rails installations because it used a
regular expression internally and it was
a very general mechanism and so some
people rewrote it in C and it was quite
long and then they rewrote in rust using
the same plugging it in in the same way
as a little standard library thing and
they got the same performance and we
were happy right they just wrote that in
particular so so that's cool we'd also
like to really go further and build up
higher level abstractions than that
things like parallel iterators right as
you probably know from other languages
like Scala and so forth
which will do the same basic thing but
we execute in parallel this time and all
the libraries in the world are great or
are useless I should say if you can't
easily access them so we also have
things like a package manager and stuff
that if you're used to doing scene C++
programming you know that's not quite so
easy right you have to go download these
things and configure them and integrate
them and it's very difficult and
languages like Java and you just like
Ruby have really pushed the boundaries
there and we're trying to also
capitalize on that but all of that is
the productivity that's the first part
of productivity when you first write the
code but what comes later is the long
haul where you have to keep the code
working and extend it and do that
without introducing lots of weird bugs
and so imagine that you had that
parallel loop that I showed you which by
the way iterated over a series of paths
and loaded images and that's working
great but then some other developer
comes along and wants to extend it to
like count how many JPEGs there are on
the filesystem and maybe they throw this
lines of code in there because they
don't know that this is executing in
parallel or they just don't know the
implications of that so what's happening
here is we're adding 1 to this JPEGs
variable we're doing it in multiple
threads at once it's going to be a nun
synchronized but addition so you're
going to get a data race and the final
result will probably not be the correct
number of JPEGs right so in rust if you
do this this code just won't compile I'm
going to go through some of how that
happens later on you'll wind up with a
compilation error that will guide you to
the right thing and this is a really
great feeling when you're doing systems
programming I have to say or any kind of
programming having a kind of non settled
bug or subtle bug that would have taken
you quite some time to find just raised
up quite early
really boosts how much you can get done
right and we want to do this not just
for kind of data parallelism like this
with a loop but also all kinds of
different parallel abstractions so in
rust you can use channels you can use
mutexes and for all of them we built
them up in the library and we guarantee
database freedom in a kind of equal way
so rust is out now for about two years
since our 1.0 release and we've started
to see some use in industry and so forth
so Mozilla was the primary sponsor and
we started to use it that actually was
not a given we had to kind of prove our
way into Firefox but we've also seen
Dropbox integrating it into their server
infrastructure and now on the desktop
NPM uses it in their servers and you can
go to our web page and scroll through
there's a big list of companies so it's
starting to really get out there and get
used and in this talk I'm going to go
through three parts usually in my talks
on rust I focus a lot on memory safety
I'm still going to talk some about
memory safety but I want to try and get
through that and talk about some of the
other parts of rusts that are really
cool and that we don't talk about that
much and in particular I wanted to talk
about traits which is our technique for
doing generic programming it's very
similar to Haskell type classes and how
we model closures and how those two
interact so let's start with the memory
safety though because that really
provides kind of a foundation that
everything else builds on so just the
first thing to understand is what
exactly is the problem anyway
now if you've worked a lot in languages
with garbage collectors and so on you
may not be that familiar with kind of
all the myriad ways that you can shoot
yourself in the foot when you're writing
code in C++ right so I think a lot of
people think of like returning a pointer
to the stack after the function returns
and that is one way you can go bad but
there are also somewhat more subtle ways
like here I have a vector of strings and
I'm going to access and this is going to
make a reference this line of code to
the first string in this vector and
we'll call it element and then I'm going
to add something new to the string
what's happening here okay and the
problem is if it happens that this
vector
I think I'm standing on the chord since
the problem if it happens that the
vector is at capacity then we might
reallocate the backing buffer copy the
old data put the new string in the new
location and update the vectors data
pointer and everything looks fine from
the point of view of the vector but we
still have this element reference just
dangling around all right and if we were
to go on and use it that would be very
bad indeed so this is a kind of bigger
problem called iterator invalidation
basically while you're walking through
or have references into a data structure
you really shouldn't be changing it and
it has two key ingredients in it that
show up time and again and all these
different kinds of problems and the
first one is that we have aliasing we
have more than one path to reach the
same memory and the second one is we
have mutation and either one of those on
their own is pretty much okay because if
you just have mutation you're only you
can always it's only the memory is only
reachable from one path it's kind of
clear what to do to account for the new
changes you made but if you have
aliasing in the mix then you don't
always able to attract for that right so
the vector updated it's data pointer but
it can't find this element that's in
another stack frame it doesn't even know
about so what we do in rust is we bring
to bear some of the techniques that have
come through research the research
community in the last few years or last
couple decades I guess I would say and
I'm going to kind of explain them here
at a more intuitive level we call it
ownership and borrowing so basically
there are three ways to work with data
in rust three primary ways and what
we'll see is that in every case we don't
have we either have aliasing or we have
mutation but we never have both so the
first one is ownership that's kind of
the the central building block and the
idea here is that every value that you
create has an owner which is a variable
so in this first line this is some rust
code in that first line there I'm making
a vector and I'm storing it into the
variable vac and vac is then the owner
of this vector I can mutate this vector
so you see I said I should point out let
mute Veck in rust we tend to make
immutability is perfectly okay but it
tends to be something that you opt into
that you write so that you see it when
you read the code and in this case we're
declaring when we make the variable vac
that the data it owns is going to be
mutable so here we can mutate the back
we can append things to it and then
we're going to call take this is where
it gets interesting because the take
function has an argument whose type is
BEC event and what that means in rust is
I'm going to take ownership of some vac
of int when you call me you give me my
own vector that I own so we'll copy the
data over into the take stack frame and
now this take is the owner and we are
not so our variable is basically it has
no value left in it anymore
and Tate can execute and when take
reaches the end it takes all the data
that it owns and it throws it away
that's what functions do when they
return so that's when memory gets freed
and this is basically how memory
management works and rust you make
values you store them in places you move
them from place to place and when their
owner goes away it goes out of scope the
memory gets freed much like a C++
destructor you're familiar with that so
you might wonder ok now this memory has
been freed what would happen if this
function tried to use the vector
afterwards and the answer is that you
can't because the compiler remembers
what you had and what you've given away
and it won't let you access things that
you've given away all right so this
would be an error if we tried to use vac
afterwards and this is pretty handy of
course for like in this case preventing
us from accessing freed memory it's also
a really neat building block for
building api's because you can have sort
of logical tokens that give you
permission to do certain things and when
they get consumed you lose that
permission so that's ownership and
that's the most common pattern in the
sense but it's also a pretty inflexible
one a lot of times we don't want to give
ownership of a function we just want to
write a function that will read some
data real fast and computer result for
us and for that we have shared
references so the idea of a reference is
kind of analogous to to borrowing in the
real world all right if I give you a
book I
mean for you necessarily sometimes I do
but to own it I just want you to read it
and give it back to me when you're
finished and it kind of works that way
so if we have this vector which effect
is the owner of and we call this use
function if it takes a reference to an
end that's basically going to be
borrowing the vector from the owner so
it's not taking ownership it's just
using the data and on the other side we
don't pass the vector would be giving
ownership we write ampersand back so
we're creating a reference and passing
that in terms of runtime that's going to
be a pointer and that means that the use
function can now read as much as it
likes and when it's done it will just it
doesn't own the data so nothing gets
freed we just pop the reference and come
back at this point since we only lent
the data out we now still have access
and we can go on and use back some more
afterwards so the trick is I call them
shared references because you can copy
them so if you have one shared reference
you can make many copies of it and they
all refer to the same data that is the
aliasing part that implies then that we
shouldn't allow mutation and E we don't
right so if you have a shared reference
I can't for example push onto the vector
that API is not permitted nor can I
increment the data that's in the vector
I can only read from it any one of those
attempts will result in an error and I
should say that this is I'm simplifying
here we there are times when you do want
to allow sharing a mutation but we will
force you in that case you go through a
there has to be some kind of API that
protects it so a common example will be
like I want to share a single mutex
across multiple threads now if I have a
mutex and I couldn't share it it would
be kind of pointless because only one
thread could ever use it anyway but
that's exactly an API that guarantees
some protection
so that's shared references and the last
thing then is mutable references which
is kind of the same idea you're lending
out data but this time you're lending
out not a immutable version of it but
data that can get changed so here's a
function which takes two vectors from
and to the from is a shared reference
that we already saw but two is a mutable
reference and it's going to copy data
from one
to the other alright so since this is a
mutable reference we're allowed to make
changes we can call push and it's kind
of interesting to look at what happens
when we execute this function first off
when we come down to this for statement
we're iterating through a shared
reference to a vector and in rust that
means that we get back shared references
to its contents and so we started out
borrowing something we're now borrowing
the things in it so basically the type
of element is going to be a reference to
an integer and that's why when we call
to push we do star LM to dereference
that and pull the data out and it's
going to go appended on to whatever
vector 2 refers to somewhere up the
stack or down the stack I guess and when
we come to the next iteration we're
going to do the same thing we would do
in C++ we have our reference to the sum
pointer we're just going to bump it
along at a constant offset from where it
was okay and that's a really efficient
way to iterate of course it's also
really good if the thing in your vector
is not just an integer but some bigger
structure but now you might ask what
would happen if we took that same
execution but we allowed from and 2 to
be the same vector this would be exactly
another instance of iterator
invalidation right because now from and
2 are both pointing to the same place
and maybe when we push on to the vector
we have to reallocate the backing buffer
free the old one and we're left now as
we go to the next iteration we're left
again with this dangling pointer that we
had before of course that can't happen
because we don't allow you to to create
shared references and mutable references
to the same thing at the same time right
and in general that's kind of the rule
in rust so if you try to do it if you
made a shared reference and a mutable
reference you would get an error
depending on which one came first and
more generally we maintain this rule
that if you have a mutable reference to
something there is no other way to
access that memory you can't go through
the original path nor nor can you go nor
can you have shared references at the
same time all right so that's in a
nutshell the three patterns that we're
going to see
wanted to go through them both because
this is the most unusual part of Russ
but also because these patterns kind of
crop up from in different places
throughout the language where you are
going to have to deal with either you're
working with memory that you own or
memory that can be read but not written
to or memory that you're going to be
mutating so let's look a bit at traits
so traits are our mechanism for doing
generic programming and we saw earlier
on this this iterator trait I'm going to
kind of go through that one in detail so
this is an example of using iterator it
is a dot product it iterates through two
vectors vector on and Veck two of
integers and it works by you kind of
start out going through one vector and
then zip with another one which means
that you'll walk pairs of the two things
and just like zip in many other
languages if they're unequal lengths
this will take the shortest of the two
and then we call map now I want to
emphasize iterators and rust are lazy so
at this point nothing has really
happened we're just setting up the
computation that we're going to do right
now when we call map we're saying after
we zip these pairs together the next
thing we will do when we do the
computation is we'll multiply the two
parts and so we'll get back an integer
that has the product or see a series of
integers with the product and then I can
call some write this code it looks quite
high level when you compile it what you
wind up doing is generating a custom
code to do just exactly that one
computation and the compiler then sees
that and it even actually ends up being
vectorized which is pretty cool and we
can then go up if we were to apply this
parallel iterator we would have the same
basic same basic idea except we just
changed it or two parter and now what we
wind up with is we're going to break
that those two vectors up into sequences
distribute them over the course and each
core when it processes a sort of chunk
sequentially we'll do the same thing
that we saw before so you'll have Cindy
layered on top so that's pretty neat how
does it work
this is how you define a trait
and this is in fact a portion of the
iterator trade so a trade is kind of
like an interface and there's an
implicit parameter which we call the
self parameter which is the type for
which the interface is implemented right
or the trade so in this case that's the
only parameter we have we also do
support kind of multi parameter traits
and we'll see one later where you have
more than one implementing type and
inside of a trade there can be many
things in in this case there's the first
one we see is an associated type which
is basically what kind of element are we
iterating over and you can reference it
this way so here you're saying given
this self which is some kind of iterator
what is the item for that and finally
you see that there are methods that you
can invoke and one thing that's kind of
interesting about them is that they
often they don't have to have a self
parameter but they usually do they have
a self parameter and they take it in one
of three different ways this is a this
one is a mute and an mute self method
which means it's going to mutate the
iterator the idea is the iterator will
update itself preparing to produce the
next value for you you can also have an
self methods and by value self as we'll
see later and those kind of take
ownership or take shared references all
right and if you only have say a shared
reference then you can't invoke
immutable methods you can only use the
ones that are suitable for the kind of
access you have so we get to use traits
in a pretty kind of low feeling style so
if if it or is some variable of some
type that implements iterator then we
can write it or dot next and that will
invoke the iterator method but
internally that's basically d sugared to
this functional form and you can use
this one too if you prefer where you
extract out the method as a function and
then you pass it the receiver as the
first argument and it dispatches in that
case to the right implementation and you
see that when you use the dot form you
kind of don't have to put the an mutes
and some of this other computation that
we do in the D should ring so the result
of this would then the option of T : :
item work that's the Associated type
again alright so that's how the iterator
trait looks
this is the I thought this is the zip
struct how one would actually implement
the zip iterator which is a kind of nice
example because it's non-trivial but not
too complicated so basically when you
call dot zip you're going to get back an
iterator as I said that is basically
represents the suspended iteration
saying when when I execute I will zip
this is what that struct is so it's a
generic struct it has two type
parameters a and B and they're both
required to also be iterators so zip is
going to combine their results and it's
just inside its fields there's really no
state in particular just the two
iterators that are being combined so
this is what the this is what it looks
like here on top we have the struct we
saw and down below we have something
called the impulse is basically where I
say I'm implementing a trait for a
particular type where you supply what
the methods actually do right this is
the generic implementation so the
implementation applies to any a and B it
will implement iterator for zip of that
a and B and so you don't have to be as
generic as your type you could implement
iterator for zip of some particular kind
of iterator if you wanted and so on this
is the most generic form so zip will
work over any two iterators and the kind
of values it's going to produce is a
pair of the two items that we extract
out from A and B and you can see that
also of course gets mirrored in the
return type so inside the actual
definition you see that rust has some of
this functional feeling so that you
would get from like if you were using
okay ml or some other language so
basically what we do is we just call the
next method on self dot a and call the
next method on self dot B put them
inside of a pair and then match on the
pair and if we get to sums we can pull
the a and B out and put them into
another pair and so on and if we don't
get then we'll return none and none in
this case is basically signalling hey
we're done with the iteration now so so
that's that's what zip looks like and
you may wonder then okay we saw with the
struct zip capital zip but how do I use
this method form how did that get in
abled the way that that works at least
in the case of iterator is that in
addition to having this base set of
items that we saw before the top two you
can add additional items down below and
these ones have defaults so zip is
defined on the iterator trait and it's
basically defined for all iterators by
default so some particular iterator
might choose to override it but if they
don't they'll get this default
implementation which says how to zip
myself with some other iterator of type
I and here I'm using this rare Clause
notation it's exactly equivalent to the
notation we saw before just sometimes
it's nice to pull them out and all it's
going to do is create an instance of the
struct packaging up self and other
together so the last thing I want to
emphasize is the compilation model I
said that this was a generic imple that
works for any kinds of iterator types
and the way that that works at
compilation time is we use the c++ sort
of monomorphic strategy so basically
we're going to make a specialized copy
of this imple specific to the sorts of
iterators that you happen to be using in
your program and that's how we get that
full optimization and we do that to you
know as far down as we have to go now
sometimes you don't want that and we do
allow you to use traits as types which
gives you more like an object that you
can that you can invoke with dynamic
dispatch this is less common in practice
okay so that was the trait system under
than in nutshell and the next thing I
wanted to talk about is how closures
work and how they integrate with the
trade system because basically whenever
you're defining these sort of community
KPIs
right we saw zip you often end up
wanting little bits of code that you can
stick in there to do customizable
operations like the closure here in map
but closures in rust are not built into
the language the only sense that they're
built in is that we have some tactics
sugar for them but really there
just types that implementer eights and
so when you see a closure expression
like that one that's kind of syntactic
sugar for some sort of struct like this
one that captures whatever that closure
needs from the environment to execute so
any other variables that it uses in this
case the closure didn't use any
variables from the environment so it's
an empty struct which means that at
runtime it has zero size and doesn't
actually even exist it's just a type
that we trace through um and then here
in the map you would just make an
instance of that struct and this struct
implements a closure trade which is like
when you call something that's sort of
an overload able operator that goes
through a trait but in fact we don't
have just one this is where the
ownership patterns come in again we
actually have three traits depending on
how you're going to call it so for
example the base layer is a function
that only gets called once FN once and
it defines an output associated type
that's the return type of the function
so this is a multi-parameter type class
I should say so the self the implicit
self is the environment that's being
invoked and the a is the kinds of
arguments that this thing accepts so a
given thing can implement consumer be
overloaded with different sorts of
arguments but in any case the FN once
the key point is it takes ownership of
the closure itself when it gets called
so that implies you can only call it at
most once because you can only give
ownership once the other traits go
through the other modes and so FN mute
has a mutable reference which means you
can call it as many times as you want
but only once at a time because each
time you have to give a unique reference
over to it and you can't have more than
one unique reference at the same time of
course and this this notation here is
called a super trade notation and
basically we're saying if you implement
FN mute you must also be implementing FN
once because if you can be called
multiple times surely you can be called
just once right that's sort of a subset
um and similarly down here we have the
FN trait which has shared references
which corresponds to something that
being called in parallel with itself or
maybe recursively or something else just
missing more than once at a time alright
and so if you put these traits down you
see that as you go down the hierarchy
you get more ways to call the function
it starts at the most restrictive and
then it gets gets more flexible and you
kind of pick the level for what you need
as a consumer of a closure but on the
other hand as you go up the closure gets
more power because if it's only going to
be called at most once that means it has
ownership of its environment it can move
things away right and if it's going to
be called sequentially with a unique
reference then it can make mutation to
the variables in its environment
and so forth so between these two the
closure kind of decides how much power
it needs and the caller decides how much
power it can give it and they better
match so when we have the map Combinator
that's also a struct just like zip it
has a base iterator I and it has a
closure F and because map is in a
sequential iterator that's going to be
fmu because every time you do the
iteration it will invoke this closure to
do a map on the next item alright and
you see here there's a little bit of
sugar this this bound doesn't quite look
like other bounds it has parentheses and
not angled brackets and so on well I
guess you'd be this is actually just
sugar so we found the bottom tedious to
write so we made a shorthand for it
basically that applies to closures so
what happens is the argument types get
tupled up so there's always one argument
a which is always a tuple of the
different arguments to the closure and
the arrow R is just specifying what the
return type is right
so this syntax says there's the
arguments and this is saying I implement
F and mute with the associated type of R
so that's sequential iterators and I
showed you this example of parallel
iterators
that would prevent a data race they look
pretty similar the main difference if
you have parallel map the main
difference is this instead of FM mute
you take fm
because now you're going to be using a
shared reference which is split across
different threads and so if we look back
to our example of the data race
it's kind of interesting to look at how
this particular closure would be d
sugared so the previous closure we saw
in the dot product had no state it
wasn't very interesting
this one is more interesting because it
uses a variable from its environment is
this variable jpgs and it's going to be
incrementing it by one so when we do
sugar this it's going to look something
like this it's a struct that has a feel
which is a mutable reference to the jpgs
variable and the compiler does this
automatically on our behalf it looks at
how you use each of the things that you
take from your environment and picks
what mode you should be using so because
we're mutating this we need a mutable
reference to it and then the actual
implementation of FM ute that the
compiler will synthesize looks kind of
like this and you can see it's it's
actually the same as the code we had
before except that instead of saying
jpgs plus equals one I'm now rewriting
that systematically with get this
reference out of my self pointer and
dereference it and in order to actually
do this mutation the most I can
implement is FM you all right I can't
implement FN for example because if I
have a shared reference to a mutable
reference that's still aliasing right I
have many copies of a unique reference
it's still a shared reference and we
won't allow mutation through that path
so in terms of our of our two parts we
have then that the the closure is
actually providing just these two
impulse right something that can be
called FM mute or can be called F and
once and on the other side the parallel
iterator wants something that provides
all three and this is exactly where the
errors arise so the lesson here is that
I'm trying to show you is basically that
when you're using these different
mutable references and shared references
and building up your api's you can
express the invariance that the clients
of the code need to follow and then get
so that you will get errors and so forth
at the right times if there would be a
database so that's the the summary of my
talk so I hope I've kind of got you some
of your interest in the way rust works
and also how generic programming and
rust works and how you can
build up api's if you're interested in
learning a little bit more about rust
there's a lot of resources online or you
can of course talk to me later but I
wanted to point you to a few so
naturally our website has everything on
it and we spend a lot of time on IRC but
we also have a new edition of our rust
book that's come out with a whole kind
of fresh approach focused on ownership
first and so forth and I think it's
really good for for learning about rust
and I also have a bunch of screencasts
that cover some of the ownership model
which is worked into rust comm so thanks
everybody
so we have some time for questions if
you just want to use the center center
located Mike hi thanks for the talk like
the thing that you showed showed us with
those selecting the right type of the
closure is pretty neat but I wonder so
for example if it's basically it's the
way to say that this closure is like
pure or something like that with like or
it uses uses only the resources that are
specifically given to this closure but
what about like for example console
printing like if I if I try to print in
console in parallel would there will be
problems so the console API is a global
variable and in rust and as such it's
actually required to have a kind of
thread safe API so what basically
happens is when you call like say print
we acquire a lock for the duration of
the print so what what you're getting is
not really a pure function it's a shared
function so it's kind of everything that
you can do anything in that function
that is permitted by through a shared
reference right which usually means it's
immutable but as I said there are
exceptions for things like mutexes and
so on and so when so yeah so consoles
and other kinds of i/o events they
either either they operate through in
the case of console it's global so it's
kind of a special case and we have this
lock but for most things like streams or
channels and so on
then you have two endpoints and we use
the affine systems or if you have to
have a mutable reference to send a
message or you have to have ownership to
send the message things like that or we
can you can do that anyway if you want
to restrict it okay thanks hi I think
Ross is just an amazing achievement
because it's the first time we've all
just about the first time we've seen one
of these kind of linear or affine type
systems actually make its way into
practical use so it's just incredible
well done I'm you know I mean I'm wild
with envy what does
steal all the best ideas I kind of put
them in Haskell but I have how do you
know that what you've implemented is
right right so I've got personal
experience having screwed up many times
right so you build a system you think
it's right but then there's some nasty
corner case that shows you can Oh GHC
can seg fault that's a very embarrassing
how are you confident that the vast
implementation
never mind bugs in the realization just
the system is correct okay so well you
you just added the first caveat I was
going to say which is I know that it's
not right because I know several bugs in
the implementation but some of which I
would say or where maybe perhaps bugs in
the thinking that went into the
implementation but we'll test that aside
but what we're doing in that I mean we
don't know of course we don't have
formal safety proofs but what we are
doing in that direction is collaborating
with a lot of people
so Derek dryers the and Ralph youngness
is a PhD student is doing the most
direct work here in this Rust Belt
project where they're basically modeling
a logic in iris that is very similar to
rust and which they are proving the
soundness of many different receptions
and so forth and now what remains to be
done though is to go from rust surface
syntax down to that to that their logic
which is different but that's one effort
and there is a really big open problem
there though kind of an open space which
we're also attacking because I didn't
talk about it much in this talk but we
have the very foundations of the system
are not implemented in C they're
implemented also in rust but in a kind
of superset of rust the unsafe rust
which basically lets you have pointers
it's kind of rust plus C pointers and
that defining how precisely what exactly
is allowed in that subset what kind of
optimizations we can do what the memory
model is and so forth is a pretty
challenging problem and we're still
working on that and I think that's an
area where a rust is actively evolving
but in practice that's kind of not
something you interact with every day
unless you're building low-level
libraries and so forth but it is
definitely part of this effort and
before we can answer that question we
have to kind of define those semantics
more precisely which is why we're trying
to do it good maybe they'll be some
feedback from that process that might in
turn influence that
design yes oh definitely we've already
kind of had some episodes of that good
really good thank you hi
I was curious so you mentioned that you
can use trades as parameters and you
said something about you get object like
semantics and so I don't really know
anything about how rest packages work
but what happens if I write a package
that takes at rate as I can argument and
now I have like some binary blob do I
get like a link time mana
mono like what happens when I link
against a library that's using a trait
as a type that's a good question so the
answer is that when you have a type like
this you have a you'll notice that it's
I wrote ampersand iterator there's the
ampersand is important because we make
sure that if you're using as a type the
value that that is behind that object
could be of any size right so we make
sure you use indirection first of all
and secondly what we're basically giving
you is actually a sort of a fat pointer
it's a combination of a pointer to the
data and a V table which has all the
implementations of the different methods
and you can only do this for traits
where we can realize a V table so there
are some features that don't work that
way and in that case what will happen is
the downstream client will synthesize a
V table and give it to the upstream
library just I get like is it possible
that I will get optimizer way yeah that
can get optimized away LLVM does D
virtualization under certain
circumstances and in fact we used to
rely exclusively on that so ye oldie
rest of your we didn't have the traits
the closure system I showed you here and
we relied exclusively on D
virtualization and it worked pretty well
as long as you don't have too many like
layers of indirection and so on but cool
great work Thanks ok let's give the
speaker around a plus
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>