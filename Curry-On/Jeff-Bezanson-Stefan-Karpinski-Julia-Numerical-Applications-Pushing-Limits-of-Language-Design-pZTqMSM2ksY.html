<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jeff Bezanson &amp; Stefan Karpinski  - Julia: Numerical Applications Pushing Limits of Language Design | Coder Coacher - Coaching Coders</title><meta content="Jeff Bezanson &amp; Stefan Karpinski  - Julia: Numerical Applications Pushing Limits of Language Design - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Jeff Bezanson &amp; Stefan Karpinski  - Julia: Numerical Applications Pushing Limits of Language Design</b></h2><h5 class="post__date">2015-08-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pZTqMSM2ksY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you yeah we should also
mentions you know verall Shah who
started the project with us as well and
Alan Adelman has sort of been our patron
from the beginning but yeah we were no
longer at MIT we started a company
called Giulia computing to do training
and support for the language but that is
not why you're here you're here to hear
us talk about numerical applications
pushing the limits of programming
language design so I think we are
holding up the sort of numerical end of
most of this this two days of talks so
here's some you know if you haven't used
or heard of Giulia here are some
features that might might be meaningful
to you first of all you know in the
context of Gilad x' talked this morning
it's a dynamic language people who do a
lot of work with numbers and data and
you know figuring out algorithms to make
sense of that those numbers and data
that really like these interactive
exploratory environments and this is
very much about the exact same kind of
liveness that he you know was arguing
for and we feel the same way so we we
had no really in our minds no other
choice but to make it a dynamic language
in order to get performance we knew we
were gonna have to do just-in-time
compilation the technology for this is
the great these days usually
just-in-time compilation is applied to
light dynamic languages that already
exist as a sort of you know an add-on to
try to make them fast after the fact we
planned for it work from the very
beginning and there's a lot of ways you
can design a language to make that
easier to take advantage of and and in
fact I think the you know I had I was
having dinner with Karl bolts who is one
of the pi PI guys one time and he's
described Julia's just-in-time
compilation as ahead of time compilation
at runtime and I was very confused
because I was like isn't that what
just-in-time compilation is and then I
realized what he meant is that you know
usually that comes with this whole other
bag of tricks you do like guessing what
the types of things are based on traces
and then optimistically generating code
that does that fast but does some checks
and then bailing out if you turn out to
be wrong we don't actually do any of
that we have a fairly stupid just in
time ahead of time compiler the
cleverness is in actually being able to
express and figure out what the types
are to that to that end we do have a
fairly powerful language of talking
about
types in the language and it turns out
that multiple dispatch is a really
powerful paradigm for numerical
computing in particular the most obvious
you know case is you can you know you
say see a plus B and what code gets
invoked there doesn't really just depend
on the type of a it depends on the type
of B as well and there's some
awkwardness other languages will let you
overload this like Python has this are
adds stuff but it's it feels like a bit
of a hack but it does work so one of the
things we had is sort of like early
design of the language actually it could
very much be you know summed up is what
does it take to make plus just a
function and plus is a you know it's a
very very even in you know completely
monomorphic languages like C you can
even write you know one plus one plus
five 1.5 like an integer and a float
will work a float in the float will work
so plus cat nose can do things that
normal functions can't do so these are
sort of the the early basic design
things what's come along over time
although Lisp style meta programming and
macros was actually there pretty early
but other things that have come along
are carefully designed equality ordering
and hashing which I'm going to talk
about next because it actually shows off
a lot of other features of the language
and it's kind of it's interesting in and
of itself and not something you often
hear about in languages talks meta
programming and macros and then a very
recent feature in it's in the in the
development version but not in the
stable version currently easy to use
implicitly invoke generated functions
and this is a form of staged programming
that I put it in quotes because we
actually had to coin a term for what
exactly we're doing is we haven't seen
it anywhere else so if anybody has a
good name for it that's better than
generating functions please let us know
after the talk so the these last three
points are what we're gonna focus on
here because we've given lots of talks
about the other points in the system
multiple dispatch is really a great
paradigm and I am so so pleased with how
that's worked out so just totally
different language first of all to
introduce equality as an issue what is
this C program print
anybody want to guess
all right so I happen to have this C
program handy you can see it here okay
so just to say that there's no no tricks
up my sleeve that is the program I'm
gonna compile it and then I'm gonna do
run non-transitive and so you can see it
frigate prints 1 1 0 ok so what's the
big deal about that why is that a
problem well it means that equality is
not transitive in C right so if it was a
koala if the first two are true that
means they're equal and the third
comparison is comparing the first two
you know the last thing and the first
thing in chain the last thing in the
chain then you don't have transitivity
of equality now in C this isn't such a
big deal because you might argue that
well those are really it's just like you
get to have syntax for different
equality functions and they're not
really related and one of them is the
float equality and one of them is the
long equality and they're not they're
not actually the same thing so that's
that keep keep that in mind when we talk
about the rest of this stuff that's
that's one issue so we for example do
things like this I'll just show it to
you this this works correctly in Julia
as you would expect it to so let's say x
equals 2016 y equals int of 1e 16 so you
know you print out the whole thing Z
equals x plus 1 and x equals y is true y
equals Z is true wait that's did I do
something wrong
x equals y so let's see what XY and z
are hold on I confused myself already
IAS our Z equals the equals x plus 1
that's the
yeah that's why okay sorry
did I do Oh if yeah it's the first the
first and the last ones are long sorry
I'm a little confused here right x
equals 10 to the 16th y equals the
float64 of the X and then Z equals x
plus 1 and then x equals y is true y
equals Z is false this is actually the
key difference all right and and then we
expect that x and z not not being equal
is true is it that they're not equal so
the key the key thing here is that you
want that y equals z inequality to be to
be an inequality and the question is you
know how do you do that and what's the
point
well it's instead of just doing the
naive thing where you just convert both
to the same to double and then do the
comparison which is what gives you true
and that's what C does we actually have
to make sure that we're doing the
correct thing here and we note that you
know that is actually not an integer
that is representable precisely as a
float and so the principle here this is
what it was like an very early thing
that we were like oh yeah that's
actually kind of broken how can we
actually do that comparison correctly
and actually you can see the LLVM code
if anybody's familiar with LLVM that's
good you don't actually need to be so
what this does is it actually compares
your foot it casts your floating point
to an integer and then does a floating
point compare and then it cast your
integer to a float and then does an
integer compare and then and those two
and so that trick gives you the correct
answer all of the time and you can prove
that inequality is much much harder you
might worry about certain things like
okay what happens if I have a function
that you know just checks if something
is zero so this is the notation for
defining a function there's a one-line
definition and then there's a like
longer thing that looks kind of like
MATLAB or Ruby or something you might
write n't want to say X you know equals
equals zero okay we check that it
actually works is zero zero okay that's
true zero
zero okay one point zero and you'll note
that I'm passing values of different
types in here so you know what I haven't
mentioned any types but what's actually
going on here we can find out pretty
easily by looking at the code all of
them again alright so what happens here
is that even though there were actually
those so this is under under the hood by
the function definition this is
comparing a float and an integer but you
know the compilation process is clever
enough to figure out like that it's a
constant float and actually propagate
all of that through and then realize
that okay all we need to do is do the
floating point compare so most of the
time you actually don't have to do all
of that and you know nasty stuff you get
the performance you want and of course
if you're comparing two floats then it's
there's no issue you just use the
floating point compare okay
so let's back to the presentation there
we go okay so this that was you know
sort of an early thing that we had to
worry about and think about later on we
encountered an actually much airier
thing that but that is also related to
an inequality and equality in hashing so
suppose D is a dictionary this is you
know valid syntax in a lot of lot of
dynamic programming languages and you
insert at the with the key one say you
know D of one is equal to the string
curry on and then the question is what
are these dict look up to do D of 1.0
D of 1 plus 0 imaginary which is you
know it's Julia syntax for a complex
number D of 2 over 2 that's Julia syntax
for a rational number so what are these
going to do they're all like
mathematically equal to 1 but are we
gonna return this that value or not
because they're not exactly the same
object and so I you know in asking this
question you might look at what other
programming languages do and there's you
know whole empires that have built on
top of hash tables and dictionaries so
there's languages that really have
should have thought about this a lot so
here we create a dictionary in Ruby we
assign D D of 1 to curry on and then we
check of d of 1.0 and we see that it in
fact is nil
and that those things don't hatch the
same but yet one in 1.0 are equal so
that's a little weird okay so I actually
looked at what Python does I was gonna
skip the slide but since it seems fair
to show it Python actually does this
right they get they get good stuff Oh
somehow I got cut off I'm not sure what
happened there yeah so Python gets this
right DD of 1 is equal to curry on gives
you D of 1.0 equal to curry on and you
can do the same thing with a complex
number which is in the standard library
it also gets that right I think where
this falls down python does pretty well
is that if you then create your own
numeric type something that's supposed
to be like a number it's super-awkward
and then you like have to you can
implement the hash incorrectly by hand
but you know it's tough to do so the
julia also gets this right but as Python
shows it does is entirely possible so
the question is how do we do this and
how did we manage to do it without
sacrificing performance so we actually
took a different approach initially
because this is a sort of stupid obvious
thing to do and zero-point-two version
we actually hash numbers with different
types differently so those things we did
what Ruby does which i think is actually
defensible it's totally fine to punt on
this and be like look we don't really
care that much and so this would end up
in a different slot and you would end up
with a dictionary with an entry for 1
and an entry for 1.0 and they're
different so that seemed good it seemed
really easy it's certainly fast it's
simple to implement different types just
are unrelated and they don't have to
worry about what the other types do but
then we encountered some weird stuff
that we that would made us unhappy so we
have this language of types and we
actually have parametric types so for
example the dictionary type has two type
parameters which are in in this case I'm
saying that's the key type and the value
type and we can generate much more
efficient code and much more efficient
storage based on that if we know it so
this is constructing a dict with with
specialized you know key key and value
types int and string and so now you know
you assign into into it with you know D
of D of 1 equals curry on
good that's good okay now what happens
with the second thing D of 1.0 equals e
coupe so there's two options it's like
not not very clear what you can do what
you should do here so the two options
are throw an error which is not very
dynamic or convenient because I'm like
well you know I used a floating-point
number or maybe I used an int 3 to
instead of an at 64 and unsigned int but
you know you know what I mean
it's one like we know how to convert
between these things we know what type
you want so why wouldn't we just do it
for you
and so that's the also alter all other
alternative automatically convert to
what 1.0 to an int so now this is a
problem the same key code would now work
very differently depending on the type
so if you have a none type dictionary
you end up with a dictionary with two
entries if you have a type dictionary
suddenly you do the exact same thing no
errors are thrown and you end up with a
dictionary with one entry this is bad
this is not fun for writing programs
generically that work and do what you
expect them to do so we ended up coming
up with the solution is to just bite the
bullet and figure out how to hash
numbers correctly by value but of course
you know the tooth to you know elephants
in the room at that point are can you do
it efficiently and can you do it
generically and so I came up with a
clever trick to do it efficiently at
some point which was actually based on
exactly the thing we did with the
quality right the thing we did with the
quality was we converted to both end and
float and then did the comparison so I
was like oh wait what if we convert to
both int and float and then do the
hashing all right you can totally do
that
so this is the solution you define
hashing so here we actually see another
feature of julia which is the multiple
dispatch you take a function you buy
based on the argument type you can
assign different define different
methods and then the correct one will
get called and the compiler knows all
about this so it can inline everything
very efficiently and generate like good
code for you so for for X being a float
when we hash it H is just some function
for hashing 64 bits of whatever you can
define it how we use murmer hash you can
use whatever you want so
you do you come by and you do some
mixing function in this case it's three
a plus B because that actually is fast
to a compute and avoid certain
unfortunate collisions and cancellations
but that's sort of neither here nor
there
so you hash X and then the other hat
you've also passed the you know
truncation of the in of x2 and n64 and
then going on the other side you go in
the other direction so if you haven't in
64 you also you convert it to a float
which can be done losslessly and then
you hash the bat and you combine the two
and so now those two hash values are
going to be the same as long as those
two values actually are numerically the
same and this is like slightly slower
but reasonably fast but then what do you
do about other numeric types like that's
a cute trick for those two things and
you can actually make this work for you
unsigned in 64's as well without too
much collision so here is this is this
is sort of where you know Julia ends up
having this large focus on these generic
functions that you know you you
implement you plug in certain methods to
plug into them from below and then
anybody who uses that generic function
in a generic way gets the same behavior
and you just have to sort of plug in
your the appropriate generic functions
from below and we'll see that in a
second so the idea is this decompose
function which again is not terribly
well named but I you know I couldn't
come up with anything better when I was
working on this so the decomposed
function is the point where you if you
if you have a rational numeric type and
you want to hook it into the hashing
protocol so like this actually happens
people write and write their own numeric
types using julia all the time like six
point number types polynomial types
might want to hook into this you know
you name it begins big floats so the
decomposed functions of activex should
return three integer num values num the
numerator the power and the denominator
such that the value of x is
mathematically equal to the number times
2 to the power over the denominator and
that's like floating point numbers are
sort of fallen to this representation
rational numbers fall into this
representation pretty obviously and so
do integers so you can compute those
things very easily
for all those things and then you have a
fast special case where you do the trick
from the previous slide if you happen to
have something that's equal to these
values and let me just show you briefly
what that looks like we're not going to
get into the mint nitty-gritty of it but
yeah here okay so it's this it's so it's
the generic hash function and this will
work for any real type you can overload
it with more efficient clever things as
long as they match the semantics of this
and we do that for a bunch of things
that you want to hash faster but they're
just faster ways to compute the exact
same thing so you do the decomposition
you handle Mane's and IMP specially you
do some normalization then you check and
this is relatively easy to check in all
of these like finding the trailing
zeroes finding the number of digits
these are all fast and easy to do on
simple numeric types and then you just
you you call out to the actual the
specialized versions that we already
defined elsewhere and then you get to
the end and basically you say okay well
if I have these three things and I've
gone through all this normalization and
special type checking all I need to do
is call this like thing that it
efficiently hashes integer values and
chain the hashes together and then
return something so you create a new
numeric type all you need to be able to
do is say okay I can know how to
represent it in this special rational
form and then I can hand it off and
we're good and so if you if you want to
hook into this you can do it relatively
easily without actually having to know
very much about this all right so I
think that's enough about hashing
inequality so now I'm gonna hand it over
to Jeff and he's gonna talk about stage
programming all right thanks so another
problem we've encountered is that in the
scientific computing space program
generation is unusually common so
basically programs that write programs
it's used very often so I mean
well-known examples you might have heard
of packages like spiral or fftw which
are basically programs that generate
signal processing code and it runs
really really fast so there are actually
lots and lots of libraries like this in
the numerical and scientific world
basically you know people can figure out
tricks on how to generate really fast
code for certain problems that a
compiler is you know arguably never
going
to figure out right sometimes you have
to prove novel theorems to get these
things to work so you can't just expect
a compiler to do it so people write
programs to write the program's right
and this is this is a pretty difficult
thing to do he says this is kind of a
black art no it's so it's much harder to
do that than just to write out the
program yourself so this was another
thing that we wanted to try to address
what can we do about this can we make it
easier somehow so we've been trying to
chip away at that as well so so staged
programming generally generally letting
you you generate the code so there's
several forms of it one can contemplate
so here's a basic program translation
pipeline starting with source text
ending up at native code and there are
various points where you could sort of
hook into this and imagine doing code
generation so a famous one is macros
right from another from the list world
where you can basically intercept some
piece of the program text or syntax tree
manipulated in some way and change it
and transform it or also you know in a
compiler back-end when a compiler does
optimizations and eventually generates
code it's arguably doing you know it's
another form of code generation so you
might try to hook in there and do
something but then they're also they're
there other stages in between so in
particular in julia we do have we do
some type inference and we have some
kind of a type system so there's there's
this other intermediate stage where one
can imagine hooking in where we have
basically some information about the
program but no not not the runtime
values yet but we know more than just
the the basic syntax and so this so we
can actually hook in and in all of these
stages to try to do these things so some
simple examples so we started out from
the beginning we had macros you know I
like this so I like these tricks so this
is a this is an example of a simple
julia AST level macro that basically
generates efficient code for evaluating
polynomials and basically you write out
you you put in the argument which could
be some variable and you put in the
coefficients and this will just loop
over generating nested expressions to
come
shoot this I can just show what this
looks like
don't I Drive sure
so this is what a call to the macro
looks like with a we put an app sign in
front that's our syntax for invoking
this so you know something special is
happening alright so there's a function
that uses it you can see it evaluates
polynomials I guess that's the right
answer yeah but you can see the the LLVM
code that eventually gets generated is
just you know a straight line sequence
of ads and multiplies this is pretty
much you know the the optimal efficient
code you can get for this do you want to
show anyone all right so this this you
know for a simple case like this this
works fairly well but this is actually
pretty limited so this is this is quite
limited you with something like that
you're basically limited to you know you
have to know that you want a polynomial
you have to know how many coefficients
it's fairly rigid and you know the basic
problem with macros is they don't know
that much about your program they
basically just know what it looks like
you know you you you look at the ast and
you know if you think about it you know
there are many ways to program something
you couldn't you know to get the exact
same result you could you can type it
differently right I could write a plus B
or B plus a and it does the same thing
you know you know it does the same thing
but a macro has this sort of excessive
flexibility that if it wanted to it
could look at that difference and
generate different code based on that so
a macro kind of doesn't it doesn't obey
the meaning of the program in some sense
it can just manipulate it in any way it
feels like which is kind of not not so
great and it also doesn't have that much
information all that all it sees is the
basic structure you know then the macro
itself doesn't know what a is what B is
it might not know what plus is either it
just knows that it's a plus symbol so
it's a little bit limited and then a
macro itself also doesn't work like a
function we'd like to just have
functions it's one of our favorite
abstractions I think probably all of us
I would hope you know you can pass it to
other functions you can you can do all
these things with it that you can't
really do with a macro you can't uh they
don't they're not really very first
class in some sense so there are lots of
lots of problems with this kind
cogeneration it's not so great so so we
actually have a different mechanism that
we developed so let's see so so Julia is
multiple dispatch the basic paradigm is
you define lots of methods for functions
and they're dispatched on all the
arguments so what this means is if you
look at all the types of all the
arguments you actually have a fair
amount of information and so what we
added a feature that lets you basically
intercept at the point where the types
of the arguments are known whenever that
might be and generate code for those
types and so we've got an example of a
yeah and use that so this was actually a
very much a motivating problem for us
and I'm gonna walk you through a little
bit of why so the problem we have is
that you we want to we have our arrays
our n-dimensional so let me maybe just
give you some examples of throwing
around arrays so you can have an array
that is you know you just generate four
random elements and we print it as a
column because in math vectors or
columns and this is a you can see the
element types there is float64 of the
array we also have type parameters that
can just be values so one can just be a
type parameter and in this case it
indicates that there's only one
dimension to this array but you can do
things like you know make a
two-dimensional array so you have a
matrix four by five matrix and you can
see that the the you know second type
parameter for the array changed
indicating that we have a matrix but of
course you know there are people who do
things that are much bigger you know
this is not unheard of it's actually
pretty standard to do things in six
dimensions for you know doing for
example if you have a field of
velocities right there's you know three
dimensions of points so your array is
three dimensional but then the
velocities and themselves are three
dimensional you got six dimensions if
you also wanted to track acceleration
you would have nine dimensions and so
you know this you you get fairly high
dimensional things and there's actually
no real predicting exactly how many
dimensions people are going to want to
work with we've seen some fairly crazy
stuff
but wanted large numbers of dimensions
so let's just consider the problem of
just trying to efficiently iterate
through all the elements of an array and
so here's I have a diagram of an array
we'll see you in a second okay so this
is how you store a dense array in memory
and we're julia's column-major which is
you know in the Fortran and MATLAB
tradition so you would actually iterate
this efficiently in memory going down
the first column then the second column
then the third column fourth so on so
and so on and those are just at
successive indices in memory so there's
this thing called linear indexing which
is done in MATLAB where you just you can
even though the thing is two-dimensional
you can just index it with one dimension
and what it does is it's like okay I'm
gonna ignore the fact that there are
multiple dimensions here and just you
know offset from the beginning to add
that in index and give you the element
that's there so you can scan through all
of the elements in the in this
contiguous array just by hopping through
memory one one step at a time but then
there's a thing that you frequently want
to do which is you want to slice a part
of the array out so you can for example
the the syntax for this is that you
write a you would write this particular
slice as a colon comma 3 colon eight
indicating that you want to take all of
the rows and you want to take columns 3
through 8 now in this case we got lucky
and that is actually still contiguous
right it's still contiguous the stride
which is the step that you can go
through is still 1 so we can still use
linear indexing to efficiently iterate
through this but now let's say we just
left off the bottom row now we can't do
that anymore because now all of those we
would at some point we need to know that
we've reached you know we've reached a
multiple of 4 and we need to loop back
around and we actually need to add an
extra element so now you know there's
various tricks you can do you can do
mods and divs and various other things
to do this in this case doing mod 4 is
not terribly expensive but you know it
could be mod 5 it could be mod 7 it
could be mod anything so you won't
always be able to just do bit shifts and
masks to do it you can also have much
more complicated patterns you could
easily have this pattern
or this one or this one these all happen
this is like not at all made up
currently what we do is totally
suboptimal and it kind of hoists us on
performance pretty regularly we just
copy it so we copy if you slice into an
array we copy all the data into a new
array you can imagine why that is not
the best for performance and then the
sort of this embarrassing situation
where you're like people are like well I
wrote this code and it was really fast
and numpy and why is it so slow and
we're like well you got to use this like
view thing and it's kind of awkward and
it's actually not as phonetic you're
just like all right I'm just gonna go so
we'd like to solve this problem but how
do you generate generic code for the
array case it's you can you could you
know do something essentially you what
you want is you want for the number of
dimensions of your thing you want that
many nested for-loops if you have that
many nested for-loops and you know the
strides of each of the dimensions you
can generate really really fast code to
do this that slide probably should have
been right before the examples but you
know whatever sorry okay so what we're
gonna do is we're gonna do this thing
we're gonna use this generated function
so so just just to say you know let's
say a is R and you know three comma four
if we wanted to iterate through this
with two for loops the way we would do
it is we would say for I 1 equals you
know 1 through we actually you know it
size a comma 1 and then for I 2 equals 1
through size a comma 2 and then let's
say we just wanted to do print line you
know a of I 1 comma I 2 equals and then
we actually want to you know print the
element
yeah we could do something like that
okay and that you know that efficiently
scans through and goes through all the
things and if you have a view that is
strided or something all you need to do
is put an extra like you know you
actually don't have to do anything
special you just I one starts at a
different number and maybe steps by a
certain amount with every loop so it's
actually super heart so for easy like
doing it with linear indexing is crazy
hard and involves mods and divs doing it
with four loops is straightforward and
fast so what we would like to do is
generate that code but we have to
generate that code for every possible
number of dimensions of the array a and
this is where the stage function idea
comes in and so I'm just gonna you know
rather than take you through writing it
by hand I'm actually just gonna cut and
paste the code so this is an N loops
example and here's what it does I'm
gonna just like look at the look at the
code for briefly so the way generated
functions work is they actually look at
the they hook into the point in code
generation where you're like okay I need
a version of this specific to this type
and since the number of dimensions is
part of the type we generate different
bodies for different different
implementations of this depending on
that N and you can see that in the type
signature so n loops is is parameterised
over T and n where T is the element type
and is the number of dimensions and then
because of the at generated this is what
what happens is this method body is
actually not what is not what runs when
you run the code it is what runs when
you're actually deciding what to run and
it returns an expression which is then
actually compiled and run bear with me
here I know that's a little confusing
during that a is actually bound to the
type rather than the actual value
because you don't have the value yet and
so what this code does is it you know
VARs is an array of symbols inner is
this in this print line expression that
we're trying to construct outer is
initially the same as inner and then
what we do is we just go through for
each of the dimensions that the array
has we you know save var as this is the
symbol that is at that at that depth we
keep track of that var then we actually
append some stuff
to the inner print line expression and
then we actually redefine the outer
expression and that frowny face operator
is our code quoting syntax which we were
actually just talking last night about
changing and then what you do is you say
I'm gonna take I'm gonna make this this
for loop this is quoted code and then
I'm gonna splice the previous value of
outer into that and so what you see is
you build up more nested for-loops as
you as this goes through for each
dimension okay
so I'm actually I'm gonna run this
without degenerated because we can
actually see what it prints first oops I
ran it alright so I'm just gonna delete
the generated and then we can have so a
is a two-dimensional route thing and if
we call n loops on a it actually prints
out the the code that it generated it
returns it as a value and we can print
it and it'll look normal so you can see
here that it generates pretty much
exactly the hand code it actually does
one thing better
I had the loops in the wrong order that
is actually this is the correct fast
order tat to have them in to generate to
scan through in column major order okay
that's fine so we already had that code
why is this exciting well you know let's
say that instead of a it is Rand three
which is one dimensional then we just
get one loop it ran three four five now
we get three loops you know six we get
four loops and you know ten okay so we
get lots and lots of nested loops at
some point you might want to stop doing
this because you know you should
question why you need an array with that
many dimensions but people have done
more bizarre code than this so now let's
actually do it let's actually define it
with the add generated symbol at the
bottom at the top and now it'll it'll
actually generate that code and then
compile that and run it and this is all
transparent once you've defined this you
don't you can just you treat and loops
as a as it just as a black box so what
it a stay is still that so n loops
is a and you see we go it goes through
this is and this is actually exactly the
same elements you would get from linear
indexing it's the same order except it
works for you know various things so R +
2 3 4 you know it scans through that and
this is the fastest code you could
possibly generate to iterate through
although all the values in a general
array even with strides so really what's
what ends up being so magical about this
and really really the good and kind of
novel thing about it is how automatic is
so when you do code generation some of
the big problems is really just kind of
the logistics around it somebody has to
be in charge of invoking the code
generator and then you get something
back and then you have to put that
somewhere it might be I might be an
extra source file on your disk and maybe
you need another build step or you might
have to keep it in memory and keep a
pointer to it yourself and know when to
call it and there so there's extra sort
of logistics and bookkeeping that goes
around doing something like this and we
can in this case we can automate that I
believe ok fftw uses Oh camel to
generate C code you know you can imagine
what those make files look like right
it's not it's not a pretty thing yeah so
in this case basically the you know a
library writer just puts that generated
in front of something and then they
don't have to worry about when that's
going to get called our compiler will
call it as necessary and then from the
user's perspective it just looks exactly
like a normal function call API they
don't have to do a single thing
different they just call the function
and you know M just internally the
method cache takes care of generating a
special version and storing it where it
needs to be and then once it's cached in
there it can be reinvented so it's just
it's just very smooth experience ok and
so we have actually would you just go
back to the prompt so yeah sure yeah so
this so this this n loops example is
kind of motivating but it's just to give
you some flavor of how how much more
complicated this can get so we have a
whole that for you
well I'm not gonna type very much ok so
we have a type in in the standard
library that people have implemented
that does do an in-place non copying
view of an array which is this sub array
type and you can see if you look at it
there's lots and lots of stuff in there
so
basically you know these are basically
the properties of one of these so it has
a it has an element type a number of
dimensions it has some underlying
storage type and then it has a tuple of
indexes which can be vectors ranges
integers or this special : thing so
these this has sort of a lot of
information inside it it's basically
there's a whole tuple of different kinds
of indexes that it's using to view some
array and then once you have one of
these
somebody might index this thing with
some other tuple of indexes and so at
that point this becomes kind of a
difficult problem to generate efficient
code for you know all these combinations
of different kinds of views and
different ways of indexing it so that
this is one thing we use we use this
feature for it this adding generated
functions to our our language managed to
reduce the size of the code for dealing
with arrays in our standard library by
just a massive amount and it not only
does that but it allows us to solve
problems that we didn't know how to
solve before let's see I think that's it
for the slide so I have another I have
another example here that I really like
this so this example was made by Steve
Johnson at MIT this basically comes from
A&amp;amp;M physics so there's a technique a
numerical technique in enm physics
called the boundary element method to be
contrasted with the finite element
method the interesting thing about this
problem so this is a problem where the
user inputs gives you some geometry and
some potential functions and they want
to solve for state of potential
everywhere and the interesting thing
about this particular problem is it's
been very difficult to make a generic
library for this problem where you can
just pass in anything and get the answer
from the same library and I guess the
reason for that is apparently that and
when you do this problem you get lots of
integrals that are really difficult to
do you get difficult numerical integrals
that have singularities in them and
figuring out the right you know an
efficient way to compute this integral
is pretty difficult so there there
aren't a lot of generic packages for
this so it turns out that you can use
our system to to make one of these so it
says so that all the details of the text
isn't important he made this really
beautiful notebook but the the details
aren't important but basically what we
do
so first he defined some types that
describe the important properties of the
functions that we're going to be working
on so this this is an example of
basically nominal function types so
Julia has started using nominal function
types of fair amount this is it's kind
of like also what Java does with its
lambdas we are a dynamically typed
language so we you know we feel like
arrow types you know arrow types are
great but they do not work really that
well for us in a dynamically typed
context so we haven't really come up
with a satisfactory way to to use them
so for now we have nominal function
types but it turns out that nominal
function types are actually surprisingly
useful in a lots of these kinds of
numerical and scientific applications
and the reason is that people have some
idea of what is the important property
of these functions that I care about
right they they might not really want to
care about or talk about the argument
and return type of the function they
might not be thinking about it's often
just float to float right there like
that's totally like doesn't tell me at
all this just float to float you know or
maybe two floats to one float if you're
getting really fancy right so so in in
this case what they actually care about
is basically the degree of the
singularity so we saw that's that's the
key property so you want a type that has
that information in it and so that's
that's what this defines let's see
so you can define the behaviors of some
of these functions and see now I can
construct a first integral of a power
law with certain parameters and then
just call it and you get an answer so
this is kind of to know for a particular
special case so this this was a special
case that has an analytically known
answer so he could just write out
exactly how it's supposed to work
explain so this this call definition so
when you write f of X that is actually
an overload able syntax so you can
define how something that is called like
a function actually behaves and the way
you do it is you add a method to the
call function which is a generic
function itself and in this case what
you're saying is when I see you know a
call where the thing that is being
called is a of the type first integral
with this you know power law P and
business as its type parameters and then
X is a real argument I would like to
define that to be this so this is
defining that behavior and that's what
we're actually seeing here we're
defining f to be the one a particular
first integral instance and then we're
calling it on the value three point
seven that's what does that make sense
so that was sort of a special case that
you can kind of you know write by hand
like you can define any method of a
generic function but the the general
case is really really hard in in this
situation so he he wrote some code to
basically take a general one of these
and figure out a chebyshev polynomial
that approximates the thing you need
really well and but it actually wants to
do that at compile time because this
process is way too slow to do at runtime
but you can you know if you're a
mathematician you can figure out which
part of it can be hoisted to compile
time and so just evaluate this those
boxes are supposed to be subscript K is
but apparently even on even on a Mac you
don't always get your unicode right so
here's the here's the general version
you can see it uses this this generated
function thing and the goal of this is
basically to generate something based on
the type of kernel function we have here
I would point out that for example it is
doing an integral wealth
what code to generate this is so this is
like we now have like a compiler step
that is actually solving an integral
numerically it in order to like then
generate code that you're then gonna run
so here's here's an example of that
working so I just is just defined
another one of these nominal functions
and so we can now we can just ask for
you know what is the code generated for
that so here's the LLVM code we can see
there's actually an error check so just
do a simple arrange check at the
beginning and then the rest of it is
just a really nice straight line code of
adds and multiplies with all the
coefficients in line so you get
basically you know this is pretty much
as as fast as you can get for computing
one of these approximated with
polynomials and so you would just get
all of these bits of code piling up in
memory and we're gonna have addresses to
them somewhere and then and actually
people will do things like they you know
then they want to be able to have a lot
of flexibility with these they might
make an array of these functions that
has functions of various different types
and you can just call them and you
effectively get you know a jump table to
different routines of this flavor you
know sort of automatically when when
that happens and you know this works
like any other function you can plot it
if you want so pi plot is a plotting
library that actually well it's a Giulia
package that calls Python to do its
plotting we do actually have several
rather nice native plotting libraries
but some people prefer PI plot Steve
Johnson who did the rest of this work
wrote the PI plot package so that is I
think yeah I don't refer matplotlib is
it has tons of plots and it's really
good so just you know call that and you
can see this is uh this is mapping the
first integral function over X for over
a certain range and so you see that this
is efficient enough to actually solve
all of those and make a plot of it and
you know fairly little time how much
time did that take let's see
yeah it's you know 55 milliseconds
that's that's sufficiently good anyway
yeah I think that's that's pretty much
it so we're about done thank you
all right of course questions microphone
how do we hash complex numbers well like
you veneno us why well we could look at
the code I guess but I'm just curious
now open the old words oh if I recall
correctly you just hash the components
and then hash those together with some
particular bit pattern okay thanks yeah
the only thing you'd have to worry about
there is you need to make sure that you
that when you hash the complex part and
it's zero that you get to you just have
to like XOR it with the with the zero
the hash of zero to make sure that it
cancels out and equals the ration of the
like really real version hi thanks for a
very impressive demo so from what I
understand you have two kinds of well at
least two kinds of compile time
functions the macros and then generating
functions so we've seen the benefits
that generating functions bring to the
table so what's the point in macros then
so yeah what's the what's the point of
macros yeah very good question my
thoughts exactly sometimes you have you
I mean so macros essentially just
operate on syntax and so sometimes you
don't like the syntax you'd have to
write yeah I think the only real use of
them is if you know people are just very
fussy about their syntax and they just
really want a very specific notation for
something and then that's the only way
to do it that's that's really the reason
I guess so you can see what the at time
macro you know that that's a macro and
you can see what it does it just sort of
puts a bunch of stuff before and a bunch
of stuff after and then the expression
you called in the middle I don't have to
write all that stuff myself I also need
to make sure that sleep doesn't get
evaluated until after you know if I if I
sleep and then take the result of that
I'm not gonna get very interesting times
right so you do need back rows for some
things first I'm super happy to see that
you integrated staging basically in a
very nice way into the language unlike
Kokomo and others that you have to build
beforehand but then I have a question
here because now it's so widely
available how do you manage the code
caches because you generate a bunch of
code basically
for all these generated functions so
they first do you do you manage the code
cache is how do you manage them and what
happens when people basically called for
example these functions with very large
numbers so that you get like megabytes
of code right so yeah so the question is
how do we manage the code cache and what
if people call these things with really
big numbers or do sort of abusive things
well we you know we just have to trust
people really in the and the code cache
right now we don't do anything very
fancy it basically just keeps growing
and that that has not really been a
problem yet but we already generate a
lot of code I mean numerical computing
is a good area for that sort of thing
because all of these like I mean a lot
of the techniques we're using here JIT
and you know macro macros don't generate
that much code but you know these IDs
ideas are old right they've been around
since like you know the 70s or the 80s
but you know people have these these
sort of small machines where like how
much code you generated really mattered
if you're working on a you know terabyte
data set you really do not care about 50
megabytes of code that you generated so
we we haven't really hit that problem a
lot I mean if we're trying to do stuff
on embedded machines it might be a
different story but that's not something
that's something we're doing just yet
but we are kind of thinking about it um
so this is a question regarding the
first half your talk um
so I'm assuming you've mayor of scheme
given your you know appreciation for
macros um and thus you're probably
familiar with a numeric tower there so
my first question is do you have big
numbers and you automatically promotes a
big nums
and if so then what do you think about
schemes division between exact and
inexact versus your choice to
automatically treat one and 1.0 as equal
even though they aren't referentially
transparent you were probably a better
person to answer this yes our parser is
actually written in scheme in a scheme
that Jeff implemented so so there okay
that was allows a lot of questions
alright so we so we do not automatically
promote too big nom that's that's an
easy one and also we have basically two
forms of equality so this is also you
know I think Common Lisp had about five
you know scheme and scheme has a couple
it depends how you count we we have we
have basically two so there's there's
the double equals where one equals one
but there's also a triple equals
and this is the this is the disciplined
kind of exact equality that the
distinguishability based equality so
that for that for that they are they're
not equal says Henry bakers you gal yeah
and so about the about the the scheme
numeric tower well you know the scheme
numeric tower is is really good it's
yeah it's certainly was you know was
very well designed I think it's I I mean
I think it's kind of a shame that it's
difficult to implement in scheme you
have to I mean you just have to use kind
of big nests of if statements pretty
much so I think it's no it's not too bad
that it has to be kind of built into the
language spec what do I think of exact
versus inexact it's also it's also not
extensible right you can't come and make
your own type and fit it into the
numeric hierarchy so all of the Julia's
numeric types are actually implemented
in Julia so I mean even like int and
float are just there we define we say
here's a bag of bits and here's how you
add them and here's how you multiply
them and all of that stuff is that it's
completely bootstrapped in the language
and and if you have your own numeric
type that you'd like to implement it is
in no way less privileged than the ones
that we provide we just happen to
provide those to you so I think that's a
very big distinction yeah and the exact
and exact I think is it's kind of cool
but I suspect it's sort of not all that
useful because when you people who do
American numerical analysis don't really
talk about that very much so I I think
it's you know at the end of the day it
might not actually be so important to
have that in fact there was one day
where I decided that we should that you
know since rationale is this exact thing
that we should rational should sort of
win in a lot of promotions like if you
have a float and irrational you should
convert the float to the exact rational
number that it represents and then give
give that rational I don't think I've
ever done anything quite so unpopular
like like I just snuck that in this was
a couple years ago and like there was
you know people were screaming bloody
murder and we reverted that very quickly
because it basically means that
rationals like so exact types poison in
exact types in that in that way
so as julia had in the adoption outside
the scientific community of people
making websites with it or games or
graphics or anything like that
there's a little bit of interest in well
yeah I know I've seen that so there's
one one guy who made a really impressive
quake engine in Julia using using using
open out using OpenGL but I don't think
anybody's using that in earnest it was
just a cool project there's another guy
at MIT who's doing sound stuff so he
likes the same things you know that
numerical people like about it is
because you know you can you can write
simple code and get really fast
implementations of it what he doesn't
like is that our GC is not real time so
you know scientists don't really care
about big pauses in GC because it's all
about throughput if you're generating
live music then you really do care about
a you know um perceptible pause in GC
but yeah I think the basic answer is yes
I mean you know P I don't think people
least of all us really want a super
niche programming language anymore so
you know I think if you look at it it's
it's very clear that it's a really
general-purpose language and people are
starting to use it for other things I'd
like to first off say that so one of
those I work on idris and one of the
things we'll love about it I think is
that we have really pretty colors in the
output and that was inspired by a Julia
demo I saw a couple years ago so hey
thank you thanks for helping improve our
language yeah but in light of the the
keynote we had this morning about sort
of live environments that are better
than just a repple what are your plans
for Julia along those lines or are there
plans to do something nicer than just a
type I thought notebook Oh nicer than an
eye Python notebook are you are you
kidding me I mean what for example with
the debugger yeah I would put a debugger
in the ipython notebook yeah no I mean
there's been some where there's a
there's a project called Juno which is a
light table with lots of Giulia goodies
baked into it some people really like
that I I'm kind of old-school like I
like a text editor and a repple but this
is like the fanciest repple I've ever
used
so it's got a lot of interesting
features I mean I'm sure you noticed
that like you know you can do multi-line
editing you can go up and like change
things and you know it's it's all pretty
straightforward to use it's not that
straightforward to implement you can
also shell out so you can say you know
LS and you can see the different things
there's also what there's also a help
mode where you can say you know I'd like
to know what you know help help meta
help ya so but III think at some point
we will want to develop something that
is like more like you know could I what
I'd love to see is something that is you
know could replace MATLAB for the people
who use MATLAB and like that style of
thing but could also make you know me
and Jeff happy right like I use sublime
text Jeff uses Emacs and you know MATLAB
kind of sucks it's it's the the IDE like
gets the job done but it's really
painful to use when you go back to it
after this kind of multi line that you
can't do multi line editing in an IDE I
don't get it but yes so we'd love to
have something that covers all that I
mean I actually I'd love to reuse more
stuff too I mean like we re using
ipython notebook it's been very
successful and I'd you know whatever
people do in that area I hope we can you
know we can take advantage of it yeah
yeah I have two questions but first a
quick bounce on the macro question then
I think the true power of macros
officially lists macros which work on
the ast is actually proper compile time
metaprogramming which which is also
another important thing proper proper
compile time meta programming that
that's the true power of Lists macros
what do you mean by proper proper I mean
working on the ast yeah ours work on the
aft yeah yeah I know that was a bounce
on the previous question so the two
questions I have is so julia is
obviously stuffed with features inspired
probably from
Melissa and probably also from Dylan I'm
not sure about that one and you said I
heard you loud and clear that you like
Lisp so the the obvious question I guess
is did we really need yet another brand
new language
why not building on something that's
been around for a long time and which
you know has a strong and long lasting
community why why the need for some for
something completely study I mean
started from scratch that's the first
question and the second question is as a
radio technical detail last time I
checked I think Julia didn't make any
difference between biding and assignment
so the question is is that still the
case or am I wrong am i right and if if
that is actually the case then what the
hell were you thinking thank you very
much
so I mean we could have done something
like compiling to Common Lisp you know
there are a lot of really really
excellent Common Lisp so that you know
that might have worked well I think I
mean probably the the difficulty would
have been that no people would have
there would have been a lot of tension
about how much like Lisp it's supposed
to work for example and we didn't want
to be saddled with that and I think
they're they're just certain specific
places in the design particularly the
type system where you you really need to
be able to basically force something on
people and you know people really need
to go along with that and then you know
just having picked the appropriate
minimal amount of thing that you're you
know that you're really going to a force
on people then from after that point
there can be lots of flexibility but I
and I so I think to to be able to freely
experiment with the type system without
people complaining too much about
interoperating with them a host language
I think is probably you know
necessitated doing this differently also
so julia has broken we didn't talk much
about multiple dispatch in that but
we've really broken ground in terms of
what you can express with multiple
dispatch so Dylan does have it Common
Lisp has it you can do multi methods in
closure but I don't think it so that
Dylan is probably the closest in terms
of having really good performance with
that and also having them be the default
but in Common Lisp you have to say you
know def multi right
you can't just def generic and then def
multi you can't you don't like plus or
you know just built-in functions by
default they're not generic functions
and Julie everything you see that you
call as a function as a generic function
which means everything is also
extensible and another flipside of that
is making everything fast despite that
so like we you know we define all our
entire standard library like for loops
and like iterating over using integers
that's all defined in the language in
terms of operations that are defined in
terms of generic functions I don't know
if anybody else has pushed the
performance of generic functions that
far so and that's actually I answer
addresses why we don't protocol II
promote to Biggins
right so it's if you're relying on an
implementation of languages integers to
be efficient for implementing loops and
whatever else then it's fine to have a
little bit of overhead but if that is if
you're implementing all that stuff in
the language itself then you really
can't afford to have that overhead all
right and then on binding versus
assignment I think I would just say that
I what we have I think is just very
convenient and unsurprising to people I
think it just tends to sort of do what
they expect by default I don't know I
mean I nothing nothing has blown up so
far I mean I pretty quite still I still
have all my limbs I you know I I think
it's alright it's pretty close to what
Python does as well which people seem to
be ok with yes yeah it's very close to
that yeah so it might even be identical
actually I'd have to look at the details
but yeah I mean I would I would look at
you know if you if you able to find an
example that really does something bad
you know please send it to me you know
I'd be curious to see
yeah that that maybe yeah most most
dynamic languages have this issue okay I
think we have to wrap up we're a little
bit over time let's thank our keynote
speakers it was very nice</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>