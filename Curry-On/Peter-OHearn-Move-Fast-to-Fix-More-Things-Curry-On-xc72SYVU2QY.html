<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Peter O'Hearn - Move Fast to Fix More Things - Curry On | Coder Coacher - Coaching Coders</title><meta content="Peter O'Hearn - Move Fast to Fix More Things - Curry On - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Peter O'Hearn - Move Fast to Fix More Things - Curry On</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xc72SYVU2QY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello I think so
you
okay hello let's get started right so um
I'd love the idea of this conference
it's about academia and industry needs
to talk so a bit about me I'm working
for Facebook now on static program
analysis but I came from academia I was
a professor for like twenty years or
twenty two years before joining Facebook
and so what I'm gonna do in this talk is
I'm gonna get to the Facebook part
deploying program analysis but I'm gonna
go back a bit before that to some of the
academic work we did and I'm gonna talk
about some of the sort of weird and
wonderful things we've learned trying to
take some academic research and apply it
in this industrial setting so let's go
back in time a little bit so we're
working on program verification or
static analysis we had a paper in the
computer aided verification conference
in 2008 the CAF conference where what
we're trying to do is make a program
analysis which takes in a program and
tries to prove that it has pointer
safety or memory safety so there are no
null pointer dereferences no memory
leaks things like that in order to do
this you had to do something called a
shape analysis so we wrote this paper
and the largest programs we were
handling were around 10,000 lines of
code this was C code we found some bugs
in the code and then when we fixed the
bugs our program analysis confirmed that
there were no bugs left right so it
verified the code I thought this was
this I love this I thought this is
awesome right so a bit about my
background I came from denotational
semantics then I did logics of programs
and somehow I get dragged into doing
static analysis and finally I'm doing
static analysis and Industry well this
was at the leading edge of academic
research in static analysis and program
verification over in 2008 so at that
time program verification was going
through a renaissance because of slam
and ashtray and certain tools which you
would call verification oriented
abstract interpreters and so a great
thing about this work
that right so we found a bunch of bugs
two of our collaborators on this paper
Burdine and cook we're working at
Microsoft at the time these bugs were
missed by the celebrated Microsoft tools
like slam and they got the bugs fixed by
the people in the kernel team and so I
thought that this is really awesome for
academic research right I came from
Theory denotational semantics and here
we are getting bugs fixed by the Windows
kernel team awesome so I thought that
this was really great but then that's
the kind of data structure we found in
one of the device drivers the Microsoft
FireWire device driver was five cyclic
and linked lists three of which had an
acyclic sub list and so we had to have
accurate program analysis for that and
it wasn't too easy
so we succeeded so I thought it was
awesome but then I'm sitting in a cafe
in the East End of London with my
collaborators there's Yang and de
Stefano and calcaneal Catania was here
and this cap in this cafe how can you
say these results are completely useless
this is ridiculous and I said well what
do you mean I mean this is obviously at
the absolute leading edge of academic
research right um
this does a little bit better with the
celebrated tools like slam we're doing
he says how many companies are going to
have a lot of discreet 10,000 line
programs the key you can apply these
these problems to not many companies
maybe one maybe Microsoft I'm so you see
kal Kenya wanted to make a company to
market this stuff he didn't and he
didn't want to merely get to the edge of
the academic research he wanted to make
a company so he said this is useless so
this was really an eye-opener for me and
it should be for academics what are the
things we aim for a very often you can
get to the edge of the academic research
but you should ask yourself is that an
end in and of itself in this case my
collaborator can you said no that's not
an end in and of itself and so I was
taking it back after recovering I said
well well what is it you want Cristiano
he says we need to go for big code
millions of lines of code he said what
is the main blocker stopping these
advanced program analysis techniques for
applying to millions of lines of code I
knew immediately they need preconditions
they need humans to give me
preconditions and this makes for a
global program analysis that will never
scale so in any case this is the only
little bit of logic they are going to
see in this talk so we made a program
analysis which uses the notion of
abductive inference which you might have
heard of which is inference of
hypotheses we used abductive inference
to guess preconditions for procedures
and this is just a little bit of it
there so in this in this bit of code
we've got respect for foo which takes
two separate linked lists that's the
only bit of separation logic we will see
two separate linked lists and gives me
back a linked list then after a few
after Malik Malik we call foo now I've
got a link I've got X is well that's a
linked list of length one and I've got
Zed when you see my precondition needs a
list X and it needs a list Y we're
missing something and so what we do is
we call what's called a by abductive
theorem prover you see at the bottom the
list why the theorem prover doesn't just
say yes or no it discovers the it
discovers the list Y at the bottom and
it discovers the Zedd points de nil at
the bottom as well so it discovers the
Zed points to nil that's the bit that's
unchanged by the call to foo that's an
artificial intelligence probably called
the frame problem that you need to solve
the other one is the abduction problem
that's Cristiano was mainly did the
frame inference Dino mainly did the
abductive inference in any case we use
the abductive theorem prover to guess we
do the symbolic execution of a program
we use abduction to guess what the
preconditions should be and eventually
we get a post condition that's sort of
as technical as we're going to get but
the upshot is by using this abduction
technique we were able to move from ten
thousand lines of code to very big
programs it gives you a compositional
program analysis technique where you can
analyze the procedures independently of
one another
I mean modulo some things about
recursion but you see there's things get
grouped together as well you can get
after interprocedural bugs but you don't
end up verifying all of the code because
well maybe there's a bug in part of the
code or maybe your abstract domain is
what we talk about your program your
abstract domain might be not smart
enough to verify the entire program by
the way like if you give me Linux
there's nobody's ever made an abstract
domain that's smart enough to verify
Linux to the port parts of Linux don't
have any bugs I'm so the compositional
approach is very tolerant to imprecision
so this is good and it scales very well
and so where we had the Cabo 8 paper
where we could deal with ten thousand
lines of code
moving onto Popolo nine paper we can
deal with millions of lines of code
because of this thing going for
preconditions and the interesting thing
is we did that because Calcagno reacted
and he said although this was the edge
of the academic research it wasn't good
enough because it won't let me apply to
big code so applying to big code is what
brings us now sin the next part of the
talk I'm gonna talk about our experience
with the infer program analyzer at
Facebook so we're academics the
difference between doing the whole
program analysis on 10,000 lines of code
and doing the abductive analysis on
millions of lines of code is that you
can make a company based on it and we
did make a company based on it and some
folks with inside facebook saw the saw
that this had some potential and so they
acquired our company so now we go work
for Facebook and this was sort of
realizing Cal cannulas idea that we had
to go for big code in order to make it
real but okay so that's all well and
good we go for big code that sounds good
so nonetheless once we landed in the
company talk about a culture shock for
people coming from program verification
program verification let's make up a
slogan for that subject
move slow and break almost nothing right
let's write specs let's write proofs
let's do that and we land and we find
move fast and break things and things
like this right it might you might think
this is the worst possible situation for
people coming from program verification
I'm gonna try to argue in this talk
though that actually once you understand
these things right there's a great
situation for deploying ideas for
program verification and if only the
academic community would like start
moving a bit faster they'd have an
opportunity to have a lot more impact so
just to give you an idea so you might
think program verification people will
land in a company like that
let's change their programming culture
right let's teach them how to program
well that's not really gonna work you
know what there's this was from last
year there's a hundred and thousand
commits git or mercurial commits per
week to the code bases right um this
thing is not only is it big code
it's huge momentum right it's moving
fast and it's big and I'm not going to
come in with some unproven philosophy of
program verification and change that so
I think a better idea is for us more
academic people to adapt to that sort of
situation
so we land and then we've got a program
analyzer I'll tell you what it works for
later it works for objective-c and it
works for Java and we're running on a
mobile asset we've got a program
analyzer
and we hook it up to the internal
Facebook infrastructure and then we say
now we've got a deploy right so this
wasn't our end goal but at first we said
or I had this idea I you know what I've
heard from the academics especially
false positives are the most important
problem in program analysis so we worked
and we filtered and we tried to get that
false positive rate down and I sort of
thought it was probably like 20 or 15
percent or something like that false
positive right when we deployed and what
we did is we made we
run it nightly take millions of lines of
code takes several hours make a bug list
and then assign the bugs to developers
and what happened was nobody
congratulated us for our low false
positive rate the bugs would sit there
and not get acted upon and I was very
puzzled thinking I mean what are we
going to do here I tried to understand
this and I went around the company and I
was asking people and they were giggling
at me because they knew that this is
like the really wrong idea for how to
deploy anything but let me give you some
examples of why that is the most
important part is context cut the human
cost of context switching so when you're
doing a proof I'll speak to the
academics when you're doing a proof
right and somebody brings you one of
your old proofs even from a year back
and they ask you a detailed question
about that proof you need to context
switch out of your proof context which
in the old proof I mean it's hard right
and this is quite irritating if people
are coming at you and they're not sure
there's bugs in your old proofs right so
big cost of context switching same thing
in software development I'm working on
some code somebody brings me some code
that I worked on a year ago and there
may be there's a problem it's pretty
difficult to his context switch back in
right so context switching is hard it's
even hard to figure out who to assign
the bugs to so this this deployment
model didn't work it didn't work very
well luckily we had this compositional
program analysis that I showed you
before which can which if I change a
little bit of the program I can
reanalyze just that little bit of the
program like you do with a compiler and
this fits beautifully with the way the
programmers work their workflow and so
the way the programmers are working is
programmers submit code at Facebook then
there's a code review system there's
like a social network for code called
fabricator and then other people the
reviewers and the and the decoder will
talk about the code and eventually the
code will be changed and changed and
changed and accepted so there's a
conversation going
so our program analysis participates in
that conversation and so the way it
works is the developer submits a code
change then there's something called the
continuous integration system code
reviewers are discussing the code
program analyzer runs in the data center
program analyzer is running in the data
center and gets the the code reviewers
are discussing program analyzer sends
bugs on that code change not the entire
code base at that moment you see this
gets a long way to solving the context
problem right everything is in context
when the developer gets that information
so we've gone some way to solving a big
part of that human problem the other
thing is it needs to run fast they're
gonna commit their code they're moving
fast we need to get the information back
to them within 30 minutes or so millions
of lines of code base but small code
changes we need the information back in
30 minutes there's all better in ten
minutes
or we'll be too late but so what happens
is there's code and automatic comments
are written on the code like there's a
potential null dereference here
automatic comments are written on the
code by the program analysis tool as
it's running in the data center and
eventually everybody's happy and the
code gets shipped to production this
made an unbelievably huge difference
right when we made the original
deployment then you know hardly any of
the bugs get acted upon and I have was
chasing people trying to get them to act
on the bugs now all of a sudden hundreds
of bugs are getting fixed every month
hundreds of bugs are getting fixed
because it's just there in the workflow
unbelievable difference so this moving
fast bit
can't overemphasize how important it is
for program verification analysis to to
move fast here's an example the
developer's feedback to us they're happy
because it's moving fast it gives a way
better experience on the other hand what
about breaking things so here's here's
one of these things again oops a false
positive so one of the developers does
comment to me in a messenger chat whoops
there's a false positive there and I
said oh that's pretty subtle now you're
worried right as your static analysis
developer oh I've committed a faux pas
at this point we've made a we've made a
false positive but then the developer
says you saved me trouble other times by
seeing these NPS and thanks for the tool
so it's interesting working inside the
company the developers are moving fast
and they're incredibly positive they
just don't want us to slow them down our
tools need to move very fast and the
interesting thing there is we used to be
so scared of false positives we would
never ship a check until we were sure we
thought the false positive rate was low
not sure why we thought now we shipped
them earlier and get feedback from
developers and make it better so we
developed the infer static analyzer in
an iterative fashion same way as many
products in this internet age are
developed so we're less scared of false
positives and the developers will accept
us breaking things as long as we move
fast and this is really a key for making
static analysis more widely used in the
real world okay so let's look at a
couple examples right how many people
here have programmed in objective-c
that's a lot more than a purely academic
conference let me tell you so does
anybody see a problem with this code oh
you should cuz there's the there's
something at the bottom okay objective-c
doesn't use the normal I can't remember
the jargon but there's a garbage
collector which can collect cycles as
well as non cycles
the objective-c uses reference counting
and problem with reference counting of
course is when there are cycles in the
garbage it doesn't get collected
necessarily now in Objective C so you've
got this problem but it turns out that
this problem comes up in practice almost
always in conjunction with lambdas so
this up arrow is a lambda in Objective C
one of our people with this stÃ©fano i'm
talked to some of the Facebook
developers and they said this is the
main problem in Objective C that causes
us pain and so he made a check and so it
finds this retain cycle so here little C
gets allocated and then C dot handler is
equals this lambda expression the on
lambda expression at runtime creates a
closure right another object and it's
got a reference to see within it so
there's your cycle and then they go to
scope and so that wouldn't so that's a
what's called a retain cycle so the
interesting thing is this actually it's
a small example but it needs some
somewhat advanced program analysis it
needs shape analysis cyclic versus a
cyclic structures it needs to
distinguish and a little bit of lambda
all right so it needs so that's the was
the main thing the first thing the
Objective C programmers that Facebook
told us to get after here's another
example of the kind of thing you come up
against so I'm not going to show you
Facebook code but oh here's the funny
one so when the when when there was the
heartbleed problem infer program
analyzer did not find the heartbleed bug
like many other static analysis teams we
implemented something which then would
find the heartbleed bug but that's too
late right I mean we just have to admit
that that's too late so we didn't take
any credit for that or but we did run
infer on open SSL at that point when we
found some bugs and we submitted 15 of
them to open SSL I know businesses also
fixed them here was one of the easier
ones but it's deceptively easy so
there's a malloc and then there's a
dereference and so malloc might have
returns no except that this is what you
run into when you're doing program
analysis in the real world open SSL
malloc isn't malloc it's a wrapper for
malloc
and it's this rapper and so what is in
the program analyzer had to do to
understand this it had to first analyze
this procedure find pre-post specs using
that thing that I told you before that
and then it had to use those pre-post
specs to analyze this procedure and by
the way it had to go and analyze the
other procedure buff string uncopyable
simple looking thing and quite
sophisticated interprocedural program
analysis has to be done to catch it many
many of the noah bugs we come across our
inner procedural of this variety here's
another example
so what infer has been open sourced so
that was a see example this is a Java
example this is something so Google has
the Garrett code review system and so
this is something you they use for code
review and they've open sourced it and
we ran infer on it and infer has inside
of it what's called a taint analysis and
it found this problem and it reports it
like that tainted value reaching
sensitive function there's something let
me say this something which could be
vulnerable to a man in the middle of an
attack SSL socket was not verified
there's a point I want to make about
this example two of our engineers found
this example by running it on Garrett so
this is Sam Blackshear and Jules Villard
they stared at this potential bug for
hours might have been over ten hours and
they're trying to figure out is this a
real bug or not and they couldn't figure
it out so then they talked to some
security experts in Facebook who have
worked on this sort of thing is this a
real bug or not not sure but it looks
like I'd be careful about that submitted
it to the Google folks and the Googlers
they didn't tell us whether they said it
was a real bug or not but they fixed it
but there's a serious point that I want
to make here and that's that's that's
this one of the main things I've learned
is this is that there's a concept of
false positive and it's a good concept
false positive would mean if I happen to
have a complete program and I report a
bug at a certain line then that bug will
occur that's true bug if it won't occur
can't occur it's false positive um I
have no problem with that concept but
the false positive rate is a very
difficult concept it's a very difficult
concept because it's essentially
unknowable humans don't know that the
most the experts like in this Garrett
bug aren't sure whether that's a true
bug or a false positive many of the
things that the static analyzers are
reporting for reports are in between so
maybe it's it's repugnant but the human
doesn't know even after looking at it
for a long time furthermore this is
worse we have code bases in the millions
of lines that are changing at an
incredibly fast rate humans can't keep
track of that and figure out the false
positive rate so this concept of false
positive rate is something that to my
way of thinking it's not measurable so
it's an OK as a sort of sort of abstract
concept it's not you can't it's to have
them it's good for a measure to be
measurable and false positive rate is
not measurable so I think the false
cross of concept is not useless but the
importance of it is completely
overestimated in the academic community
and in industry what I've really learned
is it is it's evidence-based we like to
measure we like to measure more than I
ever did as an academic there's
something I can measure and I can
measure the fixed rate the rate at which
the warnings by the static analyzer get
fixed by the developers when we open
sourced infer we reported there was a
fixed rate as we had measured it around
80 percent that changes over time we've
seen it dip into the 70s we've seen it
tube into the 60s but the important
thing there is compared
to the batch mode deployment where the
fixed rates you can have a pro same
program analysis to play it in batch
mode or to play it incrementally and
have radically different fix rates right
so fixed rate is more measurable it
speaks to something to the value that
the analyst and analysis is bringing to
the programmers so in all it's a better
concept than false positive right or
it's more useful to the analysis
developer so we tracked that we tracked
of course you have to retract the report
volume oh one more thing I want to
mention the things that we track the
other thing I've learned going into the
industry is the importance of perf
performance is much more than I had
realized our team spends a good amount
of its time working on perf you saw the
earlier chart I showed you were our
analyzer was running on millions of
lines of code as academics our analyzer
was amongst the most performance program
analyzers one would have ever seen in
the academic world but we're always
fighting against perf we need to get
more perf to get feedback back to the
developers more quickly and some of the
main problems we've had so this
differential perf not only do care about
perf on the entire project but on code
changes you need quick answers on code
changes even a linear time algorithm to
follow only working on an entire code
base is going to be too slow but many of
the problems we faced have to do with
perf and so this was an example of one
of the problems we faced where we were
chasing more and more bugs for
objective-c analysis and this is the
amount of capacity infer was taking in
just some portion of the Facebook data
centers this was creeping up you see as
we were chasing more and more bugs until
it was decided that you guys are taking
too much you people are taking too much
capacity and so we actually had to
switch it off for a bit and then get our
perf under control biggest problem even
though we had the most performant
academic program analysis the biggest
one of the biggest problems we faced
internally is perf so okay so program
analysis needs to go faster and fast
and faster we spend a lot we spend a lot
of time working on proof so what's the
status of infer right now
so inside a Facebook it runs on every
diff or every code mod for the iOS and
Android apps for facebook Messenger
Instagram and whatsapp right and so
there's lots of code and that codes used
by a lot of people so that's good
hundreds of bugs are reported by it for
each month and fixed before they reach
production it uses yes a custom
separation logic their improver but it
also uses I'm you know you say the words
abstract interpretation we've got
various abstract domains we use whatever
we can and there's lots of good ideas
from abstract interpretation to use and
we do we use them besides being used
internally we VOC last lunch into the
open source and it's used by several
other companies like Spotify and uber
who've contributed back to it and it
helped make it better
uber it runs on every DFA uber as well
uber has a similar software development
model to Facebook so because we open
sourced it so friends in the community
get to use it so individuals not just
companies so this person Smedley thinks
that in for his badass so we have no
reason to quarrel with Smedley there so
so lots of people have fixed bugs
another thing a bit different from
working in academia is you end up with
things like this there's a I think
that's a wired article or a I tool is
Smashing bubs is now open to all so this
is a pro conference where we hear a lot
about functional programming right so
you might ask me have you run in firaon
itself well no not yet
i work inside of a company where there's
lots of ardent functional programmers
including on our team so this was when
we open source stanford there was a
hacker news threat right in the hacker
news thread i'll just read it legend has
it there's a small room at
book headquarters containing a quorum of
oak Hamel committers although in French
for some reason hacking away at a level
of abstraction beyond the can of mortal
man so yes in for his written in no
camel and one of the members of the
team's rule of alert is French and he
responded to this thread with this one
so that's that's a lot of fun okay okay
but to get to get a bit more serious
what I really want to say is that
there's been a tremendous amount of work
on program verification and analysis in
academia and it feels like as a felt
like it was a well developed subject
when I moved to industry I think the
work is all there's a lot of really
really good work yeah but it feels like
from an engineering point of view the
work is very underdeveloped so by that I
mean when we're developing our tool and
trying to make it go fast at scale we're
having to make algorithmic decisions in
territory that know right nobody's ever
been before and we can't find anything
in the academic literature to help us
and so we don't necessarily publish the
papers to pause to publish the papers
but it's not that we're flying blind it
seems like doing program verification
for toy little programs there's been a
lot of that doing at at scale and that
speed has hardly been done and there's
not much to find out there so maybe I
can turn this around and I can say that
I think there's a tremendous amount of
impact being left on the table by
academic work in program analysis and
the more we can concentrate on
compositional analyses to go fast
the more we can open the door to more
impact and well just make make the world
software better so ok that's a good
place for me to stop thank you
so I'm not familiar with fabricator but
it looks sort of like get pull requests
or something like on Garrett where is
this lime base where you can leave
comments and certain lines can you talk
about how you or what possible issues
you've run into trying to explain the
results of an inter procedural analysis
using just commenting on single lines do
you have developers who have trouble
understanding why then tool reached the
conclusion this is where they've
surprised us as well
so we have something which a link they
can they can click to go see an inter
procedural error trace but the nice
thing is we measure at Facebook so we
measure how often do they click that not
often way less than 5% of the time and
the think what we found is that let me
joke about the concept of abstract
interpretation so there's this arrow
trace then what we try to do is to give
an English explanation which is quotes
an abstract interpretation the best
English abstract interpretation of that
error trace that we can give which gives
the reason and we've fiddled with those
over time and usually the developers
they can read that and they can
understand it on the spot even though
it's interprocedural and they might go
look at it and getting their developers
to react quickly having the good error
message so for instance for a null
pointer dereference we say the null was
created in that procedure and returned
here and dereference here order
reference and the other procedure they
probably know enough they probably know
enough about the surrounding code to
your right there you right there and I
can see how that all fits together and
the developers are making the decisions
very quickly so often do they follow the
surprisingly well yeah there's lots of
things I mean there's there's like
typical abstract interpretation things
like join which means to not have as
many choice point listen thing there's
there's once you start applying things
at this scale there's unbelievable
amounts of fat in various parts of the
analysis so by just by the typical
things engineers do of profiling we can
find lots of fat to get rid of we've got
some novel program analysis algorithms
which schedule things in different
orders which I mean we're going to talk
about later so there's some novel
program analysis algorithms that are
actually going on which I hope will talk
about more at another time yes so
there's there is stuff but not stuff
that did this quickly I can explain that
well so my question is surrounding the
kind of problems that you're trying to
solve are all related to the kind of
imperative style that is proposed by
both iOS and Android where you have the
referencing you have these loops and all
that stuff why is very we'll try to
solve those problems kind of with the
static analysis rather than into moving
into a different paradigm where no
pointer exception is not there for way
of written that's very interesting isn't
it I mean so so so so you've got things
like I mean Apple gives us iOS and
Google gives us Java Java right and for
Android and then I mean that's not in
our control so we have to deal with that
so I love things like ml right there are
no no pointer exceptions in ml and if
the whole world programmed in ml that
would be cool with me I mean there's
lots of problems even in ml but we
should respect the industry it's I mean
to say things like Oh
your programming language and then
although these problems will go away a
lot of other stuff comes along with it
like the libraries just a lot of other
things and so I mean it'll take some
time for this some of these technologies
to be proven to the extent that they can
get wider acceptance and I think we
should just respect the industry
problems and I'm just there to help them
and if there's languages like ml get
wide acceptance I can find analysis
problems in ml too especially
surrounding concurrency so but I think
academia let's not put our heads in the
sand and say oh if only these in touch
lists would change their language I mean
they're actually thinking very carefully
about the language but also the
programming environment and they make
very serious decisions about which ones
they use will you still be able to
finish this work if you were still
working on the academia in academia we
got it to the point where it was pretty
good
now I'm gonna the point where it's a lot
better and it's deployed no because to
take the take take the leading edge
popular CAF paper turn that into
something that can be deployed in
industry is more than 10x extra work
much more than today so we know I don't
think we could have done it
watch this space some c++ is coming I'm
not giving you a date
does your 99% left include functional
specifications this is a very
interesting question I mean a program
verification person is like if only they
would write the specs I can do so much
but think of this
suppose we had the perfect verification
system that instantly gave us the right
answers how do we deploy that to the
world it's very hard to deploy that so I
mean it's it's included in what I would
love to do and certainly in that 99% but
we shouldn't kid ourselves about how
difficult it is and the great difficulty
is not making good program verifier the
great difficulty is figuring out
situations where this brings high value
to the programmers and convincing them
well there's there's education too so so
yes and that's my longer answer as well
our privacy issues not part would they
not have been addressed with
specifications well for instance yeah
sure I love functional specifications
the hard problem is getting two people
to write them not to verify them so at
work we use flow for JavaScript yeah use
flow for JavaScript code base yeah I
love flow so infer so flow can get rid
of all no pointer exceptions I think by
typing is it an example of what it can
do
it's like ml for JavaScript so the
difference is that in fur has in fur can
be used more easily you can just drop
the code in to infer flow you have to
interact with it but when you interact
with it you get more like flow as an
example like Sophia asked the question
about functional specs types are the
sort of easiest simplest version of
functional specs flow has that and so
you can get more there's more friction
with flow less friction with infer but
you can get more out of the flow model
the I'm in sort sort of
in favor of program analysis where it's
like infer completely automatic but
where you can sprinkle in types and give
you more so the way these tools tempt to
be is it's like one or the other and
there's no reason for their doing one or
the other so flow in and four are sort
of two ends of the spectrum there I
would hope that I mean going forward we
can have flow in furs so so this diagram
I showed you was resource consumption we
used up too much of part of the data
center and this is bad
so this costs money and it stops other
people from doing things so that's bad
but also if infer runs slowly then well
of the people are commenting on the dips
hey I think you've got a bug there then
it fur is too late then they're not
gonna pay attention to it so it needs to
get in there and say thirty minutes tops
as an average or better less so anytime
we've got a regression that slows in fur
down that's bad
right that will lead to a worse fix rate
at any time we take more of the data
center that's bad that costs too much
money
so both it sounds it looks really cool
it looks really cool but if I'm not sure
I understand the exact names of the
tools but the work coming from Microsoft
in that direction I think this is like
to Sofia's point the question is how to
have it deployed so the problem is like
we can create this so researchers can
use it to make demos but we need to
create this technology so that
practicing software developers use it
and for that kind of technology that's
the problem that needs
have you got any interesting insights to
language designers besides be like ml
yeah of course I do but about it I mean
being like ml is a great first step
right for more imperative like yeah I
mean probably you might have heard of
concurrent separation logic some of you
might have heard of it and this gives us
a brilliant way to type-check concurrent
programs and there are even languages
like asynchronous liquid separation
types in mezzo and it's related to rust
yeah there's lots of stuff can be done
with concurrency and language design and
typing that's an example right we're
writing our own power source or using
other person so we don't just hook into
the compiler what we do is we hook into
the build system and we intercept calls
to the compiler so one one reason why
it's 10x to cost you 10 X or a lot more
is cuz okay so we've got maven and and
buck and various other build systems for
Android in for needs to work with all of
them make it needs to work with make so
if I wanted if I want to run infer if I
can go Java C blah blah blah then I get
to infer - - and then build command
infer - - maven blah blah blah and so
then it just goes so some people can run
it out of the box so not so much we
interface with the compilers but the
build systems is huge usually important
sorry just following then I understand
incubation into the build system but
then you're into getting like each of
the codes from the compiler so why
didn't your media representation like
what are you pulling out
that compilation well I mean so there's
so we're do it differently in this
sealed Frank family of languages and the
Java family of languages but what we do
is we have to you have to take the
source you have to give it into some we
have our own intermediate language it
might be called the small foot
intermediate language and it's we
compiled all of our languages into that
then we analyze the small fan
intermediate language it's a
intermediate language oriented to the
kind of program analysis what do we do
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>