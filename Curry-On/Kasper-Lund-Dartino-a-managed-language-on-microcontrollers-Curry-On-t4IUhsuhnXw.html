<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Kasper Lund - Dartino: a managed language on micro-controllers? - Curry On | Coder Coacher - Coaching Coders</title><meta content="Kasper Lund - Dartino: a managed language on micro-controllers? - Curry On - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Kasper Lund - Dartino: a managed language on micro-controllers? - Curry On</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/t4IUhsuhnXw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">of embedded space you could say a
Raspberry Pi - you go for the three
version as well it's fairly high-powered
like ARM chips quad cords 900 megahertz
a lot of RAM actually for a small device
and plenty of flash through external
micro SD card support and it's not that
expensive and it can run just about any
operating system including Windows and
lots of sort of real and real and you
could say embedded OS is like I think
Linux is probably the most used ones and
these Raspberry Pi devices but it's
really the same kind of OSS that you're
used to running on your desktops and on
your servers if you switch it around and
go to the micro controllers the
difference is is it's it's certainly
there it's still running a lot of them
are running arm CPUs a little bit less
and clock less aggressively usually we
see people running at the high end of
the embedded space cortex m7 chips and
then the amount of RAM is quite limited
here so we probably see you around maybe
300k and I on a very good day and but
maybe the biggest difference is really
that a lot of these ships do not come
with a lot of fancy memory management
support so that means that they cannot
really run any F the regular OSS in any
meaningful way even micro Linux and you
see Linux which is sort of scale down
not using the enemy and everything still
takes up too much RAM to run in these
devices so it doesn't really fit so
you're sort of stuck in a mode where you
don't have an operating system so you
need to run sort of on the bare metal on
these on these devices this is our focus
in in the Totino project and we want to
try to make it a lot easier to write
software for microcontrollers and maybe
sort of bridge the gap a little bit so
that's some of the things you can do on
Mike microprocessor-based devices is
also possible in a microcontroller space
so I don't know how many people here are
familiar with with that show of hands
was like a third of the people here
and know about what it is so that is
actually a fairly heavily used language
at Google these days it's mostly used to
build web applications and Google
AdWords is building the the new version
of their product in iNDOT so it's some
of it an unfamiliar territory to venture
into to try to make that run really well
on these small devices and the code is
fairly familiar to people with a and
with an interest in in languages based
on curly braces it looks like C Java C++
C sharp there's certainly a lot of
inspiration from those languages and
it's designed to look very familiar and
I think in many ways that work pretty
well it also means that it's it
sometimes comes across as a little bit
of a boring language it doesn't feel
very novel it doesn't feel very exciting
at the syntax level but there's a lot of
good properties in the language also for
making it run on these small devices
that I'll try to go through if you want
to try it out in a in a browser you can
go to the top hat side and just I play
with the language a little bit there to
get a feel for what it is so why would
you want to put something like that on a
micro controller there are number of
reasons why I think one of the most
important things is that the number of
developers in the world that are
actually comfortable and productive
writing software for these devices is
very low so it's very hard for people to
actually to scale up and build good
software for all these devices out there
so it's really important that we make
these small platforms accessible to more
more developers it's also I think
important that that this area of
software development and for for these
small devices is certainly an area
that's still lacking a lot of innovation
it has a very sort of old-school feel to
it so I think it's important that we
upgrade the development experience and
make it much more modern and productive
and and we need to turn some of the
proprietary stacks into something that's
more open more flexible so we have a
possibility to actually get some some
innovation going in that space as well
everything we do in the in the top and
that tina pocket is open source and
we're trying to to have to see some
technology here and try to make it
useful
so in a sense I think we really need to
extend the tool sets that our people are
used to building software for these
small devices GCC is not really the
biggest thing that people use in the
space plus a lot of sort more hardware
near tools I think we need to extend
that a bit and and don't have like C
code and GCC and gdb be the only options
and these devices it's it's a very very
scary place for people that just have a
good business idea they want to build
some software for embedded devices to
enter into and a lot of people just
cannot get it done at all I used to
think that the biggest problem was
actually like doing the hardware side
but it seems like software and these
small devices is a really big issue too
and we talk to a lot of people that are
building these small devices and even in
low quantity software the software side
of the of the of the cost of building
new devices is is it sort of estimated
to be maybe 2/3 of the year
after your overall thing so that's
that's certainly change right even if
you look at a five hundred to a thousand
quantities of custom hardware design so
which is somewhat surprising I think
that it's it's already getting there so
I think we need to do better than this
and at least for the you could say the
higher end of the of the low end
embedded devices we're specifically not
targeting small 8-bit microcontrollers
or anything like that I think there are
much better tools for for that but but
for these fairly spiffy new devices that
come out you can do better so the
programming model that we're proposing
for for a managed language on these
small devices needs to be a little bit
more flexible than what you can get from
from a stack based on C so what we do is
that the bottom layer we have a
traditional embedded real-time OS and we
use free artists for a lot of things
because it's open and available and we
like this sort of accessibility that's
built into that and on top of that we
put the tattini runtime and then and we
actually allow you to have multiple
independently develop programs that run
on top of this of the setup this is very
different from a lot of the from a lot
of the systems that run straight on the
embedded real-time OS because they don't
really have a way of running sort of
independent components in a truly
independent way because they also
interfere
it needs to be linked together in one
what an elf file at the end of the day
one binary file that can be flashed so
this is an area where having a
abstraction layer in form of a runtime a
virtual machine you could say really add
some value that you can you can get from
a runtime instead of having that from a
traditional OS based on systems that
have memory management support that
allows this on top of these multiple
programs we we actually do run multiple
processes so you can have multiple sort
of independently executing versions of
the program or part of the program
running next to each other it's very
much inspired by some of the success
with with Erlang and we're well being
able to sort of model your concurrence
in a very straightforward way by
splitting it up into multiple
independent executing processes seems to
be a good way to get some more and a
fault tolerance to build into your
application that's actually a thing that
people writing suffer for these devices
is very interested in they feel like
their core components that they'd like
to make very robust and there are the
parts like the UI that they could
probably live with having to like
restart if if things go bad but there
are certainly things where they where
they communicate with their networks or
they they do the upgrade that's the year
of the firmware that just needs to be
very robust
so having yeah ability to isolate
certain components is a very good thing
so to make this actually work on these
small devices with a few hundred
kilobytes of RAM the process need to be
very lightweight like an airline so a
small memory footprint for them a few
hundred bytes and we also need to mint
them to be be able to block and wait for
some event and without taking up a lot
of system resources which means that you
cannot just map a a process that vans on
top of 1302 a a threat or a task from
the underlying OS and those things
that's gonna be too heavy weight so we
have to sort of multiplex on top of
fewer native threats and and it's a it's
a nice design if you can make sure that
if you ever end up on an embedded device
with multiple cores you can run these
things in parallel so that also
influences our design a bit right now
we're actually not running on any
devices that have multiple cores so they
don't really run in parallel but they
certainly do execute and
in in an independent way with preemption
and everything so one of the things that
this is a larger to do is that when
you're building something and network
connected device you can handle new
connections a new process because the
overhead is fairly low and and here's an
example of this piece of dart code that
runs on these devices where you just
keep accepting incoming connections and
spawning off new processes as you do
that and and in this new context of a
new process you can there you can do
some utf-8 encoding you start by
probably not the heaviest operation in
the entire world but at least you can
you can do this off the side if you did
something here that you were more
worried about getting getting right
something that could compromise the
integrity of your system it probably
would make more sense it's a little bit
derived so I'm it just shows that it's
possible to have this or more blocking
mode where the spawn accept will
actually not continue to execute until
it gets a new connection in which case
it will then spawn off another process
so to actually get these processes to do
anything useful for you you need them to
be able to communicate and based on some
other languages like go and other other
systems like that we've experimented
with using channels and and ports for
that a channel is a queue of messages
and a port is is a it's a sort of a
reified the object that acts as a
capability to send to a certain channel
so without having gotten access to a
certain port you cannot send to the
channel that sort of sits in the other
end of that port so there's no way you
can invent a a reference to a channel
you could say and it allows two simple
things like this where you you spawn a
process and you just keep sending
messages from one to the other and the
other process will then just start
consuming them from that channel very
simple stuff in some ways you could say
this is almost too easy right the only
thing you saw here was sending integers
which is almost trivial set between any
any kind of in any kind of system so you
probably need to be able to send
something more structure than just
integers and strings so it's certainly
an option just to say like why don't we
just have like shared state concurrency
between these things we'll just say you
can send any object as a message without
ping it so you just like get hold of a
reference to the other object at least
that's a very very cheap way of sending
objects around the system like that and
then you can have these multiple
processes just operate on these objects
in a potentially in parallel if you end
up with multi cores and at least
concurrently in a variant on control the
way you could say and then we just throw
in some explicit synchronization
primitives to make it all work how does
that sound
most people don't don't like it they
don't want that mob so that's not
invalid we implemented we have something
very similar though and the only thing I
had to add there was the immutable word
and so any deeply immutable object can
be sent as a message without copying it
so if if the runtime can guarantee and
can prove that what you're sending
cannot be changed after you send it at
all
then it's fairly safe for us to share
these things and you can have these
multiple processes operate on these
objects without any issues and then
there's no need to have explicit
synchronization support in the in the in
the language or in the on the core
libraries in addition to what you get
out of the out of the channels so this
seems like a much better starting point
for for these things
so either you you sort of view these
structure your your your mutable objects
and and send something more primitive or
you are allowed to send without copying
objects that are sort of provably at
runtime deeply immutable it's not based
on static typing it's it's based on
dynamic properties of the objects so and
a deeply mutable object is an object
that only refers to other DP mutable
objects and that does not have any way
of muting its own state and it's pretty
easy to to maintain information about
that at runtime
it's also possible sort of Erlang style
to monitor certain process and figure
out what they're what they're doing if
they're misbehaving so the usual way a
spawning process actually makes the the
spawner and the spawn e linked so that
if one fails the other one fails to but
you can you can sort of up out of that
model place next spawn in a detached way
and and saying that you want to monitor
and the any kind of events that flow out
of the process in terms of why it's the
suddenly terminating or getting
getting uncaught exceptions so you have
a way of sort of receiving those events
and acting on them I either by restyling
the process and again they're very much
inspired by by a similar approaches in
inner lining and other systems so you
saw here that there is a a call to
receive that's blocking so you may have
this problem within one process you can
only really block on one thing at a time
and we found that and it's a litte bit
too limiting and then people want a
little bit more than that so we've
experimented with that with an approach
that have a cooperative set of
concurrent fibers within one process and
they are not preemptively scheduled they
are concurrent concurrently executing
they're built on a co-routine model and
so they're also sort of co-routines
underneath and but it allows you to sort
of wrap part of a call that does a
blocking call in a new fiber and and
sort of fought that off and and get to
so our threats of execution within one
process here they do share a an outer
space that they can share a mutable
memory in this way and that's the reason
why we prefer zout and not having them
preemptively scheduled and get more
control to the developer in terms of and
more easily understandable places where
you might do the switch between them so
that's the that's the that's the front
of the fiber model so I think when
building a somewhat dynamic language for
these small devices that the biggest
issue we run into is is how do you do
the dynamic dispassion the call of
methods without wasting too much RAM on
these devices and how do you make that
actually work pretty well and I used to
work on on v8 and the tricks we use in
v8 to make and make it run fast all
require us to do like mutations and
caches and and and lots of sort of small
adaptive tricks to make it work well you
just don't have that amount of RAM to do
this on these devices so we've had to
sort of look in the literature a little
bit and find some other ways of doing it
so like the fundamental challenge is
fairly simple like if you want to call a
method on an object and you have no clue
on what kind of object you might get at
that point in your code you need some
way of finding the right method and
invoking it and and finding the method
is the one thing I want to go through
here this is out of the fundamental
problems
of having a system like this run run
well and run efficiently so like the
most naive approach in a body sort of
single inheritance language and the most
naive approach doing this is just look
at the the class of the the instance did
you call something armed at runtime and
then just like traverse the class
hierarchy looking for the method like
traversing up the super chains and
looking for the looking at the method
tables in the individual classes it's a
fairly slow process and there are lots
of ways you can make that faster through
binary searches and hash tables and
whatnot like all the classical tricks
apply here but at the core of it this is
sort of what you need to do right if you
have an instance of a and you want to
find the method foo you look at the
methods in a and you find it there
you're done but if you look at it and in
stuff B instead you have to look through
like power and to string before you
realize that it's it's not defined on on
P and then you can traverse up the the
class hierarchy reach object and look
through the methods up there and realize
that it doesn't exist and it serve a
simple process but a little bit too
expensive people have spent a lot of
time optimizing this in the past in
dynamic systems so usually where they
start is through a sort of global lookup
cache of some sort and and mostly they
end up with a system that looks like
this
like they have to and sort of hash
tables make a primary table and a
secondary table and and the reason why
they have two tables is because they
when we when you built these systems you
really want to have the lookup in the
first table where you expect to get most
of your hits as simple as possible which
means that you don't want to deal with
collisions in that table at all so you
have this way of demoting entries where
you do hit collisions in the first table
to a secondary table to make the cost of
collisions smaller but of course you
also might need to then like there's
only two levels here and you can add any
number of levels if you want to but at
some point you'll end up throwing
information out or having hash tables
that actually deal with the collisions
and so this is actually what what people
have done in the past and something I
built myself as well where you have
really trivial hash functions for these
these two tables you have different hash
tables in this case one of the options
is to have the hash be it's like the XOR
of the address
the class and the selector and and in
the other case in the secondary table
maybe you flip it around and say we have
a similar simple operation like
subtraction that also gives you a really
cheap to compute hash code and if you
look at the from an sort of an abstract
point of view like the kind of code
you'd need to go through to actually
look up in this table is something like
this like you first you sort of probe
the primary table see if if yeah if the
entry you find there matches the class
in selector you're looking for if it
does you're done and this is where you
you hope to spend most of your time I
just hit that table and you're done if
that doesn't work you look in the
secondary one and if that's there you're
fine still and otherwise you have to go
through the expensive step on doing some
sort of class hierarchy based lookup
demote the primary to the secondary
table possibly retiring a and entry in
that table already and then update the
primary overwrite the the primary the
primary cache entry with with new
information so that you might hit it
next time it's it's really hard to
actually make this work really well like
it works pretty well if you can get your
program to always hit the primary table
but in practice it turns out to be
almost impossible with these trivial
hash hash functions like you're torn
between having to have really trillion
hash functions that are really quick to
compute and and get through and also get
some very low circulation rates so just
kind of hard to do the the machine code
you you want to run and want to hit when
you most of this is something like this
right where you where you just XOR the
the the pointer to the receiver class
and the and its pointed to the selector
together and you just mask off some bits
to it to make sure you hit the table and
then you look it up and you compare the
the entries in there to make sure that
you're hitting the a valid entry in
there and and if this actually works and
you're not taking the conditional branch
at the end here and then it's actually a
pretty fast thing so it's it's really
the the the problem with this approach
is that you're not always hitting this
case you end up in the missed case quite
a lot and additionally and it uses a
fairly significant amounts of mutable
memory like the size that we need to run
on these small devices we easily have
maybe four four thousand entries in the
primary table and a couple of thousand
entries in the secondary table and it
really adds up like all entries have to
be maybe maybe 16 bytes and and it just
it's a bit too much if you have a
multi-layered system manipulating this
table is also expensive just because you
need to synchronize or have threads
specific versions of them so it's a
complicated version like the next level
up here is to avoid doing the like sort
of the globe will lookup caching and go
for inline caching I don't know how many
people here familiar with the term
number of people sort of know what it is
it's it's actually just saying things
let's associate the cache entries with
the call sites instead of having them in
a global table and and it means that for
any call site the selector is a fixed
thing thing like we do object our foo
object might vary but the name food does
not vary so you don't have to check that
when you validate that the cache is
correct and you don't have any hash
collisions here and so that the kind of
code you can run through here to make
this run fast it's kind of neat like the
original approach for this is to say
like let's just put in the code at check
for whether or not and the class is what
we expected it to be and if it is then
we'll just go ahead and do a direct call
to that that code and then we'll use a
self modifying code to just patch this
up whenever we end up in in this case
self-modifying code is sort of not that
hot anymore for security reasons and on
these small devices you don't have
enough RAM to store all your code in the
mutable sections anyway so you do have a
problem there so and most systems are
sort of going away from this approach
and they're not anymore relying on
self-modifying code for it for doing
these things certain architectures also
come with a fairly big cost to do these
things and like where you have to
explicitly go flush some and instruction
caches to make this all work out so it's
back in the day this was a very clever
technique and it worked really well
today it's sort of not the way to go
anymore so most people end up with
something like this instead today it's
just another level of indirection and
you move the the data in the cache
outside of the code makes it easier to
patch it up but it does mean that the
direct call you happy
for there now becomes an indirect call
through a cache entry object that might
have gotten patched up so here you're
now relying on the branch prediction
engine ft and of the CPU to do a really
good job to get the get good performance
out of this so in some ways you made a
little bit harder on the underlying
system to make this right but you do get
some nice benefits in terms of security
that you don't have writable sections of
code in there floating around in the
system it still has this problem that it
requires multiple words of mutable state
per call site it's hard with the
multi-threading as well and it only
really handles mics and monomorphic call
sites places where you only see one kind
of object floating around that's the
only thing it really handles well
certain can be extended to to the
polymorphic cases but it doesn't really
deal with the call sites where there's a
large set of different kinds of
applicant flowing through it doesn't
really deal well with that you need an
another approach for that and so like
none of these approaches are super
attractive on these small devices
because you have so little RAM and it's
so hard to control the performance of
these these things and we find that for
certain benchmarks we can make it run
pretty well but there always be another
benchmark another program where you will
not hit the sort of the the sweet spot
of performance wise and you end up
having issues there so having something
better to fall back to or entire
different entirely different strategies
seems very like a very attractive thing
to go for so if we take a step back and
look at the sort of like the core
problem here and you have an object and
you want to call a method on it like in
some systems right you actually might
have ecstatic type of information for
everything you do so you have something
like this like a and you know a the
optic variable here always refers to
something of type a so if a is a class
type and you have single inheritance you
could probably do something much better
here and go through like something like
v tables and well you just use the fact
that you know that at this point in the
code you only see a s
and so you can compare you can compute
an offset into a table at at compile
time and just stuff it in there the just
doesn't really work in a dynamic system
right because first of all a might not
be a class type it could be an interface
type and also you will have code or you
don't have type information so you need
to make the general case run faster the
question is can we get some of the
benefits of V tables without having to
go through adding static typing
everywhere I think the answer is is yes
if you take it and look at something
maybe slightly more complicated and
think of a simple simple solution here
which is to say we take all the methods
and class in the system and we create a
matrix and and that matrix will be
essentially all methods all combinations
of classes and methods in the system and
we just like to lay it out there and say
why don't we just say that the classes
are a b c and d we have fubar and bass
methods and we have this table and you
just look up in it and you find the
right method to call and it's a constant
time operation it's very very cheap very
simple to do that seems like an
attractive approach right except for the
fact that this table will be huge it's
gonna be really really big like number
of method names and the number of class
in any reasonable system is gonna be too
much for you
but other than that it feels like it's
kind of a nice approach to it so why why
don't we just run with this sort of this
model and see if we can actually make
this become somewhat smaller and this is
where a technique called selected based
row displacement comes in essentially
you see here that there are rows that
have lots of empty slots in them so why
don't we find a way of using those empty
slots to store information from some of
the other rows so we can actually
compute like essentially one one row
where these different selector rows are
sort of displaced down on each other
so the sort of thief the row could end
up looking like this since there so you
have all the methods that are defined in
the system in one table and you use and
reduce basically all the holes except
for a few in the in this layout so how
do you go about computing this table how
do you make it work well the trick is to
assign a an offset to all the selectors
so that the selector offset plus the the
ID of the class will give you the right
entry in this table so if we want to
take say
the bar selector here and lay that out
first because that's the longest one
then you can sort of see that and we get
we get to give bar offset zero to make
sure that if you actually call bar on an
a which has index zero and we end up
hitting the serious entry in the
combined table and and so forth with all
the other possible classes that they
either have an implementation off or
have inherited a method definition for a
foot bar so for the next one for a for
foo it's a bit more complex but we need
to make sure that the B implementation
of foo ends up in entry for there and B
has index one so the offset for foo
needs to be III to make this work and so
we assign through the offsets three and
then just put these these things in here
you may have noticed that I'm adding
some extra numbers next to the entries
down there and that's because now that
we saddled overlaying these these
entries we have to make sure that we
don't sort of by accident end up
grabbing hold of a an entry from another
row when we call a method there so when
I call say foo on an a I would actually
by adding foods off at three two A's ID
zero hit the third well not the third
but the ma index three in the in the
table which is an implementation of par
so I need to verify that the entry I
find in the table is actually for the
the right selector I'm looking for and
it's kind of neat to just be able to use
the offsets of the message for for the
selectors for that so just verify if you
call through on an a and you'll had in
index three in this table and you can
verify that that in offset in that that
table is zero not three so it's not a
valid entry and then you don't have to
go searching for everything anything you
just need to say that this is not a
method that exists anywhere in the
system and it's a constant time so have
no such method invocation again when you
would they want to add the the last
method here you might run into the
problem that and that bass needs to get
entry and offset that is for not three
and you might get holes in this table
and it's because it's really really
convenient to have
the same have the property that you have
unique offsets so this validation
becomes a simple comparison the next
sense just like overlaying putting down
one table and then off you go
it's it's much simpler and the other
approach that we've seen so far and like
you need to grab hold of the class ID
from from the from the receiver class
you need to add them with the selector
offset and you need to look over the
table and then you need to validate the
entry but other than that you're good to
go so except for the fact you have to
validate the entry this is almost like a
V table call retail calls don't have to
validate an entry here you have to check
that the one you find is correct for you
this is a small price to pay I think so
this is actually what we implemented in
inductee no this is what's running on
this device now I'll show you that in a
moment and it works pretty well and it's
it's guaranteed constant time and maybe
the nicest thing is that the whole table
is pre computed and it's started in the
in the in the read only segment which is
like flash of the device not RAM and the
downside is to takes up a little bit
more space and V tables which is not
necessarily the most company orientation
in the first place but we can move all
of that to flash and have like no RAM
user general which is kind of convenient
and so I think this actually is a good
approach if you have closeable
assumptions and you have an a setup
where you you want to have really fast
dispatch without relying on static types
and I did not come up with this strategy
at all it's a well-known technique
documented I think really nice way in in
a book by a coward reason and and if
you're interested in this whole area
with there was dispatching and and
calling methods making that fast
I read certainly recommend the book
covers lots of other details as well and
as many other good things in this in
this field even though it's 15 years ago
this was written it's showing them
updated at all there's lots of the
wisdom and truth and there's today so so
I want to just the end up just showing
you some of this stuff on a real device
and I brought one with me here and and
and it might be a bit hard for you to
all see
but you can always come find me
afterwards and you can get a proper demo
of harlotry ones and what we build this
is a small SDK that allows you to run
dart code on cortex and force and m7s
this is the m7 device I brought today it
has a nice touch screen so it's easy to
show how this all fits together and how
it all works and we're still pretty
early in the process building this thing
and we're trying to figure out if if
everything we've sort of put together
here fits well and is a useful way of
developing the software but so far it I
think it's become very apparent that
it's very easy to make it a lot more
accessible for developers and then the
current tools I think and there's a lot
of benefits and actually providing in
the air and that's decay that's much
easier to get going with with a
high-level managed language so so the
way you would run code on a device like
this from a command line and showed you
can certainly run both this Totino code
on your development machine and on the
device here I just it's not very
interested to see this on an on a slide
but it just shows you that you can
choose to run your stuff on the on your
in this case your MacBook or you can
flash it on the device and have it run
there so and I actually did a bit of
flashing before you guys came here that
came out wrong
but then I did update the device and and
and you can actually see it running here
it prints hello from free artists on the
device and it works pretty well
and if you want to see a little bit more
sort of code in action
I built a a small app for this this
thing in dock using our sort of
preliminary tooling for this thing right
now we're building a small plugin for
Adam to to get a feel for how this all
works out but this is actually dot code
running that will run on this small
device in there in a short while it
shows you that you can have like a main
method sets up some like channels and
ports to communicate it creates a
separate process to actually pull the
the touch State of the of the display so
you you can it's touch enabled if you
look at the code for the touch side oops
poling it's it's down here this is very
much the way people write say python or
or arduino code for these small devices
like small loops it ends up sleeping for
a while following the the underlying
state of the system and in this case
it's a very simple thing it just pulls
the state if there's nothing pressed it
will send that information to the to the
other process if there is some something
pressed it will check well another it's
changed enough that we want to send it
to the other side or if we want to
filter it out right now so it's very
very simple saying where you see like
the distance to call down here between
these points the points themselves are
immutable objects so i can send them
between the process right quite easily
and and they end up up here where we're
receiving the events and and drawing a
line between the previous point and the
new point so if i run this it will
actually start maybe you can see down
here and there's probably the most
painful part of working these devices
the flashing process itself is it's
somewhat slow something we're looking at
doing instead of in a more incremental
approach to and so it takes probably
around like five six seconds using sort
of standard tools with this flash and it
means that if whenever you want to
experiment on these things you have to
wait and wait and wait I'm still waiting
so it's probably more than five seconds
if things actually work it's up and
running now and now some of you might be
able to see me touching the screen at
least it's actually drawing stuff here
on the screen you can play with it but
it's a very simple what you can do here
and it just shows you a proper high
level language running on these small
devices so I think the conclusions are
pretty fairly simple maybe not bad then
ground shaking yet like the open
software ecosystem for these small
embedded devices is still very much in
its infancy that GCC and gdb has come a
long way in the space and they're much
easier to use today than there used to
be arm is doing a good job and packaging
them up and making them available and
but it's still kind of hard to get
started on these things and it requires
a special kind of programmer to to be
productive there it's very clear that
the world needs more
developer for these devices going
forward like the amount of software in
this device it's got to go up and and we
certainly need to be be able to equip
more folks with the abilities to deliver
something good on these devices and our
job here is try to make embedded
software development easier and it's
through a managed runtime and language
play on on these devices I think that's
it on time we have about two minutes for
questions
why have you picked apt dark not as a
language like go or for example
ikema script and it's a very good
question like what makes top so fitting
here it's I mean part of it is the
language but it's also very much around
to look in the core libraries and I used
to work on on v8 and JavaScript and an
efficient implementation of chalice is
much more complicated than an efficient
limitation of thoughts so like getting
the runtime system into the the kilobyte
Reynaud kilobyte range without the
megabyte range is it's very very
important here and making javis would
run fast on these devices would be much
much harder go is a very different beast
and I think it would be fun to have go
running there as well I think a lot of
people find their ego very attractive I
think a lot of people also find simple
object-oriented languages fairly
attractive in this space actually I
think the most popular alternative to to
see it may be job on these devices
Python in the form of micro Python so I
think there's a lot of interest there
but I mean rust go there are certainly
other alternatives that would probably
do well there so one more question would
you recommend using dirty new for
systems that have hard real-time
requirements let's say building musical
instruments no I think the short answer
is no and we're we're we're getting
really good at interfacing with external
code so if you probably want to keep
your your hard real time constraint code
in a lower level language it's very hard
for us to guarantee and that GC pauses
will be predictable enough for you and
it's not an area we're investing in so
short answer is probably no
the question is about GPIO so like what
is the support for GPIO is it like a
native support like you need to have
like library yes Co controller or
doesn't need to be something like that
the communication goes through sisyphus
or something like that how do you how do
that in the art I start you know so
there there is no sort of sisyphus on
these devices so it's much more native
and we're building the libraries for for
a number of these devices but it's
certainly an area where people with a
little bit of skill sets in to how these
devices work and maybe the way you write
the same thing in C and that would be an
easy way to contribute to something like
this last question so the the RAM
consumption is it's mostly foreign for
the GC may add a metadata so all these
supporting structures we need for for
keeping our garbage like it heaps around
I think we have an overhead there of a
few percent so I would say that the RAM
overhead is probably in the maybe 20
kilobyte range and and the flash
overhead is it's much more significant
probably in practice with the free
artists and all that stuff a hundred and
fifty two hundred K flash but we're
focusing very much and bringing down the
ram numbers so thank you let's like this
because thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>