<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dmitry Ivanov &amp; Nami Nasserazad - Practical Demystification of CRDTs - Curry On | Coder Coacher - Coaching Coders</title><meta content="Dmitry Ivanov &amp; Nami Nasserazad - Practical Demystification of CRDTs - Curry On - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dmitry Ivanov &amp; Nami Nasserazad - Practical Demystification of CRDTs - Curry On</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ShiU9g5JFq8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">ok I think I can start hello everybody
thanks for joining us for this talk in
this talk we are going to talk about the
practical domestication of crdt I'm Nami
is Dimitri and DDA also had a great
contribution to this talk what he
couldn't join the first disclaimer is
that ok we are not hardcore academia
guys or from academia or we are not very
hardcore disparate system guys but we
won't just use some academic achievement
for solving a real world problem yeah
these are this is us so we do everything
and developer in this project in tomtom
it's a full full stack developer doing
from this front end to the back end and
they also handled infrastructure the
project that experience this research is
called naf cloud it's a cloud-based
storage service to allow users to
seamlessly synchro synchronize trip
information between devices as well as a
tomtom website which then you can have
your navigation information like
favorites active rail routes
destinations although all those things
and you can you can have it everywhere
and now the TomTom is a lot of customers
of course and so and a lot of devices in
the market all of them gradually will be
enabled by enough clout so the project
should be the service that we provide
should be scalable and available and
because of the senses because these are
sensitive information especially the
location location based information is
one of the most sensitive information
and we have to be really secure and also
complying to the legal requirement and
also because this is a service and it's
going to be using the third party
application we have to be reactive and
do not degrade their performance these
are the technologies that we use on the
server and clients are cost price color
and we deployed an amazon web services
and also we build different set of
clients libraries to let the clients
integrate with our services this is a
nature of the many second synchronizer
these are the nature's of the many
synchronization systems in the
ubiquitous computing error everything
all the connections are really unstable
so you can be disconnected for most of
the time you traveling in the tunnel you
going somewhere in the forearm we don't
have cover it and you lose your
connection in tomtom case also thompson
provides provides sim cards and some of
the devices it built in sim card and it
paid for that same card so but these sim
card should have very low bandwidth
otherwise it will be really expensive so
your bandwidth also really limited so
the data that transmitted with the
server and clients should be really
packed compacted actually and also use
because you're most of the time offline
user doesn't want to wait until you get
the connection to change the stuff they
want to be able to do things in offline
mode oh and this is the result of this
is to have it changes which are
concurrent and those changes can be in
the conflicting states of course in this
route system there is no guarantee for
the order the user doesn't expect any
data loss and user expects that the data
converge the state that he prob most
probably expects how to deal with this
nature of course you can build a lot of
logic all over the place to handle this
I doubt about that but if you also be
able to do that it's really honor will
be on unmountable code on maintainable
code but as leans toward says said
actually the good developers mainly
solve the problems with the data
structures level because the data
structures abstracts a lot of things
from you and can handle all of those
logics out of the box that's the reason
that we went to use we decided to use
see our duties as I said crd T's is the
data structures a data type it has its
own algebra and it's meant to be
distributed so it each serenity instance
can have a lot of replicas all over the
place and all of those can be out of
sync
at some time and even in the conflicting
States but crdt knows how to solve the
conflicts and they all will convert will
be kind of will converge to am correct
state how sad it is does this the main
ingredients of doing this is actually a
merge function merge function is a
binary operation between to see our
duties using another crdt which it must
be competitive associative an idempotent
and i assume that these are clear
characteristics and why does this matter
because apparently these characteristics
is a good match the distributed
corrected systems characteristics for
examining the service systems orders
order is not guaranteed and of course
you can receive events in a different
order but the good thing is that if you
merge if you reduce they receive
something from the client and you're
just merging in your node at what every
client or server you have a local at
stake you receive something from the
network and you just merge if your merge
function is commutative and associative
it doesn't matter in which order you
receive those those events because
marriage function is commutative and
associative and even in also in a
distribute system you receive events
more than once because imagine I send
you something you send me back
acknowledge the acknowledge it will be
lost and then I have to again send to
you so you receive to us but if the
merge function is item but important it
doesn't matter it doesn't harm I just
again merge it and in practice see how
it is not for just servers and nodes in
the cluster stuff which actually gives
the user a very good experience because
if you have co-ed everywhere in the
distributed systems then you can do
local changes and local trees that means
that user doesn't need to wait until it
gets connection so it can do or flying
changes always that you want and theor
if you will promise him that everything
will be converted is the correct state
example is that imagine if you want to
count a number of the Heat's on your
website so it is these counters always
growing do you counter is one of the
latest data structure that actually is
always grown count
one way to solve this imagine that your
website is really successful and you
cannot count number of the heat on
single machine and you need to
distribute Italy count the number of
hits on your websites what you can do
you can have a Fiat of machines and each
machine count separately and edge for
example this one counts till now five
times other 16 times and at some time
sometimes they are starting gossiping
with each other and then just add all
the value together and receive reach
some value so imagine that the three
machines that we have one count 6 15 14
I can sum up all of them four or five
six it's going to work no why because
addition is not the crd the compliance
operation addition is not idempotent so
upon the gossiping if I receive your
value twice I will count them to us and
this is wrong so the solution is that
you can define an array of values which
each element is corresponding to each
node and each node only increase the
element corresponding to itself and open
gossiping they just pass these arrays
together and each machine will never
receive value from other machines is
just picks the maximum of the
corresponding elements so for example in
this case there is ABC so our area will
have three elements ABC and each of them
they increased a one be increased be one
and upon God sitting for example C will
receive the value of your current value
from the B and a and it just picks the
maximum of the corresponding elements so
the result in this case for example will
be a 63 and c 9 and the total value will
be some of them this one we work why
because unlike at maximum ease crt-d
compliant because maximum is idempotent
associative and committed another
example is G set G said is always
growing said you just put you get the
element and you just put it inside the
your set in this way again this first
solution comes to the mind is that ok
you have a different machines and
whatever you receive you just update
your local set and open gossiping you
pass this set together and each machine
whenever received sets from others they
just Union them is it going to work
actually yes because unlike add union is
crdt compliant you
is associative idempotent and
competitive so 4G set is even easier you
just have a yoga local said you just add
it to that and upon some intervals you
just merge them together so and these
are this is the reason so let's see that
whether this one can solve our problems
in nav cloud the crd T's in enough loud
we are synchronizing different
Navigation informations one of them are
failures you go somewhere you like it
your market as a favorite we also sync
other things like routes like a point of
interest and a lot of other things but
it's this example and afraid each paper
it has different attributes like
longitude latitude name and other things
the naive approach of synchronizing
things because you may go to the parking
and like that parking you want to set as
your favorite but at this moment you
don't have connections so you will you
will send this data a little bit later
to the to the server but user doesn't
want to do that you want just set it and
what finally it should be synchronized
of course there's a naive approach ok I
could try the device try to connect to
the server and if it is successful so
it's just send it to the server and
server using last right wins and if it's
not successful just try again try again
try again until it gets the connection
and of course it's not going to work
because last right wins it has a lot of
situation that you can have concurrent
changes and actually your changes which
happens before reaches server after so
actually the result will that this tale
updates will win and you don't want this
and user really doesn't want that and
you see in various many synchronization
and synchronization system these day
that is actually happens so what let's
try step to see that whether crdt is a
good match or not you already saw this
is slide this is characteristics of the
knife clout and any many synchronization
systems the connection on an unstable
CRT doesn't take doesn't care at all
because it said that I can do local
updates and whenever you have connection
I would just propagate the state and it
will merge I promise you van with is
limited of course
there's a two way of CR dt's there's
operation by sniffing an estate base
acidity in a state-based theory that
these talk mainly is about nose should
sense the entire state every time that
they want to gossip and reach the total
state so this is not very bandwidth
friendly what we did what we extended
the algebra of crdt to add diffs to that
and we only send stiff over wire and
this is really really bandwidth friendly
of course the third bullet about offline
update of course here it is really good
for that concurrent changes co ed says
that it can solve the conflicts order
the merge function is associative and
commutative no data lies your loss of
course we never over rival always merge
and data convergence ok why data will
converge us everywhere that's the
question so i h-hear emerge there
emerged a why they are going to converge
the same value because we use the same
merge function everywhere we use the
same merge function in client and server
and even in database so as an example we
use react as our back-end database as a
datastore t value data stories that
masterless react is masterless key value
data store inspired by amazon dynamo
article so uh what react does whenever
you write you to react react attach a
something called vector clock to that
value and whenever it dick you can just
don't think it is a vector clock likes a
tag and whenever you read back that
value you will also read that tag when i
read the value and i read the tag it
meanwhile something happens on the
database the tag will change if i write
back to the database i will write with a
state AG and react in this case doesn't
overwrite the existing value because it
said your tag is stale if you configure
that it keeps both value as something so
called siblings and this is a
responsibility of application that often
read just merge all those siblings can
resolve the conflicts but for us it
doesn't matter we have a lot of CR dt's
saved on the database as siblings and we
just read them merge them
on the client we use the same merge
function on the server we use the same
function merge function so we know that
these merge because of also the arc
commutative associative an idempotent
they all will converge so that's really
simple it's just two line of codes for
us and no no not not that much logic
this is a yeah this is yeah so this is
some little bit of introduction and the
theory and now the image is going to
explain exactly how we implemented these
things oh thanks dummy so yeah exactly
let's try not to implement this here the
key set that will meet our needs so what
our needs actually so we want to have a
replicated collection of favorites that
will allow us to add elements to the
collection on different replicas to
remove elements and have a more or less
efficient way to to mutate elements in
that collection and as namie said
already a footprint of the collection
the the data that we are going to send
over the wire we expect it to be
reasonable because we have network
bandwidth limitations so we started
looking at the crdt research papers and
different options that we have to
implement a collection so the first one
we looked at was a two-phase set so it's
it's a set that does support addition
and removal operations and it can be
modeled as basically just 2 G set to
grow only sets in one you store added
elements in another one you put the
elements that you want to remove so it
always grows and the removed elements in
that case they also can be called Tom
stones let's have a look at the example
so we have two replicas they both store
2g sets each with some elements so if
for example you want to remove an
element exactly you you you take for
example a cation on be node and then
just move it to remove set right so how
do you merge this data structure
together so what you need to do you need
to nurse to G sets to add sets together
and to remove sets together and we
already learned that G set actually is
mirja ball right
it has a merge operation it's just a
simple Union so that will be the result
the result of the merge and how do we
calculate the lookup of that collection
so what is stored there what are the
elements we need to find all the
elements in the ad G set that are not in
remove set steadily simple here is some
calls how you do that exactly look up at
set diff remove set that's it and then
from ursa just the Union it didn't work
for us for two main reasons so one is
that if you have removed an element in
two-phase set it's gone forever you
cannot riad it back that's the first
thing and the second thing is that
elements are very immutable so one may
argue that of course you can model your
modification operation as simple just
removing current value than adding a new
one but if you if you do really
alphabeat frequently for example then
your remove set the set of Tom stones
will inflate really fast and that is
going to bite you am I going to buy tea
we will have a look at that bit later so
we started looking at the other option
so there is a last right lass straight
wins element set so you can think like
what straight wins hmm we are we thought
that we said that it's not really it's
going to name the approach so let's have
a look how it works actually so um it
actually works in a way that to each
element to raise an additional metadata
which is added is a timestamp so it can
be modeled again as 2g sets 14 headed
phone for removed elements each element
now has is a pair of a timestamp and
value and in that case it does support
three adding of the elements and how you
do that you just need to add an element
with the debt value but with a higher
textin so let's clarify with an example
we again two replicas each element is
appear as a set of time stamp and value
and how do we merge these data structure
um it's again the same technique we have
2g sets we just need to merge the
counterpart the headset and remove says
that's it and
question is that's the result and then
how do you calculate the lookup so for
to calculate look up actually you have
to find all elements in the ad set that
have a timestamp higher than the
counterparts in the remove set if the
reigning in that case all elements have
one because they're the time stuff of
addition what was higher than the one
that in remove and here is exactly the
same predicate that you can encode will
share code samples later it didn't work
for us still and the main reason is that
the elements are still immutable so you
have to do the same procedure of
removing adding back a new updated value
so there is another variation which is
called or set it stands for observed
removed set so or set solves the problem
a bit differently so it actually adds
additional metadata which is a tack
unique tag associated with each element
again it can be modeled as 2g sets for
difference and for removals and it also
does support the adding of elements so
if you have a value that is stored with
the particular tag and removed set the
only thing you need to do is to add that
value back to the ad set with a
different unique timestamp here is an
example so each element is again a pair
this case in this case it's a unique tag
like our example C and cat and then so
how do we merge to two replicas together
again exactly the same techniques we
have 2g sets their mobile we just take a
union of them what will be the the
lookup in that case so in order to
calculate the lookup we need to find
elements in the ad set that have a tag
which does not appear in the remove set
and at that case again all elements have
one because um all values have at least
one a unique tag that is not in removes
yeah and here is a code sample for that
again the merc's is exactly the same as
previous set just emerged
enough to f-22 g6 so doesn't work for us
still same problem immutable elements um
so exactly the same procedure for for
retaking element so now we started
thinking like can we do can we tweaked a
bit the existing solutions to meet our
needs so can we extend the this year the
existing services at with this updated
functionality so we came up with this
observe updated remove set or insured
our set so pun is intended and actually
this set stores additional metadata per
each element so it has a unique
identifier same way we have with unique
tag associated with each element and
unique identifier is is an identity of
an animal and element so it's an
immutable a date identity which is which
is there forever and there is a value
associated with the element as well
which is mutable how do you imitate it
to the value if you want to change your
value you need to preserve ID you need
to update timestamp and update the value
that's it so another trick that we did
was that instead of using G sets for
example we use just one single
underlying set that stores both remove
the non remove two elements it's just a
simple optimization and in that case we
have a sort of discriminator field
remove flag so if it's set to true then
an element um is is removed one right
and if you want to remove an element you
just need to update it that that flag
you need to increase tank stamp and
you're done and of course this this
underlying set can contain only a single
element for the particular ad IDs should
be unique so here's an example to
clarify that we we have two replicas so
each element in these replicas is
actually a consists of four fills so ID
then time-stamped and the value that we
want to store it can be more complex one
than just the string this is just an
example then an optional a discriminator
remove flag so how do you merge them
together so in order to merge these two
our sets you need to take a union of
them
then um take a union of all elements
then you need to group them by unique ID
and then each of this subgroup you need
to find a winner how do you find a
winner well you have a time stamp so you
can pick a winner by time stand for
example in that case we identify it to
the winning elements and how do you do
look up in that case so for look up you
need to take the elements which don't
which have removed slack set to false
pretty simple right and here's some code
exactly the taking union of elements
grouping them by ID taking my good mugs
by timestamp that's it so okay so we
have this model of our set so let's
apply that to to our use case to to have
a replicated collection of my places so
we have that additional metadata that
has to be added to our domain specific
object which has feels like name
location and etc we had this metadata
which is ID timestamp and remove slack
and we wrap it into sort of element
state object that case favorite state
the one might argue ok so you mentioned
that we do much bye-bye attempt stem so
what happens if we have exactly the same
time stamp for four values yeah that's
that's a good question so so actually
comparing time stamps is not enough so
you have to compare the the whole
element structure so what do we do so
first of course you compare vitran stem
if you have a tie you check the remove
flag and in that case you have different
bias you can have an advice or remove
bias depending on your actual use case
and then you have to compare the rest
attributes it's important that the the
compare function is deterministic so you
cannot just pick a random value ok you
think that x times are the same adjust I
don't care right no it has to be
deterministic and that's important also
because merge depends on that for
example what you can also do you don't
want to compare all the seals in the
value one by one you can just take a
half of the value for example and then
there's just compare two hashes in
lexicographical order in terms of
determine
it's fine so okay now we have these nice
and shiny as let me explain the
structure where we have Co DT is
everywhere and different layers in our
SDK client-server even a database layer
and the model basically is like in all
the layers you you operated with this
merge function when you receive let's
say update from from other layers and
then if you want to send something you
just need to calculate a different than
that it's pretty unified model to think
of and to reason about and also to
program for example yeah if you if your
server node for example receiving there
is an update from a client replica what
is it mean to do it needs to check to
get the local replica from database
layer it needs to merge it with the
client and then store it back and then
if the database layer has a conflict
exactly it's not me explain we will also
just so good separately so no layers the
kind of the flow algorithm is the same
so no you can think like okay it's
solves all the problems so is there any
trick well the trees kind of always have
strict right so let's talk a little bit
about it like downsize or at least the
considerations that you have to take
into account so I think the most common
question that we being asked about is
when people hear about co duties and
we're using them in production they
select so what did we garbage so let me
clarify sociology is set um tends to
grow because of Tom stones the these
deleted elements marked in the set right
and it actually it's kind of you can be
unbounded growth and we already had we
heard a nice talked yesterday about
building stateful distributed services
that unbounded data structures like a
killers of distributed services and
that's that's that's complete true so
what are the options um so one thing
that you can consider is like yeah well
of course you need to prove the deleted
element right so the question is when so
intuitively you can think so so I can
get rid of this tombstone if I'm sure
that all the replicas that hold
the disability set actually I have
observed that Tom stall if it's not the
case if you have a partitioned client
for a long time and you meanwhile remove
the tombstone then it goes back online
it will it will resurrect that Tom stone
and you're back in the same situation
that's pretty bad one thing that you can
kind of consider is using some sort of
time to leave for Tom stone role where
you basically put a sort of address hold
on the lifespan of the Tom stone and
saying like after some time I want to
get rid of it it's it's it's a
reasonable approach but it is also a
tricky one you have to apply this rule
independently on all the replicas
otherwise you will have the exactly the
resurrection case again yeah and it's
it's it's a bit not that flexible so
another canonical way to get rid of a
garbage in is to use a bit upgraded
versions of theology set which are
replicas where CEO duties that's what
what what what researchers suggesting
integrity fields we don't use that
because it's sort of a trade-off in your
system in your api's if you want to
introduce the replica awareness you are
in you are sort of kind of making your
your API harder to work with so if there
is always a trade-off so another way to
mitigate the impact of growing sets on
your your own functioning of your system
is to use this s nami explain so we
extended the algebra of your duties with
d 4 / a shin and yeah probably you can
think like if the client creates an
update couple of elements in its own
local replica it can easily calculate
the diff based on the last value it has
seen from a server and then push just
this team it works pretty well we see
that client has modified two elements
then it said it to the server the
question is that what server has to
respond in that case so imagine that on
the server mean meanwhile one element
has changed and if heather has a is
winning against the one of the elements
that client has sent
so in that case we need to notify the
client that's actually the one of the
element have it has changed in the
meanwhile so we can merge it an update
its local state so server doesn't know
about the clients state of clients
replica because we don't have a client
awareness replica wellness so the
solution might be to just respond with
the fully merge set from the server back
but in reality actually most of the
elements that that server will respond
way back client already have seen them
so another way to optimize that is to
use we call it scoped if so when the
client sends a bunch of elements the
server will respond only with those
values that have one over the elements
that client has sent so actually in that
case the client will receive only one
element that has been updated in the
meanwhile and the only thing it needs to
do is to just merge this local replica
it doesn't care if all updates has
succeeded then a booby and an empty set
the same logic for the client okay so
let's talk a little bit about time so or
I would say the problem with time so
well people say there is no such thing
as a reliable time yeah yeah of course
you it can be reasonably reliable but
it's a known problem in distributed
systems so I like this code by owners
banare actually um he was arguing in one
of his presentation that yeah when you
track the time actually you are
interested in in a causality between
events the how you can order events in
your system you you're less interested
in most cases in the actual time value
and this is true so causality in
ordering of prevention is important so
when we are when we have a lessee
concurrent updates to to a single
element these are events that we want to
order want to pick a winner that's
basically we want to order them
sometimes time can be just good enough
so what is good enough so I like to
think about it like in two cases the
simplest case of course when we need to
order updates to single element within a
single node like the know that merges
updates to its local replica so in that
case timesten for us is low is is just a
logical clock which basically the only
thing we expect from it is to grow
monotonically so if you sequentially
update apply to updates to a single
element within the
a local replica set you just expect that
the water will be the same user expects
that so one is it monotonicity is
important and we know that yeah if you
use naive approach if you use I don't
know I'm gvm system.currenttimemillis
you know that it can go backwards it's
not reliable at all so you in order to
ensure the monotonicity at least what
you can do is to employ the the platform
strategy that we use this is a quote
from our Java SDK so what we do we
taking max so we get the time stamp from
whatever reliable and unreliable time
resources it and then we compare it with
the just lost my t4 modify the previous
last modified value plus 1 to ensure the
ordering ok so and what about the the
more complicated case so we need to
order updates to the single element on
different notes happening on different
tones concurrently that's a much
stickier problem to be honest yeah so of
course some of our clients we work with
navigation devices some of them have GPS
GPS clock does provide in certain
conditions a reliable pretty reliable
clock in that case we are fortunate but
what do we do with other clients mobile
clients and etc at least what we try to
do is to prefer server time over local
time providers and reliable time
provider studies and that case so you
can do server time and then calculate
elapsed time since the last moment when
we fetch the local server time and you
get a pretty reasonable reasonable time
stamp value I must warn you still yeah
there might be edge cases if you have
multiple clients modifying exactly the
same element concurrently without any
reliable tank look there might be armed
serve behavior that why they be done
expect it to the user in short time
frame especially but it's about
understanding did these edge cases and
thinking whether they are acceptable for
user experience and in your domain so
all we already seen that picture where
we have
this unified merch model everywhere we
merge and if awesome is there a problem
with that so one merge to rule them all
right there is a trick you have to be
careful with the merge behavior and with
compare behavior will really talked a
bit about it when we talk about time
stamps type so merge and deep operation
have to meet the same output given the
same input so the Rita it has to be
deterministic and it has to be the same
on all our your clients on all the
replicas so what if it's not the case
then if you have a divergence you might
have endless synchronization loops and
that's not fun at all if your client
just constantly thinks that something is
not seeing that tries to push all over
all over again you can kind of mitigate
that prevented that false declined but
still it's it's important thing to pay
attention to when you are implemented
client especially in this kind of system
so a little bit about takeaways so
what's the point um we kind of wanted to
demonstrate that academia is not a
chemist or at least it's not that scary
sometimes as it might seem to like
pragmatic deaths from industry yeah of
course there is a steep learning curve
in some stuff and ensure duties as well
if you for example go to the Wikipedia
page to read what is your duty the first
sentence that you read actually is that
crdt is a bounded join semi lattice okay
now I got it come on yeah it's so easy
right so yeah of course there is this
steep learning curve and we have to we
have to collaborate with each other the
research the industry we have to bridge
the gap we have to make things more
approachable because we argue that there
are lots of solutions distinct solutions
like Co DT that make implementing these
kind of systems and meet your
requirements easier than reinventing a
wheel but you have to have a rationale
to use these kind of solutions you have
to be sort of like sometimes even
salesperson when you talk to your
industry fellow
leagues so what's why should you
consider using CDT why should you
consider using three models for example
yeah it has to be a business value in
that and we will also struggles with
that at some point because people think
that it's too complex in some sense yes
but we argue that it solves problems oh
is it solves a problem and you do
understand limitations and you kind of
agree with them then it brings good
results and of course it's always about
like monitoring how it's actually
performing in your real case and
constant tuning and improving things so
there is a code available and get help
with some samples that we already shown
and some other ones doing the our set
implementation it's actually pretty
pretty small like matter of hundred
lines of code something like that
scallions your job parse they're there
they're completely the same with the
amount of features implemented yeah we
also put some some some links and useful
like presentations and papers that we
found and love really interesting just
if you if you want to know more just
just feel free to check them out there
is a lot of going on in crdt space
nowadays it's kind of becoming a hype
that's true but we still need to bridge
that gap and make it a little bit more
approachable because there is still this
this difference between the awesome
resources that happening and actually
the understanding how you can apply that
in real system industry systems so given
that um yeah the slice already available
on speaker deck so any questions thank
you thank
given how scary it can be if the
implementation of the merge functions do
diverge how do you actually guarantee
like what level are your confidence that
the implementation is actually correct
and how do you guarantee that so don't
answer yeah okay so um so yeah that's
that's the important part so we have as
namie mentioned we have a number of
education reference clients
implementations so we have sort of a
bunch of standard reference tests that
we have to write to to verify the emerge
behavior and compare behavior which we
basically just replicate two different
platforms the another thing that we did
lately is that to minimize the diverge
we we we kind of started migrating to a
single C++ based implementation of of
the core and then just using that in
different mobile clients like Android
iOS and others of course we also expose
REST API of our server so if you like a
first party developer wants to want to
integrate with nap cloud you will have
to implement a merge correct yeah so we
we will prevent the faulty clients to
impact the the stability of our servers
we have rate limiting and this kind of
stuff but of course you have to
implement yourself these reference test
that verify that and yeah we have
rigorous testing in different stuff like
end to end tests that's verify the
correct convergence in the situation
when you when your device becomes so
flying we have of course also the
integration tests and unit tests the
spec for merge and compare is not that
big actually reasonably small I would
say but yeah I have to implement that on
different platforms if you don't share
the same common core
you actually get up page I already
created an issue the first issue that's
22 to leverage scala check for that
because yeah we don't use property based
based based testing in our code base yet
but yeah it's really appealing use case
for that absolutely I had a question I
was wondering if you could clarify what
you meant by by choosing the server
clock over the client like are you
rewriting the the time stamp as it comes
in to the server from the client and if
so doesn't that potentially introduce
false concurrency if for instance do you
have clocks gear or could exacerbate
false concurrency so yeah you mean
rewrite in the sense yeah exactly so we
prefer if we can't get that server types
that we will prefer to get it if we
don't have for example GPS reliable
clock yet that sounds yeah so um yeah
that's that's that's the sense that um
there is this edge case yeah with what
do you mean by a false concurrency first
of all so to just to clarify okey um
oh okay um why isn't the Bison is is it
this is an issue basically like if you
like if you run again the merge function
they're the reason I'm we're just asking
is because in react we observed that
with extremely large sets that reading
reading the object into memory and
performing the merge in writing the
merge back if is unnecessary because
because the object is actually
equivalent is extremely expensive and so
sometimes you can optimize that case by
storing a vector clock outside of the
crdt yeah that's that's that's true arm
so yeah it's a vector clock exactly so
for example you can you can also prevent
unnecessary reading from database in
that case if you have a vector clock if
you sort of compare that it's the same
yeah that's true actually when we were
starting with that system we were basing
on we were all so you're only using the
vector clocks so the first pieces of ApS
were implemented with vector clocks that
were basically like attached as a
metadata to the synchronization
synchronized bleh entities and then we
were just passing them over and then
exactly we could detect that if Victor
clock hasn't changed and you don't have
to do anything um it's it's it's true
that you have these unnecessary loop
always yes so we kind of we kind of
ignore Victor clock now in that in that
sense at least at least we will always
go to the database we get this here this
is set we get it back when when it might
be is not important yeah it's I would
say it says if you're looking to
mutation that case yeah
a very quick question was the precision
of time stamps insisted i am nah no time
stamp or just like a second base times
exactly so you can you can increase if
you need arm but then you will have a
stronger requirements for for your
clients for example client integrates
with our SDK or is the K asks to to
provide a time provider for example in
that case the client will be responsible
for providing a time provider with nano
time precision um sometimes it's not
possible
questionnaire okay okay with this day
thing would you consider it is a
state-based crdt or an open issue based
the rdt yeah
but arguably your son adjust the update
so you could all right
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>