<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Manu Sridharan - Moving Fast with High Reliability Program Analysis at Uber | Coder Coacher - Coaching Coders</title><meta content="Manu Sridharan - Moving Fast with High Reliability Program Analysis at Uber - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Manu Sridharan - Moving Fast with High Reliability Program Analysis at Uber</b></h2><h5 class="post__date">2017-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/D26qNN06r4Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Manu Sri Vernon I'm going to talk to
you about some exciting work we're doing
around program analysis at Hoover so let
me start at the highest level so what is
uber and actually I don't think I even
really understood how much code
particularly in the mobile applications
was present until I started so uber is
multiple apps we have a rider app this
is probably the app you're most familiar
with for booking a ride to go somewhere
and then we have a separate app the
driver app where drivers can you know
see who's requesting rides and get
navigation directions and then there's
more and more apps that are coming like
uber eats for ordering food and there's
there's more planned for the future and
beyond the number of apps here we have
separate apps on both iOS and Android so
you can see how this is adding up to a
lot of mobile application code so what's
interesting about mobile application
development particularly on uber well
one thing that I found very interesting
is that uber cares a lot about
reliability and you know so everyone
should care about reliability uber
really cares because it's business
critical right so if the Ryder app is
crashing then someone's potentially
stuck right and they can't get home
maybe they end up using some other
competitors app if the driver app is
crashing a driver you know can't earn
right directly infects their their
income another interesting point is that
using uber apps almost always involves a
payment right so when the the customers
actual money is involved there's
potentially you know a higher
expectation that things work correctly
and then there's a big customer service
burden when things aren't working
correctly and finally at least by modern
standards apps can take a significant
time to patch right so if you've got
some problem and server-side code once
you diagnose it you can switch over
users to the new code you know basically
instantly but with an app when you have
app review processes and you have delays
in people actually installing the new
app it can be you know on the order of
weeks or even for months you can still
see Crashers from old versions of the
app in your logs so very important the
the mobile app code is reliable and in
fact this is the mission statement for
uber and you can see that reliability is
a big part even of the mission statement
of uber it's it's a big deal so at the
same time
uber needs to move fast so we're
constantly developing new features in
these apps for you know new new
functionality and also different parts
of the world need different features so
we have hundreds of developers working
on the mobile application simultaneously
this leads to on the order of hundreds
of commits per day and I did measure and
we do have millions of lines of code for
our mobile apps and one of the explicit
goals and uber engineering is to let
builders build right so whatever tooling
we develop we don't want it to get in
the way of developers mostly being able
to get done what they need to get done
and also it's an explicit goal when you
have this many developers you really
want them to be able to work
independently and not be constantly
stepping on each other's toes so this is
to me kind of the key interesting
question and trying to bring more
program analysis to Oberer right is how
can you burr both move fast and keep
reliability high right and I don't think
I have the answer yet but one thing that
I think is exciting that we've been
exploring is this idea of modularity
both in design of the apps and in the
analyses we design and how can these
interact right so I'm going to describe
how some of the app design principles
that are already in effect at uber
emphasize modularity again so that
developers can work on their features
independently and that they can also you
know then that helps them to move fast
by not stepping on each other's toes I
think there's a lot of potential for
program analysis to both enforce the
modularity in these designs and also
leverage it right so if you've got
independent modules hopefully we can do
analyses of these modules independently
scale better and also get more precise
results basically by avoiding pollution
and
analysis results from completely
unrelated code and one other cool thing
is that in working with a lot of the the
core platform engineers there's a very
strong willingness of uber moving
forward to adjust the design of these
apps in order to aid analysis if it's
going to really help reliability
performance or something else that we
care about which I find you know very
exciting a lot of my background in
program analysis basically the idea was
you've got this huge codebase and
analyze it but that's it whatever crazy
stuff it's doing you make your analysis
do a good job with it and so the ability
to sort of influence the code as it's
being written to make analysis easier to
me is just very refreshing and very
exciting so in the rest of this talk I'm
going to briefly cover a few topics
first I'm going to give a little bit
more detail on this idea of designing
for modularity and analyze ability then
I'm going to go through a case study of
null distinguished analysis that was
already being used in uber and which
we've managed to improve significantly
in recent months and then I'm going to
talk briefly in a fairly sketchy manner
about future projects and open problems
that I think are interesting so let's
start with designing for analyze ability
and here as a key example we're going to
look and focus in on the writer app so
in 2016
uber completely rebuilt its writer apps
from scratch right and Apps is plural
because we've got pretty separate code
bases for iOS and Android
so this is a pretty ambitious task and
it was success and one of the key
reasons was because of some new
architectural designs that some of the
core platform engineers put into use for
these apps and the key goals of these
designs included high availability of
core flows and I'm going to talk in more
detail in a couple slides but core flows
are sort of the most important features
of the app we want people to work on
sort of less important features but not
have that work compromised the core
functionality and also maximal
decoupling of features so people can
work in two
pendant Li and I'm going to argue that
these goals will also help in the future
static analyses that we build so one of
aspects of this architecture is a
plug-in architecture which I think we're
all familiar with it's it's it's not a
new concept but it's quite cool how they
actually pulled it off in this app so
plugins a key a key functionality to
provide is that they isolate the core
flows from other features so here a core
flow and the writer app would be
actually booking and getting a ride but
an encore feature would be something
like changing your account settings like
your mailing address right that's not
something that's absolutely crucial we
would say compared to the core flow of
booking rides so plugins enable us to
separate these things and because of
that they they do risk feature
experimentation so any code that's
inside a plug-in we can actually disable
with a flag from our server if it's
causing problems so in the field we're
seeing a lot of crashes we can turn off
a plug-in as needed and if we look at
the app actually a lot of stuff that you
see here is implemented via plugins so
we've got this feed at the bottom with
extra information location shortcuts
this button which takes you to scheduled
rides this button for features all of
these are plugins which with the flip of
a server-side flag can be disabled
individually so under the hood we have
this notion of core code and optional
code and the core code defines where the
plug-in points are and these are
essentially arbitrary plug-in types but
it's all done via Java scenarios you
might be familiar with other plug-in
systems that use XML files and
reflection to write plugins and
thankfully from an analysis perspective
none of that is there here so any change
to the core code gets additional review
from a set of the people who designed
sort of the core application and to
double check that you know this is
critical code that can't be turned off
right so it needs additional review and
then there are linting rules that is
sure even at Build time
that the only way core code can
reference the non core code is via this
plug-in system and one interesting is
that so 80% of the code and the rider
app is actually sitting in plugins which
i think is quite a success you could
have imagined that you know this design
wasn't flexible enough and everything
starts leaking into the core but it
seems that that didn't happen and there
are automated UI tests where essentially
all the plugins did disabled and on
every commit these UI tests ensure that
the core flow still work okay so that's
one cool aspect of the architecture
another one that I found quite
interesting was this notion of deep
scope hierarchies and this is dealing
with a very tricky problem in mobile
applications which is trying to scope
the application State and manage
lifetimes of this state so it's clear in
a mobile app that some of your state
needs to be shared between different
features so maybe the most obvious
example for the uber app is the map
right a lot of different features need
to know about the map in the location
but there's also other things like the
user account information once you're
actually logged in a lot of different
features are going to have to know
different information from your account
like you know payment methods and such
things now key question is where do you
keep this state and this kind of goes
back to the to the keynote in some sense
that you know global state is the bad
solution to this problem right for any
number of reasons I probably don't need
to tell this audience about this but
data races subtle dependencies creep in
between features this is a bad idea
another crucial aspect of this for
mobile applications is that we really
need to manage the lifetime of the state
very carefully to avoid leaks so a lot
of mobile apps you kind of open them use
them for a bit and then you hop right
out but if you think about our driver
app for example that might be just the
only app open for hours right and so if
we're leaking state it's going to be
constantly be crashing without a memory
Eric's exceptions which is a really bad
experience for drivers right so more
specifically say after you take a trip
for the driver app you really want to
guarantee that all the state and objects
associated with that trip
are discarded which can mean different
things on different platforms like on
Android it means they're garbage
collected maybe on iOS it means that you
know everything is freed and in the hold
writer app there were a lot of different
conventions around this trying to null
out pointers or in some cases you try to
reuse objects by writing these reset
methods to unset the state but it was
all quite fragile and there were just a
lot of leaks so in the new app they've
added this notion of deep scope
hierarchies which are kind of like
region based memory management that's
how I like to think of it let me
illustrate it with an example so you
have these scopes which are dynamic
notions in your app so you start out
with a root scope and really try our
best to have very little state stored in
this root scope because this is
essentially global State but then you
introduce new scope as your app
transitions into different phases so
initially you might have this child
scope which is logged out right so this
will have all the state necessary to
enter in your account information and
password to log in and then once you're
logged in a new scope is introduced for
this logged in state and then the logged
out scope
kind of disappears hopefully with all
the state and objects corresponding to
being logged out so similarly now that
you're logged in unite enter a state a
request scope all the state needed to
make a ride request and then once you
make that request and you get in the car
you're on the trip and hopefully all
this request state can just be cleaned
up and goes away so they have strong
conventions around this this is the
scope tree so we have parents which
create and destroy child scopes and
state must be explicitly shared from
parent to child you can see it in the
code base that you have to pass this
down explicitly and you're actually
statically prohibited from accessing any
state from your siblings so again this
helps to keep features independent here
and object lifetimes if this was all
done directly is tied to the Scopes so
once you kind of release the scope all
the corresponding states should be
released also which helps a lot with
preventing leaks this is all based on a
new mobile application framework called
the ribbed framework that was defined at
Hoover and we've talked about some
publicly details aren't super important
at for the purposes of this talk other
that you can think of it as a refinement
of model-view-controller with specific
types of objects for managing the shade
state sharing and and tree structure so
what are the implementations of all this
design for program analysis
well the decoupling is really great for
helping developers move fast right as I
said before with these scope trees and
plugins features it's very easy to keep
features independent right and this is
actually a challenge with the amount of
app state that needs to be shared you
have well-defined contracts right like
between features via this tree you know
exactly what state is getting passed in
what you're passing to your children and
also between the core and optional code
via these plug-in points so this helps
developers stay sane and not constantly
get blocked by code that's irrelevant to
them I would argue that there's a
potential for this to be really good for
analysis also for static analysis in
particular so one thing is that just
because the app is designed this way I
think that whole program analysis will
see some benefits just because there are
various kinds of data flows that are
already explicitly prohibited and so the
app that when you do a whole program
analysis hopefully you'll get less
pollution from imprecise data flow but
another really cool thing we could hope
to do is more modular verification so
you can try to verify some strong
properties of the core code and if you
know that plugins only behave in a
certain way you don't have to analyze
those plugins and similarly of these
individual features if you know how
they're interacting with other features
via these deep scopes again you can try
to do some modular verification and this
of course is going to require
specifications at all these boundaries
okay
which I think it's an open question how
to get them I would hope we can infer a
lot of them but there's going to require
some digging for each individual
analysis I think this is really quite a
big opportunity because we've got a huge
code base here you know as AB you know
you can't scale whole program analyses
and actually get the performance that
you want to need that you're going to
need but leveraging the app design I
think could really lead to huge
performance and precision
improvements okay so now let me switch
gears kind of to talk a little bit about
the novice checking that's done in our
Android app which does sort of take into
account that some of the higher-level
principles I talked about before in
terms of try to do things modularly and
scalable so I've identified some of the
principles for bug checkers that seem to
work well in the mobile application
development so far so one is we really
want to block the build okay so if
you're checker is reporting errors you
shouldn't be able to merge your code
back to master we want to keep master
green and what's the reason for this
people are trying to move fast they're
focused on their features if you print
out a bunch of warnings and say take a
look at these these might be you know a
problem they're going to say this is
just noise I'm not looking at this I
just got to get my code committed right
so we really want this to block the bill
but this means precision is critical
false positives are just going to you
know cause a lot of problems we also
want to run checks as early as possible
so we have a fairly standard development
pipeline which I'm not going to get into
detail but basically you develop locally
and then when you have a change it goes
through a code review and we run lots of
tests in our continuous integration
system and then eventually before you
merge back your code there might be even
more tests run so you can think of these
as stages in a pipeline and we'd really
like to run our checkers as early as
possible we'd like to aim even for
instant feedback in the IDE so
performance is really critical and
finally and again this is in contrast to
some of my previous program analysis
experience annotations are okay if we
can only incur a modest annotation
burden and we can really make the
analysis work better the development
teams are very open to sort of requiring
annotations if the properties we're
trying to prove are very important so
this leads into how we do Nell pointer
checking in our Android app which is
sort of a type based approach which I'll
illustrate briefly with an example so
let's say we have this logging function
that's just taking an object and
printing out its string representation
but here we're calling it with null so
in our type barista
you're first going to get an error here
because we assume that any parameter or
return type or field is not null unless
it's explicitly annotated otherwise so
here you get an error you can't pass
null to this parameter because it's
supposed to be not null
you can try to fix this by adding this
nullable annotation here but now you'll
get another error saying hey your D
referencing something nullable so that's
going to cause potentially a null
pointer exception and finally you can
fix this by adding a null check which
the type checker is smart enough to
reason about and says okay now this code
is fine and this is done in a few
previous tools such as eradicate which
is a part of Facebook's infer tool but
also previously in the checker framework
and I think even going back to tools
like es see Java so what's our
experience been with doing this kind of
checking so this was deployed
aggressively in 2016
using the eradicate tool across Ebers
Android codebase and it had a huge
effect just a huge reduction in null
pointer crashes in the field when they
when they did this now there was a very
significant initial annotation effort
because we had to add nullable
annotations for everything that could
legitimately be null and they did it
I wasn't around for that I kind of feel
bad for them but they pushed it through
they saw it was worth it and they saw a
huge reduction in crashes the downside
here was for how we ran this tool the
eradicate tool the performance was not
quite where we wanted it so we wanted to
keep our master green which meant zero
warnings but with the performance of
this tool we actually couldn't
reasonably run it on developer laptops I
mean they could run it but it would take
on the order of minutes and no one would
so the only time we would enforce these
checks is very late in our CI pipeline
and that's not a great experience for
developers right you have your new code
feature it's gone through code review
almost all the tests of pass and then a
couple hours later you get a null
pointer warning
what kind of breaks there flow if
they've been moving on to something new
so as a solution
recently we re implemented this kind of
check in as a plugin to this tool called
error-prone it's an open source tool
from Google that essentially lets you
write your checkers as plugins to the
Java compiler and this is great for
performance because we can reuse all the
work that the Java compiler has already
done and
of building an ast in terms of type
checking we can just reuse that
precomputed work and as a result now we
can do this kind of checking and give
very quick feedback on local builds so
we've got as I've measured it five to
ten percent overhead it's quite
manageable and now developers every time
they compile they get these kind of null
pointer warnings so people are really
happy with that
and now talked about soundness and I've
got my soundness slide too so how sound
is our checker it's not sound and I
would say it's not even sounding that we
have all there all kinds of constructs
where it's actually well known how to
handle them soundly but we make a
deliberate choice not to because it
increases the annotation burden or
forces you to rewrite certain code
patterns and we haven't seen a
corresponding benefit in terms of
reduction in actual crashes that are
happening in our app right I'd say this
is a good point of contrast would say
the null pointer checking that's
available in a checker framework which
is trying much harder to catch every
little loophole that could lead to a
null pointer exception so I mean I can't
even list all the holes but
multi-threading arrays mutation there's
all kinds of ways our tools unsound what
I do do though is I keep an eye on what
null pointer crashes are actually
happening in production and is it
something that we could easily address
in our tool and a lot of them are
actually deep in the guts of third-party
libraries so there's very little we can
do about that but once in a while what
we could do is improve our modeling of
these library methods so that we would
actually check where our code is calling
into the library that you're not passing
null or null is not in a certain field
and there are some good ideas about
there how to even infer these library
models that we might be looking at in
the future one other interesting
question is you've got these annotations
in your code about null ability but what
about data that's coming in over the
network or from disk and then getting
marshaled into data structures how do
you know that that is well-formed right
you might assume that some field is
always non null in a network response
but you
get invalid data coming in over the
network and then all your assumptions go
out the window if you actually get a
null value there so at over they wrote
this tool called rave which is open
source which actually turns your null
ability annotations into runtime checks
at this border between your code and the
disk and network so at the border where
data is coming in we use rave to make
sure that whatever null ability
annotations were written statically
actually are adherent to at runtime and
we have some extra checks and other code
pads if if you have invalid data so
there's a bunch of goals and challenges
one attempt to make this checker backer
one that I think is pretty fun is around
streams which is used heavily in our
code base I'll talk about more later but
here's a simple code example so let's
say you've got a data class that has a
bunch of data about like age and other
things and then we've got a person who
has a data function but it's possibly
null okay so there may be no don't know
no data associated with that person so
now let's say we have a stream of these
person objects and first we filter such
that we only keep the person objects
with non null data and then we do a map
operation like we're trying to sum all
their ages right just looking at this
code we've filtered out all the person
objects with null data so it's safe but
our type based null checker doesn't know
this right it's going to say here that
you might be dereferencing a null data
object so I think it'd be very
interesting to work on type system
extensions to try to be able to
understand these stream constructs
better understand that filter imposes
additional predicates on the remaining
objects in the stream and to use that to
actually avoid reporting errors here and
this actually shows up a lot in our code
base they might be one of the probably
the biggest source of false positives
with our checker is due to these
streaming constructs so I think it'd be
quite cool to think about type system
and type inference extensions to handle
code like this okay so in the last part
of my talk let me just talk briefly
about some open problems that we're
working on right now and that we'd like
to address in the future so one one
thing I think is is really quite
promising is doing better analysis of
experiment flags and how this affects
your codebase so experiment Flags enable
us to remotely enable and disable
features and I kind of already talked
about this with the plug-in system right
so we can use our experiment flag
infrastructure to disable plugins but
it's also used for things like a be
testing of different features and also
to gradually roll out a new feature to
play it safe right in case it's causing
a problem we don't instantly deploy it
to millions of people and in the code it
looks something as you would expect
right you call into the experiments API
you say if this new feature is enabled
let's run the new feature otherwise
let's run the old one but it can get a
lot more complicated than this right I'm
not going to show it in the slide but
sometimes if this is enabled we source
some state in a field and then in some
other chunk of code you read that field
out and do some actions and it's not
immediately obvious just staring at this
code what impact these flags are having
so one thing I've been working on is a
static analysis to give greater
visibility into how flags effect
different parts of the code so the thing
that immediately came to mind when
seeing this is let's compute a forward
slice to try to see how this flag
affects different code now when you're
dealing with real-world java code things
like the heap cause slicers to not scale
very well i've been using a technique
that we use before for security analysis
we called it hybrid thin slicing to try
to deal with the heat more efficiently
and one thing that I'm just starting to
look in is how can we leverage that
application structure that I showed you
before to do a better job here we've got
these scope hierarchies we know the
siblings can affect each other so
ideally we should be able to cut off
slices that we just know can't cut
across these sibling features so that's
something I'm still thinking about and
trying to work into this analysis in a
clean way and I think once we have it
they're going to be many use cases for
it there's lots of interesting questions
you can answer for example you've got a
crash in the field what's the best flag
to turn off just
this crash from happening it'd be great
to be able to answer that with the
analysis or someone is trying to push a
change into the app and we think it's
kind of risky already we actually
require developers to say what's the
revert plan on this change what flag can
you flip in order to turn this off if it
doesn't go the way you expect but
there's no analysis that's actually
checking that all those changes are
gated by the stated flag so if we could
check that statically on the diffs I
think that could be quite valuable also
and there's a bunch of other
applications of this so I'm pretty
excited about what we could do with this
another aspect of a liability that we're
working on is multi-threading which as
we all know can cause all kinds of nasty
bugs right data races or the classic
example in mobile apps and other thing
that we worry about is that certain
tasks need to be performed on certain
threads or more particularly not on
certain threads right at least on
Android and I think also on iOS if you
try to touch any of the UI data
structures and you're not on the main
thread then your app is going to crash
or worse it's just undefined behavior
and it's going to do something weird way
later on an interesting thing about the
mobile app code and uber is that almost
all the multi-threading is done via this
framework called reactive X it's a
framework for doing functional reactive
programming for asynchronous streams and
it gives you a nice abstraction for
dealing with things like network
requests user clicks that sort of come
in asynchronously and you know you want
to you want to sort of process them as
they come in and specify the operations
in a more kind of declarative manner but
what's interesting is this framework
implies a very structured use of
multi-threading
so here's an example so the streams are
called observables in reactive X so
let's say we have some source values a
source of observables and let's say you
want to do some expensive computation on
these values well you call this function
observe on and you pass it this marker
that says put it on some computation
thread and this means everything after
that is going to happen on a computation
thread right so now we can do this
expensive computation something like a
map operation but now we need to render
the
results to the UI in in order to ensure
that that happens back on the main
thread you add another observe on call
and say okay now let's run the
subsequent operations on the main thread
and then at the end you can display your
results this is essentially how the
multi-threading code works in the apps
there's very little use of explicit
thread creation or executors or anything
like that so I think this is quite an
opportunity for building specialized
analyses that understand on this
reactive paradigm to doing
multi-threading and then can do a really
good job of finding multi-threading
errors so one interesting thing is that
a lot of these operations like these
maps and filters really they're supposed
to be side-effect free so I think if we
could actually show that they're not
side affecting any global state that
takes us a long way towards dealing with
race conditions in the app and then if
we can keep track you can see that you
know even in a tight base matter you
might be able to keep track of the
thread that's associated with one of
these streams if we can track that with
analysis we can get a handle on say
ensuring that when you're displaying a
result that the corresponding stream is
already back on the main thread so I
think there's there's a big opportunity
to really just get a handle on almost
all the multi-threading issues in our
apps by specializing it to this rx
structure so one last thing I'm going to
talk about what's a really big issue for
us is performance both execution speed
and memory so this is a micro map SPARC
it's a phone that's you know quite
popular in India the Micromax is an
Indian brand this is about
I checked recently about $60 to buy one
of these phones so one of the things is
is not very high-end hardware both in
terms of CPU but also in terms of memory
and flash speed but it's really
important for the uber app to be able to
run smoothly on all devices particularly
these low-end devices in markets where
there's a lot of growth like India like
Latin America and here honestly it's
kind of wide open and if anyone here has
answers come talk to me there's a lot of
different things we could try to do we
can try to statically detect if there's
slow code running on the main thread
maybe using things like what I talked
about in the previous slide
try to give visibility into what
network requests have results that are
blocking the UI try to analyze things to
reduce out of memory errors or memory
leaks and try to leverage that app
infrastructure I talked about but here
are the real challenges new features are
going in constantly into the app right
and we really again need to be precise
and scalable in our tooling so I don't
know off the top of my head of analyses
like particularly static analyses that
we can plug right in here to get a huge
win maybe dynamic analysis is a better
approach this is something we're going
to be thinking about a lot though
because it's really important so that
was just a couple examples but there's a
lot more stuff that we're thinking about
analysis of swift on iOS is a huge open
problem for us we're investing a lot on
the app development side in writing
Swift code but we need to build up some
infrastructure for doing static and
dynamic analysis there there's certain
startup code and that is sort of very
critical to the app so if we have a
crash there you might end up in this
crash loop where you can never actually
start the app so I think that might
merit stronger verification to ensure
that we don't end up in those crash
loops lots of code duplication across
our apps it's an interesting question
what can we do about that regression
test selection I think it helped a lot
in terms of speeding up the jobs that we
run in our continuous integration
structure I mean there's just there's
tons of problems to work on and and a
lot of opportunity for impact I think so
this is what what really excites me so
that's all I had in conclusion I think
analysis has a really great chance to
help kind of square the circle at Ober
in terms of achieving hi app reliability
while also enabling developers to move
fast and work independently and the way
that we're going to aim to do this is by
modularity both in the app design and in
the analyses that we develop and have
the to kind of feed off each other in
kind of a kind of a virtuous circle so
thanks there's an uber engineering blog
where you can read about some aspects of
our of our app architecture so if you go
to ng u / comm you can read some more
details about these things and thanks
I'm happy to answer any questions so we
have some time for questions if you'd
like to ask a question I will direct you
to the center mic hello
first of all awesome talk good question
you mentioned that so many devices out
there and it's a problem so how do you
actually measure their performance like
whenever you let's say start a be
testing a new feature do you like
monitor on what devices running how it's
performing and yeah it's a good question
so I mentioned the experiment flag
infrastructure and that gives us the
ability to only deploy certain features
to say certain geographies also so that
can help us keep track of where things
are running in terms of actually
measuring performance we have some
infrastructure based on code
instrumentation in order to selectively
sample and measure these kind of things
but it's a it's a tricky problem because
that doesn't give you complete
visibility into low-level things like
native code sometimes you have apps
freezes which are due to blocking a
thread right so that's not going to show
up as much in execution time so we have
some handle on things like startup time
and how much time individual functions
are taking but I think there's more work
to be done there in terms of getting
really really good information from the
field on on the performance implications
of these different features thank you
hey and I was wondering if you were if
you're going to open source your new
version of eradicate yeah yeah
absolutely it's in the plans so I know
hopefully within the next few months
we'll have some good news
I'm working on it
so I was wondering so you said you have
these quick soundness checks to make the
developers develop quickly but they're
not very soundly even right
yeah specifically with the numbers
checker yeah there are various unsound
aspects of the track right but on the
other hand you said you had this checker
that actually gives very good results
very precise but it's too slow ah so we
were using a checker that was giving
very good results but didn't quite have
the performance that we needed but ah
would it be a possibility I mean you can
have the sound the known sound the
checker for the developers while they're
developing but kind of in the evenings
or in the nights that you run it with it
more complicated check or is this
something you already do that's that's
no that's that's actually it's not
something we do it's a good idea to sort
of have different features enabled in
the checker at different stages of the
of the pipeline and maybe on a nightly
basis do more rigorous checking it's
something that we're thinking about
but isn't deployed yet but I think
definitely something that we're going to
have to do moving forward as we do
deeper analysis which no matter how much
we optimize just doesn't make sense to
run on every single local build so yeah
that's a really good point and it's
something we're looking at so another
question was just completely unrelated
so you you said at the end you had the
performance problems with some of these
low ends smartphones right but your
systems already set up that you can kind
of disable features is that is that a
way of kind of for the user to kind of
scale down his uber application so that
it actually runs perform utley on its
machine yeah that's it's it's a it's a
good idea it gets kind of complicated
for a couple of reasons so firstly
that's a dynamic way to turn off a
feature yeah but one of the issues we
actually have with LowE devices even at
installation time just the size of the
app can be quite big and being able to
dynamically turn off a feature doesn't
turn off the size of the app on disk so
we we need sort of an end-to-end
solution for some of these things and
then I mean there's the general
question of well which features should
be disabled should it be your feature or
my feature right we've got all these
different teams that care a lot about
the features that they're delivering in
the app so but night it may be the user
says I don't care about this feature
yeah that's yeah it's something we
should we should think about more I'm
not sure that inexperienced users will
be able to sort of I mean power users
absolutely they'll love us for it but
I'm not sure that for our broader user
base they'll be able to find the right
settings they'll probably just stop
using our app rather than going through
that trouble so but it's a good point we
should maybe find ways to automatically
disable features that are that are not
performant and not critical Thanks okay
let's thank the speaker again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>