<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Pony: Making it easy to write efficient, concurrent, data race free programs - Curry On | Coder Coacher - Coaching Coders</title><meta content="Pony: Making it easy to write efficient, concurrent, data race free programs - Curry On - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Pony: Making it easy to write efficient, concurrent, data race free programs - Curry On</b></h2><h5 class="post__date">2015-07-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KvLjy8w1G_U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the pony session from my
point of view the pony endeavor started
in 2011 when Sylvan came to Imperial
College said he wanted to do a PhD and
he wanted to develop a programming
language where it would be easy to write
safe programs safe programs they should
be memory safe type safe exception safe
and in particular concurrency should be
correct it should also be possible to
write those programs easily they should
have all the necessary abstractions
object oriented programming functional
programming and most particularly actors
and asynchronous method calls and it
should not be very expensive to run
those programs so we should have all the
necessary features in order to make
those programs run fast so here is my
first reaction these features are
already known Sylvan we have been
dealing with them in the last couple of
decades or so and Sylvan answered no I
believe that if we come if we rethink
them from scratch and if we not only
adapt them but also think how we combine
them we can get to something better and
such a thing would have a horrendous
performance and again sylvans reaction
was if we think about all the
abstraction levels at the same time then
we can improve the performance and if we
use the language features in order to
get the low level to run better then we
can make it run faster again so at this
point my reaction was mmm I don't
believe you I have been I have grown up
with a Cartesian approach to things but
let's see so we started the endeavor we
had great time we have made quite a few
interesting discoveries I think and two
years ago a student Sebastian
blessing joined us and he was totally
convinced and he said we have to start
the company we have to start
implementing it now
and he convinced us and we convinced
some angel in vase angel investors and
we started the company so we started the
company thirteen months ago now we have
got the compiler we have got tools we
have got wonderful results I believe and
we are very excited to have the
opportunity to talk to you about this
and I want to so this concurrency is
hard the altie grantees are dealing long
time but 40 years ago he would kind of
solve this problem now I don't need to
solve it in terms of the Florence but
kinda something in terms of the mental
model we need in order to build software
that mirrors what the hardware actually
does so in a parallel setting actors
units of sequentiality a lovely little
sequential programs to do exactly what
you expect them to do that if you want
to accurate a whole state for everything
sequential that means you want to use a
lot of actors and I don't mean tens of
thousands of active I mean tens of
millions of actors probably churning
over a long run long-lived application
so that this is just another world
Lamoni one of this side of the sandbox
if anybody wants to without a laptop and
experimental Pony code while I'm talking
please
so lots of actors means lots of messages
and lots of messages if they are going
to be fast they have to be zero copy
messages if we're gonna do this like
Erlang and copy everything we're gonna
pay the price that are laying pays and
that's not interesting because Erlang is
already awesome and already does what it
does extremely well so we've got to do
better than that but if we're gonna do
zero copy messaging it's got to also be
safe because we can already do this in
C++ there's a there's a for example two
c++ actress framework was really nice
open source project does this in c++ but
it's not safe so we want both so what
we're using is reference capability so a
lot of people who've worked on reference
capabilities is a big list here Tobias
is even in the back of the audience
right there
anyway so what these are are type
qualifiers now there have been a there's
been a lot of different research on how
to use this so Ted qualifiers like
concentrate only it's a lot more
powerful stuff that you can do with
reference capabilities so our reference
capabilities are based on deny
properties it's all about the existence
of this reference denies other aliases
from existing in your program statically
check the compile time so you know that
you can reason locally about these
things so let's look at the big matrix
the things that we need to deny are
pretty straightforward they're exactly
the things that Phillip Paulo already
talked about in his research we need to
deny read/write aliases right that's a
thing but a different thing is denying
right aliases only and another thing is
what if actually it's okay to allow all
aliases and we need to differentiate
between whether those aliases are held
by the same actor locally or by some
other actor and globally because those
are pretty separate things so the first
thing is that we're not going to deny
things locally that are allowed globally
because that doesn't make a lot of sense
because they could be passed back to the
local actor so we're gonna X those out
those aren't interesting and we're gonna
talk about these so yeah it turns out
we've got mutability immutability and
opaqueness
as separate categories of reference
capabilities so let's start with the the
sort of straightforward ones that we're
all pretty comfortable with if you can
if you can deny global read and
right aliases then it's safe for you to
just mutate the object as if you were
writing Java and had some mutable object
that's what a reference type is a ref in
Pony it has a little bit more
interesting guarantee because in Java
you don't you can't prove that other
people aren't reading from it you can't
prove that they're not mutating it and
here pony makes that guarantee now that
we feel free to ask questions in the
middle of the talk that's all right ball
I'll answer stuff and then we have value
types global immutability things that
you know are are you've denied right
aliases both globally and locally so
there are no right aliases remaining in
the system
that's great immutability global immune
ability then we have box a sort of a
black box type where by denying global
right aliases but allowing all local
aliases you're saying this is locally
immutable I'm not gonna mutate it here
and I know I can read from it because
nobody else no other actor is gonna
write to it but I'm not gonna guarantee
that this actor isn't gonna write to it
that's pretty useful it turns out it's
probably the most used type right it's
things you want to read from and you
don't really care about what's gonna
mutate it then we have a pretty
straightforward type in some ways which
is tagged it's an opaque type these are
things you can either read from nor
write to so why is that useful while
identity obviously object-oriented
programmers it's pretty powerful
to be able to ship that concept of
identity across concurrency across
actors also an actor itself when you
send it an asynchronous message that's
not reading that's not writing so you
can type actors as tag then we have the
the fun ones isolated isolated is read
and write unique this is the only alias
through which you can either read or
write not just the thing itself but
because it forms a bubble all of the
things that it reaches with some
interesting exceptions about being able
to reach immutable things that are
reachable by an isolated thing external
evening this separate uniqueness I
should say then we have transition types
this is kind of fun I thought this was
an artifact of the matrix and I thought
these weren't interesting types it turns
out this is a right unique type which is
kind of fun it means that we know this
is the only right alias but we're not
making any claims about it being the
only read alias which turns out to be
more interesting and powerful than I
fought at first it would be so there we
go we have three kinds of mutability two
kinds of immutability and a kind of a
picnic but we also have send ability so
when you're denying local aliases in the
same way that you're denying global
aliases those are things you can send in
messages to other actors because those
are think things that are making the
identical guarantee locally that they're
making globally when those guarantees
aren't the same communicating them would
be unsafe but here you can't so you can
send tagged things pretty
straightforward it's just an identity
obviously everyone can have that send
immutable things globally immutable
things yeah of course but you can also
send isolated things you can send
mutable state safely across actors
that's fun
so aliasing turns out is a thing here
because what local aliases can exist are
based on the deny properties so for
example let me back up one so for
example local aliases for a transition
type because it's write unique because
of what it denies which is to say local
write and global read and write you can
only have things that obey those deny
properties as aliases so it's okay to
have a tag everything's okay to have a
tag right because that was neither read
nor write so you can have a tag atleast
anything but you can also finally you
can have a box alias to a transition
type so you can locally keep readable
references to this thing that is a write
unique so you can be write unique for a
while and later you can give up some of
those capabilities and become globally
immutable while not caring about the
fact that you had these locally mutable
references hanging around they're still
valid so that's kind of fun and the same
thing goes with globally is is there's
another set of what global aliases can
exist underneath this is pretty
straightforward what it tells you is
that
immutability is for sharing and
isolation is for passing that's good so
cognitive load that's a that's a lot of
stuff I just covered and to say that the
programmer is just gonna happily go and
add these kinds of annotations their
programs everything's gonna be fine is
obviously not strictly speaking true on
the other hands
we've had better luck with this than I
expected
programmers and we're talking about
hobbyist programmers here people who
like hop on the IRC Channel and say I
want to write a package and Pony to do
you know Jason parsing awesome I really
did that a bunch of different packages
actually yeah and generally the pattern
goes like this they get on they say Pony
looks really easy I'm gonna write a
bunch of code this is awesome this is
crap none of this works I don't
understand how to use any of this and
then they ask a few questions and after
maybe a couple of weeks on the outside
for hobbyist programmers they're really
comfortable with it they're not actually
overloaded a lot of this has to do with
using same defaults for types and so
that a lot of the annotation happens to
disappear it mentions in the in about
20% that's in the standard library that
we're using about 20% to be honest in
people's code that they're writing
themselves it's probably less annotation
the standard library is pretty
aggressive about using interesting
annotation so alias in' and inalienable
things that are unique read unique or
read and write unique can't aliases
themselves so we need a concept of being
able to recover capabilities and consume
capabilities because otherwise what are
you gonna do is that isolated thing how
are you gonna send it when you still
have a reference to it so this is pretty
straightforward here's hello world
rewritten pretty pointlessly but still
rewritten to use an isolated string
instead of an immutable string so we
have a recover expression which is
building a mutable string a string ref
but when it returns it recovers
capabilities and what it recovers to I'm
gonna back up just a little bit here it
recovers to the top thing on the matrix
for the type that it is when the
expression terminates so that a ref can
be read and write unique a box can end
up immutable things like that so and
consume does exactly what you'd expect
it to do you kill it out of the lexical
scope out of that name and that means
you've killed off a name which means
you've killed off an alias which means
that now you have the unalienable Eocene
worked especially in the presence of
polymorphism where
least type of parameter annotation gets
to be kind of fun and interesting so
capabilities security in the type system
literature this stuff is often just
referred to as capabilities after
talking a bunch with Mark Miller and a
bunch of other people who have done
capability security research we've
decided to use the term reference
capabilities to try and draw a little
bit as a distinction about what this is
now reference capabilities are a form of
capability security but in Pony we're
also talking about object capabilities
in in the object capabilities systems
research sort of level so reference
capabilities are attached to the path of
an object not to the object right I have
a ref to this and you have a box to that
and that's fine nothing is encoded at
runtime in the object about that that's
all compiled time information but object
capability is about what the object can
do the unforgeable token that represents
access to that object and the methods
you can have on it so Pony combines
these two things to get some really fun
concurrent object capabilities security
and is a capability secure language
which is really fun all right more
things we're gonna do we're gonna void
runtime exception so we want to felix
was saying his talk on rust leverage
these programming language research
features we want a non-null type system
safe constructors right finishing a
constructor without initializing all
your fields that should clearly be a
compile time error that's pretty
straightforward if we have an unknown
type system what do we do about you know
link lists and stuff like that well we
need algebraic data types these Union
types as a form of option type we have
checked exceptions without signature
explosion so if Pony uses partial
functions as opposed to more traditional
throw mechanisms I won't really cover
that today obviously you can still run
out of memory if you want to smash your
stack or allocate out of the heap we're
not solving the halting problem we're
not gonna prove that your program is
safe in all these circumstances but
we're covering a lot of other fun stuff
so now let's get off these fundamentals
and into the some of the things that
make Pony more usable than you might
expect at least I hope than you might
expect
obviously generics when you're dealing
with object-oriented programming I think
punting on generics is an unfortunate
choice oh we didn't do that but that
means that we also need capability
polymorphism
which is kind of fun and this is what I
was mentioning before about annotations
for the unalienable and the alias
version of a type so here's an example
that I left out the implementation but
this is from the standard library the
array is obviously implemented in Pony
and here we're gonna initialize an array
where everything is set to the same
initial value but that value has to be
something that can a Lee Asst as the
thing that we have an array of right
because if I say we have an array of
isolated strings for example and I say
set them all to this same string we have
a problem we have multiple issues it
copies we have multiple references to
the same isolated thing so this says you
can't pass me the thing that I'm an
array of you have to pass me something
that will alias as the thing that I'm an
array of and similarly down below I'm
gonna skip over this because this gets a
little bit more complicated but the fun
on copy to the destination is a is a ref
array something that we can you take
this we're gonna copy into it but it's
not an array of a it's an array of
things the array that we're dealing with
right now how it would see them so for
example if we were calling copy two with
an immutable array it would be how an
immutable type saw its element type
which is the view point adaptation if
you're familiar with that stuff and not
only that it has to be an alias of it
because we're not deleting them from the
existing alright so that gets
interesting too so traits nominal typing
Pony is an object-oriented language for
sure but it's not an inheritance based
language it's a trait based language so
this is based on excellent work that
already exists we do some override alias
we don't do removing methods at this
point you've considered it but we didn't
seem to have a use case for it yet no
state traits don't have state in them
ambient talk for example has traits with
state in it and man that's quite
interesting it may be it's something we
can learn from ambient talk we haven't
done it yet but it's something
interesting we can look at but we also
have structural typing similar to go
interfaces but they're obviously
polymorphic and they give programmers a
nice dynamic feel to what otherwise is a
pretty statically typed
entirely statically typed in a bit
constricting language but when you just
say I only want an object that conforms
to basically this and I don't want to
have declared it in advance and I just
want to interface something like this
that's really nice for the programmer
but that's not why we did it the reason
we did it is that one that I've glossed
over in the middle there variants on
type parameters is hard Java got that
perhaps slightly wrong other languages
have got it perhaps slightly wrong Scala
covered it I think quite perfectly and
in detail with Coe and contravariance
annotations on parameters but to say
that that can be somewhat unwieldy for
the programmer I think is not a
controversial statement and so in Pony
what we use is structural typing for
that you can have a structural type that
says you know what all I need to be able
to do is say read from some sequence it
has to behave like a sequence and I want
this type back and there are lots of
things are gonna behave like that
and when you've limited yourself to that
interface you you maintain soundness so
that's nice so functional features so if
you mentioned that we want those two
well yeah I want those two come on
so type expressions algebraic data types
Union types intersection types
intersection types are really fun and
powerful tuples as well built into the
language not not a form of sugar but
actually built in politic types problem
Orphic methods as well obviously but
also partial application lambdas object
literals not only that but we get some
really nice interesting behavior on
being able to build these things without
runtime overhead so you get lambdas that
don't involve allocation and things like
that unless you and then when you're
capturing scope you can capture with a
single allocation and kind of fun
interesting optimized ways that's really
nice obviously pattern matching on tie
pattern matching on structural quality
all that good stuff on the other hand
there's something a little bit
interesting about pony's pattern
matching in that it may it respects the
object-oriented encapsulation boundary
scholars work on case classes is really
fun and interesting for this and I think
and ISTEP the right record I think I
hope we've done something even more fun
which is you can do this arbitrarily on
objects you don't need case classes you
can you can but you don't automatically
destructor objects they have those
objects
to expose destructured fields yeah yes
exactly that sorry I probably glossed
over that too fast Scott Lee scholars
case classes and extractors are exactly
the inspiration for this stuff
absolutely so but it turns out really my
background is in low-level C hackery not
in type systems and not in programming
language here that's all new to me so I
want to I want to have my cake and eat
it right this is not about building a
language that's safe and has all these
high-level features this is about
building a language that scratches my
personal itch and my personal H is a
background in large-scale financial
systems video games physical simulation
cryptography things like this things
where performance is really the only
metric there is nothing else right it
turns out even in financial systems
robustness takes second place to
performance that's exciting and
interesting so what I want to do here is
make sure that all these high-level
features aren't being used to slow the
language down that we can actually use
them to take shortcuts that these
guarantees let us cheat it means we can
implement a runtime that absolutely
wouldn't work if you didn't have these
guarantees higher up in the language in
fact it would just follow for dead you
would do things that are absurd but we
can get rid of these dynamic checks you
can use actors turtle actors all the way
down and get lots of fun benefits there
let's start with the scheduler obviously
it's works doing scheduler right single
producer multi consumer queues to steal
actors cache aware stuff if an actor has
pending work and you send it a message
it should stay on the scheduler thread
it was on right it's working set is
probably in cache if anywhere on the
thread that it was scheduling previously
on the other hand if it wasn't scheduled
and it gets a message it should get
scheduled on the local thread because
it's working set probably isn't in cache
anywhere it might be but you're taking a
gamble
and the message that you just sent it is
definitely in cache on the thread that
just sent it this tough it turns out
matters a lot the silk guys in Intel put
a lot of work into this kind of stuff
and it's really good work but we need
fast schedule excuse because scheduler
queues are the second worst thing you
can get wrong in our fun time for actors
the worst
obviously message cubes so zero tonic
ops on push with no loops that's good
that's great I'm really happy with that
that's a that's fantastic on the other
hand 128 bit atomic compare-and-swap on
pop is nothing special right that's what
everybody's gonna get out of an
unbounded SPMS EQ fast message queues
right so if you send a message to an
actor that we're gonna do that a lot
right we mentioned lots of actors lots
of messages so we want that to be as
fast as possible here single atomic
operation on pop no loops and here's the
fun one zero atomic operations I mean
sorry it's one complication push zero on
pop no loops on an unbounded queue with
previously empty detection on the
question sorry if this gets a little low
level for people haven't worked on this
stuff yet please interrupt me if it if
you want to know more about it to meet
you view cough who now works at Google
on the go runtime did a bunch of work on
these kinds of cues that's really
interesting and that we've learned a lot
from memory allocation it turns out you
can cheat with memory allocation when
you have these high-level language
guarantees which is super fun we we have
separate heaps for every actor that
means every actor can go and allocate
without ever dealing with any kind of
coordination of any kind so not just no
synchronization but no coordination at
all so we have an amortized a lot cost
of CTD count trailing zeros which is
good that's fast on a cache line aware
allocator yeah no we don't you mean
segmented stacks or Sigma 3 Sigma sis
down yes indeed we do yeah
so those heaps are their individual
heaps but and they can grow arbitrarily
large so we're going to get into the
garbage collector in a little bit and
talk about how we take care of that
because that's a very important point
yeah extraordinarily important point
yeah so cache line aware allocation
right we all need to be doing that but
we get to again we have all these
high-level language guarantees we know a
lot more about what that cache layout
and I'm talking about mostly about cache
lines here in terms of data layout we
know a lot more about what that's gonna
look like than you might otherwise know
so we allocate on the local Numa Numa
Numa node awareness is really important
on modern system so you don't get many
servers these days that are at least two
notes at but actors migrate
so we allocate on the local Numa node
and then we Regas get rescheduled on
some other schedule a thread that had no
work and now we're running on a
different new node so we tried migrating
all our pages um i if anyone's tried
that you know as well as we do at this
point but that's a horrible idea that's
about the biggest performance lose we
ran into trying to do this stuff leave
it alone it turns out is the only
strategy we've run into if anyone knows
better please talk to me afterwards but
right now it looks like the OS handles
this better than we can in user land so
garbage collection this is Doug Lee and
did a interesting talk and mention some
of the things that he's run into with
garbage collection yeah blocking jitter
times things like that these things are
problematic
so in ponying when we GC we have a fully
concurrent garbage collection in the
sense that we don't even have GC threads
actors collect themselves only we have
no stop the world no Ribery errs no
right berries no synchronization no save
points no stack Maps
none of this stuff and actors are
collected as well which is really nice
and it turns out it's actually sound a
bonus so doing data race free GC is
where we get most sure actors help
hugely because we're talking about
collecting individual actor heaps but
there are also problems with that that
we'll get to in a second but data race
free GC is where we get a huge win
because we're not dealing with data race
possible data races at the language
level we can take all kinds of shortcuts
at the runtime level so here's where we
get into some issues a per actor GC is
is great right we collect our own heat
but cross actor GC we were talking about
zero copy messaging before so we've sent
punctures across actors that were
allocated on different actor he's so now
we have a problem now we can't just
start collecting those things and in
actor GC actors form cycles right we're
gonna collect those actors figuring out
how to do that is non-trivial so per
actor GC pretty straightforward it
happens between behaviors although I'm
gonna full disclosure I was talking with
cliff click earlier and this might not
be a great strategy honestly it works
really well
the stuff we've done so far but we may
want to also do collection during a
behavior full disclosure
anyway but we can do this stuff without
looking at the state of any other actor
and even when we do it during the
behavior that's going to hold none of
these things change it's just gonna add
some interesting stuff on stack maps and
things like that so you know stop the
world step all that stuff and maybe we
should do you see during behaviors what
is that doing I have no idea here we go
right so across actor GC this is where
we start getting really tricky on the GC
side so deferred distributed weighted
reference counting is a lot of
adjectives on reference counting
basically what this means is we're using
the actor model in the runtime to handle
reference counting not based on the
shape of the heap right because I don't
care if this object has a reference to
this object or if I'm you take the heap
and drop references addresses all those
things that slow reference counting down
in that sense we're just gonna ignore it
we don't care about that
we only care about messages we only care
that I've sent an object that I
allocated and then we need to do
interesting things to keep track of when
that has been sent on so causal
messaging I haven't messed its causal
messaging yeah I shoulda mentioned it
earlier so the runtime is built on
guaranteeing causal messaging so if a
sends a message to B and subsequent to
that a sends a message to C and in
response to that second message C sends
a message to a we want to guarantee that
a receives message one and then message
three this is a really strong guarantee
other forms of the actor model make
guarantees that are as weak as no
ordering at all this one is a very
strong guarantee now on a single node
this is so cheap it's free it turns out
we can't actually implement a faster
message passing system without causal
messaging fantastic in the distributed
context which by the way is still
vaporware with Pony but I'll cover it a
little bit at the end this is not free
this involves some interesting hackery
not only that it might be wrong full
disclosure right there's an interesting
concept called EE order that comes out
of Mark Miller's research on his
language Eve it might be more useful
here I'm not sure yet anyway the point
here is that because it's all based on
messages
and we have causal messaging if if an
actor receives a message that doesn't
own and excuse me he seems an object
that it doesn't own that means it wasn't
al-qaida on its even it wants to send it
on it might need to manufacture
references and send and say to the
original owner you need to up that
reference count by another couple of
thousand just in case I need to send
this more later when you have causal
messaging you can do that without an
acknowledgment cycle that's really nice
so you just pop that message on the
queue single atomic operation and you
send the message on no delay no
coordination and no object cycle
detection because we're not keeping
track of whether objects have ret sent
references the other objects only
weather actors have references to object
so there's no cycle detector required
here that's good
but actor garbage collection we want to
be able to garbage collect actors
because manually managing actor lifetime
is unfortunate right we we've all done
it before and in other actor model
languages and they're much like
collecting regular old object garbage
it's a lot nicer to know that you're
never ever gonna send a message to a
stale reference on an actor that's good
and also poison pilling actors and all
the things that we do it's problematic
and especially problematic when we start
talking about the tens of millions of
actors type scenarios that I'm talking
about so we want to collect them but
they have to decide die when they cannot
possibly receive a message in the future
all right ok so that's complicated and
it requires cycle detection not only
that but because the actors view of its
topology and the cycle detectors view of
the topology are both almost certainly
out of sync with the real sort of
derived topology that you would put
together if you could stop the world and
figure everything out we have a problem
in making sure all this works so this
was our oops the paper a couple of years
ago it's not as bad as it sounds it
turns out a cycle detector actor isn't
that much of a bottleneck because it's
kind of like a GC thread you can you can
tell it to not worry about it and things
and defer and slit and run run in the
background so that's not that bad and
more importantly the the protocol to
determine that these things were in some
known isolated cycle at the time
the cycle detector was informed about
them isn't that bad turns out when you
collect it when you sorry when the cycle
detector detects an isolated cycle of
actors all it has to do is send them all
a confirmation message with it just a
token in it that says this is just an ID
number and all those actors do is echo
it back that's it
they don't examine their state they
don't know anything cuz we don't want to
examine state on an actor that might be
collected because then you're examining
stuff that shouldn't really be in your
working set that's a problem we don't
want to ever look at stuff that is
internal working set but when it echoes
it back each time the cycle detector
gets that acknowledgment message back
for a given blocked actor if it hasn't
received an unblocked message from that
actor it turns out that means we can
prove that that actors view of its own
topology was correct at the time that it
sent it and therefore also at the time
that the cycle detector received it so
if we get back these acknowledgement
messages without an unblocked message
for everything in the isolated cycle of
actors we can prove that the topology
was correct when the entire cycle
blocked and now we know that we can
collect these things that's pretty fun
admittedly this is a round-trip a
message roundtrip every actor in the
isolated cycle but our message queues
are fast so it's not that bad we're
talking about two atomic operations per
actor in the cycle which in terms of G
seeing an actor that's pretty good
so other things that we want to do for
speed yeah so the was the act of GC do
you foresee any potential issues when
you start distributing these things you
bet absolutely and the main one is going
to be that you're going to want to run
these cycle detectors in a hierarchical
manner in a distributed system obviously
if you've run a single cycle detector
for an entire to distribute the system
what you're gonna have is the node that
you're running the cycle detector on is
going to fail and then you're never
gonna collect anything ever again so
yeah you have to run these in a
hierarchical manner and to say that
that's straightforward is a big fat lie
but it's not as bad as you'd think
because it turns out a little just
digression into the distributed side but
it turns out you only ever need to
forward a cycle to a parent higher cycle
detector if you would
examine the cycle and discovered that
there's missing incoming references
everything's blocked but there's missing
incoming references and you can prove
that those missing incoming references
come from somewhere above you in the
hierarchy instead of below you so very
rarely have to forward that cycle on to
a parent cycle detector which is nice so
fast dispatch I mentioned structural
types before and if oh yeah please
can messages contain references do
actors I'm sorry can sit again can
messages contain references to actor
absolutely yeah so it's an arbitrary
soup of the actor graph is an arbitrary
soup and can change and change
dynamically yeah absolutely
so right structural types of I mention
structural types before if there's if
there's anyone who's programmed in and
go you'll know that sometimes you have
to build a V table on on the fly for an
interface and that's problematic I'm not
familiar with how structural type
dispatch and Scala works but I think
it's a little bit complicated yeah that
was good nod so it turns out we're
taking advantage of a paper that yan
Vitek may or may not remember having
written 20 years ago about selector
coloring it turns out there's this
rather brilliant algorithm in there for
being able to do the equivalent of
register allocation on your method names
and when you can have an ahead of time
compiled language like we do that has
all of these static guarantees that we
have we can cheat and so we can build a
single V table where that works for both
structural and nominal dispatch and it's
always a single array index that's
pretty fun now obviously it is a form of
a colouring algorithm you can get into
pathological cases where you end up with
a V table that's just too big
that's not solved how often we run into
it so far never but theoretically the
problem is there right so that may be
something we need to revisit we're not
sure so this holds even when you're
calling a method not just on something
that's a structural type or nominal type
but also on a union type or an
intersection type it's the exact same
dispatch it's always single array index
and
thing that checks the type at runtime
it's just an array index and go which is
nice so obviously we use LLVM for
cogeneration I suspect a lot of people
here have hacked out on LVM if you
haven't find a project to go do it
because it's wicked fun we use it for
all kinds of things but probably the
thing that's most exciting to us is that
it means that we're capable of handling
interesting future architectures yeah
thank you we can handle interesting
future architectures that's pretty
awesome there's all kinds of
heterogeneous architectures that LVM is
going to be supporting that make for
really interesting high-performance
computing platforms so some benchmarks
otherwise known as snake-oil we tried so
hard to find benchmarks that they were
somehow useful people I hope these are a
little bit useful to you we didn't write
our own because that's really
problematic we use them from the C++
active framework which we really really
like it's a it's a great open source
project so the three that we're gonna
show here one is for a message queue
convention the other is a combination of
message passing and CPU load the other
one is for actor overhead how fast can
you create a lot of actors so mailbox
performance so this is a single mailbox
being bombarded by a hundred million
messages from a whole bunch of actors
I'm sorry I can't remember how many
actors are sending the messages but I
think it's I don't know a hundred
thousand something like that and this is
the mailbox contention this is all
relative to Erlang on a single core all
these speeds so we do pretty well this
is good we're not only faster than
Erlang for dispatch on one core but
we're actually maintaining a nice
mailbox performance even in a really
heavily contended system this is this is
a 32 core machine and we're running all
the way up to 64 hyper threads
originally we thought we weren't going
to bother testing with hyper threads
because it's going to kill us but it
turns out all right so the black ones
pony on the top there Erlang is a little
bit hard to see it's that slow pea green
one we have the C++ actor framework
which is a little bit unfortunate down
at the bottom blue there's charm plus
plus which is a which is a very
interesting supercomputing framework
they gets a lot of use it's not the most
modern thing in the world but it is well
used and well known and robust system it
doesn't do that well and I'm sorry felt
that Scala doesn't do these that well on
this either so this is a message ring
and factorization this is a whole bunch
of message load that serves no purpose
whatsoever followed up by a whole bunch
of large integer factorization that
serves no purpose whatsoever and the
idea is just to keep make sure you keep
the CPU loaded while at the same time
you're sending messages and banging on
the message giving system and we get
some interesting profiles here too
that's pretty fun stuff we're doing
pretty well on that you'll see that our
jitter all comes out at when we're up in
hyper threading our jitter appears to be
worse than other people and I don't know
why yet so that's interesting
also caveat you'll see that we don't
have as many results for Scala we ran
out of benchmarking time so we tried to
get some representative core counts
everything else it's specific it's every
single core count all the way through we
don't have that for Scala so you might
see some interesting behavior in between
there but I'm afraid I'm sorry about
that
so creating actors I like this one
because we didn't win and it's really
nice when you're showing off snake-oil
to make sure that not everything is a
big win here we're creating a million
actors and seeing how fast we can in an
in a tree that are and they're all
you're doing the big creation and then
they're all echoing messages back to the
route so you can't do anything except
wait for this entire tree to resolve
which based on the fact that we do cycle
detection our own actors is pretty much
our worst case this is this is it this
is the worst possible case for pony
creating it a gigantic tree of actors
normally you're gonna have a graph
that's much more susceptible to
collection than this so the C++ actor
framework does brilliantly here it's
unfortunately it's not a
garbage-collected language neither
object collection or actor collection
but they do get great performance
results here that's really good fun
stuff pony does pretty well we do well
at first and but we left aloud a lot
sooner on the other hand this is doing
cycle detection on those actors that's
pretty good I think
oh right enough snake-oil this slide
came out yesterday India let's talk and
I buy it I really do
unfortunately I'm not gonna claim that
pony is a live environment it's not it's
about the most dead programming
environment you can think of you're
talking about a text editor and a
compiler we don't even have a repple I
mean come on
this is dead so we're trying to do our
best to give you tools that make that
still useful so let's see what we've got
so far
one thing is fast compile times now
right now in an optimized build 90% of
your time is spent in the LLVM optimizer
people have used a VM are probably
familiar with that being the case but
that's pretty good it means that our
overall compile times are seem to be I
won't make thanks to many claims it
seems to be faster than C on average
obviously still slower than gogo is the
king of compile times I would love to be
as fast as them but on the other hand
they're only doing single pass
optimization and we're doing a whole
program optimization so there's a bit of
a difference there right so see a bi
compatibility when you don't have your
own ecosystem and you want to do systems
level stuff you better be able to talk
to the C avi directly and in pony's case
that means you can also compile an
entire Pony program and with the C ABI
and have the compiler generate a header
file so you can call it from C as well
as the other way around that's fun all
this other stuff editors direct
integration with the debuggers you
already know how to use that's good
stuff
community we've got a community probably
the only thing that I really find fun
about this slide is that somebody
already ported it to FreeBSD for us come
on that's awesome
there's a 32-bit x86 port that's being
done right now
this is 64-bit x86 only that's so x64 on
the other hand this 32-bit port seems
like it's gonna work which I'm frankly
surprised but it does look like it's
gonna work and someone's working on a
64-bit arm port once we have those we
should be able to do a 32-bit arm so
there's all kinds of fun stuff that
we'll be able to do future backpressure
remember all those unordered chews I was
talking I'm sorry I ordered unbounded
queues that I was talking about right
well that means back pressure happens it
has to happen at the language level so
that's interesting capability secure
mirror based reflection we want to do a
repple I'm gonna tie primers on without
primaries on values that's going to
mostly prefer performance reasons on big
matrices distributed runtime
you're talking about without that I will
bore them silly but it's vaporware right
now there's a lot of fun stuff and more
formalization so please if anyone's
interested get involved it's all open
source we have a we have mailing list
and github issues and an IRC Channel
sometimes we even answer mail on the
mailing list sometimes but the IRC
channel and github issues those those
really work that's good stuff
so please get involved so um what did we
learn from this what cheating is good
that's what we learned from this right
using the actor paradigm for the runtime
is fantastic using all these language
level guarantees to optimize the runtime
is fantastic and starting from
principles and using formal models
actually improved our implementation
drastically yeah okay we closed
soundness problems that's important too
but it actually made the runtime faster
and that's fun right thanks everybody
yeah so what's the origin of the name so
first of all for Americans a pony is a
race horse so it has a connotation of
the Pony Express and going fast but
actually that's not that's not why the
name is there the name is there because
of the typical conversation you have
with people I want this feature and I
want this feature and I want this
feature and I want a pony so there you
go I have one comment and one question
yeah so my comment is that when you
benchmark all these systems yeah it
seems to me that there are some of these
systems like Erlang and others they also
akka is distributed right from the go so
yes so I think you probably pay some
price there because the whole runtime
system has to be yeah I great tribute it
so yeah the only thing if we want to
keep really keen to talk about ponies
strategies for the distributed run time
with you if you have time at some point
the nice part is is the distributive
runtime won't change single node
performance at all so I don't feel that
uncomfortable with these horrible lying
benchmarks but you're obviously right
okay if you already know that it's
sometimes we have to first do it and
then you ya know how much you have to
change later right but we already know
that that nothing changes on the single
node runtime so that's good it's just a
prototype don't don't get too excited
okay so my actual question was you
because you said well you have C
interrupts yes so how do you do this
like on the type level with all the
different
oh yeah it's gigantic trust boundary
right when we talk about capability
security because right here we have a
capability secure language and we're
gonna say you can have a c FF i so what
guarantees can we offer you we can
guarantee you that you're gonna crash
the hell out of your program that's what
we can guarantee you so we treat this in
a different way so instead of saying
we're gonna try and like isolate Erlang
can isolate C in another process and all
these fantastic things for a bus Ness
instead we treat it as the trust
boundary you don't trust it because you
can trust it you trust it because you
have
- trust you'll have any other choice so
the pony compiler has this notion of
safe packages safe packages are the
packages that are allowed to run CF Fi
which is why we can have that the
sandbox if any one let's look at it and
let you compile a native code and run it
on our server we're not worried about it
because only trusted packages can use
the CF Fi so you establish here your
capabilities trust boundary like that
does that answer your question so I sort
of follow okay ok fall to that what's
your stack representation for your app
for Phi then what's our stack
representation yeah how do you deal with
that or just I don't know you said no
segmented stacks but I don't know what
you're using instead of segmented stacks
what we're not we're actually using a
see a bi stacks so we're we're not chain
we're not using we're using essentially
LVM fast call internally and we switch
to the the c representation when we call
it everything but each actor doesn't
have its own stack right each actor has
its own stack but it only has this back
when it's executing a behavior so
actually only each scheduler thread has
its own stack okay yeah so on you know
if you're running third is your
scheduler threads you have 32 stacks and
never more all right thanks everybody
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>