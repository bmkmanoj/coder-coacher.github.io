<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning BeautifulSoup and Python Requests in ONE VIDEO | Coder Coacher - Coaching Coders</title><meta content="Learning BeautifulSoup and Python Requests in ONE VIDEO - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Chris-Hawkes/">Chris Hawkes</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning BeautifulSoup and Python Requests in ONE VIDEO</b></h2><h5 class="post__date">2016-07-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2VxPNFejpfk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey guys what's up so in this video
we're gonna be looking at beautiful soup
and I've also done another video for
Python requests but we're gonna be using
kind of both of them so if you wanted to
check out learning Python requests in
one video essentially though just a
disclaimer this is a new type of
tutorial series that I'm kind of doing
here and it's not even really a tutorial
series in the sense that I'm not gonna
make one video to install on one video
to name a variable on one video to read
a webpage I think that approach is you
know rather sometimes and and
you know what there's tons of tutorials
that do a great job doing that and I
don't really wish to replicate that to
be honest so I'm just doing what I do
and I'm just a quick background is that
I am a senior programmer I typically
deal with c-sharp and JavaScript but
I've been a Python developer since
approximately oh nine so I am piped
Python for me is a project hobby type of
thing I've never done Python in a
production capacity like with large
development teams and things like that
so there are certain things that I'm
sure I do with Python that is not like a
Python it way but that's okay I mean I I
think I come you know I bring enough
experience from c-sharp and other you
know large enterprise development
platforms that I think that I can make
up for but essentially I don't have any
familiarity with beautifulsoup I haven't
used it in literally four years yeah
about four years probably maybe a little
bit less I don't remember but the point
is I haven't used in a long time so this
is just gonna be kind of you know a
programmers point of view of of working
through the library so all that said
let's go ahead and jump into this um I
have my C directory with my projects
folder and inside this projects folder
I'm going to put learning learning
beautiful soup and Python
all right so here's this learning
beautifulsoup and python request I'm
going to go into the folder and with
Windows I can type CMD and it's going to
pull up a command prompt here so we're
gonna do our virtual environment a
virtual environment is so that we can
isolate our I mean to do that a
virtual environment EMV is the name of
the environment and I'm going to do with
no site packages so what this is gonna
do is isolate our Python environment I
talked about this at nauseam seriously
with all the other videos that I do but
if you don't know what virtual
environment is you really should start
using it it's one of those things that
when I was first getting started that I
was labeled why the eff am I gonna do
that why am I gonna make my life more
difficult by using this tool but really
you're making your life more difficult
by not using it but newbies out there
they're gonna avoid it and they're not
gonna use it in a rocket and and it's
been dividing them but you do whatever
you want you know whether you want to
install this in a virtual environment or
if you just want to install it all
globally meaning without a virtual
environment it's up to you but now that
we have the environment set up here we
can go ahead and CD into it and then I'm
going to take a look at the scripts
directory so it's C into that of my dumb
assets belly right and then we're gonna
say activate and if you're on a linux
environment you should say source
activate but if you're in your virtual
environment if everything went well
you'll see in parentheses the env or
whatever you chose to name your virtual
environment so now that we have that
here I can go ahead and say pip install
hell I don't even know how to install
beautifulsoup so what does it say here
umm so it says pip install beautifulsoup
for so hopefully this works current
release all right so I mean I'm assuming
we want the current release it looks
like that website by the way was created
in like 1995 pip install beautifulsoup
for alright so it looks like everything
went well and now we're also going to
need to install a Python request so
we're gonna say pip install request make
sure you have the extra s on the
requests and this puts them both into
our virtual environment
I'm going to close the solution you need
some sort of a text editor in order to
run your project and for me I'm gonna go
ahead and put my project I'm gonna use
Visual Studio you guys don't have to use
Visual Studio but this allows me to run
my projects a little bit easier so if I
say browse I can set up a new Python
project by selecting this folder will
call this learning it's a long ass name
but whatever so if I say next it'll auto
detect the virtual environment so that's
what's nice about this is that like on
over here on my environment if I look
inside my environment you can see that
it has both requests and beautifulsoup
because we installed both of them I know
that's a little bit hard to see on the
solution Explorer over there on the
right hand side but yeah that's pretty
much all I can do with that right now I
can't make that any bigger but the
source code when you guys see me type
I'll make it a little bit bigger alright
so um next thing we need to go ahead and
see if we can run an example here I just
want to see if if this thing's even
running here so let's take a look
so 4.4 appears to be there I said I want
to do this what I want to do instead of
actually using all this garbage I want
to actually number one let's go ahead
and see if we can import beautifulsoup
that's that's the first thing you all
want to always do whenever you're
dealing with a new project so let's
create a Python file over here so I'm
going to add a new Python file and once
again you get you guys do not have to
use Visual Studio you can use whatever
you like to use for working with Python
so we're gonna say from ps4 import
beautifulsoup and also since I'm using
Visual Studio I need to set the start as
the start file because there's no start
you know there's no void menu like main
function like there isn't C or C++ or
Java or C sharp
so if I run this now this is going to
use our Python so there was no error
that means everything was installed fine
so that's good so now let's go ahead and
import request and we're gonna go ahead
and request all right so we're gonna go
ahead and use request and we'll say HTML
equals WordPress and we're gonna go to a
website that I own I'm doing HTTPS
because I don't want a redirect to occur
because I have it set up so that it
always redirects if you go to repress
the page without HTTPS it'll redirect
you to the HTTPS version alright so now
that we have the source code let's go
ahead and just print HTML and make sure
that we're getting a 200 because that's
this gets returned as a request class
and by printing HTML it'll actually give
us the HTTP status code of like 200
there it goes 200 I only make this a
little bit bigger 200 or like 500 server
error 404 is page not found you guys
know what I'm talking about if you've
ever done HTTP work if I wanted to get
the actual text I could say that but
this is actually going to throw a you
know we need to encode so there's some
sort of encoding I don't remember the
the syntax of it and once again this is
not a scripted tutorial this is the raw
and uncut version because this is just
what I do and this is what every
programmer does by the way they don't
know what the hell they're doing they
just figure it out um so here is a HTML
and we're gonna replace this to HTML
we're gonna send by using this iso
standard in fact i'll show you guys here
before we even do this so I'm just doing
a comment here and I'm gonna say encode
utf-8 now by default request should be
encoding the utf-8 automatically but
there's a bug or something occurs where
it doesn't do that with my website
because of weird characters but here you
can see the
damn right it looks like because
it's all over it's all mashed but if I
go ahead and I say encode it to this iso
standard and get rid of this encoding
and just punch the text then you can see
that the you know the presentation of it
is much prettier so you see how it's
much much prettier the why of that I
don't know it's based on this standard
just that you guys if you're interested
you can look that up but I'm not
interested enough to this stuff what I'm
doing right now to look that up all
right let's continue down this path here
so we want to go ahead and um now that
we have the HTML let's go ahead and make
this soup thing so let's say HTML parser
since that's what we're dealing with
so I can go ahead and paste this right
here you know I want to do it though
after my encoding so that way I can say
HTML and this will be this ISO standard
and a more HTML friendly type stuff all
right so now that we've done that we can
close this browser so now if I look down
here we can just go ahead and print
super a5 if we want to try that let's go
ahead and see I'm not sure that that's
gonna do too much let's take a look I
haven't used to beautifulsoup it so long
but prettify is supposed to like okay so
it says HTM a type of smart okay so the
reason why is because HTML guys is a if
we said you know let me go ahead and
comment this out another good thing is I
can just press that and comment it out
but if you want to say I could let me
just show you guys I want to show you
the why or some of this stuff so if I
print the type of HTML to see okay what
is it returning because obviously this
is expecting an HTML string and it got
something else so let's uh let's take a
look here I need to restart this so if I
press play and I look into this you can
see that I get this class requests
models response if you watch my my
Python requests learning it in 30
minutes video you know that that is the
type that is being returned by
Python requests so if I wanted to
actually get this to work right let's
all right so I'm gonna uncomment this
there's none in commenters all right so
I'm gonna uncomment that and then I want
to do dot text that way I get stage
string that it's looking for okay now
I'm getting ready to cuss okay character
map and Cody so it's running into this
this encoding error so you know
all right yeah little bastard all right
so we're just gonna do this the hard way
right now there might be a better way
but I'm just gonna go ahead and code
this thing - yep - yeah babe right now
let's just comment that out let's see if
we can get this work in here my website
has something screwy there with the
characters okay so it's still got a
 coding error all right so I
guess what I'm getting confused at with
beautiful supers I thought okay you're
gonna take whatever the encoding is but
what it's doing is it's doing its own
encoding so basically we could do this
until we're blue in the face and it's
not gonna matter we really need to
encode this part here so if we said in
code yeah eight by the way some people
capitalized to utf-8 I'm not sure that
it really matters let's go ahead and try
this here because obviously it's
ignoring whatever sort of encoding we
got going on before that and it's just
looking at the straight characters all
right so now this works and this is
supposedly prettified it's kind of ugly
you can see it has newline characters
and stuff like that but the reason why
this is pretty is because if we went to
like print something like this or to
write it to another file let's go and do
that real quick we'll save our file
oh wait longer than an oh my god what
I'm doing is I'm adding a text file here
we're gonna write you know just say I
think it's close I don't remember and
Python you shouldn't have to explicitly
closer I don't think anyway wow I did it
wrong
I said says that there is no directory
so obviously I printed a directory wrong
learning beautiful soup and pie paradise
okay says the right arguments must be
string and not bytes okay let's try to
stop the encoding since we may not have
to encode it like that since sorry

god dammit alright so now I'm just kind
of guessing so if I just think in cast
this entire thing to a friggin string
why don't you write why don't you work
just work man just work all right it
seems to work there all right that seems
rather hawkish but whatever so here's
our test file and this is supposedly
prettified it looks it looks terrible
looks absolutely terrible but let's move
on because this is garbage instead of
all this let's go to No we'll get rid of
that now let's go ahead and we want to
keep all this out file stuff though
because this is we're gonna be writing
things out to test to kind of see what
we're able to find but let's go ahead
and do something like prints I'll follow
right soup will say title so this should
print the title of the page which is
something like hipster code home I
believe
must be a string and not attack okay so
if I wanted to get the actual string
then I guess I need to say name soup
that title that name nothing's alright
that's gonna return the title tag of a
bank which seems pretty obvious yeah so
returns title just say hey the name of
the Titanic is title but that's not very
useful so if I wanted to actually get
the value and I have to say string which
is rather weird actually I haven't used
beautiful soup and so long you would
think it would say text or innerhtml or
something
so here hipster code home so there we go
alright let's go ahead and on let's get
all the anchors on the page so if I
wanted to get all the A's then we could
say for link and soup dot finds all
passing a and this is gonna go through
the list we could say instead of we're
gonna go ahead and define our out file
and what we're gonna do here
so that'll create the new up file for
every time you run it and then now we
want to go ahead and say out file you
know I could just end up you know for
right now we're not to worry about
writing it out but let's go to just
print the link first just to see what we
can find so we'll say link type string
maybe one of these string day let's just
print the whole anchor tag if we can
then first we'll just print link first
let's finally
so this is gonna reach out it's gonna
actually so prints off all the actual
links within the page so you know it's a
lot of this stuff is like oh man that's
got it aids that have all these like
content ripped out so like what if we
just wanted all the 888 rocks then what
we can do is we can say link yeah and
then we can pass in a truck so this will
only return actual links to other pages
instead of all the links which is a
little bit more helpful if you're gonna
build like a scraper that's gonna grab
all the links on a page and start
following this is how you would you
would start here now one of the things
you're gonna notice though is that most
websites have relative spaces so it's
relative to where they are within the
application so they're not fully drawn
out HTML pages like here this obviously
goes to Twitter but all these other ones
these were will go to hipster code comm
and the website doesn't have to
explicitly state HDTV blah blah blah
hipster code on so the question is like
how do you work away your way around
that it's gonna be difficult because
then you also have things like this page
top this page top is a link that doesn't
really go anywhere so you have to build
a scraper then that's smart enough to
know it okay this page appears to be
within this website this page is
definitely an external website cuz it's
got the HTTP or HTTPS listed in it and
all this stuff so yeah that's that's
some of the challenges that you get into
whenever you start like doing scraping
and stuff like that all right so this is
no good a different example we're gonna
go ahead and we're gonna look at a
Wikipedia page just as a simple example
of something a little bit so if this has
a little bit more data that we can
actually grab so here's this band base
art from Queens they're actually like
going back to like the earliest stuff
like it was really good like some of
their later stuff is not as good as
their newer stuff I mean but they're
newer stuff whenever more punkish man I
love that
but anyway so like here's some of this
information so if I was gonna go ahead
and like look at some of this stuff we
need them to then find something by like
ID like say I needed to get their origin
and like here it is right so it's just
TV or TR you can't what I go about this
I mean first I would go my phone is
 killing me oh my god I don't
know how many times my phone has been
heard and these videos and last full of
days it's ridiculous but here is um so
here's this table there's still no ID so
I'm looking for something okay well so
basically maybe the origin so we could
say you know what th right so we know th
with the value origin C one of the
things that I think that um the
beautiful super falls short on is that
it doesn't support XPath so without
XPath life becomes so much more
difficult you end up resorting to like
regular expressions which are just a
terrible thing they get the job done but
just terrible to work with in many cases
some people really like them but that's
because they're twisted and evil people
I used to like them but I don't anymore
so we're gonna import our U which is
short for regular expression because
what you can do is you can say soup in
fact we'll just say tag equals soup and
got fine and then we could say tax
equals R u dot compile and we just pass
in a regular expression so we're going
to look for origin
let's go ahead and see if tag actually
comes back with anything I'll go ahead
and press a place a breakpoint here so
if I look at tag tag is a nun says no so
couldn't find anything there that's not
cool
there's a version capitalized yeah it is
capitalized
oh Jesus Christ I'm a dumbass you guys
should have told me why didn't I change
the url to the right page you guys can't
give me like that man it's embarrassing
all right let's try this again I want to
see if it even finds it this is very
it's a very fragile way of finding
something but here you can see that the
tag was actually found which is cool um
you may want to give it a little bit
more control though what we can do is we
can say you know what find me the TD I
think it's a TD right and we look at
this I know it's actually a th so what
we want to say is when I say find me the
th with the text I match this origin
okay so let's hopefully see if we get
the same result I didn't place a
breakpoint but you can see that it finds
the entire thing a th ro origin okay so
that's pretty good alright so now that
we've done that let's go ahead and look
at this page so we know that when we're
here we need to go up because TD is ths
brother there it's not a child or
anything like that so we need to go up
to its parent when he has a th parent
and then go to its next child TD so
we're gonna say tag equals parents I
think it's the parent
so it looks like if I go to my parents
and I say I go to the contents contents
is the name for children which they
should just call it children you would
think but they don't so it's going to be
a list of children so really it should
be these two elements T H and T G but
let's go ahead and take a look so we
said got parent our content so we're
gonna print tag which should be a list
yep so it's a list yeah it's a Python
list here just like I said so now if
it's a list of children then we know
that the second child is the data that
we need so if I said contents dot one
cuz remember Python and most programming
languages start counting at zero sort of
computers so if we look at this now we
get origin there's children start
counting at mother-effing one why would
that be on second let's look at contents
again because I would think origin would
be child zero so I because look the
first element is a newline oh that's
some garbage that's not cool
yeah that's not cool at all there
not cool yeah so let's go ahead and try
to do something here with this we want
to say dot strip for this on HTML dot
txt I'm hoping that we'll get rid of all
the new lines because that's not cool
that it's returning a new line as yeah
I'm still doing any bastard so I mean
I'd rather not resort to some packaged
 like HTML about text equals
HTML text replace new line with nothing
that seems hackish as hell
so basically that's not gonna work and
that's not cool so just return that but
I mean I mean this thing is gonna fall
short unfortunately if we wanted to then
get the the right content I could say -
and that's gonna return on their anchor
text where it returns nothing because
that's also a new line that is this is
obviously not very efficient at all you
have to be able to strip the new lines
from the source code or it's not it's
just not gonna work all right so um
let's go ahead and take a look at this
art it's try the our script method which
is I'm rather nasty
at least I feel like it's just nasty to
do this but um let's see what we get
with our contents now
so unfortunately this is being a piece
of
so since supers gonna ignore all that
let's go ahead and say soup equals soup
our new line let's see if we get the
same result
so I'm sure you guys get the point from
here but I mean with the newline
characters that kind of sucks I'm sure
that there's a way to obviously get some
of that stuff out of there but without
the support of XPath XPath is honestly
like an imperative thing if you look at
google chrome like XPath is included and
if you can if you use selenium or
something like that and X paths are
supported so it's absolutely imperative
if you're gonna do any sort of serious
scraping operation or anything like that
you really need to have a support for
XPath in my opinion so I mean for me
personally I probably wouldn't move
forward with beautifulsoup just myself
but not saying that it's not a great
project or maybe little things here and
there but it definitely just it wouldn't
suit the type of needs that I think for
a lot of people to be able to really
really crunch a lot of data but that's
just one person's opinion so you know
take that with a grain of salt
all right guys but I'm gonna head and
kill this this video here and let me
know what you think and let me know if I
should do any more videos like related
to this or trying to expand upon it but
I don't want to start getting into some
package you know nonsense without having
to do research first so anyway guys
thanks for watching bye</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>