<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using Python's Beautiful Soup To Find Specific Text | Coder Coacher - Coaching Coders</title><meta content="Using Python's Beautiful Soup To Find Specific Text - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Chris-Hawkes/">Chris Hawkes</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Using Python's Beautiful Soup To Find Specific Text</b></h2><h5 class="post__date">2013-03-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yME299lFvFk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what up what up hey guys it's Chris so
on this one I want to show you another
awesome feature of beautifulsoup it's
gonna make your parsing you're scraping
whatever you want to call it a lot
easier it's a lot easier than using
regular expressions
it can handle broken HTML which
surprising but a good amount of websites
out there actually have broken HTML you
know proper or improper closing tags
things like that that can break your
parsing in regular using just regular
expressions so you can save yourself a
huge headache but not dealing with that
but let's go ahead and we have let's go
ahead and raise some of this stuff that
we had before and here's what we are
finding all the P tags now we can do
something like body there's something
here we're gonna copy and paste some
code that I have here so let's just say
body and there's some text that I have
that works pretty well with something
like Wikipedia and we had parsed the
bayside Wikipedia page so if I type that
in and we could see here let's go ahead
and say that we want to grab the let's
just say year's active I guess so no no
no let's just go with origin so we can
go ahead and look for origin so we're
saying soup dot fine text equals origin
and then we say find the next TD tag so
it's not always gonna be a TD tag that
you're looking for but when you if
you're using Chrome you can inspect the
element and you can see that we're
finding origin and then we're saying
fine in the next TD class now there's a
tags buried in here and the text is
between a tags but if you just grab the
next TD and just look for the text it
will find what it is that you're looking
for so it'll say fine next TD so we can
go out an
let's out file out file dot write like
we've done before and we'll say body dot
txt which will be a string and it and it
should be the origin which is Bayside
Queens New York City so let's go ahead
and see if this works we'll run it and
then we'll pull this up Queens New York
United States boom just like that boom
boom boom so you guys can get a lot of
stuff done you can scrape the hell out
of some pages and that'll be pretty good
so just play around my beautiful soup I
probably will do more tutorials on that
in the future but for right now I think
the next thing that I'm going to move on
to is in the near future I don't know if
it's going to be the next video but
we're going to work on how to fill out
forms and in Python so that you can
scrape pages that require logins before
and then I'm also going to be adding a
series on how to scrape Ajax and Ajax
can be a real bitch when it comes to
trying to get some information that you
need to get because sometimes you know
the easiest and sometimes the only way
to grab it is by really not just
replicating the user-agent like we do
here when we say we're a mozilla browser
we have to actually use the browser to
pull up the web page and allow the Ajax
and JavaScript to load and execute in
order to be able to retrieve data that
we're looking for so there are some
modules already built out there that
make that a lot easier to deal with and
I'll teach you guys how to do that once
you're able to scrape data like this I
mean you know the sky's the limit as to
what you want to do with it I mean keep
in mind that data is proprietary you
can't just steal people's data but you
can you know use that data to kind of
create your own unique website there's
nothing wrong with that you know
essentially there's nothing in
difference between having a program
scrape this data and then having to
manually do it I mean so I'm not really
sure what the legal implications
there but that's not that'll be your
concern I guess if you're scraping the
data but to be honest with you everybody
does it and there's really no way to
prove it
so anyway I'll kill this video now and
thank you guys for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>