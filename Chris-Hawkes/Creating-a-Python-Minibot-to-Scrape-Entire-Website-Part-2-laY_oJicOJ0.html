<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Creating a Python Mini-bot to Scrape Entire Website - Part 2 | Coder Coacher - Coaching Coders</title><meta content="Creating a Python Mini-bot to Scrape Entire Website - Part 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Chris-Hawkes/">Chris Hawkes</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Creating a Python Mini-bot to Scrape Entire Website - Part 2</b></h2><h5 class="post__date">2013-03-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/laY_oJicOJ0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so we're gonna start this
tutorial off with a real-world
programming problem that I discovered at
the end of the last video but to be
honest maybe I need to upgrade my
computer I got like a gig of ram and a
terabyte but for some reason the program
that I'm using the screen capture this
stuff is just a memory hog so every once
in a while like I get this notice that
my video has crashed or some and
like I've just spent five minutes
explaining something so I have to do it
over again but what I want to show you
here is that after vening is when we
print the link you see um you see all
this stuff I mentioned before it's like
okay we we got this big link and I'm
waiting for it to finish okay so it's
like okay we have this big link here and
what we want is the movie but if you
look at if I were just to print link
text I could do that
and it would just display and the text
within the a tag you know that you know
that should work but it's actually not
because this shows you the URL address
so if I'm going to be a spider and I
want to go through each one of these and
request the movie URL I need to know and
what the URL is and the actual name
doesn't signify what the URL is so like
this one here grown-ups well that's
actually a bad example because it has
2010 film on it but here's fantastic
mister actually growing up sort of in a
good example too if you look at
grown-ups here there's the parentheses
2010 film within the URL so if I'm gonna
request that I have to put this entire
thing in here to get the actual URL
returned if I just put the title if I
were just wrap the text and try to grab
the title grown-ups would return nothing
or it might return something that I
don't want so what we need to do is we
need to somehow extract the data between
and this forward slash after wiki to
this double quote
the easiest way that I can think of to
do that is by using a regular expression
and in order to do that what we're gonna
do is we're gonna type the we're gonna
type over looking for first so we'll say
fine equals re dot compile so that's the
regular expression engine and then we're
going to identify we need to match what
it is we're looking for so I'm gonna say
forward slash wiki forward slash and
then we're gonna grab dot star triangle
which means don't be a greedy bastard
just grab what you need to the double
quote so if you look at this here again
we're gonna grab everything from the
forward slash to the double quote but if
you look at that regular expression over
here it's actually going to grab the
whole thing so if I say it's like if I
tried to just find this it's actually
gonna find the whole URL and that's not
what we're looking for at least not in
this case I just want to capture what's
after the wiki to the double quote so I
can do that by using parentheses and in
regular expressions the parentheses say
hey match the entire thing and then also
imagine it and this but only this and in
order to obtain that match that second
match we need to use the re search so
I'll say search movie is a variable and
an equals re search and then we're going
to be searching fine which we just
described and then put a comma and we're
gonna search for the link now the link
is treated as a list item and not a
string so we need to make sure that we
say hey treat it as a string otherwise
it'll break so we'll say string STR for
string and then link in parentheses now
let's see if this worked we're gonna say
we'll say movie equals search movie
group
one and this may be a little redundant
maybe I don't know but uh we're
assigning movie the variable the value
of Group one and remember computers
start counting at zero so the zero match
on this ah recompile statement is the
entire thing including what's in the
parenthesis and the one match which is
technically two matches only what's in
the parenthesis which in our case should
be the movie URL the in the unique movie
URL that we're looking for so let's see
if that works and print movie and it
works just the way that we planned so
going up here you can see that it's
grabbing you know the HTML characters
and everything in Lee 1961 film both
girls girls girls those are these are
all the name of the movie that we can
request with the URL so it's alright
this should work so really after this
point we can go ahead and repeat this
entire process up here and really I
don't even need to change the names you
might want to as far as I open or you
can name open or two or opener movie if
you want it I'm not gonna worry about
that right now and let's go ahead and
identify the URL and the URL we're gonna
add on we're gonna cut it off at the
forward slash and then we're gonna use
the plus operator which is going to be
to add on to the string of the URL so
we'll say plus and then we're going to
assign it move it we're gonna add movie
onto it
remember movie is this group that we
just captured and then we say and then
let's go ahead and read it
so we'll go our URL will be the URL dot
read so we're reading it and then we'll
also then parse it was beautiful soup
now I could go through and print every
HTML page which would be a lot of
printing and obviously i'ma have to kill
the program regardless of what I do just
because it'll be a long time to go
through every single file and print
every single thing but let's just go
ahead and print soup dot title for each
one of those URL pages now you see we're
getting these lists of comedy films
that's actually something I didn't take
into consideration before as well we we
really should find a way to get rid of
those URLs out of our URL list because
you can see now we're getting into some
here's like one movie Fred Ott's sneeze
whatever the hell that is you can see
it's in that film so it's going through
each one of these I mean this is
basically a search bot so if you want to
know how to build a search engine I
mentioned before that in my opinion it's
better until you become some sort of
super expert computer programmer to just
kind of tackle one thing at a time so if
we're tackling Wikipedia today or Amazon
tomorrow or Walmart the day after that
you know just kind of deal with one
thing at a time I would I would say but
then you know this is a working body
it's it went into a page they grabbed
all the URLs and then it's going into
each one of the URLs and it's grabbing
it so these are all movies and stuff
that it's grabbing here so let's go
ahead and kill the program you may want
to do something else so that you're you
don't piss off the people that you're
scraping from you can import the time
module import time and then between
these URL reads you could say didn't
really say anywhere in here even after
the print thing you could say like time
and dot sleep so you invoke to sleep
method and then whatever you put
whatever number and they're like two
five you know I would say you probably
should wait you know two seconds between
requests just because you could get your
IP address banned possibly I've never
had that happen to me before and I have
actually ripped
and some quite a bit of resources but
I'm sure one day I will get my IP
address banned then I'm have to look
into how to you know mask my IP address
by using proxy servers and things like
that and I've never done that before but
I'm sure that'll be fun for a tutorial
one day and so I'm gonna go ahead and
cut this tutorial off here so we found a
way essentially to make a small
Wikipedia bot and I mean that's that's
that uh in the next video I'm actually
gonna you know what well why don't we do
that right now we could easily go to
like let's create an out file to our
projects directory so I'll say full-size
projects pore size training and then
I'll say movies dot txt comma space and
then within single parentheses right so
I'm creating a new out file named movies
txt and I can go ahead and say out file
dot right and I'll say just you know
this just write the title I guys maybe
so I'll just say out father right
and then so it's not all on one line we
want to do a concatenation and put a
newline character on the end of that so
it'll print one line at a time and not
all in one big-ass line and if I run
this I may kill the program out fine oh
you know what see that's not good
I said aha it's out file equals and then
opened sorry about that
if I run this again
squirt it up one time
I guess it doesn't like the fact that
this is not a string all right so it's
thinking now and it's actually running a
lot of times I probably should have
printed something to the out out screen
I could have said like print the current
name of the title or sometimes you can
see what it's doing I'm gonna press
control-c and kill the program we should
have a movies here's our movies text
file that we just made and you can see
that it has the title and this is
identifying reliable sources so this is
obviously another URL that we would not
want but and if you also notice here
this is another mistake that you run
into in programming I'm actually over
writing the file for every single item
so that's why there's only one item in
here to get around that you need to
instead of W you want to use a which
means append so it says doesn't don't
overwrite what's there just append to it
so if I run this again I'll give it a
few seconds here like that's just count
to five one two three four or five and
I'll kill it again and then let's open
this up and you can see it started
working through these movies here in
this particular case it goes through all
these URLs like all the URLs that we
don't want tend to be at the front of
this so it looks like it's not working
effectively but this would go through
every single movie like hanging over all
that stuff so we'll probably figure out
in another video how we can get rid of
some of these URLs that we don't need
but for right now that's how you can
easily scrape Wikipedia anyway that's it
for today so or not today but at least
for this video I'll talk to you guys I
don't bite</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>