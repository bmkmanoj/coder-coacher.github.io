<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Vienna.go, How we use Go at Domonda, January 2018 | Coder Coacher - Coaching Coders</title><meta content="Vienna.go, How we use Go at Domonda, January 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Pusher/">Pusher</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Vienna.go, How we use Go at Domonda, January 2018</b></h2><h5 class="post__date">2018-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BtZNJIlguUo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so what I'm going to show you now
is the tech stack and especially the
goal code we are using at Amanda in
general there's no rocket science
involved here it's more like
architecture and the way we go about
doing solving the usual things you have
to do
yeah we're using go for server and
command-line tools we are using Postgres
and are very happy we've PostgreSQL who
knows that yeah I guess so nobody so
basically what that is it's a graph QL
API layer for Posterous so basically you
can create a graph QL API from a schema
where you can query your schema and you
can also do mutations those mutations
are SQL functions that are called on you
can implement them however you want and
yeah basically it really gives you an
API for your application out of the box
if you have matching schema for that and
by using different schemas and fuse you
can also do things like different API so
if you have an external API for your
customers that's somehow different you
create another schema with fuse on your
internal structures and basically you
get an API free out-of-the-box so we've
been really happy with that that's
implemented in node it respects and uses
all kinds of Postgres wizardry to make
that happen but it really worked out of
the box and really good we have a
proprietary document database with
Russian ink so as I said we are into
accounting and the most important thing
here is to never lose anything
and always be able to prove that this
document has been delivered that way has
been changed and all this stuff and for
that we created our own document
database that's completely file paste
and has things like versioning and
checking out checking in and so on I'll
get into that later for the front-end we
are using the usual react Redux stack
and get up like many for source code and
also for deployment so how we go at
demanda how do we structure those things
so we have a single repo in github and
we have a monolith first and serverless
later meaning we always start with the
monolith everything is much easier that
way and when we see we can split
something off to something on AWS lambda
or something like that we do that we
don't go for micro services first and
build a lot of micro services only when
we see there's a benefit from going away
from the monolith may also change when
we have a bigger team but for a really
small team a monolith and the same
single repo brings the most productivity
we are very strongly following the UNIX
philosophies so everything is a file and
command-line tools that's basically all
we are using or basically everything you
can do at the mount at the mando with
our data you can basically do with files
and command-line tools and Postgres is
basically for us just an indexed cache
for clearing but everything is also
available as file and we can recreate
our complete database from files also
very important for backup reasons never
lose any financial
documents so about our own document
database it's completely file paste it
can run on s3 and we don't rely on any
features like five dates it's just the
content and the naming of the whole
structure and we have versioning we have
checking out working on some files
checking them in again which is locking
so one client is doing something with
the document of course nobody else
should be doing something else to the
document at the same time
that's basically a lot of functionality
that you get from version control
systems so while we're not just using
git for something like that well we have
lots of data and performance is always
an issue here and if we use some version
control system we can't use storage like
AWS s3 and quisha which really helps
together especially with things like
lambda and we have our own special
requirements so by developing our own
thing we have complete control over
what's going on and that has paid off so
far there have been lots of things going
wrong in development but we never lost
any data and we have the complete
history of everything and yeah that has
paid off so far so yeah the nitty-gritty
stuff you always have to do logging I
mean it's it's here more a philosophy
thing basically you can say every
developer develops his own locking
system once in his life or twice or
three times why not use like whatever
logging library is a favorite library
because it can do everything well
maybe that there are some other logging
systems in the background but what
dealing here is more like the philosophy
what we want to lock you know there are
different things like 100,000 locked
levers and different kinds of logging
messages and warnings and errors and all
this stuff and how you want to handle
that is basically a philosophy and
something you have to decide for
yourself and we are going with a very
simple approach like everything else in
go make it as simple as possible not
simpler so basically we have a locker
which has which is an interface with
three methods we have print F which
prints lock messages we have T Park F
which outputs debug output and that's
something you're just using for
development and then we have unresolved
error and it's especially on purpose
this long name this cumbersome name
because in go you don't throw panics you
don't have exceptions you want to return
all errors and all those errors bubble
up and even at the highest level you
have some way to handle those errors and
the only case where you have an error
that isn't handled because for instance
you had another error first and you
can't continue and then an error is
created because of the error before and
you have no way out
that is when you would use this
unresolved error everything else is just
printf lock message and you decide
yourself what's in the lock message in
the format of the lock message decides
what you're logging and if that's an
error or not
so usually you also lock errors with the
normal printf and only if you don't find
any way out of your state basically you
use the unresolved error and that's
basically how this is set up so
what we have is in our repository we
have a go directory where all the
packages we are using from the circle
server and the go command-line tool are
in there and we have one Singh locker
package and this locker logger package
is used by all other packages for
logging and the whole configuration is
done here so basically what you don't
have a mouse what you can see here is
basically we lock to the command line
with some colors and we can set a log
file if we want to and every package
then has its own lock variable so for
logging we are not using this locker
package directly we create a lock
variable which is this locking VARs here
which just references other variables
that's used for locking the reason for
that is if you have all those
dependencies everything depends on this
locker packages package and so on you
have the problems of initialization and
in which all is our things initially
initialized and so on and basically by
referencing just other variables with
the address operator like you can see
here the lockvar
is the real logger we are using from the
log a package and then we also are
referencing the P Park variable which is
defined in the line above that means
that those can be changed at any time
and we don't depend on the order of
initialization and if you want to debug
or get tipper debug messages from
package you change the debug variable in
that package
error handling in general so we said we
always want to return errors never panic
and one pattern we are using is that we
are wrapping arrows to get a better call
stack error information so for that
we're using this github
pkg errors package which we can highly
recommend
it's very simple all you do here is just
wrapping some errors with a call stack
and some metadata and that helps you in
debugging if you print out that message
and what you can see here is the differ
call if you're not that family familiar
with go differ makes this call wrap
error resort run after the whole
function has been executed and it will
be called in any case even if a panic
occurs and if you're using resort
variables like error here this error
will always hold the result of that
function so even if you define another
error and basically overwrite original
whatever will be returned from that
result will be available in this differ
rep result error function and what we're
using here is it can be taking the
address of that result variable that way
we can look at the variable and that's
basically the function that we deferring
here so if the pointer points to a nil
error we don't have anything to do but
if there is some error then we create a
nice error message we lock the whole
thing and we also wrap in the last line
the original error we
all these metadata that we've created in
that way basically if you crash and get
a call stack you see what functions have
been called with what arguments so
another convention for defining errors
usually you have something that
describes the this error so this error
here document not found we're using uu
IDs for document IDs and basically we
can define this error just as an
basically extension of that type by
adding an error method that creates the
error message and one convention that we
are using is that if we create such an
error we also create an is error named
function that checks if an error is of
that type so usually if you return
errors in go if you want to do some
error handling you have to check what
type of error are you using and because
we're using this errors package that
does wrapping of errors you don't get
the original error and in that case if
you just check for the type you wouldn't
get the right type and basically what
this errors package has here to resolve
that is the errors caused function but
something that happens all the time is
that we forget to use this error cause
when we check for the error type so the
convention is to always use this is
error whatever type function because it
always has that in it and yeah that was
more than mundane stuff now for the
interesting things so as I said we have
this UNIX philosophy where everything is
files and commands and basically in an
application a command is a function and
what we are doing is we are
being functions as commands so to do
that what do you need for command to run
then you need the arguments and you'd
need to do something with the research
here's an example for this patch
overview text function which returns
just some overview plain text that we
use in different places and we are
wrapping that with C lightest patcher
where this function can be called as a
command from our command line tool but
the same function can also be wrapped or
the same command can be wrapped as a
server out for a guerilla max the server
framework and you can see that we are
just adding these basically few lines of
code and we have the same function
available from the command line and also
as plain text responds with a server rod
so that's basically how the command line
tool looks like internally so we have
this string arc sticks dispatcher which
takes string arguments when you call the
command line tool and converts them to
whatever types the arguments of those
commands take so it's a standard
built-in conversion for the usual stuff
you have integers you have you you IDs
if you have structs then it's
automatically using jason to convert to
and from that from a string and
basically you can wrap any go function
as a command and then here this struct
flag load file if it exists and passed
command line it's fancy for basically
look if there's a config file use that
create initialize our configuration with
that and you can also change this
configuration with command line flags
that overwrite whatever you have in your
configuration file and what's returned
from that function is the arguments that
don't have any flags in them and they
are then used to dispatch a command
which you see this dispatcher dispatch
combined and that basically runs the
command and if there was no era we entry
have still some cleanup work like we
have here the thumbnails work until work
have finished
that's code like we use it here's
something more complex here we have a
function with one argument they get
table row with primary key so we're
using you you ITES for everything and
what we have here is a function where
you can just look up any UUID and it
will find whatever table is using that
as primary key and return you the data
which is quite handy if you're having a
lot of you you at ease in your locks and
you don't know what this is you can just
fire up the command line tool and it
returns you what table what content that
UUID reference and what you can see here
is this very able to get table row with
primary key arcs this struct defines the
arguments for this command so it has
this command arcs def that's basically
inheriting the methods you need to
handle that thing as a command argument
description and then every field in that
struct describes one command argument
and we're using reflection to get the
type and also as
can see the tax in the end the ID
lowercase like we want to use the the
name for the command argument because
we're forced to use upper case for
exported struct fields and so we have
yeah the name and also some description
that will also be used when printing
help information for that command and
basically for commands we always have
those pairs of these arcs def variable
and the function itself and yeah below
that again you can see how this command
is added to a command line dispatcher or
to router that handles that same command
as a web server yeah I can show you a
little bit more from our code base here
so basically what we have is this
tomando CLI that's the thing that can do
everything basically that we can do on
data we have quite a lot of commands
here and if we call that yeah looks like
that
okay can't increase the size but yeah
here are all commands that you can do to
add Amanda data and and then also the
channel configuration flags that we use
basically to configure everything for
for all tools to work and yeah doc
service so I said we have this
PostgreSQL API for Postgres data and for
accessing the document database we have
our doc server which is basically normal
rest services and just to show you how
that looks like so what we have here is
this server run function with gorillas
MOOCs and creating lots of routes and
basically they are all wrapping just
functions so this top database create
restructure group is a normal function
it receives destruct destruct is
automatically converted between Jason so
yeah if you call this route with Jason
input data it will convert it and call
this function if there's an error return
this error will automatically be
converted to 500 internal server error
if it's not a special error if it's a
special error like a 404 error then it
will use that for the response and if we
go back to the route so yeah what we see
here is this is the route and we have
this request body argument in that's
taking and converted as the in argument
for the command and it calls that
function
with that arguments definition and the
result when it's not an error will be
returned as a JSON response and
basically the same function is available
from the command line
yeah that's it so this is again an
overview of those packages that do this
command magic and the errors and the
gorilla mooks package we are using
questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>