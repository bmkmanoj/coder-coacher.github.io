<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Journey with Express to AWS Lamdba - JS Monthly - February 2018 | Coder Coacher - Coaching Coders</title><meta content="Journey with Express to AWS Lamdba - JS Monthly - February 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Pusher/">Pusher</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Journey with Express to AWS Lamdba - JS Monthly - February 2018</b></h2><h5 class="post__date">2018-03-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/16s0UUU0oGI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my name is Mary Andrew snack and I'm
gonna talk about our experience with
Express apps on AWS lambda let me first
ask you who has heard about a double is
lambda your hands up nice and who has
actually deployed some code on AWS
lambda so it's a good audience and who
has actually deployed Express apps on
AWS number all right so it's gonna be
something new for most of the most of
the audience so I work at out anybody
heard about out all right so it's it's
pretty big company it's it's AOL and
Yahoo together in one company owned by
Verizon which is a big American
telecommunications operator and we we
own a media like TechCrunch
which is the the most followed a
publication on Twitter so we own media
and we own some advertising platforms
which is what I do so I work for
advertising system for creating ads so
advertisers can create ads and promote
their brands and and and that's here are
some stats about the company you can you
can have a read later and this is this
is the agenda for today I'm gonna talk a
little bit about how we got to a double
is lambda and then about technology
stack we use there and what are the
limitations and obstacles we had to we
had to cross so back in 2016 I think the
company decided to move to AWS they
decided to move from our own data
centers to to the public cloud and at
the same time they also they wanted to
limit costs they wanted to reduce costs
because company had many acquisitions
and there were systems that were not
being used and
that they were just they were just aware
of the costs and they wanted to reduce
them so and that was the time when we
wanted to develop the new API it was a
new flexible system to support like any
any kinds of ads and improved
development of templates and etc it it's
not that important for the talk but
important is that we didn't expect high
load because the the API would be
integrated into internal systems and not
many people would use it but it would it
would be just backbones for for other
internal systems so we are talking about
like hundreds or thousands of requests a
day let's say and we we heard about
lambda a doublet lambda that it's yeah
we we heard about lambda functions that
we can pay only when it runs so it's
it's really good for us because we can
have low low costs and and that we have
no server management so and yeah you are
familiar with lambda function you've
heard about maybe some of you don't know
how it likes how exactly it looks like
so for those of you let me just
illustrate it really it really is a
function you can code it in a online
editor directly or you can upload the
zip if if you have multiple files so you
can you can zip it up and upload and so
as I said you only paid for it when it
runs so you you don't need to you avoid
having a virtual machines which which
has low utilization and you can upload
the zip and lambda functions they they
have free tire which is which doesn't
expire after 12 months and it it offers
you 1 million request demand and for to
have 400,000 seconds of execution which
really if we are looking at thousand
requests a day for our API this is
we would we would we would be okay with
this free tire and the benefit that we
don't need to manage servers we don't
need to you know monitor them and it
just is this it's just automatic it just
our code just just ran somewhere in the
cloud so this really was a benefit for
us and we decided to go for it and but
but hang on how are we gonna how are
going to develop our code if it's like
we would develop it in a online editor
we would be uploading zip files we
couldn't do that so we found this great
tools that that can help us in
development one of them is a SS server
server less Express library which
translates lambda events to express to
the to the request that Express app
understands so this is the this is the
it's really like a wrapper around it
wraps your Express app and do its magic
so this is like boilerplate code and you
can see that it wraps your app and then
then creates a proxy to the the lambda
event and and you can deploy this to you
can upload this to lamda what this gives
us is that we can develop our
applications as we were used to wear
like normal Express applications with
route and everything that we are used to
and it can be in one project so it's
it's really simple development the the
drawback is that we will have a larger
function but the the API is not that
large for for that it cannot be deployed
there so so it was okay for us because
the benefit was that we were we would
have a simpler development and another
thing that we used is Claudia Jas which
which prevents us from just uploading
zip files to lambda so
by running simple commands we can we can
deploy our code
Claudia jeaious is a command-line tool
which with which you can use to even
generate the boilerplate code which I
showed you before for this aw several
serval as expressed sis this first
command and this command the create
command it will create all the all the
entities in AWS for you so you just run
this simple command and the lambda
function is created the policies that it
needs roles and etc it it creates
everything you need for your your your
function to run and then when you do
some development
you just run Claudia update and it just
uploads the the changes to AWS so here's
a link to to the tutorial so you can
have a read later and as most of the
applications do we needed a database so
as SQL is is it's like not cool anymore
so we decided to use now SQL the first
the the obvious choice was DynamoDB
because it's available in AWS so it's a
no SQL database from Amazon it offers
fair amount of of storage for free and
like you pay for storage you pay for
requests but you have to for example two
hundred million requests free a month so
we would be we would be okay with that
we would not pay anything for our like
not many requests for our API but you
know we were using this dynamodb and so
the query was not flexible with this
with DynamoDB but it was okay we we
didn't have any complex queries but the
most important part here is that it has
a 40 400 kilobytes maximum item size
which for us it was really a lame
because we wanted to store like large
data in a Jason there so also the one
there's a one megabyte limit on the
retrieve data so if you if you want to
retrieve more data you need to like pull
it to do it to send you more data so we
were not happy with that and we decided
to switch to MySQL and believe me or not
it still works and it's proven
technology and especially what we found
is that there is a JSON data type in
version 5.7 which was really helpful for
us because we needed to migrate so we
could leverage the JSON data type and
the migration was was quite it was quite
smooth because of that and important
thing
it's available in RDS so we don't need
to it's like a hosted version of the
database we don't need too many servers
and yeah it's just it's just there so
yeah one more thing which our
application which our API needed is to
offer file uploads and we store those
files in s3 which is also obvious choice
for for AWS it's it's it's good it's
relatively cheap it stores files it's
it's a key value storage basically but
those if the if the keys shared the same
traffic say they form directories so
yeah it's it's good here's some some
pricing it's really it's really not not
expensive however we realize that there
is a there is a file upload limit that
there is a maximum payload limit in the
API gateway which is which sits in front
of the lambda so you can only send ten
megabytes in one request maximum
and also lambda can only process up to
six megabytes so the the request to
lambda can only have six megabytes so
this was limited because we wanted to
support uploads of larger files and
there is a feature in s3
it's called pre-signed uploads and it it
allows you to to generate the key for a
user to go and upload directly file
directly to s3 so here I wanted to
illustrate this so your API creates a an
endpoint so for example my priests an
endpoint a user hits that and it gets
returned the the URL to the to the app
loan at point so user hits your API he
gets returned the the the URL to the
upload and then it he uploads the file
to that URL well I'm talking I'm talking
the user but it can be a client it can
be a CLI so so CLI he's the priests on
applauded first and then it it gets to
return the the URL to upload the file
and then upload the file to that to to
that URL so yeah
and so we had our API and we wanted to
improve the local development because we
used s3 and s3 was is available in AWS
but for local development we found the
library it's called s3 like it's called
s3 server I don't know how to pronounce
a server so it has it has a small set of
s3 API like mocked and it's basically a
local s3 kind of mocked version and so
yeah we use that for tests and we use
MySQL in docker
so when tests run they start up the
docker container with MySQL then then it
shut down after the tests pass and we
have also some some other services just
mocked like this simple simple routes
for local development yeah
so our API was running for some time in
a NIDA in AWS and we noticed that the
API sometimes takes too long to respond
so we were investigating that and we we
realized that lambda and is shut down
when it's idle for around 15 minutes so
there is a way to reduce that so we we
created jobs that every 10 minutes makes
a request to to the API to keep the
container running and prevent it being
shut down this doesn't mean that we we
pay for it
because we pay for it only when it runs
but to prevent it being shutdown so it's
always warm so so we don't have the
additional latency yeah we have jobs
that pause the API every 10 minutes and
then also we we we created cloud watch
events which like it's also like a job
but directly in AWS so it it's it's just
an internal request we do that every
five minutes and important thing to note
is that even though we did that we we
hit API every 10 minutes to keep it warm
you can you can never avoid lambda from
being shutdown at all like completely
right because AWS sometimes it rendered
randomly shuts down the containers but
this is just to to like reduce this
shuts down a shutdown so so that's what
we did
and sometimes because we host it for
example swagger swagger you I in in
lambda we noticed that when we were
requesting static assets the lambda was
was taking too long to respond still
even though it was warm but so lambda is
not good for serving apps with many
subsequent requests because then lambda
things that oh the the the load is high
so a SS will try to spin up like more
and more lambdas so what we did is we
moved static assets to s3 and this
drastically improved response time and
only the only the the variable parts we
have been in the API and static static
assets are in a string so yeah we we
wanted to secure for example database
passwords so so that we don't store it
in the in source code and we used came
as for that
it's another AWS service it's it's just
you hidden a JavaScript API and it
returns you the the unencrypted value so
every time we deploy lambda function we
we set the environment variables which
are encrypted values and then when
lambda starts we we decrypt that value
and just store the decrypted value in
memory so it's not it's not anywhere in
and in the code
it's alright service however we realized
that our API is sometimes timing out and
the API gateway has execution time out
of 30 seconds so you can never run your
request for more than 30 seconds and we
realized that it was sometimes timing
because the because of the came is this
the decryption so we were for example
decrypting three different keys and it
just took more than 30 seconds yeah we
raced a couple of tickets with with AWS
and then it just resolves by itself we
didn't have any problems in a recent
month so I don't know but yeah just
wanted to tell you that and we we wanted
to the video processing for uploaded
files and that's why we needed a binary
for video processing so we didn't want
to reinvent the wheel just use an
existing existing library for video
processing but we realized that there is
a there is a limitation on the on the
package size of the lambda so when we
added the binary we just got an error
that all your packages is too large to
upload too large to deploy so there is a
50 megabytes deployment limit deployment
package limit too when you upload
directly to lambda there is an option to
deploy by s3 so you upload your sources
to s3 and then in AWS it somehow just
deploys it to 2 lambda and debt limit is
250 megabytes so yeah we are we are
under that I think to note also 75
gigabyte is limit for total size of
packages in one region which like so
total size of the historical packages so
sometimes you need to you need to delete
that and pretty recently there was a
team which got to me that oh we we are
we are getting the 4 1-3 errors when
hitting your API it's actually different
API that I'm talking about today but so
we have we have
api's in lambda but yeah that they said
they were they were getting four one
three errors and I googled it and there
is a you're L size limit so they were
hitting that that URL size URL can be
maximum of eight kilobytes it's you will
probably not run into this issue it's
specific to our API but it's it's it's
just interesting to know that yeah
there's eight kilobytes URL size limit
and yeah just to summarize all the all
the limitations I I talked about
throughout the throughout the talk is
that lambda shuts down when when it's
idle so you need to you need to keep it
warm by by just pulling it and there is
a 30 second API gateway execution
timeout
so try not to run your your request for
too long there's a maximum payload of 10
megabytes and actually we can say it's
six megabytes the maximum request size
and deployment package can be 50
megabytes or 250 megabytes if you upload
by s3 eight kilobytes URL size limit and
and dynamo has has silly limits of 400
kilobytes per item size and and and one
megabyte on the retrieve data and just
to talk about the result from from our
side is that we really are happy with
lambda because we don't need too many
servers so we just deploy code and and
it runs scales automatically we don't
need to update you know do the updates
of the VMS and stuff like that it's it's
it's really good we don't need to do ops
work and by using Express
the the AWS server let's express it
prevents us from being locked into the
two AWS because yeah if we decide to we
can just move it somewhere else because
it's just Express up and we also use
MySQL so yeah we can we can just migrate
to something else
we don't use dynamo and it's it's really
quite cost-effective solution for our
not heavy traffic API
we checked the how much we spend is like
for for lambda we are in the free tire
and we we really only pay for s3 and
it's like it's in one dollar a month or
something like that and yeah good to
know it's relational database might
often be better option than NoSQL so
yeah this is considerate and thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>