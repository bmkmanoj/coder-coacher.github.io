<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Kubernetes for .NET Developers - .NET South West - February 18 | Coder Coacher - Coaching Coders</title><meta content="Kubernetes for .NET Developers - .NET South West - February 18 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Pusher/">Pusher</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Kubernetes for .NET Developers - .NET South West - February 18</b></h2><h5 class="post__date">2018-03-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MF3cdWKjhwU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well thank you so much for coming and
braving the the snow and I've been too
bad so very briefly I'm I'll switch this
one first and help so I'm sure it being
a developer can active for about ten
years we now work as a kind of freelance
consultant I'm on Twitter
i blog occasionally and my email address
not that easy to read what is on me so
today I just wanted to talk about
kubernetes so this is one of the kind of
hot trends at the moment so to cover the
kind of overview cuba Nettie's how it
works
talk about how you get started with
clusters and then I kind of want to talk
around the subject so talk about manage
to kind of communities providers a quick
discussion around kind of past versus
container platforms and then what you
might want to do in terms of planning so
in terms of takeaways for today it's
really around understanding the key
concepts within communities and I've
kind of made an assumption that most
people who attend user groups are
familiar with docker by now probably
bored to death of docker one 101 talks
I'm not going to go into any great
detail about docker so apologies if you
don't know that much my daughter feel
free to grab me afterwards I'm happy to
explain so kubernetes is a open source
container orchestration platform it was
originally created by Google based on
some of the internal tools one one named
Borg and one named Omega it's raining
goats under person open source it's
hosted on github recently Google donated
the their code to cloud native computing
Foundation which is a subset of the
Linux Foundation so it's no longer owned
by Google which is why we've probably
seen a great up taken in kinda adoption
because it's not home by single company
anymore before we go too far I'll
probably just clarify a couple of things
so you often see kubernetes written as K
eights and may not know where that comes
from
so simply it's okay and then there's
eight letters in between yes so that's
all that is when Twitter have the the
140 character limit I was trying to get
that adopted but it didn't take off and
I suspect it won't now as well so I
mentioned the CN CF know who are they so
there are subject
Linux Foundation and they a large number
of companies are part of that foundation
so this this is just a screenshot from
their website these are just the
Platinum members so these guys have paid
around three hundred and twenty thousand
dollars to be a Platinum Member and for
that they get to contribute to the
project stair Asterius direction the key
thing is as you can see obviously we've
got hey WH go to Joe and go Google cloud
and then all these other companies as
well so there isn't a single company
that's that's kind of directing the
project and this helps I guess keep
other people comfortable that it's not
going to go down a particular Avenue now
red have recently acquired one of the
another company and they've actually got
quite a few people leading a lot of the
projects within the kubernetes forum so
there's probably some concerns what that
might look like in the future so the CN
CF they host a number of projects
kubernetes is probably the most well
known but once you're in this kind of
realm you'll come across a number of
other projects so Prometheus is a very
popular monitoring tool which runs
within communities and then there's a
number of other ones probably call are
things like envoi which is a service
mesh which is another very kind of hot
topic within this space and then rocky
which is an alternative kind of
container runtime and I'll talk about
that in a minute so we kind of go back
to basics Lou and say well why do we
need it what do we need kubernetes well
you know I guess most people are Adana
developers and the pub used to be
writing full framework applications and
impossible we'd have to do is we deploy
these two VMs or physical hosts
and now you'd create application you
deploy it's a hexagon but it's not macro
service and then you need to deploy
another one to give yourself isolation
you put it on a different host and then
same again obviously here we're
potentially we're wasting a lot of
resources by having these physical hosts
and also being kind of dotnet
traditional net where we're paying for
Windows licenses and each one of these
boxes as well so obviously in recent
times we've kind of moved on to the
world of docker and that's great so now
we can put more and more containers
together so we can make
better use of our resources but doing
this kind of manually still has some
challenges for example your application
may be bigger than need more resources
in a single node and the other obvious
issue is if that physical machine dies
what do you do with all those containers
you've got to go and interact with it
and weave it so very quickly when you're
in the kind of docker world or container
world you need something more and that's
where something like a container
extraction platform comes in so let's
imagine we've got whole heap of machines
the way to think about it kubernetes is
that it meshes together all of these
machines into just a blob of computer
memory and networking and then we don't
really care about the underlying VMs
anymore or physical machines we just
deploy our containers onto the onto that
platform so in terms of kind of who's
using kubernetes this is a very recent
squish I think it took this couple of
days ago and there's no surprise really
this quite a lot of big companies on
there what's interesting is they've
updated is since the last time I took
this screenshot so a few companies don't
show in here anymore for some some
reason one of interest is the UK Home
Office use kubernetes as well as I think
the DVLA and also the Department of
Justice so always find it quite
interesting that we've got government
agencies who are normally traditionally
known for being quite slow on the uptake
arguably leading the way in some cases
compared to a lot of smaller companies
and partly that's because the
complexities of kubernetes recently
there were in terms of hosting
communities running it what where can
you run it first option is obviously
on-premise so you may have your physical
data centers with racks you can store
them they're obviously more likely
you're gonna have some kind of
infrastructure as a service platform so
VMI OpenStack and it's full on there you
can even write in raspberry PI's well
you're not going to be running your
business with raspberry PI's hopefully
you can of course go ahead and spin up
infrastructure in the cloud and install
it on there and then the kind of the
final option is slightly more
interesting this is where you can have
managed services so where somebody takes
ownership of running the platform for
you and you
we just access he has a has a software
platform so and the Red Hat guys have a
can opener shift platform and then the
three cloud providers all offer going to
manage two communities and I'll talk
about these in a bit more detail in a
second we talked about cost kubernetes
is free I mention is open tools you're
welcome to download and run it now of
course free and open source doesn't
always sit very well with enterprises so
probably one of the most popular
enterprise kind of versions of Cuba
Nettie's is openshift
and this isn't this isn't a kind of rule
kubernetes if you like it's been wrapped
by my dread hat into more of an
enterprise offering sorry it kind of
builds in deployment pipelines and and
got authorization various other
components and then canonical have a
have a kind of hosted version again they
they offer kind of commercial support
and then core OS have their version as
well but again the other guys we've got
taken over by Red Hat recently so I'm
not sure what's going to happen with
with bath ticket offering and recently
helped here which is a kind of
kubernetes consulting company they've
offered this thing called a proven NT
subscription where they will support
kubernetes on any of the main cloud
providers so they have a lot of kind of
key kubernetes people working for them
so that's an interesting proposition as
well terms of features communities is
the number of features of just kind of
picked up a few so obviously we talked
about contain orchestration we have
automatic bin packing so this is where
communities can understand the
requirements of your containers and
package them onto your nodes in a
particular way to make it more efficient
so be an example you may have a
container that needs high CPU but low
memory you may also have a container has
low CPU and high memory usage those two
would sit together quite well and it's
the same node and that's what kubernetes
will do for you we have horizontal
scaling we have rolling deployments of
roll backs we have self-healing service
discovery back jobs and a number of
other things in order to provide these
features there's a number of
now most of these I'm not even gonna get
chance to cover in this talk you can
easily spend today talking about
communities I'll call out a couple of
things just have interests so we have
things we have ingress which is a this
lazy boot is not gonna work only which
is kind of layer 7 load balancing we
have things storage obviously we have
all back roles based access control we
have helm which is a package manager
secrets management so everything you'd
imagine a kind of comprehensive
enterprise level platform would have
kubernetes has it terms of creating a
cluster as I mentioned it's kind of open
source you can go and download the
source code and you can run it yourself
you can deploy there's a there's a guide
by Kelsey Hightower kubernetes the hard
way which gives you step by step
instructions and how to create a
kubernetes cluster from scratch you know
there's also tools like cube ATM and
cops particularly in AWS world for
creating clusters terms of working
locally you've got some communique band
I'll talk about this in a little one and
then recently docker racketeering for
Windows and Mac has has built-in support
kubernetes of course again you've got
those managed clusters from the three
main cloud providers and then canonical
and rancher crate will have tools which
are kind of used to create clusters so
simplify the question of clusters and
there can be anywhere can be on on
premise or in the cloud if we dive into
the architecture a little bit so high
level architecture is pretty standard
for you'd expect from a distributed
system so we have one or more master
nodes which which is the control plane
as we call it they're trying to go away
from the term master node it has
connotations so more likely ability is
controlling the management plane this
exposes an API and the API you interact
with that through either the user
interface or the CLI which is called
cube CTL or cube cuttle or cube cuddle
because we've spent a decade arguing
about tabs and spaces that wasn't enough
and we're now gonna argue about how we
the sea alight so just just to warn you
if you in this space that will come up
so the masternode doesn't host any of
the work the work is done on the worker
notes and you notice the master node is
linux only but the worker nodes can be
Linux or Windows although the Windows
functionality is in beta and it's it's
developing shall we say to label
fluidity if you dive in the anatomy of
the master node so master node has an
API server and this is the main entry
point so you don't interact with
kubernetes any other way other than
through the API server as a scheduler
and the schedulers job is to basically
determine where to run your pods where
to run your containers you have a
controller manager this is one of the
main control loops that kubernetes runs
and its job is to basically monitor the
cluster and monitor the nodes and that
fairly recent edition was a cloud
controller manager and this is kind of
recognition that when you hosting
kubernetes on on a cloud platform you
need to interact with the cloud fabric
it's a common examples here is you may
need to provision a load balancer you
may need to allocate public IP addresses
originally that code was within the
controller manager and they recognized
that this was causing a liver friction
so they split you having to a controller
manager Cloud Controller manager
specifically to deal with that and then
all of the state for your cluster stored
in ED CD which is a distributed
key-value store so that's the the main
the brains I guess of the of the cluster
master node die will it be into the
worker node so worker node has a queue
blur and this is the main agent that
communicates with the master nodes you
have the queue proxy which deals with
all of the networking aspects of a
particular node we have the container
runtime so there's always an assumption
that I mean I talked about docker
earlier and doc is obviously the
de-facto container platform but
kubernetes isn't closely coupled with
docker you can actually run kubernetes
with the different container runtime and
rocky which I showed I mentioned earlier
on at the-- with the CNC CN CF projects
rockets one no I'm
is pods and the pods actually where your
containers run there's a couple of
additional services to do with kind of
health monitoring and and metrics so got
pods and they want our pulse so the pods
actually the abstraction that kubernetes
uses to contain your containers if you
like so typically a pod will have one
container but on occasions there's where
there's a need you can have more than
one container with in a pod
the key thing is the pod is a unit of
deployment the unit of scale so why
would you have more than one container
within a pod so common use case here is
where you have these the secondary
containers sometimes called a sidecar
container and this is where it could be
doing it a kind of side job from the
main container okay
example of this could be your
application containers writing logs to a
log file location and the sidecar
containers grabbing those logs and
pushing them to some kind of log saver
some way if they're within the same pod
then they're sharing Network
communications of a local host you can't
bind the same port address as you'd
imagine now kind of talked about various
components it's when you get into
kubernetes you can get a little bit lost
in terms of where all the bits fit
together so I just want to touch on them
here and we'll go into bit more detail
on some of these later on in the
presentation as well but broadly
speaking we have some calling ingress
and this is your kind of layer seven
load balancer so ingress can span more
than one service its job is basically
direct traffic based on whether it's the
hostname whether it's the headers
whether it's packet fragment of the
address it can route traffic to your
service services a effectively service
discovery over your application your
application is packaged up as a
deployment the deployment will contain a
replica set which will have multiple
replicas of your application which of
the pods the pods can contain multiple
containers and a container can bind
volume secrets called config Maps so
don't worry if you don't get all of
those right waves just to give you an
idea of how the things fit together kind
of changing tax law we wanted to dive a
little bit deeper into the managed
kubernetes
is so people familiar with kind of a KSC
KS and GK so these are managed
kubernetes services provided by the main
cloud providers a key feature of these
is they manage the masternodes for you
so that that's the kind of critical part
of a cluster and all of these platforms
they take that away from you they take
the concern of running that way from you
they make it highly available they're
responsible for making sure it's backed
up and upgraded so it's significantly
remove this removes the complexity of
running a cluster and sending in the
case of Azure and Google you don't pay
for those masternodes so you're only
paying for the infrastructure that
you're using as your worker nodes so
it's exactly the same as I as theirs
it's literally no additional cost to run
a kubernetes cluster over running VMs
themselves practice cheaper because not
paying for these now I was in haven't as
far as I know having announcer pricing
is still in preview it's in limited
preview so I presume they'll follow suit
because as you did that first and I
think Google then changed their pricing
to to kind of Alliance so that's the
kind of managed services if you want to
work locally and I've touched on this
before good option is is some community
up so the doc of a window scaling is is
in the edge build at the moment so it's
it's a little bit hairy I'm not going to
use it today for this time I'll show you
very briefly mini cube is another
alternative
in essence both of them crate use a VM
and they create a single node kubernetes
cluster sometimes interacting with it
it's the same experience as you would on
a fully blown cluster same API calls but
I've see you don't get the multi node
experience so let's dive into quick demo
of mini cube crucial you doc you just
kiss you familiar with it so the edge
builds if you go to the doctor tooling
you can download the edge from the edge
channel here I once you installed it it
doesn't enable the kubernetes by default
you have to go to the settings you see a
new option for kubernetes there and then
you see enable it and you can see it's
running at the moment
last time I hope they say I had to
understand wind solar stopped working
sir I'm not going to use that for this
demo said I'm using mini cube now
meaning key we can find on github and
the deans installations all the
instructions all therefore I'm running
it on Windows or Mac you can run it on
you need hyper-v enabled basically on
your machine or VirtualBox I obviously
prefer hyper-v easiest way to get
started is just use chocolaty to install
it I wouldn't bother trying to do
manually it's just just far easier once
you install him it was installs the
tooling and then I can just check it's
working now mini cube has been Libby
flaky recently as well I've had one one
talk a list where we're kind of gave up
the ghost so got fingers crossed for
this talk a roll quick blog I found what
I think was a cause I mean I I wrote a
blog article about a which are whole
link to later
so I've earliest the cube CTL come on to
K so we can stop arguing over how to
pronounce it so I can do is I can say
cluster info and that just gives me a
just a very brief kind of indication of
where that clue master is running if I
say ok get nodes and if I can type
you'll see there's a single node there
so if I want to get an application and
up and running so I'm going to do is I'm
going to type some imperative commands
and I'll explain why you shouldn't do
that and no classic demo fashion so if I
want to run a container I'll do is - a
keep see - run I'm going to call it
hello world and on a reference an image
so I've gone and pushed an image to taka
hub
and I'm gonna ask one port 80 so see
this is a diploma crated I'll keep
clearing this so it's at the top now if
I say if I ask for the pods should see
we've got one pod running as of nine
seconds ago and it's one of one now if I
want you to connect cess this pod what
we need to do is expose you as a service
now another shortcut you can do there is
you can ask this exposed so I'm going to
expose so I'm looking down because I've
got some notes just to remind me and I
want to expose this as type load hunter
I'll explain what these are in a little
bit so the I think the API is quite
intuitive it's kind of get to Pavlik if
things describe if you want to see more
details it's fairly standard and then
it's always can cube CT or get and in
this case I want to get the service SVC
I can see my service has been created
it's got a cluster IP address and it's
got a pending our peepers now because
this is running locally it's not going
to get a public IP address because
there's nothing to provide its own mini
cube kind of gives you an option to
basically in essence it's running on the
VMS IP address at that particular kind
of three one one two one
for what a shortcut really is if you
just ask mini cube to give you the URL
it's behaving itself I'll give you back
all if I pop over to a browser you can
see I spent literally zero time on this
app down here you can see that we have
the machine name so this is
environmental machine name and what
you'll actually notice is that
corresponds to the
the pod name so if I wanted to scale
this so I've got a single instance
running and I want to scale it um I can
do is tell it to scale deployments oops
so again I'm referencing the resource
type and then I want to tell it to say
now if I do get pods are found quick
enough still slow you can see now
there's four pods running if I pop back
to the browser and if it's behaving
itself if i refresh often enough you
should and it's not doing it but but
trust me it would you would load
balanced across now key concept will
include net is desired state so we've
told kubernetes that we want four
replicas kubernetes job is to make sure
there's four replicas if something
happens to change that then this will go
ahead and make sure this worked because
they will act so if I delete one of
these pods so let's just delete that one
I'll scroll up on here
and then if I'm quick enough should see
that one's terminating that there's four
running so it spun up the fourth one
immediately and that one's now
terminating so when you kill a pot like
that it gives it I think it's by default
three seconds it gives it to finish
serving in traffic before I actually he
also stops takes out the load balancer
let's say finish
many sends a termination signal so it
tries to do in a in a safe way the so I
think that's that's everything on mini
cube for now so let's just flip back to
the slides so you saw me kind of typing
at the command line and we know that's
not the way to do it that's error-prone
you saw me miss type a couple of times
so kubernetes uses muscle Yama followed
you can actually be json files as well
but yeah mel is the current hotness so
everyone really uses Yama falls so Yama
files define the application structure
and the resources application needs and
this is the desired state of application
so way to think about this is your
containers the application and then the
Yama files the infrastructure as code
you kind of ignore the cluster bit of it
so these yarmulkes should be in source
control they are your deployment these
are your petitions and this is to your
to your question earlier this is partly
where you'd be able to move clusters but
basically re submitting these AMA files
to new cluster then we take a look at
one of the Jama files so you can see
this is a deployment fall so I showed
you that deployment is the cunning
encompassing object I won't call out all
of the the bits on here but the key
thing is the the files are all very
similar structures and the coin tells
you the resource so we've given it some
labels
kind of act HW over here we've told it
we want a replica
single replica and then down here is the
specification for the for the container
itself so there's the image in this in
this case is on docker hubs public repo
you can have private repositories as
well if you wanted to and then we
reference the container pool now if we
wanted to deploy this again we can run
the cube CTO command
this time we the created a chef and we
pass it the Yamaha that you notice we're
not telling you what particular resource
to deploy all of that's contained in the
file itself so this is automatable once
we've deployed application how do we can
access it so let's say we've got in this
instance I've got this application go
three instances of this particular up
here it's running on three different
nodes each one's got its own internal IP
address and I've an application that
wants to talk to that I could do the
knife thing which is discover the IP
address somehow and talk to it directly
now of course I mentioned before what
happens if no dice when the case there
are no dice kubernetes will detect that
we said three instances and there are
now two so we'll go and spin up another
instance of that pod on one of the
remaining nodes more than likely at that
time I'll get a different IP address so
obviously our application will now be
broken it's fairly standard stuff I'm
short so those of you familiar with
systems development so the way around
this is you use some color service you
saw me doing this through the command
line so service service is basically a
well-known endpoint for your application
gives you a DNS so DNS endpoint for this
service discovery application talks to
our service and then that service load
balances the requests across the
underlying pods in this situation if no
ties doesn't matter because kubernetes
will create the missing pod on another
node your service will discover that and
keep a load balancing across it so your
application should be unaffected
particularly if you've got more than one
instance running so in terms of
deploying a service the Yama file for
service looks again very similar in
terms of structure this time we're
telling it to service reusing labels
again and the the bit of problem on
Koala here is this selector so the nice
thing that could net is this service is
a loosely coupled loosely coupled rather
to the underlying pods so they don't
have any way it doesn't mention the
specific pods that the service is not
banning single cross what it defines is
this concept of a selector so the the
pods have labels and the selector here
tells us the service basically some
predicates say find all the pods to have
this particular label and load balance
across them
so the service doesn't know specifically
which pods disk analog balance - it
finds them at the time they're running
if a new pod comes into the into a node
that has the same label it'll become
part of the load balancing as well
so it's loosely coupled and this this
gives the option to doing clever things
with potentially with canary now the
load balancers are kind of basic kind of
layer 3 layer 4 load balancers so it's
loading anything too clever there's the
ingress which you won't really get
talked about too much today which gives
you the default clever kind of load
balancing that you'd expect ok so that's
kind of accessing your service so we've
got our application we've deployed it we
can access it and now we want to update
it so how do we do updates so
communities has support for performing
zero downtime rolling updates so the the
kind of gold standard if you like you
can also do Bluegreen deployments and it
does this through a reasonably simple
API so in essence it defines two
parameters which I'll talk about in a
second and what communities does is you
will go ahead and start rolling out a
new version of your application
your waits for the application to come
up be ready be healthy and then it will
start taking down all pods all the time
the load balance is now routing traffic
to the relevant pods so the two
parameters are you juggle when you do
this is max unavailable which says
basically these are the number of my
current application pods I want to take
down during the upgrade max Serge says
these are how many additional pause I
want to create as part of the update and
now both of these numbers can be a
percentage or actual number with those
two numbers you strike a balance between
how fast you roll out your update versus
your service capacity so for example if
you've got a high volume service that's
you can't really afford to lose 30% of
your traffic handling capability you
wouldn't set the max unavailable you
would keep that a low number if you want
to draw like really fast you'd sent max
surge to be higher I'll show some
examples of these in a second you can
also then roll back deployments as well
from the c'mon I'll show these things in
a second I just want to call out that as
six years kind of zero downtime
deployments are there not kind of magic
there's no magic source in communities I
will solve the data problem if any of
you've tried doing this and if you've
got schema schema changes or breaking
changes in your schema as part of your
deployment kubernetes not going to fix
that for you at some point during a
rolling update you will be serving
traffic to two versions of your
application and your application needs
to deal with that so just want to make
sure that was clear so we take a look an
example of other kind of rolling update
so we've got this service let's go three
instances of it we've we've this is a
service which is go critical capacity we
can't afford to take any capacity down
moutoku Baudette is we want have max
urgent one so what will happen during
the upgrade is overlapping the upgrade
is another pot is created
so we've now surged up to for someone
more than the max when that pot is
healthy and responding to the health
checks it will remove one of these so
now we're back to our three original
capacity and repeat the process for
three eventually we'll have all of the
VT pods running so no point did we lose
the original capacity of our cluster but
the rollout was a bit slower for that
reason what you can do is you can do
Bluegreen deployments using the same
concepts so in this case what we've said
is we want zero max unavailable but we
want to search to 100% so so you
probably guess communities will then
create 100% of the new service wait for
those to become healthy then I will take
the other ones away and that's your real
agreement so switch over so the next
time I'm going to do is in a case or
thought just quickly mention a case I'm
kind of as your guy so it's the plaid of
choice for me so very briefly I just
want to mention why Kay so I've
mentioned the management nodes
they're not even visible so you can't
access them can't do anything with them
so this this loom
some options when you want to use
certain feature flags you can run
multiple different communities versions
and you can upgrade if you're brave
enough you can upgrade your cluster in
situ while it's running to a different
version of kubernetes now the AKS is
still in preview so this has gone wrong
in the past but I think of assorted can
also scale the node count you can do it
from the UI actually I'm notice as well
now you can increase the number of
worker nodes you want just from the CLI
the the nodes your worker nodes are
patched automatically by oh but they're
not automatically restarted and recently
there was a community project crated
cured which detects when I'm node has
been patched and it will trigger a
restore in a safe manner so in effect
what kubernetes does is it has a concept
of draining nodes tainting so paint will
stop any new nodes being scheduled and
then it will slowly move them off
tactically node until there's nothing
left and then every starts a node when
it comes back up it comes back into the
cluster so it's pretty cool stuff
as I mentioned it's covered in preview
and it's like GG and the coming month oh
I think Jo ran into this you wanted to
have a play around and it was a bit
confusing in the UI he looked like your
to spin up quite expensive cluster so
you can create a single node cluster on
on a KS for free using the the quota you
get in the trial so in the past is you
all used to give you just a 150 pounds a
month now they give you certain number
of resources for a whole year so you can
run one of the small VMs on the cluster
if you want for a full year to try the
Hat so let's flip over to the demo again
previously I was using Mini Cooper now
what you can do is you can set the
context so if I do get context you see
list all the contexts and one of these
is the docker
the docker tooling then I've got my is
your class and I've got mini cubes at
the moment you can see it's using mini
cube so if I say Kay config set context
whoops
I should now have switched my contact
over to communities
I guess so now if I do get notes fingers
crossed
okay so I had this problem before we
wasn't switching so enough to switch to
the come on line temporarily just a
second see not have this probably before
but it suddenly appeared today for some
reason so I'm just gonna use the zoom on
line to switch the
mr. yes
again cool ok so just scroll that up as
you can see I've got three node cluster
now to get started on this I won't run
it but it's as easy as in the KS create
and then giving you a name and giving
you a resource group and then optionally
you can specify the version you want so
for example on that and then optionally
you can say node count so you can say I
want five nodes and there's a number of
other options you can do as well
yeah that's cool I'm not going to run it
I just wanted to because I've already
created the cluster it takes about about
four or five minutes depending on how
how quick is yours deciding to work that
day so what do you now is I'm I'm going
to create the same deployment I did
before but this time I'll use the Yama
file so I'm going to create - F and then
and I'll show you this was in a minute
because I've modified them slightly okay
don't get pods if you really kind of
want to shorten you can you can say that
and then you can spend the additional
nanosecond with your liking kids so now
if i deploy the services all oops
okay
so now if I get the service more we'll
see is we've created the Lord bouncer
it's got the internal Epirus now this
pending here right now the cluster is
talking to you on is creating as your
load balancer and it's getting a public
IP address with her now that takes a few
seconds and takes power minimal - so
while that's happening I will show you
the Yama falls good question I don't
think you do this I think the center
ones free so you pay for the traffic the
egress egress traffic but you don't pay
for the LOB and so the standard load
balancer you don't pay for now so what I
want to call out is down here so I've
added health checking to this particular
file so communities is going to do HTTP
GET on this path within my container on
port 80 if it receives back status code
between two and four hundred
everything's fine
anything else steamed to be offline ill
and self-healing will kick in so I'll
show you this in a second initial delay
says how long to wait before it starts
doing this and then the period seconds
obviously health care pros for that show
you the service of there's nothing
different in the services exactly as it
was before now I mentioned the type load
balancer so by having type load balancer
exposes the service publicly now of
course you may have services which are
internal to the cluster only in which
case you would use a type plus or IP in
there and they won't get given a public
IP address on you within the cluster
it's also possible to create a service
which actually doesn't have any pods any
references an external service so let's
say you have a sequel server running
ready somewhere but you want your kind
of Yama files to reflect as if it's
within the cluster because you plan to
move it in potentially you can create a
service which will effectively proxy to
the service and your pods will behave as
if they are talking to an internal
community service and you can also
allocate public IP address if you go on
public IP vs. already you can specify in
here and it will actually set that run
and requesting one as I said this this
is
kind of more primitive load balancing
the the layer seven ingre stuff which
you won't have time to talk about is
really where the cool stuff comes in
with a lot of the layer 7 stuff you'd
expect to find so let's pop back and see
if our service is good an IP address yes
it has
glad sometimes it takes quite a while so
I was a bit nervous then so I'm gonna
close out just to avoid any confusion
and then I'll open you again
ok and then again you have that day so
now if I want you to scale this you see
one you could do it the command line
which I said you shouldn't do so I'll do
is I'm going to update the replicas in
here or is it five save that and then
what we do is we do an apply
yep ignore the warning so now if I do
get pots that's too quick so now there's
five running what I've done on this
particular service is because obviously
my code never has any bugs in here I've
deliberately created a so let me show
you the the health check so if I go to
Home Health see how okay now what I did
was I created a those of you should
rightly be shuddering that what I'm
about to do because I'm going to I'm
going to call it get method which is
going to modify the state which is
terrible thing to do but in my defense
you don't normally do you don't normally
deliberately make you cluster sick so
now if I do what should happen if I
haven't done it secretly there we are so
that particular port there kubernetes
detected that it was unhealthy and it
restarted it automatically now the way I
set it up is if it obviously I've got
multiple instances anyway so if I go
back they might get at different
instance anyway so let's make that one
sick as well try and catch you this time
so we can use a watch which should Oh
too slow it's already updated they okay
I'm putting a good time to have a quick
chat about a look at the kubernetes UI
very briefly I think I'm just gonna
break out of that so the communities you
guys running within the cluster and see
a cluster Langdon is your so they're
giving us a kind of handy shortcut to be
able to tunnel into that cluster I'll
access the when you're doing these
things it it helps to name them in a
consistent way because nearly every as
you'll see a like come on you have to
use the name of the cluster and the
resource group so that's doing out so
that will tunnel to the cluster and
they'll pop up in the communities UI I'm
not going to spend too long on the you
I'm just going to touch on a few things
so you can see you some basic kind of
memory usage you can see the deployments
here you can see there's five pods
running if I want you to scale from here
I can do that
nice thing is also if you're if you're
not so familiar with the user interface
sorry with the kind of CL I'm not that
comfortable with it and you want to have
a look at it so what you can do is you
can see the logs from the container
itself so in this case I got multiple
instances so I can flick through so I've
got a particular one misbehaving I can
pop it up and see the the logs coming
straight from the container you can see
it's just the kind of half-baked it's
been a cool application there so let's
have a quick look at doing somebody
deployments break out that so we have
for now because I scaled it down from
the UI is you noticed and that's running
v1 so just
see if I can show it no bouncing no it's
not gonna behave itself okay so I'm
gonna upgrade this so you can probably
guess what the upgrade is gonna look
like it's just full of features so what
I can actually do the upgrade directly
in the command line but I won't because
I said you shouldn't do that so what we
can do is if you go to the Yama forum
I'll update the content image division -
I save that I'll just type it out
okay so now if I'm quick with this if I
do too slowly
it's all we can do is that we're all out
I was fumbling with the keyboard so
probably too slow there and our
deployments sorry
how is it thank you
I wouldn't have seen that one come so we
can see I'll run that again soups so
that's big camera so we can see we've
got we've got two revisions there's no
change cause because the way I
implemented the update there's two
versions and I fight back to the
application I was far too slow to show
you a happening when I call VT running
now let's assume that so in this case
the health was fine if during my health
monitoring there was an issue coming
this will stop the rollout it doesn't
automatically roll back he used to do
that and they've taken a functionality
away for some reason I'm fully
understand why but in in essence he'll
stop writing up the deployment if he if
the pods come up and they're not healthy
so so let's say for example I've
discovered an issue with this version
and I went to rollback why I can do is
and I just your handi now you can't
actually specify a specific version when
a rollback - but if you just do the undo
let's try and get status I'm quick
enough yeah so it was quick enough a we
should see as it's rolling out the
update this one so without special my
version it's only rolling back to the
previous previous deployment but you can
specify particular version - chomp - if
you want and I've seen as people say
Xuan rollback shuttle was roll forward
so in getting to that debate as well
yeah that was that I think that's
everything only soy surrender
deployments yeah so speed back to the
slides so I've been talking back with
Nettie's and obviously I kind of pitched
this talk is kubernetes vadhana
developers so let's talk a little bit
don't let Microsoft in particularly so
kind of showed Microsoft is a Platinum
Partner of CN CF and they actively
contribute to the Cades project last
year they I think it was last year
actual maybe the year before they
acquired her company called Deus who
were heavily involved in the communities
space they were creating tools including
helm you may have heard of
so by querying them they kind of
expanded the in-house kubernetes team
and knowledge Brendon burns who is one
of the used to work at Google's one of
the cofounders of kubernetes works at
Microsoft and she'd own a cool kind of
works tonic on Linux works now and I
kind of touched on this before but the
Windows nodes are currently in beta and
therefore we should be able to run
Windows containers on those nodes some
point in terms of what Microsoft does
best in terms of developers is obviously
tooling depends on how you feel about
the Visual Studio I guess and something
they announced at the connect events
some of you may have seen Scott
Hanselman demo some core Visual Studio
connected environment this is in private
preview now literally gone in five four
two days are gonna haven't been able to
play with it yet but it allows
development teams to in essence have a
development cluster that they don't have
to manage so you can all have the
similar workflow without having to have
local kind of mini of your clusters
every run having local clusters so this
one here you can imagine is going to be
developed further something from
Michael's point of view so talk a bit
more about kind of donor applications
where I see where I'm kind of excited
vacuum Nettie's is you know I see a
single platform for all of our kind of
daunting applications most of us
probably have kind of legacy full domain
framework applications and maybe we're
now working with on a core as well and
really like they were having a single
platform single kind of CI CD approach
and also having a having the kind of
cluster that consistent deployment
cluster really helps when you come to
kind of breaking up your monoliths into
micro services you don't have to worry
about the plumbing that goes with that
particular challenge so the kind of
thing I envisage is a kind of donate
corn don't know being basically built
and deployed we
Tonie full-frame 'ok you're building
windows containers the Linux containers
and they're being deployed into a
hardwood cluster kubernetes will take
care of actually picking the right node
for you to run the machines and
obviously with the later Windows Server
insiders build you can actually run
Linux containers on windows so if you if
you were a company that wasn't
comfortable with linux and there are
some out there you could run entirely
windows closed if you wanted so shifting
a little bit into the conversation into
kind of why would you want to use
something like continual castration
versus pass you know you may already be
using paths of service and as you're and
various other platforms so why would you
want to switch so I think passes are are
great for simple kind of independent
services if easy to deploy the work why
why can I change it a lot of people say
the pass has a kind of vendor lock-in
problem and I'm not convinced that's
necessarily the case because most pass
platforms give you simple deployments
whether it's a web hook from okay I have
a repo whether it's a zip file
deployment so not convinced that itself
is an issue kind of container
orchestration as a service class is is
undoubtedly slightly harder to get
started and you have some ongoing
overhead of maintaining a cluster you
need to have some knowledge the cause
has a lot more scope to mature with your
application so has your needs expand you
know you've seen me deploy applications
do some basic stuff I have not had to
talk about authorization or package
management various other things that
that's that's all there when you need it
it's there but initially you don't
necessarily need it so I think the kind
of container expression is is gives a
sweet spot between Crenn infrastructure
as a service but gives you the kind of
flexibility that you get with most past
platforms so you get power water scaling
you get the self feeling you get the
deployment and roll back support so it's
coming towards the end what do you want
what do you need to be doing if you're
kind of thinking about kubernetes and
first thing I'd say is don't get sucked
into the hype now sounds strange you've
come out there and I've come all the way
from Luton to talk to you about
humanities and the first thing I'm
saying is don't get sucked in but
you've got to look at your particular
use case and you gotta understand
whether it actually fits for you now I
think it does for most people most
companies and I think it has a potential
value in certain sized organizations
where they don't necessarily have the
ops team the huge ops team that large
enterprises have where you know you're
doing maybe the the the DevOps I think I
think of ticked all the buzzword bingo
words during this talk so hope you're
following along in terms of applications
you want to be looking at kind of
developing 12 factor style applications
I think he and Cooper's probably being
down here talking about our factor if
not yeah gotta get him down if not DDD's
he's often talking about it so key
things with these are is how you're
logging and then I showed you the kind
of health checking a really important
and I think you know this some you could
start doing now because all it is is an
API endpoint it's not a difficult thing
it's not going to cost you huge amount
to implement and then it's ready for the
future
now readiness so community is also has
support of readiness which I didn't
really talk about but this is where an
application is started and it takes a
little a few seconds worse ready to
serve traffic so it could be priming
caches or something like that so you can
also define in exactly the same ways we
have the health check you can have a
readiness check a criminal probe that
until it's ready then your saw sending
it traffic so terms of your kind of
architecture you really want to have
your kind of architecture and
microservices house in order doesn't
mean you have to have everything ready
and working you need to have an idea of
where you're going with it just because
you're going to containerize in sticking
kubernetes it's not going to solve your
monolith creaking problems you know
there's no magic here what it can do is
you can make that journey easier for you
obviously start looking at hopefully
your writing most new things now and on
a call look at migrating those things
that you can migrate off to them to to
donate core as well
see really important you have see ICD
pipelines particularly windows
containers so I do a whole talking
windows container so I can't go into
huge amount of detail here but one of
the things you've got to bear in mind
Windows containers this patch Tuesdays
means you've got to redeploy your
container you don't patch the container
like your whatever um you
to redeploy without container so you
don't want to be doing that every month
on a cheese they're saying they're
trying to redeploy definitely look I
investigate can I investigate container
rising you don't applications into
windows containers there were some
roadblocks recently and I think the last
updates removed a lot of roadblocks the
via the image size is getting smaller
and smaller so things are improving
there you know where I want them to be
right now but they're they're getting
there and again they're quickly
the final point unmake is kind of beware
of pet clusters so I've seen I think
most people have kind of bought into
these pets versus cattle so you don't
have VMs on you nurture you treat them
as cattle and you destroy them if
they're you have an issue but I'm seeing
a lot people thinking about the clusters
like there would be pets but really what
you want to do is your cluster should be
as disposable as your your VMs your
applications so some called get hops is
starting to kind of take hold a little
bit this is where you can wipe away your
production system and from a single
github push you can redeploy the whole
whole cluster and the whole environment
so that's something you want to consider
doing and that takes away some of the
concerns around well how do I pack up my
DD cluster and everything else if you're
not using manage service
it's just quickly wrapping up towards
you and now obviously in terms of
alternatives often a quick way to get
started with kind of multiple container
expression is docker swarm I haven't
used the huge amount myself but the
common pattern is that you it's great to
get started quicker than communities and
but it you can sometimes I grow it we've
got D cos for me so sphere this is a
kind of reasonably enterprise-e Big Data
Platform but it illustrates a big data
workloads using containers and then
service fabric and run containers as
well and of course if you follow the
kind of the trends in ich you know that
pretty much kubernetes is eaten all of
those up because docker now supports
kubernetes missus fear sports kubernetes
and obviously Microsoft of heavily
invested in kubernetes is all so just
summarize communities is a mature
feature a feature-rich
container orchestration platform
it's being used by many of the large
organizations and they're betting on it
as their future the window support is
gaining traction fast it's really
interesting if you follow the the all of
the work is done in Auckland they have
special interest groups who work on
different parts of the class of the of
the platform and I've seen videos where
we've had Microsoft to him
networking engineers talking about the
changes they've made to the windows
networking stack to make it work better
with kubernetes and they're sharing this
before it's been released as a Windows
Server preview so really open and of
course you know the dollar tooling is
getting easier mortgage easier you can
imagine there's a lot more to come in
that space in terms of learning more I
mentioned if you can't run a cluster on
your own machine anyway quatre coda is
awesome awesome online learning platform
it lets you basically create a cluster
in in a browser so long as you get
internet connection and then it's got
worked examples a lot of the cloud
native projects actually use including
kubernetes documentation use cata coda
to give you hands-on try me
functionality kubernetes up and running
kelsey Hightower Brendan burns and job
ADA is excellent excellent book and I
initially was hesitant about getting the
books at a while it's gonna be out today
so we think move so fast but it really
isn't a brilliant book because it covers
a fundamental so well it's it's
literally a page-turner maybe it's just
cuz I'm a huge geek but but but it's a
fantastic book and I don't think we'll
go out of date because it covers the
core concepts really well everything in
kubernetes since has been building on
top of those core concepts so gives you
a great grounding mini cubies attack
github address and then the community
documentation is fantastic as well
really detailed that's it me i blog
occasionally at addresses if you want to
see the mini cube issue on Windows
that's the place to find it that's it
any questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>