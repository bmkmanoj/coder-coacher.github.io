<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Azure SQL Database Managed Instances - Dev South Coast - April 2018 | Coder Coacher - Coaching Coders</title><meta content="Azure SQL Database Managed Instances - Dev South Coast - April 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Pusher/">Pusher</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Azure SQL Database Managed Instances - Dev South Coast - April 2018</b></h2><h5 class="post__date">2018-05-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_4gggT9PAVY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I just come along evening I appreciate
it's a lovely evening and a lot of us
would rather be down to par I'm guessing
but gave me a chance to ride the bike
over so I'm or I'm a happy man um we're
gonna be talking about as your sequel
database managed instances before we go
into the slide deck and stuff has anyone
apart from Richard and Sylvia at the
front here heard of managed instances or
seen anything about them couple of
people who here's using Azure sequel
database at the moment right it's
basically the same thing right
presentation done let's go no we'll
cover what they are and how they differ
but they're built on the same technology
so we'll have a look at that one there a
little bit about me my name is John
Martin I'm a product manager for a
company called century one we're an ISV
we build monitoring software and stuff
like that and I'll give a license to
give away tonight if the swag ometer is
working and stuff only this time I hope
I don't win the license like I did last
time I gave one away mug soft dated
platform MVP working with data platform
in one form or another for well over a
decade now started off writing DTS and
reporting services reports back in
sequel 2000 done time as a sequel day of
VI developer I'm now a reformed DBA
prior to joining sentry I used to work
for Microsoft as a premier field
engineer based out of the UK I'm also
director at large for Amir for an
organization called Pass which is a
professional association a sequel server
basically a an organization that puts on
conferences helps run events and things
like that about data platform
technologies be it relational
non-relational as your AWS whatever keep
an eye out of stuff contact details are
down the bottom here so please feel free
to tweet at me email we read stuff I
blog about I've also blog at some a
website called MS sequel tips one of the
demos are going to do towards the end
all the code is up there and my blog
post which went live today in convenient
so that's cool yeah
I'm just retasking a deck from work so
what is banish'd instance it's a new
platform as a service offering that's
obvious
as I said it's built on top of as your
single database well rather not built on
top of it's another flavor thereof okay
we've got Azure sequel database the
singletons so you spin up her as your
sequel server then an azure sequel
database you've got as your sequel
database elastic pools which is
essentially allows you to group a bunch
of them together and get better
utilization across the field when you're
using I just sequel databases so you're
paying for less throughput and then
you're basically looking at seasonality
in your workloads through the course of
a day that's how we leverage elastic
pools now Microsoft have added managed
instance the reason they've done this is
because there are a large number of
blockers for migrating an existing
on-premises workload existing
application databases things like that
to our sequel database quite simply
there are a number of restrictions
around the functionality of the platform
such as I'm gonna say you can't do cross
database queries you can't do three-part
name queries in the traditional sense of
the manner so you can't say select star
from database schema dot table can't do
that an agile sequel database okay there
is something called elastic query which
allows you to create what I refer to as
external tables essentially you create
database scope credentials and you you
log in to the other databases
you've got no no sense of the instance
like we do with your retail sequel
server environments that's where this
comes in it fills an awful lot of those
gaps in capability okay making it a lot
easier if you want to get if you've got
old servers you've got old versions of
sequel that are being retired by
Microsoft then it's simply a case of
okay maybe we can do this and stick our
apps in a VM deploy to App Service
things like that okay but the important
thing to understand here is it is as
your sequel database okay what that
means is you're running on essentially V
next all the time
it's got the latest bits there's no
updates no infrastructure that type of
thing
okay which brings us onto the question
I've been asked a lot is it really past
because you're saying an instance yes
because when you look at it your
unselect a tout version it's as your
sequel database now this is a fun one
the version numbers between sequel bed
database and retail sequel server two
different things they diverged a long
time ago okay so when you run select a
top version and tells you a v12 database
it's not talking sequel server 2014 okay
about four or five years ago Microsoft
retired the original form of Azure
sequel database and replaced it with
what they refer to as a v12 database
type okay so yeah there's been a lot of
discussion online and in various groups
or members of but it says 12 that means
14 No okay you go to a database you run
exactly the same command you'll see
exactly the same version numbers you may
see slightly higher on managed instance
at the moment because it's still running
through public preview but it is how's
your sequel database under the hood okay
so yeah don't worry if you do that and
you see 12 is the latest bits it's got
all of the latest capabilities of the
sequel server 2016-2017 has from an
engine perspective plus a whole bunch
more when it comes to the
programmability in the surface area okay
but yeah it is pass essentially what
that means is no OS to manage okay now
Microsoft are expanding the OS footprint
for sequel server retail to Linux which
allows us to use it in things like
docker containers and what-have-you but
it still runs on Windows operating
systems still need mean need to be
maintained no sequel server patching
Microsoft have gone away from service
packs quite simply they're now running
on a much much more frequent cadence of
pretty much every 60 ish days they're
dropping a cumulative update now the
reason that Microsoft are doing that is
because they're running as your sequel
database and they're starting to feel
the pain that we felt for a very long
time so it's in their best interest to
actually fix this now so the retail side
of things is reaping the benefits of it
but it does come with a big
administrative overhead that's not there
because you get that continuous
deployment capability the Microsoft are
running with the Azure platform when
they bundle all the fixes up they go
high availability disaster recovery
built-in built-in this is a fun one
under the hood because it's actually
will database you've got multiple
replicas of the data ok multiple
databases it sits on top of and will
cover the storage later but essentially
it sits on top of Azure storage which is
a nice replicated storage they run a
huge amount of consistency checking and
everything under the hood so again that
tends to alleviate things like the need
to run check DB which is database
consistency checking identifying
corruption I'm sort of doing a lot of
this in the background ok the high
availability yeah I can only talk about
the general-purpose variant at the
moment because that's the one that's in
public preview there is another variant
called business critical but that's all
I can say at the moment because they
made me sign some paperwork but
essentially it's built on top of the
Azure storage and it's multiple replicas
and they just the hive able to compute
fails it brings another bit on line if
the storage fails it just swaps out in
the background ok so there's a lot going
on there
that we don't need to worry about
anymore building highly available data
platform solutions it's the joys of
platforms of service ok lost recovery
they do the backups for you as per as
you see with database and you've also
got the ability to than leverage long
term retention for up to ten years if
you configure it small tangent if you do
initially goes for Azure sequel database
as well if you set up long term
retention delete the backups in long
term retention storage before you delete
the database because if you do it you
essentially often the storage in it's a
real pain in the backside to go and find
you end up still paying for it because
it's still there
delete the storage or delete the backups
first then delete the database otherwise
it cost you money so now we start
thinking about okay well we're a
Microsoft taking a city is it the
equivalent of RDS well kind of ok RDS is
a halfway house between managed instance
and as your sequel database from a
functionality perspective ok the big
differences here are the Amazon are
running there's on the retail variant of
sequel server so all they've got
available to them
they're running up VMs in the background
and underneath there essentially
abstracting that off okay so you have
got the ability to from a compatibility
perspective you've got the options
they're going fourteen sixteen seventeen
and deploying that under RDS so two
depends on the applications you're going
to be running as to whether or not you
can leverage that whereas as your sequel
database we're going to be running on
the very latest builds it's continually
updated in the background you do have
compatibility mode compatibility mode is
all about how the engine will handle
interpret and execute your T sequel okay
depending on which compatibility mode
you have in place any given point in
time you may see different behaviors
most notable are some of the DMV's so a
good example is back in the 2008
compatibility modes if you nest things
like the the DB ID function into the
index physical stats management function
it won't work because that doesn't for
some really bizarre reason the database
ID function just doesn't work when you
nest it bring it up to 2012
compatibility mode works a treat okay
that's what compatibility mode is you do
deal with retail sequel server
on-premises VMs things like that it
doesn't mean you're running in a
database at a lower level and and take
it back it's all about how the engine
interprets the the T sequel from an
authentication perspective both of them
have sequel server authentication
capabilities okay
both of them have Directory Integration
RDS uses Amazon's Active Directory
Integration mechanisms which in my
experience is not the easiest thing to
set up if you start looking a building
hybrid environment so if you're working
with an on-premise estate at this point
in time where you're going to Enterprise
Active Directory and things like that
and you want to facilitate single
sign-on through the applications it can
be a bit of a pain in the butt to set up
conversely as your Active Directory
really easy to set up but unless you've
engineered your applications to leverage
it it goes down the pan you can't fire
up say a Windows service so for example
if you take a standard off-the-shelf is
any apps such as
we're running as a Windows service we
haven't yet architected than the ability
to authenticate against Azure Active
Directory so if you're running as a
Windows service where the windows use
Windows user on a virtual machine that's
connected to do traditional Active
Directory if we try to authenticate
against as your active sorry Azure
Active Directory via managed instance it
will fail because the protocols and the
API is are different okay Microsoft has
released preview I think the term is now
dotnet for seven - I don't think it's
gone GA yet but that has a number or
four starts got a number of fixes in and
around the Microsoft data platform
components that it's built into but also
they've enhanced the capabilities when
it comes to making it a lot easier to
build applications that will
authenticate against Azure Active
Directory so if you are looking at doing
that for single sign-on running a
services and things like that against
now your Active Directory have a look at
daum net for 72 one of the big things
with RDS is you don't get full SI
privileges okay also whilst you have got
things like signal agent you're limited
so if you create jobs you're the only
one who sees them okay so if you want to
run your index rebuilds and stuff like
that you set it up and off you go but no
one else finds it easy to have a look at
it essentially the MS DB database is
locked down with an instance it's full
sa rights and okay you've got sis admin
privileges you can do as you need is
anyone here using RDS at the moment of
the - I can see benefits in both
depending on the type of applications
you're building if you still need a
relational engine and you want a very
fast path to building something managed
instance makes life a whole lot easier
so that's what we have now what are the
workloads essentially in Microsoft we're
really saying if it runs on retail
sequel server there's a greater than 90%
possibility that we can run it on
managed instance which takes away all
the server costs it takes away the
operating system costs
the management overhead of davin to
stack rack servers put all in that type
of thing okay there are gonna be areas
that it doesn't work as well because
it's platform-as-a-service if anyone's
using functionality like our replication
for example the moment that's not scoped
in to be full parity yet because it's
running on the azure service fabric all
of the under the hood another quick look
at the DMV's later but under the hood
there's a whole pile of applications
running on for service fabric
essentially that go into making this
service up the log readers and suchlike
are not they're full replication it can
be a subscriber for push transactional
replication subscriptions but it can't
be pull subscriptions you can't set up
as a distributor and you can't set it up
as the publisher is three third-party
applications custom apps things like
that if you're running it in the engine
if you're using column store using
hackaton all those features are there
we recently architected our platform
made some changes to it now we can
monitor it now we can actually run our
database on it relatively simple
modifications to make okay I think it
took us maybe we'll took us one and a
half Sprint's to get all of the work
done and a Sprint's or two weeks long so
we did that got everything pushed the
release everything was good I was happy
anyway cloud migration hybrid
deployments is really gunning for the
enterprise for this one if you're
building cloud borne applications from
the outset if you're going to use
relational as your sequel database
singleton or elastic pools is probably
the best way to go so long as you're
familiar with that if you're not
familiar with that particular one yet
you can look at doing this there is no
direct migration path so you can't take
the database and just say actually move
it to to an addressable database even
though it's the same platform under the
hood you've got to essentially do the
whole generate a backpack or spit the
schema route or use any of them
agression services to take it from one
service the other okay there are a lot
of requests for them to add that
capability of a push button move it so
fingers crossed
that'll come across
so coming back to your question earlier
about agent jobs agent is their
full-blown sequel agent including
database mail if you've got an external
SMTP server such as office 365 Google
things like that you set the DB mail up
we have the same functionality that they
have on print but yeah full sequel
server agent there are certain
restrictions around the job types
you haven't got command exec because
there's no command line there anymore
because you're not running on a
traditional operating system but a lot
of other ones there the integration
services and stuff like that because it
will work with some of the other
platforms of service offerings in and
around ADF integration services in the
cloud which is courtesy of Azure data
factory and things like that you input
the integration services catalog on
managed instance and stuff like that
CDC change tracking we've got access to
those now never had them for out before
the big one here across database queries
native three part names because you're
in the context of an instance it knows
that there's multiple databases in this
collection so yeah so long as you've got
the the traditional login and user
configurations to allow you to see in
interact with those databases yeah you
can build queries that are do CrossFit
across a database of queries so joining
data from database is one into two and
three it's not a design pattern I like
because it's a real nightmare to manage
and migrate databases if you ever have
to scale things out but there's an awful
lot of it out there best one I ever had
to deal with was working for a company
where that we had it was an access front
end for sequel server back-end it's
about a hundred and something databases
one database which had about 50 tables
and then 100 and something views into
all of these other databases doing
three-point that's bad because when I
had to move that there was an auto took
me six months to move a database had to
re-architect a whole pile of it linked
servers are in okay link servers just
means that we can access things at the
moment that's restricted to other
managed instances and other sequel
servers retail sequel servers running in
VMs on pram if you've got the networking
place which will jump over service
broker which is essentially service
broker within the instance inter instant
service broker doesn't function yet
they've got it slated at some point
deliver the big one here though is V net
deployment so one of the biggest issues
for enterprises that they had and also
many many other people when they were
building applications in Asia was the
endpoint is always a publicly
addressable endpoint it has to be unique
okay what that means is when you go to
set the permissions up you can say I
want to restrict it so that only these
IP addresses are able to come in or
other Azure services and there's a tick
box for that one that other Azure
services tick box basically means any
Azure service whether it's in your
subscription or not so if someone got
the credentials the login so the server
name and database name user name
password from other serve other
subscriptions they've got full access to
it okay be very careful with that one
now what myself did was with manage
instances the the managed instance
entity that you create in the azure
portal and the azure platform is
deployed onto a V net so this is a
virtual network subnet segment okay
there is no public IP address a public
endpoint so that locks that down but
what that does mean is your applications
have got to be able to connect and
Traverse to that V net now there are
various different service endpoint
options available so if you're running
blob storage a sequel database you can
put them onto V Nets now through the
service endpoints additionally with app
service there is a container solution
essentially that will allow you to
basically come in through the networking
portion there so if you are deploying
directly to app service in the platforms
of service offering you can get that
networking into the V net and not have
to traverse the public Internet if for
whatever reason you do want a publicly
available endpoint you're going to have
to look at third-party solutions in the
azure
marketplace essentially looking at Kemp
f5 barracuda
they've all got virtual appliances that
will be firewalls web application
firewalls load balancers all of that
sort of stuff and they're a lot more
secure than just trying to sort of hack
it open with something like RS server on
Windows and stuff like that way you've
got public endpoints and stuff like that
set up the device then it'll give you
full access control allow you to do TLS
and all that sort of connection level
authentication I'm sorry a connection
level encryption then make life a lot
easier we also have the ability to take
native backups so we can run a backup
database command but it's copy only and
we can push out a blob store the reason
for that is because if you want to
migrate them between managed instances
you're gonna take a backup and restore
from blob store file layout as well
now with Azure sequel database that's it
you deploy the database everything is
managed for you storage tier the works
okay here we've actually got the ability
to manage file groups and files so you
can spread your data out you basically
partition it as you need you can say
actually I'm going to put all of this
data for 2016 into this file group and
these files and what have you okay so
you've got that versatility that becomes
very very important because when you
come on to hit next no thank you
no public endpoint what she said but it
leverages Azure storage
okay premium storage what this means is
the under the hood you've essentially
got some region of 200 as your premium
disks now they are P 10 through 70 if
you look I think I've got it in the
slide deck as a link which I'll put up
online but essentially the size of the
file or some rather the size of the disk
will dictate how much I owe you get
through the Azure platform ok so the
larger the disk the more throughput you
get both in AI ops and megabytes per
second basically most often
making an assumption that the bigger the
database the more you're gonna interact
with it or the bigger the storage so
what this means is because you've got
access to the database files with
managed instance you can just basically
bloat them up with empty space okay
make them big which means if you bump
them up to say terabytes size files what
that means is you'll then get the p70
disk which has got all of the throughput
even though you've got a very small
amount of data in those data files
you've got the full capability of the
azure storage platform available to you
storage is pretty cheap okay as far as I
was concerned when you think if you want
to bump it up if you got one database at
the moment 120 gig you just turn into a
terabyte size file you'll be paying
maybe a couple of pounds more a month
okay but the capability and throughput
you get is worth way more than that okay
business critical instances this is
about all I can say about them at the
moment but they use local storage on SSD
okay local to the compute another
benefit coming back to the no public
endpoint piece and the fact we're
deploying onto V Nets means that you've
got a lot more control if you are
working from an office environment and
things like that you can establish a
site-to-site VPN which means the traffic
between you and azure is encrypted
whereas previously with Azure sequel
database singleton elastic pools you're
going over the public endpoint yes it'll
be doing TLS encryption on the
connection between your app and what's
up there but this just gives you that
added protection do you know where it's
going okay you know the route that is
taking likewise if you've got very deep
pockets you can buy Express route which
is the high speed low latency high
bandwidth MPLS capabilities that
essentially you peer into the azure
network fabrics so over here it's BT I
think that provides that capability
essentially you say here's a huge wedge
of money give me a very big pipe to
Azure
if you got the vast quantities of data
to do
have a look at it now one of the fun
things is we think about migrating
database and we'll talk about in the
back half of the presentation ma'am if
you don't have to go down the route of
Azure Express route or you don't have to
go for VPN and wait for weeks you can
put stuff on to USB disks and ship it to
Microsoft essentially you bit lock of
the debit lock of the drives you put all
the stuff you want on them you ship them
to the data center and then they put it
into an azure blob store account for you
so there are ways around it if you don't
want to spend lots of money on
networking any questions so far
okay let's try a quick demo so what we
have here is managed instances so we
think about the azure portal anyone here
use Azure at all for anything
essentially what we now have is managed
instances as an option here that we can
use for creating as a service okay so
nice and happy when we create them at
the moment this is what we see managed
instance still the standard behavior for
a shoe you've got to build the resource
group you put it in the resource group
and most of the other stuff is managed
for you so we've got West Europe is
where I'm storing it and which
subscription it's in so let's jump in
and have a quick look at it from the
portal here so what we're able to see
various different options available to
us pricing tier now like I just ignore
most of fun one Microsoft changed the
way that as your sequel database is
scaled and build okay up until about two
weeks ago you only have the option to
run what they refer to as DTU database
throughput unit which is a magical
number that they calculate based around
how much I owe so log i/o data i/o and
CPU you're using okay managed instance
when that was introduced into public
preview essentially gives us the ability
to say
how many virtual cause we want and how
much storage we want okay so it's more
akin so we know that we're running
sequel server on a machine that's got
four cores and that much storage that's
how they're trying to ease that burden
of migration and scaling it and picking
the right sort of size because dtu's
it's like wall during a basic a standard
or a premium and then within each of
those how big do I go and the top NP
databases you're talking upwards of
$10,000 a month so it's important
they're so management's brought in V
cause they've actually brought that and
now down into as your sequel database
itself as well so you've got both the
hype you've got the dtu's and V cause as
an option when it comes to creating
house you see the databases my suspicion
is that dtu's is going to go the way the
dodo and we're gonna be sticking with V
course so just be aware of that one but
we have got the ability to scale up and
down as needed
okay at the moment we've got limited
capabilities here because we're still in
preview but one of the key ones here
that's worth thinking about is the joys
of platform-as-a-service
means that Moe's got a lot of
capabilities built in okay threat
detection being one of them it's a key
part of the Azure platform because
they're looking at all of the network
traffic across the entire Azure estate
they're able to run machine learning
heuristics and things like that in the
background to look at help identifying
potential threats to your systems and
it's as simple as ticking three boxes
and saying yes turn this on for me okay
so it can do that detection is someone
trying to brute-force your account are
you liable and susceptible to sequel
injection no you try is someone trying
to do sequel injection attack against
you all of this is capability that
exists for a sequel database in
platform-as-a-service and at the tick of
a box we'll be able to sort of be
available for you to understand and get
advice from the platform okay other than
that we can see managed instance
databases here I've only got one of them
at the moment that will change later how
much CPU I'm using how big it is you'll
notice here this is the pricing tier
which is the configuration I'm using
now the size that you've got is 816 and
24v cause okay now depending on which
generation hardware you end up on
depends on how much memory you're gonna
get now the moment Microsoft has stated
that it's anywhere between 5 and 8 gigs
of ram per vehicle okay so as you scale
the system up you're gonna get an
increase in memory as well and if you're
on the Gen 5 Hardware in all likelihood
you're gonna get a bit more memory okay
at the moment I think I'm running on a
g4 I think I've got a couple of them in
subscriptions and they're on different
bits um so yeah we've got a various
different pieces to have a look at here
threat action
connections strings there's not much
here from the portal okay we can also
say how much storage we want up to 8
terabytes at the moment I'm sure that
will get larger one of the big things
that is useful those if you've got
existing on-premises licenses under si
you can tick this little box down here
and it will save you money essentially
you get license transportability so if
you paid for Software Assurance licenses
on Prem and you decommission those
servers you can basically transfer the
licensing and offset your costs so most
off of that with virtual machines and
with a couple of other options as well
so if we bring up this one a second and
then we'll break for pete's or in a
moment I think the zoom it's running
here yes it is so I've added um to
object Explorer here managed instance a
local retail sequel server instance a
national database okay now we'll
concentrate on these two because
essentially they are fundamentally the
same thing there we go
so here's my managed instance you can
see what databases node here's my retail
sequel server I've got that as well okay
and I can drill down I've got all of the
databases this
security I got logins si server objects
so endpoints linked servers all of that
sort of stuff that system databases are
all there you remember what I said
earlier about it being version 12
databases 12.0 dots 2008 okay that's not
2014 that's a v12 classical database if
we come down you'll see that the as you
see what they debase I'm connected to is
also that particular version but how
does this differ when I log into all I
get some databases and some security
settings now the reason I see all of the
database is because I've connected with
a server level account for article
database and connected to master so I've
got visibility all of those if you've
got connectivity into a single database
on a their base you see that and master
you'll also notice here that I've got an
adjustable database a data warehouse on
that particular one that's not
functionality that comes with a managed
instance that's discrete okay so whilst
you can coexist David Sigal database and
manage sequel TW on the same logical
server entity you can't do that and have
a date DW in managed instance
environment again from a security you've
got logins there you'll notice up here
we got things like credential server
roles and things like that ledge don't
exist for Ashes database but they do up
here for managed instance credentials in
Azure sequel database or at the database
level not at the logical server entity
level we've got credentials here and
managed instance because that's how we
interact with blob storage and that's
what we're going to look at in the back
half of it when we go through a
migration to face it's got built-in high
availability around data synchronization
resiliency all built through the
platform now the big issue comes when we
start thinking about things are outside
of the database and outside of the
database server logins is a real classic
one okay Network shares well we can't
get to them because we're platform
as-a-service okay
likewise age
jobs if you're dealing with things like
for example I'm using XP c'mon shell for
some bizarre reason to move things
around not gonna happen
we need to react attack those okay we
have got CLR back which we lost for a
while in Asia sequel database because of
the way that it needs to be sandboxed
and isolated and things like that - is
bringing that capability back a guy
called Yavin Popovich has got some
really good stuff up on github he's also
got some what I would consider truly
terrible things on github like building
a CLR routine that uses curl to call a
web service directly from the database
please don't do that it's the quickest
way to kill performance in the database
engine but yeah windows logins networks
file stream now this is a fun one file
stream will not work on general purpose
platform the reason being is that you
need a local storage essentially because
you're essentially dealing with network
attached storage doesn't work so if
you're using a file table file stream
also Hecate on the in memory engine
relies on file stream like capabilities
okay now when we start thinking about
these compatibility checks I mentioned
there's some scripts so you can do it
all yourself if you were fancy reading
the documentation and hoping that it's
up to date a data migration assistant
it's both a blessing and a curse
okay it was developed by a different
team and it's a command line app it's
not integrated PowerShell the fun one is
if you want to do with multiple data
pieces with it you need to feed it a
connection string a full connection
string for every database which means it
gets very verbose very quickly when
you're dealing with a large amount of
data and databases sorry okay but it is
very useful one caveat be aware if
you're using XML queries in your
database in views and still procedure
things like that
it can flag those as cross database
queries and then not I've spoken to one
of the PM's about it and Olding said
please fix this you know if it doesn't
work with adventureworks adventureworks
was familiar with it is microsoft's old
song
Apple database system it was fantastic
because it had so many things wrong with
it it actually looked representative of
what a real-world database was so yeah
it's like if it doesn't work with that
then chances are that in the real world
people are gonna be hitting this okay
and then you think about the migration
process are we going online are we going
offline
how much downtime and disruption can we
handle if we're going to take systems up
there so if you're building a brand-new
system from scratch yeah not a problem
but if you're going to take some plat
for you're gonna take a workload you're
gonna move it from one place to the
other there's always going to be that
potential for a bit of downtime okay now
where Manesh instance far exceeds the
capability of azure sequel database is
that you can take a native backup and
restore it with a restore database
command you can't do that with Azure
sequel database okay so I can basically
block backup - blobstore from my own
prem sequel server and then restore it
in but then also we've got the ability
to use backpacks and DAC packs which I
hate personally but that's just me
I find them unintuitive and difficult to
package up get them ready for deployment
and to do it in a meaningful way from a
database migration perspective from a
deployment phase yes they're great but
if I want to migrate a database no it's
gonna hurt okay there's other ways I'll
do it especially if I've got very large
databases okay
likewise if you've got very large
databases the data migration assistant
is greater auditing them it really sucks
at shifting data okay it's not very
resilient
it will script out the schema and it
will build that schema it will then
script out the data it will stream the
data in if you get an interruption in
your networking it buffs on you and then
you go to a backup star game which is
not great okay you three quarters away
through a terabyte database that could
hurt it could be men and white coats
show up and drag you off because you've
gone mad but this is where the other
options come in data migration service
now this is an azure based service okay
essentially looks to synchronize the
database
from your system not there there is a
big reliance on having V nets and in
network connectivity through VPNs for
that unfortunately though ok log
shipping is not supported yet but it's
not difficult to roll your own because
you're actually agent up there ok so
there's ways and there are means to do
it
transactional replication it can be a
push subscriber ok much like as you
sequel database can at the moment which
if which is why I'm not a huge fan of
the backpack and DAC packs because I can
just create new I don't just do a
snapshot and I can push a lot of HR
transactional replication and that's
keeping it in sync pretty well so I can
minimize downtime when it comes to doing
the cutover
but the big issue really comes around
online offline migration is the
application and everything surrounds the
database itself
where are they how do they connect how
do you control how do you repoint them
is it a massive web farm things like
that is a whole pile of people with fat
clients on their laptops and stuff like
that that connects directly to the
database ok there's all things that you
need to consider when we start moving to
and basically hosted solutions it's all
about connectivity now we think about
migrating them as I said earlier what
we'll do is we'll create our Azure
subscription ok I've got two sites here
one and two
first different sequel server solutions
and application servers them so I'll
create our I create a V now I've got a
resource group all set up I create my
managed instance essentially ok I create
some Azure blob storage accounts create
some containers now because I'm feeling
a bit flush with cash
I've gone out and bought myself an
express route
got my other site and I've not gotten so
much money now so I'm doing a
site-to-site VPN so here we've got two
different options now big difference
between Express route and site to site
VPN okay by default
things like blob storage this one here
are not available over the VPN you're
going to the public endpoint even if you
create the v-net okay now what you can
do is create a service endpoint which
you map to the V net and put your base
you're linking your blob store via the
service endpoint to the V net at that
point yes we can traverse the VPN to go
here okay but it needs to be on the same
network otherwise we're going over the
public point so for every virtual
network you set up where you've got
blobstore that you want to access you're
essentially needing to create VPN or
peer then networks together so you've
got that consistent link Express route
everything that travels over Express
route to Asha is on a private link okay
so what we're gonna do is I'm going to
move some databases because I'm an
old-school DBA I like backing things up
and restoring them back up those four
databases and then there's simply
restore them and I'm gonna move my app
service because I'm on a VPN link it may
be a higher latency
okay and my application may be very
sensitive to that latency so I want the
application servers close to the
databases as your virtual machines the
services we push your button lift it
shift it don't deploy the applications
to it all that sort of stuff okay now I
can make those servers go away now if
they were running something like an
availability group we're talking
Enterprise Edition typically which is
tens of thousands of pounds so if I
bought them on SA I can tick the box and
I can offset my costs up in the managed
instance but also when renewals come
round
I'm not sat there with sixteen thirty
thirty-two whatever cause of enterprise
I need to pay for again cost comes down
don't have to renew the hardware don't
have to renew the OS all that sort of
stuff I moved some more databases
backup/restore move the VM now I've got
a much smaller footprint here online on
my site that means I'm paying less
energy I'm paying less electricity for
the servers I'm paying less cooling so
there's a number of other intangible
cost savings as well that you're gonna
see by taking this stuff and sticking in
there but that's offset by you now
you're paying monthly subscriptions up
here if you're going to do this type of
thing it's very very important to
optimize the performance of your code
both in the application and the data
tier okay basically if you can tune that
query down and use less resources you
can actually scale platforms down okay
you can get more in there and more bang
for your buck okay performance tuning is
going to be key when you start looking
at using cloud systems rather than your
traditional sort of Rackspace kolos and
things like that where you've got a
whole server I mean how many people here
at the moment consistently run their own
premises hardware at about 80% CPU
utilization and sort of equivalent for
memory normally we sort of freak out
when we see it that don't we but that's
when we've had to buy that and scope it
in for five years we buy with plenty of
headroom okay you need to switch that
thinking around when it comes to dealing
with platforms a service infrastructure
as a service you want to be running that
kit hot ok you want as little Headroom
as you can get away with because all of
that extra Headroom is going to cost you
money ok
running at 80% CPU is great if you know
that you're going to burst another 10
percent up to 90 but then you've also
bills you've actually it's coming up the
holiday season we're a retailer it's
going to be Easter actually I can afford
a couple minutes downtime to turn that
vp8 over that VM or that managed
instance or that has your sequel
database I can actually increase the
scale of it and we'll just run it bigger
version for the next month and then
we'll turn it down again so the big
benefit is just be aware of the
workloads you're moving
and how efficient they are if the
workload is not efficient you
potentially gonna cost yourself more
money yes yeah because everything in in
Azure is scriptable yeah so we've got
part of our software monitors as your
sequel data warehouse as your sequel
data warehouse is inordinately expensive
you don't leave it sat there twiddling
its thumbs we use Azure automation with
the run books to actually turn it off
well basically make a check are you off
are you off are you off are you off and
we do that every sort of four hours or
so once it's outside of the business day
that we have as a business doesn't
matter BAM it's going down okay
if you're doing stuff you just got to go
- automation and say paws otherwise you
be in the middle of something like a
demo and then gone but there is the
facility to automate those things there
is also the ability to have building
feedback loops essentially to say
actually I'm running really hot now
certain services in our show not
typically the data platform services but
typically the app servers and things
like that the app services you can say
scale give me extra rather give me extra
nodes so if you're using stateless
environments without your container
services as I could be native services
you can just fire in say give me an
extra six replicas okay yeah you're
essentially using the you're pulling the
data from all you've got a rest n rest
api s-- which you can pull metric data
from but you're so you can interact with
as well so you can either write
powershell scripts do it the azure CLI
you can go through the REST API s as
well you can build your own little very
basic web page app and things like that
to give you that capability it's very
very extensible that platform
unfortunately when you do some of the
stuff with the data platform because of
the way that it does things are
especially without things like hey
where's dB
essentially it will sever all the
connections do the scaling and then
you've got to reconnect
which is why Microsoft suggests if
you're going to be doing stuff with
managed instance I just equal database
DW any of these relational technologies
where you're able to use the dotnet
libraries they've actually got methods
and functions and everything in there
that help you build resilient
connectivity so essentially if there is
an interruption for those native
capabilities in there that you can
leverage to say actually let's do some
retry logic so back off give it a minute
try again
back off try again back and you build
that sort of capability in there just
simply because it's somebody else's
hardware in somebody else's data center
over a network link that's not mine you
know that's the perfect storm for if Joe
Bloggs with this JCB digs up the road
and your applications around boom
someone forgets to renew a stiff occur
on your service provider they will go
down things like that a good example as
well and this is something when it comes
to to these sorts of systems I'm showing
often a little bit of a tangent here if
you are planning on taking workloads to
the cloud be they relation will be there
anything architect them from multiple
regions ok last last year early last
year maybe the late in the year before I
forget Amazon had a big s3 outage on the
East Coast the US it became very
apparent very quickly who built their
entire service in to leverages resources
in that one region even Amazon's Status
page didn't work because all the images
that said no it's broken were hosted an
s3 service in the failed data center the
cloud fails
quite simply it's still running on
hardware it's still mechanical care it
will fail there's people in the loop a
lot less now than the would be but
there's still people there there's still
processes things break Architect it if a
whole cloud goes down that's an
exceptional scenario but typically if
you build for multiple regions you're
going to be protecting yourself against
a lot of fat
a lot of these data services here manage
the instance and you see will database
things like that you can set up geo
redundancy or you will be able to set up
Ryoji redundancy very few clicks of the
mouse in the portal or a couple of
scripts which will give you if if Dublin
goes down go to Durham
go to Amsterdam if you're in the UK if
Cardiff goes down go to one of the other
ones that sort of thing okay be very
important when think about that one now
I've got those database I've moved from
my other site I'll get rid of that so
because I've got Express route and
because I've got very low latency I can
leave my app servers there one of the
important things to understand in that
sort of scenario if you're going to
build hybrid solutions or even if you're
building multi-region solutions if
you're not using the native data
transfer between regions in Azure you
get charged for data egress if you're
building hybrid solutions with
on-premises components and cloud
components you will be charged for data
egress ingress is free why put a barrier
between you putting data into their
services but you want it back that's
where you're gonna get charged some
money it's not ridiculous money but it
is still a cost overhead if you've got
very chatty applications just be aware
of that so the question is if I've got
my web app on my database talking to
each other and as you're doing it
charged if they're in the same region
okay
no if I had one announcer this an
Amsterdam and Myra database in Dublin
yes I'm gonna be charged for the data
that leaves Dublin to go to Amsterdam
and the data that gets child leaving
Amsterdam to go to Dublin the costs in
reality are relatively small unless
you're dealing with vast quantities of
data don't do what someone did which was
put multiple terabytes of data into
Hadoop in Europe and have your power bi
tenant in America and then get a
six-figure sum at the end of the month
which Microsoft went yeah you didn't
want to do that we'll write this off and
we'll move you Tennant for you so yeah
Michael can be nice but yeah it's all
cool database for migration service I
touched on this briefly earlier
it's a fully managed service you've got
a provision it in as you under the hood
there's a couple of vm's and things like
that so it is a service you get charged
for does rely on VPN connectivity
directly to the Vee nets ok so again
you'll think about how you're gonna do
the migration what's gonna have access
it can everything talk to each other
essentially you're not dealing with a
gateway service that everything runs
through you need that full connectivity
for access to the Vee nets for it to do
the the bits it needs to do now once
we've got our databases somewhere that's
only half the story
migration of everything outside of the
database then becomes key for us now if
we're dealing with Active Directory
connectivity on-premises and we've got
everything set up and my applications
use as your Active Directory I've got
them set up and it all works fine one of
the big things that you need to do is
make sure that Active Directory is
synchronizing to Azure for a start
throughout your Active Directory through
the ad Connect tool very easy to set up
next next next next next done as per
Microsoft Wizards what happens though
when it moves a rather copies those
logins and entities from on-premise this
Active Directory to Azure Active
Directory the SID the security
identifier will change okay
the said in the azure tenant will be
different to the one on premises okay
now traditionally one of the the issues
you've had when you've moved databases
between servers and it's been
predominantly for sequel logins is when
you create a sequel log in it creates a
SID unique to the server so if you've
ever run mirroring log shipping
availability groups things like that
with sequel logins it's not simple case
of creating this a log in on the other
side of the same username password
because the security identifies that
link the log in at the server level to
the user in the database will not match
which means the authentication will fail
so what you need to do is either now
there are the store procedures out there
and code out there which will allow you
to script out
logins with the password hash and the
CID which means you can take that and
then just use a create login statement
with the CID with the password hash and
that will push in and then the lineup
alternatively alter user for login but
and that will align them again there is
also a powershell anyone who's dealing
with sequel server in any way shape or
form there is a powershell come module
called DBA tools okay it's an
open-source one up on github use that
it's got a huge number of very useful
command it's in there for doing just
that sort of thing migrating jobs
migrating logins migrating linked
servers migrating credentials all of
these server scoped elements which means
you can automate it because it's all
done in PowerShell doing it with T
sequel is a freaking nightmare it's not
that's not what is really designed for
TB sequel is really designed for DML and
DDA so day two different emulation
language data definition language doing
stuff in the databases administering the
server was just a well we've got to do
something we might as well use T sequel
for it because that's what the guys are
scripting in the powershots other things
uses s mo makes life a lot easier but
you're responsible for all of this stuff
it doesn't go with the database just
make sure that's another point in the
migration process the migration as we
said it leverages backup to URL now this
capability came in with sequel server
2012 cu3 but essentially you can Bob
back up directly to an azure blobstore
container from the sequel server okay
really nice and easy you just need to
create a credential in sequel after you
setup the blobstore component and then
it just treats it like another back
application if you've got lot if you're
very large databases spread out to
multiple backup files you'll see better
throughput it depends on how big your
bandwidth is really but large databases
I mean if you're dealing with tens of
gigabytes you just gotta think about how
how easy is it to upload one large
database file ok versus well let's break
that down into three or four different
streams so we're dealing with smaller
files you higher utilize a
don't do it in the middle of the day
when everyone's watching cat videos
because you'll still have no bandwidth
and also you have very unhappy people
because they can't watch their cat
videos because you just saturated it
with a hundred gig database backup one
of the other things as well make sure
you use compression compression
capabilities natively built into sequel
server it will compress it before it
sends the data okay so you'll be sending
less up there less on the wire makes it
a little bit quicker but multiple files
will see better utilization of the
network resources you have available
likewise if your bottleneck if you if
your VMs all in as you and you're doing
that sort of backup service there you've
got higher amounts and large amounts of
bandwidth you're probably going to
bottleneck on the azure storage so
multiple storage accounts just scale out
okay if you're using right back up to
URL requires credentials create at the
server level if you're using 2012-2014
there's a specific syntax for the
creation of the credential if you're
using twenty sixteen or seventeen it's a
different syntax when different
functionality and we'll have a quick
look at those in a moment and we get to
it reduce your cost if you've got sa
don't forget to tick the box and don't
forget the decommission your service
because it will save you money now
one thing I haven't covered here and we
will talk about briefly is workload
analysis there are some tools available
okay I am a huge fan of a tool set
called our ml utilities I don't know if
anyone's heard of this basically our ml
is replaying markup language is a free
tool set from Microsoft okay in the same
vein as PS s diox equal diag nexus and
that sort of toolset but essentially our
ml utilities contains four applications
you've got retrace
so when you take a either an extended
events trace or a sequel trace retrace
does exactly that
it reads it and your two options here
one
you can have it push all of the metrics
and telemetry data it discovers through
reading that trace into a database or
you can also get work and/or you can get
it to create our ml files which are then
used by a tool in that suite called Oh
stress which will read the our ml and
basically replay the workload so what it
allows you to do is take a backup a
database restore it but when you're
taking the backup you're capturing the
trace turn it our ml and then I can
replay that exact workload into the
database on the new platform and you
server okay if you've got if you want to
simulate multiple clients there's also a
tool in there called Orca which
essentially is an Orchestrator for Oh
stress and you can either run it in a
stress mode or you can run it in a
replay mode which means I actually I
want to maintain the timings as best I
can and the intricacies are over maybe
say a client's so eight instances of Oh
stress will have the workload
distributed amongst them and they'll all
interact with the database and then
there's a reporter application which
reads the database that retrace creates
one of the launches this is if you're
going to do the whole capture a workload
turn it into our ml and replay it
capture it again there what you can do
is then use retrace to read the second
one into another database and the
reporter tool can actually do a
comparison between the two straight out
of the bat saves you having to write all
your own queries next life will be
easier I am a huge fan of our ml if
anyone suggest you use distributed
replay that came between 12 laughs of
them because a the controller costs you
money you need a full sequel license of
the controller and B it is inordinately
complex and a pain in the backside to
setup okay so those the key things I'd
have a look at from that side now let's
try to migrate some databases what I've
got here is a very basic little
application that we use called
sequel spoof essentially it's a very
very basic application that runs a bunch
of queries for us now I've got three
databases currently sat on my sequel
server
okay
it's art disconnect son what I've got
here are three little sales databases
essentially sales archive sales data
Marcel sandbox
that's the sequel spoof database that
you see at the bottom is the one that's
got all my queries in it essentially
okay I've got a bunch of logins my boss
who wrote this is a big Avengers fan so
what do we need to do well we need to
get all of these database well these
three databases and the logins up to my
managed instance those who direct the
application basically so that's what I'm
gonna try and do emphasis on the try so
let's see let me just double check I've
cleared all the things I need to clear
make sure I've got everything removed
yep okay so we should be good to go
now let's start can everybody read that
okay okay so I logged into my asia
account
earlier when i was copying and pasting
passwords so since you want me to do
here is i'm just going to set a bunch of
perhaps now this says ms equal tips
because that's where my blog post is and
that's where you can get all the code
i'm about to run along with uh basically
a step through guide
okay so resource group i need to create
one of those need to create storage
accounts storage can't type standard
locally redundant storage what that
stands for okay you can have geo
redundant zone redundant g-- redundant
read-only as well okay the more
redundant and the further apart it is
and the more on line it is the more
money it's going to cost you also there
are two different types of storage
account at the moment and we take a
slight tangent on the azure platform but
you've got general-purpose storage and
general purpose of v2 general purpose
storage is more expensive for data at
rest but less expensive when you're
interacting with it v2 is less expensive
at rest more expensive when you're
interacting with it just bear that in
mind when you think about what you're
going to put on there if it's whatever
you didn't do is very chatty go with v1
if you're going to put up there and
never talk to it again v2 ok as your
region I'm gonna put it in West Europe
and that's my container name when I'm
going to create the blob storage I want
to create a container call database
backups and I need to create policy as
part of this for when I create the
shared access essentially so I'm gonna
run this one here which is create the
new resource group ok let's move this up
a bit so scroll down so I now have my
resource group now one of the things
you'll notice here is that it's got tags
it's a property
ordinarily if I was deploying this type
of thing to production I would be
tagging these resources essentially this
is a way that I can then identify those
resources very easily and quickly so
find everything with my so for example
running a certain application okay that
application has app services resource
groups databases blob storage all these
things if you tag them all with a common
property then you can easily search for
and identify those resources in the
subscription and that can actually
filter through to billing as well if
you're looking to rebuild things okay so
it's strongly recommend a good tagging
naming convention if you plan on using
Azure just makes life a little bit
easier about breaking down those
barriers and saying okay well who's
using it for what now when it comes to
deploying resources and as you deploy
them into resource groups only deploying
to that resource group something that is
within that container essentially so
I've got a bunch of my application
contains VMs as a single database some
blob storage if it's something that I'm
gonna basically tear down and redeploy
the whole thing again that's what the
resource group is for okay very very
easy to just wipe everything out and
redeploy from scratch if you need it to
persist maybe you need to break them out
into multiple resource groups okay just
think about how you're gonna logically
lay things out because you might want to
burn an entire resource group down and
then redeploy the whole thing so you
need to think about whether it's
stateful or stateless when it comes to
what you're doing with it in the context
of them so many of your databases you'll
probably want to be stateful tearing it
down and then deploying it and rebuilt
populating all the data is not something
we typically do and this is def so I've
created my resource group now in a
create storage account and I'm gonna
create some account keys and set the
storage context this is we'll go through
the portal a minute so no highlighting
code and executing code is really not
very exciting and not very intuitive but
this is a lot quicker than me trying to
do it through the portal
percent you will create storage account
the storage account keys now because I'm
using 2017 in my VM what I need to do
what's that's doing that actually will
come across to the portal let me just
close these down storage account there
it is so I'm into my storage account
I'm just fire up resume it again so if
you're using sequel server 2012 and 2014
you need to come through to the access
Keys okay when you create the credit
I'll show you the credential T sequel
statement a minute but essentially you
will need the storage account name and
one of these two keys okay you'll need
that information to be able to put it
into the create credential statement if
you're using 2016 or above manage the
instance 2016 2017 you need to set up a
shared access signature essentially this
is a one-time code but what you can do
here is to find the types of access the
level of permissions is a lot more
granular than using it with a standard
naming keys okay you can say validity
time when's it valid from when's it
valid to restricted to inbound outbound
IP addresses things like that so it's a
full fully capable very granular
security control mechanism for granting
or restricting access to your azure blob
storage okay you can say only through
HTTPS or HTTP as well and then you
generate the the SAS key so I'll
generate one here independently as well
because it's this SAS token here that we
want whoops
okay when we take the property from that
box and take it to sequel server to use
the create credential statement this
question mark needs to disappear so if
you use the native copy bit in the end
it will copy it with a question mark and
then your statements you will create the
credential fine but all of your backup
statements will fail because it's
incorrect you make the question won't go
away and everything's good okay
so those are the two different access
mechanism depending on the version six
here if you're using prior to 2012
you're going to have to roll your own
with PowerShell okay essentially you'll
be backing up locally and then copying
the data via PowerShell is that copy or
whatever to blob storage okay
this code in my blog post as well for
that so fingers crossed this has now
done what it's supposed to yes okay
so now I need to create my container
which is done now you know the the
shared access policy and everything we
just created through the portal this is
it doing it with PowerShell set that up
so now I can create my T sequel
statements so I'll just set them into
some and then write that out to the
console actually we'll do it one at a
time so so for 2016 is this one here
create credential now the name of the
credential for 2016 and above is the
full path to the container okay with
identity you're telling it it's a shared
access signature and then you're
providing the secret as you can see
there there's no question mark on it
they weren't able to read that all right
the bomb if I'm doing it with 2012 or
2014 my statements slightly different
the credential name can be whatever you
want with identity the identity is now
the name of the storage account and the
secret again is that key that we took
from that page
okay now you can rotate these keys at
any point in time to invalidate these
credentials so someone does lose them
wipe them out okay so now I need to
create my credentials on the servers now
you'll see my very very secure password
here just simply because the password
has to be very long for managed
instances I think it's a minimum of 16
characters and I was very very tired
that day so I can use either I can use
invoke sequel command now there are I
remember I mentioned DBA tools there is
a create DBA credential command lip
however if you've not got the latest
management studio installed it won't
work I'm still working with Christy and
the team on that one to try and figure
out quite which DLL it is we need to get
hold of and pull in
because Microsoft keep changing things
so I'm going to use invoke sequel
command and I'm just going to execute
the T sequel statement I generated okay
so this is going to be on my own
premises or retail sequel server when
it's equals zero okay and then I've
selected out and said okay well there's
my so I'll set these up and then I'm
gonna create that on my managed instance
same way this time just invoke sequel
command there we go
so I've created the same credentials
which because I'm accessing the same
blob store you can create different
credentials depending on how granular
and how much you want to segment your
security now for brevity he says with a
dot dot dot basically gonna set the URL
path so there's my backup path I'm going
to pass into my backup statements and
this is an example of the powershell
commandlets from DBA tools backup DBA
databases so I'm just going to say do
these now one thing I'll say is when we
come to do the day
bass restores we can't use the the
commandments from DBA tools because
myself to change the way that the
restore command works on managed
instance okay
so the standard s mo stuff that the the
team of written doesn't work so just
back the other two up as well lost I'm
waiting for that let's nip over to the
portal briefly and then we'll come down
to containers and then there's my
container and there are my backups
backed up straight to URL okay now a
moment I need to come to my managed
instance and then archive from URL
equals and do that so what I'm gonna do
I'm gonna create three of these because
they'll make life really unpleasant for
it come back to the container and let's
just get the blob properties because
that'll give me it's full URI which
means I can come to my restore database
so archive oops
okay so we'll kick that off yep now you
can't use things like with stats for
managed instance the reason being is the
different that what Microsoft date with
mentions that they recognize that
there's going to be a potential
disconnect and disruption between my
client and the database server if I'm
doing a very large restore that can
potentially take a lot of time so what
that means is they basically
almost treated like a sort of RPC in
that as soon as I hit go it actually
sends the command so if I lose that
connection to the server the backup will
not fail it will complete because it
knows that it's in Asia the blobs in
Asia well the internet means that the
internet could have gone away so I'll
just crack on and get it done so sales
data mark restore that now the restores
may take a little bit longer and I
managed instance the reason being is
that under the hood it's actually
generating multiple replicas and
streaming all of that data down into
them as well so it's instantiating
multiple versions of the database at the
same time sandbox another thing you'll
notice that I'm not doing here can
everyone read that all right
I'm not specifying anything like with
move which ordinarily if I'm moving from
one server to another with different
storage layouts I'd need to do managed
instance just handles all of that for me
I just say just restore this and stick
the data in appropriate places on your
storage platform okay
so whilst that's doing what it's doing
let's crack on and move some databases
stuff or let's move some in users around
now you saw I had a number of logins I
need to migrate as well this is where
PowerShell comes to the fore so I'm
gonna create my credential remember
password no it's that one
no not question marks this time okay I'm
a little basically set an array of
logins I want to move now with the copy
DBA login again this is from DBA tools
you can basically say these logins this
login all logins or exclude these logins
it's highly versatile so I just run a
for each loop and off we go and I'm
gonna hope that it works well that
there's no red yet so that's always a
bonus yeah
successful so I've actually just moved
those logins across which is nice wrong
one so now if I come back to here and
then expand that out on my there we go
got more now why yeah it looks like
they're working now which is good so if
we select from servant principals here
come down we'll find Stark
okay I'm fine
Stark I figure I did something wrong
there we go
you'll notice that the SIDS lineup
they're the same Sid okay which is this
one here in the middle yes the joy is
the human eye and pattern recognition
okay so the citizens same that's the
joys of migrating if I just created if I
just create it with a standard new one
it will just create a new Sid and then
my databases won't line up and nothing
will work although at the moment my
databases aren't restored so I've run
out of time this is one of the joys of
preview services I've got most of the
way there in about 10-15 minutes so
that's not too bad but essentially all
I'd need to do then is cut back across
to my app server stop coming here update
my config file so I've migrating all my
logins and then press Start again done
okay so it can be very very quick and
easy so sorry I couldn't complete that
one for you I was being a little bit
ambitious so we go through a quick
summary really what we're looking at
here is yeah we now have another
platform as a service offering available
to us if you're migrating from one
premises it can give you a lot of value
if you're starting with cloud borne
solutions maybe not depends on how many
databases you need the architecture
you've got the type of design patterns
you're going for very high pitch
coverage which makes life a lot easier
for those are our migrating
and the migration paths that are open to
us are ones that are tried tested and
trusted backup and restore we've been
doing that forever
transactional replication is still very
very viable option for migrating
databases when you want to get them as
close as possible for minimizing
downtime log shipping backup restore
it's all available to us has anybody got
any questions
hopefully I've made you think not to you
bad it's got how to play with it one
thing I will say is you need to sign up
to the preview conditions and that can
take because someone's gonna go and tick
a box and say yes this is right because
there's big capacity issues well because
there is a huge demand for this service
it can take a little while to get
approved for the preview and then it
takes about 12 hours for an ami to
deploy because essentially you get put
into a queue and it processes through
and there's that demand for them and
limited hardware capabilities at this
point whilst we're in preview obviously
all that will disappear when we hit
product well it's not as many questions
um thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>