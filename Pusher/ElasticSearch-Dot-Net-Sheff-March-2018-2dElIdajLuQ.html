<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>ElasticSearch - Dot Net Sheff - March 2018 | Coder Coacher - Coaching Coders</title><meta content="ElasticSearch - Dot Net Sheff - March 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Pusher/">Pusher</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>ElasticSearch - Dot Net Sheff - March 2018</b></h2><h5 class="post__date">2018-03-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2dElIdajLuQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">as your search or AWS you find the same
dependency underneath them all is this
engine called leucine that I'm sure
quite a lot of people have probably
worked with for years I kind of saw it
knocking around didn't really know what
it did but it's kind of everywhere so I
took a bit of time to dig it and do some
reading and see how it works and I'm
going to just kind of explain how
something like elasticsearch would use
leucine to index documents and then run
these queries so this thing's been
around for quite a few years since about
2000 it's really enjoyable it's now part
of the Apache foundation and it's been
ported to everything like c-sharp C++
the the dotnet port leucine delay is
really stable now it's been around and
according to my book that's a little bit
out of date it it powers dig and myspace
and most impressively the the
Encyclopedia Britannica cd-rom so it
pretty much has the kiss of death for
anything that it powers but actually
bring it up to date and it is it sits
underneath all these search platforms
that you probably use like solar elastic
all their products usually seen as your
search is kind of an abstraction over
elastic search which itself uses leucine
and you know Amazon search and on those
you get built Facebook and get her
Netflix
Stack Exchange uber so you might have
used leucine in the last hour and you
know not realized it I build slight core
applications for a living which isn't as
exciting as any of those things but it
does usually scene and that's kind of
how I came into contact with it so I had
to put that in so yeah what we're going
to look at is these three queries here
it kind of looks like Google but
actually these are queries that you
could feed into Lucine and it would do
its job with them and as software
developers we probably pretty good at
using Google by now so you know some of
the more advanced features of these
searches you've probably used like the
ands and ORS and parenthesis the filters
here like we can you know within a
Google document that would just be a
field and you say query that field and
restrict it to this value there
on the bottom we've got you know
something we want we don't want to
include BrewDog so we can use - BrewDog
it's got a date range and if you notice
where we're kind of searching on pizzas
with an ass rather than pizza or ale
instead of beer but if you type tell you
these into google you'd expect it to be
treated roughly the same and there's
quite a lot going on underneath the
Lucene helps we to make sure that
happens and the biggest thing as well is
that you want that to run really fast so
when you use Google you hit search and
you just expect results to be there
straight away there's no spinner you
know the expectation for search has been
set by Google to be super fast
so what Lucene allows us to do is move
as much computation as possible to the
indexing step rather than querying and
that's kind of what I'm going to dig
into next is that the more computation
we can do when we crawl a website and
index that content or crawl the PDFs the
more computation we do there the less we
have to do when we're passing queries
and executing queries so for an example
at the top this is our bit of text on a
web page with a cool ystem with the
coolest running and cycling club in
sheffield it's just some text and in
Lucene we use analysers you know in the
dotnet port it's just a class in Java
it's just the class as well and what the
analyzer does you just feed text into it
and it token eise's it and you have
loads of control over how you want to
tokenize that text this is the most
basic analyzer that Lucene uses and it
just splits the text into into tokens
there you can see it's just wherever it
finds a whitespace it chops it up and
you know we could write that class in in
a minute or two it's really really
simple but by splitting that text into
separate terms we now don't care about
the order with which people search so
even though we've indexed the content as
Cycling Club in Sheffield I my Google
are on my earth search for Sheffield
cycling club and because we've split
that we've tokenized it using an
analyzer class we don't care what all of
those terms are added in so that's
really powerful and that that's just one
Lusine gives us
quite a few others built-in they all do
their job and you can build your own the
top one here you'll see words like the
and in and they're so common there just
be in every webpage and every PDF so
often that they don't really add any
value to our search so we can make an
analyzer class that you feed the text in
and the the set of terms it will come
out with just stripped of all the common
terms and that really helps kind of keep
the index as small as it can be the
query has to do less work because
there's less content to go over
similarly number two I might search for
Sheffield with a capital S you might use
a lowercase s we don't put the
exclamation mark on and we still want to
match that so when we're indexing this
content the middle analyzer just lower
cases everything strips out the
punctuation so that way any queries we
do we run through the same analysis
process and we don't care if it's
uppercase or lowercase it always gives
us a match which is what we want the
most interesting I think the third one
covers stem word so you can probably
guess what this is doing you've got
running runner runners ran all these
words I might say like a running club
you might say a runners club but really
the root of that word is run
so this analyzer we can just break every
word down to its to its root like
coolest you know it's just means cool
cycling just can just mean cycle so this
analyzer class we can strip words down
that way you can handle like a big
variation of queries it doesn't matter
what I type in it will break it down to
its root and always get a match and that
again allows us to handle all sorts of
queries no matter how you type these
things in and a really important one as
well is that you know I might say cool
you say best running my sake jogging and
then we know they mean the same thing
but we can build an analyzer to add
synonyms into this list of words that we
found in the document so when we index
this document when it when we add it to
the search database as it were we've
inserted synonyms so that
might search for you know cool jogging
Club you might search for best jogging
club but and they would they would all
have a match and so what we've what we
started with on the left air is this is
the text in our original document we
have the coolest running and cycling
club in Sheffield on the right hand side
is the terms that we're going to save
alongside this document in our index and
it's quite different a cool best Roden
jog cycle bike club group Sheffield
doesn't sound anything like the original
but this is what our analyzers have
extracted from that text and we've got a
much more of a robust set of terms there
so that we can handle queries like these
on the left hand side there are three
different written queries but we run
them through the analysis process and
you know I don't know who writes like
this but bestest running group in
Sheffield when you analyze that you know
we've stem best this to be best running
becomes run group Sheffield lower case
we've split the white space so it's just
terms and now we've got exact matches
with what we've saved in our index so
it's it's going to have as good a match
as the top one which is just by club
Sheffield so by indexing these documents
with analyzers things like elasticsearch
solar and all the rest of them would
work exactly the same way under the hood
we're able to power loads of different
worded queries so however you end up
bashing your search query and you'll
always get a result and it'll happen
really fast as well so that the process
of index and the documents would take a
while if you've got millions of
documents but all that crunching is
happening at indexing time so as much
thinking as you can do when you're
crawling and when you're indexing the
documents to produce really good index
terms like this means that the queries
don't really have much to do at all all
they're doing is matching the word bike
with the word bike and you know it's it
really doesn't take that much time to do
that and that's how you can get these
super super fast queries which is what
everybody wants if I use the search
engine in it
doing that I wouldn't ever use it again
so yeah these analyser classes as much
as you can use them to produce your
terms will give you fast good queries I
say the call to actions are this is
pretty much like that I only Lucene book
I think it's so boring to most people
that they don't write a lot of books on
it but I really like it recommend it and
I'm perk C on Twitter if you want to
talk about search engines I'm that guy
thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>