<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Having Your Node.js Cake and Eating It Too - LNUG - September 2017 | Coder Coacher - Coaching Coders</title><meta content="Having Your Node.js Cake and Eating It Too - LNUG - September 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Pusher/">Pusher</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Having Your Node.js Cake and Eating It Too - LNUG - September 2017</b></h2><h5 class="post__date">2018-04-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PScnvaL5VcA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you it's interesting to be back
Adam and I met up but actually at the
MIR Forum meeting earlier on in the year
and that's that's when he suggested I
give a talk so and things have developed
since then a little bit of background on
me as you can tell from the hair and so
on I've been around a bit right back to
the 1980s I mainly worked in in
healthcare started the Royal Marsden
Hospital at the cancer hospital here in
London and Surrey where we quite unusual
we developed our own applications and
and I think some of my code that I wrote
back in the 80s is still in use in the
hospital
then I became a management consultant to
Shiraz big project called the NHS wide
networking project which happened just
before the internet started to really
take off and that's when I saw this
happen I thought I want to be part of
this and since 1993 I've really
specialized in nothing else but web and
associated technologies again primarily
but not exclusively in healthcare one of
the things that I did a lot of work with
is these guys if you're in America and
you you need a blood test pathology test
and the chances are that this company
quest will do that test and your
clinician your your family doctor will
send the test request through get the
results and all the process through this
application called care 360 it's a web
application it's an AJAX application and
it runs on technology that I created and
even back in 2006 which is when it was
launched 30,000 concurrent users at peak
times gigabytes of data go into it it's
it's a huge application needs to be
highly secure you know you've got
personal information you've got medical
information you've got stuff that could
kill you
the the liabilities on this being an
American company are huge so it's kind
of scary sometimes to think that all of
this is running on technology that I
created and back in 2006 was something
called ewd
so I've been involved those with no jazz
right from almost the very beginning so
I looked it up and discovered it was
August 2010 I started dabbling with the
stuff first note point two had just come
out and as Adam said I gave one of the
talks at the inaugural meeting here l
mug in 2011 and so six years later I
want to talk about this thing here
having your cake no js' cake and eat it
so it's nothing to do with brexit having
your cake and eat it or anything like
that there's this this I think is
achievable and by the way another
indication of my age is that my laptop
you'll see doesn't have a single sticker
on it feeling very out of date so I'm
old school
very much old school so a bit of kind of
background to where I'm coming from with
this talk so nodejs
and you probably well hopefully or aware
of this you know with no JS everything
executing a single process and so you
might have thousands of users tens of
thousands of users all doing stuff
concurrently and they're all in the one
process and the way that it manages to
handle that is through these two things
non-blocking i/o and asynchronous logic
so you know the idea is that nothing
must ever block the process or
everything grinds to a halt and with
asynchronous logic you know you fire off
the request to a database or web service
and you it just carries on and it
doesn't wait for the results it carries
on moves on to the next task
and then when the results come back at
some convenient point of interruption it
can I've got the results I'll carry on
with that so no js' is effectively
server-side JavaScript but the
interesting piece of history on this is
that Ryan Dahl who hopefully all of you
are aware of Ryan Doyle he is the guy
who created nodejs back in 2009 he
wasn't actually a big JavaScript fan and
he was creating this thing he was going
to call know where he wanted everything
to be in a single process and
non-blocking i/o and so on and he did
that this
kind of environment was how the browsers
work with JavaScript and he realized
that Google at that time had open source
of the v8 engine and so he said I will
use that and I'll use JavaScript as the
programming language for this thing he
was creating so that's how really we
ended up with no js' he didn't set out
to create a server-side JavaScript
environment
now asynchronous syntax isn't unique to
- no js' it sits there in other
languages as well and non-blocking i/o
you can do it in probably most modern
languages Java Python they all have it
available and it's an ideal way of doing
stuff where you need to make parallel
requests out to to resources files
external web services and it just makes
efficient use of the resources where
it's appropriate the unique thing about
nodejs is that you have to use it right
in the others it's optional in node
you've got no option but to use
asynchronous logic the other interesting
thing about no this is something that
fascinates me because I've been involved
with all sorts of languages over the
years and in any one of those you get
real religiousness if as it were and
they'll do everything in that language
whereas even nodes greatest exponents
will always say to you there are things
that you should not do with nodejs and
these are the big big two things that
come up and there's articles you can get
up you know look do a bit of googling on
this and you'll see that these two
things always come up CPU intensive
logic a big problem with nodejs and
complex database manipulation
particularly if like me and it's the
area I specialize in and focused on
where you're wanting to do very high
level database abstractions
I'll not be talking a great deal about
that in this talk but I'll touch on it a
bit later so with CPU intensive logic
the problem here is that if some work
that one user is doing ties up the CPU
then every
else is gonna be blocked at that time
and one of the problems of cpu-intensive
logic is that it's difficult to to
determine how cpu-intensive some of the
stuff you're going to do is and some of
it is inevitable so if you're doing you
know JSON web tokens where you're
getting digest as sha-256 digest and so
on anything to do with encryption tends
to tie up the cpu pretty heavily and if
everybody is doing it then you're gonna
potentially get in trouble with with
database manipulations you can end up
with with again restrictions and and
awkwardness that is as a result of the
asynchronous logic that you're forced to
deal with and as I said the thing that I
have been working on is some very very
high level database abstractions where
you actually need chained synchronous
functions in order to create that kind
of environment if you look at at what
most newbies people coming new to to
know jazz what their concern is it's
almost always rule as asynchronous logic
I am I going to be able to get me ahead
run that and you know most people
probably do but there are some who never
really can can get to grips with the the
asynchronous logic nature of nodejs now
of course we've got this wonderful new
thing in nodejs
version eight async await and that's the
big white hope it's greatly improving
this syntax that you need for this we
can avoid all that horrible callback
hell that we used to get into and gives
you a very synchronous logic structure
and can can't I D up the way code looks
and the previous talk you know we had
all that live coding I think you saw
quite a bit of that style of logic in
there the problem with async await is
that although it helps with the syntax
it doesn't really resolve these two
other problems it doesn't deal with
nodejs concurrency so you still need to
avoid CPU intensive code you still need
to know
code that you're writing is going to be
CPU intensive and it still doesn't give
you a solution around very high-level
abstractions where you where you need
synchronous chained functions now the
usual solutions that are that are
suggested for getting around this
involve offloading CPU intensive work
and using something like RabbitMQ 0 and
Q using other languages for the database
I've seen people say you should use
Rails for example and the the downside
of that is that you then end up with
this heterogeneous environment you've
got far more moving parts you need a lot
of different skill sets and it's all
starting to get more complex
maintainability is starting to you know
lots of people involved if a problem
goes wrong where in that is it is it is
it happening so it might be interesting
to to then look at well what does lion
Dell think about all of this and as it
happens that paper that the article that
I wrote which was published I think it's
10th of August this came out not long
afterwards the end of August I don't
know if any of you have seen it if not
you should
it's a transcript of a podcast done with
Ryan Dowell which these days is a very
rare event and I thought I'd pull out
some of the things that he said in there
because they're pretty interesting so he
makes the point within a single process
should handle many requests by being
completely asynchronous and he believed
strongly at the time this is a 2009 when
he was developing no js' that that's the
way it should be but over the past
couple of years he's started to doubt
that that's the case and it turns out
he's mainly working with go now he's
moved on to go and in go they have
abstractions so even though he believes
it's still non-blocking i/o to the
developer in the kind of user land world
you don't think of those think of it in
those terms you're right
apparently synchronous logic and you've
got these green threads at the interface
between go and the operating system that
look after that and this is kind of
interesting he says I think no it is not
the best system now to use to build a
massive server web I would definitely
use go for that and honestly that's
basically the reason why he left node it
was the realization that oh you can hear
if you know Ryan dial you can hear him
say this oh actually this is not the
best server-side system ever what do I
think I want to have my cake and eat it
I actually like JavaScript I've always
liked JavaScript it fits very well with
the kind of work that that I want to do
and I think you know by the fact that
you're all here you probably all quite
like JavaScript so I don't want to use
go to do this kind of stuff I only want
to use one language
I want one skill set want one set of
moving parts I don't want all these
extra technologies I want to keep things
simple and I want to be able to use node
in a similar way actually to that way
that Ryan is describing with go where I
don't have to really think about you
know am i doing CPU intensive code if I
want to use synchronous logic I'll use
it and figure out a way of abstracting
that so that it's not my problem so the
problem with all of that comes down to
this issue of concurrency the fact that
all concurrent users in node.js share
the same process right and I started to
realize the beginning of this year that
actually Amazon Web Services have kind
of accidentally stumbled on a solution
to this and I don't think they've even
realized they've done this either and
it's this thing called aw as lambda does
anybody here used lambda as anybody few
people most of you are probably aware of
what it is if you really want to annoy
people you call it service and
strictly speaking it's it's it's what's
known as function as a service the idea
is that it's reducing you know there's
platform independence right to the to
the ultimate extreme where all you
writers functions you upload your
functions to AWS lambda and it figures
out how and where to run them you don't
know or care what the Machine it
physically runs on you just want your
function to run and you'll be charged
every time that function is invoked and
the first technology that they include
that they made available for aw there's
a double yes lambda was no js' and if
you start to examine how it actually
works you discover that when your
function is invoked it's actually
running in a private container and your
function has that container all to
itself so there's no actual competition
in that container when your function
runs with any other nodejs logic you
have that exclusively to yourself the
interesting thing is that all the
examples that you look at for AWS lambda
using nodejs still use asynchronous
api's and people even will use async
await within those functions but if you
think about it if your lambda function
really needs to be if it doesn't really
need asynchronous logic why use
asynchronous logic at all given that
you've got that container all to
yourself and going back to this issue
about these other languages that have
asynchronous logic in them Java Python
and so on for the reasons that I talked
about before if you were writing in
those languages if you didn't have to
use asynchronous logic you wouldn't do
it because it's optional
I don't know of anybody who would by
preference apart from the nodejs
community quite asynchronous logic if
they didn't have to so the question that
came to my mind then as a result was
well why should why should we be using
asynchronous logic in lambda functions
if we don't need to and I think it's
partly for two reasons one is well
that's what you do in nodejs right
that's what we do is a synchronous logic
so wide rock the boat if you don't you
know we'll stick to that but I think
mainly it's because of the nature of
node there aren't any synchronous api's
for example for a database access and so
on they just aren't out there because if
they'd never been needed now such api's
are possible there's one here in fact
the author is sat at the back there
Chris something called TCP net X it
provides a synchronous connector TCP
connector and you could use this to
create a synchronous API for accessing a
database or files or whatever within
your lambda functions and in fact
there's one such one here that chris has
done for MongoDB it just provides a
synchronous connector for longer DB so
it's perfectly possible to create these
things
so that's lambda but not everybody will
want to use lambda for everything they
want so the question then I had was well
would it be possible to create something
similar running in your own server in
your own local environment that would
create a similarly isolated container
for the functions that you want to run
within your nodejs environment so
removing concurrency as an issue so for
the past six years I've been working up
to this product here called QJ s I've
developed it along with a number of
customers and so on it's all open source
that's out there and it's based on these
principles
of being able to have a an isolated
runtime container so what I wanted to
explain a bit about was was how it
actually works and how it becomes
possible so what is queued that in
general I think best description is a
multi-purpose node.js runtime platform
that doesn't tell you a lot really does
it and but it's all about creating
isolated runtime containers for your
message message handler functions such
that you don't really end up having to
worry about CPU intensive work and it
starts to allow you to use synchronous
logic to do the kind of stuff that I
want to do which is very high level
database abstractions so the way it
manages to do this is fairly
straightforward it's a there's a master
node.js process and a pool of worker
processes the master process handles all
the incoming requests and it has Express
or Co ajs you can decide which one you
want as it's HTTP REST interface and use
a socket IO for WebSocket interfaces and
it returns the responses back to the
client and that's all the master process
does okay all of the work is done in the
worker processes and the key thing is
that a single request is dispatched from
the master process queue to an available
worker process and so each worker
process handles a single request that
queue dispatcher worker process pool
management mechanism was all handled by
a separate module called ewd queue
operate and it's used by queued but it
was actually a separate module so it's
available for people if they want to do
this kind of stuff you can go off and
and you use this as the basis of your
own mechanism so here's the way it works
so you've got incoming requests they can
be HTTP or rest ones they can be
WebSocket ones and the request is
immediately put on the queue ok no
further
processing occurs but as soon as a
message goes on the queue it triggers an
event which occurs of the dispatcher to
take the message off the queue and try
and pass it to a worker process and if
none exists at the moment it will start
one up so that worker process starts up
it loads all of the queued accused
specific logic that it needs to make it
work and then your application specific
logic any connections databases and
whatever and the request is then passed
to that worker and here's the key thing
that worker then Flags itself as
unavailable okay so that the next
incoming request to the queue if that
one's still unavailable it starts a next
one all right and that then becomes
unavailable and this will continue until
your pull sighs you're nominated pool
size is is reached in which case any
more incoming requests are simply queued
and then handled once one of those
workers becomes available so the workers
in here's the other key thing the
workers are persistent they don't close
down okay so they immediately become
available you in your function handler
your message handler that's running in
the worker you determine when it's
completed and you you just fire this
function called finished with a response
object and that is then sent to the
master process and dispatched out
through socket IO or through the web
server out to the waiting client and it
also tells the the worker process that
you are now available okay and so now it
can handle the next queued request
worker process once they are started are
persistent so this avoids this startup
cost and worker processes are quite
expensive to startup so this avoids that
they're just gets reused now if you
think about it the master process is the
ideal nodejs
application
100% asynchronous all the concurrency is
handled in there and it does virtually
nothing there's almost no CPU load in
there at all it just puts them on the
queue and dispatches them out returns
the response when they get them all the
work is done in the master Pro and they
worker processes and they only handle a
single request at a time they're
completely isolated runtime they're only
handling one request at a time so you
have no concerns about concurrency
you've got that entire process all to
yourself and you can use safely use
synchronous api's long-running CPU
intensive logic no it'll have some
effect obviously on the overall
available resources within the machine
but it won't have any direct impact on
any of the other worker processes or the
master process so ok few questions then
that's all very well but why not just
use child process and the answer is to
avoid that very high startup cost when
you start up a child process they reckon
that it's at least 30 milliseconds to
start over a child process in a
high-performance system that's no good
you can't have that now the workers in
include our child processes of course
they are that's that's how it works but
they keep running so they're not the
only startup time is the very first time
when you bring up the system the very
first request brings up that's that's
the one that gets to hit after that they
they up there they're ready and
available why not use cluster that's the
obvious way to do this stuff isn't it
well plus is all very well but actually
the way it works is it spreads the
overall concurrency across a number of
processes so each one of those processes
is still handling a whole bunch of
concurrent requests and if any one of
those ties the CPU up then everybody
else in that cluster process will will
get held up as well
so it kind of gets you so far but it's
not
it wasn't the solution that that I was
wanting so by forcing the child process
to only handle a single request and
queued gives you this isolated
environment which is what I wanted to
have why not use rabbitmq or 0nq you
know why why am i writing a whole queue
system in node well it's because I
wanted to only have one technology one
moving part right I didn't want this
heterogeneous environment and actually
when I was creating this in the first
place one of the things I did was I
ripped apart the queue mechanism and put
in 0 mq to see how how that would behave
and I thought actually it would was
going to perform a lot better actually
it gave no performance benefits
whatsoever I was really surprised about
that maybe I was doing something wrong
with it but I did a lot of work with it
and and I wasn't that impressed and you
know it proved that no you can use a
single technology or node and do all of
this stuff just as well which begs the
question and well what kind of
performance can you get from this kind
of environment and I was talking to Adam
about this at the micro services meeting
and it's kind of what I think triggered
him to say well you must give a talk on
this so I decided well what's a good way
of a good benchmark for this and I
decide well let's do it with a Raspberry
Pi you know 30 quids worth of of kit and
the nice thing about the the Raspberry
Pi model 3 model B is that it's a four
core CPU it's a it's a nice little
little machine and it means that we've
got 4 cores to spread the load across ok
with it with the master process and the
workers and it's easily replicate
replicable that's a difficult word to
say and so II wdq operate comes with a
benchmark script which is what I've used
here you can run the same thing on a
Raspberry Pi and you should you should
get exactly the same results right one
Raspberry Pi as the same as another so
as it's the same model
so the benchmark script allows you to
say how many workers how many messages
in total so I said okay half a million
and it allows you to create a
steady-state so instead of just creating
you know bang half a million into the
queue and since it's an array based
queue that's not a good idea it allows
you to drip feed them in so I set up
said right every hundred milliseconds
add six hundred and twenty two messages
to the to the queue and that created a
steady-state that it could deal with and
the messages are very simple it doesn't
do anything and just send them to the
worker and it echoes the response
straight back but on a raspberry pi 30
quids with a year I was getting 5,800
messages a second round tripping on this
thing now they're not doing anything in
the workers but the limiting factor on
the raspberry pi at least was the master
process hit hundreds in CPU so it
couldn't go any faster but the workers
were only using 30% CPU so if you think
about a real-world environment you've
still got 70% of the CPU in those cores
available to do real work in the workers
while you're maxing out the the the
master process now I've tried the same
benchmark on all the machines you tried
on this thing here you know in a VM
where it was just a single core and it
starts to get a little bit different you
get that you can't reach 100% in the
master process and I think it's because
you're getting limitations on the
network the internal networking the the
IPC channel between the worker and the
master processes but that's something
that other people may want to to check
out
so what concludes this project that I
built on top of this stuff what can
actually be used for well I've developed
it for a whole bunch of things I like to
to abstract stuff away and make it easy
for myself to use and for other people
to use and so one way of using it as a
full stack platform a bit like meteor
actually it's got built-in web WebSocket
ajax ajax messaging it's all
automated you really don't have to know
much about either of those but you can
sleep seamlessly swap the transport you
can say you can write the application
using WebSockets say no I want to use
Ajax without any code changes it'll
it'll use Ajax over HTTP instead for the
messaging obviously with WebSockets you
can do bi-directional flows as was
demonstrated earlier which you lose on
Ajax and the security within this
environment is all built in and
automated for you it can also be used as
a REST API server and it's got session
management built-in if you need to use
that or automated token-based with
server-side jason's to persistent
jason's storage using that high level
abstraction that i've created it's also
got a mode where you can say I want to
use JSON web tokens instead so that it's
all done on the client and server again
all automated all built in and you can
you can run it as an API REST API server
and an interactive server at the same
time it's got it can be used as a micro
service platform this came out of the
result of that meeting that I went to
and and with this by using shared shared
secrets you can use and and Jason web
tokens you can then spread the load
across multiple queued servers so you
can recreate fabric as it were of queued
servers and separate out the work as
microservices and these communicate over
WebSockets so just using socket IO and
if you're running that over HTTP it
means that again you're not constantly
opening and closing HTTP connections
once they're established then they just
keep running very very high performance
it can also be running it uses a
Federation platform so where it provides
a middle tier to multiple rest servers
behind it and it allows you to send one
request in fire off multiple requests to
the back-end servers pull
back together or create what I call a
dance where you send a request to one
and as a result of that response you
send another request to that guy and
another one to that and pull gradually
build a composite response as an
application where I'm involved in using
something called open EHR a healthcare
application that does exactly that uses
back-end servers known as open-air
servers and it queued provides the
middle tier to pull all of that clinical
data together the idea here being in a
clinical application actually as I was
saying to this chap here earlier on
through life you leave data that
healthcare data about yourself all over
the place you know when you go to the GP
here and you move house to another GP
you go to that hospital and you go to
this hospital and one of the big
problems in healthcare is being able to
pull together all that composite
information so that if you turn up in
A&amp;amp;E with a problem that they know that
they must not give you penicillin
because it'll kill you or the reason why
you're here is probably because of this
past history and this kind of thing and
and to be honest at the moment that's
very difficult to do so this is the kind
of application that's going to allow
that to happen it can also be used as an
interface to a style a class of database
that you probably none of you have aware
of there's a global storage database
there's a number of these one called GTM
and also new variants of that called
yatta db2 one called cache a with a new
platform coming out called iris we've
got a chap called Mike Fleur at the back
here you can tell you about cachet and
iris if you're interested I've done an
emulation of this style of database
using Redis and all of these are then
abstracted within queued as two things
press it what I call persistent
JavaScript objects so you're dealing
with objects they appear to be objects
but they're actually manipulating data
on disk instead and but also as a
fine-grained document database so unlike
Mongo where the the document is the unit
of storage with this the unit of storage
is actually the individual name value
pair with in any level of an overall
JSON
object pretty powerful database concept
although cute the the queue wdq operates
and Q is an in-memory queue you can also
have an optional resilient mode where it
backs up the queue to a data to the
database at one of these global storage
databases such that if it goes down when
you bring it back up
it'll replay any plate on unprocessed
messages and so it keeps the thing
resilient it supports all JavaScript
frameworks but there is some pretty cool
tooling some third-party so there's a
guy I work with a lot in Belgium is
using it for a retail site
and he's been doing a lot of work with
react and view with queued and he's also
using the micro services stuff to pull
together stock information between their
various stores across Belgium so that's
what cued is all about and the idea and
hopefully I've explained it to you such
that you realize that is true yes you
can have your nodejs cake and eat it too
if you're interested to have a look
QJ Escom there's a load of tutorials
that I've put together they're all on
SlideShare it's a big menu go through
that you'll see all the stuff about the
database and all about how it works and
give it give it a try</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>