<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building the Mesh - Istio London - March 2018 | Coder Coacher - Coaching Coders</title><meta content="Building the Mesh - Istio London - March 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Pusher/">Pusher</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building the Mesh - Istio London - March 2018</b></h2><h5 class="post__date">2018-03-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/07eRSVsebNs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm gonna talk a bit about how we build
the mesh and then go into the deep dive
on how all the discovery service stuff
works under the covers I'm gonna focus
on a kubernetes base disk your
installation purely because most people
who are using s2 are using kubernetes we
have others we do support other service
discovery backends so console in eureka
but really the main reason I'm going to
speak about kubernetes is it's way more
opinionated on certain things so things
like pods and services well-defined
objects that I can kind of talk about
and discuss so first there by me I'm a
software engineer at IBM these are some
of the projects I work on my day job is
working on the IBM cloud container
registry so that's the IBM cloud docker
registry as a service offering in terms
of SEO I've been part of the history
organization on github since I think a
weak lot a year last week so quite a
while I work mostly on pilot and the
proxy side of things and I'm a current
of the sto CTL feature as if you have
any requests for features for that talk
to me afterwards so first a few of the
problems so Advanced Micro servicing
which is definitely a word what I really
mean when I'm talking about this is you
have your basic stuff like metrics trait
and then some slightly more advanced
stuff like tracing and then you have
your basic advanced routing so you have
things like timeouts and retries but
then you have some more advanced stuff
like canary testing a/b canary testing a
bee testing or canary deploys and that
type of thing so I'm presuming as a show
of hands pretty much everyone has
metrics yeah okay how many people have
metrics at service levels so you can say
you can have a dashboard for service a
tox for error rates on service a
talking-to service B and service be
talking to service see how many people
have that kind of level granularity okay
so not many how many people have uniform
metrics so what I mean by that is same
kind of
the same metrics being exposed same
names and consistency and that type of
thing okay somewhat on that so a lot of
these are kind of basic things but some
some of the things that you don't have a
more advanced stuff like the tracing and
the advanced routing and that type of
thing so this is kind of a basic
application running in kubernetes these
are poorly named services because
obviously a service is something
specific in coop but it's easier to read
it's easier to read than if I stuck mark
services in those boxes but yeah in coop
normally your micro services the
containers basically all talk to each
other directly and in kubernetes your
your a lot of the concerns we already
moved been moved to the platform level
so you don't have to care about
orchestration because coop does that for
you you don't care about service
discovery and you don't have to care
about kind of the simple load balancing
that that stuff is no longer a concern
of your application code that's solved
by the platform so you've got these you
need some metrics and tracing to add to
this so this is where your data client
in right you put your client in your
client woods spout some metrics and then
you'd be able to get some observability
into your application in order to debug
stuff if you're optimizing for mean time
to recovery but so you can either use if
you're a Java shop you might use
something like hystrix or finagle to do
this which are quite advanced or maybe
you write your own our team write our
own because we use or we start adopting
go with miles before there were any
things that did listen go I assume it's
been solved and go I haven't actually
been keeping up and this is fine as long
as all your micro services are written
in the same language but what happens if
you want to have a JavaScript front-end
or something or maybe you want to adopt
an open-source project into your code
and now your basic client you've written
for your market services isn't going to
work in this situation so what ends up
happening is you basically have to write
your own or write a new
one so for the javis unite we now have a
JavaScript client here for the micro
services sitting in the front we have
three instances of the same go client
and then we have some special snake the
special snowflake wrapper basically
around your open source project in order
to try and get it to spout the same
metrics that all of your other micro
services do but this this is fine you've
now got three clients you then want to
adopt another open source project or you
want to write something else in other
language you then go write another
clients do those things and then once
you've got those three four or five
client libraries however many you have
what happens when you run out other
features to those client libraries if
you have the basic metrics and you want
to do a/b testing you've then got your
implement a be testing and four separate
clients right and it becomes expensive
to keep solving these problems in the
application code so basically don't
write like service discovery and load
balancing is handled by the platform in
coop just move all of this stuff to the
platform if something can be solved in
the platform so that's where you should
be moving it and a high level this is
kind of or this specific stuff is kind
of the value of the service mesh the the
basic kind of free stuff you get in
terms of tracing and that type of thing
it means you don't have to write it in
your code and it's just generally made
available by the platform so it's do
builds the map it achieves the mesh
using the on voice and on voice sidecar
model so every request flows through a
proxy at each step kind of in each pod
so when the request comes in it goes to
the envoy ingress controller and that'll
do basic ingress controller stuff
forward that on to the pod and all of
the traffic within the pod it uses or
that we use iptables then through all
the traffic coming into the pod to envoy
and then envoy will proxy that request
through to the service now your service
might want to make is the front page so
it might need information on reviews or
things like that and that will then try
and make those requests that'll be proxy
back through envoy and then to
downstream envoys and so on and so on
until you've finished your request at
the end so this is what's referred to as
a data plane in the service mesh and
that's basically
where your data flows hence the name so
because we've got that single envoy
binary basically everywhere we don't
have this issue of multiple client
libraries so we don't have any
unintended differences so if you're
implementing three different client
libraries you've got three times the
chance of making mistake criterion
blending three different things also
we've got language independence because
envoy basically speaks TCP in quotes
with some layer seven awareness so it
has awareness for HTTP G RPC and Mongo
DB I don't think I'm missing any other
River suckers already it's my soup core
okay loads of layer seven project
difficult to keep up on that type of
thing but any way that as long as your
micro services are talking over these
protocols it doesn't matter which
language they're talking it doesn't
matter which language is written in
right so this means the Envoy provides
SDO basically a unified approach to
configuring all traffic routing it
provides a single place where if you're
doing some advanced routing now you
might be using some stuff with
environment variables there in disparate
locations there's no kind of single
source of truth a lot of the time so
with pilot which I'll talk about it beer
which one the components of sto that
becomes kind of the single source of
truth within for a lot of the traffic
routing stuff because there's the same
employed binary at every step it means
that there's a standard set of metrics
and tracing data that can be sent from
this from all of the envoys and that
that's how we get things like the
service to service level dashboard so if
you've ever played around with kind of
the SDO demos the basic thing we install
is a graph on a dashboard where you can
basically click a drop down on a service
and click the receiving service and see
an entire see all of the information and
metrics for that service to service
communication so because we've got this
consistent set of metrics that's what
allows us to do things like that but
most importantly and one of the design
decisions early on that was made with
this geo is this is all transparent from
your mark for service codes as long as
your market service code works in
kubernetes it will work with sto and
at ease so building the mesh this
building the master starts when you do
cube CTL apply these two commands are
basically the two ways you can currently
deploy SDO so the first command is
basically we inject the proxy client
side using the SDR CTL kuben check
command and then that the output of that
is then sent to the cube API server by
cube CTL the second one which is using a
feature in coupon 9 so mutating a
mission webhooks basically does this all
server-side for you so you don't have to
worry about doing a client-side so if
you're using helm for instance you
probably want to use the second one
because then you don't have to pollute
your helm charts with loads of injected
proxies manually so yeah what a mutating
mission webhook basically does is when
you try to deploy anything to coop coop
will send a request off to sto and say
do does this does this pod need to be
mutated and SEO will return back the
route the pod that was sent but with the
SDO proxy injected into it
both these commands have the same result
is just kind of client side vs. server
side so if you once you've run this
command if you do a get pod on one of
your pods you'll notice that there's
quite a lot of Yama it's quite noisy
when we inject some proxy stuff in there
so I'm only going to focus on the stuff
that's kind of important so it's do
users coop init containers for those who
aren't familiar with LOC unit containers
are basically their containers that spin
up prior to the rest of your containers
in the pod they'll do some kind of setup
and they'll terminate and then the rest
of your pod can come up so sto in it
uses it has no admin capabilities which
might kind of give away what it does as
I mentioned IP tables earlier so what
what this container does is basically it
sets IP tables through all traffic from
within the pod to envoy for 15,000 and
one is the first parameter that's passed
in so that's where envoy listening for
the requests and then U is the UID for
which redirection is not applied because
otherwise this
is usually the you idea of the proxy
container because otherwise you'd have
this never-ending loop back as soon as
you tried to speak to something outside
of your pod so next container come up is
sto proxy SEO proxies basically the
Envoy write binary wrapped by pilot
agent so pilot agent is responsible for
managing configuring the Envoy process
it does things like hot restarts on
certificate rotations so it does a file
watch on the certificates when it
detects they've changed it when it
detects any changes it has a hot restart
of envoy so envoy can pick up the new
certificates so if we look at the SDO
proxy amel it's running in proxy sidecar
modes there are this is because it's
running as a sidecar to a container pot
there's also ingress and routing mode
ingress is pursuin is running as an
ingress controller and I believe Rooter
mode is used for egress stuff again
where zach is is it is it used for
egress off the router yes it is I've
been keeping up on that okay yeah so
that's what that one's useful so then
we've got the binary path from the
config path so envoy has two forms of
configuration it has static config and
dynamic config the conflict path is
where the static configures located so
that'll contain things like the location
of the certificates because although the
certificates change the location of the
sifrits don't and generally things that
don't change then we've got proxy admin
poor proxy admin port is potentially
where you could do a lot of damage if
you got into the pod and was curling on
that port if you were looking to debug
currently the best way to see envoys
view of the world is to exactly into
your pod and basically curl localhost /
listeners clusters or routes and that
would dump out any debug information
from Envoy I currently actually have an
ST OC TLP are open to allow you to do
this from SDI CTL so you can do
something like it's do CTL proxy config
and then give it a pod name and it will
dump out the config for that pod
- so service cluster so a cluster in
there's a lot of confusing terminology
between first off envoy sto and ku
because there are three different
definitions for what a cluster means and
those three different things so a
cluster in envoy terms is basically a
service in coop it's a collection of
endpoints that represents a given
service so the service cluster we pretty
much just map to the app labeling coop
because that's because they're kind of
equivalent so I know I mentioned earlier
there's dynamic config so that's where
pilot comes in so we need to tell envoy
waits go and get the dynamic config and
then we have the zip key and then stance
D address so that's where we'd send
distributed tracing stuff and metrics
information so now we've got all the
envoys deployed how do they know where
to route all the requests you can't
obviously have all this and Static
config you need to have it in some kind
of dynamic config so this is where the
control plane comes in and this is
really what SEO is SEO is basically a
control plane for envoy and yep this is
where pilot comes in hence the term
piloting the mesh which I believe is why
it's called pilot in the first place I
vaguely remember the discussion so pilot
acts as an abstraction over top of
kubernetes service discovery obviously
this is where we abstract away things
like if you wanted to run with a console
back end or Eureka backend for service
discovery it uses the service discovery
information and then mutates it
depending on SEO rules they're set so if
you set up a route rule or a destination
policy I forget this - changing with v3
what the exact terminology is but if you
set up things like that that it's do
will then mutate the response that it
gets from the discovery service and send
it send it to envoy so every few seconds
envoy will call out to pilot basically
to retrieve the information they need to
correctly route the traffic and then it
will cache that in memory this
information comes in the form of for ap
is so we've got the there's five on this
list I know that
so we've got the lift no discovery
service the roots discovery service the
cluster discovery service and the
service discovery service / endpoint
discovery service depending on so we
don't yet support the endpoint discovery
service because that's on the envoy v2
API but we're I think we're aiming for
Noor point eight nine point nine it's a
release of moving to v2 something like
that
okay so I thought to potentially
future-proof this talk immediately I'd
talk about the important discovery
service more prior warning all of the
pilot produces a lot of but pilot
produces a lot of JSON so the next few
slides going to contain contain a some
JSON again like I did with the Yammer
I'm just gonna try and highlight the
important stuff but the idea is we're
gonna follow kind of a request through
to work out how envoy works out where to
send the request and hopefully by the
end of this you'll become a debugging
expert but if you don't understand most
of what I'm saying there's a very good
sto community talk that highlights this
is by plus news twitter handle is bobby
tables but i can't remember his actual
name is I presume it's Bobby Bob
something but if you go and look in the
sto YouTube channel I think it was two
weeks last week two weeks ago something
like that there's a very good kind of
live demo of debugging in sto so we got
follow requests through like I said this
is basically just a normal HTTP request
from the product page service in our
coop cluster to the review service so
you can imagine a product page is
displaying a product and it needs to get
reviews it Orion needs to talk to a
downstream reviews market service to
pull in the reviews information so
that's kind of what this request is so
the first thing you can see that that's
quite small we're going to talk to the
listener discovery service so that's
available on v1 slash listeners in pilot
we get with self-identifying as the
product page and all the product page
service and the unique identifier for
this instance of the product page
service
think so this information is actually
relevant in listeners in some
microservices or in some discovery
services we pass this information and
then proceed to mostly ignore it like
that cluster discovery service and that
kind of just dumps out everything but
yeah so we need to use the listener
discovery service a listener is
basically just something input in envoy
terms and I think in most proxy terms a
listener is basically just something
that listens for incoming requests so
the top listener here is this listener
you'll notice assisting on localhost
fifteen thousand and one which is the
place we route all traffic to from the
previous slides and this one's bound to
the port which obviously means it's
listening on the port and then we use
and then we set use original destination
to true and what this means it basically
tells this listener to hand it off to
the port from the original destination
address or the best match for the
collection of IP and port that it can
find so this is once this is handed off
this is where the second listener comes
into play and what we're really looking
for here is right down the bottom
there's the RDS object there so this is
telling it that where it needs to go to
how it needs to look up his routes we've
got the we're going to RDS cluster which
is actually pilot I don't know why the
string is set to RDS I think there's
historical reasons I did ask white and
he couldn't tell me so apparently no one
knows it's lost yeah but yeah that
that's just telling envoy to go to Pilar
and to look up routes for port ninety
eighty so now we're going to talk to the
routes discovery service we're going to
use port ninety eighty and the request
and what the routes discovery service is
going to return is basically every pore
every Envoy cluster which is a coop
service this is why it gets very
confusing that exposes something on port
ninety eighty so if you're all your
Microsoft applications are exposing port
ninety eighty RDS is basically just
going to dump out everything that it
knows about
so roots deals and virtual hosts envoy
will match on domain so we made the
original request to reviews 90 80 so a
match on that and then it will check the
routes associated with that domain so
here we've got two routes associated
with it the reason we have two is
basically because this is kind of a
plant but we're doing Canary deploys
here so what we're looking for is a
header of a cookie header with user
equals jason and if a user comes into
our application with that header we will
be sending them to version two of this
cluster as app and if not then we'll be
sending them to this one so the
important thing here is the cluster name
so now we need to go to the cluster
discovery service to look up information
on this cluster so this is the cluster
discovery service it will basically dump
out everything that pilot knows about so
you'll in if you went and curl'd
v1 slash clusters you'd get things like
coop dns in coop dashboard that would
all be in there but what we're really
interested in is looking up that cost
the name there and you can see this
one's of type SDS or EDS in the new
stuff so this tells on void that it's a
dynamic collection of endpoints so it
needs to go and look this information up
from pilot again I'm using lookup but
this is kind of all stored in a cache it
doesn't make a request of pilot every
time for one of these because that would
not be scalable at all so we're gonna
take the service name here and go and
look that up in the endpoint or service
discovery service depending on which
version of history are you using so we
can use the service name in the lookup
obviously that's how she's going to be
URL encoded because otherwise it will
fail but here we've only got one host
serving this request so we now have
worked out where to set on voice and I
worked out exactly the IP import that it
needs to send this request so we know
that there's a Envoy in the first part
and we know that there's an envoy in the
receiving pod so when it get this
request is now made when it reaches the
pod
it goes into pool fifteen thousand and
one it gets forwarded to a different
listen at this time because it's got a
better match on that IP if you remember
that IP was the one we found before so
it will get forwarded to this listener
and then this one's got a lot more stuff
in line because when you're if you if
you know the but the request is coming
inbound to port 98 in a coop cluster you
know you're gonna be forwarding it to
localhost ninety eighty because that's
where your micro-services listening
within a pod
so we'll find the cluster name which is
n dot ninety eighty we'll go and look
that up too far and this one's a static
one so like I said we know that we're
going to route support ninety eighty so
we don't need to bother looking up
dynamic endpoints we can just go
straight through and route it to port
ninety eighty inline so now the requests
finally arrived handle the response
however you want and that I hope most of
that made sense has been quite it was I
understand there's a lot Jason there so
if none of that makes sense
feel free to ask me questions luckily
unless something goes wrong in SEO you
don't have to worry about this this is
only relevant information if you're
debugging stuff again SEO is in beta so
you may be debugging stuff but yeah so
why really the one take away should
probably take from this is the the idea
is that SEO is basically the next level
of abstraction running on top of
kubernetes it moves the observability
stuff and intelligent routing stuff to
the platform it does things like mutual
TLS by default if you turn it on and
it'll do things like policy enforcement
with a mix of stuff I don't work on any
a mix of stuff so I can't really talk
about it
but yet the idea is to move all this
stuff to the platform so you don't have
to worry about this code in your micro
services themselves and you can focus on
actually writing some of the domain
logic and business logic in your micro
services rather than do all of the
intelligent routing stuff here in your
clients so that's the end of my talk if
you've got any feedback for me or want
to suggest any future technical talks
because I am your local sto developer so
yeah if you've got any kind of technical
deep dive talks you want just come speak
to me afterwards I'm happy to them any
future meets up so if you'll have me
again
so you can either comes between offers
or speaks me on Twitter there with that
I'll take any questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>