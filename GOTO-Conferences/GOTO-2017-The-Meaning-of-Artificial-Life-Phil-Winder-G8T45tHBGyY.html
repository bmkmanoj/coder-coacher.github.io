<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • The Meaning of (Artificial) Life • Phil Winder | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • The Meaning of (Artificial) Life • Phil Winder - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • The Meaning of (Artificial) Life • Phil Winder</b></h2><h5 class="post__date">2018-03-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/G8T45tHBGyY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you thank you illustrious
introduction there so my name's Phil and
today I'm going to be talking about the
meaning of artificial life and it's a
talk where we're going to talk about the
history of AI we're going to talk about
its origins and I'm going to bring that
through to today and then we're gonna
see how AI is evolving in today's
industry and along the way we'll also
learn a little bit about the word that I
prefer it's data science so if we if we
think about for a moment that we're
going to think about what people think
AI is and they'll probably go back to
some sci-fi I think that's where the
origins of AI really came from and in
particular this probably two books slash
film that really kicked it off the first
the I Robot by Isaac Asimov a very very
famous book now where the Three Laws of
Robotics originally came from and it's
interesting to note that the actual
story was written in 1942 so it's very
very very old and the book I Robot the
the collection of short stories was
published in about 1950 that was you
know one of the the first real defining
moments in literature where AI was first
considered then we've got 2001 Space
Odyssey a story about a psychotic
artificial intelligence which attempted
kill the crew onboard a state a space
station in order to save its own and
soul and that was in 1968 so quite a few
years after and that was actually
produced at the height of when people
started to think about the the bad side
of AI well in fact the the whole thing
actually goes a lot further back than
the 1940 1968 even in myth in mythology
there's lots of references to - to
various automated agents in Greek
mythology Talos was a bronze automaton
and he was created by their the god
Hephaestus he was given to Europa by by
Zeus to protect her when she was on the
island of Crete he would go around
throwing
sir pirates anybody just try to invade
the island so I like the idea that gods
also need holidays on Crete as well and
even in in other cultures as well in
China there's lots of stories about
people creating human robots I think
word was yeah engineers that would
create mechanical men to impress the
Emperor at the time so through our any
number of cultures there's lots of
references to to automated agents into
the dark ages I think the the stories
get a little bit more dubious in 1206
it's quite an old reference chat
colleges II recreated a programmable
orchestra of mechanical human beings but
my favorite in around 1500 a a guy
called Park Ellis claimed to have
created an artificial life out of
magnetism alchemy and sperm now I would
not like to have been there during his
experiments and I suspect that that was
probably the birth of the sex toy
industry right there and then in 1500
slightly questioning questionable a few
of those and it is even even serious
thinkers Rene Descartes
he proposed that the animals ultimately
were just complex forms of machines so
we're starting to see throughout the
history into the dark ages that least
these ideas are a little bit dubious but
people were certainly thinking about it
a long long time ago during the
Renaissance and after the Renaissance
things start to get a little bit more
serious Thomas Hobbes published
Leviathan in their reason is nothing but
reckoning and actually I just just in
the the British Library in London
they've got a display on at the moment
which has a first edition of Leviathan
and to think that it was written such a
long time ago it's hugely impressive so
I'd recommend that you're going to see
that totally free and in 1642 Blaise
Pascal he among among many other things
he invented the first calculator and
this is really the first you know
real-life examples of machines that can
mimic some parts of human thought so he
he'd a lot of acclaim at that time
Gottfried Leibniz
was was very prolific he he was the guy
that who independently found
differential calculus he invented the
binary counting system and but more
interestingly he had some other things
that were maybe a bit more audacious
however people forget he attempted to
work on assigning a specific number to
all thoughts that human beings could
ever have in order to try and create an
algebraic solution to thinking obviously
that didn't work too well for he at
least he tried but really it was just
before the 1950s and around the 1950s
where where things started to come
together as a field and it was not
really due to one person one person was
very affluent influential but it was
actually a confluence of many different
things so one of the first ones is that
it was found that the brain was actually
it was it was constructed from a very
large amount of electrical components
and the brain was thought at the time to
to to represent and replicate an
electrical circuit and that was a key
discovery Claude Shannon also around
that time defined his his definition of
what information is and how we can
quantify it and probably one of the most
important people of all was was Alan
Turing and he he in this in this
particular instance he he came up with a
theory of computation which basically
defined the functional limitations of a
computing engine and that was really
important because it showed that the
only real limitations was the the
processing power of the machine itself
and these ideas and more started to
raise the idea that the belief that we
could actually create an artificial
brain so much so that in around 1950 we
started seeing the first implementations
of an artificial brain so think of this
as as Professor D Andreas is drones but
you know much much much much earlier a
guy called William Gray Walter he
started playing with robots and I say
they were very simple but I mean they
were quite complex at the
but now they seem quite simple all are
comprised of were a photo tube which is
like a light bulb that's filled with a
gas where the resistance changes
depending on where the photons hit the
gas on up and they would collect
connected to two vacuum amplifiers and
then fed into motors so the idea was
that this thing could follow light you
showed it to light and it would follow
it would go towards the light and that
in itself was really cool but he he he
played a little trick on people to make
it seem like there were far more
intelligent than there were and it was
this what he did he placed lights on
wall sockets on plugs on the wall and
whenever the robots battery started to
drain it would drive towards that light
and plug itself back in and charging
back up so it's just a simple
modification of his robot that gave the
impression that it was really
intelligent it was feeding itself it was
looking after itself and that's
generally thought of as one of the first
intelligent robots but really the
seminal moment was was the the
definition of the Turing test in in the
paper Computing Machinery and
intelligence and in this Alan Turing
started to think about what thinking
actually is and he came to the
conclusion that wasn't really a clear
definition of what thinking was so he
created his own and his idea of what
thinking is is if you can fool a human
into thinking that a computer is
actually a human then you can define it
as thinking and this changed the game
completely because it constrained the
problem it made the problem a lot more
simpler than it was previously
for the first time you know making
machines think seem like a problem that
people could solve and just to think
about the the ideas at that time this is
a quote from john von neumann a famous
mathematician he was in the lecture and
he was asked the question I don't think
the computers and machines will ever be
able to think how can they possibly
think I do such complex things we can't
possibly get a computer to do that and
he said that you insist is something a
machine cannot do you will if you will
tell me precisely what a machine cannot
do and I can always make a machine that
will do just that and this was actually
a key insight and I think this is 19
I think that was 1948 he said that and
the problem was people still didn't
really grasp that idea it took around 30
or 40 years as we'll see a bit later on
for people to realize that that's what
we've got to do we've not got to try and
make this generalized idea of a human
brain people around me the idea chaired
the church-turing thesis a few years
later came out and said that in essence
any algorithm that a human can use to do
something we can encode in machine form
so for example if we can define an
algorithm for sorting letters in a
post-office and putting them in a
certain box you know if we can define an
algorithm for that we can encode that in
software in a machine relatively easily
so it's just a general theory to say
that the algorithms can be can be
encoded in machine form but then there
was a an extension to this and by David
Deutsch and he he attempted to prove
that as an extension to this that any
physical process that could be simulated
by a universal computing machine could
be performed by a machine and you know
there's a couple of caveats to that and
basically the caveat circuit again came
down to computational power we need to
be able to simulate and predict that
happening in real time otherwise it
doesn't make sense but that got
everybody excited because in theory if
we have a computer that is powerful
enough we can simulate any natural
process any natural process at all and
that includes us so between 1955 and
1970 the real boom in AI there were vast
sums of money that was poured into to
doing AI research and one of those
examples is the DARPA the the the
military funding agency funded mi t--'s
AI lab to the tune of 25 million a year
and that was totally unstructured open
funding you know that was money that
they could spend in in anyway and and
also around that time some very very
intelligent people started making
predictions about what would happen when
they saw this progress you know this
this this this confluence happened over
only over about ten or five or ten years
when people
started thinking about trying to make a
human brain so they were simply
extrapolating over the next five or ten
years and they suggested things like
they would build that beat the world
chess champion you know in ten years a
new mathematical fear theorem machines
would be capable within 20 years of
doing any work and man can do so that
was quite audacious and you know as you
probably know that all popped that old
bust and the reason was people just
became disenfranchised with the idea of
AI because they saw nothing they saw all
of this grandiose ideas and predictions
of around 1955 and 1960 but nothing came
of it and in the oops of belt I feather
in in the UK at least in 1973 the light
Hill report it was a
government-sponsored report criticized
the utter failure of AI to achieve its
grandiose objectives and it completely
led to the dismantling of AI research in
the UK entirely and it's a real shame
because up until that point actually the
UK was was was quite at the forefront of
a our research and now is now it's not
it's all in the US because we lost all
the funding but to be honest yeah you
can criticize them a little bit because
they should have realised this you know
these are smart people but it's also it
wasn't wasn't really their fault
the real limitations were a limited
amount of computational power so just as
an example processes at the time 6570
they could manage around 1 million
instructions per second current machine
vision implementations needs somewhere
between 10,000 and 1 million million
instructions per second so this was
orders of magnitude away from where they
needed to be there's also a technical
limitation that they found as well it's
called the curse of dimensionality so a
dimension is a technical term my height
my age my eye color you know they're all
dimensions in a data set so that would
be three dimensions and many of these
these these vision like problems for
example are very highly
multi-dimensional
and a lot of the problems can only be
solved in exponential time so that means
every time we add a new dimension it
takes an exponential amount of time
longer to to solve that now finally one
of the one of the most interesting I
think and the coolest one is how to
encode common-sense knowledge so you
know many many problems like if you just
imagine how you see things you have a
set of rules and encodings and laws if
you you've learned over your lifetime
and you expect those to be true you
assume those to be true so if you saw a
picture where somebody was hovering
upside-down you would instantly
recognize there was something wrong with
that picture but trying to teach a
machine how to do that is incredibly
difficult because it means we need to
provide examples of people hovering hook
slide down and I think one of the best
ways of demonstrating that is is with
with my children I love talking about my
children because I like looking at how
they learn and it correlates so well
with how machines learn so this is a
painting that she drew when she was
about three she was about three when she
drew this and can anyone the audience to
suggest what that might be
jellyfish face did someone say elephant
then wow you've got an abstract brain I
don't see an elephant there you must be
you must be a fan of Picasso or
something so yeah jellyfish great hat
person and that's exactly what we think
we thought but she actually told us
something different and we didn't
understand what she meant until we
turned it upside down and it's actually
a cup of tea see the cup the handle the
steam from the tea it's a fantastic
drawing of a cup of tea she drew that
upside down so it made no sense to us
she in her three-year-old mind hasn't
quite learned that steam has to go up
the her steam can easily go down as well
so you know if we can't even recognize
that how on earth can we teach a machine
that steam has to go we have to teach it
thermodynamics just to do a visual
problem
it's insane
and finally we get to the 1980s and this
is really when we go back to von
neumann's comment and people realize
that the the only practical problems
that could be solved
you know expert problems problems where
we really constrain the problem and this
is this was called the rise of the
expert system and just as an example of
that if somebody came to me a client
came to me say I want a system that's
capable of handling orders by speech
that's a hugely unconstrained problem
and it's that would be very hard to
solve because you need a you need an
algorithm that is able to take any tech
any text and just convert any speech
sorry and convert that into text some
sort of knowledge about ordering and
systems and things like that
incredibly problem but if we convert it
if we if we try and constrain the
problem a little bit it becomes a lot
easier if we suggest that the product
will place orders given by speech for
some combination of meat and potatoes
which is apparently all you eat in
Berlin so it's got to be it's got to be
a combination of meat and potatoes and
in Berlin you know we're constraining
the problem because it becomes a lot
easier now the only thing that people
can order is meat or potatoes you've got
two things there and if you're in Berlin
you know we get some some examples of
somebody speaking German or probably
English actually everyone everyone
speaks English which is incredible but
because we've constrained the problem it
becomes a lot easier we could do
something like a simple distance measure
to say like how similar was the sound
from that person to the new observation
that we've just seen and in about around
the 2000s this some of these predictions
that had finally started to come true
and it'd been 50 years since since
Turing had done all of his amazing work
but in about 1997 one of the predictions
who won by OJ Simon beating the world
chess champion actually came true and it
was done by this big black box called
deep blue and of course it has to be a
big black box because it's built by IBM
they sell big black boxes
I'm sure inside there there was either
just a little laptop or a single single
PU maybe a person actually that is big
enough to be I bet now that when he
actually won that chess competition the
guy that was his tomb
he wasn't allowed to get out of it
because he actually be the world chess
champion and he had to be entombed for
future posterity and that was thirty
nine years after the initial we the
initial prediction by HJ Simon and it
took all that time basically to realize
that we can't solve these grandiose
problems we need to constrain ourselves
one of my favorite examples is in 2004
2005 DARPA funded the the grand
challenge and remember DARPA is the same
agency that funded the initial AI
research in in mi t--'s AI lab about 40
years ago and 50 years ago and they
started to pour money back into AI again
and this was a task for a robot to drive
autonomously through 120 131 miles along
an unrehearsed desert track so this is
an incredibly difficult problem to solve
at the time and one of my mentors Greg
Duckworth was was actually working for
Darfur at the time and he had the task
of sitting in this chase car you see
this car in the background here because
the the cars in front were completely
autonomous there was nobody inside it
they had to do that to ensure that there
was no you know no cheating basically so
they had a chase car which followed the
car to ensure safety and things like
that and inside that car they had they
had some buttons they could press there
are two buttons they had one a little
red button which was like a pause which
would pause the software working inside
the car and allow it to to come to a
graceful stop the second one was a kill
switch and knowing the Americans it
would probably blow something up
somewhere I don't know if it blow up the
car or the mountain or what but
something will probably blow up and they
were following
sorry any Americans in the audience and
and they were following this car and all
of a sudden about 20 miles in the car
suddenly veered off-course and started
raging through the desert and they tried
pressing the software pause and it
didn't work it didn't respond to kept
going and he see this is a good picture
because it demonstrates the type of
terrain that they were in you know this
huge boulders you know bushes and trees
and it was plowing through all of this
and totally trashing the car and these
guys actually struggled to keep up
because they couldn't get
through that that terrain and eventually
after following it for a little bit they
were ready to press the kill switch and
blow it up but they didn't really want
to do that wanted to give it an
opportunity to stop and finally did stop
but all of its own accord they didn't do
anything it just stopped mysteriously so
when they got out
you know they tentatively tiptoed up to
this car and like you know with the back
of the hand just sort of touched it like
that just in case it would bite them or
something you know the check the exhaust
and the engine wasn't running and so the
thought okay okay it must be safe and
they popped up on it and it turned out
that the battery lead had come off as it
was going over all of that rough terrain
and that had caused a full system reset
and the car had just stopped because
everything had stopped working so that
was why it stops but it didn't explain
why it went berserk in the first place
and so went back to the hotel and they
started looking through all the logs and
they found a mysterious log entry which
it just suddenly stopped he stopped at
22 degrees right 0.5 acceleration and
that was the last log entry and it
turned out that because they were using
C++ somebody had accidentally made a
memory leak and after exactly 21 miles
of operation it filled up all the RAM in
the computer and so it was unresponsive
to any OS commands anything in it and
that's why the software pause didn't
work just a memory leak you know
nightmare
so these complex systems these dynamics
systems these systems that are supposed
to have feedback can still cause can it
still come a crop up just because of a
memory leak so why is this all happening
now and it's interesting to note that
it's actually it's not due to anyone
particularly smart people even though
there's lots of very smart people
working on this problem it's not due to
a new paradigm you know it's not due to
a new you know fad or craze or
technology it's purely down to
computational power back in 1951 there
was a computer made by a company called
Ferranti which is an old company in in
Manchester in the UK and they I mean
they were embossed about 30 years ago
unfortunately but they built a computer
called
Marquand and that had a performance of
800 instructions per second and at that
time a chapel at the University of
Manchester encoded a chess winning
algorithm on that machine but the
problem was it took two hours to make
one single move so an entire game would
take like 50 years so it was just
unreasonable to actually use it to
actually beat anybody but all of the
stuff existed at that time and it took
until you know 40 47 46 years later
until we had something that was it was
generally good enough to be able to
compute that in real time and even today
in 2016 I core 7 has 317 who billion
instructions per second you know these
are many many many orders of magnitude
greater than than we've had previously
and that's it that's the only reason why
we can we can do all of this amazing
stuff now so do we do we see AI now are
we going to see AI as a thing yes and no
unfortunately yes in a sense if we take
Hobbs and Turing's definition of what
intelligence is then yes definitely we
can do that right now
you know we can drive cars using
machines better than a human actually
and I had an interesting chat with a guy
in one of my training courses day before
yesterday and he works for a company
that helps regulators define tests for
advanced systems such as automated cars
and they said they're having real real
problems trying to define regulations
for automated cars because the systems
are so complex normally there that I
mean basically now the regulators are
still doing like Apollo style
verification of systems you know you go
through the code line by line and you
verify that it does exactly what it's
supposed to do but in these systems are
so complex we can't do that anymore so
there needs to be a shift a change in
the way that regulators do testing you
know we've embraced unit tests for you
know decades now a software engineers
but that's still not happening happening
in the regulators so we need to need to
change that we need to force the
regulators to
because that's the only way we're going
to move forward you know so yeah cars
talking about like computer vision
problems we can do many things much
better than a human can now so in terms
of that definition yes we've got it
but for engineers I think the argument
is interesting but we're kind of missing
the point
and this brings me to my main point stop
saying AI it doesn't make sense it's
it's a philosophical debate about what
intelligent is it has no bearing on
engineering you know I think it's more
about a question of what is the
definition of a machine like if if if
you say that okay humans can think what
we've kind of already proven that we're
just again complex biological networks
can that be classed as a machine are we
just machines if we're machines then
they're definitely sentient as well
because that's just a machine as well
it's a philosophical debate so I know as
engineers you probably aware of this and
that's fair enough but when you go back
go to your marketing department and say
stop saying AI please stop saying it
because it will blow up in everybody's
face because at the moment it's being
used just like every other craze before
it you know all the big data's and and
and and everything before that
eventually it will peter out because
people will stop believing you
you know they've heard it all before and
because of that the whole field will
suffer so stop saying it and I prefer
instead to use a term called data
science and I prefer data science
because it demonstrates the
multidisciplinary approach that's
required to work with data these days
the the definition by Cameron Bure name
now a lady who wrote the book doing data
science I like her as the best and it
says that that a data scientist is a
software someone that's better at
software engineering than a statistician
a software engineer that's better at
statistics another software engineers
and I add my own as well and say that I
think it's important for for employees
to be consultants as well people are
generally more consultants than they are
they are employees so that kind of in a
in a nutshell is what data science is
but it does comprised of some of several
disciplines which have emerged over
from different fields and this isn't an
attempt to try and you know put some of
those things into context I actually
worry when I drew this picture I thought
it was great it looked a bit like a Venn
diagram but now I apologize - it looks a
little phallic and I heard a story I
heard a story the other day and
apparently on Westminster Bridge this
likely is really ornate railing this
which is like a fleur de lys on them and
when when the Sun you know goes low
these fleur-de-lis certainly extend into
these very rude shapes across the bridge
and I'm sure that wasn't an intention
and that wasn't my intention either so I
apologize but the idea is is that all of
these places all of these fields and
techniques have all come from different
places some have come from the business
side some have come from just the fact
that we're using a huge amount of data
and some have come from the idea of
trying to implement off Ottoman
automation so let's take a little bit of
time just going through those fields if
you haven't seen them before so the
first one and probably the most famous
is machine learning and this is the
practice of automating some data-driven
process so I like to say that software
and software engineering is the
automation of a process of a business
process you know this very hard fact
there's very close rules that you can
apply to encode this into software
something like a chess winning algorithm
you know it's just a it's just a series
of rules that we have to follow to get
to a an end machine learning is is doing
a similar thing but it's doing it with
decisions instead we're trying to
replicate the decision making process
the judgment that somebody makes when
they're trying to you know whether
they're trying to establish whether
someone's worthy of having a loan or not
that is a judgment call and machine
learning is the the practice of trying
to auto automate that away obviously a
great example of that is is robotics and
actually the one thing I have against
professor DeAngelis is talk is that he's
so cool working with robots robots are
so cool
you know I can software where where the
backend engineers look at the front-end
engineers and say I wish I have some
front-end that I could show off to
people because people would be amazed
because all we've got is just that curl
that we can do and it's
is taking it's taken months to write
that code and all we do is just do a
curl like yeah he never in fact it's
just a curl and then the front end guys
have got look at all these vigils and
the garage it's the same you know I do
data science
I don't do robotics I wish I did
robotics cuz it's so much cooler and
then we've got another really good
example I'm not sure how many of you are
cucumber growers hearing in Berlin but
if you were what you could do is you
could write an algorithm that will
classify big medium small cucumbers and
whether they were straight or bent so
another really esoteric implementation
of machine learning there but it just
goes to show this to the diversity of
industries that these cyber techniques
are being applied to so hopefully that
makes a little bit of sense analytics in
the business side of things comes from
the idea of trying to convert data into
actions actionable insights so so
companies that there are information
processes the companies that can absorb
pass understand and act upon that
information are going to be at an
inherent advantage compared to their
competitors and this is what analytics
does it attempts to take that data and
provide simple actionable insights of
people to to act upon and one of the
best examples of analytics is Google
Analytics because so many people are
familiar with it this is very focused
towards web-based businesses but there
are equivalents for you know at many
other sectors you know manufacturing and
offline type businesses like that now
Big Data this this this takes the crown
well this is the second crown on the top
is AI and I get really annoyed at the
word AI I also get annoyed at the word
Big Data for very similar reasons
I'm not need to look at who actually
coined the term but the term Big Data
just means lots of data you know that's
it it's not it's not really a thing it's
just an adjective to describe how much
data you have lots of it
and it doesn't even make English it does
even make sense Big Data I
I don't know there's a there's a big
amount of audience here today yeah it
doesn't even make sense in English but
it has become a genuine discipline in
its own right because handling and
scaling to to to handle lots of data is
actually a really hard problem but to be
honest I think of it as more of a
computer science type problem and it's
probably something that many of you do
on a day-to-day basis but it has formed
a part of data science because of the
vast amount of data that's now required
to to to do some of these advanced
applications and you can see a couple of
projects on there and there were also
presentations in their own right on
these technologies so yeah big data very
simple lots of data and we get to
another hype term well actually this is
the one of the ones that does generally
have a lot of promise so deep deep
learning I like to think of deep
learning as one of the first widely used
general-purpose learning frameworks and
I say that because all the way back in
1950 when when Alan Turing's started
talking about these types of things he
was always talking about them in terms
of a generic computing framework you
know this is the first hints of that
coming true its base unit is a neuron
and it comes from the idea of our brains
again and at its heart it's actually
just a simple linear function you know
so if you could go back to your school
when you do the y equals MX plus C that
is all a neuron is in a neural network
okay it's not too complicated a few
technicalities a non-linearity of a bla
bla bla bla bla but the the idea is is
that when you stack many of these
neurons in very very complex patterns
they be able that they're then able to
mimic and simulate and predict very very
very complex processes and that's what
allows them to work on this high
dimensional UBA complex data and that's
actually a big problem as well because
if we go back to professor theology
let's talk again at the star he was
always talking about feedback and how
everybody's problems always solved by
feedback
unfortunately this is so complex
this has interconnections and feedbacks
between hundreds thousands tens of
thousands of neurons and these become
highly highly unstable because you can't
control all of them with a you know in
such a my new way so when we when we
work with deep learning what you'll see
is a lot of the the you know the the
blow ups that you saw on the graphs that
he he talked about so a lot of the work
over the last twenty or thirty years
it's actually been trying to find ways
that can control that and now we do
finally have that and that goes on in a
process called training we take these
highly complex models and we train them
we basically force them we kick them
into working and the problem with that
is that it's great during the training
process but then when we release it into
the wild it then doesn't have any
feedback anymore we're asking it to do
things on new data there is no feedback
inherent in that design and that's what
happens when things go wrong so well I
keep talking about one of my best
examples is Ted or AI and it was this
chat this Twitter bot that Microsoft
created in 2014 and it was a great
example because there are a lot of
really smart guys produced a Twitter bot
that was great at answering questions in
a human-like way you would definitely
would definitely pass the Turing test
the problem was is that they get some
feedback in there they try to learn from
the new tweets it received after it had
been trained okay but the problem was
they didn't realize that the world was
full of sadistic engineers like you and
instead of it being a fantastic product
people tried to break it so they sent it
all sorts of crazy tweets really
horrific tweet tweets and texts and
finally this bot started repeating
things back that were definitely not
nice and because of that after only 24
hours it was shut down and actually the
deleted everything you know Mike the the
Microsoft police just brought a brush
and just moved everything away you know
they still own the domain but the page
is gone there's no mention of it at all
and it's a shame because it was a really
good it wasn't it was a great piece of
work it just it just went wrong okay
and data mining I like to talk a little
bit about data mining as well because
it's still really really important and
data mining is 20 30 years old it's the
process of trying to collect and parse
and understand the data to try and infer
what the process is underneath that data
and you know it still is still really
important today because we've we've got
all this data but we still have to
understand the underlying processes we
can't just apply these black boxes and
expect everything to work as well as we
would like so how is this related to AI
well I think what I'd like you to try
and realize is that all of the advanced
products that you see today you know the
the drones that you see you know they
are very sophisticated and they're very
impressive but they'd come back I mean
that's even more fundamental than data
science I'd say that's almost just
electronics you know it's just control
theory and it's very advanced control
theory but it is just that all of what
Google is Google has being big just
become very very good at the Big Data
problem handling huge amounts of data
and reducing that into a readable format
and you can generally take most products
and and split them down in this way you
know there's no magic involved it's all
well to be honest the majority of it is
just hard work and engineering more than
you know
magic but there is some relation to AI
because if we try and think about what
we do in in a day to day life
I actually I was going to actually
change this graph a little bit I think
it's a bit too complicated what I'm
trying to suggest is that how a human
model our our psyche we do things that
are soar future-oriented
we do things that are rooted in the now
in this moment and we also do things
that are related to the past as well and
these map very well to the various
machine learning disciplines so we've
got prediction and classification
they're the very future-oriented tasks
we're trying to do something predict
something in the future possibly and
then we've got observations and the
various techniques around the
observations the things like the data
mining and
your engineering and stuff that's all
rooted in the now and then we've got
stuff in the past you know if you go to
a library and look at this catalogue
it's been cataloged it's been taxon
alized and people have spent an entire
lifetime just cataloging certain things
so it's definitely an important part of
our psyche and there's a map and a range
of machine learning tools of techniques
that we can perform to do the same
things so if we excel at all of those
things then maybe we can say that we're
starting to replicate the functions of a
human to to demonstrate some of these
these ideas and some of these faculties
again I'm going to go back to my kids
and a bit more recently when my model is
about three and a half now I've been
trying to teach you how to catch ball
because as it turns out it's really hard
I do you don't think of it as being
really difficult but it is and and when
she when she started her all I did was
was just set the the task of just
throwing something in the air and
catching it and the first thing that she
did was this she just stood there and I
was still up and you know she got her
throwing bit okay but she had absolutely
no idea how to catch it it's something
that she had to learn and you know the
first thing that she needs to do is
firstly just observe this is an
observational task we need to look at
the ball so I tried to teach her to look
at the ball but she was concentrating so
hard and what I was trying to teach her
she did this I got to physically move
away from me so she wouldn't look at me
instead she did this looked just
sneaking in just win like that instead
so she actually started to try and mimic
me you know she saw I was doing this
that she tried to do this but she was
still concentrating so hard and what she
was doing so you know but there's a
number of different tasks involved the
first one is she's got a classify that
is about right the best example I've got
this is you know when you talk about
chopping something on there on the work
surface and you drop the knife off the
work surface you do this little dance to
try and escape the falling knife it's
like a 21st century Western you know
shooting dance chop shop and and that is
it
classification in an instinctive manner
because if I was to drop some food I
would actually try and catch that with
my foot
you know wouldn't jump out of the way
but I'm from Yorkshire I'm quite tight
you know we've got to save everything
and this is an instinctive thing that we
do it's it's something that we've
learned over many many many years and
she hasn't learned how to do that yet
and the second is observation she needs
to observe the trajectory of that ball
in flight she needs to estimate the
velocity and the gradient and the
position of her body and that's all
really hard to do as well interested in
it for American baseball players they
have learned to watch the pitcher as
he's throwing the ball because the ball
flies so fast they don't have time to
react to the ball in flight they're
using features they're using dimensions
that they've figured out over their
careers of watching how the pitcher
throws the ball so it's quite
interesting when you get an
unconventional pitch II know one that's
throwing it from the floor or up high or
it's got a very strange throwing action
that they really struggle and that's
purely because they haven't had enough
practice or experience to learn the
features of those types of pitches and
then finally she needs to make a
prediction and this is the exam question
that we all probably got on our our exam
for maths or physics and actually it is
still a hard question to solve because
there's lots of variables in there we've
got some velocity we've got to calculate
the differential of that velocity we've
got to take into effect the gravity and
and things like that
yet somehow with lots and lots of
practice we are just able to
automatically do that so it's actually
no surprise that it is actually quite
hard to catch a ball and it will take my
daughter years of practice and that's
kind of a lesson for it for everything
it's a lesson for machine learning
because what that tells us really is
that we need lots and lots of data we
need lots and lots of examples to be
able to train our models to do the
things we want them to do if you're
learning a new subject you need to you
need to take time to practice and
practice and practice
and then eventually you will get better
okay so now let's show you some examples
I'm going to show you a couple more
robotics examples again because they're
so cool in safety all right in a large
LED p10 computer and occupy over 300,000
30 K that word colleges are in the wrong
screen tricky communicates with a
computer shape over a rhodiola it's
about 1960 1965 engineers do the same
today looking which happened to the
computer programs that control shaky and
he's using a teletype printer even a
busy one for all that look like
communicati
the instructions on and the cathode ray
tube display very advanced monitor there
another intermediate level action she's
talking about doing you know shake it
was important or tell it to go left or
go right we just tell it to go to a
specific place it would figure out the
interaction how their ability to recover
from unforeseen and I like this we're
just gonna watch this little bit because
gremlin charlie symbolizes an agent of
change
unknown to shakey I love the video ends
in that the boxing and but it's that was
tell him where the box is okay so that
was about nineteen year 1966 to 72 that
was the state of the art and it was
pretty impressive
in about 2016 pcs from Boston Dynamics
and again this is they're just just
watch this little bit I'll stop talking
for a second
that's what drunk robots look like and I
like this example because it actually
demonstrates anthropomorphism and
anthropomorphizing with inanimate
objects remember that is a robe okay but
as we're watching this this is what's
going through my head I don't like you
stop that
that's this really mean it's let him do
his job he's got a job just let him do
it
don't don't are you absolute no and it
just it goes to show how we can actually
feel for these inanimate object though I
think is fascinating and we'll just
we'll just play one more example of the
man being mean
one idiot don't like that guy
but you know as a as a little dig to
Professor under s as well oh you can't
see that robots are so 1970 you know
nobody's interested in robots anymore
let's move on to the more advanced stuff
and I've got an example here that is
working with a new date a new ish data
set called the the Stanford
question-answering data set and this is
really cool because it's a data set
that's used to tackle a specific type of
problem with text and the problem is
given some freeform text can you answer
freeform questions and that's really
tough it's a really tough problem to
solve so let's just have a look at a
couple steam engine and we'll have a
look at examples here so the text comes
in is like this short excerpt from
something like an excited PDR or
Wikipedia or something like that and
then we are given some ground truth
answers so these are the true answers
that the algorithm is supposed to
predict for the question along with
geothermal or nuclear what is a
noticeable non combustion heat source
and you know so uh so I'll ask you
further and there's a couple of
different potential right answers here
and I've got one of the implementations
of one of the most recent solutions to
this and I don't know if we just pick
one of their pre-written paragraphs then
you can see that it's answering those
free from questions pretty well and
generally if you go through all of these
questions you'll you'll find that it
gets the right answer but the really
cool thing is that if you just ignore
this was it I said generally right okay
I didn't say completely right
daring me bunch of smart asses in the
audience today okay so they ask me how
but I've just got the the full-text of
Hitchhiker's Guide to the galaxy here
and I'm going to ask it a freeform
question first I'm going to ask a
question which I know it gets the right
answer for how how big is a dog who
typed back into my club so my search
history how old and and after a couple
of seconds or so should hopefully get an
answer and there you go and I believe
that's correct huh some of them some
more of the more nerdy in the audience
might be able to correct me but but this
is a really interesting answer assuming
it is correct because it's actually you
know this is this isn't even a number
this is a word that is pulled out of the
text and I believe actually that that in
in hitch I skies the galaxy
there's actually not that many numbers
at all most most of the numbers all
written as words so this was able to
interpret my question asking for a
number even though no numbers exist in
the text so this is a really interesting
result let's ask something and that's uh
something a bit more difficult I think
that this kind of gets the wrong answer
it gets a bit confused yeah so what
planet is safer from galaxy I don't know
that's probably part of a longer text
but it's gotta be a lot but we're all
here to do one thing and one thing only
let's see what it gets I promise you I
have not programmed that that is purely
the algorithm choosing for itself what
life is all about and either it's it's
already mastered satire I'm not sure I
hope that it has either that or it's
that it's already becoming evil and we
should stop it right now
okay and I think we're about out of time
so I'll just finish up is that right
yeah okay so you know what is the
meaning of life I'd the meaning of
artificial life if we if we take
cheering's view
you machines are already acting like
humans so we could ask a human what is
the meaning of life it's the same
question and I'm an engineer and no way
am I going to try and ask those sort of
questions so I just like to end if
you're interested in data science I
started a new a new website in business
training data science comm it gives away
some free training in data science and
also helps people learn online what data
Sciences so with that thank you very
much I have a couple of questions here
and I know we are over time or soon will
be at least okay now because our
pictures to one of them are you looking
forward to use quantum computing in
conjunction with science I don't know to
be honest I don't even know where that's
going to go I mean first there's lots of
practical issues with computer content
computing and when they become
mainstream they're just going to you
know blow over and the whole idea of
being able to compute these complex
processes and they will then become
possible so I honestly can't even
envisage what is going to happen once we
have the ability to predict random
processes that I don't know I mean
ultimately if you could predict the
position of every atom in the universe
you are predicting the future and if
constant computing can even achieve some
you know level of that if they can then
work on some physical level then the
world's the oyster yeah I have no idea
thank you for the rest of the questions
please feel free to come and ask them in
person yeah thank you very much I can
see Michael yours already here welcome
Michael
looking forward to your talk in 20
minutes and just one final note the
example with the cucumber classification
that you showed this is actually one of
the topics for the last talks today
see you around</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>