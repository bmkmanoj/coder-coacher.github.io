<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • Secure Substrate: Building the Moby Whale • Diogo Mónica | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • Secure Substrate: Building the Moby Whale • Diogo Mónica - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • Secure Substrate: Building the Moby Whale • Diogo Mónica</b></h2><h5 class="post__date">2017-10-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bmQxRHsczv0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Diogo Monica I'm the security
leader talker and today I want to talk a
little bit about secure substrate
building the mobi wale so this is kind
of a cryptic title which I hope will be
very clear at this last slide of this
presentation why I use this actual slide
and before I go into the talk itself
just want to talk a little bit about me
I do like motorcycles and I do like
whitewater rafting but as a day job I
run the security team at docker show of
hands how many people actually use
docker and the audience okay show of
hands how many people actually use
computers in the audience about the same
that's good before docker actually used
to work for a company called square
square is an infrastructure company that
does payments and I was there for four
years building cryptography and before
Square and it's not shown in the slide
because it's a little bit embarrassing
but I was doing a PhD and the she booted
systems because I wanted my dad to love
me that totally failed so ok after I
wasted too many years of my PhD I
started working in security and now
today I want to talk to you about some
stuff that we've been working at docker
in particular I want to start with this
terminal this terminal is pretty in the
first place
but the second thing that is showing is
is showing you a docker stack deploy
which is a one command that feeds from a
llamó file and deploys a set of micro
services what it's actually doing when
you do a docker deploy for those of you
that are familiar with it is it creates
networks for you it runs micro services
connects them all to each other sets up
all the environmental variables runs
these containers then all of a sudden by
running one command you have a full
working infrastructure database your
in-memory store your application your
workers doesn't matter what it is you
can actually have a full infrastructure
with one command the reason why I'm
showing you this is this is really easy
but just because it's easy it does not
mean that it's simple so today my talk
is about what is actually under the hood
and to show you what is actually
happening under the hood when you do
this command in particular we're gonna
look at all the pieces that are
necessary for docker stack deploy to
work securely and one analogy that I
actually really like to use is Tetris
show of hands those of you that have
played Tetris okay about the same people
that you would use docker so that's
great Tetris is a really simple game as
you know the goal of the game is to have
these tetra Nomos which is actually
turns out is the official name for those
little things to Tirana Mo's I thought
that was cool the Tirana Mo's have to be
piled up in a way that they create full
lines and don't leave any gaps that's
the purpose of the game whenever have a
full line the line disappears and you
get to continue playing if they all pile
up and you're full of holes then you
lose the reason why I'm using Tetris as
an analogy is because turns out that
Tetris is like infrastructure security
if you leave holes you have
vulnerabilities so today I want to talk
about tetra namas and specifically I
want to talk about the seven tetra Nomos
that are related to security that docker
has actually created each of them has a
different purpose each of them impact
security in some way and each of them is
going to contribute to the final
platform into the final docker stack
deploy working under the hood in a
secure fashion so there's several
different deter animals each of these
two tirana Mo's is actually an open
source software so you can go to github
and see every single one of these as an
independent project we have infrakit
which is a way to manage infrastructure
and an infrastructure independent way
Linux kit which allows you to build OSS
we have run C which is a container
runtime we have container D which is a
container supervisor
we have docker itself which is a
container execution platform notary that
allows you to do signing and finally
swarm kit which is a container
Orchestrator and so I'm gonna go into
every single one of them and talk to you
about the security properties that they
have and why you should be excited and
one of the things that I want to mention
is that every single one of these
pieces are supposed to be able to
operate independently you can use them
and compose them however you like and
throughout the presentation I'm gonna
show you exactly this so let's go to the
first one let's talk a little bit about
implicit what is infrakit infrakit is
actually one of the most recent to
Tirana Mo's the docker has created an
open-source projects and what it allows
you to do is allows you to have
infrastructure independent machine
management and what I mean by this is
that it doesn't really matter what cloud
provider you're using you can be using
local infrastructure AWS Google cloud
platform as your it doesn't really
matter
infrakit allows you to create virtual
machines manage the lifecycle of these
virtual machines the operating system so
on and so forth the reason why that's a
good idea is because we have one tool
one declarative tool yellow-based that
allows you to control all of your
machines and cloud migration becomes
really easy and cloud management becomes
really easy because it's an independent
platform that you get to operate on if
Rickett has a few details that i think
are particularly interesting from a
security perspective and just from a
usability perspective the first one is
the Clara t'v updates so I think a lot
of you are familiar with the clarity of
infrastructure and the concept where you
have infrastructure s-code you define a
file a configuration file that sets what
the infrastructure is supposed to be and
once you commit that something happens
and that ensures that your
infrastructure is in the state that you
want it that it hasn't diverged that it
actually has not changed it's exactly
what you defined as your configuration
their infrastructure represents infrakit
does this for the actual machine
management and it is pretty cool because
the clarity of updates allow you to
actually say for example the version of
the operating system you're running
across your virtual machines so with
infrakit you could have a file that says
I want five instances of this machine
running this Linux operating system then
if you want to update the operating
system the only thing you have to do is
you change in the file the version you
want to change you commit and then
infrakit will understand that the
version is
matching that you want a new version of
the Linux operating system and there
will auto-update it for you using
rolling deploys what this allows you to
do and what I would like you to have as
a security metric is a concept called
reverse of time that I've been talking a
little bit about lately so what is
reverse of time in why should you care
about it as a security metric well
reverse of time is the concept where
instead of you being proud about the
uptime of a server oh I have a server
that has been up for 12 years isn't that
cool instead of following that mentality
of like 15 years ago would you now
follow is the reverse of that you're
excited when the oldest server of your
infrastructure is been alive for a week
for an hour that is something to be
proud of something there's been a life
for 12 years not so much in the reason
why this is important tracking the
concept of reverse uptime as a metric is
because it turns out that drift in
virtual machines in OSS is one of the
biggest causes of downtown so if you're
constantly refreshing your machines if
you have a maximum bound of one week all
my machines cannot be older than one
week and you have something like
infrakit then you will ensure that your
operating system is constantly being
rotated new virtual machines are being
created to meet this dependency of a
week old virtual machine and that
removes drift machines can't drift if
they're constantly coming from a golden
image if they're constantly being
created from a fresh ISO from a fresh
AMI they can't drift from each other and
from a security perspective that it was
an ops perspective management of uptime
and drift but from a security
perspective this is amazing
how can you backdoor an image that
concept gets refreshed you can't have
persistence if a hacker gets in it can
have persistence on the host because the
image keeps getting updated the other
side of reverse of time is great we're
tracking the time the oldest time of the
machine that has been alive but the
other thing that we have to do is we
have to constantly update our golden
image
so another metric that goes alongside
reverse of time is golden image
freshness in this one you always want to
have the freshest image you always want
to update your golden image your ami
your ISO and by doing so having these
two metrics together you know that your
infrastructure is always up-to-date so
things like patching kernel are then
automatically because since you are
tracking reverse uptime in creating new
machines from a golden image that is
patched as soon as possible
then necessarily you have an
infrastructure as the latest patches the
latest kernel and therefore is a more
secure the way that we can do this or
the reason why we can do this is because
infrakit
allows you to do rolling deploys think
you're familiar with wildung deploys
within load balancers the context of
applications and load balancers the same
concept could actually be applied for
machines if you're running an
Orchestrator then it's actually pretty
easy to take the workload from one host
movie to the other one shut down the old
host and create a new one and this is
what I forget does for you it manages
this dependency and allows you to
effectively warn the hosts that they're
about to be shut down removes the
workloads from those hosts shuts down
those hosts and creates one fresh one
from the global image so this is
something that you need to obviously
support this kind of mentality around
tracking reverse uptime so that's
infrakit now let's talk about the next
piece of open source software Linux get
Linux kit is not an operating system
Linux kit is not is not boom boom - what
the Linux kit does is it actually builds
an operating system for you so think of
it as an operating system builder an
analogy that we can actually make is the
same way that docker like a docker image
format is not an image it is something
that allows to build an image and you
have a docker file that tells your
docker how to build this image right you
can always rebuild it and you'll have an
image to be able to deploy Linux kit is
the same thing but for operating systems
so as the clarity of infrastructure as a
declarative mo file you say exactly what
you want from your operating system in
this case you say that you want a kernel
with a certain version
you want this init system on boot you
want to run DHCP and you want to run it
with these flags and you want to make
sure that you're trusting the
organization Linux kit for security in
this case that means that these things
have to become and be signed by us
docker and once you have this you tell
Linux kit to build it in Linux it will
give you an ISO and AMI it will give you
something for you to run so it just
built an operating system for you just
in time why is this cool well the same
way that we always tell you to run
minimal containers run containers that
are the smallest possible that have the
least amount of stuff in them minimize
the attack surface really really small
megabytes size containers the same thing
applies for operating systems why would
you have hundreds of system packages why
would you have hundreds of unused
binaries why would you have that kind of
exposure why would you have gigabytes of
an operating system where you need 1% of
and so Linux kit follows the principle
of least privilege and in this case only
allows you or only puts inside of the
final operating system exactly what you
tell it to so if we built the previous
operating system with a sam'l file
you're sure that that operating system
will only have the HCP and will have the
net system on a kernel that is 4.9 dot X
that's the only thing it will have if
you want anything else in it you have to
declare it what this means is that it's
a really minimal operating system which
is obviously a very secure operating
system it actually goes one step further
and allows you to run your operating
system in an immutable fashion what that
means is that the operating system will
not be writable it will only be readable
so if there's an attacker that gets to
compromise your hosts in be on the
operating system there's no and there's
nothing that it can actually alter
there's no persistence there's no
changing binaries there's no back door
in your SSH number one we didn't have
SSH because we didn't have that binary
and number two it can't write to the
actual operating system so that further
adds to security not only at least
privileged at least Authority in terms
of only the things that you need you
can't write to it other things that we
do in Linux kit we try to incubate new
projects that are up and coming in that
are really additive from a security
perspective
things like Len lock LS M which is a
Linux security module that allows you to
EVP F and kernel we obviously are adding
why guard which is a really secure
alternative to IPSec it is a VPN
tunneling mechanism that is really small
5,000 lines of code and very very well
implemented so secure
instead of IPSec with hundreds of
thousands of lines of code
we are also going down the path of
rewriting system demons such as DHCP
in-memory safe languages like Oh camel
what this means is that the things that
you're adding to your operating system
are no longer written in C vulnerable to
buffer overflows they are written in a
memory safe language which further
minimizes your surfer's of exposure and
your exposure to attacks from the
outside
so this permeates throughout all of
Linux king lease privilege minimal
Authority a final thing that I want to
say is that Linux it is not something is
Oh Tarek in you if you've if you've used
docker for Mac or docker for Windows
you're actually using Linux hid right
now because the way that we build the
operating system that is running inside
of your Mac is with Linux kit so it's
already deployed in millions of hosts
today that was Linux kit now let me
bring you to run C run C is an open
source software that allows you to have
effectively a very lightweight container
runtime we've donated it to the OCI so
it's a standard at this point and what
once he does is the simplest sub
component of what a container actually
is a container at core is effectively a
combination of multiple mechanisms that
the Linux kernel provides to isolate a
process such as namespaces in C groups
so run C is a piece of software that
uses these underlying primitives like
namespaces and C groups in Linux to
create an isolated view of your process
in the system in the case of namespaces
what namespaces actually do is they get
you an isolated view within your
container of the system
so pidz mountain namespace IPC net what
that means is that you'll be namespaced
on all these different components the
pit one being when you're inside of a
container you cannot see the processes
of anyone else you can only see your of
your own so you're effectively
namespaced and for every single other
subsystem in the kernel there's a
corresponding namespace that allows you
to run in an isolated view inside of
your container then the second biggest
component that runs he takes care for
you is configure scene groups see groups
is the way that we limit the resources
that your containers actually have
access to so there are c groups for CPU
for memory for PIDs so on and so forth
using c groups we can mitigate against
container just consuming all the
processes in your host or container
consuming all of the memory or all of
the cpu we're effectively resource
constraining what the container can do
so these two sub components there's more
but these two main sub components allow
you to run contains from memory CPU pit
perspective and isolated container
inside of your OS and that's what once
he actually does UNC is not particularly
useful by itself you can run containers
manually but he needs something to
supervise the containers is the
container seal executing is a container
still running did it
get out with an error code do do we know
what's happening can I rerun it should I
rerun it so we need something to
supervise these containers and this is
why we created container D so container
D got donated to the CN CF and is now
again not only open source code and a
project but it's actually donated to a
foundation so the code no longer belongs
to docker he belongs to the whole
community of CN CF the same way that run
C now belongs to the community of OCI
and so container D as I mentioned we
need a way to supervise these run C
containers so we built this Titano mo in
this open source project to supervise
them and there's a lot of things that it
does obviously understanding if a
container executed successfully
rerunning containers scheduling there's
a lot of things that it does it also
allows you to pull images so the image
pooling component in execution inside of
a run seek
of an image is the job of container of
container D but from a security
perspective there's one thing that I
want to point out that is particularly
interesting that container D does and
that affects the security of your whole
system it is about container pools so if
you are running doctor and if you've
used doctor before you're definitely
familiar with dr. Poole dr. Poole is the
way that you pull an image down to your
hosts to actually execute it in dr.
Poole usually looks something like dr.
Poole and gen-x latest the image comes
and now you can execute it inside of a
run seat container so so far so good
pretty easy but docker
pull and specifically a pull method can
be done with the name but it could also
be done with a hash and so instead of
you saying that I want nginx and I want
the latest AG you could say I want nginx
but I want this specific cryptographic
hash of the content that is remotely the
reason why this is cool is we're gonna
see in a little bit in notary which is
an exit ronimal but the way that this
works is if you provide a hash to
download if you say docker pool or
container D pull a container hash
instead of a name what's actually
happening under the hood is you're using
a content addressable system so all the
sub components of the container
different layers
they have hashes that all hash up to one
main manifest hash so what's actually
happening is when you're saying please
download this specific hash of nginx the
only thing you can get is a secure
version of that content because there's
a cryptographic hash that is being
validated over the whole content of your
container so if you say nginx latest
you're not sure what you're getting but
if you're saying nginx in a specific
hash you know that you're getting
exactly the hash they requested the
reason why this is important
becomes obvious in our next set ronimal
notary notary is an open source software
that we just donated to CN CF so I just
got approved a few days ago and it
allows you to do trusted software
delivery it is arbitrary trust the
software delivery it does not have
necessarily to do with containers but
the way that it works is related to
those hashes that I were describing
in particular if you look back or
imageable we don't want to run pull
nginx random hash of God knows how many
characters that I didn't memorize what I
want to say is I want to pull the latest
version of nginx or 1.1 of our genetics
a 1.5 of nginx so clearly there needs to
be something that translates this human
readable name this version latest into a
secure hash in a way that we can trust
and so that's the job of notary notary
is a generic system that we implemented
into docker but it's a generic system
that does one job really well it
translates names to secure cryptographic
hashes and it does so using digital
signatures it has a lot of interesting
problems or a lot of interesting
characteristics that solves a lot of
problems for software delivery and
there's an attacker model and a threat
model that we have on the notary page
and I recommend you to go see it but one
specific thing that I want to say about
notary is the fact that it allows you to
have not just one digital signature so
if you had a GPG key you would sign a
piece of software with GPG and then you
would verify the authenticity of the
software with one gbg key and there's a
lot of problems with that number one if
the software is out of date
you can't revoke the particular software
that you've signed it will always be as
long as the key is valid that piece of
software would always be valid with
notary that doesn't work that way and if
you have just one GPG key you only have
the ability of signing with one key if
that key is compromised you don't have
an option as how to recover from it and
what if you have or the need for
multiple systems a security team
approval and an OPS person approval what
then nor do we solve that problem by
allowing to have threshold signing so
what you can say with notary is not just
verify that this content in signed but
you can say please verify that this
content was signed by the CI system by
the staging system by the security team
by the deployment system can add as many
as you want and then the running system
the container will only be executed if
it got signed by every
single one of these entities in this
threshold so that's one of the biggest
characteristics and the other
characteristic is in the GPG case if
you're signing software with just a pure
application of GPG Becky's compromised
you're effectively screwed you have to
go back and just reset all of the poly
key components you have to redo the
whole system you have to send a new
public key down to all of the hosts
effectively you just go and modify every
single host with notary you have
something called survivable key
compromise what that actually means is
that if the key gets compromised you can
actually bring a root key that you
always keep offline online to
automatically rotate it and you don't
have to change anything on the final
hosts there are some technical
components as to why this is really
interesting but from your perspective
the only thing that matters is that a
key gets compromised in the CI staging
does matter bring it off like key online
rotated and in seconds you're done the
old key no longer matters an attacker no
longer has anything of value and that is
something that is really important for
you to have in every single system that
you have that uses cryptographic keys
the ability of having survivable key
compromise and so this brings us to
docker because docker does a lot of
things but docker uses Runcie the
container execution supervised by
container D the supervisor platform in
notary for secure image pulls in the
combination of all of this
in a couple more things is what docker
actually is which is a software
container platform in addition that I
want to mention over run C and container
D docker comes with SC Linux and epimer
profiles so already comes with secure by
default profiles that just by doing
docker run you inherit so effectively a
container d container or a run C
container they don't know what profiles
you want to run docker comes with
opinionated profiles to ensure
effectively a good balance between
usability and security it also comes
with a capability whitelist
so there's something in Linux which is
capabilities which is dividing the
authority that the root user has and
smaller sub pieces and when you run a
docker container you have less than half
of the capabilities that you have
enroute by the
and again there's a good compromise
between usability and security by
default we also have a system system
called whitelist that allows us to
mitigate surfaced of exposure of the
kernel if by any chance somebody
compromised the container and tries to
attack the operating system kernel from
the container
we're mitigating some of that surface of
attack because system calls are being
whitelisted in dangerous system calls
that we've removed from the whitelist
can't be actually called so if there's
an exploit or a vulnerability in those
it doesn't actually affect your system
then finally as I mentioned node
reintegration comes by default you just
enable it in all of a sudden you can use
a very simple way dr. pol docker push
with the sophistication of notary and
the ability of having integrity and to
end multiple signatures rival key
compromise so on and so forth
and this brings me to the last atrani mo
debt talkers created which is called
swamp kit not last in order but last
that I'm going to talk to you talk about
today
swamp kit is a least privileged
container Orchestrator what that means
is that we took extreme care in swarm to
ensure that each node that is executing
your containers only has access to the
resources into the code and to the
containers that it needs for its purpose
no more no less and I'm going to go over
a few details as to why this is true and
all the things that we had to go through
to ensure that this was true and the
first one has to do with secure node
introduction running containers in one
host is great but if you want to scale
it across multiple nodes and you're
constantly adding and removal nodes
removing nodes you have to have a secure
way of introducing these new nodes to
your cluster in a way that you know is
trust that in that no attacker can
either join a node or join a note to the
cluster or man-in-the-middle the joint
of another Custer or impersonate a node
in your cluster so we created a
mechanism that that uses secure node
introduction that is actually pretty
simple it's based on a token that you
are probably familiar with there are
things that are similar to provide a
token to join a node and that token
ensures several things number one
ensures that there's into n security so
the node trust the
cluster and the cluster knows that this
node has the authority of joining and it
also allows you to issue a certificate
for each individual node and a
certificate is actually going to turn to
be the identity that each node in a
swamp cluster is going to use for the
lifetime of the duration of this node in
the cluster so every single node by just
joining a swarm immediately gets an
x.509 certificate which as you know is a
normal type of certificates that are
used in your PKI but we do that all for
you by just you running docker swarm in
it automatically a certificate authority
gets created for you
certificates start being generated and
certificates start being rotated
automatically and for the people in the
audience that actually care about these
things this is what a certificate looks
like has a couple of characteristics but
one that I want to mention is the CN is
the note ID that is a unique randomly
generated ID that is going to live
throughout the lifetime of your node
that you can actually trust instead of
having a name or hostname in a know that
you can trust you have a cryptographic
identity for every single node in your
cluster and this is going to become
really important because now that we
have a cryptographic identity for each
node of our cluster we can do something
really cool we can have mutual TLS
between every single one of our nodes so
in this cluster when you join the node
automatically all the communications
between the nodes and the managers the
managers being the more privileged nodes
and the workers effectively being just
the nodes that are gonna execute our
containers
everything has mutual TLS so the nodes
authorize the managers and the managers
authorize the notes the nodes know what
specific manager they're talking to and
the managers know what specific nodes
they're talking to this is really
important because if we're using TLS it
means that we have confidentiality
integrity and authenticity of every
single communication it means that
everything that we send to a worker such
as secrets it is encrypted in transit
right every single secret that we send
to the node there's no man in the middle
that can intercept a secret for us and
so this is actually something that is
not true of a lot of other orchestrators
out there when you set up a lot of other
orchestrators you don't have TLS by
default you have open access to secrets
there's no authenticity everybody can
access everything and so for us the
least privileged and the secure by
default principles came together in to
let us give you a CA that comes by
default that gives you these properties
and now that we actually have mutual TLS
because we have some identities that are
being rotated for you automatically as
as as low as every hour so you can
rotate certificates automatically every
hour if you want to and we have
certificates that are your identities
that are being rotated automatically for
you without you doing anything and so on
top of this we can now do secure secret
distribution so when you're running in a
swarm we wanted a way for you to get
secrets such as tokens or private keys
or TLS certificates for your apps
securely to the actual containers how do
we do that these are sent over the
network how do we know we're getting to
the right containers
well we're building on the primitives
that we got so far since we securely
introduced the note to the cluster we
know that there's no rogue nodes in the
cluster since we issued cryptographic
node identities to each node we know
exactly what nodes were sending this
information to and since we're using
mutual TLS for all the communications we
know that these secrets are being
delivered securely to the final notes
they're going to use them so this is
really important and allows us to
actually just spread the secrets run
containers rotate secrets in a secure
fashion another thing that I want to
mention is by default the secrets that
you act with swarm get stored in the
managers and get automatically
replicated obviously for full tolerance
but they get encrypted at rest again by
default so there's no component of the
system that does not come turned on and
you can tune it but the choices that are
done for you from the get-go are the
right ones so now let me tell you a
little bit about transparent rotation
I talked about this concept of
survivable key compromise for notary
which was the concept where if a key
gets compromised you don't have to do
anything but click a button in the key
rotates for you this is something that I
care deeply about and that it's really
important in security because the first
thing you have to do when you're
compromised is to rotate all the keys
but if you have a cluster
that doesn't allow you to rotate all the
keys what do you do you have to create a
cluster from scratch and so what's warm
we took a lot of care and making sure
that everything in the cluster allows
you to be rotated the secrets you can
rotate them add a new secret and
automatically be distributed to all the
containers but now the question becomes
what about the root key what about this
CA the certificate authority that is
actually issuing the certificates to the
notes what happens to that certificate
authority what if a manager gets
compromised because if a worker gets
compromised we know how to remove it
from the cluster we delete the
certificate and everything is good but
if the manager gets compromised the
manager has access to certificate
authority
the manager effectively allows new notes
to join the system in issues those
identities for the notes so it has the
key material of the root CA what do we
do then well and this is where a lot of
security engineers disagree and I
usually disagree and have a kind of
different opinion
usually security engineers we're drawing
this on a board we create a manager we
have all these workers and when they
come to this problem they say oh if an
attacker compromises the manager we're
screwed
there's nothing we can do let's just do
a new cluster for me the answer is not
shrug let's just create a new cluster
the reality is that the majority of the
times you don't have attackers
compromising your cluster the majority
of times what happened was that somebody
posted the private key to github or
somebody backed it up to a place that it
shouldn't have and so you need the
ability of actually rotating from this
situation and so now we have the problem
of we're trusting one root but we don't
know how to rotate it so it's warm we
went one step above and it's something
that I've never seen any Orchestrator
out there do and we allow you to
actually rotate the root of trust in the
way that we do it is actually turns out
to be pretty simple you have trust in
the blue certificate authority if you
want to rotate it you create a new red
certificate authority but what you do is
you create an intermediate so you sign
the new root with the old root and so
now you have two roots in the managers
but at this point all the notes still
trust each other and all the nodes only
believe in blue the next step is we go
through all the nodes
in issue a new certificate for every
single one of these notes but the new
certificate is not going to be signed by
blue the new certificate is going to be
signed by a chain of red of blue reds
and red so what it means is that all the
nodes are going to get a new certificate
that is actually issued by red but
trusted by blue because it is an actual
intermediate and therefore there's a
chain from red to red to blue that every
single node trusts the reason why this
is important is because while you're
rotating these the nodes have to trust
each other so it doesn't matter if nodes
has a note certificate from blue or a
node already has a new certificate from
red they have to communicate with each
other and therefore they have to trust
each other so this is why this step is
important and so after we do this first
pass we can actually invent that is then
issued by red we can go in and actually
take blue away and only trust red and so
now we went from we don't trust blue or
we trust blue to we no longer trust blue
we completely rotated the route of trust
of the certificate authority okay so now
let's actually bring it all together I
showed you seven different tetra Nomos
every single one have different security
properties all of them could use used
independently so let's actually use them
first combination that I want to do is
notary and docker
what happens if I bring notary and
docker well if I bring notary and docker
what I have is cryptograph
cryptographically verified pulls notary
is ensuring the authenticity of the
content docker
is running so it doesn't matter if
there's a cloud if you're hosting the
content or the images on an HTTP mirror
completely unencrypted s3 you are
ignoring effectively the trust of what's
in the middle the final container
executor your final docker host is only
trusting the key not the intermediate
place where it's stored this is great
what if we do swarm kit and join it with
docker well in this case these
Deuteronomists together what they're
gonna give you is they're going to give
you an authorized authenticated and
encrypted way of effectively
communicating between all notes okay
that's cool by itself not particularly
useful but we can continue what if we
join
the Tet ronimal infrakit with swarm kit
what you're going to have is for any
system that you want a secure way of
doing node introduction I describe to
you in general terms how that worked the
ability of having a token that secures
end to end certificate issuance does not
have to be used with docker you can use
it for your own machines for anything in
your infrastructure what if we put Linux
kit and use it as the base OS builder
well obviously what we're gonna get is
harden configuration we're gonna get an
operating system that is minimal comes
with secure defaults and it comes
actually built from the ground up to be
least privileged and we can continue
let's connect notary and swamp kit let's
see what actually happens there or
notary in Linux kit what we're gonna
have now is when you're building a Linux
kit OS if you're using notary now you
have cryptographically verified builds
every component of your operating system
that is being pulled in is being cryptic
graphically verified with notary that's
awesome can we continue going down this
path well let's try to get infrakit plus
notary for West provisioning if we now
add infrakit plus notary plus Linux kit
what do we get we get something that is
awesome which is cryptographically
verified boots so infrakit
spins up a virtual machine it uses
notary to resolve the secure hash that
it should be running and then it can use
linux kit to do DM Verity VM Verity is a
linux capability that allows you to
ensure if the image running on the
remote host is the image that you
actually want it and so there's no way
for an attacker to mess with your supply
chain and to load a malicious image in
your virtual machines or in your hosts
because your cryptographically verifying
it and so this is something that we
might do in the future but it's a cool
way of combining these building blocks
into something really cool but we can
keep going what if you layer Runcie
container D and docker well we obviously
get a secure by default container
execution which is what docker provides
you by default when you install it and
just do docker run now they were in the
complex ones what if we add run C
container D docker
swarm kit a notary just jumble them all
together what is this Geddes well it
gets us to secure by default container
platform
it allows you to have the execution of
containers secure distribution of
Secrets secure note introduction in
containers being executed with Runcie
container d in a lease privileged manner
and now the obvious final question is
what happens if we put all of this stuff
together all of the tirana moles and
just like put them in well what do you
get is secure by default infrastructure
you get remote at the station
verification from the boot golden images
being created with minimal linux kit
os's running minimal docker containers
that have secured default configurations
in a cluster that has mutual TLS and
secure secret distribution all with the
digital signatures of notary and keep
transparent key rotation so in terms of
conclusion today I talk to you about
infrakit the way that you can do machine
management in docker or for any system
really we talked to you about the
ability of having Linux get the minimal
image secure building we talked a little
about run C we talked a little about
container D and we talked a little bit
about docker itself and then finally we
talked about notary which is the way
that you do digital signature
verification and we talked about swarm
kit which is the way that you do
container Orchestrator so what happens
when you bring all these pieces together
you get the moby whale thank you very
much
and just so just so you know it took me
20 minutes of my life to do this
animation so I'm gonna do it again and
there you go all the pieces came
together in the end so we have a few
questions that were submitted to the app
and I want to read them out loud so this
is the question
degra has done a great job at providing
mechanisms for securing infrastructure
when will we see Duggar do the same for
application code executed inside a
container it's an excellent question I
would say that we already have it right
now so if you think about it when you're
running an application and you put it in
a docker container the only thing you're
doing is you're securing it you're
adding more security you're by default
adding the ability of mitigating access
to the host you have capabilities that
are dropped you have Linux security
profiles you have minimal exposures to
the kernel and you obviously have
contains a view and in terms of resource
you have an app that is now segregated
from the OS so if nothing else you don't
change anything in your system the only
thing you do is you have your current
system but then you put your application
inside of docker you're effectively
making them more secure by default the
virtue of putting in docker itself this
said we're going one step above we have
something like that is called docker
security scanning that scans images
docker images for vulnerabilities and so
if your application has a vulnerability
such as heartbleed that will be detected
so the fact the fact that it's in a
format that everybody knows you can use
tools like core OS has a tool called
Clair we have docker security scanning
but just the fact that docker has an own
format of an image is already helping
the security of your infrastructure
because everybody knows how to scan it
everybody knows how to unpack it
everybody knows how to look at the
binary over little bit of
vulnerabilities and as time goes on
these things are only getting better
the default mechanisms of isolation of
docker are only getting better which
means that the security of your
applications is only getting better if
you have a crappy PHP application that
has remote code execution on it if
somebody goes into it you can actually
just run docker containers docker run -
- read-only and now nobody can write to
the docker container the attacker has
remote code execution but it can't
download payloads it can't compile tools
it can't attack the kernel it makes
lateral movement
harder so my argument is it already does
help your application security and it's
only going to do more in the future
all right last question it's a
questionnaire here it says relatively
basic question
so darker and ufw has bitten me exposing
data to the public web well I fought ufw
insured limited access what is your
recommendation on IP white listening
access docker to docker containers so I
think YP I peel white white white
listing is not a security feature I
don't think you should ever use IP by
listening for any kind of security the
right way of exposing things to the
Internet if that is your goal is to use
TLS so you can't configure docker to
actually just listen on TLS and if you
don't have to listen on the internet
then just listen on localhost or use the
default docker socket docker doesn't
listen on the network by default so
close your firewalls close your ports
unless you know what you're doing do not
expose your docker to the world thank
you thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>