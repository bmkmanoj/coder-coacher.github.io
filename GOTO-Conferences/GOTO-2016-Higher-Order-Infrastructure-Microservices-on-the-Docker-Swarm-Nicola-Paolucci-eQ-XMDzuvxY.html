<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2016 • Higher Order Infrastructure - Microservices on the Docker Swarm • Nicola Paolucci | Coder Coacher - Coaching Coders</title><meta content="GOTO 2016 • Higher Order Infrastructure - Microservices on the Docker Swarm • Nicola Paolucci - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2016 • Higher Order Infrastructure - Microservices on the Docker Swarm • Nicola Paolucci</b></h2><h5 class="post__date">2016-08-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eQ-XMDzuvxY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone good morning I hear
myself amplified this all means we're
ready to go I see my title see I ordered
infrastructure micro services on the
docker swarm how much more buzzwords
could I fit in a title I think I did a
good job
apart from that so briefly about myself
my name is Nicola pallucci I'm a
developer advocate at Atlassian we make
confluence JIRA HipChat it bucket I
wanted to see if you guys were ready
video but today I'm here as an
enthusiast of you know containers and
docker have been an enthusiast
passionate experimenter and adopter
since the very beginning and so it has
been a theme of this of this conference
we've been hearing about micro services
and containers for a little bit so I'll
give you my take and a path of
exploration slightly different than the
ones you've already seen but before we
go there
what did just do very briefly also
because yesterday I saw some hands of
people not very familiar with with
things so instead of twelve twelve
slides on what docker is I just want to
tell you what happened three years ago
docker has recently past three years of
age mark which is impressive that for
such a young technology to have changed
the way we think about you know
deploying to the cloud and so even
though the technologies underlying
docker were there for many years and we
heard how Google were using containers
for twelve years already
when docker came along what docker did
was springing this technology and making
it approachable to the average software
team and so we met they managed to form
a community that agreed on a way to
package an application a way to define
interfaces into a running application a
way to cache the building blocks of your
applications and a way to store these
deliverables that you want to move so
this was incredibly successful because
this sort of technology was a little bit
esoteric in the past and and with the
usability of docker this became you have
caught us behind by storm and
industry has been seeming to adopt it
with the great infuser of enthusiasm
over the past three years now the next
step on this is what we've been caught
obviously talking across this entire
conference which is the move from
packaging a single application to say
working at a slightly higher level of
abstraction so what we've been talking
about as orchestration so the developer
doesn't think or doesn't worry too much
anymore about the physical
infrastructure underlying the the the
the application that you need to write
but just about the relationships between
the pieces and the components and the
services of the applications that they
need to write and so this is brought
obviously this is a very brief and just
just a random sampling of reasons why
this has been helping us developers of
all in all sizes and of all kinds of
teams to move the containers move to
orchestration isolating you know your
your application into tinier services
and in moving to immutable
infrastructure where you don't really
care where a certain piece of code is
deployed as long as it's it's up and
running and it supposes the ports that
they need to explore this exposes it
makes it easier to upgrade easier to to
to roll out it it it's also because as
we will see you'll be able to describe
at a high level how the various services
are connected to each other
it makes it easier to reason about and
having an overview of how your
application is linked and obviously all
these orchestration frameworks we've
seen yesterday's measures we've seen
kubernetes and today in this talk we'll
see a little bit of docker swarm they're
built for with resilience and scaling in
mind and so obviously nothing comes for
free but those those frameworks really
help thinking big and scaling your
application
to a big big trough had to handle big
traffic big loads so having said that
what I want to do with you today is to
actually work on a polyglot application
built on tiny services and we're going
to do it from scratch together using
docker swarm now I see in the audience
your level of enthusiam for this level
your level of appetite some of you are
like this some of you are like this
screaming so I hope you all are in this
category we eagerly anticipating seeing
the docker swarm things but first before
I do it we just want to give a brief
disclaimer brief demo with as we all
demos there was a few corners that I
needed to cut to fit into the 30 minutes
some of the building of the machines
will be sped up some of the you know
distributed login setups maybe we skip
it for this time so bear with me with
this because we just want to give you a
sense of what's possible and otherwise
this would take you know a few more few
more hours to set this up the other
thing I want to show you so what what
are we are we going to work through it's
a simple application you might have
already seen this it comes up sometimes
in the docker compose demos but we're
going to take it and actually deploy it
onto a docker swarm and we're making to
make sure that there's a reverse proxy
in front of it and it's a fully fledged
tiny microservices application so it's a
voting service there's a there's a
certain domain to vote to cast votes
there's a certain domain to see the
results from a point of view of the
other demo it seems relatively simple
maybe you could do this with a very
simple monolithic database driven
application what we're going to do it
the new way the trendy way with micro
services this is the architecture that
we want to build we want to reverse
proxy at the front of application that a
load balancer that distributes class
traffic to the proper services and we
will have so polyglot a micro service
application so we'll have a Python
application that receives the votes and
instead of storing them directly into
the database because we have to end all
such a real time
traffic we're going to store the votes
into a key value store using Redis the
votes are then stored in a more
permanent database using a worker which
is written in Java and to get the
results actually there's a results
application which a different team is
written in ojs and that's going to read
the results from the possible database
so it's a simple application but it's
non-trivial and it can easier sense for
how to do this so we want to give you a
sense of how to do you would do this if
you wanted to use docker zone
orchestration tools so what pieces do we
need to make this happen we need a way
to create machines that have docker
configured I tell the machines that are
part of a cluster all in the simplest
possible way we need a higher level
configuration that to describe how the
services should be related and connected
to each other how the web applications
should talk to the data sources how the
reverse proxy should you know pick up
when a new instance of of our
applications are spun up and down and we
need a cluster manager something that
actually knows what physical
infrastructure we have available and can
deploy applications onto the various
machines using some business rules that
we will decide and then there are some
side concerns like obviously the nodes
in your diverse cluster need to be able
to know each other's IP addresses and
names so we need something to manage
overlay networks we need a way to manage
logs Mount of Olives and so on so for
all of those Dockers Dockers own tools
do there's a tool that does each of
these things so doctor machine is is
able to provision host on the fly on a
number of interfaces or service
providers a docker compose is a as a
utility command that allows you to
describe at a high level your your
services and then deploys them for you
on the swarm docker swarm is the cluster
manager created by by Dockers own open
source team and then there's nowadays
embedded inside the docker commands
there's a way to create a net overlay
net
works it's a it's a pluggable
architecture so you can plug in the
network network driver that you're more
familiar with and also volumes nowadays
are first-class citizens of the docker
commands and and so on there's other
concerns that we need to take care of
some we will do some we will you know
elegantly gloss over for one thing for
sure we want and we will need and I want
to show you to you is how to make sure
you have a dynamically reverse proxy in
front of your application we will need
the discovery service that keeps track
of which machines are part of the
cluster and there's other other concerns
that when you build these sorts of
architectures you will need though most
likely we will not covered them today so
from the point of view of physical
machines we will need we will this is
how I imagined and will design our tiny
cluster we need a cluster manager where
we run this docker swarm that we will
you will use a discovery service I'll
tell you more about that in a bit we
want you know a front-facing machine
that's gonna host a reverse proxy know
and hopefully will will be hit with a
lot of traffic then we'll have them one
or more machines that will handle all
our services the web applications the
workers and will have a slightly
different kind of machine to handle
database loads we will store probably
poscar sequel and maybe Redis so that's
that's what what it's our plan I want to
give you a brief word about docker swarm
so that you can compare it well it's a
similar solution it's a similar tool
than what we've seen kubernetes is
capable of doing mezzos is capable of
doing what what docker swarm does it
allows you to run docker commands that
instead of running on your on a single
host run across an entire cluster - so
this is a very high-level
briefly drawn architecture or docker
swarm there's a master which can be
redundant there's a discovery service
and dr. swarm supports quite a few of
them
it's the console you can you can pick
and choose and
dr. swarm obviously is able to deploy
and run containers on all the machines
that are available in the swarm it's
themselves so to do accomplish that
docker runs
swarm agents on each of those in your
doctor enabled machines and to be able
to accomplish this we need a discovery
service so what docker swarm does is
delegates which machines are part of the
swarm to a discovery service in this
case we'll use a console from Hoshi Corp
you've seen how she could present
yesterday and so the first step in this
process is let's start from actual basic
is to create the physical infrastructure
that we need so to do that docker has a
very powerful command called the docker
machine that allows you to provision a
host on a number of interface as a
service providers and it's quite
powerful and supports a wide range of
providers and even though the docker
create commands can become relatively
lengthy the structure is very simple you
say doctor machine create you specify
the driver which indicate in this case
is the service provider that you want to
use for this example you see on screen a
pictu digitalocean so in that case I
need to provide my digitalocean
authentication key it's an environment
variable so that you cannot steal my
password my key and deploy machines of
my hosts and then your space might want
to specify a region you might want to
specify the size of a drive the kind of
drive you want there's a there's quite
many flags for each provider that you
choose and then you give it a name so in
this case at the screen you see creating
the console machine where we'll hosted
our discovery service but we are talking
about creating a swarm so we want to
create a swarm we need to pass a few
more flags to docker machine so don't
get scared this this can be all
obviously scripted out when you want to
create a provisional host with docker
swarm enabled you need to add a few
flags like swarm hey the laser doesn't
work okay so do you see there - the
swarm me it means
reprovision a machine that's actually
part of a force worm in this case we're
creating the swarm master so we add the
- - swarm master and if you remember the
architectural diagram from before you
use you remember that the swarm requires
a discovery service so each machine we
at which machine that we create and
provision as part of a swarm we want to
make sure that the machine knows where
to advertise when the machine is up when
the machine is down and what swarm it's
part of that those are the flags you see
like swarm discovery option D and and
the cluster store means like where we
will store information about the cluster
so this how it look if we will do this
now
I have sped it up a little bit so I
created the script that contains a whole
host of docker create commands this is
the one that creates the console machine
then this is just the command to run
console on that instance and then I have
quite a few of these can you guys see or
is it a bit yeah thank you see you can
and so you see there's all right cool
and so there's that's quite a few
commands the important thing to see here
is at the time of creation
I can annotate with labels vhosts so
this is what we will use instead of
using IP addresses or storing by hand
the configuration files of the of domain
names we can undertake all the machines
with labels and then we will be able to
use those labels to deploy workloads
based on those tags we have created so
I've now will actually go on to create
this I have sped up a little bit this
process because depending on the service
provider that you use this might take a
few more minutes and then we would lose
too much time just looking at this dark
screen so I this script just going to go
out and create the five machines we need
so I'm going to speed it up for you a
little bit as you can see it's created
the proxy has created the service
machine
is it a little bit cut and now if I do a
darker machine a less and part of me for
grapping because I have quite a few
machines that was being experimented on
you can see that I have five machines
created only one is not part of the
cluster which is the console instance
which is a discovery service and then I
have a cluster a swarm manager a
database a reverse proxy and a machine
for the services and if I want to see I
want to switch my docker command to
actually affect the entire cluster I
need to evaluate some environmentally
specifically the one from the docker
from the machine called cluster and now
I can do type docker info and Thai and
see that we have four nodes available
and I can see all the information all
the tags related to that to those
machines don't get too caught up looking
at this I just want to provide you a
brief summary at the end which is here
go back here so this is what we did we
created some a few docker machine
statements and those are the five
machines we created just with those
commands programmatically if you go if
we go and check in the digital ocean in
the instance you'll see all those are
the five machines and I've been they
know I'm going to be built by the second
for the uptime of these machines so we
have created this by using docker
machine and basically five dollar
machine create commands now the beauty
of docker swarm is that as other
orchestration platforms that we've seen
in the past day that's where the beauty
of us a burst of abstraction campaign
because docker swarm comes with
strategies and filters and so it allows
you to define a very in a very
fine-grained but still high-level way
how you want your workloads in your
application to be deployed so strategies
are for example a spread strategy will
try to deploy your applications or your
containers on as many machines as you
have available to spread out the load
and beam packing straw
tgd which we heard yesterday we're
talking about mezzos it's about saving
resources so packing as much containers
as much resources as possible on an as
little number of machines as possible
and the filters are the the the tool
that allows us to decide where gives the
business rules of where services should
reside so you can say I want to run this
only where X amount of gigs of RAM is
available or I want to run we can create
affinity filters so you can run or log
in service and you always want the login
service to run together with the
application that it needs to log
so all those allow you to find greenly
decide where to deploy your resources
across your cluster so what we want
docker swarm to do and we want it to
deploy you know the reverse proxy on the
reverse proxy machine configure it
properly whenever something comes up
like the results application which needs
to be deployed on their services box and
needs to the reverse proxy needs to pick
it up and direct traffic to it and the
same goes for the voting application and
the workers and we want Dockers want to
deploy also obviously the database on to
mesh on to database capable machine and
correctly link the applications to the
data sources now the old is linking
maybe we think we need some
configuration to make this happen
right so we do need we need a way to
link our components and to do this the
docker ecosystem has created a tool
called the docker compose docker compose
is a command-line tool that comes with a
configuration file which is written in
yml and it's a relatively readable way
to define your services now don't ask me
how I came up with this image when I was
designing I thought maybe you were all
like giggling and eager excited to see
how to configure docker compose to make
this application this demo application
happen I see you doll giggling so this
is working cool so the the docker
compose format is very readable
it's gamal file and you described at a
very high level where do you get the you
know release version of your application
and that is in the in the in the image
in the image section if you are building
the images at the beginning you can even
pass you know the folder where the
application is running that is in the
build build a flag over there you
specify which port is exposed by the
application and this is fairly recent
you can now specify on which images
these service depends upon so you can
you can specify for example for the
voting application we depend upon
register being up and running now the
interesting part of all this piece is
the environment variables part which is
how we communicate to docker swarm the
constraints that we want to impose onto
this machine in this case we want to
make sure that this service is started
on an instance that we tagged for
services this will make sure that we
will be deployed on the services machine
one or more of the services machine and
to make sure that the reverse proxy
picks it up in us and serves it when
somebody types on the on the hostname
vote the cluster local which I have you
know temporarily set up as a fixed IP
address we add an environment variable
virtual host which will be picked up by
our reverse proxy I'll show you how that
works in a bit so just to go through it
the result application is exactly the
same the only thing it changed that
changes there is that instead of
depending on radius it depends on the
permanent database DB and if we go
through the next the worker which is
remember it's written in Java also as
just an image that I published somewhere
on a private registry and I want to make
sure also that it runs on on an instance
labeled for for services and I just used
very plain vanila configurations for the
data sources obviously more complex
setups will require slightly more detail
the only thing I did here was to specify
explicitly the node where I want the
database to be so instead of using
label constraint in this case that you
use the node constraint so I say deploy
this on the machine that I called DB and
I specify the ports where red is need to
run some volumes that that Postgres
needs now there's one final bit of all
this configuration which is configuring
the reverse proxy that dynamically will
need to redirect traffic as the
containers come up and down and are
spread out across multiple machines so
to do this we use a I use a open source
project called nginx proxy and the nginx
proxy works in a very clever way it
inspects so first it connects to the
docker swarm intercepting all events
into the into the swarm so it can can
see whenever container is started and
stopped and then when whichever
container has an environment variable
called virtual host it will then refresh
the nginx configuration with that
information and start serving traffic to
it now the trick the problem with the
docker compose configuration in this
case is that you cannot run commands
inside the docker compose configuration
file so you cannot at runtime when you
run docker compose have dynamically feel
it the IP address of the docker swarm so
for that you can actually use a trick
which is to load up the proxy dot M
environment variables which is like a
file on the file system and that you can
generate with with a small script I had
the demo of that but it's not that
interesting the result is that
environment variable file contains
basically the IP address of the docker
swarm once you have all of this set up
and by the way we've gone through it a
like section by section but it's just a
single file with just a handful of lines
I know what you guys are thinking this
has been a lot of talking where is the
demo the boss key when are you too old
to see this it's like ok well ok I've
embarrassed myself enough now maybe
something cool will happen after all
this ok so let's see if all this set up
after all this setup index
Polynesians what do I need to do to
bring up my my cluster I just need to
type docker compose up send it in the
background and this will is will pool I
also sped it up a little bit will pool
all the images needed on the machines
that will want to run them and it will
be a little bit anti-climatic because
yeah we're done so the system is up and
running
I can do docker compose vs and I see
that all the tiny services that I
defined are actually up and running but
amore and so now let me actually show it
to you so I have added to my host the IP
address of the reverse proxy and now I
can so I have a voter cluster that local
and I came you know vote if I like more
cats or dogs very creative and if I do
docker compose logs myself you can see
that all the applications the aggregated
logs of all the applications are showing
and I registered that I voted then I
have another subdomain that is the
result application which will show that
I actually voted dogs was a bit scared
for a second that it would show the
wrong result but that didn't happen now
to prove that you know the system works
I'm just gonna do an anonymous session
and vote the other and you should result
should equalize oh by the way you see
all those pings coming from the result
application because just to be fancy
that's a node a node is application
using socket IO so it's gonna it's
pinging its ping in the backend to know
if there's new results so that you can
update dynamically so the next the most
important bit of it is actually to show
you where thank you is to show you where
the applications are running and if we
go and check with the doctor PS you can
see that actually the node.js
application has been deployed on the
services machine see their services
there means it used the box that we
named services and if we look at the
was the other one that the database is
running on the database so everything is
running where we have specified in the
labels that that we had defined so the
nginx proxy is what is running on the
reverse proxy machine now what
so yeah magic so what about scaling so
the the obviously this is very nice a it
works but at one point our microservices
this voting application becomes
incredibly popular and we need to
increase the scale well this this is the
beauty one of the beauties of and also
very very simple approach to scale
application using docker compose and
once you have your services properly set
up and properly tagged and let's see
what we would do if we realize that the
services machine because it's running
quite a few services it's becoming a bit
busy and we need to provision a new one
and make sure that everything works and
scale it up to there so we start by
creating in your machine so let me see
so I've typed out one of the darker
machine statements that just very
quickly briefly reviewed together I
specify a base image that I want to use
Debian 8 works very well with the docker
swarm and the requirements for the
kernel versions that you need to use to
use overlay networks we specify region
we specify that that machine is going to
be part of a swarm we link it to the
proper discovery service and we're gonna
call it services too by the way we have
to label this machine as an instance to
handle services so you see we read their
engine label instance equal service
that's the cue that would that then
docker compose and docker swarm will use
to deploy new services onto the unto
this new machine so if I do that so this
also is a little bit sped up this might
take just a few minutes more than what
we have before this talk and after we're
done then the thing we
to do is scale right so imagine that the
result application is being hit because
it hit hacker news and we need to make
sure we can handle extra traffic so the
way we do it is we Sarge's just to show
you that I have actually created the
next row machine you see that the the IP
address is different also it's a tiny
minor new version of docker
because I've done this a bit later and
if I want to scale it up just go faster
so I want to scale up I can just type
the darker scale there's a type of there
you fix it I want to scale the result
application to actually run into four
more containers for more instances and
this is actually not sped up it so this
is actually the speed that he took to
start them up and now if I go and check
you'll see that we have actually sped up
on the new services machine the result
of the result application now to prove
that I'm not lying I'm just gonna pick
one of these IP addresses and because I
haven't been explicit I've just picked
her they they've peaked and running on
exposing a random port but the reverse
proxy is going to pick it up because it
is so as you can see the actual instance
itself is running at that new IP address
which is a completely new machine just
provisioned and the reverse proxy will
pick up will interject interject that
this new container has been started up
refresh the nginx and the traffic will
be you know distributed also to this
machine I don't have a demo to show you
this because I thought I'd run out of
time which in fact I am I only have a
few minutes left so I just want to
briefly conclude with telling you that
okay so
docker swarm has been catching up to the
other orchestration platforms that have
come about and they had a lead start but
they are quickly closing the gap so
darker compose has a
has been improving really well the
support for overlay networks so all this
becomes possible and transparent in the
end very transparent to the to the
developer and there they recently
changed the configuration so that the
volumes and networks are first-class
citizen of the configuration there's a
very often requested feature of the
docker swarm that right now is now part
of the docker swarm which is like
rescheduling containers on failure on
node failure which is something that was
missing previously but now it's out of
the experimental phase and and makes the
Dockers one compelling again and you
know there are more recent news that
docker is now using the native
components of the open container
initiative so there is interoperability
with other choices that you might make
and choosing component so this with
three minutes left just want to thank
you for your attention and laughing my
silly jokes and maybe there's time for
one question or two so thank you very
much thank you
oh and you can follow me on Twitter if
you if you think it's we have time for a
question of - yes okay so question one
here is that do does darker swarm
support any kind of customs scheduling
yes you can plug in your own scheduler
okay so how do you do that you right so
so everything so the doctors forum is
written in go so with the general way to
go about it is to you need to tweet in
go so if you want to provide so if you
want to really provide your own
scheduler you need to probably implement
a go interface implemented is that then
for the entire cluster or is it for
individual applications or how does that
work yeah I don't know sorry that's okay
what about auto-scaling we saw that you
could scale manually by typing for
instances but what about based on load
yeah so this is not part of the core
functionality yet of Abdur swarm and the
docker compose those are like so you
might need some monitoring process
yeah would you please on you basically
it's on you to to set up those sort of
you know reacting to monitors reacting
to the environment but there's nothing
stopping you from even running that
inside of doctor school exactly would
then scale exactly is that okay
so what about availability zones is is
that kind of thing built-in or would you
have to do that by label and so yeah so
I think it's not it's not baked in but
what is what is bactine is a you know as
we've seen labeling so late that you can
do that with labeling with clever and a
custom schedule early on exact okay okay
so why would I pick Dockers warm
compared to kubernetes compared to mesos
so my answer to that is an answer of
because it's a it's an answer of you
know fanboy ism and that is so yeah so
the docker project has been expanding
the reach of the tools that they're that
they're building in the open with the
massive community and so if you like to
stay close to that that ecosystem doctor
swarm is is a production ready solution
for it it is true that kubernetes has
been you know in the works and also
mimicking google's and only internal
infrastructure for a long while so that
is a perfectly fine you know production
solution dorker swarm keeps you closer
to the you know docker
so it feels more familiar maybe if
you're already used to work okay is
there a good integration with ec2
container the container so one of the
providers for dr machine is actually
amazon it's a very popular one so i
don't know actually yet if this ECS is
completely integrating Dockers form yet
i have but i might have missed it but i
don't think so but for sure you can
deploy all the stuff I've showed you
automatically to to AWS with docker
machine okay that's all the questions
thank you thank you everyone - bingo
so next up</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>