<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2012 • Making The JVM Fly Experiences With Enterprise JVM PerformanceTuning • John Davies | Coder Coacher - Coaching Coders</title><meta content="GOTO 2012 • Making The JVM Fly Experiences With Enterprise JVM PerformanceTuning • John Davies - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2012 • Making The JVM Fly Experiences With Enterprise JVM PerformanceTuning • John Davies</b></h2><h5 class="post__date">2013-04-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/alk70EMozwU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you I thought if I was clever I
could make this introduction last for
about 50 minutes they wouldn't need to
write my slides I'll keep this to a
minimum yes as was introduced I have a
pilot's license I got it when I was 23
and I still tend to use it as I fly
around the world I go on business and if
I got a weekend I'll pick up a plane and
try to use it this is new zealand's
landing on the beach this is what's
called white island it's a volcano just
off the north coast of the North Island
about 50 miles off the north coast it's
quite spectacular still smoking as you
can see it's flying over Sydney there's
a lot of superb cities i'll show you
another one in a second but it's amazing
to be able to see beautiful cities like
this from the air and be able to sort of
fly around them and see them in any way
that you want to see them for those
familiar with Ayers Rock this is right
next door when I say right next door
it's about 30 40 miles away it's about
600 miles from Alice Springs right in
the middle of the Australian desert it's
called the olgas absolutely stunning one
of my favorite past times when I'm not
flying is at the pub this is combining
both this is a little place called
William Creek which is a population of
two it's about 700 miles from the
nearest town which has a population of
about ten basically land on the road
pull up at the pub and drink and this
was New Year's Eve there was a lot of
other people there that flew in a few
people who drove in for literally a day
plus the nearest farm to this is
one-third the size of Texas so when
Americans say things are big puts it
into perspective anyway sort of land and
take off on the road that was fun if
anybody knows Ross Mason this is me
taking him up in San Francisco Ross
Mason's the founder of mule sauce so
this was last year basically pottering
around in San Francisco and last slide
to say it's you get some pretty
spectacular views I'm always tempted
when I see big bridges like this to be
able to fly under them but it's a very
quick way of
a license but anyway just that was a
quick introduction what I got to go
through today give you a little bit of
backgrounds I set up to when I wrote
these originally sit down to write these
slides I thought we can go into some
really great detail of the of the jvm
and some of the settings and things and
anybody that's tried tuning will know
that every single setting and the JVM
and there are literally dozens and
dozens of them and obviously the
combinations there are thousands tens of
thousands of combinations everyone is
precise for your one application on one
particular architecture running one
particular set of work in one particular
scenario so whatever I tell you is going
to be pretty useless when you go home so
I thought I'd go back to some of the
basics and last week I was I spent as I
usually do every few weeks over in the
u.s. visiting clients and one of those
clients had a performance problem and
you expect to go over and sit there with
your head deep in there and the JVM
debugging etc and there were two parts
that I discovered very very after a day
or so maybe in the second day when we
basically learning the architecture of
what they were doing with our product
that it suddenly dawned on me if I'm
going to go and do a talk on performance
tuning we should really go back to to
some of the basics on this and the
reason being is that we're getting ten
times performance increase just by
looking at some of the architecture and
some of the city things that have been
done and I'm sure a lot of you know
these but it's I hope not everybody
knows all of these things otherwise
you're not going to learn very much but
I hope I'd be able to drill some of
these in I've spent a long time since
the beginning of Java and a good decade
before that in C so there's a lot of
experience in here in terms of things
that are important for tuning and I will
go into the JVM and I will go through
some of the memory allocations and how
those work towards the end but I want to
spend a bit of time on going back to
basics of ochem give you an idea of the
problems my typical client
we're sitting there they're trying to
process typically trade data payment
data for those that know the
technologies fix comes off the exchanges
fpm l iso 20022 sepa which is a single
European payments area Swift is payments
etc and they're getting very large
amounts of messages if you're looking at
ticker data which is price data from
from the exchanges we're looking at
hundreds of thousands per seconds the
CME hit 100 350,000 a second recently
that's not typically lasting very long
but we're looking in the high tens of
thousands into the hundreds of thousands
and if we're looking at trade
confirmations we're down into the sort
of low thousands per seconds etc so give
you an idea of the source of stuff we're
trying to process most low latency
traders etc will do this in C and C++
but of course we're we're here and we're
looking at Java and this is what I'd
like to go through some of the
performance aspects and problems now
before we we touch on performance it's
not just about making things go faster
latency as important as one of the areas
where talk I did a number of years ago
we're just before somebody had quoted on
the new york stock exchange that one
millisecond was worth about 100 million
dollars i'm sure you can do the
calculations but that's roughly what
it's worth in terms of latency this is
why they put the machines actually
physically in the environment that
they're working on because the speed of
light time one millisecond is about 300
kilometers and amazon i found an
interesting section here they reckon
that about 1 or 100 milliseconds of
delay on a an e-commerce site is worth
about one percent of their e-commerce
business so again you know the size of
Amazon that puts it into perspective
just how important this is and then
finally for those of you that don't work
in a large banking environment or large
company it's not the cost of the
software so much it's not the cost of
the machines everybody knows you can go
out and buy
server for a reasonable price and of
course if you're in a company they'll
charge you more it's the cost of running
these in production if you look at the
average life cycle of an application you
design it you develop it and then it
stays in production one would hope for
three four five six years and many
businesses will charge and I'll i use
dollars because it's the number that i
was quoted just about twenty thousand
dollars per year per machine to host
these that's the cost of of the
environment the air conditioning the
people to run these things so that's the
cost of one physical machine so if you
can reduce that this is sort of thing
that we're going to get were will aiming
for this so i'm not going to give you
any silver bullets there is no java
machine parameter that i can basically
quote you that will make all of your
applications run twice as fast I'm sorry
about that but I will hopefully give you
enough information that you can start
tweaking some of this for those that
haven't played with the JVMs or for
those even that have but hopefully give
you some ideas to to go back in and look
at what you've done so what I'm going to
try and give you out of this is some
ideas and enough information to go back
and do a little bit of tweaking I want
to go back about 20 years I used to
teach well not quite 20 years 15 years
ago is to teach for Learning Tree Java
and we used to have this section as
anybody recognize this very pretty
fractal was called a Mandelbrot fractal
and a few of you do back in about
nineteen was it 80 early 80s everyone
had t-shirts it was the the big thing
that came out so it's very colorful we
used to demonstrate as part of the Java
course basically if you wanted to make
Java run faster you had to use J&amp;amp;I the
Java native interface and there you had
to call see because see basically ran
stuff faster and you come back into Java
afterwards so this is one of the
exercises we did effectively what
happens for every single pixel on the
screen in that particular one there
which is probably about a 600 x 400
resolution each one of those represents
a real and imaginary number IE a complex
number and basically to get the color
you do a number of iterations and the
amount of iterations that that go before
you reach a certain point dictates the
color that you're going to get the
formula is beautifully simple as a
little bit of Java code they're
effectively you just pick a point the
point is determined by the the pixel
effectively imaginary on the vertical
axis and real on the horizontal axis and
you iterate a number of times iterate
typically a thousand times it's black
etc etc a few years later at about 2,000
it became apparent that this wasn't
running much faster and it became a good
demonstration of why not to use J&amp;amp;I why
you would avoid J&amp;amp;I because by this time
java had started to catch up and i think
this was the turning point where java
became a novelty language to animate
your gifts which was about remember the
internet was just coming out so the late
90s we hads gif images you were starting
to get images inside your internet
because previously it was email before
that's and the user net and porn
obviously and you could start to animate
things and this suddenly started to
become useful in the server side today
we can probably render the same thing
I've seen some pretty impressive bits
you can put this even on our iPads or
iPhones render it in sub-second on far
superior resolutions a sort of thing now
that you can render in 3d on a 1080p
screen it's still however requires a lot
of calculations the number doesn't come
down but as people have got to
understand this fractal they've got to
optimize it and what's most important is
that the optimizations on this have
almost exceeded the actual performance
enhancements of some of the machines so
the combination of the two have resulted
in a lot of performance on a day to day
work however we're doing a lot of data
processing and it's the data processing
that I want to cook into today so again
just as a reminder I want to go back to
some of the sort of earlier forms of
coding I'm sure a few of you remember
Pascal anybody learned Pascal when there
were kids as most of it or even recently
actually as you probably know
pascal string has the length of the
string right at the beginning it's a
little bit of a restriction it means
that you can't have strings particularly
long but you know hey Twitter managed to
make a business out of it and fairly
simple it worked and concatenation etc
was relatively easy if you wanted to get
the string length of this you simply
just look at the first byte really
really quick looking at see we have the
same memory but effectively we have a
null at the end so a 0 character at the
end now if you want to get the string
laying of this obviously you've got to
now iterate through the entire string
until you find the zero at the end so
it's indeterminate until you've reached
the end lots of different advantages and
things and both of these Pascal and C
are very very simple when you're
processing them there are a few
restrictions remembering these were
bytes not characters or char's as you
get in Java as Java what is it seven or
eight have now changed it's not even two
bytes per hr though they've gone into
three or four but effectively this meant
that we couldn't actually use the a with
the little i'm sure you have a name for
it in denmark the beginning of ours got
a name oh thank you one of those we
couldn't use it in the earlier days
because they simply didn't exist in
those in those character sets you
actually had to predetermine the
character set before you went in so when
we working with see it made it
relatively easy but also because we were
working at a very low level we're just
off machine code here so we're just off
the assembler level what we wanted to
actually pass do something very fast or
do something that we were doing a lot of
or iterating we could manipulate the
memory and exactly the way we wanted to
do it so if we wanted to call into a
function and the function and I use the
word function as opposed to method
because methods come off classes so if
we call it into a function we can
actually modify the string in the
function without having to return it
afterwards and therefore copy at each
time and create new versions so if we
wanted to manipulate the message we
could pass it into a function the
function could manipulate it
it was relatively simple and also it
meant that when we passed the the string
we just needed to pass a pointer to it
and then of course you could put a Const
which meant that you weren't allowed to
actually change the content of it and
that was a bit like what we have today
and so as we move forward into the
object-oriented languages we start to
effectively put more functionality into
these strings we came away from the the
byte array or the char array as we know
it and we started to create an object
around these and we started to abstract
ourselves because we're in an
environment where we want to abstract
things and we abstract ourselves away
from the underlying machine which in
some ways is good but in other ways it's
not quite so good when it comes to
performance if for example we wanted to
to pass a very large string or a large
chunk of memory we didn't need to do it
we just needed to effectively pass a
pointer to the same place and that was
it we didn't we didn't need to copy it
if we wanted to copy it because we knew
it was memory and we knew it was
contiguous we could use a mem copy or
something we could actually copy that in
a much more efficient way and then some
interesting things happened as we moved
into C++ and objective-c before the
standard libraries came around we had
collection classes we had sets maps
lists linked lists etc and different
derivations of those things it was quite
interesting because there were lots of
different versions around and they
weren't standardized and one of the
interesting problems was if you created
a string and you put it into a
collection who owns the memory of that
string so if the string goes into the
collection and then you delete the
string or you you basically allow they
you didn't have a garbage collector but
you freed it to allow the memory to be
used elsewhere it was good programming
practice the problem was that the
collection had a copy of the same bit of
memory so if you came to use that she'd
get lots of corruption so we have these
what windows used to have the general
protection faults etc so this pick
an issue and you could imagine putting
something into a collection into a set
and then something would delete it out
of that so whether it was the the putter
or the getter that deleted it or even
the list itself that managed it in a
different way took a copy and deleted it
we had some rather strange things
happening so we started to create these
objects which became immutable to make
life easier and then of course Along
Came memory management so when the
memory management came along generally
it did a better job than the near
average programmer fortunately this was
the era when visual basic and things
came along and people thought they were
programmers and would effectively go out
get jobs and somebody say okay the
visual basics really good now want to
put you on see and we get an awful lot
of problems so memory management is good
for the lower end of the programming
hierarchy should we say but for those
that were used to be able to manage the
memory it created a few issues if we go
to strings in Java today and I'll get to
the point in a second if we go to
strings message comes off your JMS so
you read a file and you read these into
strings and you need to now process this
so very simple one here I've got the
alphabet and we need to pick little bits
out of this alphabet now if we pass the
string around that's fine but if we want
to take little bits out of this string
for example we do alphabet substring or
even if we pass the alphabet in and then
we do a substring afterwards don't
forget we're getting tens of thousands
of messages a second and we might be
running multi-threaded and all of these
start to create Java objects and it's
these temporary java objects with the
strings that start to cause the problems
in the JVM now you could get to this
attitude where you could say oh the JVM
is going to take care of it all that's
fine you know I'm used to this you can
basically write your code the JVM comes
along collect does all the garbage
collection and it's pretty good at that
and I think what's happened is people
have got lazy people who have not used
or had the experience of how just how
fast the machines are that we have to
a getting back to that Mandelbrot set we
were processing what do they say in a in
a VGA screen 768 was seven hundred
thousands floating-point operations a
second now in those days your machines
would run at about five megahertz 10
megahertz for a faster one and then you
had a floating-point unit behind that
now that meant that you were getting
maybe 10 million floating point of 10
million instructions per second with
floating point instructions you were
looking at about a million per second so
if you wanted to do a 1080p screen and
run it a thousand times you were looking
at sort of 20 minutes to process this
obviously 1080 wasn't around them people
have forgotten how fast these machines
are that we have today your average
laptop is to point something gigahertz
sometimes three gigahertz you've got a
floating-point unit built into the
processor co-hosted processor which
isn't typically checking out over a
billion floating-point operations per
second so when I go to these clients
sometimes they're sitting there saying
it's really cool we're getting 200
transactions a second out of it my brain
thinks hang on 1 billion floating-point
operations a second you're getting 200
out of it what earth is it doing for the
rest of the time it's it's it is just
not possible to go that slow who here
can remember oh let's say early 80s not
a test of how old you are but I mean we
had we had machines maximum speed for
six megahertz or something we used to
get really pretty cool games out of
those things you had to sit and type for
days and days out of a magazine to type
in all of the stuff you used to get
amazing stuff out of that and it got
faster and faster and faster people have
forgotten that so let me give you an
example if I have a one gigabyte file
it's pretty big it's it'll fit almost
USB drives these days if I'd asked the
same question five years ago you'd have
thought wow take a part of my disk drive
now you want to it's got a
million rows in there each row is
roughly 1k in size 1k is about four
tweets okay put it into perspective just
so you understand what it is so you've
got a million of these things now inside
that so we've got four million tweets if
you like we need to find one particular
piece of information and we check this
in two and two a jvm if we like or we
can use any other language how long do
you think it will take to find that
piece of information out of four million
tweets less than a minute on show of
hands please more than a minute Oh
someone's scratching that that's right
it's not less than 10 seconds less than
a second it's it should be less than a
second to go through how many sort of i
gave you the performance of it the funny
thing is if you actually run it in java
it typically on an average machine it
takes quite a bit more than one second
even if you're running j ni o but if you
run this as a standard UNIX command as a
wrap or something you can typically get
less than a second and performance out
of this and people are engineering these
incredibly large complex systems that
are taking literally 30 seconds to do
this sort of computational search people
are forgetting the sort of performance
that we've got so this is when I turn up
at a client I look at these things and
think no no no that's your an order of
magnitude maybe two orders of magnitude
out of how fast this should be going so
this is why I often sit down and look at
the architecture now this isn't
necessarily the solution I had a chat
with my colleague outside and we could
take something relatively simple like
this and I'm sure between the you know
everyone here we could come up with
probably two dozen different solutions
about how to optimize this it's it's
meant to be an example so if we take the
one here where we're trying to take some
information out of it now what what I'm
trying to do is basically take a large
complex message and extract all of the
information out of that message and put
it into a Java object
which has a whole bunch of private
fields where I've got getters and
setters what I'm trying to do is
populate that as fast as possible and
make it available for somebody who now
wants to sort or put these objects into
collections and basically treat them as
Java so effectively I'm pausing the
string putting it into Java now if i
call the alphabet substring i create a
new string will be at a very small
string it's a string with one bite in it
and then I pass it to the function of
the problem is it's a string the
overhead of a string is far in excess of
the one bite that I'm creating now I
could take I could pass the string
itself if I pass the string itself it's
passed by reference if I modify the
string it's immutable so it creates yet
another string if I just want to take
the information out of it the very
quickest way to do it on this
incidentally is to effectively pass the
string and inside my method is to use a
string dot chart at get the index of the
char and then effectively if I can cast
it to a bite if I want to store a bite
or a char out of interest how long do
you think it would take to run a billion
of these sitting in this little loop
here a billion that's a thousand million
for those that are out of touch with
billions Americans used to have
different billions from the English so
will qualify this a thousand million
times just on this one one thing greater
than 10 seconds they're all sitting
there with calculators now more than a
second as she takes on my laptop point
zero six seconds it's quite impressive 1
billion times to run on this now if I'm
extracting all this information out of
here I want to get this far more
performance so that's the sort of thing
that I'm going into the reason I wanted
to bring this up is because this was a
typical problem we had we were passing
fixed messages and the original pazza
was in fact other the the code was
generated and the parser was relatively
naive and it used to basically say what
am I looking for here using reflection
that will go across and it would look up
the
motion that has got and then effectively
do a set and basically it would run
through and positive strings we never
really realized that it was an issue
because we were quite happily doing a
few thousand a second it became apparent
when a client needed more than a few
thousand a second and all of a sudden we
started to look at the parser we got
that parser from a few thousand a second
up to 138,000 a second just by up to
optimizing out these sorts of things now
this is not the sort of thing that you
can get out of JVM tuning so it's
something that I want to sort of put
forward when you're looking at the
architecture of your system to
effectively try and look at some of
these smaller things it's very easy to
take a very small part out if you can
create some j unit tests or whatever
test framework you like take out some of
the areas that you're looking at profile
what you've got and i'll go through some
tools at the end that we can look at and
then start to optimize how you can sort
of you may find that this is sort of
inherent right across your architecture
and the usage of this so it may take
quite a bit of extra work so a question
it wouldn't work uh sorry wouldn't work
with the Danish letters yes and bites
your right if you were doing char's it
would you be fine I think I did point
that out but it's yeah if you're doing
charge you if you if you're doing bites
obviously you're going to be chopping
off anything that's not asking but
unfortunately the Americans got there
before we did or before you guys did if
the Danish had invented the alphabet for
computers would have been different but
we wouldn't have eight bits in a byte
we'd have ten bits in a byte or
something other binary bites and be
interesting here's another interesting
one at a client that's another thing
that sort of got me thinking about this
so sitting down at a client site this is
this is one of the this is one of the
things that got me thinking why should
we go directly into the JVM so looking
at the client system it's it's got
somewhere to go yet it's got another
another few weeks they're not really
into the tuning
or such yet they're basically just
finishing it off it's some way short
quite a tenth of the speed that it needs
to run out but it's some way short and
they're scaling this up and they're
basically it's a distributed
architecture and this thing's running
and I went quite any numbers because if
these guys watch this video afters
they'll realize I'm talking about them
but let's say it's running a certain
throughput per second so we look at it
and just having a quick look you know
how much memory as it gots you know
what's was it working on so it's got a
four gig of ram thinking map pretty good
does not much doesn't run in four gig of
ram that's a lot the j x MX was four gig
JX ms will go through these in a second
was two gig fine no problems at all no
other parameters running minus server
look fine so I did a little PS minus EF
which basically gives me all the
parameters for everything running on the
machine just to see what sort of user
and system throughput it's picking up on
the cpu it's got two cpus in there
they're both running relatively fast
it's running on linux and i find another
java virtual machine running in there
and interestingly it's running tomcat
and that's running two gig so we've got
four gig or 12 gig on the other plus of
course the operating system in all the
bits that's machine was actually only
had four gig of ram in it it was a
virtual machine so combined the two
virtual machines to jvms plus the
operating system we had six gig of ram
trying to run inside a four gig machine
now linux allows you to do that and it
simply just swaps it out problem is when
it swaps it goes to disk so all of a
sudden we end up with these what's
normally fairly quick running in in
memory now running on disk and of course
this has a very major impact on the
performance something incredibly simple
but because the programmers had written
their application to run an environment
which they were very sure about and they
said it's very easy you just give it
this much memory and they pass it on to
operations and course operations say
what the programmer told me it needs
this and that's etc but they hadn't
actually thought about how everything
combines together easy mistake and quite
silly when you see it but it certainly
made a huge difference to the tuning so
effectively with if you're hitting the
high memory barriers we were getting or
looking at about two orders of magnitude
out of that one and you can sit and
debug that forever and it's you're not
going to find anything it's effectively
the the overall system that dictates how
this runs another example of over
engineering I've thought this was quite
amusing and had quite a long chat with
the guys on this one now they're trying
to save let's say twenty thousand
messages a second now the architecture
is you read the messages off a queue you
safe store them you pass them on to
another queue so it's nicely stepped out
architecture it's distributed put things
into cues so you can distribute them
nicely and they've got a safe store so
twenty thousand messages of seconds over
eight hours of trading i'm reading the
numbers of the screen here we're looking
at roughly 20 meg per second or seventy
two gigabytes so they decided to use an
in-memory database there's lots of them
i won't name the one in this particular
case but unfortunately as they got
towards the sort of pre-production
trials there was no problem with their
architecture there was no problem with
the tools that were using apart from the
fact that they didn't have enough
knowledge of how to run them but they
then had to get lots of people in to try
and tune this to get it working and what
they were trying to do is to get this
in-memory database working across and
sharding and and doing everything it
should do to be able to to run this sort
of performance and it's not particularly
fast performance but it wasn't working
and it was creating lots of issues and
also when they ran things through
several times they retried them they had
to then
back to the to the database they had to
clear it out if they stopped everything
they lost the rest of the days working
cetera so it got more and more
complicated my question was why didn't
you use disk twenty thousand messages a
second you can write out to him the hard
disk what are the olds you know those
spinny round things with go rusty when
you leave them too long we're an SSD a
lot of people are on SSD these days from
SSD you can write 2 gigabytes per hour
or so a gigabyte every two seconds so
there is absolutely no problem of
writing all this stuff to disk so for a
safe store we've got clients that are
sitting taking these messages off an
average of a hundred thousand a second
and they're writing these two discs so
my point is here simplicity if you want
to get people to manage disk if you want
to replicate the disk it's much much
easier than trying to get people that
are qualified in this in-memory database
that was really a sort of a sideline but
it was another thing that sort of got me
thinking about why are people trying to
over engineer these solutions so I want
to look at the the JVM what I want to
try and get out of this is just give you
I can imagine there's quite a few people
in here that know quite a bit about the
the JVM but hopefully there's quite a
lot of you that just treated as a fairly
black box and this should hopefully give
you a little bit of information about
how you can there's a few parameters
that you can tinker with and play with
that will make quite a difference in the
performance of your machines so first of
all it's divided into two main sections
we've got what's called the perm gen
permanent generation this is where the
classes are loaded up so if you're doing
object relational mapping you're messing
around with XML you're doing Jack's be
or something like that that's generating
huge amounts of classes sometimes an IDE
that's loading up all of your code
you'll very quickly run out of permgen
space and you'll get an out of memory
permgen and the very simple parameter
for this one is just to basically set
the poems in size 250 Meg a
is should see you through most usages
it's not something that's going to
change the speed of your virtual machine
it is garbage collected but it's not
going to make a massive amount of
difference as things are loading up
there fairly slow because they loaded up
from disk anyway typically even if it's
flash drive or something faster SSD so
it's not going to make a massive
difference but this is one of those
things that either goes or it doesn't go
now that the more interesting part is
the heap now there's two parameters on
the heap and does I notice there's quite
a lot of arguments or differing in sort
of how to set these these would be the
ones that you're probably most used to
and interestingly it's not necessary to
the higher you set it to the faster it
goes it doesn't always work like that
there are some things you can do so let
me just explain them there's the x ms
which is the initial size of the heap
that you get and i'll go into the the
different types of heap in a second and
there's the x MX parameter which is the
maximum size now let's assume they're
both the same for the moment now if it's
very small the JVM behaves differently
because it's garbage collecting
obviously more frequently because you
get close to the the watermark on it
garbage place it doesn't necessarily
mean that your stuff runs any slower at
all it just runs in a different way so
one of the things you can try with this
is to reduce your heap until you start
to see a fairly notable difference you
can also monitor this on some of the
tools the J visual vm j stat things like
that that you can monitor it with but
these are things to try and this is the
thing that's going to probably make a
reasonable amount of difference to the
way your code runs don't just give it
four gig or eight gig or 16 gig if
you're running in a 64-bit vm it doesn't
necessarily make it go faster and the
big difference is that you really will
notice if you've got a lot of ram in
there and you've set up your your memory
in the wrong way between your old memory
and new memory which i'll go into in a
second you end up with these complete
garbage collections now if you're
garbage collecting
16 gigabytes of ram and something
running fast it's gonna your machine is
going to halt sometimes for several
seconds if you're running your machine
across running TCP IP connections or
you're expecting users to click on
things it will stop nothing will happen
at all I'm sure a few of you have seen
this so that's one of the problems with
making it too big now if you make ms and
MX difference you'll see this graph on
the top right the orangey pink bit is
the MX so Oh it'sit's what's been
actually used and effectively it's going
up to the top to the peak now if you set
them both the same what happens is that
the memory is allocated immediately now
you might not need it but if you're
going to probably use it anyway you
might as well just give it to your Java
VM anyway and let it run the advantage
of setting them both the same as you get
much more consistent results because you
don't know when this step is going to
occur as it allocates more memory from
the operating system as you can see
those steps on the left hand side of the
pink bit as it goes up that's the
operating system handing more memory to
it so if you wanted to run consistently
my personal preference is to set both of
these the same and if you're trying to
do performance tuning you get a
consistent result each time if you're
running on a random machine and a user
mode obviously you don't want to grab
all the memory all the time very quickly
so you tend to set ms lower than MX but
if you're running in a server my
preference would be to set them the same
out of the heap we divide this into two
more sections so we have the new
generation and old generation so what
happens in this and the new generation
is then subdivided into three more
sections what's called Eden and then the
survivable so effectively what happens
we have these mini garbage collectors if
you like so as your temporary that say
strings are allocated what's happened is
that they will be generated inside the
eden space you'll get a garbage mini
garbage collection will come along
and it will move those into the
survivable space you've got two of those
and effectively eventually once it does
a garbage collection of those any
objects that survived it will eventually
put those into the old area now if you
run out of that altogether because
you've got lots of garbage collections
going eventually what happens is you get
an out of memory and I'm sure every one
of his as if you're working in Java have
seen that interesting thing is that you
can actually set the difference between
the old and the new and this is probably
the only other JVM parameter that unless
you really know what you're doing
tinkering around with the JVM this is
the only other parameter that you should
probably experiment with there is no
there is a default value per machine /
JVM depending whether you're running
client or server depending on the
architecture depending on the 32 or 64
bit they tend to be somewhere around 4 6
8 12 something like that so depending on
what you're running on this new ratio
will be set accordingly but if you you
know you're running on a particular
server you're running our 64-bit
architecture you know the way your
program is behaving and assuming you've
optimized out all of the strings as I
pointed out earlier you can start to
experiment with this and it will make
quite a significant difference to the
performance I'm not talking a few
percentage points this could go up 50
possibly even more in terms of
percentage of performance because of the
way that your allocations if you're
creating huge numbers of objects you
probably want to set new ratio down to
something like one or two if it's any
larger than you effectively get a lot
more large garbage collections coming
now just give you an idea here the x MX
effectively gives you the new and the
old the slightly grade bits are the bits
of memory which are not yet allocated so
effectively it's there it's allowed to
use it but it doesn't so we've got the
Eden the survivable space two of those
number one and two or two and from is
that sometimes called you've got the old
which is also called tenured
and then the perm gen permgen tends to
say fix as i said before either works or
it doesn't work or there is a small bit
of garbage collection and effectively
it's the new ratio that you can change
on these so this is probably the those
two parameters the XM x x ms and new
ratio probably the three parameters are
going to make the biggest difference to
your machine finally if you get into if
you really want to go into a little bit
more fine tuning you can actually also
set the ratio between the new or the
eden and the survivable space and again
this is assuming that you've really
analyzed your application most of the
applications I've come across are way
too complex and have too many different
things going on to actually work out to
this level whether we get to get into
this sort of level of tuning and I found
far better results from looking at the
architecture looking at the code then
getting into this level so my warning
here would be if you're getting into
this sort of level you really need to
know what you're doing you need the sort
of pepper dines of the world to be able
to reach this sort of level of tuning
and actually get something useful out of
it I've got a couple more slides here
now it's a couple of tools now this is
again before you get into tuning your vm
you there are some things you need to do
look at the architecture some of the
points that I made before about the
silly mistakes about putting too much
memory into a machine or not having
enough memory in the machine but to
putting too much on the vm not over
complex overly complex solutions writing
stuff to too complex expensive solutions
databases people go over the top to use
databases just because you have an
official databases everything's got to
go under Oracle everything must go on to
sybase or whatever it may be quite often
disk it's perfectly useful Oracle stores
it in a disk anyway and all the DS is
mechanism it's a big complicated and
unbelievably expensive gadget that gives
you an interface between your
application
and the disk a lot of the stuff that you
store can be written straight to disk
you can grep it you can index it you can
create your own indexes it works just as
well so assuming that you've been
through your architecture assuming that
you've been through your code finally
you can start to get down to looking at
the Java Virtual Machine and looking at
the sort of performance you can get out
of it the tools you're going to be using
and I would hope there's a lot of people
use here jconsole J visualvm that was a
call for hands few of you yeah these are
tools that will really give you the
ability to understand how your machines
being used that graph that I put up
earlier was just a cut and paste in fact
someone else's cut and paste but I've
got some others that I was going to put
in there that one just look nicer than
mine but it'll give you an idea as to
how the memory has been used you can
look at how the threads have been used
all of these parameters again don't
forget if you're running multi-threaded
you need more memory the memory is
divided up her threads so if your system
runs in one thread and it needs minimum
60 for Meg of RAM let's say we need 128
then if you've got four threads and
multiply that up you're going to need
512 at least to run in four threads if
you're running a tet cetera you're you
know how they the math works so these
are the sorts of parameters at the
bottom we've got a large list no I don't
suggest you put all of these in one go
but these obviously you'll get these
slides afterwards so you don't need to
chop these things down but these are
things which give you quite an
impressive list of information about how
the garbage collector is working and and
how that's working again in combination
with something like j stat will show you
how the Java Virtual Machine is being
used how the space has been allocated
how they the eden space the new the old
etc have been used within your machine
will give you a lot of information as to
how to tune your application one thing
I've done typically as well get someone
to look at the the code and you think
wow we're generating that many objects
why is this thing running so slow
don't try and tune it at that point to
suddenly say oh okay we'll just change
the new gen parameter and go back to
your application and see why you're
using some of the objects see why you're
getting so many objects in a perfect
world you should be really you should be
looking at object Ryu subject pools also
so things like this to try and bring
these down it's going to really make a
huge difference to your application so
in closing up if you really want more
oomph as a wonderful English word out of
your application which imply it just
implies everything just more go my
recommendation and again this is over
years and years but it was really bought
through to me in the last couple of
weeks look at your architecture first
you're going to get a lot more out of
your performance tuning from your
architecture particularly if you're
working in a distributed architecture if
you've got transactions seriously think
about taking them out people over use
transactions you're looking 10 to 100
times worse performance people get
obsessed with transactions use
compensation all transactions for
example ORM object relational mapping it
just kills machines it's you're going
from an object-oriented world into a
relational mapping world the two of them
just don't go together so think about
how you can change the architecture of
that so once you've once you've been
through this once you've gone through
these optimizations look at the code
look at the Java Virtual Machine the
Java Virtual Machine will probably tell
you more about how badly your code is
written then in fact how badly the JVM
is running so take the messages from
that go back to your code modify your
code and then come back to the JVM when
you're absolutely sure it's perfect then
start applying some of these JVM tips I
think that's pretty much it thank you
very much any questions at all
nothing at all oh yes we have one over
here I'm not an expert to be honest on
on the the changes i still have two very
large clients who I think they'll
embarrass our name people like the
federal reserve bank and these sort of
places which which are still running on
Java 1.4 when I was at jpmorgan chase we
managed to justify using Java 1.5 or
five as it's called now purely only
twenty one percent performance gain the
saving was in the well over 10 million
dollars in terms of saving so the
clients that we have typically that we
for the code that we generate we had to
be very careful not to go much past five
I have Java 1.7 i'm using java 1.7 but
unfortunately for my usage it tends to
be a sort of a pipe dream to be able to
put it into to something else so i'm
afraid i'm not an expert on the on the
changes other than the sort of nice new
features sorry I can't give you a huge
amount of information on that but I know
some colleagues you can if you're
interested I can put you in touch
another question here so a question was
looking at some looking at the sort of
optimizations which I had their on on
bytes and strings they were meant to be
sort of an example that the examples
were sort of typical code that I found
what are the recommendations for XML
parsing I must admit up slightly bias on
this one because one of my companies is
c24 which is outside and effectively the
way it's it's one of the solutions
effectively it's like Java binding so
Jack's BG Beck's these typical products
that's take a Java sorry an XML schema
they create an exact Java mapping to
that and effectively posit there's a lot
of things when you get involved in an
XML obviously that you want to be
careful of one is performance I'm sure
you well well
we're familiar with differences between
DOM Java binding and sex pauses for
example if you're just taking
information out of it sex pauses far
quicker if you're taking lots of
information out you end up pausing it
multiple times then you've got
validation to worry about and things
like that so if i had a sales hat on
which i don't because i'm a CTO rather
than the sales person i would say go
over to the c24 counter and have a look
on there it's it's our clients and the
ones that that I'm representing here use
that product to do the complex XML
parsing so that includes the sort of iso
20022 FP ml those sorts of things there
are things that will pass it quicker
there is nothing I know of that will
validate it quicker when I talk about
validation I mean beyond schema
validation we still use something like
sir C's for the schema validation so
it's not a one-off simple answer but
hopefully give you some idea any more
questions yeah over here closures and
what have you yeah did everyone hear
that I heard it perfectly what's wrong
with your ears somebody with a foreign
accent similar to mine but much further
south by the sounds of it who obviously
there's an awful lot more about java 7
than i do talking about the advice in a
concurrence architecture in concurrency
is actually if i understood you right is
actually more towards or the
performances more towards generating
lots of small objects when you got
things like closures where the functions
are effectively generating classes as
well and then you've got things like the
concurrent garbage collector which comes
along as well so again this isn't this
isn't a one off piece of advice don't
use lots of objects this was a piece of
advice for the situation that we had in
particular on this particular one
obviously we do run multi-threaded and
this particular problem that we had was
was in the object creation so sorry
what's your name josh is joshua's i saw
you outside so josh if you want to ask
questions he's sitting over there
anymore all questions you had a question
I was that visual DC plug in okay so
visual GC plugin for the J visualvm I
did notice a lot of plugins so it's
obviously one of the ones to use gives
you a lot of good so the threads stack
size how do we optimize that it's
difficult when I think anybody working
in multi-threaded environment will tell
you is it's one of those hit and miss
things as soon as you start putting
start looking into the threads it
becomes a bit like sort of Heisenberg's
uncertainty principle as soon as you
start looking at it everything changes
and it you try and hit something my
experience is purely hit and miss on on
that side again this is a sort of thing
that I would we engage people like
Martin and and Kurt pepperdine to to
basically look into these sort of things
for a literally a month to to work on
this and those those guys run quite a
lot of courses on the really deep level
performance tuning any more questions at
all one over here that's impressive so a
he has a stopped the world garbage
collection for 30 seconds actually I'd
like to take that and use it as an
example let's that's an impressive one
thirty-second garbage collection and how
would I go about stopping you can take
snapshots so you can use a lot of these
tools effectively to take snapshots and
my advice on this would be effect I mean
you're your old memories is obviously
getting used far too quickly so you may
something as simple as looking at the
new ratio might start helping you with
this but effectively the the tools will
give you a much better view of what's
going on inside them some of the
parameters that you had up there
just before embarrassing screensavers
come up but this back on you get lots of
pictures of my kids other ways that the
tools will give you a lot of information
you can you can do complete memory dumps
heap heap dumps etc that would I mean
that would give you some sort of
visualization as to what's going on
inside and those are those are things
which you can run on a you can if you
run the j stat for example you can run
that every every second or more you can
effectively see how how your memory
usage is being used up I mean that would
imply effectively depending whether
you're running server or client mode on
the JVM depending on the the ratio
effectively what's happening is you're
probably filling up your old generation
which is I would imagine fairly large if
you're getting 30 seconds where you got
16 gig or more one gig you've got a very
slow machine then or or it's busy is it
multi-threaded multi the problem with a
lot of these things is when you start to
really get close to the limits you've
got the virtual machine sort of
competing with the with the garbage
collectors sorry you got the garbage
collector competing with your
application as well and these you'll get
lots of many garbage collections as well
I mean there's no one answer for that
you maybe you'll find the concurrent
garbage collector will pick up stuff
quicker I would suggest you probably the
initial things to look at would be
trying to get an idea of your heap usage
and looking at the different ratios of
the new generation to the old generation
but you should be able to knock that
down quite considerably I would hope to
under a second any more questions are we
doing for time we're good for time so
thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>