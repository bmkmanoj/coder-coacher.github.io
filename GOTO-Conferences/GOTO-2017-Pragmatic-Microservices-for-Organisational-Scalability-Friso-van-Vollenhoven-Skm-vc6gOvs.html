<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • Pragmatic Microservices for Organisational Scalability • Friso van Vollenhoven | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • Pragmatic Microservices for Organisational Scalability • Friso van Vollenhoven - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • Pragmatic Microservices for Organisational Scalability • Friso van Vollenhoven</b></h2><h5 class="post__date">2017-11-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Skm-vc6gOvs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">morning that's interesting this is a
really big room so what happens normally
when you we have a room that that out
sizes the crowd then you get a uniform
distribution of the people over the
seats right this happens naturally and
that's fine but this room is too big so
now you all got me wondering what are
the distributional properties of the
crowd are different if the room like
vastly out sizes the crowd maybe that
should be the topic of the next talk
sometime so in any case welcome i'm
Freeza and i'm here to talk about well
pragmatic micro services for
organizational scalability say my hat
that sounded really nice when he asked
me for the title in the abstract which
as you know for conferences like these
is months ago and then when you start to
actually prepare to talk which is
obviously hours ago and you look at that
again okay that's interesting because
this is this is a fun thing about the go
to conferences that you know as a
careful observer you may have noticed
and maybe even as a not so careful
observer that basically they go to
conferences like a traveling circus of a
core team of speakers who are always
there and and then when they do a
conference they amend that with a couple
of local people so the nice property
about that is that if you go to the
talks by the local people you get really
fresh material so I hope you enjoy and
the city of fashion trade fashion trade
I'll talk a little bit about that later
CTO as you all know in in startups means
that you know if you think it's
interesting and and you want to be
perhaps joining that company then that's
the person to talk to that's what it
stands for it's not an acronym for
anything I'm also the proud owner of my
my three character Twitter and
it was at the time when I got that the
last remaining three character one and
yes I wrote a script to figure that out
and the fact that it starts with an F
like my first name is pure coincidence
also on LinkedIn I have 22 endorsements
for Awesomeness
this is a challenge to you fashion trade
is a start-up here in Amsterdam we are
working on business-to-business fashion
wholesale platform in essence that means
that if you have a clothing store you
need to buy clothing from brands like
Levi's or something like that you can do
that through fashion trade and then our
marketing department calls that
simplifying wholesale so you can connect
trade and grow this talk is not a lot
about what fashion trade does as a
business just to give you an impression
on the less it looks a lot like
e-commerce because obviously it is
ecommerce so then because we're a
fashion company we have a couple of
attributes that that perhaps requires
some explanation first of all this is
the fridge that we have in the office
and this is the first company that I've
ever joined that has a fridge that dress
is better than me in spite of the fact
that I'm even wearing my cloud shirt
today also because of our esteemed
marketing department I have a slight
template for all of the decks that I'm
supposed to use that as you noticed on
the title slide brings more emphasis to
the company logo than to the title of
the presentation so to fix that I'll put
it there again pragmatic micro services
for organizational scalability so
pragmatism whether or not strictly
defined something that we can probably
all wrap our heads around and it has a
lot to do with getting things done and
then you can get more formal about it
but I don't think for the purpose of
either wasto Kivar
Our Lives it's really important to get
to the bottom of what pragmatism is
organizational scalability however is
trickier so what does that mean mostly
when you look at startup saying you're
going through a particular growth then
especially from the outside you know it
usually looks a lot like this right all
of a sudden the company you know
attracts a certain amount of funding and
and then usually on the order of two to
six weeks later the the recruiters are
all over the place you know and all the
compensation goes up and and and the
perks become more interesting and the
lunches get better and and the foosball
tables get bigger and and all of these
things so then you hire more people
because who doesn't want better lunches
and you provide the people with a
brand-new MacBook Pro which gives them
all kinds of complicated issues when
they do a conference talk because nobody
has a USBC connector anywhere and then
something happens in all of a sudden you
have this organization that's able to
churn out more features right because
that was the point of scaling the
organization so that it looks good right
we can do this because we're we're all
software developers or engineers or
whichever parlance attracts you so we're
clever people and we'll figure out the
thing in the middle all right so that's
what you do so this is the actual growth
of the development team a fashion trade
over the past year know if you can read
the skill it's actually pretty big if I
look at that screen but it's this is
roughly a year and the the title of the
charts is active team members per week
so that means that in any given week
this is the number of people that
contributed code based on our get
commits
so you see it also goes down sometimes
because first of all people leave not
people that we've hired but we've worked
with quite a bunch of contractors to
bootstrap the company so it's natural
that they they leave in favour of our
own hires and and then also there's this
dip for some long period of time
somewhere at the end of BK and the last
year beginning of this year and that's
probably right about the time when the
team reached the threshold in size where
the CTO doesn't commit code anymore
afterwards sorry for that so so it goes
up and down a bit over time but in the
end yet the team grows so in order to
reach our our organizational scalability
targets i've personally said well
there's two things that are really
important to me first of all if you're
hiring and and you intend on keeping on
doing that for quite a while and then
there's a huge benefit in getting new
people on the team productively very
fast that makes sense right
because as soon as somebody becomes
productive on on the codebase it means
that also at that point there there's
less interference with the rest of the
team in terms of figuring out how things
work and getting up and running and then
secondly I said well is dingus bigger
then we need to you know collectively be
more productive we need to be able to
produce more yeah so the sign that's the
proportionality it's a bit weird here
because we're using the PDF version of
the slides instead of the ones in Google
slides that look really slick and just
well done so I didn't really want to put
emphasis on the proportionality sign
it's just supposed to be
so development productivity should be
proportional to the team size and and
that's good right because because it's
simple we can keep simple metrics
because if you think about
organizational scalability and and you
look at perhaps guidelines that are out
there about about achieving that and
what you need to do to achieve that it
will usually common along the lines of
200 pages with at least you know two or
three dozen things that you need to get
right in order to make everything work
and then as a result is very easy to go
into the trap of you know keeping track
on all of those individual things that
you should make work according to the
book without ever looking at whether
your organization as a result is
actually scalable so so simple metrics
are good fast onboarding of a new
developer what does that mean well for
us it's simple we want to get somebody
productive in one to two days so on your
second day at fashion trade is the
latest that you should have made a
useful production commit so something
that was actually deployed so we said
about how do we go out and do this and
obviously we said well we'll use micro
services because that's supposed to work
for organizational scalability and then
when you look at micro services and
micro service architectures then
obviously as I just mentioned you have
these you know the books that tell you
if you want to do micro services
correctly you have to do all of these
things and and once run all of them make
sense in in particular context and and
and for particular reasons but but still
remember that there's a trap that when
you start doing all of those things you
may lose track of whether they're
actually solving your problem so what
are they actually solve our problems is
something we'll get to at the end of the
talk but before that I'll dive into how
we
our architecture and how micro-services
are in sera sera because I know I'll use
microservices but then right that
there's quite a couple of things that we
actually need to take care of before
that even remotely starts to work and I
I enumerated that list here because
these these are kind of all individual
things that somehow tied together and
and make up your your platform as a
deployment platform as a target
infrastructure basically to work on of
course you need to automate all the
deployments right but we already did
that anyway yet it's it's a bit
different and I'll tell you a little bit
about it later yes you want centralized
logging you want centralized monitoring
for metrics but also you need to care
about centralized authentication all of
a sudden because if you have 25
different services of running somewhere
they need to have the same concept of
the user and a role which there are if
you have those 25 different services
running somewhere then from the outside
it still has to look like one thing it
needs to be fashion trade calm in our
case so API routing is a real concern
it's not necessarily you know soft to
satisfaction by some of the the more
popular either hosted or open source
solutions that are out there and then if
there are services then those services
need to have some kind of inter surface
communication both synchronous and
asynchronous and and that's apparently
hard so the the essence of having these
lists and we'll get to that later again
is but you have to realize that if you
want to actually say I know
we'll use the micro services then you
have to be prepared to do all of those
things because there's not really a
shortcut and there's not really
something that you can leave out here in
order to make it work in a production
setting
there's no there's no light version of
this for as far as I've been able to to
discern so you know the deployment as I
said it was always automated why is it
harder now you know remember the days
when you could just build the artifacts
and SCP is over to some machine that was
the server and then it would maybe
reload or restart there and it would
work and that process it's very simple
right so you built the deployment
artifact and you move it to the target
environment and there you start it and
it runs and those are simple steps and
then we said we need to automate that
and we need to keep the environments we
need to keep those consistent so we're
not gonna build it on the local
developer machine we're gonna build it
on a build server and that from there
it's going to move in an automated way
to our subsequent no acceptance
production whatever environments we have
but that's hard with our services
because they're they're easily like more
than 2025 technologies involved in just
getting something to run in production
anyway and obviously there are multiple
target environments for the surface and
and we deploy to key bonitas and the
cuban these primitives are way too low
level for firfer getting started quickly
so if I if I get somebody new on the
team and I have to explain them what a
deployment and an ingress is and then
what a surface is as opposed to a path
or a container before they can do
something useful
then I won't hit that target right I
won't hit that simple metric I'm not
going to get somebody to deploy
something to production on their first
or second day because you don't learn
all of that on day one in combination
with our code base in combination with
our conventions so as a result we
describe deployments at a way higher
level
because if you're taking your cue
bonitas yeah most of the manifests and
put those with the surface and make that
your your lingua franca for deployment
then on the first day somebody is
learning cue benitez instead of you know
coding so deployment is declarative as a
result I show you the details later
there's this other thing right you want
to talk to another surface its rests
simple everybody knows rest but then it
turns out it takes really well it takes
many forms and on top of that I you can
have a gazillion different ways of
achieving that on the client side and
and once you start doing that how do you
marry your centralized authentication
into all of these and and then when this
other service is there you know how does
it do logging as opposed to your service
that you're working on so the you know
one of the popular arguments for micro
services you can say hey if you want to
build this thing in Python and this
other thing in Java and and this other
thing in maybe Scala if you want to go
down that road then you can write and
that's really cool but if you want to
scale an organization if you want to put
a little a lot of new developers to work
very quickly then broadening the
spectrum of languages that you'll allow
or that you use will very quickly read
lead to reduced conventions across the
board and as a result it becomes really
hard to make people productive very
quickly because conventions make
productive and that means if all the
service calls from another service look
the same it's really easy to spot them
and then if you know that this in this
particular way you don't have to worry
about the authentication so we're
actually quite strong on conventions and
we don't have a lot of different
languages in spite of the fact that we
run this service platform so the you
know in order to make somebody
productive on their first or second day
you have to hide a lot
things under the hood and that's not
even strange right
anybody can can push something useful to
Heroku more or less instantly and
internally yeah you want to reach that
point too in order to be able to ramp up
that means deployments need to be
declarative because actually telling
Kieran is what to do doesn't scale from
an organizational point of view you will
need abstractions over common things and
you will need conventions that make
things recognizable there's a lot of you
know principle of the least surprise in
there
so this is what deployment looks like
for us when you have a service it needs
to docker file and the docker file
obviously as a result of the build will
produce a container image and that
that's your artifact we deploy that to
communities and before we all start
reading this entire docker file this is
not the important one or at least no
team for not exclusively important part
the important part of that file when it
comes to deployment for us is this this
is essentially a number of labels that
you put in your local file that will
tell our infrastructure and deployment
setup what to do with your service and
it has things in there like the path and
DNS prefix routing it has things in
there like the port numbers that you
expose on the inside and the outside and
it can have many more things in there it
can has have things in there like this
particular service needs the API key to
the email provider available as this and
this and far and then that will happen
because there are secret management
happening somewhere in the geruth and
that secret will be exposed to your
service as an environment variable it
will all you can also leave hints in
here about the resource consumption that
you expect your service to have
but whatever not the deployment pipeline
actually uses that and how it uses that
is not of your concern as a developer at
that point and so they're there there's
a lot of these additional things you can
do but the essence is is that this is a
declarative let's say language for
deploying your service based on this
metadata and we have a tool internally
built
it's called Metatron because it's about
metadata and what Ron come on
and it basically abstracts away all the
kubernetes things during the deployment
pipeline this tool runs and it creates
all of those human energy animals that
you need to get a service up and running
there and in the meantime it also allows
us to manage the Kuban aids Resource
Management at a different level from the
actual service development we somebody
can notice that a resource consumption
first surface is getting out of out of a
particular bandwidth and can actually
fix that by you know at the deployment
level or by redeploying without having
to make make commits to the actual
service this is nice right because if an
operational concern starts to result in
a commit to the actual surface then that
leads to some simple request contention
with feature development it has to be
merged at some point again that's nasty
and then when the service is there you
also see in this metadata tells you
things about routing so the Gateway
mapping on the bottom of the two lines
it has a path segment than a DNS prefix
and that basically means those two lines
that this particular service will be
deployed on API adult fashion trade comm
slash PIM PIM stands for product
information management that's fairly
domain-specific concept for us
and then there's get kids and get kids
is our API gateway so what gate gate
does is it's going to pull the
kubernetes clusters at runtime
for this same metadata that comes with
the service and update the routing state
dynamically based on that because
routing state is runtime state right and
whenever something in a runtime happens
and you need to reconfigure in a proxy
and restarted that that's usually for
brittle automation so instead what we
did know is that this thing needs to
just see what is actually there because
if you as part of your deployment or
reconfigure your API gateway but then
all of a sudden for whatever reason the
rest of the deployment fails then also
this this routing information will be
still so instead it poles looks at the
Cuban is cluster and then it takes care
of that routing on top of that it also
takes care of authorization sent ocation
not authorization that's a surface level
concern of course because it involves is
the user with this role allowed to do
this particular action but gate gate
will basically offload the principle
from the incoming request it doesn't
matter to the back-end service whether
that principle came in through API key
or basic authentication not that we
support it but let's say or a cookie
that was set which is what we actually
use so the upstream surface internally
can just trust a couple of headers let's
say this request comes from a user in
that role so in the end we tie it all
together
it looks like this I think this thing
has a laser cool I've never used a laser
in a presentation before so our outside
traffic comes in through Google load
balancer that's what we do SSL
offloading as well then it hits our API
gateway and currently that does
authentication a surface routing later
on that would also be the candidate for
implementing things like a/b testing a
rate limiting if we want that then the
internal requests which are already
authenticated and and the gate the
Gateway will also at that point already
you know give them the appropriate for a
one for a request that basically is not
even allowed to hit an internal surface
internal surfaces are deployed to the
given ITA's clusters we use three
different persistence surfaces one is
Google Cloud datastore for those not
familiar with Google it's like dynamo
but then on Google then on top of that
we use elastic searching we use Kafka
because the fashion trade our deployment
infrastructure is obviously based on
Jenkins because there's Jenkins I I'm a
big fan of boring technology right
Jenkins looks ugly and has been around
forever so that means it must be so
extremely useful that nobody had to
update the UI in order to sell it I
think that's good
autoblog we use Java we use Python
because these are so low the ecosystems
and we can solve solve problems with
them that's at this same approach would
definitely allow you to deploy any other
you know surfacing based on different
language runtimes the remainder of our
infrastructure required for let's say
control which deployment but also
library artifacts container registries
all of these kinds of things
everything except Jenkins in there is
something that we have cloud-hosted so
we don't run our own like NPM registry
for for our front-end JavaScript
packages or all those kind of things
they're fairly simple concerns that
they're they're well thought out by
several companies and and they provide
good solutions for that same goes for
monitoring and logging this is updated
this slightly moved away from Google's
internal tool called stack driver we
have some other solutions there now I'll
talk a bit about that later
but this is essentially the the
landscape that we run which you also see
here is that
our authentication provider the actual
username password management and storage
is something we don't do ourselves
either so then you get to these other
concerns right I have a services
deployed because I was able to write
like twelve lines of docker file and
then they're logging so for all of our
Java based back-end services you need to
add this snippet to your configuration
and it will do logging and then you see
this this and far that is referenced
there and that comes out of the managed
secrets in humanities which comes out of
our entire deployment infrastructure
which at that point don't really have to
know about yet metrics are monitoring
similar our Java servers are based on a
framework or observe has some nice
features for metrics and and we wrote
this this one little plugin that
everybody uses everywhere to make sure
that if you put this little snippet in
your configuration then you get metrics
and monitoring on all of the service
calls in your service you don't have to
do anything more than that so here's the
list of stuff we built we built this API
gateway ourselves and I'm aware of a lot
of other initiatives there and open
source initiatives there and and
cloud-based solutions there and yet we
build it ourselves we built Metatron
which is our translation from the
declarative deployment to the actual
runtime deployment which is cue Benitez
we build custom swagger code generation
templates to make sure that we have a
consistent API across all surfaces for
client-side calls and that they match
our usage of asynchronous HTTP and that
also they match our particular idioms on
how to do async code in general in Java
because there's quite some solutions
there as well and we standardize on one
we build the custom logging appender for
for our drop Izzard setup so centralized
logging just works and we did the same
for metrics and monitoring and also we
have a fairly complex jenkins set up
where jenkins also runs on its dedicated
humanities cluster and
docker has built built slaves and all of
these things and you don't have to
manually create jobs obviously because
when you create a new repository in git
and it ends in - surface then that thing
will become a surface and it gets built
pipeline and deploy pipeline for the
different target environments so be
mindful you actually have to do all of
these things so then there are some
other things that we do we set up and
and and this is obviously where you get
to the point where ever the
organizational scalability of what you
do is not only dictated by the
technology that you use we have code
style guidelines aesthetic analysis
rules and we have really really
extensive rest guidelines that's a
really long document and we have some
rapper line libraries that make sure
that at the code level a lot of things
that we do a lot always look the same in
order to make this skill and work
appropriately the the pitfall that many
of the larger companies fall into is the
you know the insight that these things
really help speed things up because
everybody is on the same page but then
the oversight that you need to have like
a dedicated body of governance on these
things and that's when you get like the
Enterprise Architect or the lead
architect or these kinds of things
who will every now and then just for fun
change the code style guidelines so
everybody gets to do something else next
week right and and that's really
annoying
if you have to be conscious of the fact
that all of the things that you want to
make sure that are embedded you know by
by convention into development
organization are also the product of the
development organization so anything
that that that basically dictates the
way of working to any extent is
formalized in git repositories again and
the only way to change
by creating a pull request and having it
up for review amongst the rest of the
team
there's nothing against wanting to
change the maximum line length from I
don't know 170 to 250 but you have to go
through the review process and that
involves obviously the one who that that
pull request gets assigned to but also
anybody else who has an opinion because
that's why we have it there so so that's
that's really important right so are a
lot of these decisions are a result of
process and not the result of a role not
a result of somebody carrying a
particular role and and by virtue of
that being able to change things that
includes me and I don't know what the
maximum line length is it's probably
something so there's there's the things
we didn't build and this is sometimes
hard to defend right because people want
to build these things I want to set up a
knee okay cluster because then I can say
that I've set up a knee okay cluster III
want to set up Prometheus because it's
this next cool thing and and I want to
run our own kubernetes cluster and and
and even I want to write an
authentication provider I trust me is
really boring to write an authentication
provider and and then when you see all
the things that you did wrong and how to
solve them it becomes even a lot more
boring so we really defend ourselves
against building these kinds of things
Google has hosted queue benitez it works
very well we use in hosta teal'c a stack
it doesn't work extremely well but I can
attest that it works and also the
probability that it works while all of
our other things are breaking it's
obviously a lot larger than when we
would host it ourselves just for simple
statistics right regard
of whatever the events are related or
not but if somebody else is managing
that closer and I'm managing my own then
the probability of both breaking at the
same time is just substantially less
than than what I'm managing both and and
that's a big benefit and I've been in
many environments that whenever she has
defend the logging cluster is the first
thing that breaks and you can't see
anything anymore
same with promises so so we use data
dock which is a sauce based monitoring a
matrix solution and it works really well
for us and then you know you may have
collected from what I was saying there
was a strand of keeping things boring
more or less so we have this stuff built
in Java and we do all the HTTP calls the
same way and we do all this the same way
we do all that the same way so doesn't
that really defeat the purpose is having
these services anyway to an extent yes
if you would never allow anything else
of course we do things in other
programming languages we have services
to deployed in Python as well and I'm
pretty certain that when you look at
your from now we'll have a couple of
other languages in there as well but the
thing you have to keep in mind in order
to introduce a new language you still
cannot take any of the shortcuts how do
you build a container that contains the
application in that language and then
how do you make it conventional and
simple for somebody in that language
runtime to add the centralized
monitoring to add the centralized
logging in to add the internal service
goals if we're doing Python do we create
a new swag or cogeneration template for
that language so that we make sure that
somebody does an internal service cool
it always looks the same because
otherwise it's just rest again and then
you get is 500 different packages in
Python that you have for doing a rest
cool so multiple languages and multiple
things but if one Python surface looks
wildly different from another one in the
same company then that's going to slow
you down in terms of scalability
because people will always move to other
teams and move on to other efforts and
when they get there it's just a
substantial game my stuff looks the same
so that's so cool and we did all of that
so is it working then you may ask we had
these two simple goals right I want to
do really fast onboarding and I want to
make sure that when I add people to the
organization that will start producing
more software as a result of it so for
the onboarding yes so far everybody
who's joined has done their first useful
production commit on the first or second
day and from that point on it becomes
apparent quickly enough how to do things
because of convention because of
documentation and because of the fact
that everything looks kind of the same
also when you move to a different team
or when you move through a different
particular service to work on and then
what happens is gradually over time
people will you know pick up the details
about how everything under the hood
actually works you know how our build
pipeline actually works and then the
other thing and that's more tricky right
so did the organization skill in terms
of productivity did we actually become
you know did we gain feature bandwidth
basically that's what you care about and
that's a tricky question because what is
productive and then and this goes back
to discussion that you know many people
had on software teams and so for
organizations and how do I you know how
do I measure the output
reliably measure the output of of a
software team so the the simple things
that come to mind is obviously no story
points we do story point estimation for
first sprint planning and apparently
means something so we do that we
obviously know how often we commit how
many pull requests we do how many lines
of code yeah we don't we know that or at
least we could know that I haven't
counted if nothing else
say the bully quests are the most
important thing here because whenever
you do a pull request against master and
that gets merged and actually something
gets deployed to an environment and then
when it's deployed in that environment
the person who wrote it will briefly
have a look at it and if it all looks
satisfactory it'll push a button and it
gets promoted to production and that's
it so let's have a look first thing is
the just plain number of repositories
over over time right this is the number
of git repos that we have which could be
anything right from documentation to two
to one offs to stuff that comes out of
the hackathon days and actually
sometimes you see this little spike and
that's usually when there's been a
hackathon day because then people create
these one-off but yeah sure it goes up
into the right hands
so we do more stuff and sometimes it
flattens off a little bit and it moves
up again fine
then if you look at the number of
surfaces over time that's probably more
interesting because surfaces actually
are supposed to do something
feature-wise within the platform and
that also goes up in the beginning it
was more or less exponential and then it
flattened off a little bit and then it
became exponential again and and these
things are actually you know pretty easy
to explain when you look at our feature
progression then this makes sense we're
starting to do additional new features
we got we gained more services fine then
there's the story point thing hmm
so this is the number of story points
that went from anything to done per week
according to our JIRA instance so it
looks flaky at best there's this huge
spike which either means somebody
changed the process and then did a bulk
update of something or something else
happens that that's as hard to explain
without being in the context still so
you know without diving into
the very details of how all of this
works I think it's safe to say that no
story point estimation is something
that's that's you know really hard to
reliably use as a metric and then
subsequently if we were to use it on
efforts it actually went down the number
of number of points we deliver per week
why is that
maybe we got slower maybe things got
more complex maybe we're working on more
complex features now don't know if you
look at this way so what you have on the
horizontal axis here is the team size
and on the vertical axis is a number of
samples you know so the the team size of
10 we've we've had that for quite a long
time you saw that in the beginning in
that chart and so we have the most
samples for the team size of 10 and if
you have to judge this in any kind of
way you'd have to say well an
organization of 10 to 11 people working
on development is perhaps the most
productive and and anybody add after
that doesn't really help and as
disappointing right because we did all
this work and and we set up this entire
micro surfacing and all of that and now
adding people doesn't help so when you
see this it's weird so you go around the
office and you talk to people and say
hey were more people than we used to be
do you think we're doing more work yeah
yeah we're doing lots of more work ok
that's cool so maybe we're pushing more
features or at least more and more
changes due to production so this is the
pull requests instead of the story
points and you see here that 10 11 looks
great although the variation is a lot
larger than then when it comes to the
story point estimates but then
afterwards it still gets worse alright
so now we're preaching less changes with
more people in the team according to
this so so how does that work because
people still said no no we're doing more
work and it also feels that way and it
looks that way so
in all likelihood we will you know if
you look at it this way we might not be
looking at the right things I do we do
we really have consistent estimates or
of course not because the team is
changing all the time there's new people
and and and then we create these
features plates right here with four
people and then all of a sudden you were
ten people you're not gonna be in a
single stand up with ten people so you
do a feature split and you split up some
people to do their own little teams so
that changes all the time so so story
point estimation is probably the worst
thing to look at given given that we've
only been at it for a year with
constantly changing teams does a bully
quest have a consistent average value
deliver no things get bigger you have
more technical changes you have more
more technical depth to work away so
this changes all the time and and not
everybody has equally sized commits so
there are way too many dynamics to to
actually do something useful with that
so instead if you think the other way
around so what is the thing that matters
right if you put a group of people in a
company and they need to start making so
far and they need to be each of them
individually their most productive so
regardless on personal preference about
a type of style music in particular way
shade of lighting and and whatever or
not they have this or this or this type
of desk where you can run walk sleep or
crawl I don't know
but regardless all of that there there's
two things you know in terms of
scalability that and that we believe
really matters and it's the relief of
contention so if I'm working on this can
I work on that without being blocked on
it by something else that happens and if
I am going to do work for a full day can
I spent that full day in focus or more
or less a single thing
so that
actually leads to metrics that we might
be able to know usefully measure what is
the feature contention I want is
developer focus so this is the result of
that what it has here only horizontal is
the number of surface repositories that
we have and on the vertical there's time
and up is more recent and down is longer
ago and what the colors mean is that if
it's green that means on that particular
day there was a single pulley quest
against that surface which was that
merged master and deployed eventually
went into production if it's any other
color than green with the exception of
white obviously it means that there were
at a single day multiple pulley quest
going against a single surface and is
bluegrass are initiated by by different
people right or different groups of
people or something like that so that
means that there's contention on that
service that means that there's
basically people trying to push the same
to the same part of your platform and
then you know why that happens I have
lots of reasons sometimes it's like a
simple fix that another team needs in
this thing and you can just squeeze it
through but very often it's either an
architectural mistake for you didn't do
the correct feature split or or or worse
than that it's just conceptually
completely wrong and then you have this
one surface here where that happens all
the time
so that's our front end and that's
actually one single monolithic react app
so that makes sense and that's cool
because then also this makes sense and
the front-end is you're actually waiting
for each other's builds longer more
often than anybody else so we should
probably work on fixing that so that's
cool we have something we can look at it
and we can say this should be mostly
green and if it's not we need to solve
that and then we have the other thing
that says is a person working on one
thing at a time
so what this says has the people on the
horizontal without the names
so they became numbers sorry people and
still have the time and there it says if
it's green that means you commit it to a
single surface on that day and if it's
any other color that means you were
committing to multiple surfaces on a
single day and that's not focus invest a
lot in the setup for micro services
because there are no shortcuts you can
do half of it in order to just get
started so if you can't do that don't do
it at all when you have that
architecture it can help you scale the
organization but everything else is
still really careful consideration about
the team's place in the feature splits
are really careful planning to make sure
the people can work in contended and in
focus thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>