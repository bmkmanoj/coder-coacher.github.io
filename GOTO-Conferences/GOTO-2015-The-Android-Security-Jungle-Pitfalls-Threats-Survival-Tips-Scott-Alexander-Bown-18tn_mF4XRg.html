<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • The Android Security Jungle: Pitfalls, Threats &amp; Survival Tips • Scott Alexander Bown | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • The Android Security Jungle: Pitfalls, Threats &amp; Survival Tips • Scott Alexander Bown - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • The Android Security Jungle: Pitfalls, Threats &amp; Survival Tips • Scott Alexander Bown</b></h2><h5 class="post__date">2015-10-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/18tn_mF4XRg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">(light piano music)
(applause)
Thanks for the warm welcome,
and thank you to you
guys for coming today.
I know there is quite a few
decent talks on at the moment
and Android security can
be a little bit niche.
I have tried to
use that jungle analogy
to talk about the &quot;Android ecosystem&quot;:
some of the threats and risks.
(that is  the idea behind the talk).
I have split it into two halves,
to allow for the fact
that this is a conference for
all developers, and technical people.
The first half is for everyone.
Hopefully we can
talk about the ecosystem
and dispel a few myths.
The second half,
we are going to get into
full-on survival tips to strengthen
the security of your apps.
(You may notice some references
to a certain jungle movie
throughout the presentation.
there is prizes at the end if
you can guess which one it is).
Before I get started, let
me just introduce myself
in a bit more detail.
I am a lead Android developer
at a small apps company
based in Bath (UK).
I work remotely from Bristol
(which, after chatting to
a few people yesterday,
no one really knew where that was,
and so it is about 100
miles west of London,
and it is the home of Banksy.
And those two things people
seem to get whereabouts it is.)
At Intohand I create apps
for industries
(weather apps, retail,
video on demand and stuff).
And my favorite bit, or
the bit I get excited about
and enthusiastic about
is the security part:
making them harder to hack.
That interest led me to co-author
the Android Security Cookbook.
I wrote about a third of that book
(defensive and protection chapters).
Some of the stuff we cover
a bit in the second half.
(brief in the slides, obviously,
but there is more code samples
in the book).
The last thing
is that I co-founded SWmobile,
which is a mobile
developers meetup group
based in the southwest of England
(about 600 members,
and we do regular tech
talks and hackathons).
(I am a remote worker, but
I enjoy face
time with fellow developers,
and sharing war stories and stuff,
so please do come and
say &quot;Hi&quot; after the talk).
 want to set the scene with Android.
Earlier last week, Sundar announced
that we now have 1.4 billion
active users of Android
(30-day active
devices with
Google services installed,
that does not even include all those
Chinese tablets).
(Huge number).
By far the largest mobile platform.
(This funky
graphic is trying to illustrate
is that it is a diverse platform.)
There is over a million lines of code
in the Android Open Source Project.
Thousands of different devices
(which this graphic is trying to illustrate
from the opensignals.com
annual fragmentation report).
Hundreds of OEMs.
In theory, there is eyes on the code.
This should build trust,
but there is not
a single point of failure;
we are not relying on a
single company or entity
that holds all the keys.
And the point of these
couple slides was just to say:
there is no absolute &quot;way it is&quot; on Android.
You should be skeptical
of any security vendor or company
that says they have got a handle on it.
Unlike iOS, where we have
updating devices in this diverse environment
via over-the-air updates,
when we have got different OEMs
and different carrier modifications,
over-the-air updates just do not work.
How does Google help with
security in those instances?
They put in security services.
I just picked out a couple
that I thought were relevant.
The first one being
(the one probably most of you
have heard of): Google Play store.
There is been a human involved
in the approval process
since the beginning of 2015.
When you
sign up for accounts,
there is background checks
that you do not know about.
But Google leveraged their other apps
(e.g. Gmail),
and all their data
points to help with that
background validation check.
They have also started
the developer security notifications.
When they are scanning the apps
and running their test to see if
it is not malware,
if they detect things
the developer have accidentally included
their private keys in the app,
 if they are
using a vulnerable version
of open SSL that they have included,
and they have also, there is some issues
around particular versions
of PhoneGap, Cordova.
Qhat they started doing
was notifying developers,
saying &quot;You know
you have got your private keys
in your app, you should update that.&quot;
They reckon there is about 60,000 apps
have been updated on looks
back at those notifications
(good system).
Small drop in the ocean
compared to the number of apps,
but it is a step in the right direction.
The other thing that
is behind the scene
on Google Play store is the
Android Bouncer service,
which was announced,
or publicly announced,
several years ago, and
that goes and runs
all the apps in
emulate environments.
It checks for malware
signatures and dodgy stuff,
and then removes them from the app store,
suspends them, and, if warranted,
can remotely wipe them from the devices.
The other
is the Android device manager,
a free service
(anyone with an Android device can install:
help you find, lock,
and, if necessary, wipe your device).
(If you have got an Android device
and have not that installed,
I would certainly
recommend putting that on).
Something that Google
has announced recently
is the safety net system:
an intrusion detection system.
Any device with Google
services can gather
different data
points and uploads that
to the Google Services, and
they do data analysis.

They try and look
for potential malware.

In the second part of the presentation,
I will talk about
public API for the safety net
(you can leverage in your apps,
to leverage
some of that knowledge,
which is pretty good).
Lastly, mention
Android at Work, which
is a way of segregating
your personal and business
data and applications
on the same device.
Definitely geared towards
a BYOD approach,
but it gives system administrators
API access for provisioning,
managing profiles.
You can
remove your access
and just wipe the business data and apps
not your personal photos and stuff
(I think that is cool).
The next slide talks
about the different layers
(I have  stolen this
from Adrian Ludwig's talk
from Black Hat, because I
thought it was quite good
at showing the different layers).
If you go from left to right
that is the more cloud-based services,
to the layers within
the device.
I just wanted to draw attention to
the verified apps section.
It came into Android in 4.2,
a way for Google to monitor apps
and detect potential malware
when users were installing
applications not from
the Google Play store.
Anyone with an Android device
that has installed that, will
see the &quot;Verify apps&quot; consent;
then,
when it is potential malware,
you will get a warning,
In fact, if it is so dangerous
you could be blocked from installation.
(pretty cool check, the way
that Google are trying
to increase your security
even though you are not
using the Google Play store).
The other thing that is
worth bearing in mind,
is Android's
upgrading its newer. The newer versions
have more security
features and a stronger,
I thought I would mention that
if you are looking for a
a BYOD policy,
newer versions of Android
would be a good policy.
For certain apps,
if you need certain security requirements,
targeting five and above
would be a good call.
That is the ecosystem.
I want to talk about
some of the threats now.
Malware's
and Android security
ialways gets,
the tech media love to get hold of.
I am sure you have all seen
those clickbait headlines
that are about how
Android's been ripped open.

As you learn more about it,
you can see, it is a lot of hype.
But there has been more
publicly disclosed malware on Android
than on iOS.
They tend to be around, largely,
around premium SMS driven.
Although, in Android 4.2, we
got this new warning;
if you text a short code you get
a user confirmation screen that comes up.
That has mitigated some malware.
Apart from that, it tends to be
information stealers,
and, recently
ransomware.
The last thing I
wanted to say on malware:
regions where you are in the world
plays a huge role.
Russia, China, and Persia,
the average instance of malware
is higher than Europe and America.
Something that,
as far as Google announced,
they are looking into
(omething to bear in mind
when you hear these stories about malware).
One of the other threats that we have
is app hijacking
(also known as &quot;trojanizing&quot; apps).

You take a genuine app,
decompile it
and put malicious.
Obviously,
it could potentially damage
your brand (if that is your app),
and affect your users.
You would dupe users into installing that,
from phishing emails, etc.
The concerns around this is because
reversing Android
apps is pretty easy.
(there is a talk this afternoon
which covers some of this,
I am not going to go into
too much detail now).
On Android we do not have,
a certificate authority
when we are signing apps
(each app has to be signed
for it to be installed on a device,
but there is no
central authority around that,
so there will all
self-signed certificates).
The other concern is
that sideloading apps
(installing apps
that are not from the approved Play store),
is very simple (it is just an option
that you turn off on the device).
Three things
that make app hijacking more of an issue
that n iOS (more difficult
to sideload apps).
We will talk in part two some
of the defenses you can put
into your app to guard
against app hijacking.
There has been a couple of big stories.
(I could probably
do a presentation
just on all the security
incidents in the last 18 months
in and around the Internet and Android).
(Although, Heartbleed, that
I am talking about here,
has only really affected
one version of Android).
(It was still affected.)
Anyone that bundled that version,
it was to do with an
open SSL vulnerability.
Part of the developer checks
that the Play store does
now (the app scanning)
is related to this threat.
Recently (as you probably guessed),
if you come up
with an Android exploit,
you have to come up with a cool name
and a cool logo.
(everyone's doing a great job of that,
which is great to see).
Stagefright was another one
that affected almost all Android devices
out in the marketplace.
It was a widespread exploit, potentially,
and it could denial-of-service
attack that device
(there has not
been any threats
or attacks yet).
(I thought I would mention this,
A, because it is recent).

b) some really positive things happened).
Nexus devices now
have a monthly security update
and security bulletin
(security issues have been
patched).
Samsung and LG also have committed
to frequent security patch program.
In the light of these,
this great research,
(and this funky name
that got all the media's
attention),
forced some of the OEMs
to increase their security updates.
(great thing).
(That is a couple of the threats).
Let's talk about some of the
risks to our applications
(when we are creating them).
(No presentation can be complete
without a Top 10).
I will mention the
the Top 10 risks
that there are to our apps.
This was compiled
by the OWASP project
(some of you maybe familiar with the
Open Web Applications Security
Project from the web world).
It is a not-for-profit organization
focused on improving security in software.
And a couple of years ago, they produced
the Top 10 mobile risks
(they are due
to update that very soon)

When we are talking about
survival tips
we will try and related back
to some of these.
(I have just put them here
for your reference.
it is too much to take in to, on a slide).
If you go to the OWASP site
(the Mobile Security Project site),
each of these is broken
down in
attack vectors and sample code
of how to  mitigate them
(definitely worth checking that out).
(one of the things
you should look at when you are doing
your development and testing).
If you can tick
off these 10 risks,
then you are on a good path to
making your app more secure.
(part two)

(quick show of hands:
who's an Android
developer in the audience?
Brilliant, that is awesome,
that is way more than I was expecting.
Cool - you are
going to love this stuff).
(Even if you are not
an Android developer,
a lot of this still applies to iOS
when I talk
about
mobile thick client effectively).
Let's look at how we can (survive
in this jungle)
improve our app security.
(I was going to focus on
these four areas;
each area has several things).
BWe want to harden
the network communication
between the app and our service.
We want to protect any
data that we have stored.
We are going to: use
encryption for that;
look at ways to
validate
(where the app is running),
the device and app's integrity.

Then, look at how we can
increase the binary security.
(these
apply to iOS as well).
I thought I would start with
strengthening network communications,
because
every app that I have written
has some online component.
(It almost goes without saying, but)
Using SSL and TLS for all
your network communications
should be a default.
In iOS 9,
they have made that as a mandatory
(you have to opt out).
(I hope the
next version of Android
comes with something similar).
The second point:
use the platform
SSL/TLS validation, and not to disable it.
(that sounds like a stupid thing to say;
but if you Google
or go to Stack Overflow
how to enable using
self-signed SSL certificates,
you will see the most-voted answer
on Stack Overflow with tons of rep
tells you how to disable
the SSL validation,
totally rendering the point
of having SSL useless).
There is different ways of doing it.
You can use a form of pinning
(which I will talk about next),
or buy genuine certificates
for your development service
(that is what I have done in the past;
it saves you having to
put all this dodgy code
into your code base
that basically turns off the validation).
The other thing you could do
is to only use the stronger cipher suites,
and the stronger TLS versions.
(This is particularly important or useful.)
If you control the service,
then you can control
the type of connection,
the strength of the encryption
between your apps and the server.
SSL defaults to lower versions,
to support older browsers.
But you do not have to do
that in your app. You can
enforce that, and
if anyone is using OKHttp,
2.1, saw
cool security updates and features.
If you are using 2.1,
there is a good article
on how you can enforce the connection spec
(to be stronger
and to drop the lower specs).
If you are using straight out of the SDK,
HttpsURLConnection,
you could still do it with.
(If anyone wants
any code samples of that,
just give me a shout).
It is one line on OKHttp.
The other thing you could look at doing
with your connections
is: SSL pinning.
(If I could just get a show of hands,
who's heard of SSL pinning before?
Brilliant, so most people).
(For those that have not heard of it,)
It is just a way
of reducing

the amount of certificate authorities
that you trust.
You are effectively
pinning your SSL certificate
to make sure it is that one.
There are two
different types of pinning.
1) pin the whole certificate,
or 2) pin the public
key of that certificate.
I always recommend doing
public key pinning.
It is a slight
extra step in getting the pin...
but you do not have to change your app
or force an app update
every time you renew your certificate.
(I have put a
link to the book, there,
there is a code sample of how to do that).
(There is some open source code online
by Moxie Marlinspike,
but it has not got a
great commercial license).
(Check the stuff out in the book.)
In essence,
when you make a connection,
you do some validation
to make sure it is the SSL
certificate it should be.
(that is the basics of pinning).
The other thing you should
probably look at
is networking (the
part of the Google Play services,
they have introduced this
dynamic security provider).
This is another one of those things
that, because we cannot
guarantee over-the-air updates,
we cannot guarantee that users
are going to upgrade their phones,
Google have put in place,
and the update cycle
of Google Play services
is about six to eight weeks.
In that time period,
there is a chance to get,
if there is a vulnerability that comes out,
or an exploit, there is
a chance that that fix
gets bundled within the Play services.
(I have put a link to
the training article there.
It has all you need to
know about how to call that
and when to call it;
the code sample is that simple.)
You can use that:
provider will fix any
issues in the system that has
with any of the OpenSSL libraries.
Because it is an update
of the cryptology provider,
you can use that
for
standard self-encryption as well.
You can use that instead
of Bouncy Castle.
(that is it for networking stuff.)
Next: data.
When I say storing data,
I mean encrypting your data.
Something that
frustrated me as an apps developer,
when I had pen test reports
on the apps that I have created,
or spoke to security people, analysts,
they always said, &quot;do not store data.&quot;
I want to make my app
as performative as possible,
I want to make it work offline,
or in dodgy mobile connections.
(The &quot;do not store data&quot;
used to bug me.)
If you are storing it,
it needs to be encrypted.
And, obviously, this depends
on the type of data and
application you have
(medical records,
nuclear launch codes,
probably should not be cached;
other data should be).
(Here is some code,
just to show how easy it is.)
This is a best practice approach,
when you are doing encryption:
use password-based encryption.
(not to
store the key anywhere).
The main thing about encryption
is where to store the keys.
It is rarely the
algorithm that is broken,
it is the fact that someone
find where the keys are.
This shows how to use
password-based encryption: using
the user inputs, and then using that
to derive an encryption key. In this case,
derive a symmetric encryption key
(the key that we use
for encryption and decryption).
(I put this in for reference.
there is a better example
in the book.)
You do not
persist the key anywhere,
you do not lock the key anywhere,
and then you build in an app timeout
(depending on your app,
maybe when the app goes
into the background,
maybe when the user logs out,
but you would wipe that key from memory).
(that is how it stays safe).

In this code sample we are
using about 10,000 iterations,
(nice and strong,
but just take a long time,
maybe four seconds
on a Nexus 5).
You can tune that,
depending on
 how secure you want it to be.
A couple of libraries
can make your encryption
tasks a lot easier
(commercially viable).
(Otherwise, there is no point in
mentioning them, to be frank.)
(The slides that
are uploaded have links
and stuff to all these.)
Conceal is from Facebook:
awesome for files.
They use it for encrypting photos
that they have cached on your SD card.
Easy to use,
it defaults to all the
stronger algorithms.
It uses AES-GCM (the preferred
AES algorithm).
(I definitely recommend trying that.)
(It defaults to the strong stuff,
because the stuff,
whether it is a hangup
from the Java days, you
know, from Android's past,
being Java-based,
but the default, when you are
dealing with encryption,
it does not default to the strong,
the strongest algorithm.)
(Quite a shame going in,
because you
just want to start using it
and it be as strong as possible,
but that is what is nice about Conceal.)
QLCipher, if any of you have
an SQLLite database in your app,
which you use for data storage,
you can very easily swap in SQLCipher.
The API's all exactly the same,
apart from when you open a database
and when you create a database,
you have to pass in a password,
and it uses that password-based encryption
(that I talked about a
couple of slides ago),
to generate, create a key and
encrypt your database files.
The key about these libraries
is they are very easy to use,
easy to swap in and out.
(that is what gets
big ticks in my books.)
SQLCipher uses
256-bit AES in CBC mode
(it is pretty decent.)
However CQLCipher
adds between four and seven MB
to your APK size (for
some people, that is too much).
The good news
is that Google just upped
the APK size limit in
the Play store to 100 MB;
hopefully that gives less,
less excuses not to use it.
Lastly:
Secure-Preferences,
one of my open-source libraries.
You can also look at Hawk
(much better-named
and much more popular implementation).

(skip references for
those who aren't familiar).
It is a key value store
which is backed by an XML file:
easy way of securing
or obfuscating those files
(people on rooted devices
cannot mess with your things).
With Secure-Preferences,
you can use it with password,
and it does that
password-based encryption.
(nice and secure.)
If you do not use a password,
it will generate one,
and store it in there
(if you rip the file out, you
cannot tell which one is the key).
But
it is still obfuscated, because
you could find it with enough effort.
Just small steps
to make your apps harder to hack.
Above all:
avoid hardcoding
your encryption key.

Reverse engineering
and finding a constant,
a string constant for your encryption key
is trivially easy.
But
not all apps can use the
password-based encryption,
an app passcode (or something like that).
If you have to, generate a key
dynamically per installation,
do not hardcode it.
(it is the equivalent
of locking your front door
but leaving your keys in there.
The door is locked, but
you have got no security at all,
so hopefully you guys remember those two).
Let's go on to verifying
the integrity of the app.
There is a couple things you can do.
You can check
whether
these are tamper detection techniques.
Has your app been hijacked?,
Is it running in a different state?
You can talk to the PackageManager,
and see if you are in a debuggable state,
(should not be happening
once you are in production).
You can calculate an apk checksum
to see if it has been modified.
Or you can
sign a certificate verification.
This is my favorite
one, because each of our
app has to be signed
with a developer's key
(when we publish it or we distribute it).
That key remains the
same through the
lifetime of the app. One
of the cornerstones
of Android's security is that,
the signatures have to
match. I can't take
Facebook's app, decompile it -
would break the signature, resign it,
and then distribute it,
and you install
Scott's version of Facebook.
It does not work that way.
The signatures would not match,
it would not let you upgrade.
Your signature stays the same
throughout the lifetime of your app.
You know that in build-time,
you can check in this runtime.
(And this is
quickly how you do it.)
You would use keytool (Java),
to list out your keystore's
signature.
Then you just embed it in the app.
At runtime, you would ask
the PackageManager for your signature.
Hash the signature (to assure one,
to match what you have embedded),
and then compare the strings.
(And that is a quick and easy way
of detecting whether your app has been,
has been decompiled and then changed.)
However, if
someone can decompile code,
they can take this check out.
(we will cover in
a couple of slides' time
how we can obfuscate our code,
make this harder to do.)

You can say that for
anything we put in the app,
the SSL pinning, the encryption,
someone can decompile, take
bits out and look at it.
But it is using all these methods
in conjunction with each other
to hardens the app.
If we want to verify the device integrity,
there is various different
things you can check.
In the bill properties, just
to see if it is an emulator,

there is a couple of good
answers on Stack Overflow.
Tim Strazzere has a really
good library on GitHub,
which goes through a lot of stuff
(inspired by the different malware
that he encountered as
a security researcher).
A cool library if
you should be running in an emulator
if you are in production.
It could give an indication
that
you are being tampered.
Or dynamically debugged.
The other thing that you can do
is the SafetyNet test.
(This is what I mentioned
near the beginning.)
It is part
of Google Play services.
(I think it was 7.5 that it
came, that it was released.)
There is a test you can run
(the documentation is a bit
vague about what it does).

It says whether it is CTS compatible,
and the CTS tests of
each version of Android
that is built from
the open source tree.
If it passes all them,
then it is verified as
an okay device.
The SafetyNet
will come back
false if the device is rooted,
if it is been compromised in other ways.
It is has the vulnerability,
you can
check the state of the device.
The API was quite unwieldy,
so I wrote a helper library
to wrap that.
(That does the on device validation.)
(there is a sample in
the Play store as well,
you can just run on your own device.)
It gives an indication
that that app installation
could be running on a compromise device,
and you can act accordingly on the server
depending on that information.
The sample library does not
have a server side component
(the Android
security team let me know
that that is what it should have):
you do the validation
test on the device,
(which is good, but it is better
to do the validation test
on the server, because
that cannot be compromised).

If the device is owned,
you want to do those
checks on the server.
(it is enough
to get you going with that).
I am working on a server side branch of that
to show how that could be used.
(Worth checking out.)

I commonly get asked about detecting root;
the thing that you might want to do
in your app.
I should
probably start with a disclaimer
that there is no
100% way of checking for root.
(Root being root on a
device is the equivalent
to being God; there is
no way you could ever
100% say that you have detected it or not.)
But  you can look for root apps,
potentially dangerous apps.
You can check certain system properties,
which could have been changed
on a rooted device.
The most common way is to
look for the SU binary,
which may or may not be
present, or may be hidden.
Same with the BusyBox binary.
You can also check
if certain system paths
are writeable, or rewritable
(when they should not be).

We pulled those checks
and put it into a library called Rootbeer
(logo at the top).
That does a native check as well.
And we managed to defeat
some of the root cloaks that we found.
If you install several root cloakers,
they manage to defeat it eventually.
It is a good reference.
If anyone has any
other root checks
they want to add,
that would be awesome.
Quick and easy way of doing it.
With a lot of these,
this hardening these security features.
We need to look at ways
we can protect the binary,
to make it more difficult for attackers
to take checks out.
We can obfuscate the code

(a way of turning your nice,
maintainable code into what
we see in the background here,
gobbledygook).
It is harder to reverse, but
it is what people refer to
as security via obscurity.
Your code is not encrypted,
it is just harder to read.
And then hopefully most of
you have heard of ProGuard.
it is the Java obfuscator,
part of the Android SDK, free.
Very easy to turn on effectively.
A lot of the Android
exceptions that you have to have

already have it installed
(if you have the SDK installed).
One of the things you have to remember
when you start using obfuscated code
is that if you get crashes.
(I know that sometimes happens in apps.)
(I cannot say I have ever written
an app that crashes, myself.)
(inaudible)
Trying to
work out what is going on
with a stack trace that is been obfuscated
is near impossible.
And that is why, in ProGuard,
they have a tool called ReTrace,
which takes the output from ProGuard,
which is like your mappings file,
and you can use that
with your stack trace,
and turn it back into
a sensible stack trace with line numbers
and proper names for
your classes and methods.
(The awesome thing is that,)
Services like Crashlytics, HockeyApp,
and Crittercism
(but I cannot remember if they do now),
support automatic
de-obfuscation of crashes.
I am a massive fan of Crashlytics,
(I have used that the most
I will just talk about that.)
They have a Gradle task
that runs when you do a
build; it will upload
that mappings file automatically.
(it is really handy.)
But if you want to go pro-ProGuard,
you want to look at DexGuard.
This is the pro/paid version.

Of course, there are
other obfuscators
which you could look at.
Metaphoric, and Arxan
(very popular, and expensive)
do a better job
than ProGuard at protection.
(I am most familiar with DexGuard,
I will just, I will talk about that.)
ProGuard
is a Java obfuscator;
DexGuard, has been
built for Android,
and it is more around protection.
There is security utils
built into the Enterprise
version
(some of the stuff we talked
about in this presentation,)
just using the utility code.
That is automatically
hardened as part of the process.
Just helper utilities, effectively.
My two favorite features:
sting encryption,
perfect for any API keys
or secrets that you have in your app

(when you reverse engineer,
it is easy to find).


(Using string encryption
is a way of doing that.)
In your DexGuard configuration file,
you just those
strings, whether they be
the actual variable name,
or the code
(you have different options).
Whenever that appears in the code,
that is all encrypted.
Obviously, the key is in
the APK files somewhere;
otherwise you would not
be able to run the app,
but it is just a quick and easy way
of hiding your keys.
The other one is API hiding
(part of the DexGuard process),
it changes anything that is been hidden
into a Java reflection-based call.
When you reverse engineer it,
it is more difficult to
figure out the flow of the app.
You can use those
in conjunction with each other
(that is why I like them.)
You can
hide your tamper check,
or hide your SSL pinning verification,
and then, using string
encrypt, reference your
method name, your class names,
that you have used a reflection-based
call on, effectively,
that you have hidden, and
that is also encrypted.
That  makes it
double-strength check.
Anyone that is looking for that
is looking at some code
that does not make any sense
but also it is looking up something
that they then have to de-crypt first.
(I think it is pretty cool.)
(that is it for the survival tips.)

Testing, and trying to
see the other side of the coin,
what the attacker sees.
there is many tools
and great articles about
how to reverse engineer:
Apktool, dex-to-jar, Androguard.


The Quick Android Review Kit,
(which I just can't help but think &quot;Quark,&quot;)
(and that is just how I say
it, and that is the face I see
every time I see that library,)
is fairly new, it was open-sourced
a couple months ago by LinkedIn.
It is a Python script
that you run against your
app or your source code.
It will give you a HTML
report about the weaknesses
or any exploits that
could potentially be done.
Like an exploit APK,

you can try and exploit different things.
(definitely one for your testers
and for you to do once
you have put some of those
survival tips in place.)
It is new library, they are
looking for more exposure
(I thought I would mention them.)
The other one is
Drozer, from Mercury Labs.
It is been around for a while.
very feature-rich.
(the guy I wrote the book with,
he wrote some really good stuff on how to
exploit and test apps to see
whether they are vulnerable
using Drozer, so definitely
worth checking out.)
Links,
because

there is tons of other
stuff you can look at.
(there is just some links
there which would be useful.)
As a wrap-up,
hopefully the analogy of the jungle
was not too contrived.
The ecosystem is diverse,
there is predators
and threats out there.
And, hopefully, I armed you
with a few survival tips,
beef up your apps' security.
Thank you very much to GOTO Copenhagen
for inviting me here.
My company needs a hand for
supporting me doing this,
and 20th Century Fox,
obviously, for not suing me
for blatantly ripping off loads of their,
screenshots from their films.
Thanks to for listening.
Cheers.
(applause)
- Thank you very much, Scott.
there is just a couple of questions, here.
I guess you would better field them yourself.
- Okay.
&quot;you are saying not persist
the key on the device,
how do you deal with password change?&quot;
You can do that. If
you want to see an example
of how to do this, check out
my Secure-Preferences library
because I handle that in
that, and that would
in a very dumb way
decrypt the library/code

with the existing password,
and then encrypting it again
with the other password.
You can't cope with, because that is
password change, it
does not help you cope
with if someone's forgot their password.
In that case, you cannot decrypt the data.
That is why I see it more as,
it is really good for caching the data.
But there is no way of
finding that password, that is the point.
That is why it is the
secure way of doing it.
There is another question:
JavaScript bindings in
WebView safe to use?
That is a good question,
I do not know if I have a
a definitive answer on that.
I would say no, I would
err on the side of caution.
I have always been scared
with
what you can do with that.
It got better in API 17,
with the annotation
that you have to explicitly
annotate the methods
that you can call from
JavaScript into Java.
But I have not used
that binding much.
And there is a question about...
about: Bootstrapping
baseband firmware
as a vulnerability, real or hoax?
I do not know the answer to that question.
Does anyone have any live questions,
before we sign off?
- [Voiceover] Can you
compare the Keystore
to password key, type of that?
Have you ever used one?
- Yes. One of the things
I did not have time to mention,
since Android 3.1,
there is
the Android Keystore,
similar
to iOS Keychain, in the fact that it is,
it is a place where you can store
a certificate. Unfortunately it is not
like the Keychain on iOS,
because you can just store
arbitrary secrets in it.
On Android, you have to store
a public-private key,
and then use that to encrypt other things.
That came in Android 4.3,
and there is
a couple of issues with it,
not being consistent
in the way it behaves;
if the user changes their PIN
on some versions of Android,
it just wipes the Keystore,
and at other times
it still says it is there,
but it actually has wiped
it.
One of my friends wrote an article
called &quot;The Forgetful Keystore&quot;.
He has done a metrics
on what versions and what
different things happen,
because he started using it.
In terms of which is more secure,
they are based on the same principle.
They are using
something that the user puts in,
that we do not store on the
device, to then encrypt,
to generate a key that we
use to do the encryption.
I woulds ay they are roughly the same,
I just prefer doing a
password-based encryption
that internally, with my app,
because I have control over that.
And also, forcing the user to put in
a passcode or a password in for my app,
when it is a secure app,
and there is a point to it,
is a easy sell, but
forcing that user to have
a device PIN, passcode,
when they do not have one,
that is the big issue.
That is a bigger sell,
if you are a bank,
I think forcing the user to
have a PIN code on their device
is, you could probably get away with it,
but other apps I think
you would really struggle with.
Maybe Enterprise apps,
you would probably get away with it as well,
but that is quite a big ask for the user.
Just to be clear, to
use the Android Keystore,
the user has to have a PIN
code or a passcode enabled,
and that is the key thing.
You have to force
that for the whole device
rather than just your app;
that is why I tend to prefer,
doing it in-app,
but it is just as good a solution as well.
Also, if you are using,
if you are in a lucky position
of being able to target API 17 and above,
which, I do not know if anyone else
is in that great
situation, I know I am not.
Really good question.
- Okay, one more question.
- [Voiceover] I just looked
at the conceal website,
part of this Facebook library,
and they claim that it is super fast.

Do you work with it, or do
what they do which
makes it so much faster,
or what's going --
- I have used it,
and it is pretty quick,
and it uses
a couple of the open SSL algorithms,
which are quick.
It is doing native code,
rather than what SQLCipher does
is bundle the whole open SSL library,
it just bundles those algorithms
and the stuff that you need,
that is why it is quicker.
It is not as big a
a payload, effectively.
Actually, worth mentioning,
I mentioned it in the talk,
but it is one of those Facebook libraries
that does not have the
weird license about...
I forget what it is.
It is commercially viable.
Cool.
Brilliant, thanks
for those great questions,
and cheers again for coming.
(applause)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>