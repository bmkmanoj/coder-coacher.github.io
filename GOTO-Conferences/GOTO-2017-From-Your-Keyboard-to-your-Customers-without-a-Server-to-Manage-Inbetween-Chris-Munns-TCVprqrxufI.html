<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • From Your Keyboard to your Customers without a Server to Manage In-between • Chris Munns | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • From Your Keyboard to your Customers without a Server to Manage In-between • Chris Munns - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • From Your Keyboard to your Customers without a Server to Manage In-between • Chris Munns</b></h2><h5 class="post__date">2017-11-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TCVprqrxufI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's great to be here again today this
has been a really awesome conference my
name is Chris Muntz
currently I am a senior developer
advocate for server list from Amazon Web
Services based in our New York City
office basically what I do is focus on
interfacing with folks like all of you
here in the room so my my main focus is
to work with AWS is developer customers
on understanding what service can mean
for them how they think about service I
think about service architectures now
it's interesting is that I myself or
whose iPhone is kind of trusting I
myself am NOT a developer I actually
come from much more of a traditional
infrastructure and operations background
I spent plenty of time and data centers
managing large Linux farms of servers
and doing things like configuration
management and all sorts of stuff like
that but a couple years ago kind of
right after AWS launched a product
called lambda which I'll be talking
about today I really have come to see
that this this concept of star bliss is
the future and so I am very privileged
and lucky enough to spend all my time
basically focused on this so why are we
here today in this talk so there's been
a number of talks so far this week
already on server lists on what it maybe
does mean and maybe doesn't mean it's
definitely a term in a buzz word that's
grown to mean a lot of things in the
industry one quick you know thing that I
always like to address is that yes we
understand that there are servers behind
the scenes of server lists but at the
end of the day one of the key aspects of
it is that you don't deal with them at
all and however though this is not the
point well we see service meeting is
actually I think kind of the next
evolution in how people are thinking
about building applications and
architectures and so we've kind of
transitioned from mainframes up to
server client up to the web and even
into things like micro services but what
service represents is really the whole
next life cycle of how I think
developers are going to think about
building applications so what does
serverless mean to us here at AWS really
comes down to kind of four guiding
principles that we use when we basically
will or will not label a product as a
service product so obviously the concept
of there being no servers to provision
or manage and this even means things
like containers so a product for us to
be server lists
you never think about the operating
system there's no patch management
there's no RDP or SSH there's nothing
like an operating system license that
you want to think about and
realistically you have no concept of
those underlying physical servers or
virtual servers or containers that might
be existing in that platform it should
scale with usage so as traffic or
requests or data points come in the the
service product or platform should
automatically scale to meet that what
that means is that you never have to
think about things like capacity
planning so you never have to pay for
idle realistically thinking about
capacity planning is kind of a business
decision on how much idle do we want to
pay for in hopes that at some point we
have a customer workload that will come
and consume some larger percentage of
that capacity over time the lastly
things like high availability and fault
tolerance are built in and so that's
very key today when developers are
thinking about how they structure their
architectures we're in physical worlds
or even the virtual machine world even
the container worlds these are things
that you still are typically spending a
considerable amount of time thinking
about and architecting for so kind of
for overall again guiding principles in
terms of what we feel service means and
I think it aligns pretty well with how
most of the industry is talking about it
today
now we're service kind of starter for us
here at AWS is around his products
symbols right kind of in the middle here
of lambda and so lambda is a compute
product that we have here at AWS today
many of you I think maybe are familiar
with it but if not I'm sort some time
talking a little bit further about it
and when we talk about lambda we talk
about it in the sense of being in the
middle of what we'd call a service
architecture and so with lambda you have
a concept of an event source some sort
of triggering mechanism that is going to
cause a lambda function to be invoked
and then that lambda function can do
basically whatever it is that you wanted
to do talk to other databases other
api's hughes caches data stores
what-have-you based on what it is that
your application needs to do and so a
service architecture again is pretty
much well we'll always have some sort of
event source will always have lambda at
some point during compute and then may
or may not have other services that you
might be talking to so you could
potentially have all of your business
logic exists just in lambda and when it
comes to kind of the architecture or the
use cases that we see for survival
it's actually a number of things so web
applications basically the ability to
power things like static websites or
things like single page apps that's very
common and something that we see growing
especially when we see people moving
more towards the single webpage
applications with things like react and
other JavaScript frameworks that behave
similarly backends so things like
micro-services which has been a big
topic this week here at the conference
see people building that using lambda
and server lists data processing so
real-time stream analytics ingest of
things like user clicks data points from
IOT related workloads all sorts of
things like log analysis and other kind
of things where you get massive
quantities of data and typically
organizations would do things like batch
process them and some sort of semi
regular interval well people want that
that information processed almost
immediately these days and so we could
potentially talk about how real real
time needs to be but in the case of
streaming workloads it usually means
very rapid ingest typically in the order
of seconds and this is actually kind of
today basically dollar-for-dollar one of
the biggest use cases that we see for
lambda and serverless today things like
chat BOTS so how you interface with your
customers or maybe internally inside
your organization also rapidly changing
I've seen things like internal
Enterprise chat BOTS that they use for
you know kind of disseminating
information that normally would have
existed maybe in a wiki or a SharePoint
somewhere but then we also see people
putting them publicly on our web sites
to act as kind of like sales type of
enablement bots or even customer support
bots and that continues to grow in in
use Alexa something that I talked about
yesterday actually we attempted to build
an Alexa skill on stage live or any of
you in that talk at all yesterday a
couple of you so it was kind of a race
against the clock and we got to see some
interesting aspects about Alexa and the
Alexa voice service and you know it's
understanding of my New York drawl as it
were so that was kind of interesting
session but Alexa are really growing in
terms of power and capability there's
something like over 17,000 Alexa skills
today and you can think of an Alexis
skill as kind of a micro voice
controlled applique
that lives inside of a device that's
powered by a LexA so you could say
things like Alexa turned my lights on or
turned my lights off or tell me the
weather or tell me my my current you
know bank account number or get me a
pizza there's all sorts of things that
you can do with Alexa and then lastly I
to automation which is actually where I
think a lot of people start with lambda
is using it inside of AWS to do things
like glue together various services and
components inside of your infrastructure
and I should say actually using this in
other places I actually have one
customer that uses lambda as part of a
framework for managing physical network
gear inside of their data center so they
built a management API in front of
Juniper devices actually and have been
successful in building this kind of
really cool interface in front of
physical hardware and physical data
centers so again number of really kind
of common use cases here today I'm gonna
focus a little bit more on the web
application aspect but happy to
potentially talk about the rest of these
outside of this so for those of you that
are new where do you start so this is
really a whole new world again in terms
of how you think about applications and
for a number of folks that I've talked
to it can be a little daunting to go
from the model of I have a server and
typically that contains everything about
my application or even a multi tier
architecture to this thing where servers
no longer exists and so kind of the
foundational construct that you've used
from a development paradigm is no longer
around so my first tip is actually to
start with a framework so there are a
number of frameworks that exist out
there and what these are gonna do is
kind of greatly simplify what is
involved in you building a service
application there's actually many more
than the ones that are up here these are
some of the most popular ones that I've
seen and I know the creator of clutter
JS spoke yesterday and really what kind
of differentiates some of these is the
languages that they're supporting or
capabilities like multi cloud
capabilities or other types of aspects
or nuances around like the languages
that they support so Claudia with just
an example here is a JavaScript
framework
hence the Jas in its name and with
Claudia they have a really really really
easy model for building API backends so
you can see here in what is roughly -
the fact that it
kind of squished on the slide roughly
about five lines of code with these five
lines of code and the command that's
right here at the bottom of the slide I
get a lambda function and an API gateway
and all the integrator together and
effectively I have an API back-end and
obviously hello world is not a lot of
complicated business logic but again
this is the scaffolding needed for a
very basic API that could grow to become
very powerful over time a chalice is
actually a framework that came out of us
here at AWS what's interesting is this
didn't come from any of the service
product teams it actually came from our
SDK team they had an itch to scratch
around building a framework to help them
out and they ended up building this
product chalice kind of on the side and
so it's an open-source product that you
can go and contribute to and read about
and so this is Python based similar kind
of thing to claudia about five lines and
I get an API right so this is compute
capability API gateway acting as the
front-end we can actually do quite a lot
of really really kind of advanced things
with this much like most the other
frameworks so let me just dive just a
little bit deeper briefly here into
chalice and why I won't expect you to
read everything that's on this slide
it's roughly about 30 ish or so lines of
code what is inside of this though is
actually for API endpoints in terms of
what we would call an application route
so the type of thing that ends at the
kind of the first part of a URI on the
URL for an API gateway and then as part
of that there's things like built-in
error handling and various HTTP methods
support
there's also integrated support for
different authentication authorization
capabilities and again I'm getting all
of this in about 30 lines of code so
when you're starting off when you're
starting out new in this space I
definitely recommend you take a look at
a framework and try to work off of that
now let's say that you had an existing
application and or maybe you have a
language of choice that there isn't a
framework that you like it so what we
have at AWS now is a tool of ours called
Sam
you'll also notice Sam which is our
little mascot for server lists over in
the expo hall we've got a lot of
stickers for Sam we're really trying to
put Sam into all sorts of things but
what Sam is is actually a template
driven model for defining serverless
applications to really kind of simplify
what it takes to build and deploy them
and it's completely unattended from the
language standpoint it basically is just
used as an infrastructure management
tool so an example of a SAM template
here what we've got is about roughly 20
or so lines of code and what this
actually represents is the very top we
have some headers that kind of tell the
service what this templates going to do
and then we have two resources the first
is a service function the second is
what's called a simple table a simple
table I'll cover real quick this is
actually gonna create for you a dynamodb
table and all you need is essentially
this one line of code and then a name
for it and a couple months ago we
launched auto-scaling for DynamoDB so we
do consider it now a server list no
sequel database product but up above
here this server list function type what
you see is kind of a number of things
that would be used to categorize lambda
function so where my code lives where
the handler for that code lives and I'll
talk about this here in a moment the
language that I'm using permissions that
I want to give my lambda function and
then down below here there's a concept
of an event and so I have an event that
is of type API and then you see some API
properties that are defined below and so
what will come from this is a lambda
function an API gateway a dynamodb table
and then all of the related kind of glue
components to combine all of these now
if you were to do this in the console
this would be quite a number of clicks
so you know try to think about avoiding
those and instead use again one of these
frameworks just to give kind of a
slightly better visualization this is
from an example that I'll show here in
just a little while what I have is from
roughly lines 9 through 25 all of kind
of the meat of this Sam template that I
have of what gets created from it is
roughly the six resources that you see
here so again really really easy to get
started from this when you're just
trying to figure out what the servlet
space looks like in a lot of power 2
frameworks as well as things like Sam
and then just a couple of about a month
and a half or so ago we actually
launched a tool for local testing of
service applications so you can actually
now do local kind of debugging tests of
both API workloads
and then things that would connect to a
lambda function via say like a streaming
invocation or some sort of other event
and so this again kind of simplifies the
developer lifecycle which is pretty key
when you're just starting out so let's
get hands-on with some of this let me
show you actually an example of a lambda
function and I'm actually going to show
you some Sam and Sam local as well so
the example that I'm going to pull from
them is actually something that you
could go and find yourself and play with
and if your AWS account still is covered
by the free tier you could play with
this with absolutely no cost if it isn't
the free tier you could basically run
this demo for pennies for probably some
number of weeks of time and it's
actually pretty straightforward what it
does is it has you launched a website
and I'll show you this here in motion
where our friend Sam kind of bounces
around the screen and it includes all of
this front-end code in s3 then you have
an api gateway and a lambda function
that glues it all together so this is my
example here of the sam farm so as we
see I have my wonderful friend Sam here
bouncing around there's some collision
detection so that they don't overlap and
essentially what we do is we have a
single lambda function and all the dis
lambda function really does is spit back
out to me a Sam count so a sam count is
the combination of it's just a little
bigger combination of variable called
var Sam count and then about two lines
down there is a multiplier which I can
either pull in from an environment
variable or have it statically set and
then basically it gives me the total
count of Sam's and so the API is super
super super basic so I have this running
here locally on my my laptop I've also
now gone and actually fired up just
right before we started here the Sam
local and actually let me show you real
quick here so this is the Sam templates
it's the whole thing this is the same
template for this demo so again roughly
from lines 9 through 26 it's kind of the
whole meat of what I'm going to do so
this is a node.js 4.3 runtime index that
handle
my handler the code URI which has a dot
in a slash I'll talk about here a little
bit later and we see some environment
variables and then we see the event
mapping down below so when I actually
have this template here and I'm running
against Sam local what I have done is
just basically gone and executed it so
Sam local start API and reference the
Sam template and then what that does is
take my code bundle it into a docker
container running locally on my laptop
such that I can go to the interface that
it gives me here on localhost and be
able to call my API now I just have a
single API endpoint but if I had
multiples it would show me kind of the
full mapping for all of them
so the basic here
okay great so this is the the number
returned by my API right now and this is
a factor of that currently in here I
have the number 10 and a multiplier of 1
then I can actually go back to the same
local window here and what I get is the
same output that I would get from this
lambda function if it was running in the
lambda service so if you're familiar
with lambda at all you'll see here the
same kind of output and error lines or
not Airlines in this case but the output
lines from this function are put out
right here down below I have the
duration that it took that builds
duration and the amount of memory used
so a pretty cool really easy kind of
straightforward thing for me to do local
testing with and there's a lot more
capabilities of this so one one quick
thing that I'll show so let's say that I
goof up here and I turn Sam cow into cat
now cat is not a valid number as most of
you are probably well aware so if I go
and refresh this and I get an error
message more importantly than that I
could see from my local test tool that
it told me that guess what cat is not
defined and so that is a problem and
tells you where that line is that's
broken and so it makes it really easy
for me to go back in and fix that so
again in terms of starting out you
definitely want to think about a
framework if you really are averse to
your framework definitely use a tool
like Sam and Sam local because it's
gonna make your development lifecycle
just that much more rapid so let's get
up just a little bit deeper into lambda
for those of you who aren't that
familiar with it and kind of talk a
little bit more about what happens
behind the scenes at lambda and what you
can do to kind of play with and
configure lambda so with lambda I
mentioned that basically a service
architecture has some sort of invocation
model or method then you have your
function and whatever that function does
today there's basically three different
types of invocation models that exist
for lambda so we have synchronous
effectively a push
we have a synchronous which more of kind
of an event and then we have stream
based and so the use cases across them
really kind of vary across what
integration product you method for
integration you want to put it so we see
here an example of an API gateway where
I'm gonna make an API call and I'm gonna
expect that my API call is immediately
returned
and so that's kind of a very traditional
kind of synchronous push model for using
something like the API endpoint and
something like lambda there are also
things like the asynchronous
event-driven so this is stuff like I
have let's say you have customer data
that comes to you whether it be an image
file an audio or video file or maybe
even things like a document and you want
to go through and do text processing on
that if you want to generate metadata
from that maybe you want to take an
image and resize it or convert it into a
different format and so this is a model
where you're typically not looking for a
response right away but you want to do
something out-of-band and so that's
where the asynchronous event-driven
models fit in really well and again
that's something that's kind of the the
bread and butter of what people use
lambda for these days really kind of
straightforward use case but really
powerful and easily scales the lastly
stream based this is where you would
basically connect it up with something
like DynamoDB or Kinesis today where as
requests come in so in the case of
dynamodb people are writing updating or
deleting records in your database it
will actually stream those changes back
and cause a lambda invocation or if
you're ingesting data with something
like Kinesis which if you're not
familiar with it it's it's kind of a
mass-scale
ingest service so very similar to a
Kafka a number of other things but
basically you can just kind of toss
records into Kinesis and eventually it
could be processed by a lambda function
and again this is really useful for
things like IOT workloads and extreme
analysis and log analysis and things
like that so three different kind of
main execution or invocation models that
we have and then what exists today is a
little over 20 or so services that are
integrated today from the ada vs side of
things so just kind of a brief example
of what is possible if those things like
data stores things like development
management tools this is effectively the
infrastructure glue use case that I was
talking about before
things like endpoints so API gateway AWS
is IOT platform step functions which
we'll talk about here briefly things
like Alexa again so Alexa can directly
invoke a lambda function as part of you
conversing with it and then lastly we
have things like message services
whether it actually be things like SES
or SNS or also the ability to Cronje
as someone who spent a lot of time
managing servers managing cron jobs is
always such a pain in the ass and so you
can have a completely kind of managed
abstracted away for you system for doing
cron jobs and it's actually really
really pretty cool so just talking a
little bit deeper about two of the
products that are like really tightly
aligned with lambda so API gateway is an
API gateway we weren't the first people
to come up with this product as the
concept but what Amazon's API gateway
does is give you things like caching
both in the gateway and at the edge the
ability to get logs and metrics from it
you can actually put API gateway in
front of another lambda but pretty much
any sort of HTTP or HTTPS endpoint that
you have so we have customers that will
put a peg gateway in front of things
like on-prem resources or obviously
things like ec2 and API gateway comes
with a lot of kind of really cool
capabilities to for you
so obviously it's gonna give the ability
to build an API front-end but it also
has built into it things like DDoS
protection throttling authentication and
authorization mechanisms the ability to
do things like metering or to do usage
tiers which are all really awesome
things if you're ever building a
consumed API by say external developers
it's also the kind of thing that there's
really no reason for you to write your
own today so there exists kind of many
different API gateway products on the
market I would say if you're building
something that is an API you should
always have some sort of API gateway
that you're using and so with Amazon API
gateway we considered a service product
there's no service to manage there's no
scale to think about and again it can
alleviate things like authentication and
authorization concerns which developers
spend typically a lot of time on the
next another kind of product in the
suite is AWS step functions so one
common thing when you have lambda
functions is you know they're these
small little kind of bite-sized amounts
of compute well rarely do we ever just
need just a small little bite-sized
amount of compute and so we often have
to do things like chain them together or
have them invoked in reaction to each
other then you want to handle things
like retries and failures and there's
all sorts of logic that you want to put
around there now you can put that logic
directly into your code but you end up
running into issues with
like the fact that a lambda function can
only run for up to five minutes today so
if you have a lambda function calling
another lambda function calling another
lambda function if that first one times
out you lose basically the chain of
everything below it and so step
functions allows you to basically
abstract all of that workflow knowledge
into the service itself and can do
things like as you see above here are
decision trees ability to capture
failure is ability to do parallel tasks
to do certain sequential tasks path
based on that you could actually also
handle things like custom error logic
and so if you have kind of a multi-step
workflow inside of an application this
also kind of again will alleviate the
ability or the need for you to have to
write the logic that exists between
there so definitely take a look at step
functions again if you have those types
of workloads let's get a little bit back
to lambda so with lambda we've really I
think made it as almost as simple as
possible as it can be from a compute
product to think about how you you scale
it realistically there's kind of a
single knob that you could turn with
lambda and it's the amount of memory
that you want your function to be able
to potentially ever consume what comes
with that is a proportional amount of
CPU and networking resources so you're
never gonna say I want to lambda
function that has a 2.3 gigahertz you
know Xeon processor it's not the kind of
thing that you're gonna care about when
you're gonna say is I want to lambda
function that has access to 512
megabytes of ram and then we're again
going to align proportionately some
percentage of a CPU core to that and so
if you do have a workload that is more
compute intensive you're gonna crank up
the memory because typically we find
that those are very well aligned and so
this is again kind of the only knob that
you get but there is one caveat about
this it's not always better for you to
crank that knob all the way up and so we
have here as an example of calculating a
thousand times all of the prime numbers
less than a million and what you can see
here on the chart is so today lamda
supports up to a gig and a half of
memory this actually just compares from
a hundred 28 Meg's to just one gig if
you look at the timing obviously the
more amount of memory that we have the
faster that our function gets processed
but from a cost perspective it's not
necessarily the most cost efficient is
always the fastest and so you can see
here that
roughly if we were to compare cost the
first or 128 Meg's cost just about
almost the same as a gig but if we were
really looking for maybe an optimal time
versus cost model the 512 megabytes
might have actually been a better fit
and so you want to think about kind of
in your workload do I care about speed
or do I care about cost
so in things like API calls you probably
care a little bit more about speed but
in things like batch processing of doing
things like stream analysis or event
sourcing you might actually care a
little bit more about cost and so this
knob gives you quite a lot of power but
there is a little bit of thinking that
you want to do as part of that another
thing that you want to think about is
lambda runtimes so today we support four
different languages inside of lambda no
J ass Python Java and c-sharp and
there's a couple different aspects to
why you would pick one of those or when
and where but things that you want also
think about is always kind of separating
the business logic from the the function
signature as we'll call it things like
dependencies you want to be really smart
about what dependencies that you include
and then in terms of the overall
runtimes they interpreted languages so
nodejs and Python are significantly
faster to start than Java and c-sharp
but that's just during the start time we
still find that often for a number of
customers that the compiled languages
might be much faster at things like
mathematical calculations or even things
like transformation of an image for
example there are some tools in Java
that make that a lot faster than in
Python or a nodejs
so when it comes to thinking about how
you separate so we've got to go through
these three areas here so separating
your business logic from effectively the
signature so what we see here is that
I've got kind of a map a mocked up
function here called app to do and then
what I have is my handler so the handler
is what lambda is going to look to
invoke when you have a request that
comes in this is basically the entry
point into your your codes execution and
we'll talk a little bit here in a moment
about something called effectively
container reuse but when a container
reuse happens it's going to execute what
logic exists inside of this lambda
handle
you actually want to keep your lamda
handler kind of as clean as possible and
think about taking any sort of extra
application functionality and either
moving it elsewhere in this file or
potentially think about module izing
that out and to say like a package that
you include and we'll talk a little bit
about best practices for that as well in
a bit so when it comes to container use
something that a kind of explain real
quick so know lambda does not run on top
of docker does it run on anything that
looks exactly like docker we use
container in kind of the lowest sense to
refer to effectively something that
lives inside of the kernel space of the
host that is running lambda for you so
we'll talk here about the lifecycle but
basically what happens is when you have
a lambda invocation we fire up what's
considered a container on a host that we
manage we pull your code into it we
execute your code and then your code
finishes executing now you only pay for
the duration of your code execution
based on the hundreds of milliseconds of
time but what we will do for performance
reasons is keep that host around and so
from that point you have what's called a
warm start and I'll visualize this here
in a second so there are things that you
could do inside of your function to
actually speed up the the warm started
execution such as moving certain logic
or defining things like certain
variables into the global scope this can
actually speed up your function quite a
bit depending on what it is that you do
let's say for example that you needed to
reach out to a key value store to pull
in a certificate that's the kind of
thing you would want to do outside of
the handler in the kind of early lines
of your code before your handlers
executed so that you don't have to do
that every time because typically that
type of thing is not going to change
that often so let's look at kind of a
better way to visualize this so when a
lambda function is executed again what
we do is we have to download your code
start a new container for it which strap
the runtime so this goes basically go
through anything like and include or
require inside of your code and then
start your code and execute it and so
when we talk about where this kind of
lies in terms of what you think about
optimizing versus what we think about
optimizing so a full cold start is where
we don't have a host that has your code
on it or for some reason we do disk
we have to create a new host and pull
your code onto it and then on your side
a partial cold start is we have a host
it has your code but it doesn't have a
container that has your code in it and
then warm start is we have a host it has
a container that has your code and an
invocation has come in and so we're
going to execute it right then and so
again what you really want to be
thinking about is from the bootstrap of
your runtime and this is where things
like interpreter languages verse non
interpreted languages becomes important
as well as what is that exists inside of
your handler that is going to be key to
the performance of your function now
this is a bit different than if you're
thinking about in a traditional
application environment where you have
kind of a you know all of your like a
warm application server this is a bit
different of a model because effectively
we're invoking that every time behind
the scenes for you and so what ends up
happening behind is if you run inside of
a V PC this is another thing that
customers have found well you actually
also have to deal with is the fact that
we have to put a elastic network
interface on your function in your V PC
so one thing that we'll always recommend
is don't use V PC unless you have to so
unless you have to talk to a resource
inside of your V PC because it does add
to be both well it does that to the cold
start time for your function so
important to think about this from the
perspective of how you think about what
you include inside of your event handler
how you think about what you include in
your code this is also why it's really
important to not include extra modules
in your code this could be something
that's very common today in both Python
and nodejs is hey we're gonna clean all
these modules that do all this cool
stuff but maybe you only need a small
bit of functionality you're actually
better kind of going with building that
functionality yourself or stripping it
out of that third party package so on
demo some of the ways that this is kind
of key
so if I go over to the laminate console
here let's see if it's gonna still be
warmed for me okay so this is actually
the lambda function that was behind the
API gateway endpoint that this interface
here is built upon and what I have here
is the ability to test this lambda
function so let's see how fast of it
okay so in this case it was executed in
14 milliseconds let me find one that is
going to be cold that I can really
easily so I'm just gonna create a very
basic tests open those function source
so this is a function actually written
in turnover that's why what I'm hoping
to highlight here is a cold function
that I can use to show examples to quick
anyway well you'll typically see when
you're building and testing a function
if it is a cold function that has not
been executed the initial time that you
go and execute or the first time you go
and execute that function the duration
is going to be much longer because we
have to go through that full cold start
of getting a container pulling down your
code executing your code or returning
the result however what you'll see is if
you do these tests and semi rapid
succession you'll find that duration
stays effectively very very small and so
this is why sometimes people think that
the first time that they run lambda that
it is slow you know what you're seeing
there is that first initial penalty of
the cold start that causes you to think
that that's what's happening but
realistically what we find for almost
all of our customers that are running in
production cold starts are not something
that they have to really worry about
typically most applications are gonna be
accessed somewhat frequently so you know
periodically every couple of minutes and
so things like cold starts really kind
of trail out to the very far end of say
like your TP 99 in terms of performance
pain points my apologies for not having
my example working to show you this of
course right before I came in I was
doing the Sam function one and but it's
because I hadn't tested it from the web
interface so now it's unfortunately a
warm function so it's not a good example
of what happens when a function is
called yeah it's gonna return really
quickly moving on
so again cold starts that can look bad
in development but you have to
understand that an application under
load is not going to see that same kind
of performance problem we actually have
wonderful stats and charge and data
points that show this for our customers
and we've had you know customers under
load show it as well more memory is not
always more expensive but it's not
always the best thing to do so you do
want to kind of tweak your function and
tune it for how much time it's going to
run for based on how much memory and CPU
you might need and remember we give you
just a single knob that's aligned with
memory but you do get more CPU with that
and so that's kind of one other kind of
key thing when people talk about
performance and lastly you necessarily
don't want to think too much about over
optimizing your code so I've had
customers come to me and say hey we're
doing this in Python should we be doing
it in Java or vice-versa you do want to
really think about benchmarking your
functions to understand how much time
you're spending during that kind of cold
start or initial bootstrap verse when it
is warm
so again if you're testing this and
something like the console it's gonna
look much slower with something like
Java then python but that doesn't mean
that under load your application is
going to perform equally compared to you
doing kind of one-off click tests in the
console let's move on to talk about a
couple of other things here so talk
about how you really can't move fast if
you're not measuring what's going on so
lambda has built into it number of
capabilities so has built into it cloud
watch metrics so the ability for you to
understand things like invocation count
location duration invocation errors if
you're being throttled by the backend
so today the concurrency limit that we
set is a thousand concurrent requests
note this does not mean a thousand
concurrent requests per second it means
concurrent within basically a time frame
smaller than that so because we build
functions in the hundreds of
milliseconds basically you're looking at
a concurrency of just completely at
execution time this could be something
that can throw people off because it
means that you can actually invoke more
than a thousand functions in a second
but you couldn't invoke more than a
thousand functions and say more than a
millisecond for API gateway same kind of
thing so we capture a whole lot of data
for you def
they want to pay attention to those
things and look at those graphs and
understand how to use them for
troubleshooting and understanding what's
going on is performance wise we also in
terms of logging capture a whole lot of
logging for you so with cloud watch logs
which is another AWS product with API
gateway and with lambda we capture a
number of things by default with lambda
you can basically put information into
your log just by outputting it so just
kind of doing a standard kind of council
dot log or whatever the equivalent might
be in language that you're using that's
all gonna get captured and made
available to you inside a cloud watch
cloud watch has abilities for things
what are called log pivots so this is
actually the ability for you to generate
metrics based on logs so this is one
quick way actually to create data points
from your function and then use that to
generate kind of like a visual graph and
then really so people will I think
somewhat rightfully complain about the
cloud watch logs interface it's not the
be-all end-all of log processing
interfaces but really what we courage
you to do is think about taking that
data exporting it out to a tool that you
like so there's tools like Splunk and
log lee and the elk stack and a number
of other things that are really deeply
powerful log viewing tools you're gonna
want to pull that data into one of those
most likely something that we had
integrated with lambda a little earlier
this year is a product called x-ray so
x-ray is not an application performance
tool so it is not meant to replace a
data dog or a new relic or an app
dynamics in fact those products are
actually mostly building integration
with x-ray what x-ray provides for you
is profiling and ability to troubleshoot
your functions and so it captures what
are called traces which then get built
into a service map and can kind of give
you a view of when you have a function
that has been called by an API that
talks to many other services effectively
what the latencies are that were
involved on that what the successes are
potentially failures or issues and it
makes it really easy for you to debug
kind of distributed systems which is a
challenge otherwise so here's kind of an
example of using x-ray there's really
kind of just two lines that I've had to
change in this code the first one is to
include the SDK
and then the next is to basically create
my AWS SDK client with the X ray capture
AWS put in front of it that's basically
all that I have to do to tool my code to
be able to gather information from X ray
I can actually do much more I can
actually get like into functions and
create my own capture but this is going
to give you kind of the basic
functionality so this is code wrapped
around calling something in s3 so I have
a bucket I have a key
and I have a body that I'm gonna put
into this s3 object what I get from this
is a service graph so I see that X ray
there I see that lambda has an
invocation that's the first thing that
you see AWS lambda then the lambda
function itself executing and then it
putting its data into s3 now this is a
really really really simplistic example
typically you'd have a lambda function
that maybe is talking to s3 and a
database and some sort of other service
and it's going to map out that full map
for you the other thing that it does is
give you kind of a waterfall view into
your code or into your application flow
so we actually see all the on the far
end here response codes if it was an
HTTP call we see the duration and then
you can kind of see a visualization the
duration so this is another thing that's
really kind of key and understanding the
performance of a service application
cool so that's kind of metrics logging
and profiling so next going to just talk
about build and test of your application
this case actually build and deploy your
application
a couple products here I'll talk about
really quickly that can help you with
this so code build is a managed CI
service this is useful for compiling
code for including code dependencies for
testing your code at the code level so
doing things like unit tests linting
syntax checkers that's pretty much
exactly what code build exists for and
so this is a managed service for you so
that you don't have to run say a Jenkins
or a team city or something like that
yourself
so it has a command file basically that
you put in your code base called a build
spec file and our build spec damo file
in this case and so
we see here is just kind of like basic
sections to it the first our environment
variables then we have phases which
there are four of today and so you can
see that this would be for a note J s
lambda function so I'm doing an NPM
install I'm gonna run
yes lint to make sure that my code is
clean could be doing NPM tests for unit
tests and then I'm gonna actually packet
it up so the AWS CloudFormation package
command is part of what Sam needs in
order to build and deploy your
application and then I can tell it
exactly what I want to put into that
application that I care about typically
you're gonna plug is something like code
builds into some sort of pipelining
system so some sort of a continuous
delivery system and so we have a product
called code pipeline that does exactly
that this allows you to kind of model
out from code to build to test to deploy
across many different stages potentially
so typically a developer's pipeline will
look something well this is just kind of
a snippet of part of one but you commit
your code your code repository then
that's going to be packaged and tested
and code builds and then you're gonna
use something like CloudFormation to
deploy it so if you're using Sam you use
CloudFormation or if you were using one
of the other framework tools you could
basically actually have a lambda
function that calls one of those so it's
kind of fun you can use use lambda to
deploy your lambda so the most minimis
kind of developers pipeline that you
would see looks something like this so I
have my application source then I have
my build stage and then I have a stage
down below here which uses
CloudFormation to basically deploy my
function and then I could do some
testing against it so depending on what
it is that I'm using I could be using
something like Sam local actually to
invoke request to a lambda function I
could use the lambda API to test
something or I could use a third-party
tool to say test an API and creating
this is actually really really easy with
something called code star so code star
is kind of a an interface that sits on
top of a lot of these products has the
ability for you to create what we call
projects that are based around various
different technologies and so this is
probably the easiest way to go and
create what you see here in this slide
and
of this deployment pipeline so if you're
starting out with serverless and you're
starting out with lamda this is
definitely a good place to start with
looking at all of that so we kind of
wrap up here with some best practices
running a little long on time my
apologies so common things that I see I
see people creating what I call lambda
monoliths this is the idea that you're
going to put all of your functionality
for say an API or for some sort of a
service inside of a single function this
is not a good thing to do typically so
again I had mentioned the the more code
that lives inside of your deployable
artifact kind of effectively the slower
the lambda is going to be for a cold
start also potentially complicates a
warm start but it also doesn't help you
in thinking about how you should build
lambda functions and so realistic who
you want to think about is lambda is
kind of what I'd like to call nano
services so even smaller than a micro
service so you can think of kind of
every HTTP endpoint and in call that we
would make as its own lambda function so
every HTTP method correlating to its own
lambda function and again this is where
tools like Sam and the various different
frameworks that exist make this really
easy to do but it's something that
people are very much not familiar with
thinking about like really decomposing
their application as small as possible
so unless your code basically your
function handlers share an invocation
source you want to split them up into
their own independent lambda functions
or binaries if you're using say Java or
C sharp and again it's kind of a best
practice that you really want to follow
another thing that you might want to
think about is bundling your code into
your own packaging so people will say
okay well I'm gonna decompose my my
lambda monolith into individual lambdas
but I have a lot of code duplication any
place that you see code duplication
think about using kind of a language
based module in NPM a pip package maven
package etc unless your lambda functions
I share the same type of event type so
if you have lambda functions that some
are being invoked by an API gateway some
being invoked by say oh can you stream
those should be completely separate
projects completely separate Sam
lathes completely separate code bases so
again if you're sharing a handler you
still want to think about splitting them
into files in the same repository if
you're using completely different
handlers than completely different
repositories that are completely
different applications again lean on
code reuse via packaging modules and
then from a testing perspective for Sam
templates at least always validate them
locally before you upload them so when
you upload a Sam template to
CloudFormation
it does take time for it to process in
and it's actually a very it's perceived
as slow but it's doing a lot behind the
scenes to update your resources in a
very controlled methodology and so
sometimes if you you know fat-finger
something inside of a template file you
can find that it takes a couple of
minutes before you get the results on
that and then lastly inside your CIN CD
process always validate them as part of
that so again going back to the build
spec that I had I would be inspecting my
files inside of their lambda and API
gateway just talked about here in a
second supports something called
environment variables pretty
straightforward the ability for you have
essentially a key value pair that allows
you to add effectively dynamic Ness to
your function execution and to what
you're trying to do so like it's like
two minutes three minutes right okay so
this is really useful for again adding
dynamic nough stew your environment so
we can see here an example of a Sam
template where I'm capturing two
parameters from the user so I have
something called special feature one
another one called my environment
passing them into the references for my
actual code and then your lambda
function can consume this so maybe you
have some capability that you only want
to test in staging or dev verse things
that you have in prod or you want to
pass in keys in one place and not
another this kind of gives you that
capability built in another option that
you have is something called parameter
store so a parameter store is kind of a
centralized place for keeping data like
key value pairs so API keys database
credentials configuration environment
variables well you can see here is
actually a snippet of lambda code where
I'm calling out to
with the parameter store service I'm
pulling these in and then executing upon
them and so it's great about this is
there's concepts of hierarchies there's
I am permissioning that goes around it
so let's say that you have more of kind
of a controlled enterprise environment
you can give developers access to the
certain parameter store stored data for
developers and then you can control for
production but you can have the codebase
consuming them exactly the same so one
code base that can run in any
environment without any sort of change
and so this kind of aligns back to again
some of the best practices of you know
always use parameters and as much as you
can environment variables especially you
can create a single Sam template that
can be used in multiple places this
actually extends up the other managed
frameworks as well you want to think
about reuse of those as much as possible
so that dev always looks like staging
staging always looks like prod and
therefore you have kind of the different
environments that you want to have just
a little bit so all my slides will be
posted and so we'll be able to catch up
so just kind of wrapping up here so now
I'm at a time I so sounds easy right
there's a lot of different aspects here
a lot of different things that we talked
about again you know there's the the
service space is really exciting I find
that it's really changed the way that
companies think about building their
applications we kind of walk through a
number of different aspects today of
where you start where you kind of grow
through in terms of monitoring and
logging how you think about building
that kind of a more of a professional
development workflow with building and
testing tools I again start with
frameworks
and kind of look at some of the things
like code start to help heed your easier
path through this service application
once again basically things built around
lambda so we really see things like
functions as a service as the future of
application development especially in an
event-driven model there's lots of
different things that you could think of
that make an application event-driven
closing down pretty much everything I
talked about today can be found on this
website so AWS at amazon.com slash
server lists all of the tools that I
talked about including the third-party
frameworks can be found on a page linked
off of this
at AWS amazon.com / serverless /
developer tools again with that my name
is Chris Mundy Vela / advocate for
server lists at AWS you could find me at
Christmas on Twitter month on amazon.com
always happy to answer questions about
whatever I can and in terms of today
I'll take questions outside so the next
speaker can set up but really appreciate
you coming to this session hopefully you
learned a little bit more about lambda
and server lists and thanks again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>