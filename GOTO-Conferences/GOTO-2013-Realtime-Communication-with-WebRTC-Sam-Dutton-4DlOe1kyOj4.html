<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2013 • Realtime Communication with WebRTC • Sam Dutton | Coder Coacher - Coaching Coders</title><meta content="GOTO 2013 • Realtime Communication with WebRTC • Sam Dutton - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2013 • Realtime Communication with WebRTC • Sam Dutton</b></h2><h5 class="post__date">2015-10-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4DlOe1kyOj4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I think I get started it's kind of
gone 10 - yes my first time it go -
first time in Denmark it's lovely to be
here the sun is shining
anyway I work for Google I'm a developer
advocate my name is Sam Dutton on
Twitter I'm actually SW 12 Sam DUP and
on Twitter is someone completely
different so I'm going arose onna I
believe apparently he just got bitten by
a wasp anyway seriously if you want to
follow along with these slides there at
go WebRTC app spot calm if you really
obsess there's a github repo you know
patches and issues all that really
welcome I'm of course going to talk
about WebRTC I'm going to talk about how
you can build a web RTC app but I'd like
to begin by kind of giving a bit of a
bit of context to the project so you
know WebRTC is is a collaboration as
Robert said to bring real-time
communication to the browser as a
colleague of mine Serge Lesha pearl said
you know human communication should be
as natural in a web app as entering text
in a text box it's kind of you know one
of the last it may be one of the last
missing pieces in the browser so the
core values of the project have been
that it must be all the components must
be open-source and that it must be free
for developers to implement WebRTC apps
and free for users and of course at the
heart of this is video and audio
communication but also the ability to
communicate arbitrary data between end
users of WebRTC apps and that this must
be able to access that you know the
highest quality audio video streaming
but to do this in a way that it was low
cost for people to implement these apps
and as it turned out you know the kind
of core of this has been that WebRTC
would work peer-to-peer traditional real
time communications apps and this very
very over simplified diagram
of corporate difficult to implement but
also you know going via kind of
secondary systems the kind of vision of
WebRTC is this diagram with a white
fluffy cloud in the middle but you know
the point here is to enable peer-to-peer
communication as we'll see things are
never that simple but that's the core of
this to enable you know data and audio
and video streaming between peers
directly so to accomplish this the
WebRTC project had to do a number of
things they had to kind of define
protocols and define the protocols that
would be used by the project in the ITF
and then to build specs standards with
the w3c so we have the WebRTC draft and
media capture and streams and so on and
then to do this stuff in kind of a
really difficult bit is to build these
things into the browser so we needed
really good media and communications
stack just a word about jingle because
this is kind of at the core of a lot of
the WebRTC work jingle is an extension
to XMPP to enable audio like voice and
video with chat and Lib jingle is a C++
library developed by Google to implement
that and kind of network transport parts
of that are at the core of WebRTC and
you'll hear a lot of stuff about live
jingle if you kind of delve it a bit
into it WebRTC we've seen in parallel
the development of high quality open
source codecs vp8 and AAPIs and so on
and the aim of course is for this to be
building you know a new kind of
communications ecosystem a new way of
communicating so where are we where are
we now we have WebRTC API is implemented
on chrome and Chrome for Android Firefox
and now Firefox for Android which is
great opera have said that they will be
implementing on desktop and for mobile
opera of course has moved
to blink and we've now got native
bindings for WebRTC in Java and most
recently for iOS in Objective C um one
thing by the way that just appealed to
me as a one-time cute QT developer with
just QT the project has just announced
that they will be using chromium and
what this means is that apps built with
the cute framework you know embedded
devices lots of cross-platform potential
will have all this stuff as they said
working out of the box to me that's
really exciting so we have at the moment
something like well over a billion
WebRTC endpoints a lot more predicted
for the near future over the next couple
of years so you know will this be the
end of telephony as we know it time will
tell but I think that you know just
looking at the kind of applications
we've seen recently there's some really
interesting stuff already coming through
we just had the first TV interview done
via WebRTC this was in London a few
weeks ago done by Sky in the old days to
do that you know you need it all this
kit all these people you needed like
these OB trucks and the staff to go with
them and they did this with a camera
like exactly like the one I've got here
and one of these Yeti mics which is I
don't know hundred euros so that's to me
is it you know fantastic potential there
so that's a little bit about the kind of
the vision of WebRTC but just you know
thinking about what we need to to build
real-time communication so at the core I
guess the real-time communication is the
ability to access voice and video and to
communicate that you know thinking about
telephony and video chat and so on and
this is a kind of core use case for
WebRTC and for this we need we need to
accomplish three kinds of things so
firstly we need to be able to get
the audio and video we need a way to get
you know stuff from your mic and your
camera and secondly we need to be able
to communicate that data and that turns
out to be of course wouldn't you know it
very complex and the third part is this
ability to communicate arbitrary data
other types of data as well as audio and
video so for this we have three main
JavaScript API s we have media stream
better-known I think to most people from
get user media a way of getting access
to local audio and video from your mic
and camera and we have rtcpeerconnection
which is the API for establishing
connections and communicating between
peers I receive data selling is kind of
part of that but this is the API for
communicating arbitrary data I'll talk
about this stuff later so media stream
is this kind of is the word abstraction
of streaming media we can get a media
stream using the Navigator getusermedia
methods ministry represents like a
single synchronized source of streaming
data and each media stream can have
multiple media stream tracks each of
those representing audio or video and we
get one like I say using getusermedia
and you can see in the example here in
the diagram we've actually got that
broken down one step further where an
audio media stream track has a left
channel and a right channel and you can
imagine variants on that theme navigated
getusermedia takes three arguments the
first of these is kind of interesting
but in this example it's very simple you
can see the constraints object at the
top there all I'm saying here is get me
video I don't care where it comes from
just the default device that's all all I
want is video no audio nothing else and
then you can see in the success callback
that that's passed a stream media stream
and then in this example a simple
example we're setting that as
the as the source of a video element
let's see that in action now
so you notice when I've opened this page
that's running getusermedia if you
haven't seen this before I'm allowing
access to my camera and hopefully
getting some there we go some video
coming through there if we just look at
the code when we bump that up a bit so
you can see it if we look at the stream
object here you can see I've got various
properties there and we could do things
like stop the stream which should freeze
the the getting of the video if we delve
into the stream a bit if we get video
tracks but you'll see that we can see
one for each of the sources which in
this case is just the the built-in
camera which has an ID and a kind and a
label and so on just a word about
permissions if you run a WebRTC app like
using getusermedia from HTTP you will
only be asked the first time for access
to the camera microphone and so on this
is really handy you know so people don't
get repeatedly every time they use your
app asked again and again and again you
can also do this in Chrome apps with the
audio capture video capture permissions
something that was potentially really
useful for testing is that you can run
Chrome with a flag so that no permission
is ever asked obviously this is useful
for I don't know unit testing situations
where it's going to be difficult to try
and have permission accepted so it still
enables you to to run getusermedia
without having to ok that each time and
the UI gives the ability to change
settings afterwards a word of warning
I'd keep doing this
you can't run getusermedia from your
local file system this comes back to
bite me all the time at the moment you
get this really baffling little
permission denied message if you run
getusermedia locally there are plans to
give much better warning messages but
just a warning about those warnings
because it's what's that um that's a
good question they you know it's a lot
of api's need to be run from a server
not run from the local file system I
don't really know I don't really see the
benefits for that but I mean Mike you
might have more yeah well Mike will talk
to you afterwards that um yeah it's a
good question I think you know the great
thing work with WebRTC that it's not a
plug-in is that we have access to all
these you know the kind of wealth of
HTML and CSS and JavaScript in this
example we've got getusermedia getting
video and then the images from that of
being plumbed into a canvas element then
each pixel of that is being analyzed and
from that we're getting ASCII art like
as in real text which is kind of nice
face cats
I know people may have sorry if you've
may have seen all these but they still
love them this uses the head tracker
face tracking the JavaScript library
will it work oh yeah there we go we'd
get user media so if I move around I'm
controlling the game with position of my
head sort of anyway you get the general
idea
Eric bidelman is lovely old CSS filters
photobooth really simple here you're
getting images coming through from
getusermedia and then you can just add
CSS filters really straightforward to do
some kind of crazy things and and then
you can I don't know why they're broken
here but you can then get those images
and save them just just simple stuff
with CSS filters webcam toy does kind of
the same thing but with WebGL and
if we have a look at that now you'll see
what I mean that it's kind of the same
process and yeah weird sort of delic
okay that'll do oh my god that's just
hideous
anyway if I were this really nutso I
could share that with my friends
just a word about constraints again you
you if you remember the simple example I
gave just said give me video default
video whatever that's it I didn't want
audio because it would feedback you know
now you can do some more interesting
things with constraints in particular
you can specify them to be mandatory for
getusermedia
if the mandatory then getusermedia will
have a tantrum if if that constraint
isn't met and will refuse to cooperate
and you won't get anywhere if they're
optional then getusermedia will try to
fulfill that constraint but will fall
back to acting as if you'd never asked
for that in the first place if if that's
not possible so for this we've got
things like resolution facing mode you
know choice of cameras and so on let's
have a look at that example of that in
action in this case let's look at the
code on github that's probably the best
place so if we look at the JavaScript
for this try and bump this up you'll see
that we have three different constraints
that's pretty big we have three
different constraint values each
specifying a different size for the
image when we press the button depending
on which button we press we get a
different constraint and you can see you
can actually read that that's the actual
video size you're seeing there got from
you know video height video width and we
can get in this example QVGA vga
chug-chug-chug or even more pixels like
that so yeah we can specify what we want
from the camera in that case like I like
on the plate it said on the previous
slides scaling and cropping hasn't been
implemented so you it is from a fixed
set of values
another example a little bit more
complex here is the ability to use
constraints to select the camera again
I'll just show you briefly the the code
for this on github if we look at the
JavaScript you can see that when we open
this page if you can see there with
using the media stream track method get'
sources this is getting a list of
devices that that are connected to to
this machine that we could use as a
source of for media and in the callback
for that we're setting those values in
in a select so we can select the
microphone and the video camera and when
we go to call the to call getusermedia
we're given constraints which are based
on the current value of the of the
select so the ID of the microphone or
the ID of the camera so if we look at
this now you'll see that I only have one
video source available there if I plug
in this handy camera and refresh the
page let's look let's see you can see
I've now got a choice of two two cameras
and I can get back to the other one okay
let me go back to the camera now this
really comes in handy for mobiles so I
will attempt to use this camera as a
cheap and cheerful sort of wolfvision
device and show you this working on on
my phone so I'm using Chrome Beta here
by the way if you want to download
Chrome Beta you can't get it directly
from the Play Store you need to go to a
browser on your phone chrome is good and
find it from there and then you can
install it from a link so I'll just try
and do this so you can see it
this is hard so okay I'm getting user
media here and you can see it's it's
choosing the was at the front-facing
camera in this case it's called camera
one and then if I move over to the
rear-facing camera then you can see that
I've sort of got a video of video of you
lot anyway there we go but obviously
that you know the real power there is
for is for mobile devices and a couple
of things that are coming up you will
have the ability to choose source with
I'll actually show you the spec with the
facing mode enum is this casually named
thing which kind of does the same thing
but enables you not to have to specify
an ID for a device but generically say I
want the user facing device or the
environment facing device or left or
right and so on we're also going to get
the ability to use the apply constraints
method which means you can dynamically
change constraints from JavaScript which
again will be very powerful for doing
stuff on the fly I think again you know
coming back to this idea that the real
power of robot you see is when it comes
up against other AP IDEs
we have the ability to integrate Web
Audio with with getusermedia and what
this means is you can use the output
from your microphone or the input from
your microphone as the input to two Web
Audio so using the create media stream
source method here which you can see is
getting a stream from the getusermedia
callback let's let's have a look at that
in practice then I here by my colleague
Chris Wilson so yeah so there's the call
to get user media asking for permission
the stuff from the audio from the mic is
being fed into Web Audio which is then
analyzing that audio and doing this nice
canvas visualization like
and then we can also use recorder j/s to
record that stuff so bla bla bla bla bla
and then download it yeah okay no I've
lost my presentation okay
so again you know just loads of
potential there for working WebRTC into
other api's with constraints we also
have the ability to get video from other
sources so the obvious example of this
is screen capture so we have the ability
to set the source to be whatever you're
seeing on screen so a little demo of
that if I come out of full screen you
can see I have to accept and you know
give permission to do that and then if I
just move that around a bit you'll see
we've got screen capture happening kind
of slightly useless but yeah the other
the other way of doing this is actually
the tab capture interface in in for
Chrome apps chrome tab capture which
allows you get a single tab which is a
whole potential I think the ability just
to define one single tab we've just seen
implemented in Firefox which is
fantastic the media stream recording API
and we have an intent to implement that
in chrome just to show you a little
example of that running in Firefox
nightly so what we have here is
getusermedia being called and in the in
the callback for that a media recorder
object is instantiated and then that's
essentially creating a blob of recorded
data so if anyone heard that but which
in this example is just being played out
in an audio elements but you could
download that as well
so this you know the aim of this of
course is to enable recording of of
audio and video streams if you're
interested in this stuff you might want
to look at the
streams API which is a kind of generic
concept for streaming data which is in
the process of being specified a lot of
people have asked for specifically the
ability to essentially take photographs
and again of course this is crucial to
apps running on mobile devices well we
have a spec for this it essentially has
two methods one is get frame which gets
a frame full of image data and the other
method is take photo which kind of does
what it says and creates a blobs worth
of image that you can access from an on
photo handler
so yeah that's coming up at the moment
and worth looking at the spec so this
stuff is great but of course it only
becomes really powerful when we can use
this for streaming between peers so in
order to use communication we need this
API and the API is rtcpeerconnection so
rtcpeerconnection enables connection
between two peers and then does the work
of streaming audio and video data so the
concept in this in a sense is quite
simple you've got a media stream on one
side pump that into rtcpeerconnection
and then you get a media stream out the
other end of course rtcpeerconnection
has to do a lot there's a lot that goes
into this rtcpeerconnection has to do
things like noise reduction sort of like
little things like which a hard work
like echo cancellation what's called
dynamic jitter buffering which kind of
stops video hiccups and the whole
process of enabling smooth communication
even when there are bandwidths hiccups
and so on this diagram is kind of really
there just to show you that a lot of
stuff goes on that you don't have to
worry about as a web developer
thankfully WebRTC does a lot behind the
scenes now the kind of guilty secret
about WebRTC is that despite being
peer-to-peer we
still need servers to build WebRTC apps
you know it's not possible at this point
in time to be out of kind of I don't
know for an Apatosaurus out out into the
Internet
connect me to my friend stream data with
my friend yeah that would be great it
just doesn't work like that so we need
service for two things essentially we
need to be able to exchange metadata
between peers in a WebRTC conversation
that's called signaling and we also need
servers to cope with you know the real
world of Nats and firewalls these are
called stun and turn servers and that
the whole framework that uses them is
called ice and again it's the more
detail about this the the architecture
around this which has been you know
specified in the ITF is called J sip but
the kind of simple idea here is just
that you know you're signaling goes via
some unspecified mechanism and that then
that can enable media streaming directly
between the caller and the callee so
there are these two processes going on
and it's it's a simple point but it's
kind of at the core of the architecture
of WebRTC so for signaling we need to be
able to exchange these things called
session description objects firstly we
need to wear RTC endpoints to swap
information about media so this is like
you know the codecs that I support and
the codecs that I'm going to be sending
information like that now the other part
of this is is for peers to be able to
swap network information so this is the
kind of IP and port that that a device
can be accessed from so in other words
when you want to make a connection you
need to contact the peer that you want
to communicate with and give them
Network information so that they can
actually then set up a conversation with
you
well RTC deliberately doesn't define any
messaging mechanism you can use what you
like for signaling and there is no
messaging protocol to fire
and either and the the thinking behind
this is that these things are change
different people have different opinions
so that that shouldn't be mandated in
the web RTC spits web RTC specs of
course signaling can also be used to
exchange application data so when you
you know users are beginning to with the
process of initializing your app then
they can exchange data using the same
signaling setup so how are we going to
do this well the the kind of core part
of this is course is that signaling
needs to be bi-directional so if you
imagine like Fred wants to call Wilma
well Fred's gonna have to go over a
signaling server and friend fred is
going to have to be exchanging messages
with the signaling server to start with
and then when when Wilma gets involved
there's going to be messages going
signaling messages going from Fred via
the signaling server to Wilma and then
from Wilma via the signaling service
back to Fred again now of course you
know with HTTP that kind of request
response model this in the past maybe
has been a bit tricky you know you could
do this by repeated polling like Fred's
WebRTC app could keep asking the
signaling service have you got a message
from Wilma have you got a good message
from Wilma you know this would be
inefficient and of course it's not going
to scale although a matter of fact of it
and I've seen apps where actually you
know this with a bit of optimization
this can actually work another
alternative is to do long polling you
know comet whatever you call it
to enable sort of fake bi-directional
communication with the server this is
actually used by the Google App Engine
the channel API with some of the
examples I showed you could actually use
Ajax xhr and event source event sources
the API for enabling what a called
server sent events so for a server to
maintain a connection with a web app and
send you know push data from the server
to the to the web app there's a demo
there
if you want to have a look at that in
action possibly a more natural solution
is WebSocket which is of course
inherently bi-directional and you know
this is supported by all the browsers
that support WebRTC desktop and mobile
and of course you can use TLS with with
WebSocket which is secure and avoids
some proxy problems and so on if you
want to read more about that I'd
recommend looking at you know garrix
chapter about WebRTC which is just
coming out and yeah Peter Lee Peter
lubbers stuff there is great as well
I've actually built a code lab for this
if you want to have a go at building a
signaling server this uses socket IO
running on node of course you know the
the only catch with this is that you
need to have a server running node and
the obvious ratata that is that a lot of
cheap hosting services only supports you
know PHP or whatever so for those
situations you could use of insulators a
char or whatever but if you want to have
a look at this I'd recommend this
because it's very simple with socket IO
to use socket IO to exchange messages
and if we look at the code lab code in
effect you'll see that and this is just
the signaling part there's no web RTC in
this but you can see that you know
that's the code for the server which is
is pretty straightforward and if we look
at the client code likewise for this app
it's it's really really simple to to
build you know build a signaling service
running on running on node with socket
IO and there's a live example there too
if you want to have a look at that
running on there just to a couple of
gotchas there go into the detail but
just one thing to remember if you do
build a signaling service you know
inherently signaling is not high
bandwidth these are tiny messages are
mostly exchanged at the start of a
WebRTC call but you know of course if
you have a lot of a lot of users then
the load can still be very heavy on a on
a signaling server
so when rtcpeerconnection objects are
initialized they have to do a couple of
things they first have to ascertain the
local media conditions so this is the
stuff I was talking about with
resolution codec capabilities and so on
and the second thing they need to do is
is get you know these potential these
network addresses that potentially the
the colleague can use to contact them on
these are these things called candidates
so the the media process the process for
exchanging media metadata works a bit
like this so again it's like imagine
fred is calling Wilma Fred calls the
rtcpeerconnection create offer methods
and this gives a chunk of SDP session
description protocol data which sells
stuff about local media conditions Fred
then sets that as the local description
at this point by the way you can tweak
stuff with codecs and so on so that's
why that process can be done manually
and after fred has set that as his local
description he can then send that
serialize that data send it to Wilma
Wilma kind of does the same thing in
Reverse but that's called the answer so
you have this offer answer process fred
creating media metadata setting it
locally sending it to Wilma Wilma
creating her local media metadata
setting that locally sending it back to
Fred and then they both have what's
called a remote description there's a
kind of similar process which happens
around the same time of finding network
information so the way this works is
that Fred and Wilma create their
rtcpeerconnection objects if that's
successful the ice Candidate events
start propagating and in a nice
candidate event you can get these things
called candidates which information
about how that pier can be contacted in
other words an external IP and port by
which the the host device for that app
can be contacted so Fred and Wilma both
get these candidates and then they
start firing them at each other and when
they receive them that you'd at use add
ice candidate to give that information
to rtcpeerconnection so this way they're
exchanging network information in order
to be able to set up the core this is
what an RTC session description looks
like so this is media metadata this is
the offer answer part of it this is the
kind of stuff that's being sent over if
you want to know what all these things
mean and the actual data is a lot longer
than this
check out the ITF examples with detailed
explanations and this is an example of a
candidate offer sorry a candidate object
so the the candidate here the data the
bit that you see the candidate values
there I added this on localized but this
was got from in the ice candidate event
and you send a bunch of these candidate
objects to the person you're trying to
communicate with so they can try and
make a connection with you if you want
to see this this whole thing in press in
in action I won't show you now but the
it's a really great example on the w3c
side it has the whole process of peer
connection with with signaling just to
show you a kind of demo of SDP so this
is a bit hot off the press slightly
rough so in this example we're getting
local media and then I'll create a peer
connection object and then I'll create
an offer and then you could see that's
that's an entire chunk of SDP for an
offer and I could actually edit that if
I wanted to to it's kind of tweak codec
values and so on so I'll then set that
off as the local offer
it'll be passed to the other this is
kind of silly because it's two peer
connection objects in one page but you
know you get the idea and then we can
create the answer which is kind of
similar but from the other side set that
answer and then we have a peer
connection something that's just been
implemented which to me is I think is
really powerful
is this idea of being able to use the
output from one rtcpeerconnection like
media stream from one RCP connection as
the input for another now the reason
this is interesting is that it gives us
the ability for a web app to choose how
to forward a stream to another PA so in
this again it's all on one page so it's
slightly pointless but I'll start by
getting some media and then it's
displaying it in a video element
I'll call so to this second
peerconnection object and then it's
going through a whole bunch of other
peerconnection objects to this final
peerconnection object and then playing
that media stream out in another video
element so it allows web apps to choose
how they forward streams to another peer
if you want to look at peer connection
get your head around this this is a good
place to start
this is peer connection without any
signaling it's about a hundred lines of
codes shows the whole process in action
if you want a kind of full-fat video
chat app this is the kind of canonical
google chat app with lots of logging to
the console very good for if you're
trying to work out the kind of processes
the sequence of events like I said we
also have the ability with WebRTC to
communicate arbitrary data and you know
I think this is I think for a lot of
people actually this is one of the most
powerful parts of the project there's
some kind of obvious use cases so you
imagine two like two people playing a
game and they need to communicate
arbitrary data like this which is
actually completely faked but you get
the general idea so you might be
communicating player positions with with
another another player and need to do
that with as low latency as possible the
API if data channel rtcdatachannel is
very similar deliberately to WebSocket
but of course the the point about data
channel is that they go you know you're
exchanging arbitrary data directly
between peers you're not having to go
via
an intermediary WebSocket server you can
optionally choose that that
communication transport to be reliable
or unreliable what that means is that if
you say the communication has to be
reliable then what you're saying is this
must fail unless every packet is is
delivered and obviously you're going to
need that for stuff like I don't know
file-sharing whatever if if you say that
you're happy with better performance but
it can be unreliable then that kind of I
don't know that's okay for things like
yeah exchanging game player position
stuff that we don't actually have to get
every piece of data reliable reliable
transport has been implemented SCTP in
firefox for some time and now in chrome
31 and chrome 30 behind a flag which is
great yeah the API looks like this which
as you can see is it's a pretty
straightforward kind of addition to peer
connection to specify that you want to
use a data channel and then when you get
the data channel you can set up the
channel to handle messaging very like
with WebSocket again a really simple
through one page example of doing that
if you want to have a look at how data
channel works a slightly more exciting
demo I think is the share first app this
enables you to share files using
rtcdatachannel so I'll choose this is a
photo of my local pub in Tooting in
London which we're trying to save from
being developed so I've specified that
as the file that I want to share via
rtcdatachannel and then I just need to
pass someone a the URL for it which is
here so you have to pretend this is on
another machine but you get the general
idea
so yeah I've just kind of communicated
with myself this this photograph but you
can imagine that that being very
powerful
the ability to to to to share files
without some kind of intermediary file
service so like I said you know in a
perfect world it would all be like this
we would just do this communication
directly between peers of course in the
real world we have Nats and firewalls
we need to be able to cope with that in
order to establish streaming between
peers so we have this well-established
actually technology for this called stun
a stun server has a really simple task
which is just to when a request is made
to to respond with a public IP and port
that the requesting device can be
contacted from so it's you know it's
it's a simple server it doesn't do much
it's kind of relatively cheap to to run
and yeah that's kind of the way it works
the you know the Sun server living on
the on the public internet outside the
firewall if that fails we have another
method which is to use a turn server
turn server is essentially a relay
server again this is this is living on
the public Internet and the idea of this
is that if because of complex firewalls
and that's and so on direct peer-to-peer
communication fails we can go via this
relay server called the turn server now
the downside of that of course is that
essentially those turn servers are
relaying all the streaming data so the
they don't have to be particularly smart
but they're dealing with a lot of
bandwidths so that's the cost there this
if you look at the app RTC app I
mentioned this is the the value that's
passed into the rtcp economic
rtcpeerconnection object to specify the
stun and turn servers with some some
login details there it's optional to use
stun and turn but that's the kind of
thing you'd be doing if you want to use
those servers
the framework that is used by artists
appear connection to to work with these
technologies is called ice so you know
if the the kind of the trade-off here is
that stun of course is cheap because all
you're doing is getting an external IP
port for a device turn is kind of works
in every case but it's more expensive
and it's less efficient ice works with a
whole list of candidates which you know
I showed earlier are being passed
between peers ice works with that list
of candidates to find the optimal path
and in fact you know the the majority of
calls between peers will actually work
directly peer-to-peer with the with the
help of stun it's it's I mean it's
around by these stats around the sort of
kind of six out of seven work out okay
that way it is slightly less between
business to business calls if you want
to to run a stun server there's some
options Google has a test one but you
can use for testing and there are open
source implementations the RFC 576 six
stun sorry turns over and there is a VM
image available for that for Amazon Web
Services just have quick word about
security a lot of people ask about this
it's kind of core to the WebRTC project
you know we have mandatory encryption
all the components of WebRTC and of
course like I showed you we have UI
interactions designed to be secure you
have to explicitly opt in to
participating in a WebRTC call and I
think that though that you know the most
secure aspect of this is of course the
WebRTC is built into the browser so it's
sandbox there's no plugins there's no
separate update process there's no way
to kind of kind of trick people into
installing extras so we have yeah these
secure pathways that should actually say
TLS rather than HTTP because you might
be working with
websockets but everything is secure in
those Pro is you know encrypted in those
processes just to reiterate though when
you're building signaling you must use
TLS otherwise if you're signaling is
prone to you know being intercepted
unencrypted then of course that opens up
lots of potential for kind of man in the
middle stuff of redirecting calls and so
on intercepting staff maybe injecting
stuff and so on so it's really crucial
with signalling when you implement that
to to use secure protocols so we have in
the simple case you know connection with
WebRTC between two different devices we
could actually and this works for lots
of WebRTC apps the ability just to
create more rtcpeerconnection objects
and to use those to connect lots of
devices to each other in different kind
of configurations now this doesn't scale
of course and the the kind of robust
answer to this is to use something
called a multi-point control unit
these are servers specifically designed
to handle media to enable some clever
stuff too like coping with media coming
with different codecs and resolutions
and so on and to be able to do kind of
efficient distribution of that media
between lots and lots of peers so WebRTC
has been designed for these kind of
different topologies but also also to
enable communication with the outside
world
so in particular thinking of phone
systems this a stack of stuff that's
been implemented to enable web RTC to
work with sip clients this is like video
over right so voice over IP and video
conferencing systems and also some yes
some phone api's from phone out it's
kind of integrated with jQuery and the
xing gaia embeddable own widget check
that out to connect to PSTN PSN is like
the
plain old phone network really nice
thing sorry I keep bringing that every
time I talk I'll show this these guys
from voxi own troppo they did this I
think at Burning Man this year they did
they set this up for us at Google i/o a
couple of years ago they they built
their own mobile network using the open
BTS open-source cell network and what
that meant was when they incorporated
that with their their gateway to WebRTC
that you could make you could make phone
calls from any old phone through through
their gateway through their open BTS
sell to a WebRTC app running on a
computer which to me is is fantastic you
know this is telephony without a carrier
and this is you know really really
useful in situations where there is no
infrastructure or infrastructure has
been damaged so a lot of potential for
that stuff
just a quick pointer to some some tools
to help you building WebRTC apps chrome
has a WebRTC internals page which gives
stacks and stacks of stats and so on
about what's happening with your with
your WebRTC connections and you can
download the whole lot and see it's
actually nice when you when you're
trying to get your head around we're
about to see to be able to look at all
the signaling data from there another
it's a JavaScript shim maintained by
Google adapted je s kind of abstracts
away some of the differences in prefixes
and so on the spec spec is pretty stable
now but has enabled you to use the same
the same terms without having to change
that each time there's a change if all
this is too much then I recommend these
JavaScript frameworks they're a stack of
good mature JavaScript frameworks for
building web RTC apps without having to
go into the whole process of stuff I was
talking about I've got them here
actually but there are also these simple
web RTC has a signaling server - called
single signal master so simple with RTC
is very straight for
it's really easy to build an app with a
few lines of code
likewise PJs does the same for data
channel just yeah kind of ten lines of
JavaScript if you don't want to write
any code at all there are lots of
complete services now on the web open
talk V line and others asterisk and so
on
enabling WebRTC calls without doing any
work to implement anything at all and of
course the old C++ code is there as well
if you want to have a look at the
package you can check out that if you
want more information about WebRTC I
maintain a list which is at the top
there which is kind of all the stuff I
know about and have heard about and get
some contributions to that as well and
yeah I'd recommend taking a look at the
Google i/o presentation that Justin a
Bertie and I did this year a lot of good
stuff there lots of ways to contact
WebRTC people the main forum for
technical discussion is discuss WebRTC
the Google group and a stack of new
stuff is always being posted on Google+
plus WebRTC and you know we really
welcome of course people's a feature
requests and bug reports so keep them
coming on Co bug comm slash new and yeah
I you know what what interests me is
what web developers do with WebRTC kind
of out of the worlds beyond the worlds
of kind of telephony and video
conferencing and all that so I'm really
interested to see what people like you
know you in this room will be doing with
these api's I just wanted to finish by
actually doing some WebRTC chat if
anyone's got a browser if they want to
go to this page it's torquey dot io / go
web RTC I'll just see if we could have a
video chat between whoever shows up and
earth is going to work if anyone's got a
I'll just show the URL again so if
anyone wants to join this we'll see if
we can get people up on this is it gonna
work maybe not we want two different
networks here now here we go
hello whoever you are sorry I think
that's it
we got someone else this is cool and
this is kind of brute force method you
know just lots of are TCP connections
that's brilliant
I recognize that bloke okay anyway I
better finish up like I say the slides
are online at go web RTC appspot.com
and yeah thank you so much I've got a
couple of minutes I don't know I take
some questions
I don't know if I'm gonna be handed a
find with questions or not yet okay I'll
try to answer this what about Firefox
and ie well we've got support for
Firefox which is great
ie of course has had full support with
WebRTC via Chrome Frame but certainly
not in the future I we don't know some
people may have seen this EU WebRTC
proposal which is I think you know a lot
of comments on the existing web RTC
proposal so I think it's very compelling
when we have WebRTC on you know once we
start having WebRTC endpoints of like
billions of them it becomes very
compelling for IE
and Safari and so on so we'll see where
that goes
like it doesn't make sense to include
location awareness into WebRTC that's
really interesting yes definitely I can
think of lots of use cases for that
that's a yeah a really good point people
being out of contact people who are you
know looking maybe to answer questions
and so on within the vicinity the next
question is what codec is used for
sending the data over the why is it
possible to control the bandwidth or
auto-tune according to available
resources yeah kind of you can tweak the
the sdp that you set as the local
description and send to your collie that
they then use as the remote description
so you can tweak that stuff and the
codecs you use you know what are
implemented by the app so for for Chrome
we've got you know vp8 and a novice but
you can tweak the details for that yeah
if you need more information about them
and go on to the discuss WebRTC group if
you need more specific stuff about that
can RTC handle cgn carrier-grade NAT
where individual clients
behind multiple layers of net yeah
that's a that's a good question too you
know that my little diagrams show kind
of one little gnat and it's all very
simple but in the real world it's more
complex than that you may have firewalls
and gnats behind gnats and so on and so
on
it depends I'm not very expert about
this but you know it kind of depends on
the it depends on the stun server but
obviously this can be a problem and this
is where we have turn servers to provide
a fallback sadly for that complexity
which we of course get particularly with
businesses running with these very
complex and potentially you know like
sometimes outdated Network setups but
yeah it's it's complex and I don't
really have a good answer for how we can
you know develop stun in order to cope
with these I guess increasingly complex
gnat setups ah now this is great any
thoughts on p2p CDN via WebRTC I meant
to show this off possible users worried
about bandwidth I think this is a really
interesting area so the idea is that you
don't just do file sharing like the
stuff I showed with share first but you
do something like what I don't know if
anyone's seen peer CDN the guys are
called pr5 have implemented this stuff
and it's a really interesting concept
it's it's kind of peer-to-peer file
sharing so the you know conceptually the
idea is that you would be able to get
assets not by default from a server but
by default from some other peer that you
know hopefully of course is is close to
you network wise now you know in a sense
this is exactly the kind of thing that
we can see with ITC data channel this
ability to to work with files or chunks
of files it could be the kind of p2p
dream come true of course the the great
unknown is how that will work in Prak
and I don't have an answer to that well
you know how efficient that can be
whether that can work well how that
works with bandwidths you know like any
peer-to-peer system if if I'm suddenly
working as a Redistributor of content
you know we don't know how that would
work if everyone starts if everyone
started using peer CDN and started
distributing content peer-to-peer via
via WebRTC so I don't know the answer to
that but it's it's I think a very
interesting area peer-to-peer
file-sharing and just fob distribution
really CDN is running peer-to-peer
rather than from these kind of
monolithic service setups I think that's
the last question if anyone has more
questions I'll be around today and
tomorrow so please feel free to come and
talk to me or email me my email is
Dutton at google.com so thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>