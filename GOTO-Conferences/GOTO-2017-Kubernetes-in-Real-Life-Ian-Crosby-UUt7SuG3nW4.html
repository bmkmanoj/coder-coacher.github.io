<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • Kubernetes in Real Life • Ian Crosby | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • Kubernetes in Real Life • Ian Crosby - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • Kubernetes in Real Life • Ian Crosby</b></h2><h5 class="post__date">2017-11-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UUt7SuG3nW4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for coming that sock kind of the
survivors making it to the last slot of
the conference so as Kevin said today
I'm talking about kubernetes so it's
probably a good idea to start by asking
how many people here are familiar with
kubernetes nice that's pretty good
how many of you have used it or play
around with it or maybe even something
similar like bcos or darker swarm not
too bad does anybody actually running a
kubernetes in production okay better
than I expected so I think this is a
good level for this for this talk now I
call this kubernetes in real life and I
mean a few different things by that so
first of all I want to focus on running
in production so this is not about just
kind of an intro what it is and getting
started but it's about running actual
production great clusters and production
applications and the second part I mean
by in real life is I'm gonna be talking
about actual companies and their stories
in using kubernetes and getting things
into production and then the third piece
is I want to focus on using kubernetes
as its intended and we can sometimes
have this this trend in tech where we'll
adopt a new technology and kind of pull
it into organization and just use it in
the same way we were still using our old
technology so if I can use kind of a
terrible metaphor for this imagine you
live here in Copenhagen and for some
reason you need to commute every week to
Stockholm and so you drive hundreds of
kilometres both ways every week and you
hate it and it's terrible and it takes
away so many hours of your life and then
miraculously something that some day
somebody comes and they give you a plane
and you're like cool this is going to
solve all my problems this is going to
make my life so much easier I'll get so
much time back this is wonderful and
then so the next week this is you
driving to Stockholm it's probably not
the best use of the technology so this
is what I want to focus on on using
these technologies in the proper way and
actually
leveraging leveraging the features that
they have so my name is Ian Crosby and
I'm originally from Canada I currently
live in Amsterdam where I work for a
company called container solutions and
we're a professional services company
and we focus around the cloud migration
so what this means is kind of in my
day-to-day I work with different
companies who are in the process of
moving to the cloud so maybe they're
looking to adopt something like
kubernetes or DCOs and we kind of help
them along this path and in doing this
kind of I get to see a lot of different
situations but also a lot of the same
kind of same kind of mistakes and the
same best practices that kind of come
along in all these situations and it's
in kind of collecting these different
stories that that I wanted to put this
talk together so it's actually recently
at a client and we were doing a quick
kind of proof of concept to show how we
could run part of their applications on
top of kubernetes
and as we're kind of going through this
this proof of concept and building it I
get a lot of kind of the same questions
that I get people are new to this
technology so they're asking about stuff
from where do I store my different
configuration files to how do I handle
stateful applications and databases and
as I try to go about answering these
questions
apparently Eifert a lot to two best
practices in kind of kubernetes and
cloud native best practices and then on
the last day as we were there one of the
DevOps guys comes up to me and was
asking can you point me to these these
best practices you know I looked on the
kubernetes website I don't really see
anything where can I find them and I
didn't really have a good answer for
that but I think it's a pretty valid
question and some of the reason where I
think this is the case is that you know
this is kind of an young technology in a
young space and it's also very community
driven so if we think about best
practices this is stuff we might find on
a different blog here or in a different
git repo but there's not really kind of
central location and this is kind of the
inspiration for why I threw this talk
together was I wanted to collect all of
my experiences in working with different
companies
try and take away some lessons learn
their so at least next time when
somebody asked me this question I can
hopefully just point to a YouTube clip
of me giving this talk and then that's
that'll be enough but I also work with a
great group of engineers at container
solutions who are all doing the similar
things so in kind of sharing our stories
I was able to leverage not just my
experiences but theirs as well so just a
quick outline about what I'm going to be
covering today so I want to start with
defining some terms so what is container
orchestration and what do I mean by that
I want to talk about something that I
would call the cloud native maturity and
then I want to get into these actual
stories of companies that are running
kubernetes in the wild so I'm going to
look at five different companies we've
worked with and try and pull out some
lessons and some best practices and if
you're looking up there and you say I
only see four this guy's not really good
at counting kudos for paying attention
and but there's one of these there's
kind of a two-for-one bonus in there so
then we'll do a wrap-up and try and list
them takeaways but hopefully I can leave
you with today so I also just want to
quickly outline what this talk is not
about so this is not an argument for
moving towards container orchestration
I'm not here to tell you that why this
is the best way for your company
organization it is but I'm not here to
argue that today I'm also not
specifically trying to promote
kubernetes so there are a variety of
different tools out there such as DCOs
I've mentioned docker swarm nomads from
Hoshi Corp these are all really good
tools so if you're new to this space I
would suggest to take a look at a few of
them before deciding which one is right
for you this is also not an intro to
kubernetes talk I think there's really a
lot of really good resources out there
online if you're just looking to see
what kubernetes is if you want to intro
to the to the different features and
concepts you can find a lot of stuff
online but I'd like to go a little bit
deeper today I know that being said I'm
gonna try not to assume any actual
advanced knowledge so even for those of
you who have never used or never heard
of kubernetes
hopefully you can still get some benefit
out of this I'll also be around
afterwards free to talk about any of
these things after the talk so let's
start by defining some of these terms
what do I mean when I talk about
orchestration or container orchestration
so I pulled this from the Oxford English
Dictionary and they define orchestration
as the planning or coordination of the
elements of a situation to produce a
desired effect now what does that mean
in our context so what are the elements
of our situation well we can think of
our servers our applications we've got
some networking we probably got some
storage and then what's the desired
effect that we're looking for what we
want our applications to be running we
want them fault-tolerant we probably
want some service discovery so they can
communicate and we want to use our
resources efficiently and the last piece
here I find really important this
especially surreptitiously which I just
kind of replaced with the word magic but
what this means for me is that this is
things that should happen without any
manual intervention and ideally without
me knowing how it's actually happening
so say for example I'm responsible for
some production system and it's 2:00
a.m. and one of my servers explodes what
I'm expecting from my orchestration
platform is it's going to detect the
failure it's going to redeploy any
applications that were on that node to
some other healthy nodes and it's going
to rewrote any traffic that's necessary
and all of this should happen without
any impact on my end users and without
waking me up this may seem like a lofty
ambition but this is kind of the goal
and I asked for container orchestration
platforms these new kind of applications
were building these kind of cloud native
microservices distributed applications
are much too complex to rely on kind of
the old-school superhero sysadmin who's
just gonna get up at 2 a.m. and ssh into
a bunch of terminals and figure out the
problem these new systems are much too
complex we need to hand over control to
automation into tooling
so one of these tools and one that I'm
obviously going to talk about today is
kubernetes to give kind of a quick
background I think as most people are
aware it originally came out of Google
so they've been running containers in
production for going on 15 years and
they have an internal tool which is
called Borg and based on their lessons
learned and what they've been doing they
created this new project open sourced it
and called it kubernetes and since then
it's been actually donated to the cloud
native computing foundation so there's
no longer one single company behind it
and it's grown really fast in adoption I
think part of this is because of the
community that is behind it and it's
moving really quickly features get a get
added to it at a pretty good pace and if
you're looking for resources looking for
help there's a there's lots of resources
out there so this all sounds great we
can kind of leverage all of the the
lessons learned and all of the the
heartache that Google's gone running at
their scale take this install
applications on it and we're done but
obviously this is this is not that
simple however we often get contacted
from different companies who have some
kind of message along the line of hey we
hear that you guys are kubernetes
experts could you come over to our
office and set up a cluster and as you
start talking to these guys and asking
you know about their current technology
stack what are their current processes
more often than not what we find out is
you know maybe they have some giant
monolith application and they're
deploying this thing to production twice
a year so sure I could go over there and
I could set up a cluster for them and
maybe even install their their monolith
application but then we're kind of back
to this you know driving the plane to
Stockholm kind of thing this isn't the
best fit and not only are they're not
gonna be able to leverage the benefits
they're probably going to be worse off
than they were so really you need to be
first of all kind of in the right stage
to adopt these new and these new
technologies the next thing that's
important is your motivation
so all the time a lot of times also we
talked to managers who complain about
not being able to attract and retain
talent because the technology they're
using is a little bit outdated so none
of the new developers want to work there
and the existing developers complain
about this stuff and want to work with
the latest coolest stuff so they decide
ok we're gonna go get kubernetes or
maybe there's a manager who doesn't
understand why it takes two weeks to
deploy their application when in fact
they've got their ops team sitting in
one office and the developer team
sitting in another office and they think
the solution is just to go and get the
the latest coolest technology that they
saw in hacker news so you know it's
obviously the technology is not going to
solve these kind of organizational
problems you need to look at at kind of
your processes and ensure that you're
ready for these technologies so we've
gone through this kind of process with
quite a few companies and we've
developed what we call the cloud native
maturity matrix so there's a lot going
on on this slide but the important
pieces is that we basically identified
eight different pieces of an
organization so everything from your
infrastructure to your team structure to
culture and then try to list out the
different kind of maturity levels from
the more legacy to the more
bleeding-edge and we use this too when
the one hand identify where our company
sits so in terms of maturity where they
are in each level and in this way we can
kind of help identify and show them
where they can best leverage where they
can best gain effort from putting their
resources what's important to note here
is that you really want to move all of
these columns or all of these rows at
about the same rate so for example
what's the point of moving to micro
services architecture if my application
is all running on one single node of my
server closet but assuming you do have
the right pieces in place you have
adopted automation you have CI you have
CD and you are in the right step to move
to orchestration how do we get there you
know we've decided on the technology
we've looked at a few we decided we want
to go for kubernetes
and how do whether the steps that we
need to take to actually take this to
production to start leveraging from the
benefits and I think one of the best
ways is to to look by example so that's
why I want to look at these these
specific companies that we've worked
with and try and take away some examples
of how we get there so as I mentioned
these stories are true actual companies
we've worked with I have anonymized the
names to protect both the innocent and
the guilty so the first question that
you necessarily come up to is where are
we going to run this and the kind of
traditional answers are well on premise
or in the cloud but with these new
technologies there's a lot of gray area
in between so yes we could run this on
our existing infrastructure fully manage
our own our own clusters or maybe we run
it in-house but we use something like
open shift so we get a certain level of
supports and we get a certain level of
comfort or maybe we run in the cloud and
we leverage a full kind of SAS solution
something like Google container engine
or Azure container service or we could
decide to run on the cloud and manage it
ourselves
so depending on which solution you
choose is going to depend on your
requirements and your specific use cases
I'm gonna look at two different
companies that I worked with this year
two quite different companies and the
different scenarios that they ended up
with so this first company is to start
up in Amsterdam and as startups do they
were leveraging kind of using all the
newest technology so everything was
micro services everything in docker
containers Kafka elasticsearch all this
cool stuff but we looked at what were
their actual business needs were and you
know they needed to get their platform
live in advance of any of their
competitors they also wanted to grow
their team and grow their applications
so adding features so that means that
they don't want to waste resources to
manage their actual infrastructure and
they don't want to waste time in trying
to learn new technologies so in this
situation we went with Google contain
engine because it allowed them to get
clusters up and running in just a couple
of minutes you have somebody else who
can manage this stuff for you and let
the teams and let the developers
actually focus on just writing code so
as a result of this they were actually
able to go live on time and really
they've since doubled their actual
development team and one of the the kind
of the claims that the CTO likes to make
is that every developer that comes on
board has push code to production within
two days now this is something that's
not possible if a developer coming
online needs to not just learn the
application but needs to learn about
docker needs to learn what this
kubernetes thing is and how they all fit
together so by having this kind of SAS
platform and have it building an
abstraction layer on top of it the
developers don't need to learn about all
these things they can just focus on
adding feature and adding value to the
products additionally where they were
able to do this with just one ops guy
working part time so this is an example
of really kind of moving in the cloud
native way so leveraging this new
technology so you can just focus on your
actual business now on the other end of
the spectrum worked with this company
also this year who you know they were
kind of under government umbrella and
had some pretty strict security concerns
so you know they had some very different
requirements specifically they had to
host all their own stuff in addition
they were running everything on a closed
internal network so it's kind of tricky
to be a cloud native when you're not
actually connected to the cloud but the
team here was actually still quite
motivated and they still wanted to adopt
new technologies so they had gone to
some conferences and saw ok kubernetes
is awesome this is really going to help
us move forward so we're gonna we're
gonna install this and they went back
and they started working on it and
trying to get it installed and ran into
some issues and they started kind of
looking for help so we went and worked
with them and they're kind of asking how
they went about you know installing
those communities on these these
internal networks they kind of
reluctantly admitted
that well basically they had a USB stick
and they were go to a laptop that was
connected to the internet download
whichever binaries seemed to be in the
last error message they saw bring this
over to their secure internal network
plug it in copy the binaries and repeat
the process now you know these were
smart guys and they realized that this
was not the best way to go about things
but they were just kind of worked they
were trying to work around the
restrictions that they had you know
there was these kind of security
guidelines which had probably been
around for 10 20 years that weren't
really up to date and so these guys were
just trying to get things done but the
result of this is that you know they end
up with a much less secure system
because who knows what kind of files
they were moving back and forth and also
they're wasting a lot of the developers
time you know just copying binaries and
docker images around so I think the
lesson here is that in moving to kind of
this cloud native space it's not just
about taking a new technology you have
to look from an organizational
perspective you have to review things
like your security policies do these
still make sense in this kind of world
so the next question that you generally
run into once you decide where you gonna
run your clusters is well how many
clusters do I need and how am I going to
manage my different environments do I
need to run my applications on different
clusters so I definitely need one for
production and then we have a staging
environment so I'm gonna want to put a
cluster there because we want to mimic
production and you know we probably want
for one for tests and then what about
you know the different dev environments
and all of these things so this is a
challenge that we ran into with with
another company we were working with and
this is another company in the
Netherlands and they have an online
weather service and the weather is
something very serious in the
Netherlands if you ever go to Amsterdam
and you like to make friends with the
Dutchman just make some offhand comment
about the weather and for the next five
minutes you guys will be best friends so
these guys had a very important service
that we're running and they were looking
to adopt orchestration now like any good
weather server
they were obviously already running in
the cloud sorry and but their AWS bills
were something they were concerned about
and they saw that the the resource
utilization was pretty low so they
thought by using orchestration they
could kind of bring this costs down
which is a pretty which makes sense
basically but then as we started looking
at you know these different the clusters
and how big the cluster size was and
then they thought about all the
different environments they had they
started getting concerned that their
bills were actually going to go up so we
work with them to kind of come up with a
different solution for this because you
know just because in your old way of
doing things you had all these different
environments that were up and running
24/7 you know maybe that doesn't make
sense maybe you can leverage the new
technology to do things a bit smarter so
we set up something with kubernetes by
leveraging the different features so
essentially what we want to do is is
share the underlying resources so we
start with one single cluster and we use
a basic concept called namespaces and
namespaces is basically a sub cluster
within your cluster so for example here
we set up a namespace called staging and
then all the applications you deployed a
staging can communicate with each other
and then you create another namespace
called dev for example and then all
those applications can communicate with
each other so this way you're still
using the same underlying servers
underlying VMs but you can kind of share
the resources but it turns out these
things are really easy to create and
actually remove so do we really need
these things up all the time
we actually just integrate this with the
actual CI pipeline so that you know you
run your bills you do your tests and
then you deploy this image to a new
namespace that you create on the fly you
add any dependencies and then you run
your integration tests in this this
virtual cluster then once the the tetes
finish if everything is ok you just
completely delete it so you can create
this kind of new kind of workflow then
you kind of get maybe these concerns
around access and well maybe I don't
want my developers
to actually be able to accidentally
delete everything on staging or on prod
so we have another feature in kubernetes
called
our back or a role based access control
and this allows you to give specific
roles or specific access to your users
for example you can say developers have
full access to everything on dev those
dev environments but maybe don't give
them access to staging and you can go a
step further and add something called
Network policies so now we can actually
limit the applications themselves as who
they can talk to so we can ensure that
everything running in staging is not
able to communicate with anything
outside and these are quite flexible you
can do it by an entire namespace or just
by certain applications you can control
ingress egress or or bi-directional
traffic and if you want to go even
further we can add full service to
service level TLS so this is for
something like this we would use
something like sto add it on top and
this way we can ensure that all
communication between our services is
secure so the lesson here is that we can
leverage the features of these new
technologies to solve our old problems
but in a smarter way so we've decided
where we're going to run our clusters
we've configured our different
environments and we've set things up
around security so the next thing we
want to do is actually deploy your
applications and this is where
kubernetes can really shine if for
example your applications are already in
containers for example then running
things is really simple you know with
this one really short command I now have
my application up and running in a
fault-tolerant manner on the cluster so
when I do this there's a whole lot of
things that happen behind the scenes for
example kubernetes is going to find a
node that has the sufficient amount of
resources for my application it's going
to schedule the application on that node
it's going to create a pod on that node
which is the concept in which it runs
applications it's going to create a
container network inside that pod it's
then going to go into the default
registry
my image bring it down and run it it's
also going to create a deployment so
it'll ensure that my application always
stays running if it crashes it will
restart and ensure that the right number
of instances are running so this is a
lot going on behind a very simple
command and for me this is kind of the
double-edged sword of kubernetes it's
you're abstracting away a whole lot of
things I'm specifying here
one command run I'm specifying the image
I have my docker image my app and I'm
just giving it a name and then behind
the scenes there's at least a hundred or
200 different configuration items that
are either inferred or set to defaults
and this can come to kind of bite you in
the ass so this next company that we
were working with again this was kind of
a governmental branch so think large
enterprise-e
processes and so they had adopted
kubernetes and were kind of in a
proof-of-concept stage to showing that
it would be would be valid to run this
in production and they were having
issues where certain nodes were running
out of memory and as they were running
out of memory and then certain
applications were getting killed and
they couldn't really figure out why so
we were working with him to try and
debug these things and figure out what
was going on and the first thing to note
was that they were running these were
all Java applications running in
containers and you know they were
specifying kind of the heap size and how
much memory each of them should use so
essentially they were taking these old
Java applications that they had been
running before on their separate servers
and just running them the same way
inside a container on kubernetes and the
problem here is that there's some very
important settings which you should be
using on all of your applications and
this is to do with resource limits and
resource requests and provides a similar
thing to this to the kind of Java memory
arguments but basically you're saying
how much CPU and how much memory my
application needs and what's the maximum
that it should get so without setting
these essentially it was reverting to
some default
the applications in the containers just
saw that they had access to everything
on the node and then maybe there was
something problem with the application
but essentially it was using all the
memory and then the killer would come
out and just randomly start killing
things so if you set these actual
settings then it creates what's called a
quality of service in kubernetes so
based on how you set them you'll end up
with different tiers of applications
either guaranteed first of all or
best-effort
and basically what this does is it
allows you to triage or prioritize your
applications so that if you do start to
over commit and you get into these
memory problems it'll be the best effort
ones that are going to get killed first
so this way you can identify your
critical applications ensure they get a
guaranteed QoS and that they'll stay
around running so I think the lesson
here is that you need to learn about the
actual applications you're using or the
actual tools you know you don't want to
just take your existing applications and
run them in the same way now on this new
technology you need to understand the
technology and the settings that are
there so the last case that I want to
talk about is around monitoring and I
think this is kind of appropriate
because and my experience monitoring is
kind of the last thing we seem to think
about where it's okay we're about ready
to go to production oh crap we forgot
about monitoring get something in place
and I think part of this has to do with
the fact that monitoring used to be a
lot simpler in kind of the legacy
systems you know if you have some giant
monolith application we do what I like
to call the poke it with a stick
monitoring just kind of like is it alive
yeah okay we're fine but in running
these new complex systems you know
monitoring has become not just a lot
more important but a lot more complex a
lot more there's a lot more pieces
involved you know we might have hundreds
of services running across dozens of
different nodes across multiple regions
you know in this situation if some
container dies on this this VM over
there
do I care maybe it depends it depends on
the higher context so I don't want to
know about these specific
instances of a container dying I want to
know on a higher level how is my service
reacting so again we can't just take
these existing monitoring systems we
might have had for our legacy
applications and just patch them on to
our to our new systems so I had this
project where if this was a or a company
that was about to go live with their
their application and they had this kind
of problem like oh crap our existing
monitoring is just not going to work so
we needed to find a new solution and
again there's there's different
decisions that you need to make here for
example do you build and host your own
or to use something that long as a
solution so if you actually if you are
going to run your own application your
own monitoring system there are some
really great tools out there something
like Prometheus which really focuses in
this kind of cloud native distributed
monitoring or if you need to go for a
solution there are a lot of a lot of SAS
products out there that do have this
kind of these cloud native micro service
concepts so in this specific case due to
kind of time constraints in the time
them already there for production we
ended up going with one of these SAS
providers and so we need to find one
that that does have these concepts of
these tools that you're using so a lot
of them will have maybe a docker
integration or kuba needed kubernetes
integration and so within just kind of a
couple days we were able to get very
pretty graphs which all the program
manager people type really liked to look
at but more importantly we were able to
get kind of this higher level view of
our application so it's not just saying
that you know one specific container
might have died but we get a better idea
of the health of our system so the main
takeaways that I want to kind of leave
you with today is that container
orchestration is the future it is kind
of the way forward if we want to move
into this cloud native space and you
know orchestration is going to happen
either manually or you need one of these
these kind of tools to take a care of it
for you that being said you need to be
ready to adopt it right if you're still
doing things manually if you don't have
for continuous integration in place and
then it's probably too soon for this and
you need to work on these things first
and cloud native is not just about the
tools it's a lot takes a lot more
it's about your entire organization need
to buy in and look at things like your
processes look at your security
guidelines and ensure that you have
buy-in from the whole company not just
one team that wants to adopt some
certain tools you also need to leverage
the technology so understand how it
works and what are the features that it
offers you so you can really take
advantage of all the features that it
has and generally it's it's it's about
using these tools in the right way just
as you know because we have Jenkins
installed doesn't mean we're necessarily
doing continuous integration just
because you have kubernetes doesn't mean
that your cloud native thanks
you think we have some questions in the
in the FS wall
um for example somebody is asking about
like running different namespaces in
terms of noisy and scaling up can you
maybe elaborate on that in terms of how
how do you actually think about that
when you are running with namespaces
instead of spinning up new environments
what are companies done for that yeah so
in terms of kind of because it can be
very easy to spin up you can kind of go
a little out of control so you do want
to have processes involved so for
example I worked with a company who
wanted to spin up kind of these new
environments for each of their feature
branches and so we built in that each
feature branch is built they create a
namespace deploy it run the automated
tests and then completely clean it up
but sometimes there are cases where you
want to you know leave this around and
maybe do some manual testing or maybe
just show up the feature so we also
needed to add something where
essentially we would look at kind of a
essentially cron job that would go and
see which namespaces are actually being
used which is in this case where proper
monitoring comes into play to seeing
which pieces are being used in that way
you can actually have proper cleanup
otherwise it can get kind of out of
control cool can you maybe go back to
that maturity model you had because
there's some questions about like all
the different products in the ball ship
and because there's a question is is it
scooping it is basically foss and I
think maybe could elaborate more on that
like what does it take to move two
companies and if you already set out on
ansible is it worthwhile going to
communities yeah so the important thing
that I wanted to highlight here was that
you want to move kind of everything
along in a similar pace so you want to
ensure that you have your process
kind of move forward as well as your
architecture and your infrastructure and
so specifically stuff like continuous
integration has to be in place before
you can adopt some kind of orchestration
and generally you need to have fully
adopted automation kind of everywhere so
the question around is their benefit
going from ansible to kubernetes I think
definitely so ansible in my experience
is more about just setting up your
actual infrastructure so you can also
use it to kind of sure handle
deployments but it's not going to give
you these other features like like
service discovery like communication
like and you know fault tolerance if my
applications are running or if they if
they failed are they gonna get
rescheduled it's not really built for
that kind of thing so I think having a
platform like kubernetes is a natural
extension or a next step
fingers are something about the whole
cloud native computing foundation it
could be elaborate more than that in
terms of because they have already
chosen the self tools and how have you
seen maybe these get adopt it in the in
the companies that you've been working
with comparing to the choice that so
native computing Foundation has chosen
yeah so the decline of computing
foundation it's a branch under the Linux
Foundation um yeah and they start of
they kind of adopt these set of tools so
kubernetes was the first one I think now
there's at least a dozen Prometheus
Slinker de jager a bunch of stuff and I
think this does offer a certain sense of
security or or companies are more likely
to adopt these things when they see this
kind of brand or or badged attack to it
whether that's relevant or not is maybe
a discussion for over a beer rather than
here don't to get in trouble but it does
offer some sense of legitimacy and they
do for example have rules around it must
be open source which i think is
obviously a good thing but how have you
seen the adoption in the common
he said you've been working with is that
something they've been taking in and
saying yeah there was a good choice so
companies adopting those technologies
and yeah well so yeah I guess I could
say that I have yet to see a case where
yeah maybe a company adopted these
technologies and said you know no this
is crap why did they why is this under
the CNC F but it's early days yes you
would you recommend using many of the
things that the CNC D yeah so the ones
that I'm familiar with
for example kubernetes and Prometheus I
would both I think are great tools and
some others I've worked a little less
with but but generally there's they have
pretty good guidelines in terms of
adopting technology I think okay I think
there was mostly then there's also some
questions about some very specific ones
and I think maybe you can ask Ian about
that just in terms of some of the limits
and requirements in terms of CPU but go
and ask that yourself that would be
really good other than that really
thanks for the presentation and give me
a hand</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>