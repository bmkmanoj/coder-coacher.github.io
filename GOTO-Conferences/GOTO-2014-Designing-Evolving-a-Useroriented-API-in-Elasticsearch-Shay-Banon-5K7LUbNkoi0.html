<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2014 • Designing &amp; Evolving a User-oriented API in Elasticsearch • Shay Banon | Coder Coacher - Coaching Coders</title><meta content="GOTO 2014 • Designing &amp; Evolving a User-oriented API in Elasticsearch • Shay Banon - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2014 • Designing &amp; Evolving a User-oriented API in Elasticsearch • Shay Banon</b></h2><h5 class="post__date">2015-01-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5K7LUbNkoi0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm gonna talk about elasticsearch it
started as a talk about the api's and
how we evolved the api's in
elasticsearch but then I found that a
big reason why the api's are so
successful in our success is that you
know how does it work also in the
internal systems of it like how does it
works internally and how it exposes and
how it works internally and then through
that what what does it reflects when it
comes to using the API as themselves and
I was like the to give them more
technical talks here so it will be a bit
more technical now so let's start
elasticsearch what does he do
I don't how many people here use the
elasticsearch how many people here use
the scene so elasticsearch what is it
it's a real-time distributed search and
analytics system very very simple we're
not gonna exactly talk about how to use
it
we're gonna talk about how does it work
in practice and through that we're going
to understand why the features that we
expose in a search how do they work and
why is it so beneficial to some use
cases obviously that you try to do with
your data so obviously the first step
that elasticsearch does is to make text
searchable right it's a search engine
this is how text looks like right so if
I want to go and try to search across
that text typically what people do is
you know it's in my database that's
great I'll just do a like query and just
run it and everything will be okay but
that's effectively slow and inflexible
inflexible right it's it's it has to go
into reverse the full text you know that
you try to find matches and if you hat
doesn't take relevancy into account at
all right if one document is more
relevant than another one for my search
term I would love to see it appear
higher in my search response so let's
take these texts and see what it's at
what a search engine actually does the
first step that a search engine does is
it takes the text and
Drex it down into tokens or terms if
you're familiar with loose in elastic
search this is the effectively the
analysis process right take that text
and break it somehow into terms that's a
whole big topic obviously language
stemming things along those lines comes
into play but once it has those terms it
effectively builds a table and that
table consists of the terms on the
left-hand side sorted by the way you see
that they are effectively sorted and
where do they occur occur in the
document so exactly the the document IDs
that they occur internally within within
the search engine and then how do we
execute a search well it's very simple
we just go and find the relevant terms
that were searching for and through them
find the relevant documents that match
today this is effectively an inverted
index and this is the wonderful things
that people don't necessarily
immediately understand what happens in a
search engine which is effectively it
counts almost everything right like if
you think about a system it counts
everything what is the term frequencies
in order for example to do relevance
what is the text length in order to do
dock weight which plays a role obviously
a heavy role when it comes to relevancy
terms position again in order to do
things like phrase queries right find me
a query that matches this term next to
that term
they're obviously charl offsets in order
to do highlighting but inverted index is
not just for search an inverted index
specifically we've seen also support
indexing numbers dates which are
effectively numbers a boolean now
boolean in arms geo points geo shapes
what have you right I mean you can build
a whole ecosystem of a type of data sets
that you have that will play a part in
that inverted index and one interesting
aspect that that people don't
necessarily realize is the fact that
everything is effectively indexed in
you see nor in an asset search by
default so for example if you take a
document that has 100 fields in it
all of them are indexed think about
taking a database with a database table
having a hundred columns and putting an
index on all of them that's pretty much
right you're not gonna do that the other
part that is interesting with the way
that a search engine works and inverted
index specifically when you do a search
across multiple fields all of those
indexes comes into play that's another
very important aspects of why I'm
inverted index and why search engine is
so fast right it doesn't if you look at
typical databases and you execute a
query against multiple columns not all
of those indexes will come into play
maybe one maybe two but that's typically
it so this is another big big reason why
when you execute searches on our search
even complex searches and involves
multiple multiple fields searches are
still extremely fast but search is not
enough or you know full-text search or
numeric searches or something on all
those lines
and this is very core to what we believe
in an asset search this is not enough or
why we view searches more to be
completely honest I think search and
compasses with innate analytics and the
reason is very simple
imagine indexing Twitter yeah very easy
example to broke and you're executing
some sort of search they say go to
Amsterdam and everybody here are pro
philic twitter users obviously you use
the go to Amsterdam hashtag a lot and
you execute a search and you find a
billion documents now you can go and
present those tweets in a list with a
page and you can people can scroll
through it but that's not very
beneficial right I'm not going to be
able to go and click next next next next
we're trying to understand what's going
on you want to present it in a more
digestible manner for example take all
of those tweet and show them on a graph
so I can see how they tweet over you
know an hour by hour or a minute by
minute or something along those lines so
this is a big big part we see
as a big big part when it comes to
executing to building a good search
engine actually providing this
functionality so how do we do analytics
in an asset search if you remember
before we took terms and map them to
dock IDs write or values and map them to
dock I disturb the actual dock ID that
match for analytics we actually need the
other side of the equation we need the
ability to map dock IDs to values so as
we search in the scene for example a
live scene tells us oh this talk I'd be
matched we need to go and now run
analytics on top of it some sort of an
aggregation and that aggregation will
we'll have to take the dock at the end
map it back to values in order to do
that this is if you think about it the
process of uninviting nutritive index
exactly taking what it has in building
the opposite of it today in an asset
search the default behavior is to cache
those values in memory and we call it
field data so this is how we we treat it
we take a little values caching into
memory to have a very very fast access
imagine executing a search request
across two billion documents and as you
map them you have to be able to perform
those operations super fast because
you're gonna do the billion times right
gets to a point where even taking using
a regular hash map it's just too slow to
do that and obviously to memory its
extensive so we have specific data
structures specialized data structures
in order to do all of those type of
aggregations this is a side note there's
also another option which is a leucine
feature to store those that data that an
inverted data effectively on disk
it's called dock values so if you look
at typical data bases that's a columnar
store right storing in a columnar manner
in order to be able to access it if you
want on disk so you won't have to look
bloated to memory obviously a bit slower
but you know it might be beneficial if
you don't have enough memory so as I
mentioned data access from ROM again
it's very very fast but also very very
important it's in the context of the
users query so for example imagine
providing that Twitter example that I
gave and we're showing all the
graph of tweets that you have and
putting the text box on the top so
people can as they type for example
execute searches and see what matches
immediately reflected in their graph
this is what we're aspiring to write I
mean that quick interactions even when
you're doing this heavy-duty analytics
on top of potentially large volumes of
data so it actually breathe brings you
into being able to build relevant
analytics for each users right if you
look at typical ways that people build
analytic systems today they say I'm
going to predict what the user wants and
I'm gonna build the data structures in
order to build that analytics right I
know that the user might want to do a
hash tag so I'll try to find the hash
tags within Twitter and maybe index them
in one specific way in order to do that
maybe geo points maybe something along
those lines but then it becomes almost
unmanageable right imagine someone
wanting to do a geo point with a hash
tag with a list of user IDs in Twitter
that want to do that right and then they
want to see the analytics results of it
slowly and slowly it becomes a bit
unmanageable to try to build a very
effective and efficient analytics engine
in order to do that and this is
effectively the bread and butter of
elasticsearch right that freedom to
slice and dice the data however you want
I mean very being able to aggregate it
that's effectively what we do well so
what type of aggregations we call them
aggregations by the way in elasticsearch
do we have the typical metrics that you
can think about count min max sum
average or numeric values recently we
added percentiles and cardinality which
are pretty cool
obviously standard variation some of
queires all of those another type of
aggregations that we have are
effectively group by aggregating so or
we call them bucket aggregations so for
example you can have popular terms
significant terms range estates
geolocation and other stuff this is a
side note how many people here are
familiar with significant terms okay so
I can I can have a quick sideline about
what significant terms
because I think that's quite cool and it
shows about the power line Burton index
has so how did a significant terms came
to be mark who worked with our company
implemented this feature and what he saw
is that for example imagine taking the
UK crime database and the UK crime
database includes a lot of data the most
important one is the fact that it
includes the crime type at the
geolocation that it happened and imagine
taking the UK and using our geo hashtag
regression in order to break it into
areas and trying to find what are the
most popular crimes that happen in the
UK now if you run that aggregation that
means you're running popular terms
that's not interesting if you look at it
you'll see that the top five crimes are
exactly the same regardless of location
right aft or something along those lines
on the other hand we want to find the
interesting crimes that happen in
locations we fondly call it uncommon ly
common the uncommon ly common crimes
within that area and how does that work
once you change it and by the way that's
a simple change from terms to
significant terms you start to see
interesting data starts to bubble up
from from elasticsearch for example when
we ran this we saw that there is an area
in the UK that has a high proportional
and unproportional commonality of bike
thefts compared to the rest of the UK
and if you zoom in to that location and
try to understand why you see that it's
Cambridge so people ride a lot of bikes
and people still then we saw that in
another area there was a high again
unproportional amount of cry of bike
theft
sorry of of done possessions that happen
in the UK and when we zoomed in we saw
that it was an airport so people get
searched on and I have no idea why
people bring a lot of guns to the
airport but apparently they do and if
you can imagine this type of ability
it's only possible because actually you
seem does the heavy duty for us which is
counting everything so you can easily
take
matched in a specific area and check it
against the backdrop right the
background no background data that you
have and try to find out a commonly
common situation another interesting
example we took that and try to find
fraud in credit cards so imagine you
know have a lot a lot of credit swipes
happening you know your your credit card
company or something along those lines
and there's a few people I don't know
around this area that reported that the
credit card was stolen so if you look at
their credit card history you'll see a
lot of transactions that they don't
understand what what what is it right
someone stole their credit card and when
you know crazy on it but if you try to
find that the top terms the most common
places where they interacted with that's
gonna be iTunes so that's gonna be
Netflix or Tesla's all those lines right
on the other hand what I want to find
here is actually that bike shop on the
end of the street that every button to
go there and someone installed a credit
card
I don't know faff thingy so if you want
significant terms you can actually find
that right you want to find the uncommon
ly common data sets out of that so I'm
I'm super excited about that and it
shows you like how we think about data
there's a whole talk about it that Mike
that mark gave on cue con highly
recommended I'll continue one of the
interesting aspects that we did with
aggregations is that aggregations can
actually have sub groups and subgroups
within them so if you're familiar with
elastic search there's a lot of freedom
that you have with its query DSL it's
very verbose if you try to type it with
adjacent but the ability to compose
queries together it's a very very
enriching capability can actually decide
oh here's one query I'll wrap it in
another query and then filter something
and I wrap it in another query and
filter it with something else and so on
and so forth if you remember in elastic
search way back the facets facets module
that was used for analytics you couldn't
do it
so aggregations actually allow you to do
that allow you to compose different
aggregations together so you can
actually four you can for example in the
UK crime example that I give you can
actually run a geo hash grid aggregation
that includes within it a significant
term segregation so you can find the
significant terms within each area in
the UK okay but how does it work in
practice how does it work
you know internally in the scene let's
start from the scene so first of all
this is an inverted index somehow we
have a set of documents you know JSON
documents for example and they have to
end up being in a New Britain index so
the first thing that you need to
understand is that that portion of the
inverted index is immutable and that's
very very important first of all it's
very cache friendly like we don't trash
to shame the same filesystem location or
something along those lines the
operating system can cache the hell out
of it into the file system cache or what
have you
reads from ROM a lot of the data has
very advanced data structures internally
in the scene in order to do that very
very efficiently both in terms of memory
usage and execution times if you cache
things that are associated with it from
that for example our field data from
back when we're doing analytics they
never change so we don't have we don't
have to worry about how do you maintain
cache coherency it's effectively
immutable
obviously it's compressible because once
we have all the data we can actually do
interesting things about compressing
common datasets and it has no locking
because it's immutable effectively when
you search over it there's no locks you
don't need to lock because it's only
it's read-only but it's immutable so how
do you dynamically add documents to it
so here's how it works first thing is
that there's an in-memory buffer that's
in the scene itself and as you add
documents to it they exist in that in
memory buffer
eventually you can issue a committee in
loosing and that commit will sorry that
commit will generate a segment in the
sea that's the mini inverted index that
we saw before right
and now we have a commit point and this
is searchable we add more documents we
issue a commit another segment now both
of them are searchable okay another
another set of documents another commit
and we make them searchable so how does
loose income it works it writes a new
segment as we saw write a new commit
point it f syncs all the files that are
relevant for that segment because that's
the persistent storage of it and it
clears the in memory buffer in order to
be able to accept new documents what's
expensive here F think that's a pretty
heavy-duty file system type of
operations right it needs to go the file
system now if it doesn't even any file
optimizations or doesn't go to disk or
you have slow spinning this or something
along those lines now you have to go on
each one and wait till it gets
acknowledged by the operating system
potentially hopefully by the device
driver to make sure that it's there and
everything is fully persisted so how can
we make it more lightweight this is the
near real-time search aspects still in
the same land by the way so we have an
in-memory buffer but now we do flush we
don't do commit and create a segments
make it searchable but again we do
flushes searchable
another round make it searchable what's
and now we commit the data okay so now
we can make it like fully persistent on
disk so what is the loosing flush what
does it do it's very very similar to a
commit invite a new segment clears the
buffer reopen the index to for searches
but there's no F thing involved right
because it's it doesn't guarantee
that if you do a leucine flush that
you'll be able to later on come back and
reopen the index at this point only a
commit current is it so this is
relatively light weight right cool but
data is not safe until it's get at
synched so how do we make sure that we
don't lose data we use a transaction log
very common in just in databases right I
had log transaction log both are very
popular names for it so we have that a
memory buffer with all the documents
that we want to have they go into the
transaction log as well we do flush we
have a new segment that's searchable now
another set of documents come in go into
transactional as well with your flush
that's great searchable now all of that
is searchable you have a transaction log
in case of a crash by the way Alaska
should come up and then we'll replay
that transaction log on top of based on
the last commit point and now when we
issue a commit we can actually have a
proper Lusine commit point and we clear
the transaction log so we can start a
process new data sets this is called an
elastic search refresh so that Refresh
in elastic rich happens every one second
relatively lightweight and executes
solution flush makes all the changes
searchable and again as I mentioned very
very lightweight an elastic search flush
which is poorly chosen word because
there's a list in flash that there's
something else effectively does the
leucine commit like properly commits
everything clears the transaction log
persistent or persist all the changes in
loose in itself and it's relatively
heavy in the last search itself managers
in the background all the process of
issuing those flushes periodically to
make sure that the transaction log is
kept at being okay
let's go let's continue but we have many
segments right if you can imagine we
keep on adding documents and documents
and documents into the system segments
keeps on being created when a search
executes its search across all the
segments in the scene if you have a
thousand segments that's gonna be slow
so let's let's see how segments gets
reduced so here we have one segment
segment properly searchable that's great
create another segment properly
searchable that's great another segment
properly searchable perfect maybe we
have too many now so there's a process
now that is called merge that takes
those three segments and merge them into
a new segment that includes all of the
different data that you have in those
three segments just in a new new segment
now remember that this also helps with
compression if the term dog existed
three times now in those three segments
it will only exist once in the new
segment so it also helps to reduce the
index size and once that merge happens
and it happens in the background by
leucine and Alaska which also manages it
with the same together then make sure
that make it searchable and then those
three segments can be thrown away
there's a lot of trickiness involved in
making sure that we keep that three
segments around for existing searches
and only new searches can view the the
previous ones but all of that is managed
by by elasticsearch itself again we add
three segments now we have two big ones
and potentially at the end we can and
with one big segments so merge process
was easy to do it takes many many small
segments merges them into one big
segments removes deleted dogs the leads
are always tricky in you seen it's
effectively a bit set that says this
this document ID is deleted this
document that is deleted this document
ID is deleted but deletes are still
around they're not being treated as part
of the search when you execute a delete
and a refresh happens but
still hanging around hanging around the
only process that actually throws them
away is by doing this merge that
effectively as it merges just doesn't
take them into account during the merge
process but even a single Lucene index
can just become too big right I've seen
cases where the Lucene index of 250
gigabytes or something on those lines
that's that's pretty much pushing it but
you know singly in that can just becomes
too big sometimes you just need another
one so this is the process of actually
scaling up and not necessarily scaling
out they're not necessarily up and
that's obviously by shorting your data
just take a single Lucene index that
would ever had I know 1 billion
documents and break it down into five of
those so this is effectively a process
that is relatively transparent in
elasticsearch and if you can think about
it many segments or singular scene index
is one shard and many shards in a
massive search is one index okay so this
is the terminology that we use in
elastic search and ask yourself some
node is effectively a running instance
of elastic search that's effectively
typically a 1/1 server that runs it and
it's just a container of shards right
charge just go around and flow between
them and that's the physical worker unit
that still have seen index that executes
searches distributed searches
what-have-you and everything
index itself is just a logical namespace
it just points to one or more shards
potentially having compass of the data
how do we calculate the shard itself
it's effectively we take the ID of the
document we hash it and we pointed at a
specific short maps to it note that you
can also override it so you can provide
it a sketch with a routing value if you
want to control that specific documents
should live in the same shard together
so how does it look when it comes to
actually doing executing an API if you
put document with doc ID one for example
we'll end up for example in short -
thanks - because of its ID and the
hashing algorithm if you try to get a
document with doc ID 1 again the same
hashing will work and you go back to the
relevant one searches on the head other
hand typically goes to all the shards in
order to provide it so how do you scale
with elasticsearch there's a lot of
effort in a succession to start small
I've seen a lot of cases where people
just start with one node right either
using a script for logging a lot of
times you just start you take your
Apache web logs and start to string it
into elasticsearch or maybe visualize it
with Cubana you don't have enough data
to justify starting a 15 node cluster or
something like that and that's fine and
as it should grow with you as you have
more data and you find it valuable
so easily just start another node and as
you add more nodes and ask the coach
will automatically start to balance
those charts around so it will take some
shards and move them around to the new
nodes in order to make your data
properly balanced across all the new
nodes that you have if you add a new if
you add a new index then there's those
relevant shards also exist and then
again properly allocated across now
three nodes instead of only one node but
more Hardware most chances for hardware
failures right for example a 3 a.m. on a
Sunday you lose one node so what do you
do you add redundancy up until now we
had only one copy of the data so let's
make another copy of the data and
elastic search is the notion of a
primary shard that actually that's the
main sure the ones that all the the
indexing requests goes through and
replicas shards which are effectively
copies of the primary short so if you
start with one node all the shards are
primary if you add another node then if
you have replication enable then Alaska
will automatically go and allocate those
replicas they'll recover their data from
the primary
properly be allocated if you add another
node now you have another rebalancing
factor right I mean we can now take some
of the replicas around and move them on
top of just taking primaries and move
them right there just shards and if a
node fails then effectively the first
thing that we do is you saw we lost a
primary over there so we go and elect a
new primary to make sure that you can
actually go and continuously ingest
documents on this new primary and we
allocate replicas of the data the new
replicas so elastics will actively go
and try to maintain whatever number of
replicas you've configured it to have so
you don't have to come back and say oh
you know my my you know my database
backup or something went down I need to
go and actively start it up in order to
make sure that still replicated or
something along those lines last which
will go and based on the number of notes
that we it has will make you try to make
sure that you still have the amount of
copies that you've configured it to have
and then it's effectively rebalance back
to into nodes so primary charges as I
mentioned it's just roll it all the doc
changes that happens go through the
primary charge you know to maintain
consistency and it forwards all the new
doc updates to the replicas in parallel
the number of primaries is fixed so you
cannot change the number of primaries
that you started with in a single index
this is an intentional design decision
there's a whole new - a whole other talk
if you want to go online that talks
about how to design a switch to scale
even beyond that limit effectively of a
single of the fact that the number of
farmers is effectively fixed for one
very very popular example is time-based
data like Twitter where people just
create an index per day so you can
actually grow with the volume as well
maybe today you are ingesting 1,000
tweets if tomorrow you're ingesting a
5,000 tweets actually maybe
index might make sense to have more
copies of more replicas and be even
further partitioned replica shard its a
copy of the primary shard serves read
and searches as well and by the way so
if you add them you can actually add
more search capacity but it's only if
you have more hardware right it's like
if you're just gonna add more replicas
on a fully balanced elasticsearch
cluster you're not really gonna add more
read capacity you need to add more
hardware so those replicas will go and
be allocated there to make make use of
it the number of replicas can be changed
dynamically so you can go to an existing
index and change the number of replicas
from one to two
a very common design use case in our
asset search for example when ingesting
data or doing the indexing or something
along those lines is to start with an
index with zero replicas so you don't
incur the cost of indexing in other
copies and one you're done once you're
done with indexing just increase the
number of replicas and this is simple
this simple tip just halves the time
that it takes to index your data
typically but who controls all of this
so in an asset search there's
effectively an elected master node and
the node is effectively a running
instance of an existing elasticsearch
cluster if your starting node a and you
have one or more nodes with the same
cluster name working together then
whether it's with multicast or unicast
as you add more nodes they get joined to
the cluster and with multicast or
unicast and those nodes join and one of
them is always elected as a master the
nice bit about it is that I think
mixture makes sure to share all the
cluster States between all the nodes so
this means that who met whichever node
you hit will know where to redirect
those with that request something is
will know how to read forward the
request to the relevant node
okay how does he do it so every knows
where every node knows where each
document exists this is the cluster
state that I mentioned so it's a cluster
level information it includes the
indexes that it has the shards the nodes
if you're using elasticsearch we
actually expose all of that data through
our API so I can actually go to our
search and get a full list and an
understanding of where there exists
where any that's the part that can only
be updated by the master node so
changing the cluster state adding a node
being added creating an index something
along those lines has to be only managed
by the cluster State it's elected when a
cluster forms if you have single node
then you have one node that is likely
that's master if you add another node he
joins the cluster if you're not if again
you join another node then he joins and
identifies that there's another master
in the cluster and joins it just roll
and if the master fails another another
master will be elected automatically so
as I mentioned the master node only
manages cluster level changes so it
doesn't manage things like dock level
changes or something like that so not
you don't we don't have to go through
the master for every every operations
that we do what is the result is
distributed real-time search in
analytics which works the same way on
your laptop this is one thing that we
try to make it very very easy to users
just get started with the ask search but
also in your cluster and I've seen quite
quite significant sizable clusters that
are being used with the elastic search
this is a side note one of the
recommendations that we have I don't
know why we didn't have it here but
because of the master itself is just a
role in the cluster in order to create a
more resilient cluster itself we
recommend that you run dedicated master
nodes once your cluster becomes bigger
so dedicated master nodes just three
nodes that only responsible for master
elections and then have a lot of other
data nodes
are you know just handling data and
half-charged alakay in the morning on
them so who's using it
Wikipedia uses asset search we're very
proud very humbling full text search
highlighting search snippet search as
you type working very closely with them
one of the Wikipedia developers has been
an amazing contributor to elastic search
helps push a success forward
The Guardian if you're gonna watch the
talk I highly recommend it how last wish
can be used as an analytics platform it
happens today remember which time to be
honest Stack Overflow uses elastic
search to search across obviously all
the relevant stock overflow questions
that you have github uses elastic search
as you every time you search on github
you you you're effectively executing a
search across elastic search Goldman
Sachs is a search to index an alley and
analyze form you know close to five
terabytes of log data every day by the
way log is very very interesting as a
concept and a successor started to
effectively become o being used a lot in
the context of blogs which I find very
very fascinating and and I think the
reason why it happens is that log have
transitioned into something more than
just operational logs so people now
expect from logs to be more than just
try to find my application errors that
happen very rarely when we see today in
logs is that people index or put into
elasticsearch logs of the application
itself logs of the web server that talks
to the application logs have potentially
some important metrics that happens on
each machine into elastic search and
then you can answer very interesting
questions for example can I correlate a
specific error to a five to an increase
in my load on my own specific machines
that comes from a specific geolocation
that hit my website those are very very
interesting questions that you can now
answer if you put all of that data
together in a search and I think that
this is one of the main reasons why
Alaska she's being
you so much for logging as well so
that's it
thank you very much short talk will be
short I don't know yeah 40 minutes any
questions
very good question how does how do
updates happen so updates effectively in
usin itself it's a delete or mark as
deleted the previous document and
indexed in your document so it is a
reindex what is important to remember
it's actually tends to be not that
expensive
anyhow you need to reanalyze your data
or something along those lines
and if Lucene tries to try to solve
in-place updates like you know databases
do with b trees or something along those
lines it will lose all the benefits that
it has with the mutability
so there's tons of benefits that you get
from the fact that the same works that
way that actually people don't
necessarily understand immediately
understanding the immutability aspect
that actually you want that to happen
you want you seem to reindex the data so
you can execute searches with no logs so
you can do it you can create caches that
has don't have to worry about cache
coherency there's tons of stuff that
comes with it yes
yes well first of all we don't recommend
running elasticsearch between data
centers I recommend running Alaska
within the same data center typically
between data centers people put like
message views or something along those
lines and we potentially might work in
the future to have a different type of
replication model that will work well
between their centers which will not
work what
I need
so that that part we recommend to run
something like a message queue between
them and replicate the operations on the
other hand if you're running a last wish
for example with rack awareness or with
in in Amazon between availability zones
then you can configure elastic search
and we call it awareness allocation
awareness you can configure our search
to make sure that it places copies of
the data across availability zones so if
one availability zone goes down then you
still have the copies of the data
actually it goes even a step further and
says if one of an ability zone goes down
you can configure it not to go and
allocate all the copies of that
availability zones in existing cluster
because that might crumble your cluster
and wait until it comes back up and we
say
yes the support many comes from the
scene itself by the way there's a lot of
working machines to support multiple
languages mainly around the analysis
process so how do you take that piece of
text that I showed and break it
correctly for different languages
because different languages have
different different rules on how to
break you can just break based on white
spaces so each language has its own
analyzer some of them are really good
some of them not as much so from one dot
X we guarantee that the protocol within
nodes will be backward compatible so a
1.1 100 to you you can run one one or
two node next to one one cluster so you
can do a rolling restart today in
elastic search the rolling restart can
be expensive because even if you disable
allocation like you go and tell ask
search okay I just shut down a node but
don't go and try to allocate all the
shots that were on it because I'm gonna
bring it back up again we we over-over
copy some data that exists between the
primary and the replicas of that node so
it can take more time than you know we
would have loved it to be we're working
on making that process a bit faster and
then effectively a rolling restart will
be hopefully you know very very quick
and you don't have to wait a long time
so the question is how do you how do has
this updating nested documents work in
Nazca sure we have a JSON structure that
is complex and have so there's there's
two ways to do that in our third search
the first one is nested documents or the
nested concepts and it's taking the
internal objects in a JSON structure and
and creating documents and external you
seen documents next to it so one
document might end up being five or six
documents then you can perform searches
that'll be more advanced when it comes
to relationship between fields within
those objects
so because there because it ends up
being 5 or 10 documents or something
like that there's a few guarantees that
happen for example there's a guarantee
that all of those will always happen
within the same segment so even during a
segment merge or something like that you
have the guarantees that they will never
split between segments so that means
that you can make sure that when you
update something you do have to reenacts
all of that nested documents but at
least you won't have to get into a
situation where you see partial results
or something like that if you on the
other hand because they exist within a
single segment searches are super super
fast right it's like even even faster
than joins in a database because it's
like it goes just on a bit set and
finding the matching ones there's
another feature in Alaska it's called
Parent Child where you can have a parent
document and a different document not
internally that have a relationship of a
parent-child relationship and when you
have that in elasticsearch lastly to
make sure that the parent and the child
exists within the same shard using the
routing mechanism automatically and then
when you do searches you can execute
searches that says whether this parent
has discharged under this child has this
parent and then you can update them
regardless you can go and update the
parent or you're going update the child
this is a bit more expensive though so
searches using Parent Child will be
slower compared to searches using nested
documents but you get the ability to
only update portions of that document
instead of having to reindex the whole
document we know we we hope to address
security and of future versions of
elasticsearch but you'll see how how we
work we when we address security we want
to make sure that we add all the
features that comes with security
including ACLs as well for now what we
recommend and we always recommend to put
a proxy in front of elasticsearch and
thanks to the fact that it's restful
then you can I've seen people create
rules in that proxy in nginx or
something like that that allows specific
users to access specific indexes based
on the URL pattern that they have thank
you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>