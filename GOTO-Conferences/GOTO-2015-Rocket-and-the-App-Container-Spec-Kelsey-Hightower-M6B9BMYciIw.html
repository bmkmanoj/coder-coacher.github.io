<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Rocket and the App Container Spec • Kelsey Hightower | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Rocket and the App Container Spec • Kelsey Hightower - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Rocket and the App Container Spec • Kelsey Hightower</b></h2><h5 class="post__date">2015-11-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/M6B9BMYciIw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right how many people know about
containers this is the docker track but
you always got to check how many people
are a couple more containers great
because I'm not going to dive deep into
what a container is but I will talk
about containers in general I typically
don't like talking about containers
because I think they're really like 1 to
5 percent of the overall problem but
this talk is pretty interesting I think
because we talked about the need for
things like standards right so we will
talk about rocket an app see which is
the container spec from core OS in an
attempt to provide an industry standard
guidelines on what an application
container is and the first question we
get is why write so early on you know
maybe even pre docker a lot of people
had this vision that they could use
containers to build the perfect
infrastructure right so most people
their first experience with the
container you go five minutes in and
things are fantastic right you have this
in your mind or whatever you whatever
your infrastructure looks like right now
your initial belief was you adapt
containers and it's going to be
beautiful
and then you go to production and you
find out that there's a lot of pieces
missing right so you know you're you're
deploying you're deploying but you don't
really have like things like service
discovery figured out and then you
discover things like the docker bridge
for the first time and you find out that
it's not really easy to get your hosts
to communicate between each other and in
some cases and some rare cases you
actually download a container that
actually does care about what kernel
version is running and now you have no
way to address it because there's really
no standards around this stuff it's just
new right so you move down that road and
what do you do if you're a developer you
call your ops team right you're off team
sees you kind of wavering and things are
looking bad so you're bringing your ops
team
again there is no standards so
unfortunately your ops team can't do
very much for you right so unfortunately
this is how it's going to end you
actually have no choice in this matter
the good news is that things are
improving and one of the goals of this
talk is mainly to provide an overview of
application container spec and we call
it app C for short and then rocket which
is our KT is pronounced rocket and I'm
going to highlight where app C and the
docker image format agree so there's a
lot of things people involved in apps II
agree that docker has done right which
is provide this idea that we can take an
application and describe it as a single
application that we can reason about
that means we stop talking about Java
that means we start talking about Ruby
and we just talk about applications
right and the other part is there should
be a config inside of that image that
tells an executor what to do with that
image right so we want to do is write
that down what does that mean and then
when a dish and I think to really drive
the spec home we're actually gonna do
something with it so live I'm going to
take a set of docker images I'm going to
convert them to AC eyes I'm going to see
what that process looks like so we can
see where things are the same and where
things differ and then we're going to
talk about how to actually sign and
distribute those so one of the goals of
FC was we needed a stronger trust model
so if you're pulling random things from
the internet first you should not do
that
don't pull random things from the
internet but one thing you would like to
do is be able to pull something and
validate where it came from
all right so if you've been managing
systems for any amount of time you've
been used to this for your whole career
right using a package manager normally
those packages are signed from a
specific entity that you trust so when
you bring them in
you kind of know who your trust in here
we moved to the wild wild west these
days where there's just things on the
internet and we're just like randomly
pull them into our infrastructure and
this is especially dangerous when you
start thinking about bringing in things
like databases
and key services that power your
infrastructure this is getting really
really really dangerous for a lot of
people and then we're gonna talk about
how to actually do something with rocket
like why did we build this and how is it
fundamentally different than other
container runtimes so first at a high
level the application container spec and
the goals with this is to have something
that is well II specified meaning we've
documented every single detail on what
an image is how it should be executed
what system call should be in play and
we want to build a community around it
so the goals were the spec is no good if
there's only one implementation of it so
we're trying to foster other people to
implement and there are actually a
couple of implementations of the
application container spec so the number
one thing is the image format right the
image format is called an ACI second is
a discovery mechanism so when you build
one of these images you should be able
to host it wherever you want so that
means if you have a web server and you
want to just throw your images in there
and just serve them to your organization
should be able to do that there's no
special registries there's no default
registry so that's good and bad in some
ways the bad part is there's no central
place to go to find all the ACS in the
world the good part is you don't need
much tooling to host any of this stuff
everything in app container
specification was meant to be simple you
can build an application container spec
our image with command-line tools right
you can use tar gzip and GPG to sign
them and you can just build your own
image no fancy totally required and then
the runtime environment so what you do
have an image and you can find the image
the next thing you need to do is be able
to specify how you run the image so if
you want to be compatible with
application container spec you need to
do a certain set of things so that
people can kind of rely on behavior even
across systems and then a set of tooling
to help build validate and help people
just in general get application
implementations correct
the first thing I talk about is the
image format so the image format very
similar to the docker image format here
pretty much the starting point for
application container spec the ACI needs
to contain everything that the
application needs to run and if it
doesn't they should at least specify the
mount points that need to be added to
make it so so if you think about if
you're using docker and you have an
image the image tells you a few things
maybe it's entry point but it doesn't
have to tell you all the volumes it
requires you're free to just buy mount
in anything and they're mapped wherever
they want right so there's some
advantage there there's flexibility but
you can't read the image manifest inside
of a docker format to know the required
amount points for an image so if someone
writes really good documentation it'll
be really easy to pull it down and mount
things in but it'd be much better if you
actually ran the image and it said you
didn't mount in all the required mount
points this won't run we can do that in
app C because we make it a requirement
so there's two main things there's a
root filesystem same thing as Dockers
image format and the root filesystem is
just that some people will take an
existing system and you can tar the
whole thing up and make that your root
file system you can use docker build to
produce a root filesystem is probably
the most popular way of producing root
file systems these days or you can use
native system tools Debian RedHat have
good tools for building full systems in
at root and then you need an image
manifest so for a very simple ACI this
is one from a project called kubernetes
for managing containers and this is the
API server and it's a statically linked
go binary actually this woman isn't
statically linked I'm going to bind them
out in some libraries from the host
normally you wouldn't do that sometimes
you would just say I'm going to build on
top of Debian but I'm a big fan of
containers that are about 10 Meg's I do
not like downloading containers that are
like 500 Meg's or a gig and there's ways
you can get around that and the manifest
so if you visit the spec it has details
on each key that you can find or
describe in a manifest
now these manifests are version
so this is the 0.5 that one version of
this manifest an executor can read that
version and nobody can find this out
that manifest now this is incomplete so
I can fit it on the screen but this
tells me the name of the application
container the version is basically
similar to a docker tag and it's up to
the executor to reason about what that
tag means it could be a cemented version
it could be anything I mean we do have
the concept of an OS right so one of the
goals for application container spec was
to work from multiple operating systems
in order to do that the images need to
have some sort of metadata to tell you
this will work for FreeBSD and this will
work for Linux right containers have a
shared kernel
they just won't run anywhere so what we
do is we provide some metadata to help
the executor understand if it can
actually run that label run that
container or not and then we have an
entry point called is ech so this is
basically similar to the entry point
you'll find in docker user and group and
then the mount point are specific so
here I'm specifying that I need the SSL
search from the host so my static link
binary will try to search this local
file system for certs but it won't find
them so what I'm specifying in my image
manifest is that those need to be passed
in at runtime if they're not defined
here and so what mounts things in won't
work you have to be very specific about
your intention and application container
spec then a discovery mechanism so one
of the goals was we wanted to be easy
for anyone to build and host their own
registry the docker registry is actually
really really really powerful but it's
actually complex so complex that you
have to go find one in order to get
started there are some good open source
ones out there but sometimes you want
something super super simple and in this
case we're looking at a a CI and all a
CI is by default must have a detached
signature when you attempt to install
one container run times must check to
see if there is a detect signature and
do the verification process then you can
turn it off but we do make you jump to a
flag that says in secure skip
verification so that
no you're doing something that you
probably shouldn't be doing and so in
this case we have these three artifacts
and the public keys so that way an
executor can download those public keys
and use those public keys to verify the
image now there's simple discovery and a
simple discovery you take your artifacts
and you put it behind any HTTP endpoint
does it matter
throw it on nginx put it on f3 Google
storage it doesn't matter you refer to
the full URL and then what will happen
is an executor will follow a convention
it'll take your URL and fill in the
blanks so that's a template that we see
there so we'll take the name of the ACI
the version or that tag and the
extension will be a CI and then by
convention it will look for a SC knowing
that that's the actual detached
signature and attempt to do the
verification the other option is meta
discovery so let's say that you have an
executor that may have different
capabilities maybe you want to
distribute your images via BitTorrent or
something some other protocol so what
you can do is you can give the executor
hints and you can also have a different
place where you store your actual images
so maybe it's not on the same server
that's serving up the metadata on where
to find the image so in this case we can
hit an endpoint and all you have to do
is return back this HTML header right
and the header is only a template to
tell the executor how to fill in the
blanks to find what it wants all right
so I hit this endpoint and I get to this
Casey discovery tag back and it tells me
that the content you're looking for so
if you match this name use this template
to actually download what you're looking
for if the content isn't there then
you'll just handle through the normal
HDTV process is not found and then down
here we get the public key so I have the
ability to pull those down during the
discovery process and this was designed
because we feel that people will
probably want to do something outside of
HTTP s3 maybe even something like
BitTorrent you have lots of hosts so you
want to know where we can find the entry
point for that stuff then the runtime
environment so the other half of this
story is you have an image now you've
got to run it so epsy defines how a ciz
are executed on a particular house so
one thing we need to talk about is like
our file system layout so an app see we
have this concept of a pod and we'll
talk about that a little bit more later
but we got this idea from the kubernetes
project of the ability to compose a
collection of containers into a single
execution unit now this allows some very
interesting patterns you can take two
distinct maps that need to run together
and have them be independent ac is and
then compose them into a pod construct
and be guaranteed that they'll share the
same execution environment meaning that
they have shared namespace so they're
going to contact each other or localhost
they optionally can share mount points
between each other
and they can share their Isolators
meaning how much CPU memory the combined
unit can have now once you have a pod
concept it makes it really easy to
schedule across a cluster you can say
these things must go together you don't
end up in a situation where half of your
dependencies land on a host and the
other half may be pending and can't find
a home and get scheduled so you resolve
that by having a pod volumes like we saw
earlier in the manifest how limes are
actually managed or how they're mounted
executors job is to do that by default
you need to be able to handle various
networking so we have a networking
implementation or standard I won't go
into details there but one of the
implementations of AB C which is rocket
has support for network plugins so you
can do things like IP VLAN or DHCP
something similar to the docker bridge
your choice
you bringing your own plug-in and then
resource Isolators on Linux that would
be C groups right the ability to specify
CPU limitations memory limitations this
guy yo Network IO all the things that
the kernel supports you can express
those in a form of Isolators now
Isolators will be different for
different operating systems because they
mean different things then the case of
Linux you're basically just describing C
groups and then logging it also
specifies that the the runtime is
responsible for handling logs for all of
the pods and the containers running in
them then there's a set of tooling so
the
fault tool that ships inside of the
application spectra posit Ori it's
called AC tool and what AC tool will
allow you to do is build a container so
let's say you have a CI system and
you're building your application what
you can do is line up the root
filesystem for your app put everything
in place with just regular move and CP
commands and you end up with this
directory structure and what you do is
you add in a metadata file describing
how that particular application should
be executed and your run AC tool build
and then spits out something a CI or you
can do this with just command line tools
you can just basically do a tar and gzip
on that and that's the same effect the
next thing you can do with the tool is
also some ad hoc things let's say you
pull down a CI you want to look at it to
manifest you can print it out from the
command line to see what the user's
intention was you can also validate
these manifests so again standard tools
to pull the manifest out using tar just
to fetch a single file once I have that
single file I can validate that manifest
or you can validate your manifest before
you build your a CI you can also
validate the the actual a CI as you
build it and there's other tools for
validating discovery endpoints and make
sure you've done it right and finally
the AC tool can also be used to validate
a implementation of the spec itself
right there's a couple AC eyes we can
use to give to an implementation to
exercise the C does it actually
implement the spec correctly another
piece of tooling last one I'll talk
about is docker to a CI right so Dockers
ecosystem is vast right that's where the
majority of the containers live and
there's between Dockers image format and
app C they're so similar that we can
pull one down on the fly and convert it
so you have multiple options so if
you're running let's say rocket rocket
we'll take a docker in point grab that
container convert it on the fly and just
execute it sometimes you may want to
switch things up a little bit so you in
my case and we'll see in the demo we can
use dr to a CI to download the docker
container from in this case from the
queda io registry I'm pulling down this
container and you just notice that my
container is pretty tiny it's like seven
point eight Meg's just a binary and it's
compress form and then it starts to
converting it to an AC I so it
all the layers and a nice thing about
this tool it works on any OS where you
can you can run this go binary so from
my Mac I can actually download all the
docker layers but what will happen is
it'll start converting things so in your
docker file if you use the volumes
directive dr2 AC I can pick up on that
and actually create all the metadata
pieces we need to represent the volumes
that you were needing your AC I
automatically for you and then it just
pops out the result and will actually go
through this so the other part of a CI
or application container spec was we
wanted to have multiple implementations
in order to have a really validated spec
you need more than one implementation of
it so there's a couple of libraries FC
being the one that we use inside of
rocket and there are some C++ libraries
and there's also some runtime
implementations so very shortly after we
published a spec someone came through
with the freebsd jails and ZFS
implementation of ab c-- i was really
awesome and they did this independently
by just following the docs on the site
chroma which is a container management
orchestration tool from a company in us
call f Sarah and that's pretty
interesting they have this container OS
that basically runs application
containers but was designed to be like
this cohesive whole so it's just a
clustered OS by default and they just
chose to use app C because it was
specified enough for them to avoid
implementing their own thing and follow
standards that were already published
and of course rocket one thing about
rocket and its runtime implementation a
lot of people don't know at a very high
level there are some details there that
have a high level what rocket does is it
takes these root file systems and we
have these things called different
stages stage zero stage one and stage
two what stage 0 our job is to download
all of those a CIS and construct a file
system so you can imagine doing this
where there's a Java a CI that just has
your JVM there's another a CI that
actually has like your war file your
application and maybe some other things
that need to run on top and what we can
do is we can construct this and lay it
out into a final boot file system and
what we do in rocket is we take that
root filesystem and we give it to system
D and
but and let it manages the process for
you and the way we make it work with
system D in spawn or system D in general
is we look at your manifest and we can
automatically generate system D unit
files for you and say that here's the
execution point here's the commands you
need here's all the by mounts you need
and we can turn it over to the OS to
manage your application for you so then
you inherit all the benefits of
something like system D and we'll see
what that looks like
alright so before we get to the dem
we're going to talk about rocket a
little bit and I'm gonna get hands-on
with this so you guys can fill the
actual flow for this so rocket we had to
change our name because of name clashes
with other projects so we just call it
our Katie but we still pronounce it
rocket so rocket is a CLI a tool for
running app containers on Linux that's
specific right there's no plans to make
it up work on any other platform it's
pod Linux we hope to see other
implementations on other platforms using
their native constructs but rocket won't
be that Universal tool to do that at
least today the important thing to
understand that rocket has no daemon at
all alright so there is no rocket daemon
that runs that you interact with you
know rocket runs in the foreground and
this works well with systems like
upstart and system D because they will
take over and manage the process going
forward so we have to do some really
tricky things if you have a command-line
tool that has on system store where
you're storing all your images once you
download them then you have to do things
like file system locks and advisory
locks to make sure that multiple
instances of the CLI don't start
colliding and overwriting data but we
handle that the old fashioned way faces
now one thing that's unique in rocket is
that the execution engine is swappable
so what I explained earlier was that we
use system D and system D in spawned to
take your a CI and run it ideally you
could use live container right from the
docker project and do the exact same
thing you just have to interpret the
metadata and do what you need to or in
the case of Intel they actually take
your AC eyes and run them in a very
specialized VM that runs in KVM that
gives you not too bad execution speed
in about 150 milliseconds and the nice
thing about it is you know people that
are worried about container security you
probably should be worried about
container security because it's not
meant as a security boundary is meant
more to kind of give you ice elation if
you throw it in a VM you kind of inherit
that that wall garden some people are
looking for so what Intel does is they
take rocket and add a different
execution stage one where they just
throw it inside of KVM and boot it from
there
right but the workflow feels exactly the
same you have an ACI you give it to
executors and the executors just chooses
this back in that it wants to run under
or you have the option of just running
dr. images straight up straight from
whatever register you have works just
fine in most cases and it's friendly
within its systems and cluster
orchestration tools so one thing we
wanted to do was make sure rocket was
small enough to be something you build
platforms on top of the good news is a
lot of the work we've done in rocket and
the collaboration that we're doing with
the docker team is to try to get some of
the same modularity inside of docker so
it'll be nice if you can take docker and
run it without the daemon or maybe take
docker and run it with only the build
steps right or have docker do something
where it just runs in the foreground and
allow something like systemd to take
over and then pods are that unique
concept again you can run one of them
more containers in a single execution
unit and if you do that those pause gets
shared namespaces and optionally volumes
so we talked about system D and here's a
little bit more detail Intel calls their
implementation clear containers right
Intel has done a lot of work and
investment in getting VMs to be fast
with their vxt extensions and all the
security that they they've done around
it so what they decided to do was to
take allow the other technology that you
find in the kernel and they actually
figured out a way to speed things up so
most VMs today boot in I don't know
seconds sometimes minutes depending on
your platform but seconds are really
slow in comparison to what you get from
a container runtime like docker or
rocket so what they've managed to do was
figure out how to build a very thin or
Wes just enough
to get you to docker right even skipping
the BIOS boot process because they don't
need it
right they know that you're not going to
be trying to run a full system there so
you just skip the whole thing then you
go straight into the kernel into docker
and you run the container doing that
allows them to get the overhead way down
so you're gonna have an additional 18 to
20 Meg's of overhead on memory but you
get all the things that were used to
before so if you have some kayvyun
management tools guess what they just
work if you have that fancy overlay
networking thing that you were using
with KVM it works when you open the
stack management tools with rocket will
just work and the same thing can
possibly be applied to docker by
building another execution back-end all
right so here's how rocket works at a
very high level so remember I said by
default you have to trust the images
that you point out now there is a flag
where you can skip the verification but
we try not to promote that idea we want
this idea where in this case if I want
to download this kubernetes set of
binaries or a CIS I need to trust the
public key first right key distribution
is a problem trusting keys from people
other problem but once you do trust
someone this is how you add it to your
store so in this case I'm making this a
root key saying you don't want anything
signed by that key I'm willing to trust
now you can scope this down and say you
know what I trust that key for a single
AC I image that's it or maybe from
anything from a specific domain if you
want to just download an AC III and
verify it
you run the rocket fetch command and
once you've downloaded a few of these
things you can call the images to see
everything that's installed on your
system now one thing to keep in mind
when rocket downloads in a CI we store
it by its hash right so a lot of people
are thrown off when you take a container
and you call it I don't know
0:19 and you push that tag up well
anyone was free to just overwrite that
tag again right and guess what 0:19 is
this new thing it was something else
yesterday but it's this new thing
today and that will throw you off
because it doesn't behave the same way
even though it has the same name so in
rocket when you go and fetch a container
we take that we get the we make a hash
of it sha-512 and then we store it in
the content addressable store meaning
that when you want to run that thing
again we look up the index and we run
that hash that's it we're not going to
go fetch something because it has the
same name we don't match that hash we're
not running it if anything is thrown off
with the contents on this it's gonna be
broken
alright this gives people a little bit
more security and reliance on what you
actually have the great news is in
dockter's v2 spec they're planning to do
the exact same thing so if you've seen
some of the work in dr. V 2 you can
actually address containers by - they're
hashes now right so this is very key to
actually having kind of this immutable
infrastructure or something that you can
actually trust so that's excellent to
see now when you want to run a pod when
you launch a pod even though you're in
this case I'm running a single container
they still run in a pod here's what you
do now this is kind of our bose rocket
does have config file so if you didn't
want to specify this on command-line can
actually put it in what we call them pod
manifest so it's basically like adjacent
description of all the flags that you
need to pass all the volumes and then
you can just pass config files to rocket
instead of all these flags so here I'm
showing it this way for simplicity so
inside of our ACI we specify that we
need some volumes and then at runtime we
map those volumes in and we have to be
specific the volume comes from the host
we can also mark them read-only very
similar to the way doc handled volumes
and then here again we're specifying the
ACI that we want now remember once we
use this name and we do download an ACI
future runs we'll use the hash instead
going back out to the Internet and then
the rest of these are the flag passed at
the entry point into the container very
similar to what you do in docker and
then if I want to list the things that
are running we run the list command you
also have the ability to use the other
systemd commands like machine CTL
because when we run a rocket container
we register with system D and all the
other OS tooling just works dry
all everything else in the OS is fully
integrated and then finally when you run
a lot of containers I don't know how
many of you run into this you're running
containers containers cuz Kenyans they
die they come and go they come and go
and then you do like docker PS - a and
you're like whoa who did that right and
then you're not really sure on which
ones you can delete because you might
delete one that's actually still being
used by someone it's hilarious when you
do that so what we do in in racket we
have this we basically took a very
simple approach to garbage collecting
the containers we're like okay if the
container isn't running anymore and it's
being referenced by no one else then we
just do this one part where we sweep we
just say hey we're gonna are we mark all
the pauses we move them into a different
directory on the filesystem
implementation detail but we just mark
them and it gives you time to like hey
maybe start it again and then we have
some policies so by default every 30
minutes we go through everything that
has been garbage collected or marked let
me sweep them they go away and we did it
in a way where you can actually run that
command inside of a cron job right so
you would mark them on your timetable
you sweep them on your timetable or you
can just do them manually again there's
no daman so you're free to figure out
how you want to do this and then this is
how you run rocket with systemd upstart
would look something similar so this is
a normal system d-unit
so instead of running a binary here we
run the rocket command that we saw on
the command line earlier and then you
get to use the rest of the system D
process management meaning restart
policies all the other error checking
and another big one to me that I think
is really powerful most people overlook
is the ability to depend on another
service right like do not start this
service unless this other server starts
all right so system that you kind of
gives you that for free we're not going
to try to implement that in rocket let a
better process manager handle it and
then you just use your normal system
tools right so on the first boot this
thing will be downloaded stored in the
content-addressable store validate it if
everything checks out it will run if not
it will fail and system D will tell you
hey here's the error we got from rocket
invalid container it won't run
all right so that's the overview of epsy
and rocket so we're gonna try to do now
is run through the conversion of some
docker containers we'll look at the
darker files and just see what it takes
to make them a CIS right and I'm going
to try to pick a complex set of things
there's a project called cover nays by
Google that allows you to manage
containers and scale so what I've done
is and I like to use docker a lot
actually so I've made docker containers
for each of these things all right so I
did it in a way where I actually used
something like composed to spin up a
full kubernetes cluster you're
interested in that you can check out
those details but what we're going to
focus on here is basically I created a
bunch of docker containers that look
like this right very simple I do my
build and CI because I don't like big
bill containers so I take my artifacts I
copied them into place and what i'm
doing here is specifying every single
volume that I plan to map in in the
future I'm doing this to give hints to
the ACI tools for conversion right
because without this I will have to do
some weird things and I'll show you some
of those issues the most complicated
docker file that I have in this whole
stack is the couplet the couplet is
interesting because it interacts with
the host and it needs to do some weird
things to the host and it has a little
bit of trouble running from a container
I need to know the host is release I
need to actually be able to inspect
things that Dockers doing I also need to
run some binaries that live on the host
and I need to do some hackery I need to
use NS enter to enter the namespace of
the host so I can do mount points there
so that way when things are mount it via
docker back in other containers it still
works so this is pretty complex image
that when I run it I'm going to have to
mount a few things in so I specify all
the mounts now you guys know what
building duckers images look like so
once I have all my images built and well
this is the part where we'll do a bit of
a walkthrough so what I want to do is
take all my AC eyes that are running in
Quetta AO and convert them to a CIS
alright so the way we do that
is will use the docker to a CI tool so
I've downloaded them in case Wi-Fi
doesn't work but we'll try a couple of
them so you can see the idea here so
we'll start with let's do the API server
so what we do here is we run the docker
to a CI command and we give it this
prefix you know docker colon colon I
mean colon slash slash that knows it
needs to go out to docker and what will
happen here Wi-Fi please work is will
start downloading each of the layers and
once we have them all on disk we'll go
through the conversion process meaning
we just want the root filesystem have
you ever looked inside of a docker image
there's a bunch of other little root
file systems that make up the different
layers we take all of those and just
combine it and basically flatten the
whole thing out
we rip out the metadata from docker look
at its JSON file and we convert it and
map the keys that make sense and then we
end up with something like this right so
once you have one of those you can use
AC tool to cat the manifest let's see so
there's a couple of commands here we can
cat the manifest we can do some
validation to make sure the thing that
actually converted it actually works if
we want to we can cat the manifest file
come on manifest and then we're going to
print it print it so we can actually see
what it looks like without a mess of
drat
Jason on my screen and we downloaded the
couplet so that's Kelsey Hightower and
coop API server and that's what the
conversion looks like right so the tag
we got from docker ended up being our
version the name is queda IO I actually
don't like that name so I want to change
this right but I don't want to manually
go in and rip this thing down and put it
back together so what we can do is use
the patch command so I can actually
patch some AC eyes so here and I'll just
put this on the terminal so you can see
it a little better we can call the AC
eye patch manifest command I can rename
the AC I
and that's all I really want to do for
this one and what's happening here is
the a/c is being ripped apart the
manifest is being grabbed out updating
some values that we want and is being
put back together now those are all
pretty simple but the one that's a
little bit more complex is the actual
couplet one mountain point that I can't
do in a CI or that docker won't allow
you to do is mounting an Etsy resolved
comm all right that's added at runtime
by docker if you try to specify that as
a volume docker won't allow you to build
a container so what I have to do is do
it after the fact so I'm going to patch
that in using the patch command so for
the couplet we'll run this command and
we also need to run it as a privileged
container now in Dockers manifest
there's no way to say that this needs to
be a privileged container but in a CI I
have to specify this so in order to do
that I can specify mount that I need to
get resolved comm and I can actually
specify a few more capabilities here so
once I have that I build my new
container and if you notice I'm actually
renaming all of these containers as I go
through this right so I'm stripping off
my prefix from the registry so I'm going
to go through really quickly and convert
the rest of these and once I have these
done the next thing we have to do we
have to sign them right so signing is
pretty straightforward you do everything
with GPG so if you have experience with
GPG what we can do is we're going to
export the public key for my signing key
and this is so I can host it on my
endpoint so that's the public key that
we can trust later and then we can go
through and start signing our a CI so
I'm just gonna use this for loop we're
just going to go through for each a CI
we're going to output a detached
signature for each of those things right
so we're going to sign them all now this
may blow up because I haven't converted
all of my container alright a CI is over
let's see what happens
all right good it's signed the ones that
were in place so now I have the test
signatures for all of the a CIS right so
those are all the artifacts I need now
once you have those artifacts I'm just
going to store them in a file bucket
I'll Google compute right so this is how
you distribute them so you build them
you sign them and you host them to where
you want now rocket does support I think
things like basic auth so if you want to
put them behind some authentication you
can do that and that back end is
pluggable so you can add other
authentication mechanisms so here I'm
hosting everything that I need the next
thing we need to do before we can launch
these containers is we need to trust the
key so what we do is we hop on our
machine so here's the machine running
rocket and we tell it to trust that
particular public key I'm going to make
it a root key so it's asking me do you
are you sure you want to trust this
particular key so this is in my rocket
science signing key and what happens is
it gets stored into the key chain that
lives on the server again everything can
be done with simple command-line tools
so if you want to know all the keys that
live on your system you can LS rocket
trusted keys directory and they're all
stored in there by their fingerprint
name right so anything that has a
fingerprint that key will be used during
the validation process now once you
trust these things you can run rocket on
the command line but remember it'll be
pinned to the foreground so what you
really want to do is create system D
for all these things and I've ahead of
time put the systemd units in place so
here I have a system D unit for all of
these services if you look at it and
some of them have dependencies on others
most of the services here require that
this API server be up and running here
I'm doing a full configuration for
kubernetes
and what I want to do if you look at the
controller manager it also requires the
API server so we're just gonna let
system do you work that out for us and
we're also gonna let system D handle the
restarts if this were to fail all right
and also running in the foreground which
rocket does by default
that means the journal is fully
integrated so all logs flowed through
the system D Journal rotation tender
handled and all of those things we don't
have to go look for logs for our actual
containers once they start running so at
this point we can just start these
things so okay so we can enable them if
you want them to start automatically at
boot time or you just call the start
command for system D so we'll do this
here will do the controller manager it
really doesn't matter what order I start
these in mainly because the actual
binaries themselves are smart enough to
wait for the dependencies to come up
well start the scheduler and then we'll
finally start the Akula itself all right
now you can from here on out you can
actually use system D commands to figure
out things about your processes manage
them that way if you want or we can use
some rocket commands so I can do rocket
list and I see that all of my containers
are actually running we also have
integration with machine CTL so we can
list them and the Machine CTL right you
know rocket does it registers all of
your containers with system D and then
you can start using the Machine CTL
tools and they're all addressed by this
hash and once it's up and running if
everything is working correctly we
should be able to see kubernetes
actually working and it does we can
actually see that one of the nodes got
registered in the system so what we've
done here is we've taken a set of docker
containers we've converted them to AC
eyes
we signed them we patched them we put
them into an upstream repository we
created some system d-unit files for
them and then we reference those ACIS
that we built earlier and now we throw
them in system D units and we let the
system take over and manage our services
just like we were doing before like rpms
or static winters distro and now we have
a full crew Bernays single no cluster up
and running so with that I like to
conclude the presentation and open it up
for questions thank you
I'll take that first question is that
the person that creates image that signs
it or is it the repository that signs
the image you see what I mean so the
question was who's responsible for
signing the image you always want the
responsibility be the person that's
distributing and building the image
right that's the trust relationship you
want to have so not with the repository
because who is the repository right a
single entity signing all the images
number one if they didn't build the
image or it didn't originate for them
it's really hard for them to be
responsible so ideally if you can get it
closest to the person that's actually
building or compiling or writing the
software that's the entity that you want
to trust yeah so Trust is hard right
like if you want it so the question was
follow-up question was then you need a
key for every follow-up image so there
may be a world where you do have someone
that will curate content you know
there's nothing stopping someone from
becoming the centralized distribution to
have some type of qualification process
to say hey we vetted these things and we
trust them and then you establish trust
with those entities just they're
detached signatures they can be resized
all right so you can have many
signatures for them right so since it's
not baked into the actual image you're
free to go grab these things and resize
them for your own entity and say yeah we
trusted the person we've downloaded it
we validated it now let's move it into
our own repository and we'll reassign
them with our key right and then you
trust that kids that good question
yeah so the question is all the commands
that I've been running so far like this
rocket list command require sudo right
and the question is can you run rocket
as an on route user on a system so we're
working on that the main issue is that
access to the cats where everything is
stored so if we look under of our live
rocket this is where all the content
adjustable stuff is so all the blobs all
the hashes and that's a secure location
and the only person right now that we
allow to read that is route so we've got
to figure out a you know way how we can
divide these privileges up right so what
we want to do is have the ability to
download content as any user view only
probably as authorized users but then
runtime will require the permission
needed to run a binary on the particular
system so today right so this is what
we're this is what we're getting at if
we can just we can we have to figure out
what that model looks like for from a UX
standpoint it's easier to centralized it
all but you can imagine a world where
there's like containers that get
installed locally into your user
directory and they only lived there
right so since this file system base
there's really nothing stopping us from
saying here's one set of trusted keys
here's one set of calves for all the
images and that's just local to your
particular home directory and then
things launch and live there only right
so we set ourselves up to be able to do
that right it's just a matter of
priority good question
any other questions cool well fantastic
thank you guys for attending
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>