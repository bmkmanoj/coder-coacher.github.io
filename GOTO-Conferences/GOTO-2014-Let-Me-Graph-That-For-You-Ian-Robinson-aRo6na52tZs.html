<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2014 • Let Me Graph That For You • Ian Robinson | Coder Coacher - Coaching Coders</title><meta content="GOTO 2014 • Let Me Graph That For You • Ian Robinson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2014 • Let Me Graph That For You • Ian Robinson</b></h2><h5 class="post__date">2015-05-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/aRo6na52tZs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name's Ian Robinson I'm a developer
at neo technology and neo are the
commercial sponsors for neo4j which is
an open-source JVM base craft database
so I'm gonna be talking today about
graphs and graph technologies graph
database technology and the way which
they can be used to solve some really
interesting interesting data problems
data challenges so I'm going to start by
reflecting a little on the rise of graph
and graph technologies over the last few
years
then I'll briefly discuss the graph
database I'm most familiar with which is
near for J that's the thing I work on
day-to-day I'll describe its data model
and then I've got you've got some
working examples different applications
where we'd only things like
recommendations for word analysis route
planning so some some examples to show
you how some of this works so I think
it's a really interesting time to be a
developer yeah probably more so than any
other time in the last ten years and
that's partly because there are some
really interesting technologies and
architectures out there for us to use
and to play with but for me it's also
the fact that we're using software in
more interesting ways today we're
applying it in ways that generate some
really interesting and useful end-user
value so if you think of what we were
doing about 20 years ago as an industry
we were creating calculation engines
effectively you know pieces of software
that would calculate payroll or
calculate sales tax or manage your
inventory you know stuff that just
whether there's a right or a wrong
answer you know there's a right answer
when your calculation tax and there's a
wrong answer if it's wrong answer you've
got a bug okay
so we're developing all this kind of
stuff calculation based and it's very
much within the confines of the business
it's software that's being used lines
line of business applications that are
being used inside the business you think
how things have changed over that those
last 20 years and in particularly the
last ten years there's probably not a
day goes by when each of us doesn't use
a lot of software
as part of our life let's start working
lives but you know our home lives our
social lives and so on you know so
software today is deeply embedded in the
social and cultural and economic fabric
of our lives and it's doing quite
different things it's not just about
applying strict calculations you know we
use it for connectiveness to connect to
one another but it also has this kind of
suggestive and inferential
characteristic to it as well you know
even just simple recommendations engines
they're not calculating a strict result
they're suggesting to you these are some
things that you might be interested in
in the future based on what we
understand about you today so companies
are discovering there's a lot of value
to be made from being imprecise from
being suggestive rather than strictly
applying a calculation and saying this
is the right answer and they're all the
wrong answers so that to me is a
fundamental shift in the way in which
software impacts our lives and the way
in which it's embedded in our lives and
it's no longer taking place within the
confines of the business within the
enterprise it's there in everything that
we're doing many of the devices that we
use day-to-day so I work in a corner the
software industry that in the past has
been a very very niche area grass and
graph databases I mean again five years
ago if you heard of graphs it was
probably within the boundaries of the
university it's just an academic topic
you may have studied it as a data
structure and algorithms in computer
science and then there's lots of other
kind of graph based research around
social networking and stuff like that
but again all of that confined to the
university but actually a lot of that
software that we use day-to-day that has
a real impact on our lives is driven in
some form or another by graph all of the
really big web properties today Google
and Facebook and Twitter depend upon
graph for graph search Facebook's graph
search Google's knowledge graph the
Twitter the social graph all of these
things have an impact on our lives today
thank you
so graph has come out of the academic
realm
and it may not be frontmost in in all of
your interactions with that software
other ways in which you conduct
yourselves but it's there it has a
strong but hidden influence over all of
the things that you're doing today so
what is it about graphs and graph
technology that mean that it becomes
such a dominant or biet hidden force in
a lot of the things that we do today
well for me it's at the highest level
you know in the most abstract level when
I when I survey a lot of the things that
I've done over the last few years where
we've been using graph databases it's
about managing complexity in complex
data the data that we have today or
rather the ways in which we use that
data is more complex than ever before
and for me that complexity is a function
of at least three things it's a function
of increased data size an increase in
variable structure and an increase in
connectedness when these three forces
come together we're dealing with
extremely or particularly complex data
large volumes are variably structured
densely connected data this is complex
data because the questions that we ask
of it require us to manage this variable
structure and requires to understand
somebody's connectedness so we all
probably know about increased data size
about big data and we're generating more
data than ever before the volume of net
new data that we're generating year on
years growing exponentially and that's
that's a trend that's going to continue
for the foreseeable future
you know we're generating data with
every device that we use we're
interacting with business partners we're
consuming data over the web you know
every application that we build is
generating large volumes of logging data
and all that's important to us today you
know every path through our website that
a customer takes again generating this
enormous volume of data so that's one of
the forces that we're having to contend
with today and that's one of the forces
that's given rise to that larger family
of no sequel databases you know having
to deal with in enormous volumes of data
and manage it take account of it and
query
but then there are these two other
forces variable structure and
connectedness now Veritas dr. is
something that's been with us for a long
time variable structures that kind of
messy real world data that doesn't
always fit into a one-size-fits-all
relational schema and for me variable
structure is actually a function partly
of increased data size you know the more
that we learn about the things that were
interested in the more we learn about
the things in our domain that we're
interested in the more each of those
things begins to look subtly different
from every other it's at a very high
level all of our customers look the same
they've got a first name and a last name
and so on but the more we we find out
about them the more they tell us about
themselves or the more we discover about
them more each of those customers or
those users begins to look subtly
different from every other lots of
different attributes some of them shared
some of them unique to particular
individuals and we want to try and
capture all of that and and take
advantage of it how can we do that well
in the past we're using relational
technology we might apply all the normal
forms and we end up with you know
several tables that we would join to our
central user table in order to
accommodate all those different
attributes consider for an example all
the different ways you could identify me
on the web I've got a Twitter handle
contact me on skype I've got a couple of
email addresses there's some of the
attributes that are particular to me
some of you may share some of those
identity pieces of information you know
your own email addresses your own
Twitter handle you might have other
things that identify you on the web as
well Facebook account LinkedIn accounts
and so on if we were going to
accommodate all of that variation in
relational we probably pull it out as a
separate contact table and then join it
to our user table which is great we can
we can accommodate all of that variable
structure in the relational database but
then the point where we're going to
production you know we just want to
discover some simple information about
user we have to join eyes have to join
and join and join again in order to
bring all of that information together
and present it on the screen or present
it elsewhere within our application and
there's a performance penalty to doing
that
you've got an enormous customer base and
you're joining over and over again order
your queries are really going to slow
down a go to deteriorate so what we do
in the relational world to accommodate
all of this variable structure is we D
normalize and we create these very broad
sparse tables tables with lots of
nullable columns all those columns
represent the super set of all possible
attributes that that we know about with
regard to our entire customer base and
then for any particular row in that
table
we'll fill out the columns that are
relevant to that particular user and
we'll null out all the others so to deal
with variable structure we have sparse
tables with nullable columns lots of
null values and then in the application
we have to have lots of null checking
logic
so that's variable structure and then
the third thing here is connectiveness a
lot of the really interesting questions
that we want to ask of our data today
require us to understand how the things
in our domain are connected we need to
understand that two things are connected
either directly or by way of some
intermediaries and more than that we we
need to know not only that two things
are connected very often we need to know
something about the strength or the
weight or the quality of those
connections we want to ask and answer
some really interesting questions we
need to know if things are connected and
we need to know something about the
strength or the weight of equality of
those connections so I mean this
examples from from different domains
that I've worked in over the last few
years where we had to manage large
volumes of variably structured and
densely connected data and where the
questions that we're asking or that day
to require us to manage that structure
and to understand elements of that
connectedness so social networking is
the obvious poster child here where
you've got lots and lots of different
people within that network they're
connected in different ways you know we
may we may be connected by way of work
we may have a strong friendship that
goes all the way back to childhood
different ways in which we're connected
we need to understand the semantics of
those connections and we need to know
something about there's this strength of
those connections as well the quality of
those connections and then we can
discover not only
you're friends with friends of your
friends and so on and this is the area
that is probably the most well known
with regard to Graf I mean Facebook
could popularize that notion of of
social graph but it's also the area that
is probably best understood within
academia as well tens of years of
research into smaller communities social
networks and some of the behaviors that
are transmitted within those social
networks the way in which things like
the propensity for obesity or the
propensity for smoking can actually be
transmitted at depths two or three
within the network you can actually be
influenced by people you don't even know
by the friends of the friends of your
friends so that's one area in which you
know these these technologies being
applied today others are things like
Network impact analysis modeling the
entirety of a telecommunications network
from the customers and the applications
and the services the machines the
virtual machines the data centers all
the way down to some of the lower level
Network elements fibers the root is the
switches modeling all of that and then
be able to do rapid impact analysis
against that network structure being
able to say well given this important
customer of mine which parts of the
network does it actually depend upon
which machines well which applications
machines which lower level Network
elements do they depend depend upon do
we have redundancy throughout the
network on behalf of these customers and
if we don't what can we do to introduce
it or to mitigate against the the
network failing on their behalf it's
kind of top-down analysis you can do
bottom-up analysis as well given this
low-level network element this Rooter or
this switch who's it going to impact if
it fails or if we have to replace or
repair it and if we're planning a
replacement or a repair program where we
want to replace multiple pieces of
hardware at the same time part over the
course of a weekend are we going to
maintain redundancy on behalf of some of
those those customers or we're going to
break the network on their behalf so
these against some of the kinds of
questions that you can ask about a very
structured densely connected beta
structure
I won't go through all of them in too
much detail in fact a couple of them
were gonna pick up in the examples later
the other things here that I will
mention briefly route-finding you know
this goes all the way back to the
foundations of graph theory so 400 years
of graph theory much of it about
route-finding about finding the shortest
path through a network being able to
apply shortest weighted paths traversals
across the network given a couple of
stations on the London Underground for
example what's the the most efficient
route to get from one to the other and
in order to be able to answer that
question we need to know how the
stations are connected within the
network but we also need to know
something about the quality of those
connections how many trains are there
per hour or per minute how long on
average does it take to get from this
station to that and then given those
properties we can very easily calculate
that the shortest weighted path and
determine what's the most efficient or
effective route through the network
so for me graphs are great at managing
that kind of complexity large volumes
are very structured and densely
connected data where we need to
accommodate all of that variable
structure and we need to understand
something about the connections and the
paths through the system in order to be
able to answer the questions that we
need to so I work with near four jfj is
a database it's a JVM Bates graph
database that allows us to to model and
store and query our data in the form of
a graph so we'll model our domain as a
graph we will store it as a graph and
then we will create a query it as a
graph when we're querying it we look at
we're either looking for existing graph
structures we're saying finally this
graph or this sub graph structure within
the existing data set or we're creating
new graph structures we're saying I want
you to create this graph or this sub
graph structure within the data set so
it's graphs from top to bottom model
store and query your data in the form of
a graph and we employ a very particular
graph data modeling neo4j
it's got a very pragmatic approach to
modeling grants and it just comprises
four fundamental parts four primitives
really in our data model that you might
then use with you're building your own
application and you're building your own
application graph data model you'll
apply these primitives in order to
develop app data model
so those four primitives are nodes
relationships properties and labels and
I've got an example of our data model of
what we call the labelled property graph
here a very very smooth graph I mean
it's only six nodes and so on whereas we
can actually accommodate billions upon
billions of nodes and relationships what
was showing here are a couple of authors
a couple of the books that they've
written and a couple of people who
bought and likely read those books so
the first thing we have other nodes is
these blue ovals and we tend to use
nodes to represent the things in our
domain that we're interested in entities
anything that has identity okay so we're
using nodes to represent things in our
domain and a node is effectively a
container
set of properties through a set of key
value pairs so we use the properties we
can attach properties to a node to
represent the attributes of the things
that were interested in so you can see
that for John le carré I've attached a
name and a date of birth property for
gray and green we've got name date of
birth and the date when when growing
green died so if we know more about one
entity than we do about another we just
attach another property no two nodes
need share exactly the same set of
properties so already at the level of
the individual nodes the individual
entities we're already accommodating a
degree of variable structure so that
point we've got this very simple record
like structure little islands of data
but then we can introduce more structure
by connecting those nodes with
relationships and every relationship in
near 4j has a name and a direction and
that serves two functions really the
first thing is well it helps structure
the overall data set and again it
accommodates variable structure and no
two nodes need be connected in exactly
the same way but then the name of the
direction also lends semantic context to
each of the nodes so we understand what
each node means partly as a function of
the way in which it's connected to all
of its peers to all of its surrounding
nodes so you can see that John the Kari
wrote the Taylor of Panama and Graham
Greene wrote our man in Havana so the
name and the direction of first-class
elements within the data model and as a
developer or as a data architect you're
responsible for deciding the direction
and deciding upon the name and you don't
have to come up with a list of possible
names up front you don't have to come up
with some strict rigid schema before you
start modeling your data or actually
introducing data into the database you
can just introduce names as and when you
see fit
if you discover new kinds of
relationships between the things that
you're interested in
create a new relationship and give it a
new name so that's nodes relationships
and properties and in fact we've talked
about attaching properties to nodes to
capture entity attributes we can also
attach properties to relationships
and so to all of the purchase
relationships here I've attached a
timestamp property now whereas we attach
properties to noes to represent entity
attributes my tend to attach properties
to relationships to represent the
strength or the weight or the quality of
that relationship so again if we were
modeling a transport network with
perhaps use properties on particular
relationships to represent the number of
trains per hour or the average time it
takes to get between these two nodes
these two physical locations and then we
can take advantage of those property
values as we're traversing the graph as
we're calculating the route through the
graph and then the fourth element here
are these labels so you can see that
every node in my example here has one or
more labels labels are effectively a way
of tagging each node and we use labels
to help represent the role that a node
plays within our data set we can see
that this node here bottom-left
represents both a person and more
specifically an author and the labels
can never give us a very simple grouping
semantics I can say to the database find
me all of the nodes labeled book I just
want to get all of the knows than a
labeled book it's effectively all the
nodes that represent books in my system
but I can also use the labels to
associate a couple of different
behaviors at the level of the database I
can associate indexes with labels I can
say look every node that's labeled book
I want you to index it based on its ISBN
property so that I can kind of parachute
into the data set and recover a node
with a specific ISBN property value so
it can associate indexes with labels and
then any nodes bearing those labels will
be indexed we can also associate unique
constraints with labels so I can say
look every node that's labeled book I
want you to ensure its ISBN property is
unique within the context of this data
set so labels is something that we
introduced quite recently I mean near 4j
itself has been around for 10 12 years
actually you know it's actually a quite
an old piece of technology but labels is
something very new within are they
reflectively making it easier for you to
represent the role that something plays
and we're making easier to associate
optional constraints to layer optional
constraint on top of the data model so
today those constraints are things like
unique constraints in the future that
we've slightly more sophisticated so the
question is can we index the properties
on relationships and the answer is yes
not as easily as we can index the stuff
on the nodes but we can index
relationship properties we're currently
in this kind of hybrid situation where
we have slightly older indexing
implementation that still allows you to
index the properties on the
relationships that that functionality
hasn't made it through into they're the
kind of stuff that I talked about with
regard to labels but fundamentally yes
you can index relationship properties
and you can look up all the the
purchased relationships where the
property value is between these two
values for example yep so so the
question there I could also do purchased
as a separate node yeah yeah I mean
they're the techniques for for modeling
your data I mean my base advice is you
kind of derive your data model from the
kinds of questions that you want to ask
of it you design for query ability and
if there's a lot more about each
individual purchase that you need to
know you know if it becomes the locus
for a whole for a large number of
different dimensions if you need to know
when that purchase took place where it
took place who made it and so on then
you would likely turn that into a node
in and of itself yeah and then you can
connect an arbitrary number of
dimensions to it this is very very
simple base model we can very easily
evolve it to introduce nodes that
represent purchases and then again we
could index those so what I'm going to
do I mean that's
yeah the highest quickest introduction I
could give you to to neo4j
or more specifically to the data model
that we employ and as I say it's a JVM
based graph database runs predominately
today as a server product so you install
it as a server product you can cluster
it for high availability
I read throughput and you can clients on
any platform can connect to it over HTTP
we effectively exchange JSON formatted
documents with the server over HTTP and
that allows you to create and query data
inside the database what I'm going to
show now are some specific applications
that technology the ways in which people
are using it today in order to do some
of this more interesting interesting
inferential predictive stuff and then
we'll look at towards the end some
things that are based more around
calculations but actually based around
interesting kinds of calculations route
based calculations and stuff like that
so the first thing here is making
connections so I'm going to start by
discussing it's probably the synced list
of concepts in graph theory but it's
also one of the most powerful and it's
something that's actually applicable in
lots and lots of different domains it's
something called triadic closure
that's what's triadic closure well what
we observe is that in a lot of different
kinds of networks but particularly those
networks where there's some kind of
human agency things like social networks
we observe in those networks at a very
local level specific elements in the
network try to form stable closed
triangles if you observe the evolution
of the network over time you'll notice
that this very very local level
individual elements within the network
will try and form these stable balance
triangles hence the term triadic closure
now try make this a bit more concrete
we've got a very very simple social
network here tiny little social network
Terry Bell and Sarah okay so you can see
that Terry and Sarah have a friend in
common bill they don't currently know
one another or as far as we're aware
they don't know one another but because
of this mutual friend there's a higher
chance than normal that at some point in
the future Terry and Sarah will meet one
another or become aware of one another
and may in fact become friends so
there's a greater than normal chance
that at some point in the future we will
close this triangle
the Terry and Sarah will become friends
because they have both the means and the
opportunity no they because they both
know bill there may be occasions where
they're both with bill and therefore
they get to meet one another and because
they're both friends with Bill and they
they're most likely trust bill they
probably also trust the people that
built trusts so they've got the means
and the opportunity to meet one another
the means and the motive yeah so that's
triadic closure so we can't really take
you know this is this is a very commonly
observed behavior within networks in
particular social networks and other
kinds of networks where there's some
kind of human agency we can take this
this this behavior and effectively use
it as a very simple predictive tool okay
here's Terry Terry's got a friend bill
as we've seen bill has this other friend
Sarah well instead of waiting for these
two people perhaps to to meet one
another or become aware of one another
establish that friendship
why don't we suggest that they get to
know one another
why don't we recommend that Terry meet
Sarah Sarah meet Terry you see this all
the time you probably see on Facebook
you see on Twitter these are the people
you might want to connect with you see
it as part of recommendations engines
people who purchase these kind of things
also purchase that the people who
purchase the things that you've
purchased have also been buying this
kind of stuff okay we're identifying
opportunities for closing the triangle
so let's have a look at a tiny little
social network okay so I've got a
version of neo4j running here a server
version of me okay when you run near
future as a server
you get this nice little web-based admin
tool it's effectively a repla allows me
to write queries and it allows me to
view the results of those queries so
let's look at the overall network that
I've created and I'll talk through you
know we've got this query language I'll
talk through a little bit of that in a
moment I'm not going to go into it in a
great depth but you can see is it okay
from the back and there's a bit blurred
a bit pixelated
see I put a social network here I don't
know quite how many people have got 10
15 or so you know and a number of
different friendships
let's find Terry just Taryn
you can see that Terry's got some
immediate friends and then each of those
friends has a number of friends as well
some of whom already know Terry and some
of whom don't okay what we can do we can
okay
Terry's our current logged on user he's
the person we're currently dealing with
let's try and identify all of the
friends of Terry's friends that Terry
doesn't currently know and let's count
the number of opportunities to close
those triangles and rank them and then
we're you know there are several of
Terry's mutual friends who are all
pointing you know the third party will
kind of rank them and we'll make a
recommendation based on the the highest
likelihood of closing that triangle so
the query I'm going to talk through this
query in a bit more detail in a moment
when we go back to the slides but
effectively we've got this very simple
query here
it's a tiny query yeah this is our query
language and it's allowing us to
traverse or navigate that network and to
match specific graph patterns within
that network but this is effectively
saying find me all of the friends of
Terry's friends but in particular look
for ones where Terry isn't currently
connected to that other that other
person that third party and let's rank
them and and select the ones that appear
towards the top of the list and if I run
that we can see that within that Network
Terry there's probably a strong chance
that something in the future Terry's
going to meet Henry and then a pretty
good chance it's going to meet Emily and
Coleen and so on so effectively we can
use this as the basis of a
recommendation these are people that you
might like to connect with so I'm going
to talk through that query in just a bit
more detail okay so this is what we were
looking at a moment ago this is a near
4js query language it's a query language
called cipher in cipher it's got a like
sequel for graphs it's a multi Clause
declarative language but instead of
doing set based operation on tabular
data this is allowing us to match graph
patterns inside of a network structure
and at the heart of cipher is the idea
that we can describe to the database the
kind of network structure the kind of
graph we'll sub graph structure
that we would either like to create or
to discover within the data set in fact
we want to be able to draw on behalf of
the database the kind of graph structure
we would like to find or create and
that's exactly what we're doing here
so this first Clause here match this is
where we're describing to the database
this is the kind of structure I would
like to find okay and the syntax that
we're using here is a kind of
pictographic representation of a graph
so we're using parentheses to represent
nodes okay so we've got a node here that
represents Terry and another node here
that represents all of well absolutely
represents the friends of Terry's
friends but you know this thing here
represents some other nodes out there on
the network in between we use dashes and
very often we'll use greater than and
less than signs but we use dash is to
represent the relationships and we put
the relationship name between these
square brackets so we're creating a
little very simple pictographic
representation of a little sub graph
structure that we want to discover
inside the data set and this part here
is saying look we want to find any node
that is labeled user that has a name
property whose value is Terry now
actually in a large data set there may
be very many with lots and lots of
Terry's so actually we've probably be
using a property value that is more
unique that's Terry's email address or
their you know some other unique
identifier this is my simple Tory data
set but if we found multiple people who
match this thing they'd all get bound to
this little variable here this is this
this identifier anyway we're saying find
me the node that represents Terry and
then I want you to match all of the the
friend relationships that connect Terry
immediately to his friends and then I
want you to go to depth to I actually
want them to match against the friends
of Terry's friends so this is what we
call a variable length relationship
match well actions not variable and it's
strictly defined it's saying match
outgoing friend relationships and then
whatever you find at the end of that
match further print relate
beyond whatever we discover at depth -
we're going to call other does that make
sense so effectively we're describing
this little pattern this thing here is a
way of drawing this picture there's a
node that represents Terry which we're
going to use a variable for the purposes
of the query are going to call it the
user we're looking for friend
relationships we're not so interested in
Terry's immediate friends we're
interested in the friends of his friends
these others and then this where clause
is saying yep we're interested in all
the friends of Terry's friends but only
so long as there isn't an existing
connection between Terry and that friend
of a friend
so we're saying where this kind of
relationship doesn't currently exist so
we're definitely looking for those
opportunities to connect the triangle
triangle doesn't currently exist but you
know here's the opportunity to do so
okay so this is the structure we're
looking for these things have to exist
that one and then in the return Clause
we're firstly we're counting all of the
people that we match as I say Terry's
got a number of friends and all of those
friends have a number of friends and it
may be that two or three of Terry's
friends all know the same person that
Terry doesn't so that other person will
crop up two or three times in our result
set so we're counting the number of
times each individual occurs in the
result set and we're a listing that is
their score and then we just created a
projection of the overall results on
behalf of the client and we're ordering
it by the score highest score first so
that's exactly what we saw in the
results a moment ago yeah Terry is not
returned because those identify as those
before you know I had user and other as
temporary variables within my within my
query that has the it's kind of implicit
side effect of saying that these two
nodes are different I'd used exactly the
same name that we could effectively
match against
the dependencies yes so Terry doesn't
crop up at this point in those results
but also I mean interestingly if we're
looking for the Friends of Terry's
friends well we first of all have to go
by way of a friendship that already
exists so there's yeah I've kind of see
the point but we're definitely excluding
the fact that that friendship already
exists so that's another reason why
Terry doesn't appear in the results now
actually if we go back to the graph
itself and just briefly look at these
friendships as I said one of the
interesting things about grass is you
know they they allow us to model
connectedness and in that mirror forge a
data model we can give a name the
direction through each relationship but
we can also attach properties to
represent the strength or the weight or
the quality of that relationship and
actually here based on some information
that people have given us we've been
able to quantify or qualify each of
those relationships we're now able to
attach a strength to each relationship
so we can actually take account of that
as well in our in our queries so I've
got a slightly more complex query which
I'm not going to discuss in so much
detail but it's very very similar we're
still looking for friends you know depth
to friend of a friend but now we take
your account you can see here in our
where clause we're taking account of the
strength of that friendship and we're
only looking for strong friendships
friendships that are valued two or above
okay and that gives us a slightly
different set of results we still get
Henry at the top but actually Colleen
and Chloe appeared further down in our
initial set of results but it may be
there's a greater chance that these
people will all meet first we'll meet
Terry first because of the strength of
those friendships and we can actually
combine all of these calculations in
order to you know to come up with some
of these very simple predictive
suggestive capabilities
so that's kind of simple pattern
matching within the graph but it's
applying a well-understood principle of
of networks this thing about triadic
closure and try to close as I say is is
relatively domain agnostic it doesn't
have to be about very simple social
networks like this it can apply more
generally particularly where we have
human agency now is I could have always
run a risk when I introduced this is the
first example my colleagues say well
look you're always talking about social
networks people come away with the idea
that graph databases are just good for
social networks and my answer is well
actually there's a lot of social stuff
out there and it's not just the trite
social stuff around Facebook or yo or
stuff like that you know for years
businesses have been bracketing off the
human element and just trying to focus
on the facts but actually human
behaviors have a lot of influence over
many many areas of our lives language is
social economics is social software
development is social that's why
conferences like this always have an
agile track because agile recognizes
that social software development is a
social activity that's all that's why
there's always that kind of palliative
care tutorial or set of talks that make
you feel better about the fact that your
organization's fucked up you know the
bugs are in the people and not in the
software
so social extends far more broadly than
facebooking yo yeah and so I think you
know reintroducing social and this is
what the large web property is these are
these are the ways in which people are
generating value today they're
acknowledging the social element in lots
and lots of different things that we do
and so these kind of principles can
apply very very broadly alright so we
were cutting matching there we can
actually come up with slightly more
sophisticated patterns again in order to
do some kind of predictive analysis we
have a friend actually somebody who
works out here in Netherlands who's
doing a lot of stuff with with graphs
who says you're in a graph there's
nowhere to hide
you can hide lots of behaviors in a
tabular structure but when you're
looking at a graph though the human eye
very quickly takes account of the
patterns there's nowhere to hide in the
graph so it's very easy to discover
patterns that are otherwise hidden when
you're looking at some other data
structure so graphs today are being used
for things like fraud analysis an
example here is what we call first party
fraud first party fraud is the situation
where you've got a number of different
people fraudsters who together
constitute a fraud ring and this group
of people will create a bucket of
identity information identity
information such as Social Security
numbers phone numbers addresses and so
on and then each of the members of that
ring will pick and choose bits of
identity information from that bucket
and use them to create or to extend
lines of credit they use them to create
accounts and so on okay so you're called
picking bits of identity information in
the bucket and very often when you're
opening account you have to supply
several different bits of identical
information each application probably
doesn't use exactly the same set of
information as all the other
applications so is this kind of broad
spread with some overlap between the
different bits of identity information
and then your foresters they behave like
good citizens for a while open an
account of a line of credit they borrow
against it they pay back everything
looks fine and dandy and then at some
point whether it's some months or some
years down the line all together they
just disappear off the radar they're
kind of clear out the accounts and all
the money's gone now the only way in
which you could identify this and
identify in a timely manner or identify
your likely risk or exposure is to
understand all the connections between
all the different things in this network
the people and the accounts and all
those different bits of identity
information and then at the point in
time where somebody's applying for an
account you can assess the likelihood
that they're participating in a fraud
ring or in effectively looking for
within that network structure
our broad flowering connections yep kind
of broad widespread of connections so if
you've got a family or living at the
same address perhaps several members of
that family the parents perhaps if some
of the eldest children they may all be
open accounts and they'll all use the
same address that's all fine when you're
analyzing the network you'd expect to
see these little clusters of shared
information but if those clusters
broaden if they can flower and extend
outwards and you deal with many many
people and many different bits of
identity information or subtly linked
and interlinked in this way then there's
a greater chance that you're dealing
with Fordring so we've got a fraud ring
here you know three people from our
previous social network with a bill and
Kahlan and Lucy and each of them has are
open two or three different lines of
credit loans and credit cards and bank
accounts and then in blue we can see all
those different pieces of identity
information the addresses and Social
Security numbers the telephone numbers
and so on and you can see that each
person has used a slightly different
combination but that each piece of
identity information is actually being
shared by at least two people this is
that kind of broader spread so again
we've got the same thing here slightly
turned on its side but again you can see
the nodes that represent Lucy and Bill
and call in all the identity information
and all the accounts that they currently
hold now I'm not going to talk through
the query again into its detail but I've
got a query here
I wonder though whether I should there's
a bit more to it it's just okay this is
the query we're doing quite a bit more
in this query this is somebody this is
new person coming along who is it I
can't see at this point in time that's
it's further off the screen but we've
got a new applicant somebody appearing
as Terry is Terry again buddy Terry all
the time so Terry is applying for an
account and he's using some existing
identity information he's also supplying
some new bits of identity information as
well so the point in time where Terry is
applying for the account and we're
trying to create register him with the
system that's what we're doing in the
first half we're kind of creating new
data while we're trying to create new
data we'll try to reuse existing bits of
data so if some of this identity
information already exists then we'll
reuse it if it's new then we'll create
new nodes to represent that new
information so we do all of that in the
first half and then in the second half
of the query we then take all of the
identity information that Terry's
supplied and we kind of traverse
outwards we crawl the graph and look for
the ways in which that identity
information has been used in different
contexts and we're using that to form a
judgment again to predict to be
suggestive and inferential is this
perhaps part of a four during is this
one of these broad spreads
so it's difficult to see the query
winner the Manas is this side hence
using text me if I run that again we've
supplied all the information and now we
can see that for things like the
National Insurance number there are at
least three different people who are all
using that National Insurance number
similarly for this phone number we've
got three people and there's a bit of
overlap here we're beginning to identify
all of the different members of that
ring and the the bits of information
that are being used so this is something
that we could do at the point in time
where somebody's actually applying for
an account it's not after the fact
analysis it's not batch processing
analysis it's pointing time analysis
when somebody's actually submitting
details perhaps over the web or over the
phone and again you know we've got tiny
data set here but obviously if you're
dealing with a large financial network
you're dealing with millions upon
millions of these nodes and connections
but again you can still get lively
results and millisecond results even
when you're querying against that larger
structure because the nice thing about a
graph query is once you've parachuted
into the graph with your starting points
Terry and his identity information what
we are interested in doing is exploring
as much of the graph as is necessary to
answer the particular question at hand
we don't need to explore the entire
graph you're just looking for the
connection so you're just carving out a
smaller portion of the graph this is
very different from computing a joint in
the relational world where you have to
compute the Cartesian product of all the
possible things that you're matching and
then throw most of it away you know we
can get millisecond performance where
the equivalent joins in the relational
world might take minutes few minutes
left so one final example so both of
these have been about pattern matching
and have been very much about that kind
of predictive and suggestive and
inferential capability that I mentioned
at the beginning you know our lives have
changed over the last ten years the way
with software is impacting us is not
just about a strict calculation it's
also being predictive and suggestive and
but actually there's still there's still
a place in the software world for doing
calculations for doing something where
you can be right or you can be wrong
doesn't matter how screwed your
organization is and how many agile
tracks no milk so what we've got here is
an example of route finding in a parcel
network so near 4j today is being used
in the largest parcel network in Europe
to calculate the routes through the
network parcel enters the network and at
that point in time we have to calculate
the most effective route to the ultimate
destination we have to do that very very
quickly because the parcel has entered
the network is actually going down a
chute it takes less than a second to go
down the chute and the bottom the chute
it's going to get switched one way or
the other we have to calculate the most
effective route through the network
before it gets to the bottom the chute
and there are you know a peak times
there are two thousand three thousand
parcels per second entering the network
you know 3,000 or so Christmas time all
right and you're dealing with quite a
large network you've got 25 national
parcel centers 2 million postcode
30 million individual addresses so it's
a very large network ok so very
structured densely connected and
reasonably large bodies of data and
we've got these strict time requirements
and the other thing is the graph the
network changes over time you know there
are more trucks on the road at Christmas
time than there are during the summer so
we have to be very sensitive as to the
structure of the network at any
particular moment and looking forwards a
couple of days we need to anticipate
what the structure networks going to be
at that point in time so this is
effectively the the data model that we
have and if you've you know you if you
picked up the book from the booth you
know we talked about this example in a
lot more detail in the book but
effectively you've got national parcel
centers and delivery bases delivery
areas going down to these delivery
segments and there are there are
particular routes that connect all of
these elements and for any particular
point in time there's always one good
route between a delivery segment and
every area between a delivery area and a
delivery base but as I say over time
because more trucks on the road of
Christmas these routes change so our
overall data model is this this is far
more variably structured and densely
connected and then for any particular
pair of nodes we're kind of attribute in
those knows we're saying well this is
the you know the logical cost of
traversing this relationship for this
particular time period so with time
stamping the relationships were saying
this this relationships are clickable
for a particular point in time or
particular period and this is the cost
that applies and then based on that we
can effectively do some very very simple
shortest weighted paths traversals at
the graph and we can calculate the right
answer versus the wrong answer because
of their the overall structure of the
graph I mean there's again route finding
shortest routes and stuff like that very
very well understood in that the graph
literature and some very good algorithms
for calculating all of that in our case
we don't have checked you have to apply
many of those algorithms instead we can
kind of navigate upwards from the the
point where the parcel comes in the
point where we need to deliver it we
kind of navigate our way up the
structure until we get to some delivery
basis I know at that point we bother
applying a more sophisticated algorithm
because the parcel centers and the
delivery bases are very complex lis
connected so we apply Dijkstra at this
point in order to calculate the routes
between stuff at the top then we can
join it all together very very quickly
and come up with the ideal route through
the system yeah that's that's the last
part of the calculation so on this isn't
the the query that's actually run this
is slightly simpler just to show you how
we can do path based operations in the
graph so everything we've been looking
at so far has really been focused on the
the leaf nodes
you know the nodes at the end of a
pattern what we're interested in here
are the paths so the nodes and the
relationships and then we want to apply
calculations across those paths so the
lowest level of the data model remember
we just nodes relationships
and labels there's no notion at the
level of the data model of the path but
the query language has a very strong
notion of what a path constitutes so
here in this portion of the query were
effectively generating a path or
multiple paths between two locations so
this is where we want to start from this
is where we want to get to and we're
prepared to navigate up to depth 4 and
this pattern will match all of the
different routes that extend from this
location to that where those routes are
1 2 3 or 4 relationships long and it
will assign all of those routes to this
path identifier here so this path
identifier will be bound to a collection
of paths and then the return Clause
again is doing some calculation and
returning some results the important
part here is the reduced function so
what we're doing here for each path
we're iterating over the relationships
in that particular path so we've match
four different paths for each path we'll
go iterate over the relationships and
we'll reduce them will effectively sum
all of the the costs of those those
relationships to come up for though with
the total weight for that particular
path yep it's a simple reduce operation
and then we are returning the results
the calculations for each path but we're
ordering the results and just taking the
top one so I guess with this one if
we're doing it in ascending order we are
we're picking the cheapest shortest path
effectively or the the least costly path
based upon this total sum so effectively
that's the that's the very simple
algorithm at the heart of this and
there's a bit more on top but that's I
just wanted to communicate how you can
work with part with neo4j this is what
the overall query looks like and it
looks a bit more complex but actually
the equivalent in the relational world
you might be looking at several tens of
pages of of joins and stuff like
actually we just we've got there's three
different legs get the OP leg the down
leg and the bit in between at the top
and then do those path calculations
across the whole thing and that's going
to give us the optimal route through the
system okay so I've got a couple of
minutes left to answer some questions if
you don't already have a copy of what go
grab it from there at the booth or if
you want a pdf version and get one from
graph databases com it's free and this
is a kind of top to bottom view of the
world of graph databases starting with
you know why they useful why are they
important how are people using them
today and then chapter by chapter we dig
in deeper looking at the internals in
particular the internals of neo4j
looking at the query language and
looking at some of those examples in
more depth at that point I'm pretty much
done are there any questions that's
right yeah so within the the the data
model itself every relationship does
have to have a direction but in the
query language you can ignore the
direction so the general advice is when
you're creating your data set and you're
wanting to modify directionality don't
worry about the direction just choose
one of the other quite arbitrarily but
then in the query language as we saw the
initial queries we just ignore the
relationship direction and it works as
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>