<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Agile, Lean &amp; Rugged - The Paper Edition • Ines Sombra &amp; Adrian Colyer | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Agile, Lean &amp; Rugged - The Paper Edition • Ines Sombra &amp; Adrian Colyer - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Agile, Lean &amp; Rugged - The Paper Edition • Ines Sombra &amp; Adrian Colyer</b></h2><h5 class="post__date">2015-11-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pZVSbrTHJk0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">article are chillin and rugged the paper
edition our other working title was
Clint Riese for knowledge but we weren't
sure of how that was going to run so we
settle for this and we're going to go
for a little bit of introductions right
now my name is Anna sombra remember this
debris systems engineer with a company
called fastly where CDN content delivery
network so you come to us you give us
your data we spread around the world and
we make your application faster but I'm
not here today to talk about fastly i'm
here to talk about this organization
that i'm a part of that is called papers
we love also i speak really fast
sometimes my use of language is language
full so just bear with me agents go tell
me if I'm going super fast you're going
to be like I think it's my cue to drink
every time I'm going really fast but
papers we love I don't know how many of
you have know what papers will love this
yeah cool so I assume that maybe you
went to a meetup yes yes cool all right
so papers elope if you don't know it's a
meetup that deals with bring in but the
goal of the group is trying to bring
academic research closer to
practitioners so every month we pick a
paper somebody comes presented and
people that are interested in just
expanding their knowledge about computer
science research kind of come and then
just hear it and have a shared
experience and not share introduction to
concepts that may or may not have been
familiar to them for me it started with
a very dreaded American tradition called
a yearly performance goals so he was
2014 and I realized after a graduate
grad school I stopped reading papers and
I decided to that year to take my yearly
performance goal seriously so I was like
I'm going to read more papers and it was
January and a few days after that I
started writing my goals I noticed that
the group in New York City started a
meetup called paper to love and
obviously I'm like sold i'll do this in
a with social pressure and san francisco
was the second the second meetup that is
started and by now i think we're the
largest chapter it was a thousand 112
yesterday maybe do like who knows how
many we are right now
but I think that this group and this
organization hit a nerve because a lot
of people like had an interest for this
and now we have over 24 chapters all
over the world and London is included
and I think they meet on this building
and I think I'm crash I'm actually like
ruining their meetup because I'm here so
yay so now I give it up to Adrienne okay
guys I'm my name is Adrian I will try
and bring balance by speaking a little
slower for you Adrian should be easy to
remember I'm also in the VC game i work
with accel partners thankfully the other
adrian has proved that you can do that
and still be technical so I'm just going
to follow in his path you may know me
from former CTO roles springsource being
where pivotal etc but really the most
relevant thing for tonight was actually
a blog that I right which is called the
morning paper which started just over a
year ago I began reading a CS paper
every weekday and let's see from the
eighth of October last year I had to
look it up I've been writing up a review
of that paper every day on this blog
called the morning paper which has been
a really interesting journey kind of
just a sort of imagine that and to start
learning and discovering etc may seem
like an odd thing for somebody in my
position to be doing but actually what
I've really found is you know it's so
hard I'm sure you find this to to keep
up with the immense pace of change the
volume of information that's published
every day just you know trying to
understand all of that so what do you do
how do you get a handle on it especially
if you're in a situation where you need
to rapidly assess and come to judgments
and decisions about you know which way
to go and what parts are taking my case
investments maybe in some of your cases
what technology to build on etc and i
found out that actually along this
journey there are two things that i got
from papers that are really useful to me
and one of them is looking at the
foundations so really understanding some
core basic principles that gives you a
context in which to go and understand
when you encounter something new what
does this line up with what I know about
foundational principles here's a
framework I can set it in and understand
it and then the second thing that I
really tried in enjoy is looking at the
frontiers trying to understand where
things are going and so I found that you
know papers have been very very
beneficial to me for those two reasons
and so a mix of foundation
frontiers and that's what we've done
tonight to structure the talk it was a
difficult brief I think you've got to
give us some slack Adria said I want you
to talk about academic papers and I want
you to be entertaining which is not the
immediate pair you'd put together yeah
but we do have beers to help so we've
taken aboard a challenge we are going to
in the in the three conference themes
which you now know very well agile lean
and rugged we've selected two papers in
each category one that we're calling
foundational and one that we think is a
little more on the frontiers although
it's somewhat arbitrary but they're all
papers that we like and to get through
this in available time we realize that
we therefore got about five minutes per
paper yeah which is actually pretty
tough and so to keep us to that any
society wouldn't it be fun if we had a
strict timer and a bell such that and I
get to go first typically at if we
overrun the five minutes we'll get cut
off so most importantly drinks should be
on time following this mechanism yes so
those are the rules five minutes for
paper one foundation one frontier no
cheating no adjusting the clock along
the way no ring the bell too early thank
you going to need all the minutes we can
get so with that let's dive in shall we
look at some papers alright so the first
category we've picked on is a gel so
yeah job category you want to come over
here why don't I grab this come to the
center yeah so okay so we're going to
start with a foundational paper in the
edge our category and you one of the
things that we this is very off-putting
what I learned that already one of the
things we've heard a lot today is it
agility is all about embracing change
and adapting to changing circumstances
and being good at doing that this is a
paper a very famous guy called David
Palmer wrote in 1994 and I love this
paper because I said he could have been
giving this talk at this session today
and yet this is way before you could
have sort of predicted many of the
things that we're talking about it's
1994 he also wrote the marvelous on the
criteria for decomposing systems into
modules but we won't talk about that
today
one of the things he says really early
on here is that actually success we have
to get over this excitement about
getting to the first working version and
we had to think about success as
planning for a series of changes over
the long haul and that's when we really
know that we're winning now I don't know
if you ever had the experience of
looking at a piece of existing software
perhaps it a little bit of disdain
thinking I could write that so much
better if I could just kind of rewrite
it in the right language with the right
tools using modern design principles it
would be great and pond that says this
is a bit like looking at an 86 year old
man and saying you know he we should
have more exercise when he was younger
and not appreciating that the guy was
actually a champion swimmer right into
his 50s and so you know one of the
points here is that what he calls
software aging it's just inevitable what
causes software aging two reasons
parnassus the first reason is your
software can't become obsolete by
failing to change if you just leave it
static it doesn't adapt and keep up for
failure to change will age your software
it's obsolete it falls off the tools of
the past the second reason that software
ages is changing it so you're damned if
you do and you're damned if you don't
Thomas says that if you want to plan for
success you need to plan for change
because the only systems that don't get
changed are those that are so bad that
nobody wants to use them likewise there
for a failure to plan for change is
really planning for premature aging and
death which I hope we don't want for our
software how is it aging hathon you hope
that the original writer of the software
has a clear concept in mind when they
create it that it's somehow conceptually
integral and coherent but later along
somebody comes along to do some
maintenance to make a change and they
don't quite understand that clear
original concept and so what they do
isn't quite in line with it now to
understand the software you have to
understand the original concept and the
change that was made repeat this process
a few times and you find that the
original designer of the software no
longer understands what it does the
maintainer of the software never
understood what it did
and therefore nobody understands what
this software does interesting now
software aging says is inevitable and as
it happens it reduces our agility as
software ageism becomes more brittle and
harder to understand the rate of change
slows down also the performance of the
software may slow down as a structure
deteriorates and it tends to get more
buggy one of the reasons is weight gain
the easiest way he says to add a new
feature to the cap to the software is to
add new code and we tend to violate the
dry principle we get duplication etc now
changes had to be made in multiple cases
we're on the slippery slope what can we
do that you're hiding the timer what can
we do about this preventive medicine
parnis says first of all we have to
design for change planning for change
remember is planning for success so
think about that right up front what can
help with this embracing modularity and
information hiding in other words
breaking your system down into smaller
well-designed coherent pieces that
become units of change which is kind of
very reminiscent of micro services when
you think about it he also stresses
clarity and documentation maybe more so
than we would today but with the goal
that remember you're writing this for
the long haul think about the people to
fall over maybe your future self if a
part of the software is too bad just
chop it off amputate the disease ridden
parts don't let it spread again that
means that having a unit of change you
can easily amputate is great and finally
plan for eventual replacement it will
happen software does age start saving
financially and investing in new tools
and techniques to be ready when that
time comes look at that time out yeah oh
nice
oh okay okay oh hey that's okay fine it
said this is like a little bit too soon
all right so my paper that I chose this
much better all the time over there it's
like every second count so this is fast
database we start at Facebook and then
we chose this as an angel' paper that is
in a frontier so when we want to as
developers we want agility of operation
opportunity of development and GDP of
testing and verification an agility of
delivery but you'll see this all of
these deals with how we construct
software and how we put it out in
production but once it's out in the wild
we actually need to support it and we
need to do maintenance to it so we also
really want agility of operations as
well so people are dropping their drinks
poop so this paper deals with facebook
scuba and if you're not familiar with
scuba scuba is an in-memory database
that is used to monitor and analyze
facebook products and services and the
paper describes the struggles of the
scuba team was dealing with so it deals
with a little bit of the architecture
but we're not going to cover it although
I'm just going to tell you that they're
machines and each machine has sarah has
some servers I'm since this in memory
all of the data lives in the server's
heap so this is all you need to know
about scuba but the problem that the
team was having and the problem they're
pretty much everybody that has to deal
with state a large quantity size that
it's kind of tricky it's like it's not
necessarily trivial and for them
restoring a database cleared its memory
so it meant that he had to load it up
from this and it was around 120 gigs of
RAM from disk and it took them around
three hours per server and you hide
around eight servers per machine so they
did this strategy to actually get them
to get a little bit more functionality
while they had to do an upgrade then and
they did things like orchestrator
restarts like the only restarted two
percent of the fleet two percent of the
service of the fleet and and they also
like wall the word service were
restarting they use this thing that
would be like partial that they do you
see a strategy called partial queries so
they don't return the full results set
but returned a little bit and then they
keep restarting machines but dancing to
Plymouth Rock 12 hours and required a
full-time engineer to actually monitor
the process and I don't know if you
might or the property so far this is
how you look like whenever you have to
do this thing what the team notice is
that whenever they shot on a service for
a plan upgrade the server memory was in
a good state I suppose that whenever
server crash and you can't really tell
if the memory was good or not if you're
there was some corruption so they
decided to decouple the memories
lifetime from the process lifetime
lifetimes so they did it this way and
they went they did it by actually just
like serialization and deserialization
sistina structures that went to desk so
it went from from hip to memory and
they're from Sherman from from
keep2share memory and then through
shared memory was the thing with that
kept the state then the process we
started and then it just read everything
back from shared memory into heap and
they use different data structures on
the paper covers this and this kind of
like the description of how they did the
staggered the staggered restarts and it
took them around an hour to do the full
fleet and in the server took from going
from three hours it took them around 2-3
minutes per server so so this is agility
of operations and this is what you look
like if you're the engineer that is on
call for that one boom yes so all right
now we're going to go for lean forward
with an so good yeah I have your spare
minutes yeah oh come on no rollover yes
all right so a paper tour of lean um and
I get to do the foundational paper again
are you started the timer okay so my
choice is scalability but at what cost
especially at 2015 paper Frank McSherry
and metal but I really liked it it
teaches us a very foundational and
perhaps you'll find it counterintuitive
lesson when you first encounter it and
so it's teaches the question why we're
pursuing certain goals and whether they
are indeed the right ones and whether
they have lieen consequences so let's
take a look at this particular chart
which shows here is scaling out some
distributed systems or adding nodes and
therefore we're adding cause and we're
looking at the speed up that we achieve
as we add cause this is a classic kind
of scalability of my system show off
graph and we'll see that system B starts
to struggle after about 10 cause then it
sort of seems to be flat lining and not
scaling terribly well whereas system a
we had at our nose in his head our core
seems to scale quite nicely within the
time limit and a quick show of hands who
would prefer to deploy system a and who
would like to deploy system b11 curious
taker because he's figured out there
must be a catch here's another graph of
the same system running the exact same
workload again we're seeing the number
of nodes in a distributed system and
hence cause but now we'll look at the
actual time it takes to process this
workload what I want you to notice is
that system be the system that scales
the worst actually performs better than
system a at every scale now which system
do you want to deploy in your data
system a or system be huh that's kind of
trusting isn't it's a little bit hurts
hang on I want to deliberately deploy
the system that scales worse that kind
of tech is we're so use the kind of
scalability as a goal in its own right
does your system scale its web scale
single-minded pursuit of scalability
this paper shows this could be the wrong
goal it's a very thought provoking
counter example we're more interested
perhaps in performance of different
scales are in cost performance etc how
does it happen so the common wisdom has
embodied in many many papers and
discussions and debates is that if your
system scales really well you must be a
really good system builder because
scaling is hard and you clearly done a
great job and luxuriate hours actually
you have some uncommon wisdom here any
system can actually scale arbitrarily
well do you have a particular
distributed systems with a sufficient
lack of care in its implementation how
does this happen well in order to get
scaling and to go up to 300 nodes we
introduce all sorts of overheads and
inefficiencies that are going to let us
work in this distributed manner they
turn out to be easily parallelizable now
you get a lovely-looking scaling graph
but you don't have good performance the
second thing that tends to happen is
that a program will optimize around some
of these distributed programming
paradigms restrict your algorithm choice
and so you can't always encode the
algorithm in the most efficient way
so they introduce a notion of cost
what's the configuration that
outperforms a single thread so the cost
of a system is the number of hardware
cause you need to use before you're
particularly distributed system
implementation outperforms a competent
single-threaded single core system many
systems it turns out actually have
unbounded costs they never choose this
goal so let's if kind of damning and
interesting let's have a look this is
it's a graph processing you do it many
other areas 20 pagerank iteration Joe
Google's PageRank algorithm etc here's
my single threaded system on the top so
the parenthesis has how many calls were
using so you can see that most of these
systems never get to beat my single core
so spark with 128 cause for example is
actually slower than my single thread on
a single core GraphLab is it GraphLab
just about does it but it uses a hundred
and twenty eight cores to do it 128
times more expensive than if you used a
single core pull barham said you can
have a second computer when you shown
you know how to use the first one
choosing a good algorithm apart is
really at the heart of computer science
and if we're forced into positions where
we can't do that it has serious
implications for being lean in his blog
that accompanies the paper Frank
McSherry says look here's the acid test
if you're building a system for others
to use particular distributed system
just make sure it runs better than it
does on your laptop and by the way he
shows you see how you can do this with
very large data sets and all kinds of
things it's not just for small data and
if you're using some kind of distributed
system just make sure it's better than
your laptop so incredible implications
for running lean here just by kind of
assuming scalability following the crowd
and actually accepting a lot of
inefficiency as a result what doing so
good No ok I'm up next as well I'm going
to steal a few seconds from the reset
I'm going to do the frontier paper and
so frontier paper also from 2015 again
thinking about lean
my choice is aprox Hadoop bringing
approximations to MapReduce frameworks
now whereas scalability but at what cost
teaches us to question whether we're
pursuing the right goal this paper
really teaches us to make sure that
we're not asking too much of our systems
and again I want to tease you with a
graph this time we're looking at
analyses of the size of articles in
Wikipedia okay and so you've got me on
page size in bytes and the number of
articles that have that size via the
green the solid line shows the absolute
precise perfect results analyzing every
single article looking at exact length
and giving you this distribution what's
really interesting at the cross is over
lay there in red if you're not red green
colorblind that's the same thing but
calculated by only sampling one percent
of the data so this was producer say
look we're one percent error bounds and
ninety-five percent confidence interval
can you tell me what this distribution
looks like it turns out if you're happy
to take the red crosses rather than the
solid line again you sample about 1% of
the data you can get that about 32 times
faster or using about a 30 tooth of the
resources and I wanna lie to you what do
you really need you know if your goal is
to understand the shape of the
distribution to look at reports etc you
know you're not doing kind of billings
kind of stuff off the back of this in
many cases is the Red Cross perfectly
good enough now a report that you only
around once a month you can run it every
day for the same cost okay there's a
related piece of work it's not in the
paper but I wanted to touch on it call
blink DB which also incorporates this
approximate querying idea now here again
we're seeing the cost of running a query
gets two different data sets two and a
half terabytes seven and a half
terabytes so big data query response on
the y-axis note that it's a log scale
okay and again we're saying if we are to
this query at one percent error then at
two and a half terabytes we were between
about 10 to 100 times faster or cheaper
and at seven and a half terabytes you're
about a thousand
times faster / cheaper if you're
prepared to accept that approximation
which I just showed you from many
purposes is actually pretty darn good
how does the prox hadoop actually work
and so it's a two-stage sampling process
when it does is first is it just chooses
to input a subset of the data blocks and
then given that it chooses to run or to
drop a subset of the map tasks of course
the trick is figuring out how much data
you need to look at and how many tasks
you can drop but after doing this
two-stage sampling to use it as an end
user is dead straight forward they
provide you know super classes for
mapper and reducer that you just extend
like you would the normal kind of super
classes and that's it off you go there
are two ways of specifying what you want
you can say if you understand your data
set this is the sampling rate I'm
prepared to accept and this is a drop
rate format reduce tasks or you can tell
it this is the error bounds that I'm
interested in and this is a confidence
interval I need now error bound is how
close to the true answer do I need to be
within one percent within five percent
within ten percent confidence interval
how long do I have perfectly time
confidence interval is how sure are you
that you're within that error bounds so
for example if I say ninety-five percent
confident one percent error bounds that
means 19 times out of 20 the answer I
give you is going to be within that
bound how do they work out how much to
drop based on this that's kind of where
the smarts are that's the bit you
wouldnt want to do yourself so for
aggregate computations things that are
doing for example a psalm or a count or
that kind of thing they use multistage
sampling theory and if you've got a
process that's looking at extremes like
computing a min or a max etc then the
authors use extreme value theory and
something called the Fisher Tippett good
a denko theorem don't ask me about that
I can't tell you but some smart guys
have figured it all out and really the
takeaway for this for me is don't ask
wasteful questions do you really need
the answer because getting from 99
percent to 100% you pay a heavy price
okay go okay so now we're going to do
rugged at the beginning we decided to
split them and then we're going to see
if each one of us can take a full
section but it looks like we're made of
time so let's do it so the first paper
that is foundational that we've selected
was harvesting yield and the unscalable
tolerant services and the reason that we
love this paper is that it was made in
1999 but a lot of this the mechanisms
and a lot of the strategies that you
finess talked about in previous sections
are actually like formalized in this
paper and and and it's really really
cool so if this is my interpretation of
ruggedness which has nothing to do with
security so I'm sorry to the speakers i
really enjoy your talks and learn a lot
of them but but yeah you i am dealing
with like pci right now so it was like
ah so good so ruggedness i also went as
a practitioner when I think about
ruggedness I also think about system
availability and this is why I like this
paper allowed because this paper gives
us give us strategies to enhance enhance
ruggedness in the press a presence of
failures so we have anything that runs
on the internet eventually will fail
like it will fail so so the way that
this paper actually gives us a mechanism
and a better way to think about what do
you do or how your system availability
is impacted by failure so that's why I
like it and that's why I put that the
knowledgeable clergy so the two concepts
of this paper introduce is yield and
harvest so you Lissa fine as a fraction
of answer queries and harvest is the
fraction of the complete result so we
now like the authors propose that we
start thinking about our system
availability in terms of yield and
harvest and our systems eventually like
have a preference for what they're going
to be tolerant to are you going to be
like favor yield or they want a favor
harvest and that it's not something that
you built after your system gets
constructed you build it this behavior
it's an outcome of your systems design
which is something like really like
pretty interesting it's like you can't
really build security X and Austin your
system is finished but it's the same
thing with the behavior view system in
terms of failures so these two concepts
are rather tricky so I'm going to cover
them again to make sure that that we
understand them
together it took me a little bit of time
to actually get what they meant by yield
so you it's kind of closer to up time
they mean the percent of requests that
get answered successfully but it's more
useful than up time as a metric because
this correlated or maps directly to use
your experience so say for example we
have a shopping cart on your system is a
shopping cart and you are doing
Christmas season and then you have two
minutes of downtime but it's a different
like there is a different yield than if
your system goes down at 3am on a
regular Wednesday princess same out
uptime metric so so this is the
interesting part then the author's tells
us that we should actually be focusing
on yield rather than up time when we're
trying to talk about our systems
behavior so harvest that right now this
is decided a very illustrative example
so so harvest is defined as the percent
of the data that is included in the
response from all of the data that we
have so say that I have this following
distribution of data on servers and I
have queued on server a baby on cyber be
animals on server see and I want to
search for cute baby animals offer this
is what happens when web server then
server seagulls beetle goes down I have
sixty-seven percent of harvest but
actually my query is pretty good so this
is again to that the approximation the
day and was talking about like we don't
have to have one hundred percent harvest
to actually return sensible result so
the authors propose two strategies to
help us help us build our systems in way
that are much more tolerant or rugged to
failure so one of the admission like
strategy number one or door number one
is probabilistic availability and this
is where like the concept of like
graceful degradation like comes up so
it's graceful harvest aggradation
because it's like graceful like ability
they'll have like more like a proximate
result on the guys from the scuba paper
did that under a fault randomness is for
example if I spread one percent of my
data through through different different
servers then wife once ever dies it's
kind of like rate but for you for for
your saving of state if one of the the
server size then you actually have one
percent that is randomly distributed
data you can actually replicate more
things that are more important to you
and you degrade result based on client
capability at the second one is the
composition
man decomposition the only thing that is
really important that I want you to take
away from this is that you can split
your application into sub systems that
are independently intolerant to failure
/ your application itself is like
tolerant to those systems failures so
it's kind of like you build an API tier
but everything under your API could fail
and you're okay i have 28 seconds and
they another thing that is interesting
is that you don't have to have the same
consistency for everything only for the
subsystems are needed orthogonal d when
I have to go and read it on your own the
next paper is that frontier paper you
can be fine and then this is one of the
authors we really like this paper and
and again I'm going to really find that
the theme of ruggedness and also when I
think about ruggedness I think about our
systems like ability to stay up a
symptoms ability to be secure but the
only whether you know this it's actually
be a verification and be a testing I
mean the realm of testing there's like
all sorts of classifications and this is
my mental model so you have things that
are like much more academic like formal
methods and then informal methods you
have things like human assistive proves
model check in like wear formal methods
and their grade and they give you this
level of assurance that regular testing
doesn't give you but they're very very
labor-intensive and they also have very
very specific application so if you have
something that is safety critical you
tend to go for a human assisted proof
you spend maybe like six months of your
life proving like 30 lines of code but
you really have like very very great
assurances eve of us is actually using
form of methods and they have a paper
about it but it's really really
interesting about how to use t la plus
to verify and make more aggressive
changes to AWS services then you have
your regular testing which is a thing
that we all of us do hopefully do your
pay attention to your tests and people
classify testing depending on like the
perspective on your system so you have
things like top down and and using like
white black box it's like I'm awareness
but the paper introduces a new term that
they call bottom up and they call it
lineage driven fault injectors are part
of bottom-up so I thought that this was
this sound for this because I guy it's
really difficult to pronounce so I'm not
going to say lineage driven fault
injectors anymore I'm going to call it
Molly because that is the name of the
system that they implemented to
prove this concept and this concept
comes from like database literature
where they trace that the outcome of
something but then they use this
mechanism to actually like sick failures
so Molly recents backward from a correct
observe system behavior and it tries to
just like figure out what could have
prevented it from happening and that is
super powerful and then it uses this
information to only put failures that if
things could have prevented the good
outcome to cut to like from happening so
so he said is smarter than your regular
fault injectors because it actually
knows and has an understanding of how
your application works so say I want to
build a rocket system with Molly and in
the paper that describe the situation
but it's kind of a king like a game with
a developer and the programmer I put a
monkey but no no nothing don't take any
conclusions from that one and the
verifier simoni so so I me as a
programmer I give Molly my program a
correctness specification my inputs and
a failure model like we have to agree on
what are the failures that my
application is supposed to tolerate and
how many of them and over what amount of
time and Molly runs my program enough
services execution and then it's going
to pick a fault and from the things that
we've agreed upon and then it's going to
run my program again with that fault in
mind and we both get to observe the
result so if Molly breaks my program my
program and the correctness
specification is violated then I lose
forget to submit my program with a patch
yet again but if it looks good then
Molly would I win that round and Molly
would pick another failure that is
possible for my application and then we
try again and we try again and if Molly
breaks my program then I lose if my
program like manages to stew like
survive this evaluation then i win and
then I get a get a certainty that I
wouldn't necessarily get with other fold
into injection mechanisms another thing
that is interesting that if a wife is
relevant is because at the end of the
day formal methods allow you to have an
analysis of all of the states at you
that you program on your system can get
into but-but-but testing in testing you
actually have to force a system to fail
otherwise you have no component no
confidence that is going to operate
correctly in failure modes Molly
provides as part of this execution a way
to
we reason about failures so because
after the first one for example my
program was crap and he told me and then
that is a lineage thing and then he
gives me also a lineage costs and in a
lamp or diagram so I can reason about
time then I get to submit it again i get
to submit it again and by the end of the
day you see that my lineage is a little
bit much more complex and it's a little
bit like a much more sturdy so you can
see this in the paper fifty seconds now
this is like actually not that bad right
yeah we're doing good so so the recent
of like Molly a lot it's also because it
presents a middle between things that
are like much more pragmatic like
testing I'm a formalism and a rigidity
of formal methods I don't know if any of
you see also those in school but the
first time I told them it was just like
ahh and then I didn't understand why
they were good and then now I get that
the certainties are much more like
they're much more concrete they're like
they just complete their mathematically
provable so so like this gives us a
middle ground and and it deals is the
status by the importance of verifying
the the very fine for tolerance in spite
of the complexity of the space of faults
ah ok hi Craig eCos nice of our partners
yes so the hard part is to know like
what everything that could be in the
ended like space of input yes whoo
so hopefully by this time what we're
trying to do it's like exposed to ideas
that were new to us or things that we
actually like learn and different
perspectives that we acquired by reading
papers so even ourselves so as we were
just like as we were like toying with
which paper we're going to put on
different of different sections we
actually learned that our point of views
we're a little bit different and then
what I found valuable over one paper
were the things that you find maybe in
and then when you find value or were the
things that I'm like that whatever
everybody knows that but but it's
interesting so like so so what we did
for you in case you were asleep I like
to do this thing with my presentations
where we put summaries but I did i do
call them feel the arse so if John is
not pick our first one bring it thank
you so we looked at three foundational
papers one in each category agile lean
and rugged in the agile paper remember
we heard from David parness telegraphing
to us from 21 years ago designing for
change is designing for success so
that's a really important lesson and
we've had a lot about that today in the
link category looked at scalability but
at what cost Franklin cherry 2015 a
scalable system may not necessarily be a
lean system and so just pursuing
scalability for its own right out of
some context may actually be quite
costly and there the marvelous cost
metric to help us evaluate that in the
rugged section it is took us through
thinking about availability in terms of
yield and in terms of harvest and the
ability of a system to gracefully
degrade and to still performing in some
manner either in the face of stress and
that's a great design outcome oh okay
mine again all right so in the frontiers
in the frontiers section we saw that
when it comes to our job handling state
can be challenging if you have to
operate a database at scale like you
know this and city state and share
memory this trick that other like that
other people were using even on Facebook
but this team leverage allowed them to
restart DV processes faster and the team
itself became more agile because in
terms of operations that were able to do
everything that took them 12 hours in
the span of one so that is super
powerful in terms of lean asking the
wrong question its waste
and you think about you should think
about what is truly needed if you can
use an approximation then you save a lot
of effort and a lot of a little work and
then actually like your your process is
much leaner because you waste listings
and in the case of rugged then 3 sine
about from a good state and recent about
backwards can can just actually like
help you determine if the XA their
execution failures that could have
helped they could have prevented this
output from happening so this is also
very nice because I'd normally were used
to think in one way but we don't really
think the way back and and and i think
this type of thinking also like helps us
become a little bit more rugged because
he gave us tools to actually understand
where our systems were doing when they
were there when they were being run and
yeah so so that is my rugged summary we
have compiled so obviously papers are
fun read them sometimes a little bit
challenging to get started into the into
reading but Adrian's blog is great
because it helps you at least understand
the gist of what you're reading and I we
have a repo with everything that has to
do with everything that we found helpful
to actually get started with papers we
have linked to all of the papers that
we've discussed it's kind of a
disservice because they're very very
good and we had to be still them in five
minutes and there's much more
information that is super valuable so go
check out the reporters link to the
slides already I've already published
them and this is a reminder to actually
join your local papers for love if you
want to speak it's really great we're
always looking for new speakers you
don't even have to prepare a folding
stock you can do a smaller one and the
organizers help you develop it and the
morning paper is great so so read it and
for now we have like dranks
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>