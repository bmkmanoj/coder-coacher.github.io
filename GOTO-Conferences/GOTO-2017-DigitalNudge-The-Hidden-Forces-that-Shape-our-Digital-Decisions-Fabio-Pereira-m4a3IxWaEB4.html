<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • #DigitalNudge - The Hidden Forces that Shape our Digital Decisions • Fabio Pereira | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • #DigitalNudge - The Hidden Forces that Shape our Digital Decisions • Fabio Pereira - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • #DigitalNudge - The Hidden Forces that Shape our Digital Decisions • Fabio Pereira</b></h2><h5 class="post__date">2018-01-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/m4a3IxWaEB4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon everyone as a first thing
I wanted to show you this is a robot
this photo is from two months ago it's a
robot conducting the Philharmonic
Orchestra in Italy so this is just to
give us a bit of a taste of where we are
in terms of Technology and if you've
been to the artificial intelligence
track you would have seen a lot of those
artificial intelligence revolutionary
things that we have at the moment as
well but let's take a step back right
not even robots running orchestras if
you go to Google right now and I landed
in Berlin yesterday and I went to Google
and I googled where to eat in Berlin and
then I thought maybe I could try this in
German and then I had no idea how to
pronounce that someone helped me so it's
something like MOOC and money in Berlin
Essen there are 17 million results to
that question right and Google even
humiliates us saying that it calculated
that in 0.43 seconds and in which of
those results do we click ninety one
point five percent of people end up
clicking on the results from the first
page of a Google search so do we think
that that decision was us or was it
Google who actually helped us make that
decision for us if out of 17 million
results if we click on the results from
the first page I will turn of us enough
from that decision or was that the
algorithms of search from Google that
actually influenced us to make that
decision so that's what I want to talk
to you about I call this digital nudge
and it's about these hidden forces that
actually shape our digital decisions
please ask questions through the app and
we'll try to answer them at the end this
number 35,000 what does this mean this
is the average number of decisions that
every human makes every single day so
that's probably a decision every two
seconds
so think about it one two you've just
made a decision right that I hope it's
to keep paying attention to the
presentation but I want to tell you
about an experiment that experiment is
actually what changed my life about
seven years ago someone told me about
this experiment
and my life has changed completely the
way I see the decisions I make and the
way I see the decisions that others make
has changed completely I don't know if
anyone knows this experiment here it's
the economists experiment this magazine
actually presented the subscribers with
three options for subscription one
option was the digital version for $59
the other option was the print version
for $125 and there was an option for a
combo of print plus digital for 125 what
happened was that everyone most of the
people actually bought the combo for 125
no one actually got the option in the
middle and a few people got the digital
version but the majority of people
actually got the combo and then they
said hang on let's actually present
these options in another way let's
remove the option in the middle since no
one bought it why should we even bother
presenting something that no one buys so
if you only present the digital version
and the combo version what happens is
that the majority of the people end up
buying the digital version so I saw that
experiment and something inside of me
went like I wouldn't fall for that
because I'm totally rational and I make
rational decisions so that wouldn't
happen to me I would buy whatever I want
to buy regardless of what I see and then
I ended up starting to study these
things right and there is actually a
name for this option in the middle it's
called decoy it's an option that is put
into an equation to influence you to
make a decision there is even a formula
if you have two options a and B and if
you want people to select option B you
actually give them an option minus B
that makes B look better so pretty much
someone would say why am I gonna pay
$125 on the print version only if I can
pay $125 or both and then suddenly this
option looks so much better that we
don't even look at the other option of
course that happens to a majority of
people it doesn't happen to everyone and
then something inside of me really
wanted to understand why that happens
right and one TED talk actually helped
me understand this and it was a TED talk
that compared these things to optical
illusions so as we all know we have
problems in our brain when we see things
our vision is not perfect so when we
look at an image like that
the
blue circle on the left looks slightly
bigger than the blue circle on the right
right but they're actually the same size
what happens is what's around it
actually influences the way we see
things so because what's around
something influences the way we see
things what's around a decision also
influences what we will decide this
optical illusion here is really creepy
because it makes me think that I'm
really problematic the square a and the
square B are actually the same color
it's the same gray color so when you do
that you actually see they are the same
color so I actually opened on Photoshop
and copied the little square from the a
and then pasted it on top of B and it's
actually the same color what happens is
what's around a is light so a seems
darker because what's around it is light
what's around B is shade and then that's
why B looks a bit brighter but they are
actually the same color basically what's
around something influences the way we
see it so the same way that we have
optical illusions we have what we call
cognitive biases the like optical
illusions but they are optical illusions
of behavior and we call them cognitive
illusions or cognitive biases so I'll
refer to these things throughout the
talk and they're pretty much these
little bugs that exist in our brain when
we make decisions and to give a bit of a
background in terms of where they come
from
think about psychology and usually when
I talk about this I say that it's the
psychology behind the decisions we make
and people go like but is it like the
psychology of Freud of like it's it like
when we lay down and we talked about a
problem so it's not that type of
psychology psychology is that big blue
circle inside that big blue circle there
is cognitive psychology that understands
a bit of how we see things and how we
how we learn things language and other
things and there is an area called
behavioral economics which actually uses
cognitive psychology and neuroscience to
understand economic decisions and public
choice dan Ariely I was actually
mentioned by the previous talk here I
don't know if someone was here he's one
of the main authors on that on that area
he wrote this book predict
irrational and it was actually through
this book and through one of his TED
talks that I got to understand a lot
more of our irrationality and there is
also another very nice book called nudge
from Richard Thaler and Cass sustain and
interestingly enough last month on 9th
of October we were all really happy like
everyone who likes behavior economics
was really happy because Richard Taylor
actually got the Nobel Prize from 2017
in economics for combining psychology
and economics that was just like a month
and a month ago so to bring this a bit
you to our reality in technology I want
to bring to you a case study I was
working on a project it was an insurance
project we wanted to sell insurance
straight to the customers usually we buy
insurance through a broker but in this
case they wanted to sell it straight to
the customer and I don't know if you've
ever bought insurance here but you buy
insurance you have a lot of options
right you have to take that and take
that and then there's many many options
you can buy those two options or those
three or those two and then basically
there was a situation where to buy an
insurance we had 51 511 options to buy
that insurance what we did was how can
we simplify that interface so that users
don't have all those options and we
actually simplified their lives so
people on the project actually decided
to do what we call digital
personalization but when we do digital
personalization we have to think about
based on what will personalize in that
case it was based on profession and
other characteristics as well so if the
person was a photographer they would see
those three options if the person was a
mechanic then they would see those other
three options it was during that moment
when I combined the knowledge I was
learning from behavior economics and
what I saw on that project that I really
realized that there is a lot of power in
the hands of people who actually
personalize that and personalization is
a big pillar in the digital world
because we can only we can personalize
it to the extreme that each person will
see a different digital interface in the
physical world that's quite difficult
because we can't just say if someone
walks into a room I will set up this
whole room personalized for each and
every one of you but a mobile lab can be
personalized to each and every one
you and then I realized that there is a
lot of power in the hands of UX people I
don't know if there's anyone here who
works with UX user experience or
experience design but those roles on
projects are quite important because
these people they actually define how
this environment in which users will
make decisions is designed in behavior
economics there is a name for people who
actually design physical environments
they're called choice architects so I
actually call UX people digital choice
architects because they are designing
the environments which are digital in
which users will make the decisions
there's a number when I saw that
research is quite interesting because
there is a number that in Austria it's
99 percent and in Denmark it's 4 percent
I asked in one of my talks if anyone
knew what that was and someone said it's
the number of Austrians could be but in
this case is the number of organ donors
and it's quite interesting so I when I
saw that research I understood that in
Austria you already are a an organ donor
you have to ask to leave it's an opt-out
version and in Denmark you are not an
organ donor you have to ask to be an
organ donor so just by having what is
called the default changes everything
because by default you already asked
something so humans are lazy we just
have a tendency to remain on whatever
default is so pretty much it's quite
important to define what is the default
because if you define what's the default
people the majority of the people will
remain on whatever the default is
I actually looked up as well the
research to see why Germany was and on
that research it was 12% but we try to
use the max and the minimum numbers here
so quite interesting this is one of the
most representative behavior economics
research to explain the power of default
and default is actually one of these
biases so one of these things we have in
our brains that actually make us decide
one way or another
the default bias is one of one of them
it's called status quo bias when I
learned about these things I suddenly I
started to visualize them in the day
because I worked with technology and
then I started to see things you know
when you learn something you start to
see something that you didn't see before
so I was filling out my Netflix
subscription and then suddenly I saw
that please do not email me Netflix
special offers so pretty much the
default was to email me and then if I
don't want to receive I have to check so
by default they will send me the offers
basically someone made a decision on my
behalf that I want the email office and
then if I don't want I have to do
something it's quite interesting I
opened an uber and then suddenly there
was something pre-selected the uber pool
I don't know if there is uber pool here
but recently they've they released that
and then pretty much the uber pool
allows you to share your car with
another passenger so you can pay less
but then you have to go to wherever the
other person is going as well and then
it was already pre-selected
so pretty much someone from uber decided
that the uber pool was the decision that
I wanted to take in that case I actually
went and I tried the uber pool because
he was already selected but it was quite
interesting because once that I know
that now I'm aware of the fact that
people are doing this to me so I can be
manipulated but I can be consciously
manipulated right so it's like I'm I
want to be manipulated I know you
manipulating me but I want to do that
it's very different from being
manipulated and not even knowing about
that right so when I was actually
talking to an uber driver and he said
that there was this lady who approached
the car and she had selected the car
pool and then there was another
passenger in the car and the lady was
like so what's with the other passenger
and the the driver said you selected the
pool and the lady went like I selected
the what so she didn't even know that
she had selected something because he
was pretty much pre-selected for her
that's the power of the defaults and
with the default there is a lot of power
right but there's a lot of
responsibilities as well that's why I
want to talk to you about a few things
you will have received an email from go
to conference and in the email there was
something that said when you signed up
to go to Berlin you accepted to delegate
all your decisions to the members of the
organizing committee did anyone read
that
no you actually didn't have that so four
go to Berlin I actually didn't do this
but I gave a TEDx talk the other day and
for the TEDx I actually organized with
the committee beforehand and we actually
did that so we put that on the text for
everyone who received and then that was
the text at all in Portuguese so you'll
have to agree with me that that's what
it means it said that every everyone who
signed up for TEDx was already
delegating all the decisions of their
lives an hour of 400 people only 13 of
them actually asked to leave they only
opted out so pretty much almost 400
people have taken a decision without
even knowing there is a very nice
website called dark patents it's from
Harry brignall he actually catalogued a
few of these things and he called them
dark patents one of them that I really
like it's the one that says sneak into
basket pretty much there are some
ecommerce websites that if you buy let's
say tablet they actually put a tablet
case inside your your trolley because
you might as well want to buy one so
they already shove it into your trolley
and then if you if you want to get it
that's okay if you don't want you have
to remove it right and that's an
anti-pattern or a dark patent that Harry
calls sneak into basket sometimes I
imagine in the real physical world we
wouldn't accept that right can you
imagine you're in the supermarket and
then suddenly someone comes and put
something in your like we would never
accept that so why is it that we accept
that in the digital world it's because
we behave differently in the digital
world but to bring you to some to bring
you the level of awareness that I really
wish someone had I want to show you a
few of the digital default every time
you see one of these things there is a
default already decided for you every
time you see a checkbox if it's checked
if it's not checked every time it time
you see a drop-down it might have been
selected or someone might have chosen
like what's the order that we have this
drop-down if we have it alphabetic order
then you will be more likely to select
the one on top if it's not alphabetic
then of course there is someone who
thought about the order any time you see
an order complete if you actually start
typing something it autocompletes for
you you are more likely to select what
come
the autocomplete then to actually keep
filling it search results any default
settings that comes on any mobile device
that you buy someone has already
pre-selected that timelines as well when
you go on Facebook or Instagram or
anything that has a timeline you
actually are seen what they chose you
for you to see because what has been
rendered over there it's based on
whatever rules that Facebook or
Instagram or any other timeline like
LinkedIn they actually decided to render
for you so those are all defaults so
when I talk to you about a concept
called nudge which is the name of that
book I actually went yesterday and try
to translate it so it translated to subs
or shoobs I don't know how to say that
but hopefully it's shoobs
so I was going to translate it to shoobs
but then I translated it back you know
when you translate and you're going on
the way back
so actually translate it back and shoobs
actually means job so I was like that
should be wrong so let's stick to nudge
and just so we understand nudge it's not
a push it's not a shove it's just a tiny
push so I will actually ask you to give
it a bit of a nudge to the person on
your side even if you don't know them
it's a great way of getting to know
someone right so yeah cool don't drop
them from the chair okay cool so that's
a nudge and what I want to talk to you
about is what I call digital nudge which
is pretty much understanding all these
little nudges that happen in the
physical world and how can we adapt them
to the digital world so we understand
how we behave in the digital world and
we are actually more aware of that I'll
ask you a question and I want everyone
to actually respond that so can you give
me a thumbs up that you will respond
that helps because if you don't do that
you usually don't respond so that's also
a bit of a trick so it has to be very
quick right so I'll ask you a question
and the first thing that comes to your
mind please just say it out loud say it
really loud could be anything
be careful but it could be anything like
related to the question just say it out
loud cool you have a bat and a ball and
the bat and the bow together cost $1 10
the best the bat costs $1
more than the ball how much is the ball
cool 10/10 a lot of people said 10/10
good how much at the ball ten cents
someone already thought it's five cents
so that's really good so let's let's
slow down for a bit because we did it
fast and now let's do it slow so when we
when we think fast
it's 10 cents of course like there's
usually one or two people don't worry
like more than 50% of Stanford and
Harvard students always make this
mistake so don't worry I also made it so
we're all on the same here except for
one person who said 5 cents which is
really good talk to me afterwards
maybe we can do some stuff together so
if the bat is actually if the ball is 10
cents then the batchest $1 more
expensive then it would be 1/10 the
total is 120 so when we think better
then the ball is 5 cents because the bat
is 105 and then it's 110 cool so pretty
much what happens is and if you want to
understand a bit more about this have a
look at this book it's called Thinking
Fast and Slow Daniel Kahneman who's also
a Nobel Prize winner has discovered
through a lot of research that we have
two brains not really physically
hypothetically it's like hardware and
software it's like we have to to
software running one runs really fast
the other run runs a bit slower and when
we think fast we make mistakes when we
think slow we make less mistakes than
when we think fast but we can't think
slow all the time can you imagine if I'm
just walking I go like should I walk
with my left leg or with my right leg
maybe if I walk with the left leg oh we
can't right so some things we just do
automatically and that's how we actually
build habits because habits are some
things that we do thinking fast
I actually think about this concept not
just about Thinking Fast and Slow but I
think about it in the way of scrolling
and clicking fast and slow so can you
imagine when you are scrolling on
Facebook or Instagram when you're liking
things when you disliking them when
you're commenting on Facebook on
Instagram you imagine if you're thinking
fast or slow this is actually a bit of
some data
that came out recently this is what
happens in one minute on the internet
there's pretty much sixteen million text
messages sent there are nine hundred
thousand logins on Facebook 3.5 million
search queries 7,000 hours watched on
Netflix so it's quite interesting like
the number of things that we've been
doing and the insight I had was how many
of those things do we do thinking fast
and how many of them do we do thinking
slow so when you comment on a Facebook
do we think or do we just comment the
first thing that comes to your mind as
if we were saying the 10 cents that we
just said now think about that so I've
lived in Australia for for about 8 years
I work for this company called thought
works and we also have offices here in
Germany we have four offices in Berlin
Hamburg Cologne and Munich no yeah so
we're hiring for those we're also
recruiting for those four offices all
around here so if you want there's a
booth upstairs so I worked fourth always
and when I joined the company about ten
years ago there was a this reputation
that working for the company was really
fun and then I moved to Australia I'm
originally Brazilian and then I was like
so I'm gonna go to Australia and then
I'm here I'm gonna see a lot of
kangaroos and koalas everywhere and then
I was like am I thinking with my fast
brain or slow brain and that's really
true like there was a lot of koalas and
kangaroos and everything and there is
also a lot of fun at the company but
also because I'm Brazilian when I was
living in Australia people would think
that I would play soccer and that Brazil
would be full of peaches and everything
so the beach side is actually really
true but the soccer thing is actually
not very true because I'm a horrible
player in fact there's a friend of mine
jewel sitting over there who's a much
better soccer player than me and he's
Welsh so you see how sometimes our
thinking fast brain makes mistakes
this Fabio here is actually in Australia
there's only one named Fabio and it's
this one so
so everytime I said my name was Fabio
this is what people pictured in their
mind with their fast brain because there
is no slow brain their Thinking Fast and
Slow is another big concept from
behavior economics and the conversion
from the physical world into the digital
world is what I mentioned before the
clicking and scrolling fast and flow
but speaking of Brazil and all that let
me bring some data to you Brazil is the
first country to have more than one
mobile per person it has one point 38
Mobile's per person
90% of all today's data has been created
two years ago 10% of all digital photos
have been taken in the last 45 days and
there are about 16 billion things
connected to the internet right now so
given all that those stats do you think
that those 35,000 decisions that we make
every day how many of those decisions
are digital decisions what I've defined
as digital decisions are decisions that
we either use one of our digital devices
to make the decision or it's a decision
that we fully delegate to a digital
device how many of those they've been
increasing more and more
can you imagine you you see that
headline for it some news people around
you control your mind when I saw that
for the first time I actually thought
that was not true right but then it was
from the Washington Post so I clicked on
it it wasn't fake news and then pretty
much the research said that there was
this news that has been had been
scientifically proven that if you come
into an airplane let's say that you and
the person sitting next to you actually
buy something your chances of buying
jumps by 30%
so you're thirty percent more likely to
buy something just because the person
sitting next to you bought something and
my brother is a flight attendant so I
actually thought how did they run that
research right did they partner with all
the airlines and then they got people to
observe where people were sitting I
actually thought it was like a physical
research but it turns out it was a
digital research what happened was they
grabbed all the
data from almost 2,000 flights from 257
thousand passengers and 65,000
transactions with that customer behavior
data they ran thousands of mini
experiments just with the data and then
there was a data insight that came out
of the data that your chances of buying
jumps by 30% if someone next to you buys
it so this is what I believe it's data
science helping us understand better how
humans behave so when we understand how
better we behave we can actually adjust
and be more aware as anyone here heard
about this some insurance company called
lemonade it's supposed to be the world's
first peer-to-peer insurance carrier
it's got a 13 million dollar budget to
actually reinvent p2p insurance it's
like uber for insurance basically what
happened recently was that they've had
the fastest claim I don't know if anyone
here had to have to lodge a claim but it
just takes ages for any type of claim to
be returned so they actually had a claim
all paid in three seconds so pretty much
that was the fastest claim ever paid in
the whole world they have this thing
called behavior lab where they try to
understand how people behave it says
it's something that happens inside
lemonade so they treat human behavior
really seriously it's very similar to
something we do as always called
Innovation Lab where we actually go to
where people are actually doing what
they are supposed to be doing and we run
experiments with them and the
interesting thing is do you remember
that guy Dan Ariely who I spoke about
the predictably irrational he was made
the chief behavioral officer at lemonade
so this is the overlap between a digital
company it's an insurance company that
is hiring a behavior economist to
understand how humans behave to create a
better digital product I actually got
the privilege to meet and a really the
other day in 2015 a friend of mine
bumped into him at a coffee shop and
then we've actually been in touch since
then he's been a bit of a digital mentor
for me so it's a big
big privilege I have so it's really
changed the way I see things and it's
really changed my way of visualizing the
teach the world so I just want to share
with you if you read about then you will
know that he actually burned like a lot
of his body when he was quite young on
an explosion and then he doesn't type
when he emails so he sends audios so
it's quite good because this is more on
one of the and one of the emails that we
were exchanging then he sent me this
advice on the on the book that I've been
writing so I just want to share that
with you I think there is some audio
which is the audio on
is it not no
cool so let's skip that it's just a bit
of an advice on the book so what I
wanted to tell you is that I was
thinking about writing a book on one
area and then actually changed in one
like 30-second audio he actually
expanded my mind into writing a book
completely different so I'm working on
this book right now which is called
digital nudge and it's the overlap
between behavioral science and the
digital world and it's really based on
the concept of nudging so if you want to
if you want it's coming soon please go
to that website Digital noise org and
then you get you get a free chapter as
soon as it comma comes out so a lot of
people come to me and they ask Fabio by
knowing a lot of these things of how
humans behave can someone be manipulated
and I say yes there is a lot of ways to
manipulate people there are two types of
influence there is persuasion and
coercion persuasion is getting people to
do the things that they want and that
they need to do and coercion is actually
getting people to do things they do not
want and that they do not need so I
believe we need more persuasion and we
need last coercion we need to help
people do what they already need to do
and what they want to do that's why I
started the digital nudges for good
movement it's a movement where we try to
understand in the digital space which
products and which digital services are
actually helping people do what they
need to do so for example there is a
continuous glucose meter that helps
people understand when they need to take
insulin if they have diabetes diabetes
is a huge issue in the world one in 12
people have diabetes now in the world
this company called ayuda heuristics is
a very nice company that's using machine
learning to actually help someone with
diabetes with most of the decisions that
they have today on that day to day lives
well understanding what they need to eat
when they need to sleep what happens
when they sleep more what happens when
they sleep less what happens when they
do this and when they exercise and so
it's it's this is a digital nudge for
good so we can influence someone to eat
something and that's persuasion it's not
coercion this is a project from
Australia called smart cap it's
truckdrivers where that you prevent
microsleeps so when they're about to
have a microsleep the smart cap actually
measures their brainwaves to give them a
little nudge to wake them up and prevent
an accident
that's another digital noise for good
but I want to bring another perspective
to you as well this is a face
recognition software so I think we've
all seen one of these face recognition
software you look at it and it
recognizes your face and there is a very
good TEDx talk from this woman called
joy she actually found out that this
very specific face recognition software
doesn't recognize her face and why
because there is a process in face
recognition which is the training
process where the they actually give a
lot of photos to the algorithm so the
algorithm learns what's a face and
what's not a face and unfortunately for
this specific piece of software no
photos of black people have been given
to the algorithm so because no one
thought about that no one thought about
diversity when they were actually
training that algorithm then we end up
creating an algorithm with prejudice
right we end up creating an algorithm
that's not inclusive we end up creating
a computer that ends up not recognizing
someone's face as a face because it
hasn't learned that that's really a face
so joy actually has a movement called
encoding which is supposed to have
inclusive coding where inclusivity and
diversity is part of what we do when we
are training algorithms it's quite
interesting because I read that news on
the other day after I had seen that TED
talk from joy I read those news and
recently they had an AI algorithm judge
someone just from their faces to tell if
they were guilty or innocent and that's
quite revolutionary right you have you
have someone who looks at a lot of faces
and then they learned that whoever is
guilty or whoever is innocent and in the
article that actually said different
from a human judge the computation of
vision algorithm has absolutely no
subjectivity emotion or prejudice I
agree with the emotion part
but the prejudice it depends on how that
algorithm actually learned what's a
guilty face and what's an innocent face
interestingly enough on that result for
that algorithm it found out that people
with a smaller mouth are more likely to
be guilty on a crime because it's
decided that the size of the mouth is a
relevant dimension to actually
understand that because the algorithm
shows by himself
now the algorithms are making the
decisions on which dimensions they
should be looking to create their own
prejudices I quite like that quote from
the the conference mind the product
recently that says the machines only
know what we feed them so we have to be
really conscious about feeding computers
with whatever we feed them and also when
we decide which dimensions matter we
have to decide them carefully this is a
video from Tesla in San Francisco I
don't know if anyone has seen that but
that's a autonomous vehicle the vision
from this car is much better than any
drivers vision it can see things from a
distance that no one in this room can
see I'm sure unless someone here is a
superhero so what you've seen there is
everything that it's actually detecting
objects road lights and everything so
and it's driving by itself right we know
that these cars exist we know that they
are already being trialed in a few
places but when we see that video it
kind of changes a few things of course
we have these cars driving around cars
are making decisions on our behalf right
so there are a lot of digital decisions
being made by cars right now we make a
decision to actually turn left and right
you actually accelerate your to actually
break a car like that's a human decision
that we are delegating to a car so it's
becoming a digital decision there is a
website called Mauro machine mit.edu
that actually comes up with a few
challenges ethical challenges that to
which we don't know the answers yet so
pretty much if there is a car coming
with three people inside the car
it's coming at our speed that there is
no way that they will not like if it cup
if it keeps going straight it will kill
these three people so it's already
calculated that if I keep going straight
I will kill these three people there is
no way to stop because it does that
calculation very quickly and if it turns
here it will crash on a wall and it will
for sure kill these three people so
which decision should that car make
should the car kill these three people
or should the car kill these three
people so we are having decisions that
computers are making to who they will
kill and there is no ethical code there
is no ethical moral or anything around
that that tells us what we should be
doing or what people writing those
algorithms should be doing the world of
Economic Forum has released what they
call the moral dilemmas of the fourth
Industrial Revolution and that is
definitely one of them so I want to
bring that to our awareness as well it's
called ethics 2.0 so if you are working
on an application if you are working on
anything that has digital decisions
think about what are the ethics behind
that today I spoke to you about one and
a few others of these biases that we
have in our brains one of them is called
status quo bias which is the tendency we
have to stay on the default those are
the mapped biases that we have now in
behavior economics so just understanding
each and every one of those biases that
we have in our brains just helps us
become more aware of how we behave in
how we make decisions and just a quick
thing I want to ask you is that a
chihuahua or a muffin is this a
labradoodle or a fried chicken sheep dog
or mop parrot or guacamole it's very
hard right it's very hard so that's
that's part of an article that actually
highlighted that in 2010 algorithms
would look at a database of images and
they would actually know what the images
are with an error rate of almost 30
percent in 2010 recently last year that
number has dropped to 4%
right and what's 5% humans so last year
for the first time we have algorithms
detecting images better than humans
that's where we are right now we have
computers actually better than humans on
a lot of things including detecting
what's a parrot or guacamole there is a
new type of intelligence right now we
should question ourselves what is that
matters right now there is an
intelligence called DQ it's been defined
by the DQ Institute if you want to know
more go to DQ institute.org it's its
claim to dit to be the new IQ and the
new EQ it's pretty much the type of
intelligence that we need right now in
the digital space and it's it's been
separated into a few capabilities around
privacy critical thinking footprints
empathy cyber bullying screen time
management cyber security and digital
citizenship identity that's the type of
skill that we should be learning right
now to become better and more aware in
the digital world so to take a few of
takeaways from you if you are a digital
choice architect if you are a UX person
or if you know anyone if you work on
your team with someone who designs
interfaces design them for good if you
have behavioral data if you work for a
company that actually has a lot of data
around how people behave run digital
experiments to understand how your users
behave and to help us understand how we
behave as humans and if you are a
digital citizen as I think we all are
let's improve our consciousness let's
become more aware of how we make these
decisions in the digital world there's a
number that in 2016 was 144 billion do
you know what that number is other than
the fact that I forgot to translate it
from Portuguese
that's the number of steps that Pokemon
Go users actually had so 144 billion
steps have been taken by Pokemon Go
users right so Pokemon go is a game that
uses augmented reality it's just an
example of how these things are actually
taking over the world where we are right
now
augmented reality virtual reality
machine learning autonomous cars all
these things are just part of our
day-to-day lives and they will just be
more and more part of our day-to-day
lives and I truly believe that if we
understand how our brains work we will
create about a digital environment for
all of us thank you
Duncan
thanks Fabio they're not a lot of food
they're not a lot of questions actually
maybe people were just so immersed in
the presentation the first one I think
is more of a comment something around
conceptual manipulation and marriage so
I don't think it's a question it
actually ends with a good exclamation
point and then there's one comment on
the autonomously driving cars about the
trolley problem so surely when it comes
to the trolley problem the ethical in
quotes thing to do is for the car to
drive defensively so not to not drive at
a speed where it cannot safely stop or
swerve which is what human drivers are
already doing so I'm not sure there's a
question in there so that you yeah cool
so the person in the audience was saying
that he was wondering if they were ever
gonna be any non-digital decisions
anymore what I believe in and it's
always a belief and if you came to the
previous talk like you know that it's
always like we believe in something
there is no such thing as real truth
because we don't even know if we are in
the lane and if this is reality what I
believe is that we will switch our
decisions what we do is I think will
delegate more and more decisions to
digital devices and then we will we will
switch we'll start making different
decisions than decisions we make right
now just like right now we make very
different decisions from what we used to
make 500 years ago like we in 50 years
from now we'll make different decisions
but I don't believe that we will ever
like become non decision-makers on
anything but that's that's a belief and
in terms of the what the car should do
if feel free to go to moral machines or
mit.edu and actually say that because
what they're doing is they're
crowdsourcing what people believe the
car should be doing to actually inform
some sort of ethical code that will be
decided when those algorithms are
written there's actually one of the
German ministries had an Ethics
Commission put together twenty-eighth
occur rules about autonomous driving I
think that so
one of the first list of those things -
the first attempt at that but they left
me with a lot of questions but maybe
something to look up if you're
interested in this yeah that's great
thank you I'll actually look up look
that up and include it to the book and
the presentations and all that thank you
anything else yeah that's a wrap then
that's a wrap
thanks everyone</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>