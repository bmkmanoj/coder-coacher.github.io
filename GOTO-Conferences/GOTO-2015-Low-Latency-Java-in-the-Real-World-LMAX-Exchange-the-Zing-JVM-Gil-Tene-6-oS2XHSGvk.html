<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Low Latency Java in the Real World: LMAX Exchange &amp; the Zing JVM • Gil Tene | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Low Latency Java in the Real World: LMAX Exchange &amp; the Zing JVM • Gil Tene - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Low Latency Java in the Real World: LMAX Exchange &amp; the Zing JVM • Gil Tene</b></h2><h5 class="post__date">2015-07-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6-oS2XHSGvk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in fact with a nice cozy audience like
this we can add even see if there's
special interests or people actually you
know as an in general that you're
interested in the the actual subject is
low-latency Java in the real world with
actual experiences of the Xing JVM it's
a product we make at L max at the L max
exchange and we've been doing stuff
there for a couple years now how many of
you actually deal with low latency
systems okay how about doing that in
Java well I know what you do good okay
so it's in that world the others are you
interested in low latency in Java
hopefully you're here yeah okay so that
that's what I'm going to cover in I
actually put this presentation together
with L max and I'm really really happy
that we have this material because it's
really rare for us to have a financial
services customer that is willing to
openly talk about their experiences with
our products usually our customers won't
talk
Azul is installed in seven out of the
top ten financial investment banks for
example in the world running various
systems but none of them would let us
say who they are
notice I didn't say ten of the top ten
so I can still say that right
but L max exchange actually is fairly
open and they'll talk and they'll
describe what they actually do and
you've seen results with open source as
well
so it's about low latency Java in the
real world so low latency we know
hopefully don't that you know this is
like things that take low tens of
microseconds to maybe milliseconds and
Java we hopefully know what that is and
the real world is important this is not
theory this is actual experience over
two years of actual deployments so we
could talk about what happened and I'll
cover some of the some of the lessons
learned as well what would we do
differently had we started today for
example you know I'll talk about me and
then I'll show you who I stand in for
I'm the CTO diesel so it's all my fault
I've been working on all kinds of things
including garbage collection for a
decade plus around JVMs and this is some
evidence of me doing garbage collection
in my kitchen it's a broken trash
compactor fragments are falling off the
back the compaction function wasn't
working right so I had to fix it in
debug it I thought it'd be cool to take
a picture with a book this is in 2004 so
it's stale and I really need a new
picture I have a long history of
building all kinds of things physical
machines virtual machines kernels a lot
of systems programming applications
distributed across many systems for
millions of subscribers and firewalls
and switches and lots of stuff I'm a
little older than I look or maybe it
started you know catching up with me but
I've been working with computers since
about 1982 so I have a long memory now I
also have pet hobby of scaring people
about latency not about the length of it
but about what they know or don't know
about it and irresponsible things they
do when they measure it if you're
interested in a topic you know look up
how not to measure latency or things of
that sort and there's some useful things
around that so that's me now I'm also
standing in for Mark Price who is an L
max engineer and we actually build this
presentation together but he's in London
right now so instead of him there's me
this this is a scary picture that I took
when taking a really really scary ride
and you could see my reaction to it this
is the Dumbo ride in Disneyland it
really is you know it's taken from
another Dumbo and we were making a face
I like the picture anyway
mark is a finger developer at L max he
has focused on performance not just in
his job but in general he just likes
performance things he's he's touched
pretty much everything at L max because
he's been there for I think about eight
years and and right now he's focusing on
performance and monitoring but he's
touched not just performance things he's
actually built a lot of parts one of my
favorite thing
about howdy describes his job is he used
to be this guy the guy who everybody
came to like the psychiatrist here with
their GC logs and they told him their
troubles and he had to console them and
try and help him through the problems
and you know teach him how to do better
with their life and you know live within
the environment they have to live with
and such so GC tuning and garbage
collection knowledge was one of his
central perfuse and you know he was the
go-to guy around that l max in general
and again I'm not l max but oh I forgot
to do a really important thing here
right here see when they do this we're
gonna do this experiment when I'm mark
I'll do that and when I'm Gil I won't
have that on we'll see how that works
okay so here's me going through our cool
discussion and at El Max and I'm not
speaking for el max but this is their
material L max is basically a venue for
low latency trading they are the first
regulated MTF that's a multilateral
trading facility I believe for
transparent order driven FX trading I'm
sorry I'm reading the points because
it's not mine and need to be careful not
to say wrong things they have all kinds
of accolades and awards for example they
were they won first place in a tech
track 100 and in general they aim to be
the world's fastest FX trading exchange
so they compare themselves to other they
actually put up things on their website
to talk about their latency behavior
over the last 30 days things like that
they're amazingly transparent for what
the industry usually is which which I
like a lot because at all not not only
do we like them as a customer and that
what we get to see their improvement and
the fact that we can share that with the
world is great
now the openness of them is also
relatively rare not only are we here
talking about what they do with their
material they are also they've embraced
open source quite a bit and you probably
know them from
4l MX disruptor which is a common
pattern used in low latency or high
throughput systems today that came out
of L max okay so zing yeah we talked a
little about L max what is things
zing is a JVM for Linux x86 it's
basically good for not just being fast
but being fast all the time we actually
think that the decision probably about
20 years ago to build this runtime
that's so popular now but allow it to go
out to lunch anytime it wants to was
just a fundamental mistake computers
didn't behave like that before it wasn't
acceptable and the fact that we've
evolved into something that is so
ingrained and fundamental and productive
and good but goes and stops anytime it
wants to and doesn't run continuously is
just wrong so we roll the clock back on
that I said JVMs are not supposed to
stop it's okay for your application to
do whatever bugs you have but the JVM
needs to keep running and keep her
hanging and it shouldn't be stopping you
at least not for noticeable amounts of
time so we start off by basically
eliminating garbage collection as a
concern we don't eliminate garbage
collection we just do it right I mean we
do it without stopping the application
or stopping an application for any
perceivable amount of time from the
applications point of view for an
enterprise environments that's a
complete elimination and we're not just
talking about the big bad G C's we're
talking about any of the GC effects
small bad newgen all gen they're all
gone and whether it's low latency or
human scale response time the effect is
very noticeable in low latency systems
people think that multi millisecond
positives are deadly humans would love
it if that's all they had right and in
human applications when you're you know
doing interactive analytics with a 50
gigabyte data cube and it works pretty
well most of the time but then when it
wants to do something you need to go get
a cup of coffee and come back right and
then there's the annoying you know
online retail level of people just don't
like waiting more than a fraction of a
second to see the next shirt or dress or
something or TV so it across all that
small
large memory high throughput low
throughput GC no longer bothers you you
don't longer think about it and you know
it's a self problem and I'm I talk about
it a lot but we really should just stop
talking about it it's done let's move on
to actual engineering we don't need to
reinvent that wheel over and over and
over again anymore and I think other
people will solve this - let's just sing
right now is the only one that does
now the key quality of this is that
idiomatic Java code actually works you
don't need to start writing non
idiomatic things just to work around
things that are broken in your system
the system works smoothly even when you
write regular Java code the way you
would naturally gravitate to using it
and that means that you know even if you
can't afford any kind of blips that are
noticeable things still work well now at
Lmax it's very important to stay
responsive and a good example of that is
a recent event that happened in a market
you might have heard about the change in
a Swiss franc pricing and how it
decoupled from other things and that
change came as an event a surprising
event to some people in a market causing
some interesting spikes in volume that
went right along with it so even when
the traffic pattern changes and even if
when it changes as a surprise you still
need to stay responsive in fact this is
the most critical time to stay
responsive if you look through news
elements a right after this that play
the trading systems and exchanges that
made it through unscathed mate put our
press releases on the fact that they did
because that's something to be proud of
the guys who didn't put out press
releases well you know you can think of
what happened there they probably just
didn't draw attention to what happened
Lmax made it completely unscathed with
this they should be very proud we should
be very proud of our participation in
part a small part of doing that now when
you look at the traffic the real world
traffic that changes all the time this
is a very interesting data point we got
and and this is actually looking at what
a second behaves like a
across the day so this is every milli
second of the second left is zero there
is a thousand but repeated over a day so
this is the average of when things
happen during a second what you see here
is an interesting set of patterns there
are four spikes every second and
something happens four times a second
that changes information and people
react to it by trading and they don't
wait half a second they don't smear it
doesn't happen randomly over time they
concentrate very hard if you just
measured rates per second you get this
red line over there but if you are only
able to handle the red line or two or
three or five times that you and come
close to being able to handle this
without blips in fact this is the
average across an entire day you can
imagine that the bad seconds in the day
have spikes they're an order of
magnitude bigger than this now the
message here is when you design the
system to handle load it needs to handle
the worst load you actually need to
handle which is the top of this speak
times 10 or whatever it is in the bad
seconds and that number is nowhere close
to an average working on the average
means dying most of the time it's not a
good business proposition so you need to
stay responsive at the top of the top of
the peaks and statistics don't help you
know when bad things happen in the phone
rings with upset customers right looking
at the architecture and the some of the
key pieces of the execution venue at L
max these are block diagrams of pretty
much you know gateways talking to
external things market makers on one
side and brokers and customers on the
other you have flows going into matching
engines and a secondary for redundancy
and some journaling and it's the predate
risk and credit things that happen in in
English English a this is called a
packet of chips so this is funny in
England we'll take a packet and move it
through the system right
we did the presentation in first and
basically you'll have packets going in
coming in from market makers in this
case going through a disruptor each one
of these circles is a disruptor going
through the gateways doing whatever
protocol conversions and such that
happen they're going into the actual
execution matching engine performing the
actual matching but since you need to
get good records of this this goes both
into a journal into a second there in
case failure as their joins back in when
we know that both of them actually taken
thing whatever output formatting and
processing and other things need to
happen sent back through the gateway for
whatever conversion and sending there
and then go back out to the market
makers that is the typical classic path
of latency through the system from
taking the message to getting the
message back out that's the latency that
we're really interested in and as you
see it goes through multiple hops
through multiple systems in the case of
non market makers there is additional
hops going through and that's because
there's additional steps that need to
happen as well now that's the picture
and system in Lmax looking at from an
Azul perspective and as a perspective
the general world of Java and low
latency first question we often ask is
really I mean why are people using Java
and low latency don't you know what's
gonna happen right alright this is a
platform that wasn't designed to pause
but in practice just pauses a lot and
that should would seem like a
contradiction and the interesting thing
is the answer comes back is yes we know
that and we still use it and there are
reasons for that for example time to
stability of the platform from the day
we need to do something until we have it
stable in people's hands running in
production Java is provably better than
others empirically better than others
across many many organizations and
that's not limited to enterprise web
facing applications it includes low
latency systems there are good proven
things when people actually do this
where they just get there quicker time
to market goes right along with that so
not only do you get a good stable
product you can basically ship earlier
not just stability but
actual completeness is there quicker in
one of the very important ones and
people underestimate this is time to
performance so people might think Java
might be fast might be slow and we think
it's pretty fast can you do faster
probably but what can you do in the next
three months and if you start today
who's gonna have a faster system in the
market three months from now
it's almost invariably that Java beats
other environments well when I mean
other environments I mean non run time
based environments for example C C++ in
doing that eventually you might be
faster otherwise but if you need to get
there quickly for example if you have an
alcohol or something
yeah or you actually want to be in the
market quickly the amount of effort and
the time to get there is shorter these
are all things that we hear from
multiple customers not just Lmax in the
actual java world as the reason that
they actually code in java for low
latency this is the why now that way is
there even without zing before we came
along and change the picture a little
now overall productivity and delivery
and everything just trump the downsides
there are downsides people are aware of
them but the benefit outweighs the bad
so when we look at this things like Lmax
every single step we just showed you is
pure Java there's an any native code in
any of these systems and this is the way
it was designed from the start it was
delivered and it's a poster child it is
the fastest FX trading venue out there
better than whatever else there is and
it's written all in Java and this was
true before Xing was started there this
is purely a Java benefit now Java has
good as I said but it also comes with
some bad in some uglies right so the
good is you know fast it's productive
you can get really good code out of it
and you know if you saw Charlie's talk
which I didn't but I've seen versions of
it the the compiler isn't optimized to
do an amazing job at getting good
machine code out yes you could do a
little bit better in a various ways but
you get damn close to to do there so the
way I think about it is if you
have good developers they will get good
stuff out of anything they'll get stuff
on a machine code out of C out of C++
out of Java and most of the good
developers actually no most multiple
languages and they'll choose whatever
it's the right tool for their job
usually it'll be whatever gets them
there quicker or whatever makes it
easier and more stable whatever they're
aiming for so when people I see in low
latency choose Java that's not because
that's all they know most of the people
I know in low latency Java are actually
really good seeing C++ programmers that
choose to use Java and she tells you
something the same is true in Reverse
bad developers are gonna give you bad
slow code no matter what they write in
you can't help that and that means you
need to get good developers if you want
good code especially if performance is a
hyper critical kind of thing now the
simple truth is there are more Java
developers than C and C++ developers out
there the hiring pool is larger by an
order of magnitude or more that's not to
say that the Java guys are smarter or
less smart they're just more of them so
if you're out there hiring for
developers to deliver something it is
easier to find people to do this it's
easier to find them and or train them to
get there there's are all the good
things
however JVMs are not continually fast
they just weren't built that way from
the start and and we don't think of this
as a design criteria of Java it's just
an accidental artifact of history people
didn't think it will be used in places
that are so sensitive so they didn't
design that into how the runtimes work
and when you actually look at it the key
things are GC but there's a lot more
than GC out there there's lions and
tigers and bears and the lion is the GC
there are other things JVM do's JVMs do
that's stall that even if you solve GC
they will come back and bite you in a
zoo we actually look at all of them we
don't think that solving GC is we're
done the goal is to not blip and pause
whatever that is whatever causes that
right now low latency Java and I use
quotes to describe that is usually John
but written differently you use the Java
syntax you write in Java but you avoid
using idiomatic Java because it's the
idiomatic Java things that then make the
environment eventually do the blips and
pauses and bad things so in some cases
it means don't load and unload classes a
lot that's I think that's fairly
reasonable but in some cases it means
don't allocate objects or you still have
a key to a lot of them try to allocate
so slowly that there won't be a GC and
all a full GC or a knowledge in GC today
and maybe just an agent very rarely it's
a very common practice and how do you do
that by not being idiomatic you can't
you can either do nothing and then it's
easy but if you actually do work and
you're doing idiomatic Java you will be
generating lots of temporary objects
that's just a side effect of idiomatic
Java work if you want to do it
differently you're gonna code
differently and the first step in coding
differently is not using anybody else's
code because everybody else's code was
written in idiomatic Java so it doesn't
just matter what you do there's this
nice protocol engine over there it can
parse things for you and you don't have
to write it but unfortunately it
allocates objects so you can't use that
and there's a nice journaling system
there's nice messaging system all the
things that other people have built in
Java are not directly usable if you are
trying to do very low on location Java
which means you write everything
yourself and you lose a lot of leverage
but this does work and that's what
people tend to do so with that you know
let's look at what Xing does to low
latency Java Xing is basically a JVM
that values consistency we put a high
value or a high price on being
inconsistent and GC noise in Xing and
other noise too has been reduced to the
level where it's below the operating
system noise we are not at zero we
actually do pause four times for each GC
cycle but the pauses are so short
they're not perceptible for most systems
even when the system is well tuned the
natural noise the operating system has
is higher and more frequent than the
noise we generate at this point we can
improve it better
we can do better but it's becoming hard
to measure because we are not the signal
we are just the noise on top of the
signal at that point in the correlation
is very low now that means we keep all
the good and we get rid of the bad and
ugly parts so you get all the
productivity you'll get all the leverage
you get to use other people's code and
you get to write an idiomatic Java and
you don't have to think of those GC
saving let's not pressure the GV VC
let's not hurt it let's not scare it
because we're sensitive to latency if
the GC just works right the way it was
supposed to work from the start
regular idiomatic work shouldn't hurt
and we're saying it doesn't so basically
you could just take away all the weird
things people do to get around or avoid
stuff I often have debates with people
that say you want high performance you
gotta allocate less that's and
and some of those people are will debate
it hard with me right I have a simple
proof for that on a regular hot spot GV
I'm not saying I can have 20 gigabytes
per second of allocation done on a
couple of threads sustained with noise
that's no bigger than 5 millisecond
that's big for us but you know if
there's absolutely nothing in the heap
if all you do is generate junk you can
allocate that fast allocation is not a
hard thing and garbage collection behind
allocation is nearly free it gets more
and more expensive in blips time to blip
if you actually have objects and the
pauses get better but the efficiency is
there allocation doesn't slow things
down I know people think that but we
have proof that it doesn't it slows
things down by creating unacceptable
blips which makes you say I can't go
there and that's design differently not
because you're inefficient not because
you're spending 30 percent of your time
on something or your takes longer to do
stuff in fact allocation is often the
fastest thing you could do in Java or in
any language it's faster than object
point for example mathematically you
can't do an object poll this as fast as
a as an unhip allocator
so at the Lmax exchange what do we do
with thing so Xing started deployment
about two years ago at L max we we did
the dance and other things together but
about two years ago is when we actually
started deploying in we went to an
interesting and long road in deploying
it with some lessons learned we started
off from incremental deployments from
the most critical systems to the least
critical systems across the board and
where things are now is you know we went
from a cross layton secret sensitive
systems and then filled up throughput
sensitive systems that are not even
latency sensitive so the expansion is
now fairly wide I wouldn't say
everything is running in xing but most
critical services end up being in sync
as a default know the latency critical
path is obvious why you would apply it
if you care about the jitter and the
spikes and the stalls and the hiccups
and the noise and Elayne see path thing
is simply an easy way to address those
in addition to whatever other
engineering am i doing it or as a boat
is a replacement for it but the
throughput critical path gets very
interesting and the throughput critical
path it's about speed and you need to
keep going fast so why would a blip
matter if it's not an a' latency
critical path what happens is if a stall
is big enough in the throughput side for
example in historic market data
capturing or in gateways that transmit
things to people that are not that
sensitive to the latency but can't lose
stuff then you get back pressure and the
back pressure says oh wait a minute I am
behind by a lot I need you to stop
install and you do knocks into the
critical system and you see outliers
that come from multi second or half
second level things not milliseconds in
the three-foot path starting to blip the
latency path so unless you have truly
decoupled unbound and queues or they
built the acceptance of loss in the
throughput critical side you end up
affecting the latency critical side too
so that's why solving blips that are
higher magnitude down there becomes
important
some of them are streaming for example
market data capture and journaling of
stuff like that some of them are just
think of it as well I guess it'll be
streaming too it's just broadcast
systems of some sort right you know I
got it forward it get it to other people
reformat it whatever it is but yeah so
that's an interesting thing we learned
because we didn't think we'd be going
after the throughput critical at the
beginning and it turned out okay there
was some good value there too now if we
look at the systems on the latency path
we started off with the center the heart
the most important part and work to
address that in in deployed there and
from there we expanded to additional
pieces on the latency critical path in
that order and now we cover all those
was saying and then we expanded to these
other latency non latency but throughput
sensitive junk systems that could back
pressure this or in general need to be
happy so that's that's the order of
deployment and we'll discuss some of the
lessons learned about that in in a
little while
now if you look at development practices
at all max I think there's a lot to
learn from there in general but also how
it helped us here there's a heavy focus
on test-driven development in continuous
integration at L max they're the
acceptance tests that they have a very
wide and robust they have a good
discipline around not doing just ad hoc
testing and not retaining them for
regression and such and then if every
test systems for test generation
performance is tested like correctness
news and that's a very very important
thing to understand and it was extremely
valuable in going through this process
because the performance regression is
considered a failure which a lot of
systems fail to do they'll have a side
thing that gives them performance but
they don't treat it the same way and
they treated extremely in extreme ways
in a sense of like that is a breakage
you just don't go any forward from that
you don't kind of keep going and hope to
fix it later and that's a very very
healthy way to look at it for
you'd need to have the test and then you
need to actually treat them seriously
confidence you get confidence out of
that to create large changes because you
have the coverage you actually have a
feel for what it'll be like when you
deploy it rather than you got this nice
functional thing that seems to work well
but you know we don't quite know what
the performance will be like because we
don't have a good robust set of tests
for performance the fact that there's a
good set of tests for it and a good
modeling system for you know packet
arrivals and stuff like that allows you
to say what if we deployed this and get
relatively high confidence in doing this
the real world is always the real world
but those thing in Lmax
produces some benefits we would like to
see first of all we see improved latency
behaviors and that that's that's
obviously one of the key features we
would look for right actually
measureable improved latency behaviors
but interesting Lee probably the most
important or the more important value
over time is not the improvement in
latency because in reality give good
engineers a task of improving latency
they will find a way to do it
it's a reduction in the engineering
effort in general and engineering effort
aimed at reducing and keeping latency
healthy that is the real benefit it's
not the thing is the only way to get
this you can rewrite the whole thing in
not Java and maybe get better latency
consistency that would just take a lot
of work and hurt your productivity and
time to market but it's doable the
actual measurable things are how much
efforts do you spend on these problems
and how much time do you save from that
I wouldn't say that we have specific
numbers from that or at least not ones
that you could share am i running no I
don't think I'm gonna think I'm running
behind I think that was just early good
okay hopefully come looking at the clock
and saying Wow 35 minutes in the RT clap
Wow
you can clap for me if you wanted but we
will continue good okay so look not only
do you get better latency behavior but
you no longer battle this stuff and know
battling means you don't have to think
about it performance unit go through
three weeks of the new thing is there
and it regressed them we're fixing it
every time so it's not just the numbers
it's the time to get those numbers in
the effort and the cost to get those
numbers idiomatic Java and being able to
use it or use it again or not stop using
it it's a big deal and this all of those
have happened here so there are places
where there are new functionality needed
and oh you can use the DI Matic Java and
other people's code to do it there are
places where you're able to keep using
it because the alternative to getting
what you want was to re-engineer away
from it and they're places where it was
engineer the way and now you could go
back to using it all of these have
happened within the systems right at
various degrees so you can avoid doing
special practices you can avoid easing
up an allocation style so you can avoid
you know not using other people's code
so you can go back to good productive
things and that gives more leverage it
makes the Java choice even more right
than it was before Zee Java was right to
begin with but I think we we we kind of
tipped the scales much more now let's
look at some specific things or yeah
let's talk about actual numbers so I I
asked yeah okay you're right
exactly I asked for actual numbers these
are the numbers that Lmax was willing to
share and here's some interesting things
so Xing helped tame new Jenji C's which
is most of what they dealt with keys
remember this is highly tuned code
across across the spectrum and for
example in a previously highly
engineered system this is systems that
you know the center of the center the
thing all the engineers were were
looking at thing was already highly
tuned the improvement was from four
milli second blips which is amazingly
good every 30 million every 30 seconds
to a one millisecond blip every two
hours so we took a really good system
and maybe it made it a lot better so
okay the magnitude
is much smaller for the blip right 1/4
but the frequency is dramatically slower
this is hundreds of times less frequent
for outliers so multiple orders of
magnitude of betterness from a latency
outlier and glitch and people being
angry at the performance point of view
now in a less well tuned system this is
still low latency but just not that much
attention like a formula it can give hey
these guys are excellent right somebody
who could get an actual Java system
running in production do not bleed from
more than 4 millisecond without saying
hats off to them thank you
but in in the normal ones lips that were
50 milliseconds roughly every 30 seconds
went down to 3 every 15 so in order of
magnitude reduction in magnitude in the
size and an order of magnitude reduction
in frequency at the same time these are
actual impacts on actual systems
measured from before saying deployment
to after overtime right so where are we
to think anything and these did not
involve engineering to work around you
see quite the opposite right now that
was new gen alchun also happens not in
the latency critical path so much except
when you have you know surprising
bandwidth and surprising volumes because
if you actually look at how low latency
systems avoid doing all gen anything
they just have a big enough audience so
the promotion throughout the day or the
week in an FX system doesn't fill it up
so it never needs to collect that works
great until you have a higher volume
event where this week has five times the
volume of a regular weekend maybe you do
have to collect it right in the list
these critical systems this happens even
more because people just haven't spent
the engineering to avoid allocating
enough and promoting enough they just
have real-world things there and in
those cases the CMS this is a concurrent
mark-sweep collector that most people in
a latency a response time sensitive
environment in Java would use on hotspot
today generally they've had you know 1/2
second level blips intraday and there's
a completely gone
that means you know there's no more back
pressure on from the throughput critical
system into the latency critical systems
and that helped now
Priya's ill these would occur less
predictably but multiple times right
they would happen all over the place and
you'd have to hunt them down and be
quiet kind of depends on traffic
patterns and the behaviors I guess now
after they deployed zing this only
happens if somebody forgets to turn
singh on or to use thing because hey
they're still using stuff every once in
a while for everything's okay so let's
look at some lessons learned from this
and I would say I could wear the hat or
not these are lessons learned together
now first of all what would we do a
little different in this deployment it's
a natural thing to do we went after the
problem by attacking the critical
problem first this is the the hardest
thing to do in the system right we went
after the heart of the exchange the
execution venue this is the thing that
was only pausing for four milliseconds
it was extremely well engineered this is
where people had focused all their
effort and engineering effort and we
went to go and make that better now
obviously it's the heart and it's the
highest value point but it's also the
one that's had the most effort put into
it it's also the one that's the riskiest
the most conservative from a decision
point of view right if you go and do
that you know you need to beat the
engineering effort and you'll have
smaller games and you'll have to gain
confidence on the bet the business part
of the thing right that's what we did
and we did and we made it through but it
was a long time to get there because you
know you need to show the numbers
achieve the numbers and get a lot of
confidence that the real will will
happen before you cut over we succeeded
in doing that and from there we expanded
to them much easier systems right but
with hindsight we could have started
either backwards or concurrently don't
take the biggest bully on the playground
and go punch him in the nose and take on
the fight and when you win that let's
let's deal with other people just let's
play with everybody else first let's get
a coalition going that's good talk to
the
altogether right we could have taken the
things that took us a day or two to show
extreme value in that are not as
critical that could be converted easily
with high confidence or without that
much confidence just to show that we
have confidence develop confidence there
there are food good practices there get
a lot of value there places where what
we did is remove a 500 milli second
instead of formula second live and with
that take out potentially a lot of
engineering that wasn't yet done so a
lot of value to be saved as opposed to
here where you know it's less value and
then after we did those go after that
critical thing so ending in the exact
same total deployment picture we could
probably have gotten there faster by
starting from the easier first things or
at least working concurrently not see
early through them so we probably would
have seen quicker ROI quicker time to
gain and and quicker confidence in the
delivery of what we do obviously the
choice to go with us was done based on
what everybody believed we could do but
showing that that actually happens
getting to a point where two years later
they just know it's right there's no
point in doing the other in if you're
latency-sensitive
getting there takes time takes actual
showing real production stability
quality and actual delivery okay so we
could have gone in a different order
other lessons learned she sees not the
only problem she's just the biggest blip
that makes you think but you take that
out there are other things there for
example you do have dominated outliers
so it's natural to think everything is
there to pay most attention to it but
once it's gone other problems surface so
some of the harder things page cache
lock contention certain Linux kernels
have extremely bad locking behavior
around emptying page caches so in
systems Journal where a lot of
loneliness this doesn't have to journal
because they're dealing with money then
when the kernel stalls to write a whole
bunch of stuff it orphans actually locks
and stops progress and
systems parts and even the lower the the
the things there's an outside of latency
critical path going to disk might stall
other things that are latency critical
power management tuning bias and OS lots
of tuning things were very important air
map file access and page faults and safe
points in the interaction between them
which are not unique to you know did
they apparent they apparently happened
on all runtimes zing and nuns in could
come in and create some interesting
issues now one of the big lessons
learned was to proactively not
reactively but proactively override
Linux defaults Linux has a whole bunch
of things that are just bad defaults if
you care about latency behavior they're
there to save power in the data center
not to make your application behave well
and if you care about your application
behavior more than you care about the
power in the data center did the wrong
choice so you know examples let's go to
specifics this goes this way it's my
second yeah the page cache tends to be
dramatically miss configured by default
on on Linux and this specific parameter
is the distance from filling all the
memory before the page guest starts
flushing things out how much empty
memory is it aiming to keep in the
system for things like I don't know
allocating memory with Malik's right now
interestingly the choice of the number
for that was chosen about 20 years ago I
think around to 1995 or 96 and it was
modeled according to size of servers
back then 20 years ago and then they
didn't fix it at a constant they had a
model for it growing but it doesn't grow
linearly it grows to the square root of
the system size so we have 20 years of
accumulated system size which roughly
translates to if 20 years around Moore's
law is probably under five to ten
thousand X capacity but instead of
growing the buffer from the edge of
memory by five thousand x over time it
was the square root of 5,000 X which is
much smaller number and what that in
practice means is that the filesystem
runs into the edge of memory all the
time creating situations where you have
no empty memory and it has to get rid of
stuff but it takes time to get rid of
stuff therefore you have a blip on a
simple memory allocation or an expansion
transparent huge pages a really really
really cool feature for efficiency that
is really really really bad for any
latency measurement this thing should be
turned off it is turned on by default
without expanding on it here the simple
behavior you could experience if this
feature is on is that your thread
because it's doing some malloc or
expanding a stack or something else
might be the one that stalls to
defragment all memory in the system for
the next second and which thread gets
hit with that is just Russian Roulette
the more I owe you do in your system the
more fragmented large pages are into
small pages the more likely this is to
happen unfortunately there's a lot of
journaling IO happening in most of these
systems so it's very easy at all sois
penis needs to be set to zero for some
reason it's not I don't know why people
with a hundred gigabyte system needed to
gigabytes swap file except for to make
the latency bad I don't know what it's
good for other than that but you know
should be off and off and then this is
an interesting play mode it turns out
that by default at least in some kernels
when you have multi node systems like a
two socket system as a multi node system
you could be turning you could have swap
off on swap set off but if you end up in
a case where one of the nodes is out of
memory but the other one has memory it
will still fall so unless you turn this
zone reclaim on to zero you your swap
eNOS could still not take effect and
their other around the page caching to
you as well so each and every one of
these if you don't set it right can and
will cause multi hundred milliseconds in
your Linux system without Java being
involved so if you don't take them out
proactively you
and wait until they happen you're just
gonna have a big mess to try and figure
out so it's really hard to prove that
it's one of those when they happen it's
really hard to point a finger to them
each one of them has been built through
experience of accidentally running into
a proof that one of these did something
so think the lessons learned from a big
industry that you know has run into
things and there are other sets but
these are good examples to start with
okay some more lessons learned measure
measure everything measure everywhere
you can you know we you know at L max
measurement was already been done to a
lot of things but measurement of things
like jitter and hiccups and
inconsistencies is a hard thing because
of what you tend to summarize data so
you have a good average as good maxes
maybe but when and how much and what the
spread is is hard so it's really hard to
collect this and it's worth spending the
efforts to put an infrastructure
collected not just within parts but
across multiple hops you saw the kind of
hops that a critical path for this
measuring it not just at every point but
across them with consistent time is
important the other one is if you want
detailed latency distribution
measurements that means you can't sample
and you can't average and you have to
keep either keep a lot of information or
record it in a way that supports doing
that and if you have information about
the latency outliers at every step and
across the whole that really helps you
triage where to look so if you have a
blip on the end-to-end latency but you
don't have a record of where other where
what the spread is on latency on
different nodes you don't know where to
start looking within them the averages
are good everywhere it's a blip so you
need to know which one's had blips and
look for correlations if you don't
record enough information for tracking
blips it's their full percentile
spectrum histograms are very useful for
this I've actually built an open source
library that's very useful for that call
HDR histogram Michael Barker from L max
created the seaport of the same library
so it's now in Java and C there's a
c-sharp port a python port a go port in
Erlang port I'm waiting for the
JavaScript port you want to do a ruby
one
well you can just use the Java one from
JRuby so you don't care yeah so it's
it's it's become a very popular library
for doing exactly that if you're
interested in measurement I recommend
you do that and I'm also doing a
full-day workshop on it on Thursday if
you're really interested and not on HD
or Instagram but latency measurement and
coordination is general recording system
level hiccups at all levels is extremely
useful for triaging there's a tool again
I I actually created it three years ago
and open source is called J hiccup and
all it does is basically measures
whether your process experienced the
hiccup meaning it was supposed to be
able to actually couldn't couldn't it
measures every milliseconds so anything
bigger than a millisecond of blip for
whatever reason can't hide from it you
run one of those in your JVM to see if
your JVM is blipping you run one of
those idle in another process to see if
the system is blipping and you keep
records forever for that well for weeks
not because you need to know all the
time but because somebody calls you up
and says there was a bad transaction
with a blip and you try and figure out
where the blip happen and whether it was
a system blip or JVM flip an application
code blip
if you find that your system blip for
the same magnitude as the complaint you
don't need to look at application code
there's nothing wrong with the
application code something in the OS or
in the hardware or something blipped if
you find that the system was fine but
the GPM blipped well then you know the
system's fine and go look at the JVM
itself maybe the tuning is wrong maybe
you're just not using sync then if both
of these are nice and quiet and you have
a blip then some things go look in your
code maybe you have a cue maybe you have
some other thing that happened maybe the
latency on the wire is wrong maybe of
bad wires but the triage ability of that
slicing which parser system to go hunt
down are critical for evolving good
latency over time now if you look at
observation points that lmax is used yep
I'll wrap up in two minutes
observation points you can see across
here there are multiple points that
latency numbers or time stamping numbers
are collected an interesting thing is
the more points you add the more it
becomes interesting to think of
how you collect the data and where you
put it so you take the message and you
track it through and you want to know
when and where things happen and if it's
a handful of things then okay you can
often add it to the payload that a lot
of people will do that that's a good
starting point but if you actually go
through and start wanting to have many
many data points of where things were at
what time for a message it starts being
a challenge to put that data in the
messages it goes through there might not
be room for 50 data points in the
payload or you're strongly affect the
system at that point it becomes nicer
and better and probably much more
scalable to start logging the latency
points as metadata on a side stream so
the messages are going through and you
don't carry that when I was where on the
actual payload you just log to the side
message ID this was here at this time
and that's a stream of metadata going to
the side not latency critical you just
need to get it somewhere either a
journal or another system and later you
go and correlate them all that becomes a
post processing streaming thing again
the purpose of this is for knowing what
when you need to know you can look at it
or you could do samples and monitoring
with it too but it's a very very useful
thing and it's worthwhile investing in
that investing a lot I think because if
you don't do that you're gonna invest a
lot in debugging in the dark so let's
look at summary and wrap up Java is
viable and profitable in low latency
these are often things that people
challenge it is viable people do it
anyway and it's profitable to do it you
can show numbers of why economically
this is a good choice from a development
effort from a cost perspective from a
profitability a time to perform it's
time to profit kind of thing with
regular JVMs you have to jump through a
lot of Hoops to get there but it's still
profitable and viable people do this all
over the world and thing basically helps
in that well to make it even more
profitable and even more viable right so
it's easier to do it and it's as easy
and low latency in other languages so
think of it as it's the speed of Java
which is
similar to speed of other languages now
with the consistency of other languages
too now once you stop dealing with j-b a
related issue you can actually go and
take your smartest people and apply them
to the interesting and good stuff think
to that opening slide where Mark showed
what he used to do on a regular basis
people would come to him with GC longus
and try to figure out together what to
do about them he doesn't do that anymore
he hasn't done this in a long time
the answer to a bad GC log is wiring out
running in Z and we don't get bad GC
logs from saying or we haven't seen them
at least so that's that's a simple
summary with that so with that I you
know do we have a little time for Q&amp;amp;A
or we have to go okay well well yeah we
started five minutes late so I think
we're even but if you guys want to I
mean I think we're last year and we can
go out but if you guys want to ask me or
me a question I'd be happy to answer</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>