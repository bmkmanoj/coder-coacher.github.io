<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Swift 2 Under the Hood • Alex Blewitt | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Swift 2 Under the Hood • Alex Blewitt - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Swift 2 Under the Hood • Alex Blewitt</b></h2><h5 class="post__date">2016-09-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VxrmEfc7dBc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so about this talk what I'm going to do
is I'm going to talk a little bit about
the history of Swift where Swift came
from some of the things that turned it
into the language that it is today I'm
gonna use that information to then talk
about what makes Swift fast why it is
that Swift is a better language to have
the objective seen from the speed
perspective and we'll have a little bit
of look at where Swift is going my
name's Alex blue you can reach me on
twitter at our blue and i am for my sins
our next owner and a veteran objective-c
programmer back in the days when having
big black pizza trees was cool I also
wrote a book Swift essentials which came
out at the end of 2014 end of last year
all of this information is being
recorded for the video so just for that
this information is based on Swift 2.1
which was the public release in december
came out a couple of months ago Swift is
still not yet open sourced I checked
before I started they have not opened
sourced it yet they have four weeks left
to open source it which they said they
do by the end of 2015 so check back soon
I've also got another book another
version of the Swift two essentials
coming out next month
so where did Swift come from Swift has
been under the covers for quite a long
time in development but you can trace
the history all the way back to when
objective-c started Objective C came out
in 1983 and it was devised as a small
talk based language that could be fit on
one on top of a C based programming
language that probably wouldn't have
taken the world by storm
except that next licensed it as their
operating system and next is fairly
famous next that came out in 89 and is
the NS prefix that you see on things
like NS away and NS dictionary and NS
object next itself wasn't doing too well
until Apple bought out next in 1996
and that was really the turnaround time
for both Mac as the platform and Apple
as the company so objective-c goes all
the way back to essentially the early
2000s there was a product called OS 10
server that came out in 99 but it was
really OS 10
came out in 2000 and then publicly
released in 2001 that bought Objective C
to the masses interestingly on the TOB
index as of November objective-c was had
quite a big Y's due to the iPhone and
it's now on the way down and actually
Objective C and Swift are neck-and-neck
in the t OB index next month they will
be swap around so if will go above
Objective C for the first time so what
is Objective C well you probably know
about it if you've been involved with
the Apple ecosystem or iOS ecosystem for
any length of time but essentially it
was a processor that originally a
preprocessor that translated classes
could compile down into C based code and
the reason why it's so popular today was
because we form the basis of the
next-step operating system and then
because it was integrated into the GCC
and therefore releases the GPL you
started to see other platforms pick up
Objective C there's one called new step
which is still around you can still have
the equivalent of project builder inside
there but there perhaps not as popular
on non-apple systems you can actually
have a look at where Objective C comes
from into one time although probably not
on this slide it goes back to 1999 Apple
computers so a long history but the
reason I mention Objective C is because
there's actually been a lot of
development of languages since the old
days so in the old days we had C in
small talk those are the blurry ones on
the left and Objective C was really the
lovechild between C and small talk that
came out in 1983 about the same time as
C++ came out so the original C++ and the
original Objective C came out at the
same sort of time not what happened for
quite a while and then LLVM was released
in 2003 which is really the starting of
Illuminations of the redevelopment of
the apple developer platform and that
led to objective-c sort of tangentially
in objective-c 2.0 tangentially in 2007
when we had things like dynamic
properties automated automatic reference
counting and when Apple finally got with
the GCC within clang which was released
in 2009 there was real momentum behind
what this platform would have those
things all came together with the
and release of the Swift platform in
2014 now by that time they had been
working on it for several years it picks
up influences from both the objective-c
background would also C++ as well and of
course recently we've seen Swift 2.1
which was released a couple of months
ago now the important thing about these
languages the ones at the top are all
based on static dispatch that is when
you compile and call methods to a
particular object you know at compile
time what it's going to talk to the ones
at the bottom are all based on dynamic
dispatch and the interesting thing about
Swift is that it actually has modes to
be able to do either these things so you
can have something which is compiled the
new static dispatch and therefore could
be linked in quickly and you also have
the ability to call to the existing
objective-c frameworks and use dynamic
dispatch as well but that's a period of
30 years and quite a lot has changed in
the last thirty years thirty years ago
back to the future we're still in the
future thirty years ago humans thought
digital watches were a really neat idea
and thirty years ago there was a Star
Wars film in the cinemas so lots has
changed since then but importantly for
processes
they've got faster and faster but
desktops tended to plateau out about
three gigahertz mobile devices are still
rising today but generally they're in
the order of one to two gigahertz and
the performance over the last decade has
come from the additional number of cores
that have come in so whether that's
multiple cores on a CPU multiple CPUs or
for the GPUs multiple cores inside the
GPU that's really how we've been getting
faster but the important thing is that
whilst CPU speed has increased the
memory hasn't increased nearly as fast
this is a graph from computer
architecture a quantitative approach
which is a book that's received by LC
burr you can't really see the numbers
but it's sort of decades from 1980 on
the left to 2010 on the right and on the
axis on the far side that's really just
a log index for the power ten hundred
thousand ten thousand and so on so to
put a few markers on this graph so you
can see where they came from
we had Commodore 64 coming out in the
mid 80s and that was roughly the sort of
comparison speed that you had between
we and CPUs interestingly enough the
Commodore 64 was pretty much the same
processor and power as they had on the
Apollo landing computers that were
mentioned in the presentation earlier
they're about the same sort of speed
that had the same kind of memory that
the Apollo landing computer was a 16-bit
and the Commodores an 8-bit but it's
similar sort of processing power between
them then we had the Apple Mac being
released in 1984 the original version we
had the Mac station that came in in the
90s and that was really the birth of
objective-c
now objective-c actually happened a few
years before that sort of in the period
between Commodore 64's and the Mac
release but it was at a time where in
processes were getting faster and memory
was getting faster about the same time
they were still relatively close to each
other but then scroll on through further
systems with the iBook the PowerPC g5
and indeed the iPhone back in 2007 and
as we've been going faster and CPUs the
gap between memory and CPUs has been
getting wider and wider and
interestingly one of the most recently
released computers you might have heard
of it the Raspberry Pi zero kind of fits
in around about here on the map in terms
of the processor speed we think we're
going quite a long way if you're a fan
of Raspberry Pi and you're a fan of
space you might be interested to know
that there is a vari pi sitting on top
of a rocket in Florida at the moment and
will shortly be departing for the
International Space Station that
launches tonight at midnight this local
time if you're interested in watching it
but the point with all of these things
is that there's a real difference
between how fast the CPU is running and
how fast we can get data from the memory
and that's because there's a huge amount
of latency that happens between memory
and the actual running cause the way
that we solved this was by introducing
caches so every Core these days usually
has a level 1 cache that sits pretty
much light next to the CPU core itself
can get data in and out at about 1 and a
nanosecond latency there's usually a
layer 2 cache which if you have multi
cores on a single chip is then shared
between but all of those calls and
there's often a level 3 cache that hangs
around at the back end each time you get
further away from the processor you have
higher and higher latency that is the
time between when you request the data
to be there and the time that it comes
back and this is actually quite an
important part because when Swift was
developed they were trying to avoid that
latency gap the latency of going out
fetching something to do next and then
bringing about him in certainly these
numbers are based on the iPhone 6 and
iPhone 6s that's the iPhone the CPU
processor a8 and a9
and so this diagram if it shows up well
the presentation slides are available
afters you can go back and look at the
details but on the far left hand side
we've got the level 1 cache we've then
got a level 2 cache you can't see the
axis down this side but this level 2
cache is about kind of 10 nanoseconds
worth of latency a level 3 cache hitting
in about 80 millisecond 80 90 seconds
and then main memory being that much
further away so if we can shrink the
size of the programs down and we can
solve the round-trips going out to
memory when we jump around the place we
can make our processes faster and we can
reduce the battery voltage and faster
processors and lower battery consumption
are really what Apple is concerned about
so that's why Swift was created we also
have a few other nice things that came
in Swift for example we had namespaces
and modules I was a big way of breaking
things down that previously was using
frameworks importantly with Swift we
have the ability to choose between a
reference base time and a value base
type so reference base types of dist NS
objects you have a pointer to somewhere
in memory and then that data is stored
inside there with reference truck sure
base type of value base type then the
object is actually contiguous in memory
and if you have an aware of them you can
lay them out importantly Swissport
around interoperability with Objective C
and because Objective C is based on C
it's got things like an undefined
behavior and nasal daemons those are
generally bad things to have swift
doesn't have any of these undefined
problems that we need to worry about
modules well we know about modules in
Objective C terms they're frameworks
Objective C based ones that we can hook
into are things like foundation UI kit
sprite kit we've got modules that
represent C programming
is like dispatch for doing the grande
Grand Central Dispatch that you'd use in
the objective-c as well the sim D if you
need multiple executions and things like
Darwin which then hook into the C
libraries that you might expect to come
across things like random and exit and
so on and then there's ones that are
based in Swift these are few and far
between at the moment but if and when
Apple releases Swift as open source you
can expect that a whole bunch of those
are going to come alongside so we've all
got the Swift which is automatically
important module that defines things
like string and array in dictionary and
there's a module built in as well and
built in is how the swift one-time
associates the data with the process so
that you're running on it defines
internal representations like 256 bit
int and so on all of these things are
wrapped together in a consistent type
space the type space has either
reference types classes either in Swift
or in objective-c and value types which
should take the form of structures but
those are the things that actually get
laid down in memory the type system also
has the ability to lay on additional
things on the top of them protocols are
a way of doing duct based typing a
protocol basically says if a class has a
particular method then it adopts the
protocol and you can add protocols to
existing classes without needing to
change their source code and extensions
are ways of adding new functionality to
methods and classes without needing to
change any source code either both of
those two things have proved over and
over again with Objective C to be a
great way evolving things forward and
Swift is no exception to that the
interesting thing about this is that at
one time when you have something like a
numeric value 64 bit in 32 bit int then
it's represented the same way that it is
in C it's represented just as one small
bit space without any extra pointers
inside but it behaves as if it was a
real type so the last presentation was
talking about scholar and types you have
things like which int in there for being
able to wrap additional methods around
existing integer objects but in the
scholar approach those types
essentially a wrapper value so it's a
wrapper object and it changes the
structure and memory in Swift you don't
change the structure in memory you have
exactly the same content in there you
just add additional behavior inside so
the way that inter is defined is by
having a structure and that structure
has a single value inside it along with
some other methods that do what the
maximum and what the minimum value is so
although int looks like just a 32-bit
value it's actually treated as a
structure type in surfed and because
it's treated as a structure type you can
have methods that are associated with it
you can also adopt protocols so there's
something called a signed integer type
which represents all the signs types in
Swift and you have a protocol called
comparable which allows you to compare
two things and make sure that they have
the same content similarly with the
unsigned int you int that also has a
similar set of protocols at the top with
unsigned integer type and comparable the
nice thing is that the size of both of
these things is still 8 bits so when you
have one of the eight bytes when you
have one of these things that lights out
to memory then it takes up a fixed
amount of space inside there and that's
because these built in in 64 so actually
the real thing that's under the covers a
lot of processing happens in Swift with
these protocols and the way that it
looks at we draw it as a type is that we
have any at the top which is actually
just a generic name for a protocol
without any methods inside there and
then all of the types in take in 32 you
int you in 32 and so on
I will structure base times their value
base times when you have a value type
and you call the method you pass a copy
of that object into the function you
don't pass a reference to it if you have
in a way of these things then you have
it in a way that takes up the contiguous
size of the number of structures that
you have inside and we add behavior to
them by having protocols and then the
extensions if you want to if you wanted
to write a method to calculate half an
integer for example then you could add a
method called half as an extension to
the int type and then you'd allow you to
do on the command line anywhere one dot
half and it will give you the value back
again so I've spent a bit of time
looking back at objective-c and talking
about how things are laid out in memory
why did I bother doing all of that setup
well it's all to do with how Swift
essentially has the means to be able to
be faster than Objective C at one time
one of the ways that he does that is by
how the memory is laid out if you have
Objective C and you use something like
an NS array of objects then really what
you're doing is you're storing and a way
of pointers and that's a way of pointers
then points to an object over here or an
object over here object down here and so
on this leads to both memory
fragmentation and also diverse memory
locations and this actually hurts CPU
performance because if you want to write
a loop to go through all of the elements
inside an nsarray it's not just the case
of having to step through the point is
you also have to dereference all of
those pointers as well and when you do
the dereference the CPU has to then go
back out to memory it's probably not in
cache so we have a full 180 no I know
seconds hit to be able to get the object
that comes back and once we've done that
and we go on to the second object you
have exactly the same thing again arrays
of structures or value types in Swift I
actually laid out as one continuous
block so if you have in a way of 32 bits
then it's just 32 bits after 32 bits in
memory and this is great for processors
because one of the ways that we've seen
the CPUs deal with latency problems is
by having cache and what happens when
you issue a read for the first element
in the array what happens is the system
will hit and fill up a full cache line
and a full cache line is different for
different processors but 64 bytes is not
a unheard-of number for the level 1
cache so what happens is you issue a
read for 64 bytes worth of data and that
means as you go through the first eight
16 32 you're actually just reading
straight from the cache the other thing
that CPU is a very good at is noticing
that you read this block then the
subsequent block so you're probably
going to want to read the next block
afterwards and the CPU can actually
issue speculative weeds to say ok we
look like we're walking through this
array linearly
let's read ahead and let's get some data
that was filled up in the cache lines
and so the memory optimization for value
based types is really important now I
should point out if you're dealing with
objective-c there are actually a bunch
of struct based values if you dealt with
things like
she wets disruptive float values and so
that has the same kind of performance
but Swift makes it clearer and it tries
to encourage you to use more value-based
types rather than rapper based objects
that you have in Objective C the other
difference is the static and dynamic
dispatch we talked about the influences
the languages and where they've come
from in the past but static dispatch is
the thing that's used by C and C++ and
by Swift if you don't use Objective C
classes and the nice thing is that the
function calls are then known precisely
so when you have a function call and it
reaches out to a function that you know
at compile time what it's going to be
the compiler can generate essentially a
direct function call with call or call Q
to the direct simple this is not only
the fastest way that you can call
functions but the compiler CPU knows
about these cool instructions and if we
can see in the pipeline there's a called
instruction coming down and it's
pointing to an address that's already
resolved then it can reach out to memory
and start downloads in that code so by
the time the call instruction hits the
CPU it's already got the code in there
to do it dynamic dispatch which is the
way that Objective C methods work and
the way that Ruby and object and the
small talk work will go through an
indirect call called objects obviously
message sent essentially what obviously
message senders doing is it's replacing
the call with a pool to a dynamic lookup
of something in a hash table so when you
want to call a method name or a selector
in Objective C terminology it hooks up
looks in the table and then gets the
data back Ian the reason I put in here
in Swift Swift is actually capable of
generating classes that will fit in with
the objective-c runtime and use dynamic
dispatch and they've got that there so
that they can have compatibility with
existing iOS frameworks like you I get
and ultimately provide a migration path
from one to the other so the difference
between static dispatch also effects
optimization if we have a sequence of
function calls a to B to C and we can
prove that we're always going to call a
them a gonna call B then we're going to
call C there's a way of optimizing all
of these things together essentially
squashing them down into one method so
that we just have one copy of the code
if you do that there's no hopping around
in memory there's no late
see problems the CPU can just get what
it needs to done and then go back into a
deep sleep mode without taking any extra
energy in dynamic dispatch like you have
with Objective C you don't have that
because every time you hop from one
method to another you always go in via
Objective C message sent and the C key
you can't really optimize Objective C
message send because every time you go
through it it's looking up an entry in
the hash table and it has to wait until
it knows what the answer for that hash
table is before we can then branch out
and call the function now Objective C
message n is fast its built-in assembly
and it's been hand tuned over the
decades but there's still some overhead
there's overhead not only in the fact
that there's extra instructions which
means that you're going to cause extra
battery power but also any function that
you have in Objective C message send
means that you're taking up at least two
parameters you're taking up the self
object this that's referring to the
object you're calling form and also the
CMB the selector value and that means
that any function that you call is
always going to have two arguments that
get passed into it now that is important
because under the covers what happens
with call based processes is that they
usually have four arguments that they
can store in registers and then the rest
of it gets spilt onto the stack so with
Objective C you really only get two
arguments that you can call in an
efficient way before it has to form a
slightly different efficient thing and
if there's one thing that Apple love its
efficiency because efficiency translates
into battery life and the long you can
have battery life then the more phones
that they can sell now this assembly has
been evolving over time back in the
leopard days it was about 100 bytes
worth of assembly there was a huge jump
that went down to Lion when he dropped
down to 47 bytes that's when they took
out a special case handling of garbage
collection something you might have
remembered the garbage collection
support that Objective C had back in
those days and particularly eagle-eyes
will have noticed that in Yosemite it's
actually gotten up a little bit and
that's because there has been something
called tanked pointers or non pointer
Isis which needs a little bit of masking
before then calls into the actual
function it's off so it's still pretty
fast
most of the bytes that fit in there are
going to fit into one cache line but
essentially the CPU can't optimize the
calls between functions because it goes
into a message send and then it goes out
to pretty much every Objective C message
that
now the other reason my optimizations
like this so important is because if you
have a pool chain of A to B and you can
compress that down into a B you suddenly
open up the possibility for more
optimizations to occur not only do you
get rid of the function calling and the
any stack or register spills that are
going to go on but you can also avoid
branch missing and memory jumps which
can also slow things down but
importantly it also unlocks further
peephole optimizations so if we have a
function here foo which takes an int
value if the int value is negative say
we've hit some sort of error condition
and then we return an abort early out of
the function then if we ever call it and
we know at compile time that the value
is negative essentially it's a no op and
we can just get rid of it and wipe it
out and actually quite a lot of the
optimizations do that one downside is it
increases the code size potentially if
you're squashing these things together
but on the plus side if you have
negative values or other things at from
a particular condition then you can
optimize the calls away and generally
the fastest code is the code that the
CPU never has to run there's also
something R which is being called either
link time optimization or whole module
optimization depending on where you add
it from first but essentially the
purpose of this is to say instead of
just focusing on a single file and doing
the optimizations inside there what we
can do is we can pull out modules we can
call our optimizations across different
files across different modules and that
usually then unlocks a lot of different
optimizations that happen so when you
compile file instead of generating out
an Intel object file with all of the CPU
specific information inside there it can
actually want to have a form of LLVM
byte code or ir when the LLVM linker
ones it can then pull all those together
and run optimizations and generally do a
much better job for being on to optimize
things and it wouldn't surprise me if
those things started bleeding down into
the swift libraries as well so that when
you're copying the Swift library code
it's actually optimizing the library
code for your particular application so
that it goes in now from our programming
point of view if you want to take
advantage of this you'll be wanting to
make your methods
data structures as final or private
because those then essentially unlock
permissions for the compiler to be able
to unlined those sluts are always final
you can't subclass structs so you don't
have any way of changing that and if you
have functions defined as private or
internal then they're going to be
declared as being local to ID that that
file or that module or target and they
can be optimized away now certain LLVM
really came together about the same sort
of time the guy who did most of the work
on LLVM was a guy called Chris Latner
and he was also the main architect
behind Swift and he's one who's really
pushing to get Swift open-sourced LLVM
has been around for a while but
originally stood for low-level virtual
machine which is not really a great name
for it especially for people who've come
from vm backgrounds from either Java or
the.net world really what LLVM works on
is the idea of an abstract assembly
language something where you have an
infinite number of registers and can
actually call functions without having
to declare particular prototypes it's
called and returned convention agnostic
so that you can specify things and you
can either have a c function call or you
can have an objective-c function call or
a direct inline function call as well
and this is used in the Swift compiler
the Swift compile pipeline has something
that translates it into an abstract
syntax tree first of all the abstract
syntax tree then gets parsed and
semantically analyzed to make sure be
referring to correct types then it gets
translated through into something called
SIL which is the Swift intermediate
language which is kind of like high R
but a slightly higher level so it has
knowledge about Swift intrinsic slike
exception handling calling sir
functionality and Swift methods there's
been a video posted on YouTube by Chris
Latner from the LLVM developer's meeting
that happened in October I think the
YouTube video went up about three weeks
ago where he talks about the benefits of
having SIL as a separate language to IR
if you're interested in I suggest you
look that up from the LLVM developer
meeting and then the sil gets translated
into hello VM IR now that's been around
for a long time that happened when LLVM
was initially released it's used by a
clan and the objective-c compiler with
Xcode since
Xcode five or six so it's been around
for quite a long time but the ir tends
to have some
platform-specific dependencies in there
like what the word size happens to be
for example and then you can output it
to either assembly bits code or like the
output the bit code here is the one that
Apple are encouraging people to use
because if you upload bit code into the
Apple Store then Apple can we link the
whole application and maybe perform
additional optimizations that you didn't
know about when you built your code so
how does this work in practice well
everyone knows how we do hello world
example so this is our hello world
example in swift print hello world that
goes through a parse tree genex to an
abstract syntax tree goes to a semantic
based analysis to make sure everything
works out and hooks up from a typing
perspective gets generated into the SIL
point line to generate Swift
intermediate language that then goes
through a further set of optimizations
before it's translated into LLVM ir and
then once it's got to LA via my art it's
just handed over to the back ends of the
LLVM tool chain which can then spit out
either object files or dynamic library
files only native executables and that's
sort of the pipeline now one of the
interesting things about Swift and
indeed LLVM is that there's arguments
that you can use to actually see the
intermediate stages so each of these
things I think the LLVM guys left them
in there initially for debugging
purposes but it's quite interesting to
see what happens and if you wanted to
you could write your own language which
targeted si l or maybe you'd want to go
from translating ruby into si L or Java
into si all those kind of things are
possible if you wanted to be able to
generate those things so let's work
backwards and see how it all looks like
this is the example in C which got a
main method and a puts hello world
if we run clang with the emit LLVM
argument then we get back the LLVM code
and so this is the LLVM code for the c
based language it kind of looks similar
you can see where some of these things
have come from from a syntax perspective
there are some things to do with global
variables so this app STR at the top is
called a global value or global label
and then once with a % or essentially
local
a particular function those are the
infinite registers that I was talking
around and then the call function there
ends up just invoking the put slop
symbol which is then resolved from the
linker when it comes in and you can then
trace that down into the assembly if you
want to by using emit assembly on the
time compiler and you can see on the
pool cue puts line in the middle of the
assembly at the top that it looks as if
it is you know calling the function
directly that's a nice thing that the
compiler can optimize for you and
there's a whole bunch of reasons why ir
is good it allows you to understand
what's going on at program from the
compile level it allows for accurate
transformations you can have in learning
across function calls because it knows
they're calling syntax and you can
eliminate code paths but it's got a
bunch of phases in there that are
language agnostic there's a lot more
things that you can unlock if you know
things about the particular application
if you know that for example you're
calling a function and you can prove
that because of the arguments you use
you're never going to see an exception
bubbling up then you can actually just
omit the whole exception catching code
that you would go along with it so let's
have a look at and see how this works
with Swift with IR we can use the Swift
compiler this time with an emit IR
argument rather than emit LLVM a
standardization and then you end up with
something that looks a little bit like
this again we've got the app's main in
there which is the global we've got the
at zero constant which is the hello
world string and we've got a bunch of
complete gibberish on the method that
we're going to call there so what does
that mean why have we got gibberish
there both of them something nice like
just print well the reason why that
exists is because something called name
mangling a name mangling is the way that
you translates the source base functions
into the actual names of the symbols
that get put out in the assembly file C
has a really complex encoding Convention
for this it sticks an underscore on the
front so actually C based programs are
relatively easy to debug C++ use name
mangling because you could have method
overriding so you can have different
methods with different return types or
different argument types and in order to
distinguish from nose and indeed the
main in one class versus the main in
another class there was an encoding that
was used so anything that begins with
underscore underscore Zed
is going to have a C++ name then there
is a length based encoding so the for
immediately after the Zed means that
there's four characters of name that
comes up afterwards and then various
different symbols have particular
meanings like AI meaning int and PPC
meaning a pointer to a pointer to a car
well that's the car and char star star
that you have at the top of the main
method swifty is much the same except
it's a lot more complicated
so anything beginning with underscore t
is a swift based symbol so in this one
we have a whole bunch of stuff which I'm
not going to read out most of this is
probably going to be uninteresting
because you're never likely to look at
these things directly but F means it's a
function type anything with a capital S
means it's to do with a swift module and
s capital S with the little s means the
swift module that you get with import
Swift v print means we've got five
character method name a function name
called print the TGS ap is actually a
concatenation of these things bunch but
a bunch together
it's a tuple of a generic array si is
away and then P underscore underscore is
a protocol which essentially that line
consists in a way of empty protocols or
in a way of any objects and then we've
got a couple of other arguments we've
got a separator and we've got Terminator
as well now in Swift 2.1 the print
statement actually has a couple of
arguments inside there that allow you to
have separators and a lie to put
additional new lines on something that
was changed from the swift one days but
essentially if you do print 1 comma 2
comma 3 that gets translated into an
array of values and then for each one
that gets printed out it prints out a
separator so if you wanted to have a
semicolon organized list of elements you
could say 1 comma 2 comma 3 separator is
semicolon and then the Princeton would
would hand a hat for you that's why the
print statement looks a little bit weird
when it goes on now fortunately you
don't need to understand any of these
things because there was a tool called
Swift d mangle you can't run swiftly
mangle because it's not on the path
directly but if you use xc1 and either
pass in the value as an argument or
simply pipe the stream through you can
then use it to figure out what it means
so in this case the symbol that I've
pulled up here when we've deep mangal
dit essentially says there is a function
called
- dot print it takes an away or protocol
angle and closed brackets
that's the anytime in Swift and it has
two other arguments a separator and
determinate er and it returns a nothing
um so we can use this to see what the
intermediate language happens in this
rift alright so if we do Swift C compile
the Swift file and then use iMix si L
then we get something that looks a
little bit more understandable again
this still has the references inside
that for those particular functions but
one of the most things it does is it
spits out in comments what the function
types and function references actually
mean and you can also pipe the whole
thing through the Swift d mangle and any
time it sees stuff beginning with an
underscore t it will automatically try
and translate that into an appropriate
time so in this particular case our
hello world has got an implicit main
function which is the still at main down
at the bottom it says we're using the C
based convention for calling function
calls and the arguments that we get is a
32 bit int an unsafe mutable pointer to
an unsafe mutable point of intake so
that's our class star star and it
returns an int 32 value the reason why
cell is interesting is because it allows
us to introspect the lookup tables for
functions so if we have a class world
and that class world has a function
hello inside there and we compile us and
have a look at the SI l I then down at
the bottom we get something called a
Silvie table V table is virtual function
called lookup and essentially it says if
you have got a world object and you want
to invoke the hello function then you
can do worlds or hello and that
corresponds to the TFC for main five
hello but when a five world five hello
function now the nice thing about this
is it's actually possible to do lookups
of functions that you're calling in
classes and automatically now at compile
time which function is going to be
called and so all those Swift does have
the ability to do dynamic lookups and at
runtime go to the V table and then from
the V table called the particular
function it also has the ability to
inline this at compile time so that it
actually ends up just calling the
function directly there's also usually
four classes some other types as well
if you don't specify it you get an
initializer for free and there's also a
deallocating DNA which just D allocator
which then cleans up the object
afterwards now to show how some of this
works I've put something together called
send inspector there's a github project
that exists that you can download it and
compile it from I haven't released it as
a binary because it's actually something
which is easy to compile if you've got
Xcode and play around with it but let me
just bring up the argument over here so
the idea of this was just to allow me to
show what happens when you use Swift and
certain optimizations we've got here our
print hello world and if we pipe it
through the abstract syntax tree we get
back a lisp kind of representation for
what the source file actually looks like
so in this case it's got things like
there is a top-level source file there's
top-level cone statement we're calling a
particular function inside there now
there's actually a lot of stuff in there
that you probably isn't necessary and
once you do the semantic analysis a lot
of these things collapse down so the
initial ast is just something that
happens very quickly and just spits out
things saying you know there's a
semicolon here but once you do the
semantic analysis on it you know that
we've got a string little there which is
a UTF encodings string which is hello
world if we had different other
encodings inside there utf-16 for
example then they could be written out
in the same kind of style you can also
have a look at what these SIL is as the
cell is the the Swift intermediate
language representation and at the top
you can see maybe there's a bit more
subtlety in Swift going on
so all files that you write in Swift
automatically import the Swift module
that brings in things like the the array
in the dictionary and so on and we've
got this thing called built in and built
in is the way that you get exposed to
datatypes on the underlying platform so
what in a nutshell is in 30 to really
mean what is a native object those kind
of things are install imported and built
in now you used to in older versions of
Xcode be able to hyperlink into built in
and see what was going on it's
there but they're taking that out of xo7
one but if you want to even go into the
swift core library and then be able to
dump the functions out inside there so
we've got our main entry point inside
here this sill at main with the calling
convention is the entry point just like
in any other compiled program that you'd
have and we then have the code now a lot
of this looks like it's complete
gibberish what happens and the reason
why the print example is so complicated
is because print is a function that
takes an array of values and also has
two other separators as well so firstly
when you call print it has to call and
find out what the default argument for
parameter two is for the separator is
and then the default value for the new
line and then use those to be able to
call the functions and it also has to
take your values that you've passed in
build it into an array of protocols and
then call that as well and we have down
at the bottom these type functions like
did enter main unsafe mutable pointer
which generally are complete gibberish
you can't see this in the slide and the
presentation because it's a little bit
too small font but down at the bottom
left there is a command that you can run
to be able to do this in the command
line so if I open up this and make it a
little bit bigger if we do the same
thing with the print example and then
you pipe it through the Swift command
then you'll see the same thing that
comes out from there and even that's a
little bit too small as well so anyway
you'll see this from the slides that if
you download the app you can play with
it as well so what all of these things
mean inside here well if we wanted to
find out what these mean we can pipe the
whole file through the Swift deep mangal
and the 50 mangle will then look for any
accounts ease of underscore T and then
convert them so I've got an option in
here to just do mangle this and if I
switch that on then you see we start
getting sensible types in here like the
initializer of the Swift based type and
the real implementation of the function
though comes in at the bottom of this
function block so inside the main based
function that we've
which starts off here there's actually a
lot of things that are happening most of
them are to do with setup code so most
of them are to do with how we pass the
arguments that get passed in there is a
function inside here which means very
little which I don't think gets
translated which is yeah the Swift one
school and you'll see a reference to but
when you do Google searches but
essentially the arguments they get
called it's looking up things like the
function reference so percent 21 is a
function reference to our thrift based
print function that takes an array of
folks any objects the separator and the
Terminator and then it's using it to be
this apply call so those of you who come
from a functional background you may
have seen apply before but this is
really just a way of saying given this
function and this set of arguments then
make the call the nice thing about this
and so we haven't talked anything about
the underlying architecture that we're
running on or the way in which those are
going to be translated into byte code
there's a canonical canonical
representation of this as well which
does some other optimizations so in this
case we've got built-ins that are that
can be used to do addition so the S ad
with overflow in 64 is actually a
built-in function reference that's
actually used to be able to add values
together and you can then see what the
generated IR for that looks like so the
IR actually looks quite similar to the
way the Swift based functions work but
it's one level down and with one level
of elements removed and if you want you
can have a look at the assembly that
goes on but the main example the print
hello world example is not particularly
exciting because of the amount of stuff
that adds up inside here if we were to
create a function instead where we're
adding a couple of integers together for
example and we are returning an int
value
and you can type and talk at the same
time then you can actually see what that
gets translated to yes love these
unnamed parameters and then you can see
what it gets translated to so inside
here we've got a function called add
that gets defined so this is our
function in the main module that takes
two parameters inside there's a couple
of debug values those who use for when
you're using something like the Xcode
playgrounds where it's popping up values
generally they'll be optimized out for
real code inside here and then we've got
a function reference to the swift plus
function so Swift plus is a perfectly
valid name for a function to be so that
gets pulled out with the int types
associated with it and then cool down at
the bottom to give us a result number
five and then five is returned to the
calling function and then if we look
where we're calling that in our main
method here we're then calling the
function with the two arguments to get
the value inside you can then have a
look and see what that looks like either
in the generated IR or in the assembly
the nice thing is about the assembly you
can actually see where this is being
done so inside the assembly here we've
got our pool function we've got dollar
one which is the first parameter which
is the hex value of one which is our
first parameter that were calling and
then we've got another value inside the
second problem number two which goes
into the value and then we're calling
main to add with those two values nice
thing is that the call key function is
something that can be statically
optimized by the compiler and in fact we
turn on the optimization then you can
see what happens is it figures out that
these two things are the same and if I
find where am I where the function is
going on here I've lost it now then
actually it's just translated this to
the add Q instruction down here so our
main bot add function is these three or
four lines where it's in lined all of
the indirect calls to the function type
and it's just using an add key which is
about the fastest way you can add
functions up inside there there's a jump
to an overflow so if the
and with meta cooperation overflows then
you get notified for it as well but the
really nice thing is that if you turn on
a whole module optimization and we mark
this thing as private in our code and
then have a look at the generated output
then what happens is the compiler
realize is that actually there's no need
to have an add function at all inside
here so it disappears from this list and
because we're not doing anything with
the function at all it's just going away
so to actually capture the return result
so it's not optimized the way if I
import Darwin which is the underlying
iOS if you do foundation then you get
darwin in by default but then we can use
exit as our function inside and if we
turn module optimization on and mark the
function as private and I'm just going
to change these two into 32 because
that's what the X function needs and
it's easier to do that than after
properly then what you'll see inside
here is that actually the compiler is
just optimized it directly realized that
one plus two is three replaced the fee
with the call inside there and then
exits of the way so the key thing is
that Swift brings all of these examples
together and unlocks the power of
optimization through enlightening and
you can do things like inside the source
you can say if I is less than zero then
we can print something like negative for
example and without optimization on if
we look at the generated output inside
here we're going to have a bunch of
print statements they get pulled in so
the print the print is inside there
because dynamically at one time it might
be called but if we mark the field as
private and we turned optimization on
then actually we can optimize the print
statements out completely because it
just doesn't play any part it knows that
one is bigger than zero it knows that
two is bigger than zero and so inside
our function references inside here we
don't have any references to the print
function at all so Swift is all about
the optimizations how far can inline
things how far it can optimize code away
that it doesn't need to worry about and
then
can translate that to essentially less
instructions operated by the CPU and
less memory hits out from a performance
perspective so if you want to download
that it's on github our blue city
inspector I'll put out a tweet
afterwards so you can pick that up as
well if you want to but the key point
about Swift is that it's really a
compatibility with objective-c it's a
way of moving from the old way to the
new way and so for example if you create
a swift object then it has an ISO
pointer so he passed a swift object into
an objective-c function then Objective C
can still call functions and use the
methods dynamically to look things up
once that portion if you mark your
object as Objective C the compiler will
have to put those functions inside the
code it's got no way of knowing whether
or not you're calling it cause it's
dynamic or not so you can use Objective
C you need to use Objective C if you're
hooking in with things like frameworks
and UI kit or wkk or something watchkit
to be able to use any of the classes in
there but in future we expect to see
that Swift is going to take over from
Objective C so where is Swift going yes
hopefully open source watch this space
we've got four weeks left from today I
have to find out if that will actually
happen but is Swift fast as C's not
really the right question question
should be is Swift fast or faster than
objective-c
and I think it is possible for native
Swift applications to be faster than
objective-c simply because of the
optimizations to get unlocked when you
go through these things I can certainly
be faster if you've got a lot of data
processing inside there if you're just
using Swift to write Objective C classes
without the angle bracket syntax then
it's going to be the same speed as
Objective C it's certainly not really
any slower than that but as we see Apple
move towards more of a stable ABI for
the Swift language will see more
optimizations coming up and ultimately
more usage of Swift itself Swift is
still undergoing active development it's
being heavily developed we've seen three
releases or so in the last year and it
provides a translation mechanism from
Objective C we're not actually seeing
the death of a rejecter C yet because
all of apple's functions still use
Objective C for doing
the objects and their frameworks in iOS
code and we'll see that happen for
sometimes come but I predict as soon as
Apple open sources Swift will start to
see frameworks being created we'll start
to see an ecosystem grow of pure Swift
code without the objective-c baggage and
then we'll find something that allows us
to have native Swift applications I
would say safety is the future of iOS
development potentially also the future
of server-side development depending on
how and when the open source happens so
in summary Swift has got a long history
coming from LLVM roots it prefers static
dispatch but it also supports
objective-c for being able to talk to
existing code and applications the
values can be laid out in memory very
efficiently which allows for efficient
memory access as well as efficient
processing the static dispatch allows
for inlining which then in turn leads to
further optimizations reducing the
amount of code needs to be able to run
and things like the whole module
optimization the ability to upload your
applications as bit code to the iOS App
Store is only going to get better over
time and the modular pipeline that we've
seen allows for optimizations to be
inserted at different stages and so you
can expect those will improve over time
as well so thank you very much please
when I'm going to rate the session and
if you have any questions I'll be happy
to take them now so there was one
question there was one question to the
app that asks what is the difference
between virtual so the question was
what's the difference between static
methods in C++ and dynamic methods in
Swift well Swift has the ability
essentially to call eyes with them so if
you have a native Swift class then it
uses the similar sort of static dispatch
halls as C++
if you Swift to hook into an NS object
with dynamic message protocols then it's
using the dynamic message so if can
actually use either of them but from the
source level they look exactly the same
and I think this is going to be a great
way of training iOS and objective-c
developers to be able to move towards a
C++ kind of like model maybe C++ got it
right all along and the other questions
in the audience now well in that case
thank you very much and enjoy lunch</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>