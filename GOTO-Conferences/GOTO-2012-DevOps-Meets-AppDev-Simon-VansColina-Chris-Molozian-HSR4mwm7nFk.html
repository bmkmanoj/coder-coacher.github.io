<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2012 • DevOps Meets AppDev • Simon Vans-Colina &amp; Chris Molozian | Coder Coacher - Coaching Coders</title><meta content="GOTO 2012 • DevOps Meets AppDev • Simon Vans-Colina &amp; Chris Molozian - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2012 • DevOps Meets AppDev • Simon Vans-Colina &amp; Chris Molozian</b></h2><h5 class="post__date">2012-12-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HSR4mwm7nFk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so because you usually don't run react
on a single note it makes very very
little sense to do so you could but you
would lose all the all of the fun that
real offers were just distributing your
data as distributing your data for
performance as well as for failure so
what we do we use a sha-1 a key space so
160 bits and then we create a ring so we
then we even lead to provide this by the
number of actual notes when I say notes
I mean physical notes the way we get
around this is when this changes we
actually sign everything a virtual node
and we change the size of how many
virtual nodes are assigned to it this on
so that's why we can actually divide it
like that so here's how it looks
swedbank data now your typical value for
replication is 3 we recommend that we
recommend you start off with at least
five notes anything less you're not
really a building in for failure which
is one of our strong suit so if you
aren't doing that you can totally get
away with having a different end value
but you're going to trade off your your
actual data consistency so in a disaster
I don't fails so your data is already
been distributed three different notes
it is able to when you go to a node it's
able to know where that where the other
data is at any given point in time when
it does fail the requests will go to the
fall backs the data will actually hand
off to other nodes and then as soon as
comes back online the data will
redistribute automatically there's no
thats this is built into the system
there's no you don't have to tell it oh
this notice failed it will figure that
out some of the features on the offer
MapReduce full-text search hits solar
like and I'll actually touch on this
because we have a new back end this
coming that will make it fully solar
light and secondary the secondary
indices are only available with the
leveldb back end which is three backups
olivia is the google back in if
everyone's are familiar with big table
google uses that source files on disk in
SSTs camera with SSD stands for right
now that gives you secondary indexes
it's great when you can fit your key
space into memory so you are going to
have to write to just you're gonna have
to touch disk it's great that it does
compact like a lot of the other
solutions for shooting databases so you
have different reasons called levels you
have multiple levels of data so if you
do have to search through every single
level of data you're going to be doing a
lot of Sikhs so fastest and leveldb like
each other a lot bit cast is what we
actually have developed ourselves bit
cast is just a simple log appended you
don't get secondary index indices but
it's it's very very fast hi through both
and then there's a memory back end I
wouldn't suggest that anyone use it
outside of testing because it's just you
it's just in memory so if you die you
die it's not very good nuin won't want
you these are I only include these
because a lot of these were features
that were asked for for a long long time
used to do when you had joined an ode to
a cluster you just join it and it just
immediately have you know jumped on well
if you're adding say 10 nodes to a
cluster of 50 that's a lot of network
traffic a lot of people were complaining
because they don't necessarily have 10
gig e on the back end and that would
just crush their networks so we've done
is we've done a basically it's kind of
like a svn you know you stage and commit
and then you can later you can stage
commit at any time you can set a cron
job or something to actually commit it
later that makes the load on the network
of
a lot easier it also means that if you
have a plan that you set up you don't
want to go with just clear capability
negotiation used to be you had to run
the exact same version of react so
rolling upgrades were pain now we
actually have feature where you can have
mixed versions no problems it will it
will negotiate capability so that you
know if you have a feature that is si
added 1.3 it won't it won't break it
will drop down to the lowest common
denominator better handoff visibility
this is a key thing a lot of people
don't know where the handouts are
happening and just because they seem
giant spikes network traffic and want to
confirm that things are actually passing
from one node together correctly this is
a big one I'll touch on this repaired
cape with the repair KP and search via
console it used to be so we do we
prepare so values out of date on a node
you repair round promise you have a lot
of data that's you know say that it's
not right you couldn't there was an easy
way to go in and repair all of the
values that's something we've added in
the latest version stats sooo boring one
for those who are big fans of freebsd
and smart us we have it official
packages and then the big ones EES ssl
built in we used to use like stud or
something in front of it and then
granular controls the problem we're
having with multi data center or
replication is the sheer quantity of
data is shifting you know going on with
it going over the pipe so we don't have
both real-time and full sync there are a
lot of customers who don't necessarily
want all of their data passing over
there lan interface constantly and this
is the one I want to type it's one that
we do have full text search it's not
really like so this is sourced Yokozuna
is our new back end it's coming soon
to make it come sooner but it's
basically this installs a solar instance
on every right next to every react
instance on that Reno cool thing about
this is you get you get full solar
compatibility anything you can do in
solar you can do in you can do it so
cozy the nice thing is it's instead of
being multiple instances on the solar
side it's all you just query one and
then react does the distribution it's a
horse like a distributed query works
very quickly I would show you we have a
wish its live on our documentation site
right now I don't have Wi-Fi so yeah but
the l's the bonus series we also have
active anti entropy this means that
instead of having to do as I mentioned
earlier with your repair we're doing
read repair this is constantly going
through a repairing values so you can
delete something and it'll just know
once once in exchanges happened between
two nodes it realizes that something's
change its fixed and yes so we FCS is
basically an s3 compatible storage
engine that runs on top of her luck it
does almost everything that s 3 can do
like I say can do everything that Esther
you can do because we still can't do a
few few bits but it's very very very
fast and gives you all the fun things
you get it from s3 you get multi-tenancy
multi-building so you can look at
individual customer usage this is a big
big request from enterprise customers
they really like to be able to use us
just for different apartments inside
their own organization this is how it
works basically we access is just a very
thin layer that sits on top of react so
we use multiple backends on react but
it's just a bit just a small early
processor typically to run reacts
reality you could run it on different
notes but it doesn't make sense for the
performance so dev ops this is what I
our role of bachelors to make things
easier for everyone to install a lot of
the problems we have with folks we give
them rioc is that first early they're
just they're puzzled by the
configuration files running it locally
it gets it gets very messy so a lot of
the work that we have done on the DevOps
I'd has been making it easier to use mr.
chef cookbooks pubmed Canyon Republic
recipes I think they're call I'm going
to demo the reactive cluster which is a
ruby client written by our friends and
saying a roach or a rigged system
written by them that makes it releases
spam a local cluster for testing because
that's the biggest problem is getting
people to download a compiler lang
getting all the dependencies set up and
then oh well you've got your on OS 10.7
will you need this particular into this
particular GCC Harper recommendations
that's something we've been working on
recently a lot of our customers have
pushed us to the point where we can't
actually test their skill they have
fifty hundred nodes and that's not easy
to do if you don't have 50 200 notes and
some of these customers have insane
specs or machines like maybe eight
thousand pound machines that are you
know all SSDs and 24 course so what we
do is we we've been testing the customer
with my setups and then me we basically
break rioc a lot that's what we do we
set up test harness is where we
constantly mounted with our fasho
vegetable and then once we find these
educators we pass them off the app dev
and we say here we found a new way that
it's broken so that's what we've been
doing a lot recently is breaking react
and react CS and then those enhancements
of they rolled into there are actually
three or four releases that have been
made in the past two months of just been
from DevOps recommendations
where we've seen them break and as
emmagan scales at 50 to 100 meters what
we've learned linux kernel's really
really bad defaults for high performance
it's actually it's basically designed
for the lowest common it's basically
designed for i386 that's really bad when
you have a database let's pushing its
able to saturate your network and reduce
subsystems so don't have one use a Linux
carb little faults with react it's it's
a bad idea so some of these we found
most g tcp settings in the car far too
conservative we're typically running
ryokan real physical hardware you can't
run it in like something like ec2 but
the latency they get it in kind of
distribute or a magistrate but a a
virtualized system like that is there no
guarantees so we prefer low latency 10
gigabit high throughput in networks so
you can tune tcp a lot the pd flush that
i mentioned their dirty pages linux
kernel doesn't is not optimized for high
throughput for them also expect swap for
everything you're not going to swap if
you have 32 gigs of ram or you shouldn't
be swapping so that vm sloppiness value
is set to a very it set to 60 by default
you drop that down to zero you never
want the colonel to think they can swap
sir you probably won't have some swamp
there because a lot of applications die
if you don't have swap but you never
want to be touching that IO schedulers
terrible the default scheduler and
Colonel 26 and above the cfq I've done
that cute little completely flawed
queuing it's supposed to be fair there's
a deadline schedule and a no-op
scheduler we've seen performance of
prudence of about two hundred percent
where we change the schedulers it's it's
really that bad it's basically trying to
say oh I'm going to give you know i'm
going to fairly schedule every single
process on the shoot typically on these
machines you're only running one running
one process and that's real that's the
way we notice it's a lot of customers
they're like i'm getting terrible
performance you know maybe only getting
ten thousand dollars change the schedule
eighty thousand birdies hardware load
balancers aren't realist grades are
cracked up to be we run each a poxy
locally on each rioc instance that way
if any node goes down it's already aware
of the other nodes in the cluster that
actually is very small performance hit
and it's a lot more flexible than
running a hardware load balancers really
had that Harbor low bounce or being a
single point of failure and bachelor
bench is our open source tool that we
use to benchmark Korea we can be used to
benchmark any kind of key value stores
written in early and you have punch
different options for all the packets I
was going to show this off but this is a
if anyone who's curious in playing with
your access we actually have a live demo
that's running in our data center it's
multi-tenant so anyone can sign up just
put in you can actually just go to the
site request to a login and then in our
Chelsea gives them out actually how you
doing but I did want to show us those
are pretty grass sometimes that's the
end of my presentation my part of the
presentation but i want to show everyone
our this is
so we have this little break so this is
if you want to set up react really
quickly on your local system just do a I
have already done a rate install but if
I wanted to start with a new cluster
flag node cluster this will actually
this is also for OS 10 specifically so
if you're not running OS 10 it's
actually it's pretty easy to do it on
the linux box but you have to again know
how to compile our length so the other
bits this will show you what we actually
looks like
oops
so what this will do this is actually
going through joining each of the
individual nose to the first move you
don't have to join any specific node to
any other node in a specific order once
it's part of the ring you can join any
and you know any other maybe those words
so this is real control this is a nice
little web interface you can very easily
see the status of your cluster so the
green check mark if you're running low
on memory or for notice dropped out of
this big red X but here is the fun part
so here you actually see the actual
distribution of partitions and this will
actually change as these nodes just
reload the page so as you see these
numbers will actually change line this
is the these are the vinos or partitions
that are being distributed between each
of the individual nodes so if I were to
kill one of these right now
so it will read that as an error that
notes gone down within the numbers will
actually change can redistribute as it
recognized that that that note is down
like I said this is all based on an N
value of 3 which is why we recommend you
have five notes so if you have three
copies of your data of five notes you
got to start around so you can suffer
failure and the performance at alliance
that's all I have and I was going to
pass it approaching Chris yeah alright
as set mentioned i'm part of the client
services team of bachelor in mia so the
London office has been around for about
six months and I've been with battery of
about four months and I wanted to take a
different approach to this presentation
I thought I could make it a little bit
more interactive and basically hand it
back over to you I mean I would like to
ask has anyone actually experimented
with react before this talk no one else
is experimental real okay to explain how
you can get started yet working with
Maria typically as was mentioned I think
with casado talk young cassandra has a
query language react speakers just HTTP
rest direct it was built in the ground
up to speak to a rest interface recently
in a couple of versions ago now it's
been a staple for quite a long time out
we introduced a protocol buffers
transport layer as well and so all of
our official client libraries and many
of our community supported client
libraries can talk both the HTTP
interface and the protocol buffers
transport interface okay and that in a
production environment we pretty much
recommend that you use the protocol
because the HTTP header overhead and
some of the conditions are go into being
a faithful implementation TV protocol
specification means that there's a
little bit more overhead than there
should be to respond to your requests so
if you want to be in a production
environment in whatever implementation
language your your application that is
being developed in whether it's Java
Python Ruby c-sharp whatever typically
when you switch you could do a lot of
easy development in HTTP and then when
you want to switch to production you can
easily switch the knob over to protocol
buffers and you'll get that performance
improvement and the there are typical
this there's a lot since scenarios where
people go well what is react sweeps or
when should i use react vanish when
should i not in 30 and we like to just
like fasho we do our own benchmarks we
do our own performance tuning and we try
to keep as open as we can to all of the
research work and all the developments
going on in the other databases that's
extremely hard to do because things like
rethink DBA though if you guys are aware
of that just recently was announced
about two weeks ago that was a rien
ounce mentality about a few years ago so
the no sequel database landscape
continues to grow at a alarming rate
okay so I haven't had a chance to do any
analysis of rethink baby I don't know
where their sweet spot is yet in the
market so please don't ask me anything
about reason but with react typically
this is going to sound extremely obvious
but if you can denormalize as much as
possible you can do a pure k vlookup
that is going to be asking about things
like user profiles the dollar dollar
companies like Rovio and riot games who
are customers of us and what they do is
they use user reactor store users
gaming session of state and that's very
beautiful kv story because you know the
users ID so you can use that as your key
to your your records again you can be
normalized as much as possible there's
one request and you can retrieve in one
look up everything you need for that
Linux gaming session other use cases
I've been working a lot of interest
recently from people developing content
addressable storage solutions and I like
this one because it's a matchup of
taking advantage of the fact that react
CSR cloud storage platform six there's a
pic proxy just right on top of your
react cluster ok so really what you get
when you pay for the enterprise folks
you get that thick proxy to handle
distributing and dividing up those file
or objects into blocks that we can then
store to disk and replicate for data
redundancy and availability and but with
the content dress for storage solution
what you can do is you can store file
metadata information and user account
information into the underlying react
storage engine but then still access
through the s3 layer for your actual
files so we've got people building their
Dropbox style clones so things like some
sort of demon process maybe in Python or
Java or whatever sitting on a customer's
machine or in one of their business
units Dennis enters going and constantly
kind of calling out to the react
underlining under the cs layer react or
product going in talking to that getting
a file listing getting those over all
the s3 flat handles that you need to
pull those files back out and stall a
local copy and you can that happens as a
secret
process asynchronous process to to pull
that data as fast as possible keep it in
sync the way that dropbox and their if
you're aware of that storage solution
how they do that so a lot of customers
using that at the moment what i would
always recommend when deciding whether
or not react is a sweet spot for your
use case is think about your query
patterns okay it seemed obvious but some
databases like Cassandra are as was
mentioned right optimize react is a
pretty much agnostic to that it it will
let you read as fast as it let you write
you know you're really constrained by
what if one of your disk subsystem is
allowing you to write to this okay we
don't do buffering in memory to kind of
bulk together block load these rights
and then and then push them to this we
write as fast as you to let us write to
disk basically based on the hardware
spector you've got and you can do need
some neat things with that a common who
was at the front who asked about that
but asked about SSDs and optimizing with
SSDs right what you couldn't do if you
you don't necessarily need to ever solve
the problem that you're talking about at
the database that you could actually do
the same thing with Cassandra you can
basically take gfs we're big fans of CFS
as a great file system that allows you
to use an SSD as a kind of a what they
call an l to r catch think that is a
extension to your ran that can maintain
your hot data set and then obviously
everything else is managed also managed
by the ZFS subsystem to actually make
sure that it's on the spin dists that
are in the rest of your storage there
that's really nice because then you can
keep it cost-effective you get an SSD
modest-sized SSD that kept almost bumps
up your round count basically and then
you can use cheap spinning disks to
actually store the data for as many uses
if you want to store it for so we find
that that's something that I typically
recommend because I spend a lot of my
time doing a combination of dead and
modeling trying to help people find the
correct balance between when should i be
using
secondary indexes when is linked walking
appropriate how does this work under the
hood should I be doing that reduce
operations and what's the key set that
other size that I could really you do
efficiently and with a react you know
how bounded is that is that access force
in real time analytics and typically
these phones can all be solved by
pulling them away from the request chain
that comes in from your application
layer so let's say that you're building
a mobile and your mobile app has to
sustain I've seen people talking about
kind of 30,000 dots per second across a
modest duster running an ec2 not the
greatest hardware it's possible but what
you want to do is not be doing MapReduce
operations made to every single one of
those requests that are hitting thousand
keys on your on your cluster it's it's
gonna not you're not going to get the
trooper and the Lincoln sees that you're
looking for you you will be constrained
at that stage so when you can do is work
around that by basically for a time
series use case for example you take
time boxes so you pick sort of time
increments you want to box up into some
sort of what we call buckets and react
just logical name spaces for your keys
and then roll them up as a background
process and do background processing to
actually take the nap produce across
that key set and then fold that into
what is it a single record that thing is
pushed into your one minute bucket or
your one hour bucket and and you can
almost end up using the system to do
robots like that and that allows you to
do everything you could do with the
analytics that you need to do without
really worrying about do I need to do do
I need to attach this request change
these this heavy read or write
throughput done
you through my system directly into the
cluster and have it serviced the mall in
one girl you know riding into a bucket
leather background process go in and
then fold that yet reduce that result
set and then store it again to another
bucket one of our customers boundary and
they do they've got a network demon that
goes on servers and then will stream
information about kind of a network
latency zand other kind of network
topology information each of those
demons is attached on a computer and
access as a react cluster in their
infrastructure but we don't they don't
do in that produced operation when
they're doing their analytics to display
their graphs to customers they don't
attach that to their request chain they
use time boxes and then roll it up so
there if you stop the problem you
compare then this is something I've come
across quite often is impossible really
to compare relational databases to these
scheming s designs because you're
talking about different trailers and
different throughput and different
legacies so once you understand that you
have to stop thinking about your data
model in a lot more detail than you
would have done before I mean up I was a
little bit late to this event because I
was in a meeting earlier and in the
meeting we were talking about how can we
put together a handbook and in that
handbook describe typical patterns for a
little relational mindset to move into
the into a react denormalized kv mindset
I'm not a fan of that process because
that person is trying to offload the
thought patterns that go into actually
caring about how to model the little
problem into something that can be
turned into it they learn by rote
approach and there's too many variables
to account for to get the color
efficiency that
these days and the right throughput and
volume of access we need in a highly
available system the reason I ask so
much actually about distributed counters
earlier because it's an extremely hard
problem to solve I guess I too have an
interesting implementation it's a lot of
work that we're doing at the moment and
one of our research projects is into
commutative results and data types and
these data types allow you to basically
their particular particular subset of
all data types of abstract data types
they can be known to be monotonic
structures which means they're known to
grow in size okay so for instance if you
take the set union of two sets where you
know these sets are never going to be
reduced then you can just do the set
Union operation and then you'll have
your complete record set when you're
doing some sort of conflict resolution
on concurrent writes these this kind of
research is very interesting stuff is
extremely hard problem to solve in a
distributed system and especially if you
don't wanna introduce lots of any kind
of some sort of transaction mechanism
but we're doing our research into that
and one of the things that set mentioned
was a I'll work in yokozuna for search
that takes a bunch of previous research
we've done with this active anti entropy
technology which is one of the areas
where it was possible for you to lose
data in previous versions of reactances
pre one point was that you could
basically react with do read repair when
you next with the value right so if you
have replicas of that data when you do
read it'll go and it will request all of
the replicas and then verify whether
they're stale data that needs to be
updated with the current primaries
primary copies of that data okay but if
those stale keys haven't been read for a
long time and that note has been down
and come back online it could well be
that at some other stage in time another
load in your system
goes down that has the other primary
copy and then another one and all these
happen at different time periods but
happen before the next read of that Key
has happened so what has actually
happened is that you've now got three
stale copies of that data and you're
unable to determine which one is the
most up-to-date copy and therefore make
sure kind of bring push that consistency
back up which is what the read repair
operation does active anti entropy is
think of it as a background process
which constantly actually the new
structure we use for storing on this
makes is much more efficient but it
accesses the these V nodes and access of
the data partitions and determines has
anything changed here if it has let me
make sure I do it run re prepare and
push this consistency up and that no
longer has to happen on every request on
every read this happens as a background
process and that work is going into our
1.3 release which should be December
January tinnitus yeah also also also
Christmas time yes if it's a Christmas
gift right and that won't yet that's
paves the way for work with your kazoo
know which again is this direct
integration between the JVM and the
airline vm so that we can control and
spin up day Liam instances along side
your nvm and allowed to be water managed
allow you to define indexes that you
want to be searchable and copied across
until you've seen and solar indexing so
you can do distributive queries over
that data yeah I wonder if anyone has
any questions is there anything you'd
like to know about react versus
Cassandra
I have that question a lot we ever we
have different sweet spots at this stage
in time if you want to do distributed
counters or you want to do time series
data and I would still say go with
Cassandra but if you want to do
denormalized pure kv lookups and you
want to make sure that you can scale
because as far as I'm aware correct me
if I'm wrong but the Vino implementation
in cassandra is not it's in master I
think that hasn't yet been resolved in
on side rock awareness so scale
factoring in Cassandra means either
manually recalculating your vino
distribution or scaling the factor of
two so you can even lead to divide it in
a box and then distribute them across
few all of your new nose so we have
different sweet spots you can do time
series in react like I said boundary do
it but it requires a lot more thought
into your data model where an
environment like Cassandra which gives
you this ability to do partial updates
because of their column
family-orientated database will give
them an edge in time serious problems
yeah so if you want to still gain
session data you want to do time series
like Mallory does with their analytics
platform or content addressable storage
or anything that can be denormalized
into a pure kv problem and you want fast
rates or fast rights yeah do you have
any questions yeah so the I've got
exposing mentioned is a sound a bit like
mapreduce MapReduce underpin ok geez
where you so you saying put it into a
bucket yeah they have another map juice
on that well yet put the put the value
basically as with any of these a schemer
that's database engine do you really
just think about what is going to be
your index what's going to be your key
right and in the time series problem
your pee is going to be something and
some sort of time status
right so if you can put those those keys
into a particular bucket a logical
namespace like you wouldn't react then
you can store 70 80 90 100 texts in
there and after your tip countless reach
certain failover a time you pick up
another bucket and then your background
process sweeps through does a MapReduce
operation over that bucket which is now
closed off time box so you know no more
records are going to be pushed into that
bucket you can then flatten that into
one record push it back into react
that's how I found you doing is that
part of its not part of reactive caesars
palace phnom you do it's what I mean we
I do a lot of denim modeling work and
people that want to use reactor is open
source on the mailing list or whether it
later becomes enterprise stuff and i
love that becomes yet talking about how
we can think differently about storing
that storing that data and that time
boxing process you would have to build
when we've got ur line now produce
phases that you can pre bill operations
you can then use to do that time box
reduce but the actual process of taking
your application layer logic to push it
and logically namespacing that time
would be a problem installing the
application there's no pre-built
solution for korea but there's a lot of
people that are doing it and the mailing
list is full of people that could help
them explain myself includes the best
way to go forwards with it yeah cool any
questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>