<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Jepsen IV: Hope Springs Eternal • Kyle Kingsbury | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Jepsen IV: Hope Springs Eternal • Kyle Kingsbury - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Jepsen IV: Hope Springs Eternal • Kyle Kingsbury</b></h2><h5 class="post__date">2015-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dE3KT7hHkKY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so the title of this talk is Jepsen for
hope springs eternal there is in fact no
three don't go looking forward it
doesn't exist this should tell you a
little bit about what we're going to
discuss in the talk today my name is
Kyle Kingsbury you might know me as a
fur
I am scared and confused and excited
about computers all the time
and today I work at a new company called
stripe we are a credit card company we
help you sell goods and services via
some API which is phenomenal right
developers say oh I want to take credit
cards how do I do it well I could build
all this PCI compliant infrastructure or
I could just make an HTTP request to
some magical rainbow in the sky and
everything will work out just great
we've all built api's right they're not
they're not real things they're
abstractions they're imaginary
constructs so that's this rainbow up top
that's our that's our API right but it's
actually supported on this steel girder
framework which is our code that's
written in Ruby and then that code rests
on top of all these libraries and the
Ruby VM that's represented here by this
big pile of sticks and those things in
turn rests on a pile of tires which
symbolize our databases and accuse
another distributed systems now is
anybody who's used a database how many
of you have actually very very good less
than I expected anybody who's used to
database knows everything is unfired all
the time and our job is to continue
building the tower higher and higher to
try and get away from the flames this is
called the hierarchy of abstraction so
as good information hiders we're trying
to isolate the terrible things happening
down below from the good things which
our customers think are happening and
ideally it works ideally customers
continue to come to the site they make
requests data flows properly even though
nodes internally are failing and bad
things are happening to the network
that's the goal what kind of bad things
am I talking about well if you've ever
used a queue or a database or any
consistency system that so ever you know
they can get into split-brain scenarios
where different nodes believe different
truths or there might be foreign key
problems where you go to look up a
record and it's gone or maybe you see
you read on
where you go to examine a record and
maybe you do a write and you do a read
and it's not there and you do another
read and it comes back you do another
annex con write interesting flip-flops
and state can occur so in the face of
these these problems we want to know how
likely are they to actually affect our
systems our as our use of the database
correct is is our software likely to
show these problems to users and the
only way to do that is to measure them
so Jepson is a project I've been working
on to understand distributed systems
better it's it's a code base it's
articles it's talks trying to put
pressure on vendors trying to educate
users and figure out for myself what
consistency actually means in Jepson we
take a systems-based approach what is
the system well anything you can put a
box around which means pretty much
everything is the system inside of the
system we're gonna have some interacting
components there they're gonna have
complicated and nuanced things happening
between them but our goal is that if we
draw a box around the system as a whole
we should be able to characterize what
goes on inside the box just based on the
interactions it has in this environment
and hopefully those interactions are
simple so at the edge when we're when
we're pushing things into a system and
taking things out
we should have simple rules like maybe
matter is conserved or maybe for
momentum is conserved or maybe if I put
things into a queue they come out again
maybe if I write data to a database it
should still be there in a week those
are those are simple high-level rules
and then internally the database can do
whatever kind of locks and
transformations it wants to make those
things happen
thinking about invariants for a minute
like what what sort of rules what sort
of high-level properties could be want
we might think about a simple program
right like allocating a variable X set
it initially to a will read the variable
by printing it that prints out a right
when the world will set x equals B print
X we all know what this does right
written the program like it's before
what do you think it does is we start
off with the state a and we'll read it
and then we'll change the state to B by
performing a write and then we'll read B
so in print a and then B straightforward
enough but this is not the only possible
interpretation of this program
we could read B we could we could read a
we could do anything the program doesn't
have to obey any laws unless we tell it
to so the invariance in our head map the
program structure the the sort of
lexical structure of the process to the
behaviors which is allowed to undergo
invariance are constraints that apply to
the history of the system like what what
possible orderings of states could we
see what possible ways could the
operations come together we might think
about not just a single-threaded program
but a concurrent one where multiple
processes interact with the state at the
same time so here a top process reads a
and then B that's that's crazy why did
it change will it change because a
process on the bottom performed to write
of the value B so individual processes
may not have the whole story but if we
unify the whole history from every
process we should get something that
follows the same rules but it's a little
more complicated than that because our
systems aren't just concurrent they're
also distributed and distributive
systems have some characteristic
difference or some characteristic
distance between nodes it takes time for
messages to propagate if I want to write
a value to a register and DRAM I have to
go off of the CPU into the memory
controller through a bunch of caches
back onto some wire like 11 whole
centimeters over to the DRAM into the
actual bit and it flips and that takes
like what a nanosecond so then I have to
come all the way back and that takes
more time so whenever we're manipulating
States somewhere it's gonna take a
little bit of time to go back and forth
and that time means that things might be
ambiguous we could see different orders
for example if I do a write of B and
then concurrently begin a read and then
the write completes and the read
completes one possible ordering
depending on how those message is
propagated is that I see the value B
because the read arrives after the write
but I could also see a if the reader is
first a or B a or b all the changes is
the ordering of the messages and an
asynchronous network like the ones that
we're usually working with an IP we
don't get to control what those
orderings are so both both histories are
valid we have to consider all possible
interleavings and concurrent operations
but it's not infinitely bad because
we're not allowed to break the laws of
physics we can't go back in time if
we're actually talking to a single point
of truth somewhere in the system then
the earliest possible state I could
interact with is the one just after I
send my request and the latest possible
states the one just before I receive a
response so you get some window between
invocation and response and that's the
the range of states we could interact
with this property is called linearize
ability and it's kind of the gold
standard for both distributed and
concurrent systems you want to have
things like atomic registers like
mutexes that give you real-time
guarantees on the states to interact
with a mutex when you lock it nobody
else gets to claim it until you release
it that's a really nice strong property
so linearize ability means that any
operations that are not concurrent are
orders back to each other it's not a
total order right we can still have
those windows of concurrency where you
could get a or B but that only happens
when two operations overlap in time that
means that if I do a right and the right
completes and then I begin to read
because those two are concurrent the
read is guaranteed to see the right or
some later state so everybody's gonna
agree on the same order events we all
see ABCD everybody's going to agree on
when an operation is visible once you've
completed an operation you know
everybody else is gonna see it and this
means we get nice invariants like no
scale reads like mutual exclusion lots
of systems rely on these these
properties but we don't have to be that
strong this is a really rigid thing to
do we could we could relax the time
constraints we could let you go
backwards and forwards in time you could
read something from the past and write
something to the future well how do you
write to the future well you can put
your message in a bottle and you throw
it in the ocean somebody else picks it
up if your ocean is well ordered as mine
is
then this works is fine everything
arrives in order at your at your
recipient maybe on a different Coast and
then they apply your operations and they
see the same history of messages they
just see them a week later so all the
participants are going to agree on the
same order of events they'll all see ABC
but they might not agree on what time
those things happened we could relax
that invariance still further if you're
thinking about a transactional system
with lots of different cells interacting
like an SQL database we could have a
property like serializability where we
say that every transaction has to fit
somewhere into a single linear history
but we don't have to agree on when it
happened or even in what order just as
long as you can squeeze the transaction
somewhere
so in a serializable system operations
happen in an order we don't know what it
is it's perfectly legal for example in a
register to put all of your rights to
time infinity and all of your reads to
time zero and just have deveneux will be
your database that doesn't seem very
useful right but it's a sort of trivial
solution if you have a more complex
system like an SQL database where you do
something like set this row in this
particular column to be three if and
only if this thing plus that thing is
equal to this other thing when the time
is whatever those comments those
constraints are actually a lot more
difficult to preserve and so you get a
stronger and variant out of it finally
we don't have to just have a single line
of history we could actually have a
forking diverging history in eventually
consistent systems you constraint is
that things have to come together
somehow so we have a counter this value
is 0 that counter could diverge we could
have two distinct copies of it and each
one of them could increment separately
and return one the reads will show one
for a while and then when the counters
exchange information the value will
converge on to if we do everything right
so eventually consistent systems have to
converge and what that convergence does
doesn't just mean I have to agree on
some value ideally they should converge
on a correct value so the correct value
might be the most recently written value
in the register a correct value might be
the number of increments that have
occurred it depends on the semantics of
the data type that you're working with
finally we could imagine a variance to
just order two operations like a write
and write or write in a read we get this
family monotonic writes monotonic reads
writes follow reads reads or writes
monotonic right just says that if I
write a and then B those have to take
effect in the same order in the database
and the same thing for monotonic read I
should read a and then B and then C
never see then B then a writes follow
reads means that once I've done a read
any write that I do will follow
subsequent to it and conversely a read
your write just says oh if I if I write
some data and you read
we'll see that effect so we're just
relating the order in the program
history remember the the first program
we talked about x equals ax equals b
we're just putting those constraints
onto any pair of operations and you can
mix and match these things there are
infinitely many consistency classes
they're just they're just allowable sets
of histories so if you can write it down
it's it's a consistency model we could
take linearize ability plus the property
that after some time you know t1 all
reads caused an ancient squid gods
arrived in the depths that's Cthulhu
consistency this is only implemented in
certain data stores but they tend to
fall into some sort of hierarchy maybe
not a hierarchy it's a partial ordering
but we could we can say certain things
about inclusion so if i have a system
which is linearizable but is to say
everything happens in a certain time
window and everything happens in the
same order because everything happens in
the same order on all nodes we also know
that system is sequentially consistent
and it's also by extension causally
consistent it obeys p.m. which is a
parallel memory model it gives us those
four properties read your rights
monotonic reads monotonic writes rights
follow reads all those things are sort
of they come out of the single register
consistency research that goes back way
to the 70s and then i'm currently in the
database world people were looking at
transactional systems for SQL databases
for object stores and so they invented
things like read uncommitted read
committed monatomic atomic view cursor
stability repeatable reads
serializability all those properties
have their own sort of partial order on
the right hand side now the interesting
stuff here is that there's actually
theorems that tell us that these systems
have different performance and
availability characteristics the reason
you relax consistency is for speed but
it also happens to give you availability
so if you're down here monotonic reads
monotonic writes branch cut isolation
monatomic atomic view those those safety
models can actually be provided in the
system which is totally available and
that is to say that every request to non
failing node will terminate successfully
that's a really strong property right it
doesn't matter what your network does
you could have nodes like here and on
mars that don't communicate everybody
gets to do operations all the time
that's phenomenal from an Operations
perspective this
terrific but if we want a stronger
property like linearise ability the cap
theorem rules that out it tells us we
can't have that be totally available we
also can't have curse of stability or
repeatable read we can't even have
sequential consistency those properties
are only attainable in systems which
have some nodes go unavailable during
failure maybe they have a privileged
primary node maybe they use majority
quorums in the middle we've got this
kind of a purple section that's things
that are sticky available so that's
totally available with the constraint
that every client always talks to the
same server and if a client server dies
and that client has to abort its
operations and it loses those invariants
so different consistency models and and
by weaker I mean the ones that let you
do more histories the ones that allow
more possible orders those are more
available in the face of failure and
they're also faster and less intuitive
because they let more things happen and
they don't place a strong constraints on
what kind of curve so the weaker models
require less coordination you have to
talk as much if you look at CPUs for
example they reorder your operations
like mad you actually have to ask a CPU
to get a sort of linearizable write or
read you should do an offense operation
or an atomic compare and set if you just
write a value it's happy to cache it and
maybe you'll see at some later time and
it does that because it's expensive to
coordinate between CPU cores finally I
want to note that weakness doesn't
necessarily mean unsafe it depends on
what you're doing
so if I'm building a hit counter service
I can tolerate a little bit of loss in
my reads my reads can be slightly laggy
but eventually I want to sum to the
number of increments that occurred if
I'm building a registration service for
users that were on mutex a property like
linearize ability is critical i can't
use an event the consistent system so
safety depends on your actual
application alright to recontextualize
for a minute what why have I been
filling your heads with math this is all
useless knowledge right the goal of
these invariants is to put constraints
on the interaction of a database system
with environment like though all the
clients and the people behind those
clients and then I'm going to test
whether those invariants actually hold
in real systems so I'm trying to take
theoretical results from computer
science research and apply them to
actual databases that you might see
failures in the wild so our database
could be comprised of five nodes maybe
running an L X C maybe on physical
hardware and those nodes are connected
by some IP network then we can induce
failures in that network or we could
kill processes we can pause processes
induce different sorts of events and
then outside that system we're gonna run
five client processes and those are
going to be a sort of logically single
threaded series of operations against a
database like incrementing numbers or
reading and writing and we're trying to
observe the boundary and see if the
database preserves the invariants we
think it does we have no idea what
happens inside of the database if you
hand me an instance of react or you hand
me an sense of Postgres I have no idea
what kind of message is exchanging
internally I don't know its internal
state it's complicated its millions of
lines of code but if it follows these
laws these invariants we don't have to
know what it does internal e we just
watch what occurs in the boundary and
make sure that the clients will have a
consistent view so a client's gonna
generate some randomized operations like
write the number what number try six
maybe it'll try a read maybe it'll try
an increment will move apply this
operation to database and then they're
gonna terminate in one of three ways we
could we could successfully terminate
and that's when we know the operation
succeeded we could crash and we know it
failed so that's like if you couldn't
even look up the database know to talk
to you know your operation didn't take
place we call it a failure or it could
be indeterminate maybe there's a network
timeout may be a process crashes you
just don't know what happened and then
we have to consider that operation as a
possibility maybe it occurs maybe it
doesn't and it could take place at any
time in the future maybe it's buffered
in some in some network hardware and
arrives ten minutes later so as the
clients interact with the system they're
going to build up a picture over time of
increments or of additions to sets or of
reads every one of them is gonna have an
invocation and a completion some window
of time it was valid and if it crashes
that window will be infinite out to time
infinity and our job is to figure out if
these operations together makes sense
like if we're looking for linearize
ability I have to find a path that takes
us through all of the known successful
operations in a way that is consistent
with the model
of the system and and that means if I've
got a register for example I have to
read the value that's currently in the
register along that path so I'm not
allowed to read be from register
containing a I have to always read a
from register the contains a to do this
we write a datatype it's a function that
just tells us what things are allowed
what can you do with a given data
structure so for register you might say
I've got a register contains a single
thing called X I have a step function
that tells us given a current value of
the register there an operation to apply
how we're going to evolve the system it
depends on the function f of the
operation if we're doing a write we just
replace the register with a new one that
contains the given value so if I write
the number four I hand you back a
register that contains four if you do a
read though it depends on whether the
value that we have X is equal to the
value from the operation so if you try
to read the number two from a register
that contains two this is valid and it
doesn't change the register so the
register just returns unchanged that's
our if you try to read something else
like you you you do a read and you see
three but the value should have been two
you know that it's inconsistent and so
we returned the special inconsistent
type this this single-threaded function
encapsulate all the behavior of a
register this is the model the invariant
that we talked about in that first
consistency slide it's it's all the
rules that we expect from reads and
writes against a variable and then we'll
apply it to a given sort of single
threaded interpretation of the history
so if I've got a state like three I'll
say okay let's call a step function with
the register that contains three I'll
pass an operation like read the value
two because those things aren't equal it
returns inconsistent and we know that
that particular time line is invalid so
over time as we move through the history
we'll take every possible path and we'll
come up with some some operations some
some histories that are valid and some
that are invalid and ideally we'll find
one valid path or more than one valid
path that takes us through the whole
history and it'll load the system was
linearizable
or for building an eventually consistent
system who might validate that all the
successful increment operations and the
counter are eventually the residents in
a read or maybe if we add things to it
set all the things you put in should be
eventually present in some final read so
you could write different sort of tests
different checks against this sort of
history so generating random operations
applying this database looking and
seeing what happens and then from that
concurrent history we we apply some
functions that check to see whether or
not it makes sense sounds so good so far
okay so now for the blood are you not
entertained so we've got we've got a way
to check systems now and I've been
working on this for a couple years and
I've run quite a few analyses the first
ones were worth read a sentinel MongoDB
and react Redis Sentinel will go into or
at least would go into long-lived
split-brain and lose a bunch of data
maybe up to 50% depending on how the
petitions happened MongoDB lost it at
every level of right consistency reacts
defaults for last right winds caused it
to lose data as well during petition but
if you use C or D T's and allow mult
true or siblings everything works as
designed this is actually our react has
intended to work this is a
well-documented result but because the
defaults were lost right wins
you could REM scenario if you tried to
change data you could lose information
info of 2013 came back in testing Kafka
new DB and Cassandra also zookeepers
occur past Kafka had a bug in their Oh 8
beta prior to release where the
replication algorithm would fail to
preserve documents when it ran out of
instinct nodes so if you had a primary
die when it was isolated away from the
network that would cause it to discard
inputs nuodb claim to beat the cap
theorem and the way it did this was by
not doing anything at all during
perdition's and just waiting for them to
be over Cassandra that load strategy as
long as your positions are short
cassandra lost data the same way that
react does it uses time stamps to do
resolution so it will discard more
recent writes if your time stamps for
your clocks are not perfectly
synchronized the transaction system in
cassandra also had a number of
one is that uses for round trips for
every message which makes it somewhat
slow the next one is that it would
deadlock permanently and you had to
reset the cluster state manually the
next book I found once that was fixed
was that it would actually lose data by
running multiple copies of the operation
over and over again cassandra has since
fixed those things I think the timestamp
issues are still present but I think the
transaction system stronger 2014
rabbitmq split brain again when RabbitMQ
recovers from partition one of the nodes
simply clobbers the other one and so you
lose all the information that happened
on that node at CDN console are strongly
consistent configurations sort of
coordination systems their rights appear
to be safe but the reads which are
supposed to be on your eyes a bowl were
actually still they let you see old data
from the past elasticsearch loses data
in all sorts of exciting ways we'll talk
a little bit more about that later this
is the part of the talk where I would
print to you new databases I'd say and
now for something completely different
to do something completely different
however I would like to do something
which is in fact the same we're going to
come back to some of these databases
that I've talked about before and see
how they progressed from MongoDB which
many of us know one loved Mongo had a
number of safety issues in the first
Jepson test for writes it will lose data
if you write to it well let's back up
for a second the way MongoDB started was
by not checking to see if any errors
occurred whatsoever it would just sort
of cast its operations into the void and
hope that they arrived safely on some
foreign Shore this of course is very
fast with two phenomenal benchmarks and
reputation for performance it persist
today however it is not particularly
safe the new defaults that they've been
putting in place actually check to see
when on an error occurred some of the
clients look to see if an error occurred
up to the point at which it is
acknowledged in memory this of course is
not safe and no crashes other clients
will check to make sure that it's safe
on disk on at least one of the nodes but
that's also not safe if you're not
running to a majority of nodes in Mongo
if using anything less than record sir
majority you can have a rollback and
rollback is where some alternate history
proceeds and some other No
would accepts new information which
conflicts with your rights and when the
two come back together the one that has
more sort of authoritative nasaw that
means in Mongo will beat the one that
did not replicate its rights fully and
those rights will be written on to disk
in some file and you was an operator
have to go and look at that file and
figure out what happened this is of
course impossible at least in generality
because imagine that I give you a
counter which has two versions one of
them from the database as it currently
stands and one of them from disk but one
of the database says the counters value
is 6 the one on disks as the value is 5
and these things can flip what is the
true value what do you think it is 6
that's a great answer right so the value
would've been 5 and then one node was
isolated and we did a single increment
in the new value is 6 I'm good right who
thinks it's correct yeah that could be
it it could be it another possible
answer do you have one
let's try 11 imagine that diverge at
state 0 and once I'd incremented 1 2 3 4
5 another side incremented 1 2 3 4 5 6
the proper number of increments is 11
because these operations we gives me a
new causality track and we don't know
when the divergence happened you cannot
tell what the correct value supposed to
be only certain data structures called
seer duties are safe to use in Mongo at
any level right less than majority if
you hit a rollback you can lose data at
least for the way most people use it so
problem with majority rights even though
even the strongest level which is
supposed to be safe is that when MongoDB
hit a network error it would check off
the ok box and send the response back to
the client the client would of course
interpret this is OK and then it would
consider to accepted rights to have
succeeded when in fact they were lost so
that bug was fixed and I'd like to come
back to MongoDB now at version 267 and
try to evaluate whether it bay is the
same guarantees the testing 267 here 300
was released during testing 3 Oh still
has I believe single mode data loss
problems in Wired tiger so it might be
but
test those I believe everything I'm
going to tell you here applies equally
to 267 and the three O series the model
I want to test is a linearizable
register this is a single document right
Mongo doesn't give you inter document
guarantees at all it's always on a
single object and we're just gonna write
a single number to it the operations we
can do in a cash register or to write so
we'll change the volume from say 0 to 1
we can read and again reads have to read
the current value that's in the document
you can't read some random value and
then we can do this thing called a
compare and set which is where we've got
a current value of like 0 and we're
going to compare it to the first
argument and then if it's true we'll set
it to the second so I can compare set 0
from 0 to 1 new value 1 if we try to
compare and set 0 from say 1 to 2 will
fail because 0 and 1 are different so
this is a hybrid of a reading the writes
it's an atomic transformation an
interesting thing happened when I ran
these tests
I saw histories like this and of course
there were thousands of elements long
but this is this is a tiny fraction of a
history from just after a networked
petition began and the sort of strange
things happens we initially know that
value is zero we do a read of zero so
somewhere in that green bar the very
first one we know the state had to be
zero the next known operation is a read
of four so the value had to be four at
that time and the only way we could get
there is by jumping up through this
compare and set from zero to four okay
so far so good now we have to get to
this read of three we could execute a
compare and set from four to two that'll
go through because the current value is
four but that leaves the value is two
which is not three so that path will
fail we prune it alternatively we could
write 3 and that allows us to read 3 so
we've got a consistent path now we have
to get to this final read of 0 we could
go through this write of 4 but that
makes the value 4 not 0 we could write
for change 4 to 2 and then that value is
2 and that's not 0 either we could read
3 compare and set 3 to 1 1 is not 0 we
could have that cash from 1 go through
we could go to 4 we can go to 2 no
matter how we order these operations
there's no weight
get 0 it's almost as if the state split
in time and and one note on one copy of
the history the state is still zero it's
unchanged and the other one who went
through these changes and we saw four
and then three occur okay so this is a
linearize ability violation this could
be interpreted as a stale read like
we're reading a value from the past
alternatively you could look at it as a
dirty read where we're reading some
uncommitted garbage data that she's like
a right than succeeded when it shouldn't
have or more specifically a right that
went indeterminate it could have
succeeded it could have not succeeded we
don't know what happened to it but its
effects were visible regardless so these
they are now reported at a server one
seven nine seven five in Mongo both
dirty reads and stale reads are closely
related phenomena dirty reads are known
this is something that's documented in
MongoDB because Mongo only supports read
uncommitted as its maximum isolation
level dirty reads are where are our
rights those casts operations are talked
about in the writes those are all
happening on some minority node in the
cluster they don't get replicated
they're not successful they never
actually should have gone through at all
but MongoDB just writes it immediately
to the local node and then tries to
replicate it and so it's visible to
anybody else who reads in that primary
so we're doing read operations we can
see this garbage data that should not
have been committed and those things
would be destroyed during a rollback
alternatively we could look at it as a
stale read which is where those rights
instead of happening on on the minority
component they happen on the majority
and then you can write valid data and
not see it so these things are are sort
of two sides of the same phenomena
since mongos read operations aren't
linked to the replication algorithm it
doesn't offer us any guarantees about
the values that we read in time that
rules out read your rights and monotonic
reads because I could write a value two
and then see one I could see one two one
two any order is allowable I can see our
betrayal a far back in time depending on
the time scales emergent petitions it
also by induction rules out peer am and
causal and sequential mini risible and
and 1s are all those consistency models
you want to have
if you're doing things like mutexes or
trying to do things like claim a
username those things no longer apply
this is particularly interesting because
my going to be explicitly claims when
your eyes ability in their documents
they say they if you read with reap
reference primary you will see the most
recent right so you will see the most
recent versions of a document this is
not true you can see old versions we
also know from dirty reads that we can't
have read committed and anything higher
than that so that there's a documented
failure on that side we know that read
on can read uncommitted
rules out we committed month um kind of
view core stability all this stuff
this however is new so monger will
actually give us monotonic rights rights
file reads we know committed what it
claims to give us is all the way up to
linearize ability on a single document
so there's a discrepancy here between
what the documentation says and what it
actually provides if you're among going
to be user the results been somewhat
complicated they close the ticket saying
it was a dupe of dirty reads they then
tried to close the ticket saying that it
was working as expected now it's been
rescheduled for hopefully version 3.1 so
we should see a fix at some point if
you're Mongo user the documentation says
you only have to worry about stale reads
if you read from secondaries this is not
true you have to worry about it all the
time if you do need to ensure recency
you can do a compare and set changing
the value you want to read to itself and
also to keep the optimizer from ignoring
your operation you have to change an
unrelated field so you do a hybrid
reading kaz operation those two things
will give you a live miss bound that
tells you whether not you read is valid
okay elastic search elastic searches
test was for one one zero
in June of 2014 we found well a there
was an unknown case of inconsistency
elastic search had a long comment thread
about how if you have a partition which
isolated most of the network the left
one node connecting two sides a note on
each side could elect itself a primary
and claim the node in the middle as a
follower and that node in the middle
would happily sort of serve two
primaries for a while and it would you
know overwrite it stayed continuously
and you would you would lose data when
it came back together and this state
would persist as long as partition did
what was not document at the time was
that monger sorry elasticsearch will
actually lose data even if the network
position completely cuts the cluster in
half and in fact it will also lose data
even if only a single node is isolated
so this could result in the loss of lots
of data maybe up to 90 percent of your
documents inserted during a failure the
cluster status could return green when
remove is in fact hosed you could end up
with clusters that were permanently
wedged and had to be removed
you could gosh this is a fun one this is
oh wait there's a hard coded timeout and
elasticsearch no matter how many the
knobs you turn down you cannot lower
this as far as I know it takes 90
seconds to elect a new primary during a
petition so if you're doing rights of
elasticsearch you have a 90 second
window in your time a network hiccup
isolates of primary during which you
just can't do anything you have to block
elasticsearch had initially no
documentation for these failure modes
however they went back and added a bunch
of documentation so there's now a really
great page that has a huge overview of
all the stuff can happen including stuff
like Lawson documents during networked
addition they also went ahead and closed
the github issue and that issue is for
the split-brain losing documents during
intersecting partitions they say yes
this issue was definitely fixed now
because it had a bunch of kind of false
fixes before and had subsequently been
reopened now folks are still referring
the last talk they're asking for a
follow-up
the response from elasticsearch
employees is usually something like
durability in lasted search isn't a
major problem these days because these
complaints are old so I'd like to come
back and reevaluate this is with the
most recent version as of late February
1 5o interseting petitions that case
that was closed still cause data loss
it's less less than before
it no longer enters split-brain for the
whole duration of perdition now I just
enters it for about 90 seconds and again
that's related to that time out in in
membership transition so you'll lose
some documents but not all in fact
complete transitions are so your
complete petitions and even single mint
partitions will also still lose your
data so every
fail
that we discussed in the first test is
still open in Las research right now
even though the doc github page has been
closed that only applies to the long
list the brain not to the short-lived
one and there are other tickets that
address this now electing a new primary
still takes 90 seconds so be prepared
for unavailability but I want to
emphasize the Lassiter's has made
tremendous progress that that failure
page that talks about all the ways they
can lose data is actually a great
resource for operations engineers who
are trying to deploy this thing I really
want to encourage all database vendors
to have something similar on their sites
so elasticsearch failure modes during
networked petitions are no longer as bad
but they are still present if use
elasticsearch and your network is
somewhat less than perfect which is true
you need to be aware that you could lose
data so you should store your data in
some other data store hopefully a safer
one and then continuously fill
elasticsearch with a constant that
database and you you troll over your
primary database every day or so that
means if a document ever goes missing
it'll be restored by tomorrow and this
is typically fine because most the time
search is probabilistic anyway right
it's okay if a document disappears for a
little bit as long as it comes back
later finally I want to close with a new
database this is aerospike which is a
high-performance five dimensional key
value store it looks a little bit like
Cassandra or like BigTable it's often
used in osep for AdTech often uses the
cash offers phenomenal agencies like
typically like one to two millisecond
latency z' for you know millions of
operations per second it's been very
well optimized and it has this wonderful
claim on the website a reliability 100%
uptime with strong consistency acid a
hundred percent okay my high bar for
availability is the like the Ericsson
axd 301 switch right which is offered
like 99.999999 nine uptime over the
lifecycle the project or whatever it's
like 1.1 million lines of airline code
this is a significant technological
achievement for uptime this is
infinitely better
and it offers acid which this is the the
Ericsson switch did not so on
I'm thrilled specifically it tells us
that there's no data loss which is like
alright I'm in there's Road level
locking and media consistency asset was
synchronous replication so I'm guessing
at this point that they've got a pax
this algorithm that's gonna handle the
the sort of rights would be synchronous
or to be highly available but it'll
it'll lose availability if it ever goes
below quorum I'm excited this looks a
little bit like foundation to be to me
but we have to go a little deeper we
have to dig into the documentation
somewhat aerospike is it says by and
large an AP system which offers high
consistency who knows the definition of
high consistency nobody because it's not
a real term aerospike provides read
committed ah there's a real term read
committed isolation level using record
locks to ensure isolation between
transactions that's ok we committed over
here that's down in this green region of
availability where we can have total
availability that's an AP data store can
offer re committed this is so far so
good
but it goes on for operations as a
single key so the replication aerospike
provides immediate consistency using
synchronous writes two replicas so we're
gonna we're going to write an operation
to did a store it will replicate out to
its partners and then come back and then
it can respond that's a synchronous
replication we typically see it with pax
house or zap a raft read requested says
are guaranteed to find the newly written
data that to me sounds like when you're
on stability or but that's that real
time constraint most recent copy that
property is explicitly prohibited from
being totally available by the cap
theorem so how do you be cap
well you don't it's a theorem it's math
right the way you beat it practically is
you virtually eliminate partition
formation proven by years of deployment
in data center and cloud environments so
the Microsoft Sync on paper tells us
that well managed data centers are not
immune to partitions the cloud
environments you're likely to deploy to
probably see partitions on a weekly
basis and we certainly see them and
anecdotally I know a lot of folks you
know you can't own up to it publicly
right nobody's gonna get up and admit oh
yeah our network is terrible but a lot
people learning the instrument it but it
is very common the way you avoid it is
to setup aerospike with cluster nodes
that are tightly coupled so partitions
are virtually impossible to create
remember coupling and availability are
diametrically opposed if you put all
your stuff in the same rack it's gonna
be more highly coupled it halves
it has fewer network hops so the
partition probability is less but when
the rack power fails you lose your whole
thing so you put them on different racks
okay now I'm working with the top of
rack switches the link between those
could go down that's a chance for
petitions maybe for even more
availability I'm distributing them out
between multiple data centers multiple
availability zones and the probability
of network interruptions there is much
much higher so for high availability we
want to distribute things widely
logically if not spatially and yet for
partition tolerance this you know the
more you distribute the more likely
versions become and the more we have to
actually worry about these problems so
what does aerospike recommend you deploy
to where's the magical network you'll
find that doesn't have these problems
world's apparently Google compute engine
or Amazon ec2
have you ever deployed to these things
like we know you don't okay so what
happens you know if you're if you're
given that network operations will occur
what occurs in aerospike for a compared
and set register you get anomaly so look
a lot like the MongoDB one where we read
a value 0 we do some transformations we
get 2 we get 4 and then we compare this
at 0 to 3 this requires the value be 0
but there's no right of 0 that could
possibly have taken place in that time
frame so this is this is actually worse
than Mongo Mongo we'd read a value that
was bad so we had a stale read and this
we're doing a write which could have
only taken place had the network or had
the state kind of diverged this means
that has operations are not safe
you can lose rights in aerospike if an
hour question happens so that's that's a
hard constraint right linearizable
registers is a tricky problem
what about
commutative operation what about
something that can be eventually
consistent like a counter we'll do a
whole bunch of increments and then we'll
look for the counters read value to be
somewhere between the number of
attempted the number of completed
increments and hopefully it'll it'll
drift into that range give them long
enough counters as it turns out will
also drop data during petitions so if I
look at the the read value over time
that's this red line it should stay
somewhere in the orange region between
the number of attempted and acknowledged
increment operations it doesn't it falls
lower and lower as petitioners occur and
you'll even get in to split-brain mode
like right here in the middle where you
get this kind of bounciness that's
because we're talking to two different
replicas one of them thinks to value is
100 100 100 to the other things to value
is like 200 201 203 and so you get
bouncing oscillating values depending on
which replicas you just you talk to so I
thought maybe I'm doing it wrong maybe I
forgot to flip a configuration switch
and in fact in the acid documentation
there's a setting that talks about AP
versus CP mode CP mode of course does
not exist there's a lot of discussion of
how it could work but it's not a real
feature how does a P mode work well it
works by resolving conflicts using a
generation count which is the number of
modifications that have happened
so if I write B and C to one copy and
then I write D to a different one D
happens temporarily last aerospike
claims I'll read the most recent value
so I should see D but instead I'll see
see because C's generation is higher it
went through more changes in that
replica alternatively I can use TTL
based resolution this doesn't work if
I'm using aerospike as a long-term data
store where I set my TTL to infinity if
my two tails are finite it relies on
synchronized clocks so we have the same
problems as Cassandra and Rioch last
right wins you end up with some clock
difference and you can discard newer
copies of data either way you're looking
at lost updates
there's no way to preserve the
invariance you want so the system is
eventually consistent it does agree on a
value but it agrees on the wrong value
we want semantics with something like a
C or D T where we could do a pn counter
and our final value is the number of
increments not just some higher value
now this is possible in aerospike
because there's an option called
application
that says that it read gives you two
copies both both divergent versions the
data and then it's up to you to merge
those things together if you do that you
can recover all sorts of eventual
consistency properties with CRT T's this
is how react does it this is how there's
some extent cql collections extender
work like CP mode this feature is
documented but does not actually exist
so you're out of luck hopefully it will
exist at a later time to talk to
aerospike and their enthusiasm about
building this in so to make it simple
they claim acid acid is this stuff over
here things are a Peterborough recourse
instability we committed all of those
are ruled out by lost updates like
that's that's like rule number one don't
lose write operations completely and of
course all in your eyes ability
properties those or those are out the
door as well you can write something and
it will just disappear that rules that
monitamon writes so basically everything
that is claimed here is garbage this is
especially pernicious it's it's really
quite vexing because there's a Paxos
implementation in this system it handles
the the coordination for which nodes own
what what copies the data and pack so
this is a consensus system that solves
these problems it's guaranteed that
everybody's going to agree on the same
value if we have majority that's a CP
sort of algorithm so why why don't you
put the writes through it and the answer
from from aerospike is that well with
impact performance negatively because it
would it would take too many hops for
latency I wanted to spell this myth
error spike does synchronous replication
to all replicas so in order to return we
have to rate for every single node to
come back with response that means that
our response time is governed by the
slowest node in the system in a quorum
protocol like Paxos or Zab or raft or do
stamp replication you can return as soon
as a majority of acknowledge so if I
have three nodes I can I can go ahead
with just two of them have responded so
I can actually respond faster in terms
of latency bounds with Paxos than I
could with a fully synchronous
replication system and even better I
could actually be correct this is only
true however if the number of replicas
is greater than two and it's not a
respect only stores two copies of its
data
three which actually means that if
terrorists like wants to provide asset
consistency it will have to go partially
unavailable the incident loses any node
because you can no longer get quorum so
my guess is that you could evolve the
system in two ways you could either up
the number of replicas to three and
start using a real consensus algorithm
or you can go the full CT route anew
eventual consistency and look a lot more
like react depending on whether you want
to bias towards availability and cross
datacenter behavior or more toward
safety bottom-line aerospike might be a
great database for sistex might be a
great database for ad tech stuff maybe
you're doing a whole bunch of Rights you
don't care about losing some small
fraction of them maybe you're just doing
counter tracking or caching and it's
just going to be a modal blip in your
long-term data store but if you're
actually relying on these guarantees for
you know your primary source of record
for for safety about moving dollar signs
around then it might not be a great
choice so what have we learned in
general my job is to inspire you not
just to strike fear into the hearts of
humans I want to emphasize that just
because nobody has tested the system
does not mean it is correct
a lot of people say oh you know there's
no there's no Jepson thing for that so I
bet it's fine this is this is silly
you should actually look and see what's
inside I want to emphasize that Mongo
and last search and particular and in
fact every database that I've tested has
made dramatic improvements right
everybody's trying very hard to solve
these difficult problems Mongo has now
fixed the issue with with their majority
right concern elasticsearch now has
great failure documentation this is this
is really good progress but there are
still surprises down there in the depths
and so like like Jacques Cousteau you
know we sort of as you go deeper the
documentation you'll discover new and
interesting behaviors much like aerial
you know when we are as engineers
choosing a database we're sort of
signing a contract with the marketing
department which is here symbolized but
Ursula the sea witch and they're going
to do a song and dance and tell us
wonderful things about the database and
how much they're going to help us but
unless we read that contract in full
we'll miss the fine print like your
network must not partition even if you
run a Google compute engine or you must
kiss the prints by the third day if you
do those things your documents disappear
you lose your voice so you need to read
the documents completely and then you
have to test those guarantees for
yourself you can't just you know assume
that because they claim lean your eyes
ability that actually holds true you
have to fire up a rig and figure out if
it holds if your database vendor a lot
of times people will tell me like oh you
know we're really embarrassed what the
marketing page says but that's the
marketing departments problem like they
they own that page we can't get it
through you have to stop collaborate and
listen like the the the marketing
department needs to listen to
engineering and engineering used to take
the time to acknowledge that public
representation is important a
communication is an important attribute
of our discipline right we're not just
building technical solutions we're
building social solutions and as a
cultural problem we can't solve it by
just building better systems we have to
accurately communicate those guarantees
so you have to sit down with people who
run your website you can run the website
to sit down to think about a little bit
of math and together you can figure out
the formal language describe your system
I really want to argue for formal terms
because stuff like Street consistency
acid strong consistency these are weasel
words right there they're not
well-defined they make us feel good but
they don't really mean very much in
order to tell what a database actually
does in order for us to build safe
software on top of database we need to
know formal terms like when you're on
stability like sequential consistency as
engineers we have to figure out which of
those variants we actually need so it's
worth taking a little bit of time to
read up on some of the literature and
try to identify what sort of promises do
our users need what will what will
result in the loss of money what result
in the loss of life will result in
nothing bad happening at all and in fact
some of the time it can be okay for us
to have really strong guarantees that
occasionally break a lot of banks for
example aren't 100% safe a lot of a lot
of companies that sell physical goods
don't guarantee correctness either what
happens when I failure occurs is you
call up some people when you say look
I'm very sorry but we seem to a misplace
your order can make it right it can be
cheaper to hire
people and to create cultural prophecies
that account for data loss than it is to
actually engineer system that's perfect
in the first place so you have to
consider that trade-off
once you've balanced those trade-offs
you have to consider the failure modes
that are going to happen in your actual
system think about things like crashes
right this is this is a sort of first
check on every distributed system can we
survive a process restarting you can
kill it with kill - 9 find out can you
survive the failure of an entire node
this is a little bit harder than
surviving just a process crash if you
lose power for example you might have
data that's not F saying to be not
commit er to disk in fact do that's f
synced might also not be committed to
disk depending on how your disks work so
you can use ATS terminate physical power
switches you can unplug stuff inside
your boxes and see what happens all
sorts of interesting behaviors can come
out you should test with clock skew if
you're doing all your development on a
local node you might not see these
anomalies but once you start deploying
to nodes that are distributed and yes I
know we all run TP but somehow every
week somebody comes to me with an NTP
running server that's like two years in
the future yeah it's a real thing so you
should test with nodes that are far off
set in time set the system clock to be
weird things and see what happens in
your systems use fake time to fake out
specific processes you can actually tell
fake time to like advance time at twice
the normal rate or half the normal rate
and you'll get really interesting
anomalies for garbage collection aisle
pauses what happens if your kernel goes
out to lunch and i/o takes another like
120 seconds in your processes sitting
there pick a ping and it comes back and
I think so yeah I'm still the primary
let's do some work right that can result
in all sorts of data loss garbage
collection elasticsearch actually causes
things that look exactly like a network
partition and you can simulate those
with stick stop and stick continue and
finally partitions like an amazing way
to induce failures and all kinds of
stuff
IP tables SJ drop is a really easy way
to simulate the stuff in production if
you want to go a little more subtle if
you're working with gossip protocols
especially traffic control of the Linux
utility TC can introduce delays and
drops in your in your traffic so it's
not enough to talk about a database as
safety I'm just guessing simple uses of
databases like writes to a single
document or increments on a single set
but we're building real systems that
combine data structures that perform
multiple transformations and we need to
test the systems end-to-end to ensure
their correctness invariants hold so
noticed think about the database
specifically think about the low bouncer
and the application logic all these
things can fail in tandem and makes the
failure space much larger than it would
be for single database but you can still
apply these simple checks network
partitions process crashes pauses
ultimately I'm arguing for property
based testing define randomized
operations come up with simple and
variant simple rules that describe what
your system should do when I register a
user and the user service it should
still be there in two seconds two people
shouldn't be able to claim the same
username the number of dollars that goes
into my company should be the same as
the number of dollars to go out and then
verify those properties with a common
distributed systems failure modes this
work is deeply indebted to people at all
the different aina based companies in
particular for this talk kevin porter
lucien of omar opposed less keys li
Hindman matt kangas everybody a stripe
who helped with the talk and made this
research possible especially mark
headland and Brodeur austin Kamsky kelly
sermon everybody who helped review early
copies the talk and text and thank you
all very much for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>