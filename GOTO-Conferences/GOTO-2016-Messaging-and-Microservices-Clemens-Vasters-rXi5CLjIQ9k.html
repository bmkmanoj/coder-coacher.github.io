<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2016 • Messaging and Microservices • Clemens Vasters | Coder Coacher - Coaching Coders</title><meta content="GOTO 2016 • Messaging and Microservices • Clemens Vasters - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2016 • Messaging and Microservices • Clemens Vasters</b></h2><h5 class="post__date">2016-11-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rXi5CLjIQ9k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hi my name is Clemens I work at
Microsoft I am the architect for
messaging at Microsoft in Azure so we
have a few things that we run in Azure
I've been in the there's a lot to read
don't don't worry about I'm I've been
with in the after team for nine years
now which is funny because there's not
nine years old so one of the first
services that or the first service is
celebrated its tenth birthday was at the
end of last month service bus because we
had our first public outing of that
service exactly 10 years ago on May 31st
2006 so we've been around quite a bit
quite some time and I didn't bring the
Bragg slide but our messaging
infrastructure the broker infrastructure
that we run currently runs about 350
billion transactions per week per month
the event hub I'm going to talk about
event and gesture briefly also currently
does about three point five trillion
transactions per week so we run a fairly
large messaging system and so messaging
is something that we're that we're
building as it happens since I'm a
little bit older I've been seeing the
cycle now I'm seeing the cycle the
second time I see this micro services
thing and I'm like the girl in Jurassic
Park in the control center like this is
a unique system I know this I've seen
these things turns out a lot of these
slides that I'm going to show you today
are twelve years old we'll see whether
you can spot which which of them are I'm
gonna I'm and I have a lot of slides for
you so this is going to be a lot of
material I have 70 slides so we'll see
how we can get through them and what I'm
going to start with is my notion our
notion of services and what service
means because there's a very clear
understanding that we have services and
you'll also see why because I'm going to
use Azure as this showcase for what
services mean because we build a system
that consists of 80 services that are
all work load services that not only you
can depend on but also that we depend
depend on each other so it's a very
large ecosystem of services that we
build on top of it where we build on top
of each other so it's not something
that's internal no it's something where
work load teams 30 people 50 people
actually building work load services for
you but also for other people to consume
and that can only work with particular
approach to how we build those services
I want to tell you about that and also
want to tell you about messaging I want
to tell you about protocols and I want
to tell you about choices and it's going
to end in a very simple summary picture
for how you can go and structure our
services and I think about it so what is
a service this is my definition it's
owned built and run by an organization
that's the first defining criterion for
service it's when we talk about service
it's something that is about
organizations more than it is about
software it's about ownership it's about
autonomy of that organization to go
deploy and run stuff my team runs a
service and with what means run is there
is no ops team we run that thing we
build it we deploy it we run it second
the service is responsible for holding
processing and distributing particular
kinds of information within the scope of
a system and has authority for something
in my case we build technical platform
services we build the messaging service
and that messaging broker there's one in
that platform and that's our authority
yeah we have actually we have two queues
another has a different purpose but in
an organization you know the larger
organization there is one particular
service that does one particular job now
there may be some overlaps and there
will be some overlaps due to
practicalities right companies merge
then there's a thing that calls you know
there's a there's a trap that's called
the customer service there is no one
customer service because each sub
organization has a different notion of
what a customer is but for that
particular notion of other customers
there's one service as one team that
owns it every service can be built and
deployed and run independently meeting
defined operational objectives we'll
talk about that too
it communicates with consumers and other
services presenting information using
conventions or contract assurances which
means there is a contract there's
agreement about what that service and
how that service communicates it project
protects itself against unwanted access
to security and its information against
loss there is safety for your data and
it handles failure conditions such as
failures cannot lead to information
corruption corruption so it failure
handling is part of the definition that
is the service in my view whether that
is micro or macro or whatever that is
actually doesn't matter because all
those things also stack your service
that you built as a composition of all
the services downstream services that
you consume I said scope of a system
let's go and define that too a system is
a Federation of services or other
systems aiming provide a composite
solution for a well-defined scope a
airline booking system a video
distribution portal some of those
services may be shared amongst others
and that's true for platform services
than it is for workload services that
provide business business logic so as
your storage is a service that can be
easily shared across many things because
it's not very specific a customer
service against that's the trap is
unlikely be the shareable across
anything that is not exactly that
organization that has that particular
notion of our customers the solution
scope for that service may well be not
just technically motivated but also may
be motivated by business technology
policy law culture and other criteria so
you may go and set up a separate service
a separately run service that may
consist of similar code that needs to be
run separately by a separate team
because of legal requirements because of
regulation because of all kinds of it's
not only technical requirements not only
pure business requirements with this
also other requirements for that as well
which cause a different system to be
setup in which scope in whose scope
services run
and a system may appear and act like a
service towards other services so that's
like a SAS platform office 365 is a
service but it's a very huge
conglomerate of actually built-in
services that you never see because it's
got a one pretty skin on top of it so so
much for definitions service does not
imply any of that stuff in my view so if
someone says you can only do services if
you use docker that's nonsense
if you use on it you can only do micro
services using kubernetes that's
nonsense same for JSON or XML or soap or
rest or any of those things now it has
nothing to do with it service is really
something that talks about organization
how you scope stuff and it talked about
ownership and that's something that's
important that's architecture this is
implementation this is design services
about architecture primarily we'll get
to the design piece in a moment
before that let me warn you of something
because when we tried that service thing
the last time like 1998 1999 when we
came up with this notion of service
orientation and we were kind of like we
Microsoft work on the forefront of that
something happened the ESB people came
and they messed it all up so we we did a
good way you did a good bunch of of
messing up in that whole a story with W
star specifically W security W security
was so complicated nobody understood it
it was awfully it's awfully hard to
implement so I can see why people didn't
like the whole soap the whole soap
business because was too hard the ESB
though that made everything really
terrible well how did the e has become
about ESB had lots of marketing dollars
behind it and vendors with vested
interests to go and sell you that thing
and sell that thing into the enterprise
so you could buy product a product I
don't want to bash the competitors but
you can buy those products and they
we'll were now the central part of all
of your integration interestingly enough
those vendors are now selling you the
API gateway which is exactly the same
thing so let's talk let's let's take a
look at that for a moment so that bus
that you're being sold the Enterprise
Service bus it's not a bus as a hub
typically it's for machine to machines
for machines it's somewhere in the
corner and through which all of the
message traffic rods that's not a bus
that is a bottleneck in the enterprise
and the more and more and more you add
to it the harder that thing gets to
scale that's a reality of why so I
failed in many is a failure in many of
you in many people's view is because
it's coupled to it has become coupled to
this notion of an ESB so what are the
promises the promises of these ESB s is
that you have centralized deployments
and config integration and you have all
these adapters centralized service
governance centralized management of
routing centralized repositories shared
assets all wonderful centralized you can
go and have you know turn all the levers
in that one place the dilemma is well at
scale
and if you really want to have a lot of
services if you run these where you now
have no mobile clients which show up in
hundreds of thousands you have 80
services which need to depend on each
other if you want to go and centrally
manage all that stuff that's get a root
that's getting really difficult who is
maintaining those four servers who is
actually owning all that stuff what this
turns into is the central IT
organization where you have to go and
file a change request for the ESB to go
and change an adapter or change the
configuration so that's a horrid idea if
we had done this in Azure just in this
example with all the services that we
have all the teams that we have with
with 5000 6000 engineers who are working
on this who owns that centerpiece who
owns that big rendezvous thing in the
sky who owns the
integration application server that
everything runs through nobody can it's
too hard so that whole idea of having an
ESB of having this this big thing in
that city in the middle of your
enterprise and that every everybody
rhonda busan is giant nonsense and that
is a failure that is the failure of not
of the of the notion of services that is
actually the failure of the concept of
centralization so micro services is the
resurgence of services as we fought them
up in the late 90s in the beginning
instance thousands before all that ESB
nonsense happened the api gateway is
exactly the same trap so don't fall into
it because we made me messing that up
again so be aware if someone says you I
want to have here's a centralized
managed API gateway that's the same
thing so that much as a word of warning
just because I have you now case study
Microsoft Azure how do we build stuff
how do we run these so we have a large
number of feature services we have
probably 200 services altogether
including the internal ones I think we
have 85 public feature services that we
have individual names and of course
there's a lot of stuff in the back end
that helps us kind of running the system
right just as much as as the Netflix
folks have a lot of services that you
never know about because you know you're
consuming they're they're pretty
front-end we have a lot of services in
the background that also we're running
the so and then these are the shared
back-end services such a billing such as
Diagnostics pipeline which does troll
into the events for actually per minute
and we have we're all independent teams
so my team is depending on how you count
50 60 70 people and we're shipping
completely independently from everybody
else nobody we don't need to announce to
anybody that we're shipping we don't
need to announce anybody that we're
patching because we have we're making
promises to our internal folks and
we're making promises to the world the
clear advantage that we have as a team
is that we are we have an obligation to
the public because we're shipping a
public service and also internal
internal parties rely on so we have the
obligation to upgrade the system which
is stateful it's a message broker
underload maintaining SLA maintaining
SLA means we need to have 99.99% uptime
99.99% reliability through the upgrade
process and that's something that we
just that were making a promise about we
have to go and uphold that we shipping
features and fixes daily there's this is
deployment going on all the time there
used to be some time when the executives
get on stage and we're presenting a sure
that there was kind of a change band
that no longer exists like there's good
deployments going on when Scott Guthrie
gets up on stage at the build conference
that maybe just upgrades running because
there's no band all this it just needs
to work
28 plus core data center facilities I
think we're up to well over 30 our total
data center footprint is 200 that we
have including two CDN nodes and what
else we do in Microsoft but address
currently in twenty eight we have our
service has at least two sometimes four
sometimes more clusters in each of these
data centers and facilities and those
clusters are between 16 and 256 machines
with two to four cores each so we run
fairly large clusters in those setups
across those systems and what they do is
they move messages just in the clever
way the only way how this can work
so I just talked about us but us meaning
us the service must see the messaging
team we federated everybody else so we
rely on storage we rely on compute we
rely on the the billing pipeline we rely
on all those other services so everybody
needs to be able to go and deploy
themselves everybody needs to go and
have the same agility and that's
something that you can only achieve if
we have the right principles so what I
told you at the beginning of the
definition that is the core
those principles and so I want to
explain more and how we get to those
principles how we think about those so a
service let me go and dive into more
from a conceptual perspective because
that matters and this slide is actually
this slide and this is something that
I'm done I'm really glad about and proud
of I have to say this slide is literally
twelve years old that was right then it
is right now and that's the fabulous
thing we were right about this whole
thing twelve years ago about autonomy
about doing this in the right thing we
built the services in that way this is
not a new movement this is proven
principles and that is why I'm so
excited about my core services I'm not
excited about the name actually but I'm
excited about the fact that we have
taken services back from this mess that
was the ESB and are rediscovering the
principles this is a cycle I'm really
excited about so a defining property of
services is that they're autonomous and
that autonomy speaks about team's
autonomy is independence a service owns
all the state it immediately depends on
the managers all the data belongs to
that service and only to that service
the service owns its communication
contract the service owner owns the
contract makes a promise and if it wants
to make a change we can make it they can
make a change but there's no central
committee that defines what that
contract looks like the service team
owns that communication contract the
service can be changed redeployed or
completely replaced at any time service
has a well-known set of communication
paths where it announces itself the
service shall note shall share no state
no internal state with others and
there's no common data store there's no
shared in memory state with any other
services if if you do this then you
don't have a service you may have a tear
but another service I'm going to get to
tier two tier and services and layers in
a moment and there can't be no side line
communication then we'll also talk and
I'll have you have a picture in a moment
what that means in terms of and why
that's bad
interdependencies your service owns you
owns its own uptime if you depend on a
storage service underneath whether your
data is stored and that service is gone
that's your fault because you ought to
have a replica of that data somewhere
else or you should at least minimize the
risk such that maybe one of your
partitions goes down because that's that
goes down over there but you should go
and spread the risk around for your
downstream dependency so that you can go
and stay up and you should you if you
stay if you go down then at least be
upfront about it right and give proper
errors back
don't just crash like you need to expect
that all the stuff that is downstream
from you is not available it may not be
available so what is your plan for when
that happens so that's something to be
really conscious about you own your own
up to it's not not something that you
can go and blame on others and
autonomous service honors its own
contracts because you can only be
autonomous if you have confidence that
you can go and upgrade and that means
you made a promise in in the current
version and you now made a make an
upgrade well the other people who are
talking to you don't know about your new
features in your new contract so you
have to honor the old one and in most
cases there is a people contract that
goes along with this which means we're
going to sunset this API in a year and
that's how much warning other
organisations need and that's our policy
is to say we actually give you a year to
go and change things and that's that
might sometimes even be slow so yes you
can go in and rapidly evolve your
services but you need to are all on our
backward contracts and if you look at
many of the services that we have
sometimes they they actually on our
contracts 2020 versions back because we
can't break the clients bits are
deployed bits are shipping with other
software so honoring the contract is the
is the way how you achieve autonomy for
yourself it's something that you is it a
required discipline so why is sharing
data stores bad there
a simple example so you have two
services and they sort data they've
retrieved by a primary key passes that
on to the other servants that other
service
now we relies on the same store right
token data the problem with that model
is that service can never go and depend
on the other store right you can't move
that service over to the other store
because they have a secret relationship
with each other they share primary keys
they can't they have to pass the data
around literally when you make this
those two services are not coupled why
is that that because it's one it's one
store you can't pull it apart you can't
scale it up you can't partition it you
can't do any of the things that one of
the services might want to do because
the other one depends on a particular
relationship with them so these are not
two services these are actually two
modules which are looking at the same
database the nice thing also is that
data store decoupling enables evolution
the contract piece not only is valid for
talking to you through the service
through the REST API or through
messaging it's also true for the
relationship towards the data store
because the data store also has a
contract has a schema so you have an
evolution that goes on where you now
need to have new features and if you
have new features and you need to have
the data store change well then that
data store can very easily change in if
you have the store separated so the
decomposition of services from a model
it takes application into services means
that you're breaking up the database
otherwise you don't have services it
must mean you break up the database and
breaking up the database there's a whole
talk that I would love to give and
that's the 3-hour talk probably about
data patterns look at your database and
and differentiate between the data that
is written that's read right and hot and
then you read right once and never
change again
I think about what the data does there's
some data you can easily replicate
throughout the world very easily and the
transactional core is very very small in
most databases so you have to triage
your database that big data model with
170 tables or 700 tables is dead if you
want to do services also services have
different requirements in terms of scale
and this is where we also get to to
two-tier concerns later you have a
service that deals with front-end
traffic from mobile devices and from a
mobile app that you just shipped and you
have a back-end service that just
accepts whatever bookings like you have
a travel a travel service the travel
service with the catalog is going to
serve a ton of requests those travel
bookings are going to come in you know
fairly rarely those have completely
different scale scale concerns and you
can go and build them differently so you
have a service B service P this slide is
actually 15 years old the service
becomes overstressed what do you do and
they're all sitting on the same machine
we split them up two machines
what is the requirement no shared in
memory state no shared in memory
dependencies between the two they need
to be autonomous the service still runs
hot what do you do well you sharted
across machines so in the simplest case
you cannot have crisscross instance a
this is where the notion of stateless
shows up where you don't have any
interdependencies between those service
instances they don't share state in the
simplest case because the more
sophisticated our systems get the harder
gets the state listing and the state
listing is really just a lie mostly
because it talks about the length of the
session it doesn't talk about anything
that's happening at runtime
stateless means it commonly you make a
request and after that request you
forget everything the set length of the
session is one but we have more and more
sophisticated systems where the length
of the session is longer than that so
what are we doing to do with that
so there's infrastructure that we add
for this today
we're monitoring modern clustering
infrastructure can allow for easy and
consistent state sharing failover of
ownership aspects of partitioned
workloads one of those examples is
something that we have in our cloud and
also available from premises also in in
preview for Linux and it's called
service fabric and service fabric is a
clustering fabric there's many other
examples of dhts
the serving the hash tables you can go
and find which can also go and replicate
that kind of State across machines but
I'll give you an example of how the
service fabric works in our system so
this is a generic picture of a gateway
that has stateful computer behind it and
has a storage tier behind it turns out
our the service that we build our broker
actually is looks it looks like this in
that way so we have an HTTP gateway and
you have the lookup facility that allows
you to kind of find the owner of the
bucket a one so the first this first
yellow arrow at the top is implies a
lookup to the cluster facility which
then says I need to find a one the owner
of a one which machine owns a one that's
usually a hash resolution finds that
place goes and talks to it similar thing
happens when that fateful compute
cluster now talks to the storage tier
which also finds that place now
something happens that machine dies in
automatically cluster system
automatically falls over fails over to
the secondary which has already been
primed it knows all the data which it
now gets elected to the new to the new
primary and if that same thing happens
on the storage tier well the same
failover happens so that's that stuff
that happens in these modern in this one
cluster fabrics where state state let's
no longer exists
exactly stateful is okay because we now
have ways to go in and create
consistency across a large cluster so
that we can go and scale those things
out because there are problems that
require that stateless in the sense of
Webster but is still very easy but
there's workloads where you need to go
and maintain ownership and where you
need to maintain a notion of what is
what and where is where so that was
clustering there's a fabulous talk
unfortunately I have not I there might
not be recordings but there's still its
slide deck that's around if you find if
you look for features and emissaries you
will find a fantastic deck pad Helland
wrote this he said he's been fabulous in
2000 now in the late 90s transaction god
and he wrote this book he wrote wrote
this deck about feast reasons and
emissaries and one of the key aspects
here is one around autonomy where he
speaks about how to think about autonomy
and the relationship to other services
and an emissary is a very interesting
concept an emissary is a piece of
software you give to someone to talk to
you and that's something that we do very
very often today by giving people SDKs
so Kafka for instance has a private
protocol and they reserve the right
Apache Kafka messaging infrastructure
these we reserve the right to change it
the way how they get around this around
publishing the protocol effectively or
committing to the protocol is that they
ship you bits so they ship you an SDK
for this and this and this for many many
many different languages which are
emissaries we're going to see more and
more of this in the space of IOT because
we have a notion of edge computer you
want to go to push computation out into
devices that are sitting at the edge we
want to go and push compute out to to
fog devices which are kind of sitting in
the network so services don't
necessarily all hide behind their
boundary but they may send little
software agents out into the world which
kind of do work on their behalf and if
you see what javascript does today in
browsers on behalf of the back-end
service you have a lot of these
emissaries so that
is also something that is an old concept
proven because we do that all the time
the benefit of keeping these services
autonomous is that they enable
operational agility services and all the
implementations can be moved for
configured replace behind the curtain
you're committing to a contract you're
committing to to a certain external
facing contract you you committing means
as you are upgrading as you're changing
you keep honoring this which buys you
that sort of agility autonomy also and
which means not sharing stores not
sharing anything that's kind of
downstream from you stack also enables
clustering you cannot do cluster you
cannot do partitioning you cannot do
clustering you cannot do slicing up your
work with scaling out your workload if
you share stores if you share any under
downstream infrastructure with anybody
else because you don't have agility to
go and change it that's really important
ultimately reusability and adaptability
is something that you can achieve when
you are autonomous so autonomy is is the
prime principle and if you want to take
anything home from today from this talk
autonomy is important that is the
service what do they try to achieve so
what are we trying to ship when we ship
a service let's go and move on from
autonomy scalability availability
consistency and I don't have enough time
to go and define all the ways in in
details let's reliability predictability
that's one that's easily overlooked but
someone that's actually hurting us quite
a bit if we messages flow through our
system in X milliseconds people get
really upset if it takes more
milliseconds than the usual milliseconds
and if they if it takes like five
seconds to go and move a message around
they get they call us predictability is
really important predictability means
you need to ring-fence resources to do
the same job over and over again there's
a lot to be said about multi-tenancy in
the perfect the wonderfulness of it
but if you need predictability you need
to have the resources available at all
times so that's something that's the
interesting design point we have in our
service now a capability of premium
messaging where we actually live
ring-fence resources we're in France CPU
and memory for customers so that they
get the same performance every time so
we don't run that in a multi-tenant
system anymore in those particular cases
just for predictability security is
obvious agility the ability to go and
make all the changes that I talked about
safety risk of disaster support ability
cost all of those are operational
objectives that a service team needs to
meet and the service team has kind of in
that in those all those categories
you're going to get those slides so you
can go and review those areas that makes
assurances that's the thing so basically
in all those buckets you think about
what you are trying to achieve and then
you now turn that into an assurance to
your clients because that's part of
building a service and running a service
what is my predicted predictable
performance what is my scalability right
if you buy X you're getting this and you
will go and discount based on what your
metrics are and basically what you
measure you will go and give yourself
some wiggle room and then make a
commitment to this is my reliability
this is how many transactions of I will
fail and transaction failing
transactions can be quite a bit so for
instance what we do on our brokers is as
I said three trillion transactions
closer to three trillion transactions on
event hubs per week
egress 99.99% reliability on trillions
we have a lot errors we have millions of
errors millions of errors that's okay
because we're very upfront about about
what that is you can't expect perfection
out of us because we're running a system
at drama scale but that's something you
need to be very clear about and cue
with people so what is your what is your
commitment okay so so much about
services so service is something that is
really a contract that you make with
other people and it's something that's
about organizations not about code this
is about code layers tiers and services
a layer is how you organize code you
have a notion of the interface you have
a notion of logic and you have a notion
of resource access the reason why we
introduce layers back in you know
there's very many of these layer
patterns MVC is one but there's the
three-tier classic three-tier is one
there's very many of these tiers of
these patterns and those patterns are
always for trading resiliency between
those different concerns so you can go
and change if you in MVC you can go and
throw the view out without breaking
everything everything else right in a
classic three-tier app you can add
another interface you can add another
way of communication without breaking
everything else you can replace the
database now I'm joking you can't
replace the database many people tried
everybody knows you can't if you change
the database you can screw it so the
rationale coming and it's this is also
why I have that circle right from the
outside is more flexible from the inside
and when when you get to resource access
when you get to the database your your
your super tightly coupled but out to
the edge you can be laid you can be much
looser couple that's where you have more
leverage than in the in the middle
that's also a reason why you want to
keep those things autonomous you want to
you if you need to have a major database
change you want to constrain the impact
to that one service you don't want to go
and redesign the world so that's good
hygiene in your systems so communication
layers resource layers and then the
stuff in the middle which is what we
call logic awesome tears are about
runtime organization this is and this is
where this is where
I might disagree with some other people
who call microservices what
micro-services are I just I have a clear
distinction between service operational
assurances contracts teams and tiers
which are the things that actually get
deployed for me a gateway is not a
service the game is part of a service
but it's not a service per se an HTTP
API layer is not a service because it
cannot it is not independent of the rest
of the of the system of this of the
service that you deployed the service
that you own for me that's a tier and
you may able to go and independently
deploy tiers yes but if you have to go
and do magic magic to go and make you
know to do a stamp deployment of your
service
you can't break anybody else but you can
completely replace all the internals of
it so tears are about meeting your
operational objectives and that means
that the Gateway tier may scale higher
than the backend tier may all of your
different serves all of the different
tiers that sit in the system that sit in
your service may have different
objectives that they need to meet so I
can tell you from our service from
service bus we do a lot of MPP and HTTP
traffic and a lot of crypto on the
gateway we do a lot of competitive heavy
compute work it might not seem that way
but messaging is kind of hard
a lot of compute work in the backend in
the messaging back-end those two tiers
are completely different in terms of
characteristics and we're also as a set
ring-fencing resources for customers the
predictability of the system depends on
the messaging tier but it doesn't spend
so much on the Gateway it's here the
Gateway it's here has a completely
different needs for memory and CPU and
networking then the messaging tier does
so we pulled them apart we don't run
them on a single set of machines we
actually run two clusters which are
effectively bound to each other and make
up the service and then we have another
tier obviously which is the storage tier
underneath it we break those things up
in tears because we need to scale them
differently
and because they use the resources of
the system differently and if we have
uniform usage of the resources on our
machines we actually get higher
reliability and and specifically in
messaging we sell reliability as a
service so the way this materializes as
I just said is this gateway back-end
storage different tiers one service so
layers are as about code management
tiers of our run time management and
services a really about ownership that's
that picture having a head now I promise
you communication we have 10 minutes ago
let's try that communication messaging
is all about how we move information
between systems and that's something
that's really important for talking to
services because services are networked
entities so let's talk about how
messaging materializes messaging is
about getting data from A to B and back
sometimes not always sometimes there's a
lot of here so you have a lot of clients
you have to deal with sometimes they
show up all at the same time sometimes
they show up it trickles sometimes you
have enormous amounts of data that you
need to go and deal with sometimes that
allows them they're there you need to
send one message you need to get that
message to a lot of people we have one
service that's called notification hub
so we also made which is specifically
built for the problem of let's say the
Olympic Games or news organizations
which want to go and send one news byte
but need to get it to 15 million phones
within a few seconds sometimes the
destinations are all different so we
actually need to go and differentiate
sometimes the destination is not paying
attention or can't so you have to do
something to go and you know have a
little mailbox for it sometimes the
destination is super busy so it will
throw you a 503 if you try to keep
tickling it and sometimes it just it's
just dead and you don't know what so
there's got to be answers to those
problems
HTTP which we all use and is the de
facto default for all the micro services
doesn't answer some of those questions
so let's go a little bit further and
kind of think about what protocol
requirements may be and what what things
and what those what many terms mean
client and server
what is client and what is server client
and server ultimately only describes who
makes the initial connection you have a
network someone is listening and
someone's connecting that's client and
server turns out many and in HTTP that's
coupled right
the the whole notion of who can make a
request and who can go and ask someone
else it's completely coupled to who
makes the client reconnection which is
not true from any other protocols so
let's stick with client and server as
just the the party which is listening
networking the party which is connecting
which is useful for many scenarios if we
think about you know you have a client
that needs to connect out of an
environment that is firewalled and
anatta him everything but you still want
to get back to them
from the server side right bit not it
would be nice if that was possible and
disconnected from the fact who's
connecting out and connecting and so
client or server is just about the
network connectivity direction then
there's directionality of that
connection is it simplex one-way only
some protocols do that or is it duplex
allowing flow of data in either
direction initiated by either direction
that's a separate concern then there's
symmetry AMQP which we'll learn about in
a second is a symmetric protocol any
content of the two connected parties can
do anything it likes that's defined in
the protocol at all times except
connected once it's connection
established it's fully symmetric HTTP is
not symmetric because only their
connecting party can issue requests that
has been has been relaxed a bit in HTTP
- but it's not those are not symmetric
protocols 8mn qtt friends another
messaging protocol is also not symmetric
because there's specific things that
only the client can do
multiplexing it'd be nice sometimes to
be able to go and use that same socket
for two requests at the same time HDPE
can't hb2 can because it added
multiplexing because there's there was
realization that it may would be nice to
take that expensive HTTP s ssl/tls
socket that has been established and
reused it instead of making many many
more for small payloads framing what
those protocols do is they frame the
data for us and then we take data and we
encode it on top of that jason avro
message pack xml MPP has its own
encoding CSV MPEG text raw there is good
choices for all of for all kinds of
workloads Avro is an awesome awesome
awesome format to encode time series
data it's binary it there's extra
compression it carries the schema with
it it's astonishingly much but and has
better type system than Jason right the
world is not Jason the rut the reason
why HTTP has a content type and why mqp
has a content type is that you can go
and get to choose what you're going to
go and transfer you just need to be
upfront about what you support and then
there's metadata you want to tell people
about you want to tell the other party
about what that message contains HTTP
has had three definable headers in QPS
Frieda definable headers and utt
intercellular insistently enough has not
so you have to go and mangle all that
information into the topic path which
kind of makes a little weird or you need
to have out-of-band agreements across
those so so in this context of the
communication context and service is a
reusable artifact that can access the
access through channels well defined by
some interface context so that's
communications focusing just on that
edge and it's focusing on that contract
and that you can it that you adhere to a
particular contract interestingly enough
not
no single communication mechanism fits
all uses so trying to fit everything
into rest threat trying to fit
everything into HTTP is actually not
helping but it's counterproductive for
many paths and trying to make everything
in JSON is also counterproductive we
have the flexibility in that in the
stacks to actually go and use different
formats for different purposes you have
an entirety that is the contract the
service has has a composite surface area
that is the contract you need to learn
here too but that may be composed of
multiple channels and it may be composed
of multiple ways of how you go any code
data so I'm going to be absolute five
minutes location transparency well what
did I just kill okay that's fine
location transparency means that you
don't that's actually a very easy one
you don't give people the direct address
to your service you hide behind at least
one level of indirection if you give
someone you give someone a DNS name that
then maps to where your service actually
sits because otherwise you can't move
the service there are situations that
we've had in our in our world where we
had to literally replace cut clusters in
by taking the customer data and copying
it into the new cluster because our
schema changes were radical and we had
to go we basically implementation of
pieces so we kind of did a copy into the
new cluster continuous copy into the new
cluster kind of kept the system
consistent and that did a forced DNS
switchover of everybody so we did we
flipped up we we dialed the DNS record
to zero the TTL effectively in a
stepwise way took the old cluster down
base you cut everybody's connection
everybody picked up everybody failed
picked up the new DNS records that
actually works because many sects are
good about TTL and then I had everybody
over on the new stack so and the only
way I can do this is have an additional
abstraction using DNS for location
transparency
you'll know all this you know all this
yeah so so I mean it's obvious that TCP
is a stream and village I should have
cut those slides I just realize okay so
every service can be reached at least
through one channel but it can have
multiple channels and the the the edge
is effectively the services user
interface if you will right so it you
can have you can have multiple multiple
interfaces to your service and that's
all just fine so in the interest of time
let's get to the protocols to start to
talk about them effectively as we are
now informed about them what is HT p11
HP is only allows the request response
pattern it's not symmetric doesn't allow
multiplexing allows variable encoding so
that's great
and allows metadata doesn't give you any
assurances whether and when the message
gets somewhere
WebSockets is not a protocol well it's a
protocol but it's tunnel mostly if
you're creating if you say I use
WebSockets then the question is what are
you going to put on top of the
WebSockets musicals WebSockets is a
framing protocol and that's all it does
so anything you do over WebSockets if
you're not using anything that's a
protocol that's overlaid over WebSockets
then you're using something that's
proprietary because it's just a tunnel
it's a trick to get to a 443 but it's
not a protocol in itself it just gives
you a raw socket so if you do anything
just over WebSockets you just created
your own proprietary little protocol HT
to is a CP as we know it plus
multiplexing plus binary header
compression it's no longer a very simple
protocol SHP when one was and if HP two
had come first the adoption of that
would be have it very little but now
this thing has a lot of adoption lot of
big companies behind it and the browser
vendors and the web server vendors all
you know can collude and can go make
something that's complicated but it's
effectively what we
and it has a special new feature that is
a one-way communication channel that
allows the server to go and send data
back coop is a protocol you'll hear more
about in the context of IOT the Internet
of Things that is very much like HTTP
interestingly it's a symmetric so any
site can go in initiate request and it's
super super super tiny and it's being
used today to go and manage all your all
of your mobile phones that's how your
mobile phones communicate at least in
your deployments the lwm 10 protocol
which is used for device management
you'll hear more about this if you're
involved in mobile or if you are
involved in in IOT and then there's MQTT
a publishing subscribe protocol one of
the messaging protocols which is great
for communicating telemetry great for
communicating little bits of little bits
of data and then there's the MPP
protocol which is a messaging protocol
which kind of sits on sits a little bit
up above MQTT in terms of capability it
supports multiplexing that MQTT doesn't
it's fully symmetric that MQTT MQTT is
not but those two protocols AMQP and
MQTT are the two candidates if you don't
use HTTP and two candidates for
asynchronous messaging with a broker in
the middle you can do all kinds of
interesting additional things and I'm
already in over time I'm going to take
three more minutes load leveling means
the service hangs there's a bunch of web
servers here which take traffic you have
a queue there's a lot of traffic that's
coming in and all of that lands in the
queue the nice thing is if you have a
service that sits behind those and it
now pulls from a queue that stress that
comes up on the web doesn't come down
into your service because you do a push
to pull translation through the queue it
gives you load leveling you also get
true a little balancing all of the load
balancers are HTP load balancers are
actually lying to you right that's a lie
it's lying term because it doesn't
consider load at all just spray
all mechanisms that allow that try to do
load balancing by measuring the load on
a machine and then try to push are
doomed to failure the only way that
really works is to pull the data to pull
jobs off a queue when your thread has
capacity so that's something that only
is only self determined so that's load
balancing that you also get through Q so
the Q insulates you from spikes and the
Q also gives you a little true load
balancing so that's an advantage of
sitting behind the queue and then of
course you can go and take one messaging
go and distribute to multiple parties
that is true for all those message
brokers so messaging infrastructure that
we that you'll find that will help you
with your micro-services infrastructure
that will help you with meeting a lot of
those operational objectives this
enterprise message brokers after service
bus thing we build IBM MQ activemq
RabbitMQ they have publish/subscribe
super to robust and durable and
typically allow multi node clustering
then there's lighter weight message
brokers like our a virtues or sqs that
you find on Amazon more constrained in
terms of features or most kiddo the MD
broker mo constraint features in a
certain way but kind of focus on a
particular task and then we have these
invent event and gestures like kinases
like Kafka like what we have an event
ups which are basically just meant to
take huge amounts of data from millions
of sources and capture the name
assistant so that they can go and be
published all of those fulfill
effectively the same role I'm going to
go get get to the summary because of
time fulfill the same role and that is
being your gateway augmenting your
gateway for your service so they sit up
here
there are message brokers they're not
clever they're not the ESB they're there
you can go and set up a queue over here
you can set up a queue over there you
can set up a queue over there all of
those you can treat as one because they
have no intelligence they don't touch
the the payload right they're just dumb
pipes and that's good that way but they
take the traffic for you so that you can
go pull it into
our service and and and handle it that
you can fulfill your operational
objectives that you don't get punished
by the stress that comes in from the
outside world and that and that you can
go and make sure that a message has been
captured reliably that you never lose
that message you have never any Delta TM
with HTTP HTTP is always great and all
these synchronous protocols are always
great if you need to have an ad hoc
response to something if you need to
know often it's enough to know that the
message has been submitted at the
message will later be published and
that's something we see more and more
and more so when you think about micro
services think about autonomy driving
principle second think about all the
different options you have in terms of
protocols and encodings because they are
all part of your arsenal don't let
yourself to be constrained to just HTTP
and JSON and that's what I have thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>