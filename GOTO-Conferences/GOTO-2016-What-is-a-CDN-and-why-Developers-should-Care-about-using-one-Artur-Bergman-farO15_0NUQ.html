<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2016 • What is a CDN and why Developers should Care about using one • Artur Bergman | Coder Coacher - Coaching Coders</title><meta content="GOTO 2016 • What is a CDN and why Developers should Care about using one • Artur Bergman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2016 • What is a CDN and why Developers should Care about using one • Artur Bergman</b></h2><h5 class="post__date">2016-07-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/farO15_0NUQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey stop wrong
hello Stockholm so I'm here to talk to
you about something that's actually
pretty boring in most people's mind
which is a CD mr2 Bergman long history
of doing open source development and
various large websites true history and
I'm actually from Stockholm was just
commenting it's pretty funny people
speak English to me I reply in Swedish
and people keep speaking English you so
after 13 years of living here and I
realized how hard it must be to learn
Swedish summarize the story really
starts started in 2008 when I was in
wikia where I decided somewhat foolishly
that we needed to build our own CDN in
retrospect not that foolish and I took
two servers this checked luggage and
flew from San Francisco to London and
built our first pop that is a very
cost-effective way of moving servers
between countries not recommended and in
2011 started fastly you're five years
old headquarters in San Francisco 270 m
please and why why acedia so if you have
an HTTP request my goal here is really
to convince you then if you have an HTTP
request going over the internet and
you're not using a CDN then either you
are doing something wrong or we are not
providing you the service that you
should that we should and you can't use
us because I firmly believe that if
you're sending an HTP request over the
Internet it should be using a CDN I'll
go through why so how many people here
actively use CDN was like no not that
many how many programmatically interface
with your CDN is and so on that is
depressingly few to most people this is
what a CDN is right it's a big black box
that sits somewhere between your servers
and the end users and supposedly makes
things faster but you don't actually
know what it does have works where your
traffic is going this is one big black
box right kind of like magic which is
just a meaning but you don't actually
understand what's going on so it looks
like magic to you it's not actually
magic it's very very simple it's a
reverse proxy right we all know what
reverse proxies are right like we use
them use lbs we use f5 which are
terrible we use 18 proxy squid whatever
we use we use a reverse proxies all the
time
right they terminate our HTTP requests
and they send traffic to our app servers
it's pretty standard architecture to
have them involved right the only
difference between a CDN and a reverse
proxy is that we have them all around
the world that is really the only
difference right so if your client is in
Tokyo they go to a reverse proxy in
Tokyo that then sends the request
onwards to your app server in ec2 East
but at fundamentally all it is its
reverse proxy it's also a reverse proxy
there's a big awesome amount of caching
attached to it which is key and I'll get
into that later
so this reverse proxy has to run on
something what in run song for us it's
pretty powerful machines I heard the
previous person to talk about the loss
of virtualization we don't virtualize
because lots of performance is just too
too bad but it's kind of amazing right
like one rack we can put 768 terabytes
of SSDs right like it is a enormous
amount of storage that we can deploy in
a fairly small footprint at the edge and
a lot of bandwidth that we then give
access to everyone for so what happens
when you use a see the end you have a
user
the user ghosts at the NS server the NS
server tells the user go to a CDN pop
typically you have si named or some have
delegated that responsibility to CDN see
the M pop gets the request to see the M
pub doesn't have requests it goes back
to origin and origin responsive to
object and we store it in the cache
and then we return it to you sir it's
very very simple and if the cache it you
don't actually have to go back to the
origin basically we're all used to using
memcache Redis or whatever caching
technology we use inside around a bazaar
but the CDN is is really the same thing
but outside and in a pass-through matter
right so you don't give us content when
the user requested we on-demand lazily
fill up with what comes but the user is
requested and we're close to the user so
then you know the standard complaint I
hear is my content is private it's so
special like it's only served to one
user there's no way we can cache it it
has PII blah blah blah blah that's not
usually true when you actually think
about it most of your content is
depending on your application but most
of it is actually shareable right it's
just that typically you have really bad
architectures that mix-and-match a
private and on private data into one
payload when that makes it hard so why
should you care right
traditional CD ends have been owned by
the operations people it's been
something you add on bolt-on later
and typically they just make your life
harder right they intercept your request
they cache they do weird things to them
and as developers and this is certainly
me before I started to see the end I
actually always hated using one I think
I knew it was an evil I had to deal with
but not a something that actually helped
me so why should you care so the first
reason is performance right we all like
performance
this is a very simple chart of what
happens to your bounce rate was actually
taken from Wikia when I was there - your
bounce rate when when site performance
goes down all right so the jump from
point free second load time to two
seconds is seven and a half to 20
percent bounce rate like that's pretty
damn huge and it's actually very early
in the in the chart that you get most of
the effect it's a wire finx low latency
latency is a measure of time delay
experience in the system the precise
definition of it depends on the system
and the time being measured or waiting
for right and latency adds up so
when you have something latency here you
know some ladies are hearing yeah you
have to add it all up and you get
something really bad fundamentally
though but CDLs help you if it's the
latency that you can't solve otherwise
which is this which the speed of light
all right no matter how hard you try
it's going to take you ever take 200
milliseconds for something from Europe
to reach Australia now it's two-thirds
of that in fibre plus fiber doesn't
actually follow the shortest path so no
matter how fat how clever your code is
no matter what you're doing
fundamentally you have to deal with that
difference so you catch it locally the
second is security so we all want our
sites to be secure what is this this is
160 gigabit per second DDoS it happened
very very quickly so you can see the
normal traffic starting up in the
morning going then increasing traffic
which was someone probing the network
and then within two three minutes it
goes from 20 gigs inbound 260 gamers per
second dingdong right this is actually a
pretty small attack CDNs implicitly
because you send all your traffic
through them protect you against that
right like and the only way to fight the
lead off is to have more capacity than
your
so we provide a layer of free for DDoS
protection layer seven protection you
can put in blocks you can analyze your
traffic at the edge and then you can put
in rules for what you want to block well
you know what a block but you want to
tarp it and so on and the edge is
important because you look at like this
is a normal traffic distribution for us
you can see that there's there's a fair
amount of bandwidth going between
Ashburn San Jose Ashburn Virginia San
Jose and Amsterdam which are large data
centers and then there isn't actually
that much traffic going long-distance
because our entire purpose in life is to
serve users that are close and then this
happens so having been lead off a lot
ninety-five cents out from them are from
China and I wish they would just shut
the firewall off and not actually send
us any more traffic because all of that
was China right I was really frustrating
with it is that they have this giant
firewall so they know it's happening
right they inspect every single
packet going over the wire and yet
they're okay letting like 200 million
packets per second leave the country not
enter so our ability to absorb that at
the edge far from where your data center
is far from your cloud provider is is
really powerful because it's the only
way to have enough capacity to handle it
it's also the only way to help our ISPs
handle it because they don't actually
have enough capacity to backhaul
everything to a certain region right so
like you will actually see saturation at
multiple levels of Internet so largest
in fact we've seen was about 200 million
syn sins per second and over 400
megabits per second how many people here
BB toast too many I'm sorry one of the
things that's for me that's hard as you
lead off its the outsourced your
emotional burden when you have an outage
we need to deploy a bog when you do
something wrong like you made a mistake
right you can write you can do a
post-mortem you can figure out what went
wrong
can fix it if a DDoS this action asshole
sitting somewhere else in the world
making your life miserable and that's a
huge difference from like an emotional
burden of having to deal with that
outage because you're trying to fix
something and you change a rule and then
this asshole or group of assholes
discovering changed it and they attack
you again and it's really really quite
tiring when you're dealing with that day
in and day out the other is if it's
actually cached if we can cache a page
on the CDN it doesn't actually matter if
there'd be they'll sing it like if they
want to fetch a page half a million
times a second like go for it
this is coming straight out of like
little free cash you know it's not
actually hard final one is availability
so here's another charge which looks
very much like a DDoS right so it goes
from one of the this is multiple
services but one customer goes from
about 10,000 requests per second to
Peaks close to 60,000 requests per
second in less than 15 minutes well this
actually worsens Prince died right and
this is a new large new sites traffic
and what you see is going from a total
of about 16,000 RPS 240,000 RPS this is
one of things like deed offers are
really hard to alter blocked because
this looks exactly like a DDoS
suddenly there's like millions of new
clients all across the world hitting the
site within a very very short fashion
they cashed everything so their origins
so no increasing traffic like everything
was handled at the edge they never even
noticed and you can't also scale that
right like you don't have enough time to
alter scale up in response for an event
like that and you have no way of
predicting that event right if you do we
do a lot of Super Bowl traffic that you
can also stand you can scale up ahead
for something like this you just can't
and so if you have to compute the page
and deliver it it's a game over if you
can store it in cash and deliver it
instantly
like 140,000 requests per second is
actually not that much we also support
two really cool features one actually
browser support for to stay a while we
validate but also stay in leaf error so
if your origin goes down we keep serving
whatever traffic we have or whatever
content we have so if you have an outage
and see the an has the content no one
should ever notice we have a customer
email us in once and said I took down I
took down our data center in the site is
still working can you explain how that's
like yeah it's because things work like
they should
availability wise also we have you know
we have many ISPs also the answer many
ice piece these are the ones that we use
and we can actively route around
problems to tell you for example right
now is running on like 40 percent
capacity in Sweden or they normally
should so we can stop using them we can
route around them and we also route
between our own Pope's continuously
which path we think is best so if you
can do things at the edge you beat the
speed of life and you can defend against
attacks lead office and other security
attacks as well so that's kind of
fundamentally why I think that if you're
sending an HTTP request over the
Internet and it's not going over CDN
it's not a very valuable HTTP request
like it should be going over a CD and if
it has any value whatsoever so you use
this all the time all of your all your
build systems use just at least you also
use all the sites but we support a lot
of a source projects if you install any
of these packaged libraries that's
actually coming from fastly and if any
of them if you are running an open
source project we are always open to
sponsoring them it's one of the few ways
we feel that we can really easily give
that developer tools whenever you use
github for example you rally all of that
traffic is coming through us
and Garelick is actually a really
interesting use case because for one of
the things they use us for is their
mobile SDK so when a mobile sdk reports
performance metrics back to fat the back
to New Relic it actually goes via fastly
that is not a typical CDN use case at
all right there's no caching involved
all it is and it allows the phone it
allows the client to negotiate a
handshake much closer and then lets them
use very long-running connections to us
from us to them so you don't have to
maintain a huge TLS infrastructure they
also get a nice speed performance so
even if your content isn't cashable
there is something called dynamic site
expiration and it actually does work the
reason it works is this when you open a
new connection you set us in you get a
syn ACK back so let's say you're 100
milliseconds each way from the server
you've now spent 200 milliseconds
opening these P connections you then
send the TLS handshake and you get the
TLS handshake back so that's another 200
milliseconds you don't send your request
and you start getting your response back
so you're up to 600 milliseconds before
you starting getting any data back
assuming the server responds immediately
of course and you're starting from very
very slow TCP connection because you
start with a initial congestion window
of 10 and it will take a while well 200
milliseconds for / round-trip for it to
start
opening up so you can actually deliver
bandwidth at a high speed so what if you
have a CDN like this content is not
cashable like there's no way we can
store it that entire sequence happens to
a CDN though that's let's say 20
milliseconds away and then the CDN for
words request back to origin but that is
already a pre-existing connection that's
usually already very open so you get a
total transaction time of 300 20
milliseconds until you get the first
bite back and you will typically get it
back at a much higher rate
just the actual negotiation for the
congestion window based on round trip
actually only happens between the client
and the CDM node which is only 20
milliseconds apart so the window the
bandwidth throughput will go up much
much faster
all right so even if there's no casual
content you will see a significant
performance improvement just by sending
the traffic through a CDM for a reverse
proxy close to the user and you can go
in Austin Texas and look at their DSA
numbers they actually show the
difference between a going directly to
origin and going through a CDM and so
Brazil Brazil to to the US the
difference is roughly like 600
milliseconds between having to go
directly and going for the senior hello
content though is actually cacheable
right so when I started fastly I was a
week here and if you think of a wiki
page
they don't actually change very often
all right so we have like 200 million
wiki pages we get an X number of edits
per day once the topic isn't active
anymore it usually doesn't get an edit
and fully becomes active so going back
to origin and re rendering each of those
pages doesn't make sense capturing them
close to the user is problematic if you
risk having stale data because if a user
hits edit saves and it doesn't reflect
that they get really upset right if you
think of an e-commerce solution like
inventory data and price data seems like
it can change you know can't be
cacheable but that's only if you can't
actually validate it right like it's
actually cashable because it only
changes when a trigger forces a change
that's true for a lot of pieces of
content out there especially when we're
seeing the trend right instead people
are rewriting their apps to be API
driven both progressive web apps from
yourself from their mobile apps
and they're splitting up the private and
personal API calls and so the personal
ad I quote the sorry the public API
calls versus private lunch the public
ones become very easy to cash so we have
some pretty awesome features to help you
of this it's all about real time right
because if you want to be able to use
the CDN for that kind of content you
have to trust it to actually allow you
to deal with that content so to actually
invalidate if anyone's ever dealt with
the horrible thing that AWS cloud fronts
invalidation is this is how easy it is
to validate on tastic right all you
sound is a purge the purge a CP verb to
Fastlane and then typically you will
have a hackle or api key and the content
is gone it's 150 milliseconds to get rid
all around the world which is basically
network latency one way for the messages
to distribute and once you have that
there's so much more you can cache right
like when you thought you couldn't have
because you now have the same control on
your internal on your external cache
that your internal right global support
circuit key tag purging so you can tag
is to be responsible so if you're making
a collection with lots of objects just
tag all the object IDs that went into
that collection you send one purge and
every single object matching that ID is
gone so imager is one of our customers
they tagged every image uploaded with
the user that uploaded it and then if a
user wants to delete there are five
million images they sent one cache
invalidation with that ID and all those
images are gone so it outsourced the
cache dependency to us basically we have
instant configuration takes about five
seconds to deploy config if you have
used varnish it's it's actually based on
barn if you have access to be CL when
you move your traffic to the edge you
also want to know what's going on so
your CDN should have and we do have
instant log files the one one of the
things I learned is not keeping log
files this extreme
be powerful because it means that when
the government comes and asks for them
you can say I don't have them right it's
the only acceptable way of not giving
them to them is saying sorry we don't
have them and since it's not our log
files we don't actually store any log
files but we do provide a way for
customers to stream them off our servers
as fast as possible and so we have you
know you can feed it into your analytics
engine that then detects bad actors and
then uses the API to block edge traffic
at the edge you know in a 15-second loop
it's really powerful and we also provide
real-time stats so you can kind of see
an example here this is actually the
Miss latency that we see to origin this
was a bad conference actually bad code
push from one of our customers that has
sent us this so you can immediately see
that their response rates response times
started to go bad so it's basically a
programmatic edge right can't replace
this your firewall your load balancer
and really gives you a tremendous amount
of power to work around problems to
diagnose problems and to accelerate
things from the edge so for example like
plenty of customers who use us to low
balance between different cloud
providers or they will do like they're
migrating from one you'll do like a
request to s3 if the object isn't there
they will retry it either
it's a very very common use case so
thinking like trying to think about how
you do do
architectural ii-if you had that kind of
power at the edge so I was at a customer
a while ago and they actually a couple
weeks ago and they they demoed this
really cool thing to me so they're
currently migrating to a new
architecture they want to be able to
have services all around the world there
are a global newspaper with local
editions and the way they do it is this
client comes to fastly fastly goes
through a vent acacia service which
because they pay wolf definition
server's response to us they annotate
the request with headers and they
restart the request and they for
segmentation service which does the a/b
testing and all old aspects to run
tracking segmentation service then
responds to fastly and we get the
response they annotated even more and
then the restart and actually go to the
service of the user requested and that's
certainly have services on on Google
they have services on AWS they have some
in your own data centers there's some
third-party services and then the
response goes back to fastly and back to
the client now it's really cool with
this architecture from my point of view
this is to one the requests from the
authentication service and segmentation
servers are cashable too they don't
actually allow their services to talk to
each other except via the front and bus
so because they want to be able to move
them between different providers and not
have dependencies between them so the
API service literally relies only on
headers that are signed given out by the
other services to actually know what to
do for this user
the other cool thing is because this is
cached these two of negation service and
segmentation service responses are cache
the next time the user comes you don't
even go to need to go to their services
like you just go directly to the service
you want and if that service is capable
as well which it would be if it was a
news article you don't actually have to
go back to origin all right so you can
really build pretty complicated and
really really fast systems now you say
well I want to revoke user access well
you just send a surrogate key purge for
the user next time it comes through it
will say I don't know who this is you'll
ask the authentication server the
vindication server returns to denied and
the request is denied and then you can
cache that and so you've now offloaded
your your internal services tremendously
and given the user a significantly
better experience running a CDN is
pretty interesting it it's easy from a
conceptual level if you look at
thousands of distributed systems we hit
all of them really bad right network is
not the Internet is not
it's actually pretty terrible
latency is really bad bandwidth is not
infinite Netflix launched in New Zealand
a little while ago and immediately all
bangla newzealand disappeared then you
were getting like two kilobytes per
second the network is definitely not
secure and there's many many
administrators so that's what we deal
with right and there's very little
off-the-shelf software that works most
of the distribution system software out
there assumes a couple of servers a
couple of data centers are fairly close
by to each other and that you have
reliable links between as I said earlier
our service are pretty powerful so we
also want to be able to scale up as far
as wide but the core tech we use this
all open source right reciate HD proxy
h2o it sure is pretty new it's written
by a guy in Japan it's extremely fast
they should be one and a cheapy to
server and its really really good code
I'm really excited about it
varnish bird not and based on Ubuntu and
most of the code on the forwarding plane
data playing this see most of the
control code is Ruby go and most of the
API from side is room networking so I
absolutely hate every single piece of
custom-built Hardware I've ever used
right so I think f5 should die I think
Cisco should stop making and I
think all firewalls are useless
basically because they're the first
thing that die in an attack because
they're so constrained so what we did is
we bought switches to run Linux so if
you ever dealt with a switch you know
they're pretty horrible from operating
some fun of you when I risk that you
little tight bash and you have a bash
bash it and they need you yum install
and you have like a package installed on
it so we wrote our own code to run the
risk us to do what traditional these big
iron hardware's
do and then we've done a lot of work on
coordination technologies we gave a talk
a while ago and published some papers on
by my little multicast which is how all
the pops talk to each other so it's a
combination of a broadcasting
multicast and a gossip protocol for
recovery that works around all
split-brain situations and that's what
it we also rely heavily on the CDN for
our own configuration pushes our own
deployments at our own management and
then we do use the cloud ease Google and
AWS for everything that's not actually
forwarding HTTP requests so if you want
to you can just build your own it's
pretty easy
this little varnish and a bunch of AWS
machines and then use throughout duty
free to send traffic to your closest
user ideally we should do a better job
then you shouldn't have to worry about
it but you should use something for you
HTTP requests
thank you
so we have a few questions so question
one how do you deal with HTTP painfully
we use so we use a cheap proxy we have
lots of certificates we have lots of
private keys and we have automated
systems for deploying them and then but
I don't know but the real meat of the
question is done well I guess since the
entire world is moving to HTTPS this
must be a real hurdle for you guys right
it is a real hurdle for handling though
there are things we have done to make it
much better and there's been quite a lot
of articles by other people about it so
for example one thing we do is we do a
keepalive to the browser for 10 minutes
so and browsers will actually keep
connections open to a web server for 5
minutes even after you start surfing
away from the site and like that cut the
handshakes by like 35% I think so we've
done a lot of work around that but it so
the problems you see are mainly around
speed this is about it's about handshake
and it's about CPU usage and it's about
how it behaves on the packet loss okay
what do you think about the recent
developments in peer-to-peer assyrians
I am I don't actually know
I haven't spent much time looking at it
ok so good so you made it quite clear
that invalidating caches it's quite easy
but it's not also known to be one of the
two hardest things in computer science
right naming things and cache
invalidation yep
do you have a lot of problems with
customers needing support for that kind
of thing we do I think one of the more
fun ones was a large newspaper kept
telling us that our purge was broken and
it took like two months of this
intermittent problem until they
basically apologized and bottle of beer
because they were sending the cache
invalidation before they committed to
change to database and we came back so
fast that we got the old version right
and so that happens fairly often and
people are like invalidating things they
don't know
so on but yeah it's a hard problem okay
thank you thank you thanks everyone
sigh car</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>