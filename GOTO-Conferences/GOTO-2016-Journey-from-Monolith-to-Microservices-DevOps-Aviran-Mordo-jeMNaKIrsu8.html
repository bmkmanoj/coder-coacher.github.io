<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2016 • Journey from Monolith to Microservices &amp; DevOps • Aviran Mordo | Coder Coacher - Coaching Coders</title><meta content="GOTO 2016 • Journey from Monolith to Microservices &amp; DevOps • Aviran Mordo - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2016 • Journey from Monolith to Microservices &amp; DevOps • Aviran Mordo</b></h2><h5 class="post__date">2016-11-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jeMNaKIrsu8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone thank you for joining me
um I know all of you heard about micro
services but who is actually doing micro
services whew so if you're here to
listen about cool new technologies and
cool new infrastructures about how to do
micro services you're in the wrong room
this talk is basically a very practical
talk about how to move from Manali to
micro services so the next time you'll
be in the conference you can say I'm
going I'm doing that too and you will
see that if you're doing it the right
way and very carefully and cautiously
it's not that hard to do so my name is
avi Ron and I'm head of engineering
tweeks a little bit about weeks for
those of you who didn't hear about
wix.com and what we're doing Wix is a
website building platform we basically
allow people without any technical
knowledge to build beautiful website we
just drag and ROPS
we take care of everything from hosting
to designing to whatever they need in
order to manage their website a little
bit numbers we currently have over 86
million users those are the website
builders around the world we host over 2
petabytes of data we run in three data
centers and the two major clouds we
handle two billion HTTP requests per day
and currently we are 1200 people that
work at Wix but you're not here to hear
about this number right
you actually hear about this number so
Wix is platform currently running about
200 or over 200 make micro services in
production
and when you hear about microservices
you hear a lot of buzzwords you hear
about circuit breakers and distributed
transaction and service discovery and
service boundary and all those buzzwords
that are actually confusing and kind of
scary to begin with if you don't really
know how to do all those things right so
let me take you about the journey the
journey that weeks was doing and how we
got to run 200 micro services in
production so it all started about six
years ago six years ago Wix was running
in a monolith so we had one server that
basically did everything from user
registration to editing sites to
publishing sites to viewing - basically
everything that you can think of except
from coffee and when you're running any
model if you're running into problems
eventually when you get to scale we have
dependencies between features if you
have bugging in one area of the system
it would bring down the entire system
and that was an issue and in order to
resolve that issue in order to resolve
the dependencies allow us as a company
to progress faster we had to figure out
okay what are we going to do and it was
time to start breaking the system but
it's not that easy to break the system
in order to break the system apart you
first need to understand how how is your
system is built what does it consist of
okay what are your concerns so when we
looked at our system we try to split it
by concerns and SLA so when you look at
at at weeks we have we can see two major
activities that are going on okay one
activity is editing websites where you
have
of many feature requests so most of our
features most of our development work
are done in the editor part where we're
adding more features and more capability
to those websites and of course in terms
of database part and it is write
intensive we always update your site and
the other side of the equation is
actually viewing those sites so in
viewing site so we have different
concerns it has to be high throughput
highly scalable in terms of database
it's really read intensive instead of
write intensive and it really has to
perform well so this is how we started
so we have our monolith and since we
identify those two parts at first what
we decided to do is create another
monolith
so we took the monolith and braid broke
it into actually two monoliths one was
responsible for the editing side and we
just extracted everything that we
thought is going to be part of the
viewing the viewing part freaks and we
did another thing by splitting it into
two we also put a clear boundary between
those two we wanted no runtime no
deployment and no data dependencies
between those two services this actually
allowed us to separate the product
lifecycle we decouple the architecture
we had independent deployments and on
the editor part keep things kept
changing because those are the most
feature requests and what this allowed
us is to have the viewer part which is
basically our most important part of our
system because we want our websites to
be always up and running
to be relatively stable another thing
that we gained in in just those two
Bernoulli's so it's not a lot of
micro-services it's too modest
another thing that that we gained is we
gained separation by service level so
now we can scale independently and we
have the viewer part which gets massive
amount of traffic think about those 86
million users that are building their
websites and this is on the editor side
and on the public side it's their
visitors okay so it's hundreds and
hundreds of millions of visitors to
those sites
so just by separating into two we can
now scale the public side differently
than we do in the editor side we can
have a lot more instances we can now use
different data stores we can use MongoDB
in one week is use my sequel in the
other Cassandra you can use whatever you
want to be the right tool for the job
we're no longer coupled in our data
store it also allowed us to optimize
pair for use case we can optimize the
data for read on one side and optimize
the data for write on on the other side
we current different data centers we
actually run in different data centers
so for the editor running two data
centers and the public runs in three
data centers to overrun and one in
Amazon and now we're also shifting to
Google so we can scale up the system
parts of the system as we need to we
also gain system resiliency if we have a
bug and the system goes down let's say
most of the features are in the editor
if you edit or has bug and god forbid
the system is down it's not the whole
system it's just part of the system that
is going down
and if only part of the system is going
down
you have faster recovery time because
you don't have to bring everything up
you just bring one part of the system
back up
so just by splitting in it two two and
two monolith we learned a lot and we'll
go over the things that that you learn
by just splitting in it to two monolith
no micro-services whatsoever does two
monoliths are microservices is basically
 word okay just excuse me that
I'm saying that it's service oriented
architecture done right and it doesn't
matter if it's two monolith or a 200
microservices it's simple fact of
decoupling your architecture and and
make it work as soft as as so I actually
wasn't ready to work okay so the first
thing that that we did is basically
understood our service boundary we split
into two unrelated areas of the system
and one of the best thing that you can
do in order to to help you do the
separation and help you understand the
service boundary is to separate the
databases okay no two services share
database and you can ask okay but I'm
editing something and I want to view it
on the other side so what do I need to
do and you actually copy the data so
during an in our use case when a user
click publish what we do is we take data
from the editor and actually copy
whatever we need not everything but
whenever we need and optimize it to be
read on the public side
now once you did that you need to
consider okay but how do I copy data you
need to think about serialization how do
i serialize the data so now you come to
to research okay so what should you use
it should you use binary should you use
JSON XML text is it over HTTP you have
all those considerations and all those
decisions that you need to make what's
the protocol what are your trade-offs
okay when you choose one over the other
what is more more important to you is it
readability is it performance how do you
bug it what are the tools that you have
that you know that you can find okay how
do you monitor it what are the
dependencies that you introduce into
your build and into your deployment
system because you choose one format
over the other and now that you you're
calling services you need to think about
API versioning the API the transport
protocol how do you expose the API via
rest the RPC via soap god forbid so we
took all those options we actually
started in a binary format we use our
peas and we found that it was really
hard to debug and for our use cases
while a binary format is faster it
didn't really make any difference for us
for our use case so we decided to get
rid of the binary format and move to
JSON to JSON RPC over HTTP which you
know Jackson is a very fast parser you
can use it you can use tools it's
actually text-based you can read it you
can debug it you can log it very very
easily
and this is for our internal
communication from the outside when we
expose API to the Internet then we use
rest it's easier for for developers to
use rest but for internal we actually
have we're using a JSON over RPC because
it's typed it's easier to test now the
next thing that you have okay so you
have an API so how do you do API
versioning
you need to think about API schemas
version 1 version 2 and remember we only
have two services so here I want to
introduce yakhni for those of you don't
know what yeah guinea is it you ain't
gonna need it
not at first okay what you do use is
backward compatibility don't bother
yourself with all those things you keep
planning ahead when you have like
hundreds of micro services and hundreds
of endpoints and an external client when
you start you don't have that ok it's
easier to keep backward compatibility
and and all the developers are in-house
and don't have to maintain is you don't
have the over the overhead of
maintaining of maintaining versioning
same girls to asynchronously calls now
that you have two different services
should you introduce Kafka shouldn't
reduce RabbitMQ active in queue whatever
in queue now think about it when you had
one manually did you have those
messaging systems if you do keep using
whatever you had but if you didn't don't
introduce anything else and you ain't
gonna need it use thread if you use
threads before you can still use threads
every time that you introduce another
middleware to your system you're
introducing DevOps overhead remember
you're running on a production system
and the most important thing on
production system is to keep it working
every time you introduce another thing
into your production system you're
introducing DevOps overhead if you
didn't use messaging before don't use it
now because you have just two services
when you will have a lot and your system
evolves and you need it only then
introduce new technology don't introduce
new technology just because you heard I
don't know me or Netflix or Google
that's a hey we got this cool queueing
system or whatever what about service
discovery now we have zookeeper teaches
from console if you see the Eureka all
those things that you need to choose
from right because you now have two
services and you need to discover them
you ain't gonna need it load balancers
and DNS entry is perfectly fine solution
you know eight weeks we running 200
micro services and we still don't have
that right now when we run it at the 200
we started thinking about service
discovery because we have 200 but until
then
DNS is perfectly fine don't it reduce
more overhead
resilience resilience is very important
okay because now you're getting into the
world of distributed systems and when
when you see this diagram this is a
distributed system okay see this arrow
what does it mean means very important
thing it means that you now have a
failure point you're no longer calling a
function on your monolith if the server
is running the function will get called
okay now when you call something else it
may fail you're introducing Network so
every network hub that you introduce by
definition reduces your availability and
there are ways to overcome it but it
reduces your availability the function
call that you just made may not be
executed so how do you overcome it
different patterns that you need to
understand and know how to how to use
correctly okay so you got your retry
policy but you are cure-all only have
retries on idle intent operations you
don't want to charge people twice now we
have circuit breakers and throttle errs
still those have to be very fine-tuned
you may cause your own downtime if you
break the this circuit break soon too
soon you will cause your undone downtime
okay if you circuit break when you only
have one server it's up to you right so
those are the patterns that that you
need to be experienced with that you
need to understand and you will find you
will fail definitely will
we fight until we little by little and
they stood and tweak it and understand
how that works for our system but the
fact that you have this failure point
can actually be a good thing
a good thing for for your customer
experience because now if the service
fails instead of a complete down time
you can have a degradation of service
right so if the editor is down in our
case sites can still be viewed it's not
that everything is down or nothing so
you can have like we call it a killer
feature which is a kill switch for
features so we can bring down gracefully
subsystems ok this currently does not
work come back later and you will be
able to edit your site but you can still
view it ok you can use fallbacks and
self-healing mechanism you can start
using eventual consistency for instance
we'll give you an example for a fallback
for data so when you publish a site
you're in weeks your URL consists of
your user name the tweaks dot-com slash
whatever your site name and the user
name is being taken from the user server
ok what is the latest user name because
you can rename now in a case that the
user server is down we have a failure
you don't we don't have to fail the
transaction we actually have the user
name already stored in your session
cookie so we can have a fallback just
take it from there need to think about
all the fault bags if if you really care
about availability you will need to
think about those fault box that you can
that you can that you can take if you
want to upload stuff to a different
service and it doesn't really work right
now you can sell fill it later
testing it's important right let's
impart it to test so so now you're
testing a distributed system okay it's
not just just unit testing so this is
the way we do testing I mean everybody
can have their own flavor of how they
test so the way that we run our test is
we first run the unit test on the
service itself the next thing that we do
is we run we call it an integration test
we actually also test the serialization
we put like fake servers or are simply
caters we don't mock the service we just
put a fake service so we can actually
test the serialization next thing is we
do a server end to end when we actually
run the whole service and it all it's
real relationships dependencies the
first layer of dependencies and at the
end we run the automation test which is
from the browser throughout the system
and this runs like nightly how about
logging
you have a distributed system right you
need a distributed logging not really
you only have to write two services if
you didn't have like log stash before or
whatever distributed longer before you
don't have to use it right now we're to
explain in any case we don't really like
logging it's really make it hard for
developer to actually look at the logs
beside show me one developer that I can
actually write a good log and you can
actually find this information it didn't
just copy like a log config from the
internet and stick it in right now
right logging what we prefer is actually
expose all the information to our
developers so this is part of our micro
services framework every micro services
exposes all the it metrics in a nice web
interface
the developers doesn't need to go and
SSH the machine can go to a web
interface and see all the metrics we see
the recent log entries can see
everything there remember is just - it
also works with the hundred only only
after we had like a hundred micro
services only then we started to put
like - really distributed logging system
scales perfectly good
now ownership is a key factor if you
want to do distributed systems if you
want to work with micro services and a
lot of them ownership is key here okay
you cannot scale your ops team is the
number of micro services that you have
so micro service is owned by a team it
doesn't it's not owned by a person it's
not a code that you can put and forget
and if a person leaves it has no owner
the team owns the micro services and if
you build it then you are the one that
is running it you're the one that that
is monitoring your drone that's
responsible for it if a person leaves
the team two things can happen if a
person owns a micro service she can take
the micro service with her to the new
team and maintain it with the new team
or the micro service changes ownership
inside a team so other people in the
team are now owner of the micro service
one one good things that that we do in
order to ensure that every micro service
has an owner is we do continuous
delivery and every micro service has to
be deployed to production at least once
a month so every month we get an alert
if something was not deployed to
production with the latest revision of
the frameworks and everything so you can
only be stale one month back this
ensures that nothing is get left behind
and that brings us to the most
interesting questions about
microservices that I have yet to find an
answer for and I will answer it for you
what is the right size of a
micro-service kinda stupid question if
you ask me because we now have two
monolith so what is the right size those
you can call them micro-services it
doesn't really matter so here comes
Conway
yeah Conway's law says ok the
architecture is determined by the by
organizational structure so if you have
a lot of people you will get that
working on the same project you will get
a monolith so the size of micro-service
is the size of the team that is building
it this is one reason why we build small
teams and we build small tastes by
building small rooms where our offices
are kind of small between four to seven
people and that's it if the team needs
to grow they need to go to a different
room and that's basically a new team and
they will create their own micro
services so what have you learned so far
with just two monolith we learn about
service discovery we learn about how to
monitor those okay we got experience we
chose this realization they ain't
synchronous the SLA of the service how
do we define the API is the deployment
strategies
okay the darris data separation is there
how to test it to keep compatibility
compatibility is really hard I mean most
of the time when you fail you fellas are
because someone didn't keep backward
compatibility most of the time see so
just by extracting two monoliths and
treat that as a micro services
architecture you'll learn a lot
and you make great progression if you
don't do all the overheads of all the
things that you don't really need to do
not not at first anyway so now that we
know all those things we can continue to
extract more and more micro services and
the things that we did is we actually
kept the the idea of the separation by
SLA so every micro service that that we
built the first question that we ask our
developers is which segment it belongs
to does it belong to the editor segment
or the public segment is it more read
intensive or write intensive this is how
our system it's a partial view of course
it can put like 210 year so this is how
Wix is micro services looks like okay so
some of the micro services are in the
editor segment some of the micro
services are in the public segment and
this helped developers understand and
think about what are my requirements for
from this service okay is it mostly
right what is the scalability and
availability concerns that I have do I
want to run it in two datacenters or at
least two data centers okay what is my
uptime is it ninety nine point nine or
ninety-nine point nine nine so it it
really defines your requirements from
that service and and one thing that if
you think okay I actually need both of
them this is a really good indication
maybe you should split it into two micro
services and not just build one monolith
or a bigger micro service
so what is the time to extract them new
micro-services so let's think let's
think about that you need to add a new
functionality okay so you can do it as a
micro service or a library let's take an
example let's say I need a time zone
we'll call it a service for now that
takes the IP of the request goes to max
mine database figures out what the time
zone and propagate that information to
the service that it needed so we can go
either way we can build a library or we
can build a micro service that will give
us this information and there's a series
of questions that we need to ask
ourselves by introducing this thing do I
create a deployment dependency if I
change it do I have a DevOps overhead it
needs database who maintains this
database who owns this code does it fit
the scalability concerns that I have for
this service can a different team
develop it you need to ask yourself all
those questions and a simple rule of
thumb is is micro service has ops
library is mostly computational okay so
in in this case where we want a time
zone from an IP it needs to go to a
database if the database is usually
local and I don't want to style this to
install this database on every other
service that I have so in this case it
will be a micro service I don't want to
create this dependency I don't want to
create this DevOps overhead that now
every micro service owner that will need
this library will have to maintain an ad
database so it's
micro-service that that the team is
responsible for and maintaining it and
everybody else just consume it as a
service now when we're talking about
micro services one of the things that
you can do is you got the freedom to
choose many stocks so you can have
different messaging cues you can have
different databases one can use
Cassandra one can use my sequel one can
use Couchbase one can use Mongo any
microt service owner can use whatever
they need or whatever they want which is
worse for their own micro services well
this is true I had highly not recommend
doing it okay you should limit your
stock okay
default did the stack that you know and
the reason for that is again it's DevOps
if everything will have their own
middleware only that team will know how
to manage it and how to operate that in
production if most of the teams share
the same standard or the same middleware
they can share knowledge they can they
can come to a solution to a resolution
on the production crisis and downtime
very very fast because they can share
their knowledge if someone is doing
something that nobody else knows it's a
very small team that can actually manage
the crisis
but it doesn't prevent you from from
innovate from innovation you can
innovate on a non-critical
micro-services if you have something new
that you build and and it's it's a new
micro service and you think that hey my
current stack is it's not the right tool
for the job it's perfectly fine to
innovate start a new micro service try
it out see how it works the rest of the
system is stable if that works wait
until one or two other teams will start
using your new technology or new stack
and then make it a standard that
everybody can actually use it share the
knowledge spread the knowledge don't
keep it contained within within one team
what about programming language you can
write micro services in any language
right in Scala and PHP in node whatever
but should you again you probably want
to limit your stack here too okay
because if you write in multiple
languages then you have to you cannot do
a code reuse
you have cross-cutting concerns that
have to be addressed by any micro
services security session validations
auditing logging testing the same the
same infrastructure that it takes to run
an operator production system has to be
re-implemented throughout all the stacks
if you want to change your encryption
algorithm now you have to wait until
every micro service that is written in a
different language will have to
implement it before you can roll it out
which make things really really really
take a long time and we want to progress
fast so try to limit your stack to the
bare minimum if it's they're not really
not the right tool for the job you have
no choice but to implement it but really
be careful with it don't don't
overboard and having every microservices
being written in a different language so
remember keep it simple DevOps is really
really important and when you're grown
you have a lot of micro-services it
becomes a bigger and bigger and bigger
overhead you will spend more time in in
managing production the more micro
services that you have so let's recap
what did we learn now we continue to
learn about disability transactions and
system monitoring and distributed traces
how do you trace one call that goes
through five micro services how do you
know how that goes what micro service
what server answered the call you need
to know this thing and understand it the
trade offs of new micro services
extending an existing micro service or
creating a new one for adding new
functionalities
what is your deployment strategy now you
have a feature that is dependent on on
two or three micro services to be
implemented you will have to learn all
this as you go how do you handle
cascading failures when one server
starts answering slowly you don't want
it to bring down the whole chain of
micro services that are calling it you
will need to know and learn how to how
to manage those things it's easier to
now build new teams and split new teams
ok because now each team can have a
small subset of responsibilities but
the big question is why why would you
ever want to do this to yourself why do
you want to go to micro-services it's
not because you're here and I'm speaking
about it and Netflix speaking about it
and Google speaking about it that's not
the reason to go to microservices okay
micro-services comes to solve a problem
okay if you don't have any problems
stick with whatever you have the first
problem that it solves is engineering
scale if you have a lot of Engineers
that are working in a monolith people
will step on each other's toes if you
want to go fast it's better to have them
split into small teams that each have
their own responsibility its development
velocity if you have small teams they
can progress much faster then they have
to share the same codebase and deploy
and wait for one another
hey I'm finished with this feature but
hey but we need to deploy together so we
need to wait until this team and it QA
if you split it into small chunks your
development velocity will be much higher
and the third reason is scaling now when
you're going to micro services you can
now scale different parts to different
scalability as relays if you don't have
any of those issues stick with whatever
you have don't go into micro service ism
now microservices is the first post
DevOps architecture the culture is
really really important
if you don't have a DevOps culture don't
even attempt to go there it's a huge
important in ownership and and the right
set of mind to maintain this kind of
distributed system and remember every
micro service is eventually a DevOps
overhead when you add something you need
someone to maintain it it's not a
throwaway code it's a live production
subsystem that is playing along with
everybody else so it's all about
trade-offs and remember we think if you
need if you're adding something think
really carefully if you need it if you
don't need it don't use it don't use it
because you heard about it somewhere if
you have a problem solve it with
technology ok don't just introduce new
technology to your to your stack just
because it's cool or you think that
you're gonna need it
down the road wait until you actually
have a problem so this is a basically
small set of guidelines that we put to
our developers in how to to create and
one of the trade-offs between when
creating new microservice the most
important thing that every micro service
has its own database no two micro
services are allowed to write to the
same database it creates coupling if you
have a performance consideration it's
okay to have a read-only micro services
that share database but then the
trade-off is coupling if you need to
change something in the schema now you
have to take care of two micro services
or three in order to manage your
deployment right okay
and remember if you have a problem in
Manali micro-services will not solve
your problem to just split it into many
other problems and I think I'm done
thank you
the slides are there if you want to
download it so we have time for
questions
excellent yes thank you very much first
again a quick reminder please before you
leave the room make sure to vote through
the application we didn't receive no
questions first one even if you only
have like two services but you don't
have service discovery how would you
handle failover to a second instance in
case one fails that logic you need to
put in your load balancer so when you're
running in a cluster if a service
failure load balancer actually knows
it's part of the logic of a load
balancer it knows which instances failed
so that logic is in the load balancer so
you really don't need to worry about it
it's being taken care of another
interesting question when you break down
your system into multiple services do
they don't have their own UI or is the
UI itself services how is that set up
well it depends what we like to do is to
have every subsystem have have its own
UI so it's a that you either talk stur
to its own set of micro services it
really depends on on your business
business use case but we like to split
the UI also yeah we have a number of
questions I think some of them have been
answered in your presentation but
overall speaking what was your biggest
challenge when implementing micro
services and looking back on now being
on 150 micro services what would you
have done differently knowing what you
know now this presentation is based on
the lesson learned I mean when we
started we actually thought of doing
like client-side load balancing and
started implementing it and in doing
circuit breakers which we ended up not
using because we didn't know how to use
it so we thought that we're gonna need a
lot of the things but we actually figure
that we just wasted a lot of time
building those
things that we didn't use and even when
we got to use them we thought okay we
started using those tools like after a
while after we had like 50 or 100
microservices and the thing that we
thought that we're gonna that they're
gonna solve for us when we started it
wasn't the same problem so we actually
didn't use the right solution to the
problem that we actually encounter after
doing it in real life
okay a question in more general nature
how do you deal with security do you
have things like single sign-on set up
yes so we have actually have two
mechanisms one is for our own internal
sign-on and and we have auth which does
a single sign-on we basically pass
tokens between services they're all
signed so they can verify that the
signature is it's correct
another question how do you insure
database replication between services if
they don't actually share a single
database so each database is independent
so we have one database for micro
service it's been replicated you have
another database it's being replicated
we can share database machines you just
don't share the same schemas between
microservices so it's usually we have
one database with many schemas each
microservice has its own schema so we
don't it reduce any coupling between the
data and the code but we replicate
databases per schema again finally about
versioning if the number of consumers
for a particular service is increasing
can you still get away with just doing
backwards compatibility or do you have a
form of versioning in place no we don't
have a form of versioning place not
internally anyway externally yes because
it's harder to make people move you're
not in control but inside our
organization we still do backward
compatibility if we need to do a
breaking change then we just introduce a
new API
and we tell everybody okay now you need
to move to this new API and you have one
to three months to do it and after that
we just kill it and whoever is not moved
and he's gonna break
of course we gave them ingress period
it's not that we're gonna break him but
we break them for like five minutes okay
now you have one week to implement it
and then we can really gonna break you
any questions from from the room people
like to ask down okay then I think we're
done so thank you very much and thank
you please give them another round of
applause</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>