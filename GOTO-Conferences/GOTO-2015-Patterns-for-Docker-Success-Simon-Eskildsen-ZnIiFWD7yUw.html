<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Patterns for Docker Success • Simon Eskildsen | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Patterns for Docker Success • Simon Eskildsen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Patterns for Docker Success • Simon Eskildsen</b></h2><h5 class="post__date">2015-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZnIiFWD7yUw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so my name is Simon I work for
Shopify and today I'm going to be
talking about docker and I think I'm
gonna start by talking about what this
talk is not about this is not a talk
trying to brainwash you into using
docker it's not a talk about how great
docker is but rather a talk about all
the challenges that it brings with you
once you recognize some of the valuable
things that containers can can bring to
you to your organization also be using
docker and containers kind of
interchangeably docker has become sort
of the Kleenex of containers and so this
is really a talk about a deployment
story that we had where we spend about
six months getting darker into
production and we've been operating it
in production for about a year now and
sort of the lessons we've learned all
the mistakes that we made putting it
into production and some of the advice
that I can give based on what we have
learned so just just a little bit about
Shopify first I think this is important
just to keep in the back of our head the
scale that we're at because if you're
larger than Oz you're gonna run into
more problems than we were in into and
if you're smaller than us you're gonna
run into fewer problems Shopify is a
commerce platform we if you're doing if
you want to do any kind of commerce we
try to be your guy we kind of provide a
CMS for online stores we also do kind of
a point-of-sale solution and Facebook
and multiple other other channels we
were able to run about 10,000 RPS and
10,000 orders per minute and we have
about 300 million visitors per month
which really puts us up there aggregated
which some of the some of the bigger
bigger players like eBay and Apple and
and so on we're running about 4,000
containers across two data centers
we're in co-located data centers and
running on our own bare metal hardware
so we started looking at docker and all
of these these things that docker
enables about two years ago now and
really we were set down about three
three people with three to four people
with the goal of trying to make Shopify
a more enjoyable place
to solve commerce problems really we
wanted to be the best place in the world
to solve commerce problems down the line
so that if you're if you want to do a
commerce product and you work at Shopify
that should be really easy we should
have a platform that really fosters
creativity continuous integration and
just makes the platform concern really
really minimal we wanted to be able to
do things like running CI in less than
five minutes going deploying in less
than five minutes gave our developers
more control one of the really cool
things that that docker provides is an
abstraction where it allows your
developers to own what is inside of the
container and your platform team
everything that revolves around the
container and this gives a really really
clear line in the sand between what your
application developers own and what your
platform team owns and this really gives
your developers more control because
they don't have to care about all the
infrastructure parts they just have to
care about building a container and we
really really like that abstraction that
it provided and the fact that it meant
that our product teams could just
operate as entities that just develop
delivered a container and my team would
take care of distributing that and
scaling that container and another thing
that's that's actually no and kind of an
extension of that one of the one of the
interesting things that happen that
happened in the past ten years or so is
that infrastructure as a service has
become a pretty pretty standard thing
easy to launched quite a few years ago
now and as one of the first providers
really provided infrastructure as a
service you could click a button and you
would have a server that you're now able
to SSH into you could automate this you
could do do things on top of api's and
so on and some people saw that that
abstraction sits at a level like a
little bit too low and they started
building these platforms as a service
and platform social service is really
the other extreme were instead of
providing servers and/or infrastructure
as a service you're trying to provide
services as a service so this is things
like instead of a button and you get a
server you click a button and you have a
my sequel cluster you click a button you
have a memcache cluster I read his
cluster and so on
Hiroko is a great example of that where
you have sort of like an app store where
different vendors can pitch in and get
their infrastructure to run it for your
application and easily connect to it the
problem though is that these are these
are two two extremes one is an extreme
in the low-level direction and the other
in the high-level direction if you want
to do something really large and custom
on something like Heroku in a pass you
have the problem that you can't really
customize too much and when you start
customizing the abstraction starts to
feel wrong and it gets a little awkward
so really were containers and the
patterns that containers allow us to do
is it sits as a really really cool level
just between the infrastructures of
servers and the platform as a service
where again what your developers and
what your company is giving to do to the
companies that are that are operating
your infrastructure or the teams within
your organization that's operating your
infrastructure you give that team your
container and they run it you don't have
to ask someone on your operations team
to install some kind of package for you
because now you need to communicate with
memcache and you need to memcache C
headers and so on to build your library
you don't have to do that anymore you
can just own that and the developers own
that entire container and send it off it
also has great benefits because it means
that the developers can now do that in
development and so on so these are
really the patterns that the container
mythology allows you to do and the rest
of this talk is really about how
difficult that is so we've been running
docker in production for our main
application for about a year now Shopify
is a Ruby on Rails application it's it's
basically one big monolith that we have
our engineers work on and getting to
production with docker was intentionally
challenging there's so many problems out
there that not a lot of people are
talking about because docker is not
seeing a lot of scale currently and many
of these things frankly haven't gotten
much easier but really what we're trying
to do is not make where obviously we're
not trying to make things worse in the
in the short term but what we're really
interested in is building a really
interesting platform going forward we're
trying to enable instead
selves up for success in the future by
embedding the knowledge into the
organization of what are containers and
how can we build this disk as as we move
forward and the way that the community
has approached is is kind of this
adoption adoption Chui ad where darker
darker and not any of the other
containerization technologies like l XE
really managed to appeal to developers
first somehow docker found just the
sweet spot to get developers interested
in this stuff that's much more of a
sysadmin concern when you think about it
containerization technologies have been
around for a really really long time if
you have that one friend who's seen the
light and talks about solaris all the
time they've telling you about how
they've been doing this for decades or
something along those lines in linux
support for containerization and
isolation of processes is really
somewhat recent i think some of the
first pioneering work was done by
companies like Google who are trying to
push past patches into the kernel openvz
is another project that was trying to do
this and really do this at the kernel
level instead of the virtualization
level like vm's and so on
so what docker has really done is they
built a container I station technology
around on top of these Linux primitives
that are now in the kernel and on most
of the kernels that you are running
today and made them accessible and they
marketed it extensively for developers
to start with you to solve the
development and CI challenges that a lot
of companies are having like if you have
if you're running a lot of services at
once and they need to communicate with
each other it's one it's really hard to
deploy it but it's also increasingly
hard to develop with it and test with it
if you want to have if you have two
services a and B and a tox to be how do
you write tests on top of that and how
do you debug issues in to relate when
when these two components are
interacting with each other and that's
one of the I think that's one of the
sweet spots where where developers
really saw the appeal because it enabled
them to write more services and so on
that also that's also not a silver
bullet just like docker
Microsoft's in these kind of
architectures carries a lot of problems
with them as well but a lot of companies
do have smaller smaller services that do
talk to each other to some extent and
Shopify we don't really have that we
have one big application we do have data
stores and a few services that it talks
to here and there but it is essentially
a monolith architecture at this point so
the second step in in the adoption of
docker is really the production step a
lot of companies have started adopting
docker and CI and development
environment but very very few have
gotten to the point where they actually
pushed it into production and even more
scary is the fact that everyone is
obsessing over this idea of having your
internal platform as a service cat cats
or whatever you want to call it and this
is where this is where all the the all
the vendors are going that's what people
people are building but they're really
missing that production step which means
that docker is not getting very much
exposure to production for the reasons
that people are trying to build these
very very complicated stacks that
they're only running very few
applications on and not very many people
are deploying docker in isolation and so
I when people ask me like what how how
people should add up docker and what in
which order that's really the order I
recommend development CI then production
and then kass and that's because we did
it in reverse and failed miserably in
January 2 to June of 2014 we we started
getting serious about building out our
our docker infrastructure and we started
out with this grand vision of we want
this cast we want to build this path so
that all of our developers click buttons
they get their data stores and it's
really easy to employ you just do a
docker push and it's in production we
build sliders and buttons for them and
it's all good and we had a very very
naive thought in retrospect that we
could just go and build that and there
are a lot of companies out there who are
offering solutions to build these things
out of the box but most of it doesn't
work and it didn't really work back then
especially not at our scale where we do
have very very aggressive uptime
requirements we can't just take a
completely new stock and put our
application on it unfortunately that
took us almost half a year to really
realize the good fart was though that we
spend a lot of time also container izing
Shopify and you can't because you can't
just take an application and shove it
into a container there's really a lot of
brick work that's involved in making
that happen and I'll talk a bit more
about that in in a second and then in
July we July June really we we were
starting to getting tired of playing
around with all these orchestration
technologies we couldn't get into work
it was a nightmare to debug and we could
not by any means ship this abstaining
sustainably to production so what we did
was we sat down and decided that we're
going to ship something and that
something is going to be just containers
and we will ship that as the only change
everything else still stays the same
we've been using chef for configuration
management so we're gonna use that to
orchestrate containers not any fancy
distributed orchestration we're going to
keep using run it for monitoring the
containers and restarting them when they
fail and dis stuff and really stick with
all the boring old stuff and this dis
ended up working and well it didn't
really work so we put this into
production in July 14 and the next
couple of couples a couple of months
were pretty miserable and really we
ended up with a stack that was probably
worse than what we had before we spent a
lot of time firefighting different
things we had soft colonel lock ups
because we're running on edgy linux
kernel's the api's are not extremely
stable at this point and the fire is
kind of eased out after a couple of
couple of months and then we started
preparing for the holidays because we
are an e-commerce platform like Black
Friday Cyber Monday huge events for us
so that really drained all our resources
and we didn't really work on features
for a little while so for about half a
year we had a stock that was worse than
what we had before and we leveraged none
of the none of the good things about
docker but only really the bad parts so
in in January May is and and this year
we finally started started really using
our knowledge of docker and our
experience with it
and we cut her the ploy time from about
15 minutes down to 3 minutes we got our
CI to run in 5 minutes instead of 15
minutes and we're continuing now to sort
of harvest all of these longer-term
goals that we had and to leverage docker
with it with the short-term pain of last
year so once again I do not recommend
this approach and I'll talk a bit more
about what I recommend and another
important important distinction I think
is is between Greenfield and and legacy
deployments of docker and there are many
many dimensions of different kinds of
deployment strategies that you can
choose to deploy docker and so
Greenfield is the one that that most of
the industry seems concerned with right
now
when I talk to a lot of larger banks
large very traditional companies with
development firms they kind of have a
development division split into one half
is working on the money-making
applications written in COBOL probably
emulating chips like architecture IBM
architectures from the 70s to run
they're scary scary applications that no
one touches and they don't the other
part of that development division is
sort of the growth department these are
these are developers working on new
products rapid iteration and sort of the
growth developers and what what these
companies are looking looking and going
to docker for is really having a
platform that enables these developers
to to work quickly iterate quickly get
products out quickly and so on the other
approach is is more along the lines of
what we did which is really trying to
evolve your old stack into something new
so really what we're trying to do is
evolve the platform that Shopify is
running it on now into that platform
that we want a long time from now which
is which is a little bit different from
the other approach where you keep
running your old stuff and then you have
your your completely new application so
I think it's important to make that
distinction before you get started of
are we going to do a Greenfield
deployment of docker or or are we going
with an approach trying to move our
existing stock
and of course this is extremely this
depends a lot on what your organization
looks like now if you are running
emulated IBM chipsets from the 70s then
maybe maybe the good legacy approach is
not the way to go but if you are running
a somewhat modern stack this might be a
good way to go the other problem is that
for for at least growing the legacy
approach is that most of the vendors
nowadays are very very focused on the
Greenfield approach it's really fun to
build your own casts and you see people
building their own proxies people are
building like there are more raff to
implementations out there for service
discovery now than I can count
people are doing a lot of different
things and really reimplemented the same
thing over and over again but very very
fused agreed-upon components that
everyone is using and then you have
companies like us who are trying to
evolve a current stack into a docker
eyes one into a containerized stack who
are more focused on evolving a platform
but we can't take any of the components
from these greenfield companies that are
exist now tens if not over a hundred of
we're trying to give you this calves out
of a box and did this this kind of
revolves around a chicken-and-egg
problem because if you're trying to
build a stable cos but nobody can
actually take your stuff to production
at least at a large scale then your your
road to production is going to be really
really long and especially for these
companies so really what I'm hoping that
I will see is more vendors realizing
that that and building components that
you can kind of grow grow into so you
can pick a component use it for some
some amount of a functionality like pick
out a service discovery layer from one
solution and then pick another one of
their components and then slowly evolve
into the stack that you that you want
because that's how that's how you
involve production infrastructure you
can't just take a big completely new
thing and put your old thing on it you
can put new things on it but not old
things so really what all these all
these all these cast providers and
vendors and all the people out there
developing this software have
fortunately agreed on one thing and that
one thing is docker
and really the biggest value to docker
is bringing at this point is probably
that people have finally agreed on one
thing and but everything else just kind
of remains a mystery and people keep
reimplemented the same things so because
of this the production maturity of
docker and the surrounding the
surrounding components really isn't
there yet but for development and for CI
there's there's I think a lot of
benefits to be had currently especially
if you have multiple services that are
communicating with each other and you
run into the scenarios as I described
before where you want to run integration
tests across multiple multiple
applications you want to have your
development teams have pretty
predictable environments where you can
run multiple applications at the same
time without getting into a crazy
dependency hell for example you might
have two services that are running
different versions of Ruby or Python or
whatever and doing that with something
like vagrant is is really difficult it
might require having multiple VMs if you
want complete isolations very very
interesting cookbooks or other strange
strange and really fragile ways of
building this out so I think there and
kind of every team collaborating around
containers and providing sort of a
golden image for their application for
other developers to use and to
communicate with their apps doesn't
really leak the abstraction of the
application because you're still
communicating with the API but actually
provides some real benefit now so try to
look kind of like some of the the first
parts of this talk in in in sort of an
adoption matrix and this is probably a
little bit confusing but what I so out
here we have sort of the different use
cases for for docker preparation which
means kind of preparing your your
application for for docker which I'll
talk about for basically the rest of
this talk then there is using docker in
the development environment and using it
in a CI environment production
environment and
the whole pass platform and then kind of
your architecture here if you're
somewhat of a monolithic app there
really aren't that many benefits to be
to be had from docker five five is best
here but if you are doing multiple
services I think that there are a lot of
things to gain from preparing your stack
for containers and preparing it for to
leverage this technology and especially
in sort of a CI environment it's it's
really great that you can write finally
write integration tests across apps
which is something that is is really an
unknown field currently production and
casts is still somewhat of a question
the production tools just aren't really
there in from from what I've seen it's
definitely getting better and it's a lot
better than from when we went into
production some time ago and you can
notice here that we're somewhat
monolithic so I definitely do not
recommend what we did which is go into
production with docker which somewhat of
a monolithic architecture it's it's
basically a waste of time at this point
I do hope that it that it's getting
better and image the maturity of the
platform evolves enough that even in
that case it does bring a lot of
benefits but at this point the pros just
really do not outweigh the cons for that
kind of infrastructure the last thing
down here which is kind of awkwardly
placed this is the security of
containers and I think the CTO of giant
Brian C made a really good point about
that where in Linux they're really
trying to iterate their their integrate
to security
whereas in things like Solaris again the
people who have seen the light
they architected for security right off
the bat and have achieved world-class
security at this at this point to a
level where it is way way beyond what
Linux has so what they've done is Linux
is they've kind of carried out all the
functionality and now they're trying to
make it secure and that's just not
really how it works that's kind of like
blacklist versus whitelist so that's
that is one of my concerns for for a lot
of private for a lot of people who are
running app casts or a path internally
it doesn't matter too much because as
long as you don't rely on these
primitives but for people who are doing
who are writing cast like Google
and so on who are now providing
container services this is a big deal
because it means that they still have to
run VMs underneath like sin or VMware or
whatever because they can't rely on the
security of the container so really
you're running a VM and then a container
inside of it which is - - isolation
layers and de virtualization performance
nowadays is good but it's still not
amazing and and for some applications is
really rules out this approach still so
the rest of this talk is is basically
about what kind of the roadmap that I
wish that someone had handed us and
explained to us before we went into
production it's somewhat it's somewhat
biased towards a legacy stack and and
and our our stack but I think that
there's a lot of lessons to be learned
here from whatever you're looking at or
even if you're looking at this next year
and again many people start kind of in
Reverse and then go all the way up and
we certainly did which was a big mistake
and we ended up wasting a lot of time
from that and so the first stage here is
it's the exploration stage and that
basically means that you have a bunch of
developers sit down spend some time with
containers that develop a feel for what
kind of power can we harvest from this
and is it really worth our time the next
one is about preparing your application
I'll go into depth with these steps in a
second preparing your application
preparing the patterns within your
organization to to allow for this stuff
and the third one is where you actually
finally start looking at containers
actually using them in development or CI
or in production and then in the fourth
one is the grand vision that everyone is
looking towards is that they can start
building these Casas these buttons and
the levers and so on but don't start
there and don't try to paralyze across
these stages
don't try to be refactoring application
while you're putting it into containers
and take shortcuts so the first stage is
is that it's the exploration stage and
what you're trying to do in the
exploration stage is really get the
knowledge internally of what what would
it take what would it take to put some
of our applications within
containers some very modern applications
are actually pretty much ready to just
be put in a container which is great if
they if they're looking for solutions
like this for CI and development but for
many this will be like a multi month
half if not even a full year for some of
their application to make this
transition and develop all the software
is compatible with whatever they have so
really it's about getting a good
understanding of how containers works
isn't it means understanding Linux
namespaces in depth which is what docker
containers build on top of kind of the
kernel API for isolating processes the
man pages are basically the only
documentation and kind of speaking to
the immaturity of this stuff I had to
dig out a lot of it from like the Linux
kernel manual mailing list where they're
discussing main pages because they
weren't actually into the Linux
distribution yet you should be studying
companies and their use cases and what
they're doing with docker and whether
that's that's something that you're
excited about and fits into what you're
trying to accomplish see groups is the
same thing see groups has been around
for for quite a while to work done by
Google many many years ago to isolate
processes from each other it's also
really under really important to
understand and then really developing a
feel for containers what what's right to
do in a container what's not right you
shouldn't be putting a ton of state in
your container you probably shouldn't be
running chef in your container and you
should probably only be running one or
two processes per container and so on
just kind of get that feel and it's
important to not get stuck or starstruck
and starstruck here really means that
you get obsessed with this vision of
building out a pass or a cast for your
company because that's a much much much
longer project you're taking the very
very first small steps toward this but
you really can't step in the next two
stages to get there and in this stage I
really encourage rapid prototyping like
trying out some of the ideas you have to
figure out if your mental model of
docker really fits what you're actually
able to do get get a feel for the
software out there and it's really
important that when you're done with all
this you throw it all away
don't try to develop anything any of
this into production code just throw it
away and move on to the next stage
so once you once you've explored it and
you've gotten some some level of
confidence and and and knowledge of
docker within your organization it means
that you can start making decisions
based on future architecture on whether
that will fit in a containerized world
again you're trying to set yourself up
for success because containers in the
future are going to be inevitable to
escape how long that will take we don't
quite know but in the preparation stage
you're really trying to evolve some of
your current stock into adopting some of
the patterns that are compatible we're
running in containers and I'll get to a
few examples really the mind said that
you have to adopt and then you got that
you should have hopefully gotten out of
the first stage is that you need to
adapt a mind set of immutable
infrastructure this means being able to
build build something and then not do
any online changes to it but build it
from scratch again or from some kind of
caching infrastructure so you really
need to be thinking of your application
at somewhat of a static binary that
you're shipping around and running and
so some of these some of the very common
things that people have to address to
fix this problem is something like
secrets I'll go into depth with that
just after this slide and then there's
logs a lot of people are using vendors
like Splunk and so on which which don't
work really well with containers out of
the box there's some people who are
using IP doing IPC between processes on
the same node and that really has to be
done via network and not via that be a
like file i/o or sis five shared shared
namespaces and stuff like that really
really you need to be doing all of this
stuff all of the communication with
external things over the network one
example we had was all of our web
traffic went into an engine X on every
node and then sent down to the web
servers over a UNIX domain socket but
with containers that doesn't really work
and which is just one of the many rabbit
holes because it turns out UNIX domain
sockets and TCP sockets act differently
when you when you have like a listen
back lock on the socket so there's an
incredible amount of of rabbit holes to
get into here and real
the important part is just starting to
modernize your stack towards this
towards something that can eventually be
put in containers that might not be this
year but it is an important are in the
effort to do if you do recognize the
value of containers down the line
there's a there's a kind of a paradigm
or a website called twelve factor which
kind of lists out twelve principles of
what a modern application should look
like I think some of them are a little
bit outdated in terms of docker but it's
really a great start to look at some of
these for what you should be doing and
there's a ton of other things like
making your deploys more immutable you
should be able to scale scaling your
application by adding new containers is
a great place to be into before
container izing it but really this
depends a lot on your environment and
this is why you have the first stage so
you can figure out what kind of things
that you need to change to get to the
second one and again it's really just as
much about what it's not in that stage
you're not trying to do containers
you're not trying to change your routing
layer you're not trying to switch to
some cool new Linux distribution which
can only run docker on a read-only file
system you're not trying to do
distributed orchestration or anything
like that you're just trying to evolve
your current thing into something that's
more modern and which is which enables
you to do to run this stuff in the
future so I'm going to just take take
two examples from from Shopify and one
one that we did right and one that we
did very wrong this is the one that we
did somewhat right which is secrets a
lot of people nowadays when they do
secrets for their applications is they
have a configuration management layer
like chef or puppet distributed files to
all the servers with the secrets they
need the application boots retreat's the
secrets which is a very a synchronous
model and if you followed it before what
we're really trying to do is is think of
this as a binary and secrets having as
an asynchronous model with a file on
system just doesn't work very well with
containers because it means you have to
now have like a secrets container with a
file system that's linked into every
other container or somewhere like have
them have a bind mount from the host
into every container where it can see
files and it just gets very very iffy
and complicated and really not something
that I would recommend trying so secrets
should either live in the image or be
requested externally
you're allowed in a container world to
do IPC over the network that's
completely fine and but you could also
just put it in the image obviously you
shouldn't be putting decrypted secrets
inside of your images because you want
to share the same images with your
developers and yours and your C and your
CI and so on down the line which means
that they need to be encrypt that when
they're in the image and decrypt that
when they when they boot up and did
different environments so we built
something for that and it's called a
JSON which is basically encrypted JSON
so you have in every in every repository
you have a dot a JSON file which has all
the secrets laid out in plain JSON uses
a symmetric encryption so all of our
developers have a public key can encrypt
those secrets and it all lives lives
with the with the with the application
so when we build a new container image
the secrets are in there they're
encrypted and when we start the
container we decrypt them with our
custom init process now because of
things like custom init process and
they're being still stayed on the file
system and so on this is not really an
ideal solution I feel that what what the
community needs to move towards is
somewhat of a secret broker and this is
one of the problems that I have been
extremely surprised that a community had
I haven't seen more solutions to in the
community
hashey Corp recently released a really
really interesting new project which is
called the vault and it has it's
basically a secret broker so your
containers can when they start they can
ask this container hey like give me this
secret for example for it could be for
easy to give me a secret for easy to
wear s3 or whatever and it even has the
concept of fleeces so what you can do is
you can request to see a secret and then
after five to ten minutes you have to
refresh your lease this means that
ideally you can actually move towards
secrets where every single container has
its own view its own secrets entirely
and they constantly expire which is any
security person's wet dream and so the
another example is is logging and this
is an example of where we completely
failed and got ahead of ourselves we
we didn't really honor the container
principles where where you shouldn't you
shouldn't put state inside of your
container to lift for an arbitrary
amount of time after the container has
died so we we decided okay we're going
to take a shortcut and we're going to
continue login to files just like we've
done before and then we will have
another container reach into the file
system every other container and then
take the logs and sent them off to our
Splunk server which in retrospect is an
embarrassing way of thinking about it
but that is that's what we did and we
thought that that would be a great
shortcut to do and one of the big
problems here is really that the vendors
haven't caught up we we have Splunk and
for anyone else who uses blanc like it's
paid for and they just haven't caught up
yet they haven't figured out how how to
do docker i yet so we have to build this
stuff ourselves so what we're doing is
out all of our containers are login to
files that we have that container that's
reaching into all of them and this
brings because this violates the
container paradigms so deeply it brings
a lot of issues with it like when a
container stops really the right way to
do it is that when the container stops
it's no longer there you can delete it
straight away docker has a flack for it
where you can do - - RM and then the
container is gone but when you're doing
logging you can't really do that because
what about the last login lines just
these few milliseconds before the
containers stopped you still want these
logged so you've got to keep it around
for some arbitrary amount of times that
you think is enough for your Docherty or
you're logging daemon to pick up the
logs from the files so now you have to
have a sidekick
cross another sidekick container that is
looking at all the other containers and
then deleting these containers off disk
after a minute or five minutes or ten
minutes which is just a complexity that
you definitely don't want this is
getting better and really like most of
the issues that I'm talking about with
docker there's always an upstream issue
and it's usually been discussed for
about a year but development does move a
little bit slow in 1-6 they finally
introduced login drivers and this means
that now with with docker you can you
can write drivers and kind of lock to
where you want
in our case we would love to log
directly to Splunk or directly to Kafka
or something like that the problem
though is that if you want to have your
if you want to have you a custom log and
driver in docker
you basically need to either fork docker
or contribute it to core and go through
an extensive review process and this
really sucks because a lot of people are
doing a lot of custom things and you
like you're not going to get your
strange logging scheme that you have
found to be effective for your
organization merged into upstream docker
only if you're really really lucky or
you're okay with going through and
violating a lot of that in changing a
lot of that stuff in this stage
fortunately what docker is now looking
towards is going to sort of an extant
sensibility model where you can hook
into the daemon and do and add in
plugins at runtime but for logging
that's still kind of far out what
they're focusing on four one seven which
is scheduled hopefully this summer is
for a network and storage to be
pluggable but this is a really really
exciting direction right now there are
many different solutions around syslog
login to log into the network directly
from the application standard out
standard error we're looking at standard
out standard error and then yeah we're
still thinking about exactly what to do
with login but it is something that
we're working on right now and once
you're once you're done with this you
you have modernized some of your
application some set of your application
you figured out what are the principles
that we're going to adopt within our
organization to be ready for docker you
can finally get to the point where you
can start actually using containers and
maybe when you're at this point docker
is no longer the popular container
implementation and then you just go with
whatever fortunately once you've done
the things in stage 2 it's actually
really really easy to move to another
container implementation if you need it
to so what you need to do in this stage
is get really confident with containers
the second stage the second stage
usually can can take somewhere between
months two years for your organization
depending on what kind of structure are
you going for a greenfield thing in
which case it will take less time but
you do still need to choose the
technologies that you need for like
logging secrets and so on and some
people can step it
and basically skip this step entirely if
they start at a point where the cast
solutions like Google and Amazon and so
on they're at a point where they solve
all these most of these problems for you
so the focus of this stage is really
starting to actually adopt containers
and as I've been been preaching before I
do recommend starting with development
and CI and depending depending on your
stock one one might be face more of an
immediate user issue than the other if
you're already looking at completely
revamping your development environment
environment and that might be a good
place to start I think a lot more
patterns are emerging in the development
and CI environment about what to do with
docker docker compose is something that
the docker Inc team has built to manage
multiple containers running at once and
updating them and so on
there's still a lot of questions
question kind of left unanswered of for
example if you have if you have multiple
applications and you're tying revisions
to each other
so if you have service a and service B
and you're you want to go into you want
to test service a against service B
which version of service B do you
actually test against and did maybe
maybe you're using service discovery to
figure out which production which shiz
in production maybe every time to deploy
it they go and change the shine every
other one which also sucks but these are
there's still some unanswered questions
here and there but these are definitely
very solvable problems for your team and
really in this state is it's important
to focus on the fact that you're just
trying to introduce containers you're
not trying to build crazy features or do
do something that you've never been able
to do before it's great if that comes
out of it but that shouldn't be your
primary goal you're setting yourself up
for success for later and maybe this is
where you go into production or maybe
not and this involves a bunch of things
like you need to be able to you need to
be really good at building container
images you need to figure out Union file
systems which I'll get into in a second
in it in a container it is also
something that you might have to do
monitoring you might have to run ng
kernels if you're if you're running into
kernel lockups like we did how do you do
security updates what about the docker
registry where you host all the images
how do you manage that how do you scale
that how do you distribute there's just
a talk about the ploys and how do you
distribute these docker images because
they're easily a gigabyte or multiple
gigabytes large and the way that the
algorithm works to send over Tiff's over
the wire is not very very effective and
again this is just as much about what
it's this stage is just respond about
what it's not so don't change the
orchestration don't change your
deployment don't change Linux
distribution and if you're changing
anything but containers make a conscious
decision to go back to step to get it
done right and then move on you're not
in a rush and so when it some examples
that speak to the maturity of docker and
these are one of tens is running an init
in a container a lot of people just kind
of shove and their application into the
container and then expect it to work but
really because you're running in a
completely isolated environment you're
expected to have an init process in
there a good init process that does
everything that init and init process
does what an init process for example
can't crash because that crashes the
entire namespace but it also has the
duty of cleaning up zombie processes so
when a kept when a process dies in in a
UNIX environment it leaves it it goes
into a Sambi state so the kernel puts it
in a zombie State and something has to
acknowledge that okay it entered the
zombie State and now it's gone after you
acknowledge that and if you don't if you
don't have an init inside your container
that's doing that by waiting on all the
children then you can keep accumulating
these zombie processes which is common
if you're like forking out and you have
timeouts around that forking this is
this is really a common scenario and
then you can exhaust the kernel data
structure that stores all your processes
and your your operating system acts and
very very undefined and interesting ways
and the other thing is building samples
we at Shopify we were not able to get
darker files to work at our for our
application at scale so basically we had
to build image infrastructure completely
from scratch and this hasn't gotten
better at all in the past year and a
half which is somewhat depressing we
have about a thousand
2,000 lines that completely we
implemented the the image build system
on top of docker to get our builds fast
enough
we now have have container builds in a
minute which is remarkable based based
on what we got we after a lot of work
with dr. files we finally got it down to
around 6 minutes but if you have
requirements like being able to fix for
word really quickly if something breaks
then you need to be able to build your
containers quickly and really what
docker needs to do is just expose these
low-level primitives of building so that
you can build your arbitrarily large and
complex build system on top of it but
docker files just sit at a very very
strange and not great abstraction level
because it doesn't enable you to do
really great things that just enables
you to do very very simple things and
the last one is is Union file systems
darker needs kind of a copy-on-write
file system because you're taking these
massive images down on the server and
now you might be running hundreds of
containers based off of that image
instead of doing a copy of the entire
image for every single container you
want to be able to share share it and
then do copy and write on disk and we
tried a bunch of different approaches to
this we tried au FS with just one
implementation of this out of kernel
better FS is an in kernel a completely
new file system and set FS is another
approach but on linux is still kind of
sketchy because it runs in user land
because of licenses stuff and overlay is
another completely new implementation of
this stuff that came into the kernel we
tried au FS better FS and it is it was
agony like very bad and finally we
overlay came into the kernel and that's
been working remarkably great for us so
this is getting somewhat of a solve
problem but it just hasn't been very
talked about and in general how Union
file systems work and how the build
system works is very is not very very
nicely exposed by by the docker
documentation and really requires
reading a lot of lower-level
documentation to understand fully and
once you're done with this stage you can
finally move on to the one that you've
been dreaming ever about since you went
into stage one which is where you start
building really really interesting
features on top of this stuff this is
what this is the states if we have
finally reached where we get to the
point where we can build what we
can do CI in in five minutes due to
poison three minutes and start really
building infrastructure on top of this
but there's been a lot of really boring
daunting work that came before this this
is where you can do things like
distributed orchestration someone talked
about missus earlier today that's one of
them
there's tons there's so many companies
building so many different ones most of
them suck but some of them probably work
this is where you start building docker
bobbins for your developers this is
where you get a completely consistent
deploy stack where you have like an
overview of all of your applications and
you'll click on click on you have like
little sliders to scale them up and down
this is where you really you you're able
to build these things this is where you
might be experimenting with mini mold
Linux distributions where you might be
running docker as in it and the only
thing that their servers are running is
actually docker but this is not really a
place that that we are out yet so kind
of in the end I there's a lot of there's
a lot of problem with problems with
containers and some of the problems are
with docker I just I just got an email
that we had like a memory leak on one of
our job servers because of docker was
leaking memory but the vast majority of
our issues are really around that just
the linux namespace is not being staple
and the production tools is not being
there yet
dad said we really believe in we really
believe containers is the future and I
think that the community has also
realized this that there's there's just
too much there's too much there like
there's too much talk about it there's
too many companies building on top of it
like there must be something there may
be someone maybe they haven't quite
nailed what it is but there has to be
something there and really what you
should be looking at now is at least
developing the DES mindset internally so
that you know that you're building
solutions now that work for this when
you have to adopt this in a couple of
years and darker does have open issues
for pretty much everything we've seen
there are some bucks here and there but
most of the bigger bigger design
decisions are already there and being
discussed but the development in core
unfortunately is slow I think really
that what what's going to be the next
really interesting step and what
hopefully will move us more towards
production is when the extensibility
gets into docker core what we can do
like pluggable storage drivers pluggable
networking pluggable
logging and so on and Doc urges again
becomes that agreed-upon interface and
really the images becomes the core of
the docker community and how you build
that but again the build system sucks
currently so they have to completely do
to redo that and unfortunately I think
the prospects for for example a new
build system is is are not great
currently so with that I'll also be up
here if anyone has more questions
afterwards</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>