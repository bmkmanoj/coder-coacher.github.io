<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Containerizing your Dev. Environment • Laura Frank | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Containerizing your Dev. Environment • Laura Frank - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Containerizing your Dev. Environment • Laura Frank</b></h2><h5 class="post__date">2015-04-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kPFA240eLTA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello hello everyone welcome to a
Muenster I'm glad you guys chose to come
on this fine day for a Tech Talk
it shows how indiscriminate you are with
your time I mean really docker that's
what he go home tell you the kids I
spent the evening on docker alright it's
your time your choice if you if you
wanna be outside there outside and you
have a patio there which is awesome the
patio but go visit the patio I'll send
you a recording of this talk but in case
for those who want to stick around
welcome to boring store hmm my name is
the back of the rack fate I worked in
Morningstar a couple of years and we
have a lot of tech talks at Morningstar
we do mobile Monday's we love having
technology events in cloud they give the
global hackathons so we're looking for
anyone that wants to do Tech Talks here
event which by the way so they're
discerning so that just shows I really
like Laura's talk here so we will so
with that welcome to Morningstar if you
have any questions or want to know where
the bathroom is you know where to find
it alright thank you
hi I'm Cedric I wanted to just briefly
talk about a conference we have coming
up on May 3rd 10 a.m. to 4 p.m. I want
to make sure I have the date right
called DevOps for kids anyone with kids
in their family that are interested in
technology it's a conference that we're
holding at Loyola just off with the
Loyola red line there's going to be 4
tracks so we're going to be teaching
kids from ages 6 up to 18 about
conductive play-doh Lego Mindstorms
minecraft hacking and scratch the
programming language so we're really
looking to get parents and family
members involved it's going to be a
relatively small --is-- conference about
a hundred students or so we're expecting
oh thank you about a hundred or a
hundred a hundred students or so that
we're expecting but we'll be posting
some details to the Meetup if you also
have employer that's interested in
sponsoring let us know we have a couple
small sponsorships spots still left as
well thank you hi guys welcome to go
tonight we are really happy to be
hosting this night at Morningstar and
we're also really happy to have for a
frank here giving a presentation on
docker we actually just added a docker
workshop to our our schedule penny
Resnick is going to be giving a workshop
on Thursday May 14th called docker
master the basics how to speed up your
delivery in workflow if you guys are
interested in registering for that
training please visit our website this
year we are going to be hosting our
conference at the Westin river north
which is a new venue for us the dates
are going to be May 11 through the 12th
for the actual conference and then the
13th and 14th are going to be workshops
at the Bleacher Center just to let you
guys know just by being
here you're gonna be receiving the
ability option of getting $100 off
registration by using the code I heard
go to so if you are interested please
use that this year our keynotes are Chad
Fowler Todd Montgomery Kyle Kingsbury I
need to sing Kota and Todd Montgomery
did I miss one in that Maureen Thompson
thank you all right we'll enjoy the rest
of the go tonight and at the end of the
evening we're going to be doing a raffle
for those of you who registered so just
stick around for 2 minutes after Laura's
presentation and we'll do that all right
can you guys hear me from this mic not
very well
no no what if I turn it on yes
okay is that okay I can project age to
be a fifth-grade teacher okay here we go
okay so my name is Laura Frank and I'm a
senior engineer at CenturyLink labs so
we CenturyLink is a telco it's kind of
like saying but my team is actually in
research and development team so we
don't do anything related to the
traditional telco capacity we came from
a frog we were acquired by CenturyLink
and now we just worked on open source
all day so that sounds like kind of a
sweet job and it is a pretty sweet job
and it's pretty great that I think it's
great that CenturyLink is investing in
open source paying 13 senior engineers
to spend all of their day breaking
things is pretty remarkable
so you can find me on Twitter and github
kind of the same deal CenturyLink labs
also Centrelink labs calm and I'm here
to talk about docker so hopefully that
is something you're interested in and if
not as the VEX said their speeds across
the hall there's a couple of things I'm
going to talk about tonight and those
are three things containerization the
doctor ecosystem nuts and bolts and then
of course working with docker on a
project there are a few things I am
purposely not going to talk about
tonight so security and Dockers not
something I'm going to talk about
tonight I will be happy to talk to you
at length about it in any other venue
but not tonight I'm also not going to
talk about networking or distributed
systems using docker that's also pretty
complicated and then there are these
this huge vast environment of
orchestration tools just like a huge
landscape of all these little extra
tools that are popping up in the
periphery to use use alongside with
docker integrate with docker and they're
very helpful and very great but tonight
I'm going to focus on the nuts and bolts
of what docker actually does for you so
that you can understand what your
orchestration tools are doing I feel
like it would be a disservice to you to
show you kubernetes and all the really
awesome cool stuff that kubernetes can
do for you if you didn't really
understand how to build an image
yourself so if you have used docker
already that's great actually
you'll probably come away with some
demystification that's a word
some demystification of some things that
maybe you didn't quite understand how
they were working and if you're totally
new that's great too I kind of assumed
that most people hadn't use docker so
I'm gonna start really really at the
beginning and uh hopefully you guys will
enjoy the wild ride that you're about to
embark on so when we talk about
containerization we probably think about
it in terms of docker because docker has
become incredibly popular and very very
widely used on teams of all sizes from
google to my team at CenturyLink we're
we're you know 13 people the thing that
I want to make really clear before we
get too far is that docker and
containers are not the same thing so
docker is a tool to use with containers
docker will manage containers for you
but containers are actually a separate
discreet thing and docker is just a way
to use them so sometimes I might say
docker ization when I really mean
containerization those two terms are
interchangeable but docker and container
are very different things
so docker is a tool for managing these
containers that I've just talked about
it does two primary things first it
manages the code that goes inside of
these containers and then secondly it
will execute the code inside of the
containers I'm gonna break these down
and kind of go into some depth for each
of them as we as we go on but those are
the two primary capacities that docker
that docker has so first let's introduce
containers and learn all about them
because they're pretty cool containers
are really nothing more than a layer
virtualization they're basically a
self-contained execution environment
they do work on a shared kernel which
has its downfalls of course but they are
isolated mostly from other containers I
said I'm not going into security there's
lots of caveats with that statement but
in general they're isolated and one of
the the best features of a container is
that it's very fast and has a lot very
low overhead so if you think about your
daily development workflow and if you
break stuff a lot like I do
and that's running a virtual machine
sometimes I can spend like five minutes
rebooting a virtual machine and
reconfiguring it to make it how I want
it to be with a container that can
happen maybe in five seconds instead so
if you think about how many times you
screw up and have to re reboot a virtual
machine and turn min turning minutes
into seconds can really save you a lot
of time and frustration doing it during
your day so this is all to say that
containers are just virtualization layer
and if they are kind of like a virtual
machine and you may be thinking that
that sounds very similar and in fact
you're right but there's a couple of
fundamental differences which I have put
some blocks on a slide to help
illustrate so this is a two web service
one database service application may be
running somewhere in the cloud or maybe
in your parents basement or wherever you
host your things so we have physical
Hardware of course the host OS and a
hypervisor to help with our virtual
machine provisioning and then of course
on each machine if we can think of the
columns of those smaller blue blocks as
a machine we have a guest OS libraries
and then the service finally running on
top of things and this is great this is
nice and tidy and this is what we expect
and are probably very comfortable with
already but if you look you can see a
lot of duplicated work libraries are not
shared and also the guest OS and
hypervisor can be a bit bulky in the
docker world this model looks pretty
similar but the biggest difference is
that we can get rid of the hypervisor
and kind of sort of mostly get rid of
the the guest OS as well and instead
what we'll do is introduce this thing
called the container runtime engine this
is what docker is certainly there are
other container runtime engines other
than docker but docker certainly the
most popular and now we have two web
services and a database service running
and very well designed containers thanks
Scott Craig my designer for making those
for me and then the the biggest notice
aside from Scotts wonderful design work
is that the two web services now are
sharing the same library so that's
really great we don't have to have two
copies of the same stuff if two services
you are granted access to to use those
libraries at the same time so of course
this might seem a little complex and it
is a little bit a little bit more but
the benefit from from using
containerization is pretty great I think
it's pretty profound so they may have
slightly more complexity but using
containers can help reduce the amount of
time and space you need to run your
application and so less time less space
less machines less people less money
it's just kind of less resources
especially the less money part that's
the part that my boss really likes a lot
okay so that sounds great but let's
break out the benefits maybe a little
bit more I like to when I talk to people
about containers and why they might be
interested in using them in a in a
project there's kind of four main things
they're fast so some of these containers
have sub-second boot times if you can
imagine that in comparison to a virtual
machine which might take a couple
seconds or even a minute or several
minutes that's really great it is very
cheap not just because they take up
I guess exactly because they take up so
few so few resources and have such low
overhead you can pack many containers
onto one machine so you kind of get a
higher service density and that's where
the the cheapness comes from
they're also portable you'll see that
each container is run from an image and
those images are shared and reproducible
and kind of predictable across any
system that you might run them on as
long as that system is running docker
and then the last thing which is my
favorite because I make a lot of
mistakes all the time because I work in
R&amp;amp;D is that it is safe and by safe I
mean if you do something really bad the
worst thing that will possibly happen is
that you might have to reboot your
container right there's no bouncing
virtual machines there's no like
reconfiguration anywhere you might just
have to say docker RM and past the name
of your container and then say docker
run again so this is really very low
stakes especially in an environment
like R&amp;amp;D so containers are kind of a
profound way to change and maximize your
efficiency in both your kind of DevOps
processes and your development processes
I usually use docker in development I
work on a lot of tools that support
docker for other engineers and those
tools themselves our docker eyes
applications and my life kind of before
I used to work for hewlett-packard on
their cloud infrastructure team not
using docker and now I work at
CenturyLink with docker and it's very
different and and much better I'm much
happier developer because the docker so
they can put that on their website if
they'd like so I'll just talk about
docker I'm gonna give you guys kind of
the high-level bird's-eye view before we
get into some live demo which will
hopefully work as well as I hope so all
right docker
again is just the tool for managing the
containers so first thing we're gonna
talk about is managing code that goes
inside containers we'll get to the
execution part in just a little bit so
docker itself even if you go to Dockers
up site they'll call out this kind of
dichotomy of identity themselves so they
call themselves docker engine which is
the execution part and the kind of
technical part and then they have docker
hub which is the community and the
sharing and collaboration part and the
most important thing or the most
important component of the docker hub is
the docker registry this is a public
registry where docker images live so
every image when you can you can push it
to a place called a registry this is
very similar to github or other kind of
source control models that you may have
seen this is the public registry which
means that docker hosts it and you can
push your images there to let other
people pull them down and use it however
they'd like this might be hard to see
for some of you in the back but maybe a
third of the way down you'll see
official repositories and then we have
all these nice logos from you know
whatever project you might want to work
with these are all official in
that are maintained by either the
community or the company that's
associated with them you don't have to
do anything it's kind of like a package
dependency so if you want to have a
project using Mongo and you want to run
Mongo in a container you can just pull
it down from the registry and you don't
have to do any configure well you'll
have to do some configuration but you
don't actually have to build the image
yourself the people that Mongo have done
it and they've made it available for you
on this registry the public registry and
again it's very similar to get you'll
push pull commit etc there's a couple
other things that you can do to the
registry I do want to call out that
there are two kinds of images that you
might find on the registry and just to
be conscious of what particular one that
you're pulling down so there are
services that are already prepackaged
for you so for example if you're using
elasticsearch in your project you might
want your elasticsearch to be running in
a container and you'll just pull that
down kind of packaged up as a dependency
from the docker hub that's one way
there's also kind of what I call project
based images which are not packaged and
not ready kind of for production they're
just sort of the underpinnings of what
this the service will turn into so these
are kind of environment images if that
makes sense at this point hopefully it
will in just a little bit but they'll
basically give you everything you need
to run the service without actually
running it for you so they they give you
a little bit more flexibility I'm in a
demo both of these different kinds of
working and that's not to say that
they're mutually exclusive certainly
there are prepackaged services that have
some elements of kind of the project
image but in general the the split
between the two is pretty distinct and
the other thing to note is that you can
also run your private registry if you
are using proprietary code like for
example when I worked at Hewlett Packard
we had a lot of stuff under lock and key
that we didn't want shared so we would
have used a private registry how'd we
use docker you can actually get the
image to run a private registry in a
container from the docker registry right
so you'll run this registry in a
container it usually runs on like port
5000 so you'll just like have localhost
5000 be your docker registry for your
project you can have it as a like
authenticated private registry depending
on your level of security and you'll
interact with that the exact same way is
the public one it will just not be
public which is kind of the point right
so that's the management of the images
and kind of the community side on the
docker hub you can also find articles
really a lot of documentation and some
other kind of community aspects of
working with docker but the fun part and
the part that I like is the execution
part and the kind of technical details
and just for a second I've expressed
this in emoji mostly for my own personal
gratification but also maybe some people
find it funny but so so really though
this is to illustrate that docker is the
kind of go-between between you and the
machine you will talk to docker and
docker will do the work for you so
doctor will make boxes happen on your
computer and in boxes that looks like
this and docker is right here docker is
at this container runtime engine you
will interact with docker and then
docker will take care of executing the
tests that you asked it to and mostly
you're gonna interact with it via the
CLI so there's a couple commands that
are pretty handy if you use docker
already you've probably seen these
already we can say docker run my image
which is an image that you've either
built yourself or pulled down and I will
demo building an image yourself in just
a little bit once that image is running
inside of a container you can stop the
container you can attach inside the
container and then to see everything
that docker is doing it's docker PS
however docker PS is useless because it
doesn't show you stopped containers so
if you have like 15 containers that have
exited you can't see them I don't know
why they did this by default but just
pass on the - a flag and that helps you
can also turn on quiet mode which just a
pro tip I often do so I usually say PS
aq and that just gives it kind of a nice
little
a little interface for you to see all
the stuff that you've done there's also
a docker API which is really not super
important for what we'll do tonight the
API has what I like to call a restful
tendencies so it's not pure rest but
it's mostly rest and again using the CLI
is the same as using the API that the
daemon is when you issue a command on
the CLI right it is actually
communicating with it with an API
endpoint and the reason that I mentioned
this only is that if you are using
docker kind of heavy duty in your own
project you can build your own tooling
around it there are certainly api
wrappers and other tooling that exists
already but it's also possible to kind
of control things at the API level from
within your own application if that's
what suits you so you kind of have this
basic understanding maybe of what docker
will do for us
I'm gonna go through a pretty common
workflow which is what I do every day
which is work on an application that is
containerized and running inside of
containers so we're gonna start kind of
soup to nuts the whole deal we're gonna
start with a docker file and hopefully
hopefully with looking at some
application running in a browser so our
objectives first we need to put the code
inside of the container okay then we
need to run the code and then we want to
see this application actually running in
a web browser all of this is going to be
a containerized application so there's
gonna be kind of one extra level of
abstraction maybe then you're used to
but I promise it's not really it's not
that terrible it's not that hard and I'm
gonna talk you through it so first thing
we need is to install docker so there's
kind of a couple things you need a
computer of course code to run I like to
have coffee when I do this because it's
frustrating um I love this tweet and I
laugh at it every time I have it in a
presentation I hope you find it funny as
well you you just can't you can't do
that but I include this to illustrate a
point that sometimes docker gets a bad
reputation for being kind of like black
box key and very abstract and I
definitely understand where that
comes from as you get more comfortable
with it it the abstraction kind of
disappears and in fact there are tools
that have been designed specifically to
make that abstraction disappear I would
warn you against using any tool that is
not transparent and doesn't let you see
what docker is actually doing because I
don't think that's helpful but there's
certainly tools that can kind of be your
training wheels as you get more
comfortable so and actually installation
is sort of a an interesting beast with
this abstraction idea because if you are
running Linux actually that's great you
can run docker right on Linux no problem
just install the official packages but
if you are using anything else and I
think most of us probably use Mac's
kind of in our day to day life maybe I
don't know I don't want to make
assumptions but if you're using a Mac
you have to use a lightweight VM if
you're using Windows you need to use a
VM kind of that's a qualified thing the
windows support for docker has been
improving but it's not totally all the
way there yet so you'll probably still
need to use one and I just had shown you
all these slides about how terrible
virtual machines are so I'm I'm very
sorry to be a liar because I don't
appreciate lying or misleading people
but the point is service density right
so if we have an application and you
have maybe five services you need five
virtual machines that's not fun with
docker you can have one virtual machine
with five containers running on it so
that one virtual machine isn't really
gonna give you downgraded experience
either in production or kind of in your
day-to-day development environment so a
pro tip is to use this tool called boot
to docker which was made by docker
itself and basically what it does is it
spins up a tiny core Linux instance for
you a very just kind of worker Sandboxie
machine and it syncs your folders it
configures some stuff for you and you
can actually use it on a Mac and have
the experience as if you're running
docker directly on your Mac I'm going to
use booted docker every demo or
everything that I type where I'm saying
docker it's actually inside this machine
I'm not yeah I'm not running docker on
my Mac so please don't get confused I've
found that sometimes it's confusing
because it seems like I'm using it
natively on my Mac but I'm not so don't
but Buddha docker is very helpful I
certainly have my kind of hard way
vagrant environments but if I just want
to start something and test something
I'll use boot to docker myself so
handling this abstraction we have now
our Mac or our personal machine and then
we have the support this virtual machine
and then we have containers running
inside of it it may seem very difficult
to kind of figure out how you're gonna
get from your local machine all the way
into the container and kind of make that
extra jump and there's three main ways
to sort of deal with this abstraction so
you'll link folders of course and to get
things from your local machine to the
virtual machine
you're gonna copy files or add them in
the docker world they're different which
is kind of strange but I can explain
more about that later so you'll either
copy or add files from the kind of
docker host into the container and then
also port forwarding is the way that
you'll kind of be able if we're working
in web applications to see what is
running in your container still on your
local machine we're just gonna add kind
of another step of a port binding so all
right of course all of this is not
really that helpful if we don't have any
code to run so I'm gonna do some demo
for you I'm gonna explain a little bit
and then I'm just gonna move to my
terminal so the most important thing to
understand about containers is that they
are based on images like I mentioned
before when I talked about the docker
hub every image is controlled by a thing
called a docker file and the docker file
is really nothing more than a set of
instructions use a kind of instruction
and then it executes them from top to
bottom exactly what you tell it to do
you can build an image directly from
your own docker file via the docker CLI
by saying docker build - T which stands
for tag and then you'll give it the name
that you want to tag the image with
which usually takes the format of who
slash bar where foo might be your github
username and then bar is the name of the
image and then of course you have to
tell it what where to look for the
docker file and usually actually
generally when you're starting out just
make sure you're in that directory
already so
you can just pass a dot to it if you
don't prefer to build your own and you
just want to pull down something that's
prepackaged for you you can say docker
pull foo bar where foo is of course the
name of the repository name and then bar
is the image there are official images
that have a slightly different pattern
for the name but but mostly that's what
you'll see and again just a reminder
because this is incredibly important is
that there's two basic types of images
we have the packaged up kind of ready to
roll into production dependency image
where everything is contained and
everything's ready for you and then also
there's that project type of image which
is what you'll use in active development
but never ever ever go to production
with one of these because it's just just
don't do it it's bad of course I have a
little asterisk effort development only
because these are not mutually exclusive
you can have some services that are a
blend and in fact when I work on
development I kind of have a packaged
the packaged version of my service with
certain crucial bits and pieces have it
that haven't been packaged then are
instead linked via a volume which I'll
show you in just a little bit as well so
this brings us to actually building
something here is an example docker file
and all that this docker file does is
create a container copy over a Sinatra
application into or you know write copy
the the junk to make my Sinatra
application work into the containers
filesystem
it sets a working directory so that I
can execute commands against the
container it bundle installs and then it
runs my Sinatra application so before I
go through and kind of explain to you
everything I'm actually going to show
you a failing demo which some people
might think is silly but I just want to
I'm having some trouble with ruby gems
today which is fine I appreciate honesty
so I'm gonna do this and it's gonna fail
but I know that it will fail so I
already have a couple images already I
have some backup so we'll be able to get
the full experience I've named them
grumpy because I was very grumpy about
this problem so we can look at the
docker file and this is actually
you guys can see that hopefully this is
exactly the same thing I have on the
slide maybe a couple like insignificant
differences but we're just gonna build
this from top to bottom and the reason I
want to build it for you is I want to
illustrate the layered file system that
docker has so with each instruction
you'll see it kind of creating a new
layer with a different UUID in the file
system and they kind of just stack on
top of one another and again to docker
or to build something will say docker
build - tea we'll call this hello world
because that's what it prints and we go
past dot and we will see that it is just
executing these in sequential order from
top to bottom every layer you can see
here kind of gets its own ID the great
thing about this kind of layered file
system is that if I were to make a
different image that maybe had just one
thing different docker doesn't need to
go back and rebuild the whole image it
will just find the ID of the layer
that's the last common element and
branch from there so it's very much kind
of like get in that sense or like it's a
tree so it'll just kind of find find the
the common ancestor and then kind of
make a different branch so one blur will
just kind of do its thing and that's
fine we can get back to this but so well
it's executing those instructions or
actually it's not doing it at all but I
want to explain to you in some depth
what these instructions actually mean so
the first thing that is absolutely
mandatory and necessary in every single
docker file and every single image that
you're building is the from instruction
the from instruction is the origin or
the source there does exist a thing
called scratch like from scratch if you
are doing really low-level kind of
customization for your docker projects
generally you'll have something like
this which is a base image that someone
else has written and taken care of for
you for you this base image is from
scratch so that's kind of where that
scratch layer comes from so basically
what this Derby base images is kind of
the setup part it has Ruby and has a
bunch of other stuff installed on it but
kind of the common pieces of any Ruby
application that I might
Khanh I have extracted that put it in a
base image and then all of my other
services can be can be from instruction
from this image that way I can get rid
of a lot of repetition and kind of
duplicated work and the next important
thing I'm going to skip like maintainer
is self-explanatory this is the run
command so the run instruction and run
just runs the command that you pass to
it so in this case we're gonna make a
directory and then the next thing we're
gonna copy everything in my current
folder into this new directory that
we've made this is the point where this
is the point of no return so if you have
something in that directory you're
copying it in there you cannot go back
and change this so this is probably
worrisome if you're doing active
development and in fact you would not
use this way when you're doing active
development because you would have to re
rebuild your image every single time you
made a change in order to see it and
that's really just not fun so this is
great for dependencies this is great for
when something's ready to ship but not
great for development when you look at
things on the docker registry this is
the type that you'll most commonly see
because a lot of those services are
already prepackaged and ready for you to
use in production so they're gonna use
this style and the next thing is setting
the working directory or the work der
which is fun to say this is just saying
every run command that I give you from
now on please execute it within this
directory so if I were to have said run
bundle install and then set my working
directory this whole thing would have
thrown up on me because docker doesn't
know in which directory it should have
run that command so again just make sure
you have everything in the order that
you that logically that it needs to be
and then finally we have the command
command which is just CMD for short and
you can either just pass it the command
or you can give it like an array of
strings or however you need to make it
happen for you this is the command that
will actually start the container and
that you will kind of drop into the
container at this command so when I run
this image it will be running Ruby
HelloWorld and will
able to see it which in fact let's do
that right now because we can alright so
yeah that failed and that's fine um but
I was thoughtful enough for all of you
to make some backup images so this
grumpy image that I made is just exactly
what what we talked about in the
previous slides so we're gonna run this
by saying docker run and in order for me
to be able to get what is in the
container into my browser I kind of have
to do a couple weeps and one of the
things I need to do is set up a port
mapping rule and I know that I'm gonna
be running on four five six seven in the
container so I'm just gonna bind that to
four five six seven on my boot to docker
host so not actually my virtual machine
or not my local machine but the virtual
machine that's running the tiny Linux
are the tiny core Linux that's
associated with boot to docker so I'll
make that port mapping rule and then I
can just pass in Grumpy and we should be
able to see this start which is cool and
if we go over here we can see this
running in a container so I just started
Oh
random applause thank you it really is
not that hard see the whole point is
that it's not that hard so this is great
we have a Sinatra application running in
a container and it took like just a
second so that's awesome and it really
wasn't that hard we just had to make a
docker file make the image and then spin
up a container from that image but of
course if I wanted to go change this I
can't do that because it has been
packaged and copied into this image and
if I wanted to change it the way that I
had kind of built the image already I
would have to go rebuild it which is not
super fun so
come on actually I'm going to first
change this okay so we have this thing
hello go to this is the local file on my
on my laptop so this is not in a
container this is just like my working
code that I would have open and whatever
editor that I like so we're gonna look
at our images again oh just let me have
two of these open please
it drives me crazy okay so we look at
images again and I have this thing
called the grumpy base image so what I
did for this is let's look at our docker
file one more time so the main
difference between the static or kind of
prepackaged service way and then the
dynamic active development way comes in
this run where this run copy happens so
when I say copy everything into this
directory again it's like static and
sealed we can't change it so if I just
want to have a base image I can omit
that piece completely and I'm also gonna
omit the command because I want to drop
in a bash session I don't want it to be
started already with Ruby HelloWorld I
kind of just want to drop in a container
and have it feel like I'm just in over
in a virtual machine so we can run this
image and I'm sorry that the I can't
just kind of do it how I normally would
because we're having some some
networking issues with ruby gems so this
is the closest closest approximation is
i can give you but i'm gonna show you a
couple customizations at runtime that
are pretty helpful and as you go along
your own way and maybe are experimenting
with docker you'll see these things come
back also all the code that i'm using
right now and is on github in a
repository called hello world container
demo on my personal github account i
also have a blog post that is up on
centurylink labs
and also the readme for the repo has all
of the information that you'll need to
run this in case you kind of want to
follow along at home after we're done
here
but to run this in a kind of way that I
can actually manipulate the code inside
of it and see it reflected in the
browser I need to run it in interactive
mode so this is just so that I can kind
of have access to you TTY and other
things that I might need
so we'll do docker run IT and we need to
pass a port mapping rule again so this
is the same Sinatra application just
kind of configured in a different way I
need to run it on a different port
obviously because it won't work the
other way the most important difference
is that instead of copying in the docker
file like I did before I didn't copy I
don't have any code in there what I'm
gonna do is Mount the code via a volume
so I will pass dash of E and the way to
mount this is we pass in write our
directory where all of our stuff is
which is that Cohen I'm gonna drop into
our app so all this is gonna do is kind
of mount the files that I have in again
in the boot to docker machine which are
synced back to my laptop so again we're
making kind of an extra jump here but
we're gonna put that those files inside
of the container so that when I modify
them actually on my laptop we can see
that reflected in the container so we'll
see that in just a second
so we have docker run IT port mapping
rule volume volume rule will give it the
name of the image which I believe I call
this grumpy base image in the last
argument I'm gonna pass is the entry
point so before we kind of started the
container with command Ruby HelloWorld
dot RB we don't want to do that this
time we actually just kind of want to
drop into the container like normal and
have it kind of feel like if you like
our own laptop instead of a container so
so far away so I'm just going to drop in
bin bash and and hopefully when I run
this
I am so now I'm inside of a container we
can see ya I'm just right there I'm
gonna go back to where I put all my
stuff and I can see that all my files
from my Mac synced into my virtual
machine are now inside of my container
by way of a volume mount so hopefully
that's clear that we're kind of making a
couple jumps and we can run this I've
already done the bundle install crap
kind of before I got here anticipating
some problems so great so now we're
running the same application just in a
slightly different way and this one says
hello go-to because I just changed it
and in fact if this can ever stop coming
close I did something wrong I think I
have some docker problems today but yeah
we can change this awesome people
great great right so this is how you'll
use it when you're actually developing
so of course it doesn't make sense to
have to recompile or rebuild your image
every time you make a change it's very
frustrating
there is a way to handle the abstraction
of docker while still getting the
performance benefits of containers when
doing something that requires a lot of
heavy active development and isn't just
running a dependency in a container so
that's the point I'm trying to
illustrate this is probably the most
common way that you'll use docker in
your in your own workflow especially if
you're working on web applications so
that's kind of the two ways that you'll
use docker again static and then the
project files
static being the first thing and then
the project way or the dynamic way being
the second thing that I just showed you
and very quickly I want to go back to
this idea of a base image so we can
remember in both of our docker files
regardless of what type of kind of what
strategy we were using when developing
with a container we have this from
instruction it's mandatory for every
single image
the base images are great if you can use
them smartly if you can figure out the
commonalities across all the services in
your application and kind of find out
where the breaking point is like figure
out what's in common you can make a
separate image for that that can be
shared across all of the services the
other great thing about base images is
that because you're using a base image
that has a specific tag there's no need
for any kind of version management
inside of a container there can only
ever be one version of something running
at a time in the case of Ruby you might
have gem sets and other things that are
very annoying to manage outside of a
container inside of a container doesn't
matter and you can only ever have one
there's no RVM in a container it's
brilliant so if you need to have a
different version of Ruby you'll see the
colon for the tag and just change it
from what to not one - to what - to - oh
I think we're on right now I can't
remember but that's how you'll update
the versions if you are interested in
updating it's just to change one thing
in the base image and that's kind of
really all you have to do you don't have
to do any manual configuration and of
course Ruby other images elasticsearch
Mongo all these things that I mentioned
have official images available on the
docker hub they are maintained by other
people which is excellent if you are
lazy which you should be because you are
software engineer these repositories
include instructions for bootstrapping
and these images again can be base
images or actually run services I can't
tell you I'm telling you this many times
because I've made the mistake many many
times and I just want to save you the
heartache and headaches and sadness a
couple notes about the ways that you'll
work with docker the easy way is boot to
docker which I've been showing you this
whole time I really can't recommend this
to a highly enough it's it's quite
amazing it kind of obscures everything
as you've seen it looked like I was just
interacting with docker I'm on my own
laptop but I wasn't it was a trick I was
using booted docker it is not great for
more complex systems of course when I'm
actually working on Panamax which is the
open source tool that I work on we have
like anywhere between three and five
containers running at any time
I don't really use boot to docker for
this because it's not just not suited
for the complexity of that system but if
I just want to sandbox something or
prove one of my co-workers wrong I will
often just spin up what I do that I'll
often just spin up boot to docker the
hard way or hard way right is you can
also use booted docker in association
with our kind of in tandem with
something like vagrant which is what I
do this is kind of more difficult you
have more control though with boot to
docker you're running tiny core Linux
and if you want to use a different
operating system like core OS which is
what I use you can't really do that with
boot to docker so you'll have to do it
your do it yourself there's a couple
other kind of pain things like oh you
have to SSH into your VM and blah blah
blah whatever but um it's really like
again is vagrant you set it up once and
then you kind of forget about it this is
a couple lines from my vagrant file just
kind of to show you what it might look
like and it's really not that much extra
work to kind of get vagrant and docker
to play nice together so I use core OS I
actually don't recommend going on their
alpha Channel it I do it because I'm a
fool but for you probably just change it
to stable please don't be on their alpha
Channel and then again I'm gonna sync
some folders so that I can X I can
eventually mount those as volumes inside
of inside of my container and either way
remember that port forwarding if we're
you're working on a web application it's
it's not optional you need to do it in
order to be able to see your stuff in a
browser like we did and there's a nice
diagram that my designer made so thanks
Scott again I'm gonna make him watch
this talk and I'll prove it okay so all
of this is well and good and we've kind
of learned our docker ABCs in one two
threes but if you think about doing all
of this manual typing kind of at a
larger scale it seems kind of tedious
and probably annoying and makes you want
to pull your hair out a little bit which
is fine
learn how docker works itself first and
then move on to something that will
allow you to make applications
place so this is kind of the space of
docker that I work in I were going to a
called Panamax which is an application
template like templating piece of
software does so so much more which I'll
tell you all about in just a second but
the basic idea behind application
template is probably not surprising just
from the name so you'll use your own
images images from the docker registry
and specify all of your configure
configuration options beforehand and
things like port forwarding environment
variables for databases etc and then
instead of having to type docker run for
each of the services that you spin up
you can just say you know docker compose
up and spin up the entire application
package itself instead of doing it
piecemeal service by service and I
mentioned docker compose just now
because this is Dockers application
template link tool used to be called fig
if anyone is familiar with fig they got
acquired by docker Inc and now think is
docker compose which is unfortunate
because I liked fig much better because
it's only three letters I think actually
that's like a pretty it's like a heated
thing in the community it's like why do
I have to type docker compose it's so
long and of course now you dump
requirements into docker compose damo
instead of fig diamo and run it with
docker compose up instead of fig dot up
so but basically they just kind of took
the fig project change it around a
little bit added to it made it a little
bit better and now it's part of docker
proper so doc docker calm slash compose
will show you everything that you need
to know about docker compose the really
great thing about using a tool that
compose is that it is a docker tool so
if something changes in docker that will
be reflected in docker compose almost
immediately and you don't ever have to
worry about kind of learning the wrong
thing or participating in a bad pattern
because um you're sort of insulated
against that but the coolest tool which
I hear as lovely core maintainer x' it's
called Panamax so this is Century links
tool this is the tool that I have been
working on for the last year along with
12 other engineers so we're kind of I
guess I don't know maybe we're a small
team or a big team but it's taken us
took us about six months to build this
thing
so Panamax is a docker workflow tool it
kind of sits on top of docker and is the
interface between you and docker itself
is a containerized application and I
mentioned earlier that I wasn't going to
talk about a lot of these orchestration
tools or peripheral tools that are
associated with docker we do use a lot
of them in Panamax and they're very
helpful so you might you've heard core
OS already is the operating system fleet
and that's CDR what we use for service
discovery orchestration we also use
kubernetes things like mezzos marathon a
couple other things actually there's
kind of a multitude of docker related
tools and those are kind of all wrapped
for you in some of these workflow tools
like Panamax if you're interested in
more about Panamax we have Panamax io so
the templating language that Panamax
uses is actually very similar to docker
compose and we did that quite on purpose
because we feel like if you start with
docker compose and want to move to
Panamax that's great and if you start
with Panamax and decide that you're just
comfortable using CLI tool that's great
as well
the biggest thing though that
differentiates Panamax from its peers is
that we support remote deployments and
we don't just support remote deployments
we've actually created a separate tool
called dray that will provision your
environment in a remote location for you
using containers so awesome people so I
just want to show you a little bit kind
of what Panamax looks and feels like I'm
going to talk to you a little bit about
this remote deployment thing which is
actually super super helpful Panamax is
integrated directly with the docker
search api so if you search in Panamax
for like WordPress or something
we're actually searching the docker the
docker registry so we have these
templates which are things that people
have already kind of a some
WordPress and my sequel together and
done all the configuration for you so
you can skip the configuration part and
just run this right out of the box
there's also the individual component
images that if you want to assemble an
application for yourself you can go
ahead and do that from here so this is
the kind of basic application template
in part of Panamax but I think the
coolest part is this remote deployment
so it's great to kind of tinker around
with containers on your local
environment but of course you probably
want to put them somewhere eventually
and by no means is this a substitute for
any other like more sophisticated
deployment tool but it's really great to
just to be able to deploy to AWS or
Century links cloud or digital ocean
kind of with a click of a button like
the docker the docker systems that you
might be deploying are pretty
sophisticated and if you can do that
with a click just to make sure that it's
working it's it's kind of life changing
I should say and so we have this tool
also called dray which is a separate
tool from Panamax but we use it within
Panamax and drea is basically a workflow
tool the tagline is like it's like UNIX
pipes but for docker so what we do is
you have a task with some n number of
steps and for each of those steps we
spin up a container to execute that step
for you and then we take the standard
out from that container spin up another
container and pass it in a standard in
so in the world of kind of provisioning
we might have a couple different C I'm
I'm actually not going to demo this for
you right now you can kind of give your
own API things later if you'd like but
basically we'll create a new job and Dre
by way of spinning up a bunch of
ephemeral containers will provision your
entire your entire environment on
digitalocean for you it will notify you
when it is finished and you will have it
already set up within Panamax to remote
deploy to that instance so you'll have
the IP addresses and everything you need
so that when you search here so we'll do
a search for WordPress you can either
run locally or you can deploy it to this
target so that's kind of handy you don't
really have to muddy or mess around in
digital ocean or AWS if you just want to
configure a really simple like core OS
environment or cross cluster for you
will do that for you all within Panamax
so it's pretty self-contained and we
also have a couple other projects that
I'll give you a little sneak peek right
now this is Laurie i/o so I've actually
faked some errors because I thought it
might be nice to look what look to see
what errors will look like this is a
docker compose or other yamo kind of
application template authoring tool so
it can be kind of hard if you're new to
docker to understand exactly what you
might need to put in your application
templates and then even if you have what
you need it might be hard to figure out
exactly what format so these like this
Laurita io lets you very kind of clearly
see what all of the things in this
docker compose demo file are doing and
it also alerts you of any errors so
after you've finished making your docker
compose file using this authoring tool
you can either save it as a gist copy it
to your clipboard
there's a couple other export options
that we're still kind of working on
integrating right now so Laurie will
probably be released in the next couple
weeks if you're interested in
application templating I would
definitely check it out I know that I
even sometimes use it even though it's
still not finished but I found it to be
very helpful when I'm trying to work on
kind of a sophisticated project the
other thing that is very interesting is
this tool called image layers and
perhaps it is most interesting cuz I
wrote it so we've been working on ISO I
wrote it with my with my pair Gary I
can't not give him credit where credit
is due so this is actually a go API and
then in angular front end if you want to
talk to me about that bring me a beer
and I'll talk to you about angular and
grunt later
but nonetheless what this tool does if
you can remember when we built that
image we saw each of the different
layers this is just a visualization tool
so that you can actually see what your
what your docker images have in common
with one another and if there are places
that you can extract things out take it
turn it into a base image and make it
more efficient so this is just a really
simple kind of illustration of looking
at different versions of debian so it's
might be a little bit hard to see cuz
it's it's definitely not optimized per
projector but you can even see the
docker file that has generated each of
these images on the bottom and then we
can see the commonality so this one is
you know scratch is required for
everything so each of these three has
scratch but we can see aside from
scratch they don't really have much else
in common so there's you know some
pretty significant differences in this
there's a couple other things you can do
like filter etc if you're using docker
in kind of any sort of production
environment I highly recommend running
your images through this sort of animal
like analysis tool not only do we show
you where things are where they're
shared and where they're not shared we
can make suggestions to you for example
I mentioned that there is a difference
between add and copy add takes up a lot
that's a lot more bloat than copy does
and you should only be using add in very
very specific instances so we can kind
of look at the information that we get
back from the docker API
analyzing your images and give you some
recommendations on how you can optimize
your images a little bit more so it's
kind of a cool a cool tool it sounds
kind of funny it's a cool tool and what
I like particularly is kind of looking
at this average size layer and looking
at how I might maybe either break up or
reorganize the layers to make them a
little bit to optimize them a little bit
more so we have dried Panamax this image
layers and then Laurita IO all tools
that are related to docker either with
your own tooling or your own workflow
working with docker or in the instance
of dray a tool that will do other things
for you but uses docker containers as
the mecca
to complete those tasks for you and
again okay this is a sample application
template upon IMAX template or the
docker compose we've seen Panamax so
just a couple additional resources to
leave you with the docker hub is very
helpful if you're looking at adding some
containers to your project or maybe just
want to kick the tires a bit I have
never been involved in an open-source
community with better documentation than
docker it's really exceptional they do
an amazing excellent job so you can
check them out Doc's docker calm boot to
docker is that boot to doctor to i/o
Panamax we have our website if you want
to follow us on twitter we're at Panamax
io em and then CenturyLink labs is also
great like legitimately great not just
because I work there great but so we all
are engineers that have backgrounds
ranging from like HP pivotal tracker a
couple other kind of cool companies but
we all work for CenturyLink labs now and
any cool thing that we see with docker
will write about it on our blog and we
found it like it's pretty helpful for
people again we work in R&amp;amp;D so the
problems that we're having now are
probably problems that you'll have in
like a month or two and we've already
had to deal with figuring out how to
solve them and we've written down the
solution so please check that out I will
take questions afterwards if you want to
find me and just in the interest of time
to to kind of get us out of here so
thank you very much I hope that you have
at least learned a little bit about
docker if you do have any questions just
find me afterward and otherwise I'll
hand it back to you Alex
all right thanks Laura um actually if I
could just have you pick randomly a
number from 1 &amp;amp; 2 to 35 42 I think
that's the most common number that I've
ever got I'm sorry
I am 100% going to mispronounce this
last name so I am I apologize it's
Carlos fig water is that right that's
all right all right perfect so I'll grab
your information and you get a free
registration to go to Chicago all right
thank you all for coming and thank you
Morningstar for hosting us thank you to
the DevOps community for also pushing
out to you guys and also thank you to
Cedric for videotaping all right</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>