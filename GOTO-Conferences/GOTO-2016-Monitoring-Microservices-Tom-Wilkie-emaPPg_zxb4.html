<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2016 • Monitoring Microservices • Tom Wilkie | Coder Coacher - Coaching Coders</title><meta content="GOTO 2016 • Monitoring Microservices • Tom Wilkie - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2016 • Monitoring Microservices • Tom Wilkie</b></h2><h5 class="post__date">2016-08-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/emaPPg_zxb4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello please rate me on this app and my
name is Tomoyuki
thanks for the introduction thomas i'm
going to talk about monitoring Micra
services and yeah let's start with some
warm up actually everyone has done this
so you feel pretty warmed up so I'm
gonna skip that I'm running slightly
short on time so the thesis of this talk
is very much Mike services have changed
the architecture with which you build
apps and maybe you need to think about
different techniques to monitor those
apps when people talk about monitoring I
know I instantly go to a kind of drawing
nice time series style charts and what
I'm really here to talk about is maybe
trying to persuade you to think of
monitoring there's more than just time
series charts so I'm going to break this
talk down into traditional monitoring
visualization and tracing so let's start
with traditional monitoring your
traditional you know monolith maybe
looks a little bit like this
it's not a particularly interesting
diagram you've got some load balancers
you've got some application service
you've probably got some databases the
thing to note from this the character
characterization right it doesn't change
very often it's reasonably static
there's a small number of moving parts
and you probably maybe have dedicated
hosts or dedicated VMs for each of these
components you've probably named them
other people have covered the kind of
named them specially in you care about
them your Mike Rosario lots of people
have talked about this it's more dynamic
you're pushing you know maybe every
three and a half minutes at the very
extreme you don't really have a
prescribed technology you don't really
have a prescribed architecture you've
delegated a lot of the responsibilities
you know this is a good thing that
Adrienne covered in his keynote
yesterday you've delegated the
responsibility for the tools they use
for the languages they use for the
architecture of the subsystems to the
teams responsible for building them and
this is fantastic but it does mean you
know it's flexible it's
changing you can no longer rely on a
single static like monitoring system so
you know we've heard the analogy of pets
versus cattle I like this picture anyway
we'll cover it we'll skip over that one
so what you end up building for a
monolithic application is a big
dashboard like this this isn't our
dashboard I just pulled this off the
internet but if you look at the
application you tend to see these are
host metrics this is the hosts disk i/o
the hosts CPU these are host centric
metrics and I suppose the real thesis of
this section of the talk is in the old
world your your system the primary key
on your monitoring system was host and
in the new world the primary key should
be application or service so who knows
or has heard of Brendan Greg's use
method good someone I like this I like
simple easy to remember things it makes
it makes your job of like DevOps easier
anyway Brendan Greg talks about the way
to monitor a system is to measure the
utilization saturation and error rate of
every resource and whilst I think this
is useful especially for things like
capacity planning this is not what I
like to use and so this is a little bit
tongue-in-cheek please don't quote me on
this I think we should have the read
method and the read method is for every
service we should be monitoring the
error rate the rate of requests and the
duration I would want to say latency
really but Arielle doesn't sound as good
so so yeah you should monitor these
three things the primary key should be
the service and you really want to be
looking at these metrics in aggregate
you really don't want to be looking at
these metrics of an individual replica
of a given service you want to be
looking at these as on the service as a
whole and if you start measuring these
kind of metrics this will enable you to
have a lot more confidence in things
like your blue green blue green
deployments so how do we do this well
traditionally you would do something
like this it's a lot of code but you
basically declare some metrics in your
application you measure them and you
export them and so this is going to
require you to go out to all your
different services all of their
different binaries you've written and
instrument them in this particular way
and now one of the kind of theses we
have so if you do this sorry get ahead
of myself you end up with a nice
dashboard like this this is graph honor
which is running offer Prometheus
back-end and this is what we actually
use to monitor our service that we've
works and it's quite nice it does a good
job but there must be a better way you
must you know this when I referred
earlier to this kind of delegation of
responsibility but with a lot of
monitoring topics and this is going to
be a reoccurring thing you end up with
this kind of top-down mandate
everyone must instrument their services
in a particular way with a particular
technology and that's completely against
this delegation responsibility right
every team should be able to choose
their own tools to also operate their
services but it doesn't work that way so
is there a better way can we do
something that means teams you don't
have to mandate that teams use
Prometheus and I believe you can
I believe the platform or the service
you're running on should provide you the
metrics you need without you having to
instrument your application so if you
look at this is specific to kubernetes
but it works on many things if you look
at most platforms they have load
balancers in there there's one in cloud
foundry Julieta's has a cube proxy these
load balancers see all the requests to
all of your instances of all your
services and so why not add the
instrumentation there and then you get
uniform consistent metrics out of all of
your services and you don't have to do
this mandate this is something that
someone can do relatively easily so we
have we've worked an open-source project
it's really really early like we just
released our naught point two so I
definitely wouldn't run it in production
just yet but it's an instrumented
programmable load balancer it uses
Prometheus to store its metrics because
we love from Ephraim II theist just got
accepted into this CNC F by the way
which is awesome news CN CF is the found
the foundation that's also owns Cuba
Nettie's as well so yeah
we think this is a fantastic approach I
would do a demo but I don't really have
time so I'm going to skip over this one
I've got more demos later I'd encourage
you to try out flux I think it's pretty
cool
that's really all I've got to say about
monitoring you need to you know to
summarize right in the old world your
primary key was host and in the new
world in the micro services world your
primary key really needs to be serviced
and then there's different techniques to
doing this but the current state of the
art is instrumenting individual binaries
and exporting them to something like
Prometheus the new you know I think we
need to move to a world where the load
balancers in your platform give you
these kind of metrics so you don't have
to do this mandate so that's monitoring
visualization this is actually what I
work on so I'm going to spend a little
bit more time working on this talking
about this it's a visualization we
talked about this world where your
application that the topology and and
the architecture of your application is
rapidly changing so how many people have
ever kind of sat down and explained to
someone what their application looks
like on a whiteboard I'm gonna kind of
hope all of you right and how many
people were wrong when they explained it
I know I was right so this is a real
problem you have the keynote this
morning talked about this kind of
institutionalized knowledge you have
people that were taught this is what the
application looks like and then they
repeat it and the application has
changed between the time they were
taught and the time they repeat it and
they don't know about that so wouldn't
it be nice if you probably notice a
theme here wouldn't it be nice if there
was a tool out there which drew you a
map of your application and on top of
all of this didn't need anyone to to
kind of annotate or declare you know if
it kind of just went out there and
discovered what the topology of your
application was now the reason I'm keen
on this is because that's exactly what
I've written it's open source it's
written ago it's primarily focused on
docker and kubernetes but we have
integrations with me sauce as well and
this is it's called we scoped the idea
here is it draws you it's kind of a like
a bit like a graph database it goes and
scrapes all sorts of information about
the system and renders it in these nice
visually attractive topologies we call
them
so this is neat what I really want to
talk about here is why this is a
difficult problem from a technical point
of view to do so getting the getting the
notes that's easy right docker PS you
know you can do PS in your operating
system to get processes get pods from
premiere from humanities everyone has an
API to get the nodes but it's getting
the edges which is difficult there are a
couple of technologies for finding out
the current TCP connections so all the
edges in this in this app are TCP
connections so the technologies we have
so contrac which is exposing the tables
used to do like map mapping as far as I
understand and really know that the
kernel technology behind that extremely
well contract can give you a live stream
of events okay this is great this will
tell you when connections are created
and destroyed it's kind of hard to
interpret there because it's just IP
addresses and so you need to join this
with containers which might have unique
IP addresses or if you're all familiar
with docker containers can share Network
namespaces so can share IP addresses so
you might need to specialize a bit you
might need to look at the port and know
that this containers listening on this
port and this containers listening on
this port but you've also done another
approach inside the proc file system
you've got the TCP tables and so you can
go and look at that and that will tell
you what FD is communicating on what TCP
connection what file descriptor which is
great but now I also need to scrape the
proc file system and get the mapping
between processes and file descriptors
and then I need to get the mapping
between processes and containers and I
need to do with this big join and to get
it all working ok so that sounds
plausible that sounds doable it sounds
complicated but not complex but it
actually gets a little bit harder so
you've got this this is going to be a
Venn diagram and I haven't seen many
Venn diagrams and many talks there
should be more so yeah this is all
connections that exist in the system and
these are the ones I can straight from
proc and I can't scrape all the
connections from proc because reading
from the proc file systems expensive so
I have to do it you know I have to rate
limit how much I can do I'm basically
going to waste all my CPU just
monitoring the application I'm supposed
to be running so I have to do it
periodically which means any short-lived
connections that occur in between my pea
I don't see okay that's fine I'm gonna
use contract that's going to give me a
different set of connections it's some
overlap there's going to be some bugs in
contract which is really annoying where
it tells you about connections that
don't exist I just got rid of one of
those yesterday so I'm really happy
about that there's still one left it's
gonna have some overlap with pop but
it's also gonna let me know it's also
not going to let me know about all these
connections down in the bottom right and
these are connections that might be
coming from processes in the hostnet
namespace
okay I can't disambiguate those to the
right process or to the right container
so this is things like connections the
docker docker
daemons making I can't figure out what
to do with those and it gets even harder
right because we've got these
load-balanced connections you know
modern software load balancers will be
doing IP tables based routing so the
kernels the thing that's actually doing
forwarding of the packets and these
these tend to go to a virtual IP address
which doesn't really exist which is
great if you're trying to monitor edges
because you see these IP addresses which
aren't real so now you've got to
translate these fake IP addresses these
virtual IP addresses into real IP
addresses and what's more mean there I
could draw a lot more circles under here
I'm just trying to show you why drawing
these edges is difficult anyway I could
go on about this but I'm not going to
I'm gonna do a demo instead so to show
you there's nothing up my sleeve I've
got a completely empty box this is all
running locally on a single VM on a
docker machine VM I'm gonna run an
example app now I normally don't like to
use a big shell script to do my demo but
this is not actually that important what
this is doing under the under the things
it's just running some containers and
these containers talk to each other
there's a load generally generator in
there so it does something and these
containers have like a Python app I've
written some elasticsearch some Redis
some nginx you name it and okay it's
really obvious to everyone right what
that does no I could you know get a
whiteboard out and draw it but no we're
gonna use scope this time so scope
launch it should be that easy to run
software and now I'm gonna get the UI up
so give it a sec to to form its scrape
for the system as you mean worst it does
that and there we go
spoke scope has gone and scraped this
app this app hasn't been annotated it
hasn't been modified to run on scope and
scopes managed to figure out who's
talking to what and you can clearly see
a kind of delineation of you've got a
low balance you've got a load generator
a load balancer some application servers
that are really just doing routing and
then a bunch of micro services in the
bottom that really don't do anything
it's just there for show but so this is
this is the basic idea now one of the
features we're just adding to scope in
this sprint should be released well it
would've been released yesterday if I
wasn't here is such so we can do things
like please tell me what's written in
Python and we can see that those four
apps invoke Python in their command line
or we can do I mentioned there were some
nginx so what's written in engine X
about the two front ends okay what about
IP addresses we can go 10.30 2.0 11 oh
that's that front end there we've got
really good if you like I who it just
like comes up with these things
anyway so that's search other stuff we
can do where we can click on a given
node in the in the topology and we can
see more information about it and we
start collecting basic metrics we start
collecting CPU memory
we've actually got a really cool plugin
for scope which injects a kernel filter
this little the EBP F's into the kernel
and starts parsing HTTP headers in the
kernel and emitting like request rates
and error rates and things like this so
similar to what we can do with flux but
in fact without even a load balancer but
that's kind of really really early
experimental stuff so i'm not going to
show you that because it probably won't
work but some other stuff you can do so
we know this is an app let's see if we
can get a get some logs out of this
machine yes
oh it's or error okay that's interesting
but we can get a terminal we could this
is just doing a docker attached maybe I
don't want to dock or attach maybe
actually want to poke around inside
there we've got a interactive terminal
that's stopped working No
this is what happens when you use
unreleased software there you go
so the whole idea here is that you can
visualize the app but you can also
interact with the app you can also yeah
you can also click on it and just delete
that one because maybe we don't want it
let's stop it and then why did it not
stop again
it stopped and now we can delete it
there you go it's gone so this is the
kind of stuff we're trying to do a scope
we're trying to show you what's going on
in your application now this is perhaps
a bit too much information what we
really want to see is a more of a kind
of higher level overview or what we can
do is group these containers together
and and by certain metrics by certain
metadata so we could for instance take
the DNS name of the container and maybe
that's the thing you're using to kind of
indicate what service they belong to and
now this is hopefully the kind of thing
you might draw on your whiteboard you
know we're not showing all the different
replicas we've kind of aggregated the
nodes up and if you ran this against the
Kuban eTI's cluster you could do the
same thing you could view by actual
service because cuba Nettie's has a
concept of a service and so on this is
where I quite like scope and scope also
understands the relationships between
all the containers not only in edges as
TCP connections but also kind of it
understands that inside this container
is a process so I can go and see
information about that process and I can
see it has 21 open files and what pit it
is and you know it understands that that
process is running on this host and it
really understands the whole topology
how connected everything is on the
computer and you can even get a root on
the computer so scope is also a rootkit
yes I've got to fix that keyboard focus
thing I am route excellent so scope is
version or point 14 so we're still not
you know we're still not released you're
still not on one oh it's open source you
can go and try it out we're really
interested in feedback and obviously we
have to do some security work on it so
there we go I think that's pretty much
what I want to show about scope it works
it is clustered it supports all sorts of
interesting stuff and it we just
released in the last release plugins and
this release is all about searching
kubernetes so moving on how am i doing
for time if you want to we have a hosted
version of scope this is what we're
hoping to sell and make money one day
but that's a bit a long way off but in
the meantime it's just the one github
and you can come and talk to me on slack
if you want to so that's visualisation
the whole idea here is your app is
changing you know you've delegated
responsibility for the architecture to
your team and you really need a tool
that will visualize that architecture
and and help you have like a common
language across all the teams and that's
visualization so tracing so this is this
is now very much you know we've gone
from alpha software to betta software
and now we're going all the way back to
prototypes this tracing distributed
tracing is not a new topic it starts
with the idea that when you had a
monolith you could do a profile this is
a go profile and you could basically
that gives you all the information you
need to debug and and and figure out
performance issues in your app but now
that any given request is probably going
to be handled by multiple micro services
you know tens of micro services you
can't go and profile all those micro
services and kind of figure out where
the requests meant it's time so you end
up with this idea of distributed tracing
which does exactly that it traces single
requests as they traverse through your
micro services app and draws you a
pretty flame a frame a flame at graph so
this is pretty cool the most popular
version in the open-source world is
called Zipkin it's modeled on something
that Google called dapper like most
things Google wrote a paper about it and
someone built an open-source version of
it and it's really cool it works really
well but one of the problems I touched
on earlier with monitoring right is
well I'll come back for that I just want
to talk about some of the literature
that Perez the Google paper Zipkin I
don't think has a paper the one I'm
really interested actually is the second
one back and this is a little-known
paper by Microsoft Research in Cambridge
UK where they did distributed request
tracing but through operating system
instrumentation so instead of the way
DAPA does it they kind of modified the
Windows kernel and got as much
information as they could out of that
and this is what gave me the idea for
this so how does how does dapple work
why is this difficult the challenge is
you've got an incoming request you can
time that you can measure that that's
easy the challenge is how do you
associate that with outgoing requests
how do you work out this causality these
services are black boxes right you don't
know what's going on in there and the
solution pretty much everyone's gone
with so far is that you inject some
unique ID into your incoming requests
and you propagate that you you modify
all of your applications to propagate
this unique ID okay and what was I
saying earlier about about micro
services and monitoring you you really
don't want these top-down mandates
please go away and modify all your
applications and what's going to happen
is some teams are going to be releasing
every few days some teams are gonna be
releasing every day some teams actually
probably have released this thing and
left it there you know not everything
has to be revved every minute and so
you're going to get this this staggered
rollout of this distributed tracing or
even not at all some teams might be busy
some software might have been disowned
in your organization yet it's still
there and it still needs to be
instrumented so you get this problem
where you get an incoming request to a
piece of a piece of code that hasn't
been instrumented and something it's
just a black box you don't see what's
happening past there and this really
hampers the kind of rollout of
distributed tracing in an organization
so again I've said this for every single
topic can this be done without modifying
your application and I think it can
obviously so the idea here is this is
obviously not how a computer works by
the way your application talks to the
kernel it does system calls it does
system calls to do I owe on sockets it
the system calls to connect to other
to connect to other computers so the
kernel provides you with a mechanism to
intercept those system calls
it's called P trace it's who's used s
trace that's all
you know I'm talking about so can we
intercept these system calls can we
build our own little in-memory data
structure of which thread which process
is writing to or reading from given F DS
which F D represents which IP address
which port you know and who's on the
other end of that IP address in port and
can we use this to infer causality this
is kind of the question and if anyone's
paying attention the obvious answer is
no because things like asynchronous you
know
nettie style reactor based architectures
are gonna are going to really
disassociate your incoming request IO
from your alchemy request IO normally is
going to do it all on the same thread or
on a small number of reactor threads or
something but actually my argument is
there's a lot of applications that don't
use that there's a lot of applications
that are a lot simpler that still do a
thread per request and some of the new
stuff in the Linux kernel makes doing
threads per requests a lot more
performance than it used to be so if
you're doing threads per request which I
believe is some subset of applications I
believe this works and I'm going to show
you because I have a demo so this one's
a little bit less reliable because I say
this is a completely completely
prototype piece of software so I'm just
going to delete everything and just to
show you that that's worked and show me
that's worked yes can everyone see what
I'm doing good I didn't actually hear
response but that's fine so I'm gonna
run a slightly smaller demo app this
time just so it's a little bit more
understandable and then I'm also gonna
run the scope to show you what that demo
is doing
okay give scope a second to scrape
everything can show you what it's doing
this is where of course it will go
instantly wrong we won't see anything do
to do to do oh there goes a really
simple app here we've got a load
generator again it's the same load
generators in the previous example we've
got a little Python app again the same
Python app as the last example but this
time we've only got two services an echo
server which is really good because you
send it a request and it sends it back
to you and a quote of the day server
that goes out onto the Internet speaks
the actual quote of the day protocol
which is like a proper protocol IETF
protocol and gets a quote and then and
then reply so the app gets a quote it
echoes it back and it sends it back to
the user to the user which is a load
generator in this case so let's start
the tracer and see what happens tracer
launch okay so that seems to have worked
you can see the tracers running there
we'll go to the port for the tracer okay
so this UI obviously isn't that good but
it's not really about the UI I'm going
to just demonstrate that we can do the
causality thing then I'm going to
demonstrate that we can join connections
between two processes instead of
incoming and outgoing we can join them
between two processes and then I'm going
to just let it run and see what happens
so let's start tracing the app container
this maybe works 50 percent at the time
well we'll let it get another trace come
on who's using the Internet there we go
so we can see here actually s use one of
these this is easier to see we can see
an incoming request and we can see we
found two outgoing requests for that
incoming request now again this apps not
been it's not been instrumented in any
way it's not been modified in any way
this is just using P trace to find out
what's going on in that app and so we
can see these are currently just IP
addresses but we can at least see an
incoming request has caused two outgoing
requests so let's stop that let's go and
try this quote of the day server can we
also do it for something written and see
the court of the day server is just a
really minimal pthread see library okay
yeah we've got an incoming request
that causes a single outgoing request to
some random IP address on the internet
and now what happens if i trace both of
them at the same time can I join the
outgoing request from the app to the
incoming request from the quote of the
day server without having any kind of
propagated unique IDs and the answer is
maybe there again you can see this one
here this is an outgoing request from
the app to the quote of the base server
which is then gone to a random IP maybe
this one will be clearer there you go
code with add a random IP it works this
is only on a single machine but I'm
quite pleased of that so one of the
interesting things here you can see some
requests are quick and some requests are
slow so can we figure out with
distributed tracing why that's happening
if we click on a slow request we see
it's always in the second service what's
the second service I wonder so if we go
and run the echo tracer
as well we should also start seeing this
here ah we've now managed to join the
outgoing request from the app to the
incoming request of the echo server we
can see the echo server doesn't actually
do anything with it it's good to know
but then maybe we can see that it's
always the echo server that's being slow
yeah it's always the echo so it's being
slow great good to know
so that's distributed tracing with P
trace one of the things to note about P
trace is when your P trace attached to
an application it gets really slow so we
this technique won't work in production
yet but as I touched on earlier there's
these EB PF filters that you can inject
into the kernel and pretty much hook off
anything in the kernel we use it part
HTTP headers in the kernel to get the
get the metrics I also believe that I
haven't done this yet that we could use
the EBP F filters to do the same thing
here and actually have a performant
version of this kind of no application
modifications tracing and for the for
the instances where you are using
something like netting or some kind of
async i/o I'm kind of hoping that we can
also use a little bit of instrumentation
or maybe even some like language level
instrumentation if it's not completely
agnostic to to get those edges as well
to get those a causality so let's kill
that because it might kill my machine
that was distributed tracing this is
really prototype software I kind of this
is more of a hobby than something
endorsed by weave works but if you think
it's interesting I'm looking for people
to work on it with me I'm looking for
some free coders so here please let me
know that's tracing the idea here is you
really really need distributed tracing
if you're going to really understand
what's going on inside your application
when you're using micro services and I
believe we can do that without
application modifications so hopefully
I've kind of showed you the three kind
of what I see is the three tenants of
monitoring a micro services application
which is your traditional monitoring
where I said what you really want is to
change your primary key from host to
service and if you're clever about where
you collect that data you could do that
without this top-down mandate
visualization which I think super
important when the architecture of our
application is constantly changing and
new services that are being launched and
turned down on a daily basis and again
you can do this without application
modifications and without annotating
your applications and tracing where
maybe you can do it without modifying
your application you know that ones yet
to yet to be seen yep obligatory we're
hiring up we've works actually just this
morning we announced the big series B we
raised 15 million from Google Ventures
so we're pretty happy about that and
yeah questions I thought I'd try and
finish early because it's lunch and I'm
hungry good and perfect timing because
my Apple watch just told me to stand up
oh and by the way there's the links I'll
put these slides online they're already
online somewhere but I'll put the
updated versions online and please write
me so a lot of questions I didn't have
is that a good thing let's see you'll be
the judge of that I guess so your
visualization is fine as long as you
have maybe dozens of microservices but
what add you know bigger scale hundreds
does this visualization if you know
small groups still work or would you
that's a great question um I don't know
we're not the the journey we're trying
to target with scope is a developer
working on their laptop and maybe moving
initially through to like initial
production stages like scope as I said
it's it still be too software it's still
not point 15 or something so yeah I
don't know we're actually just starting
to tackle some of the problems with
scale because we use scope on our own
service and you were obviously running
more than like 10 containers now and
yeah we run into a few problems we
that's why we added search for one we've
done loads of performance work so you
can just still render everything and
we're adding list views that's why we
added the grouping functionality so you
can time to take all these containers
and D dupe them and filter them you know
we added a whole bunch of filtering
stuff in the latest release so you can
just look at the system you organized
you're interested in but yeah like it's
still you know it's a open question as
to whether this technique will scale to
ten thousand containers what about if
you have an architecture like we talked
about earlier in Fred George's talk
where you have a Venice well you have a
message boss exactly because here you're
talking about connections between
individual individual nodes and now
you're sending messages and doesn't that
kind of that obstacle you see the flow
of information somewhat intentionally
some might say yeah I mean I personally
had some experience with these message
bus paper-based architecture it's not as
much as I have with the non message bus
based ones and I prefer the non message
message bus based ones but I I guess the
the the company line would be we have a
plugins architecture and if you can find
a way of expressing the relationships
between your services you can feed Skype
that data and it will render it for you
yeah and there's nothing stopping you
from maybe making a plug-in that would
support something like caf exactly yeah
yeah okay I mean is you know I think one
of the whole points of the message bus
makeup based architecture is that aren't
kind of inherent relationships and it's
very much more dynamic so I don't know
yeah I mean that's that's a unsolved
problem as well but a good question so
you and sure you showed us how to run
this locally on your machine yep how
would you install it on a real Network
oh wow well I actually just wrote the
docs on how to do that like a couple of
days ago but if you're using Cuba
Nettie's
you would do to do to do site
installation instructions installing so
he go like there's instructions for how
to install it on pretty much everything
if you've got a big Cuban nasties
cluster it's like one command if it's a
mesosphere cluster then it's in the
mesosphere store that you saw yesterday
in fact you might even seen the logo if
you're paying attention if you're using
docker swarm you use the same commands I
wrote and you just run it multiple times
on each host and what's the other thing
we support ECS we've got a cloud
formation recipe I didn't write that I
don't know what that is and yeah
basically there's a way of doing it
actually I was talking to KC about how
to get this running on Cloud Foundry
which we haven't done yet but I'm sure
we'll do like it's super generic it just
traces TCP connections between processes
so it shouldn't work on pretty much
anything so what about non docker
people don't use docker rocket actually
yeah I was working with a chap called
album although I don't know what his
real name is that's his Twitter handle
on getting it working on rocket that's
working progress okay but there's no
again no reason why it can't do that
again actually scope runs quite nicely
on the Mac where you don't have a docker
container run time so you can actually
compile this on the Arwen and just just
run it and it works fine because it's a
goal because it's going okay but yeah
like the idea between the docker
packaging is just to make it easy so
what about processes across several
networks you showed us on one machine
here but does it work seamlessly if you
have okay yeah quite a lot of work went
into especially like an IP address can
mean a different thing on one computer
than it can on another this is what I
was kind of talking about with the IP
based load balancing so a lot of works
gone into making sure we can figure out
what end the connection works on on two
different hosts fun with IP tables yeah
I mean nightmares and lost sleep with IP
tables is more but yeah so yes it should
like if you're working on very large
networks as I just refer to the first
question like scopes targeted at you
know small deployments right now you
know we'll get there eventually thank
you Tom thank you how much
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>