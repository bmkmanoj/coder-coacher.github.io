<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2013 • Following Google or Don't follow the Followers, follow the Leader • Mark Madsen | Coder Coacher - Coaching Coders</title><meta content="GOTO 2013 • Following Google or Don't follow the Followers, follow the Leader • Mark Madsen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2013 • Following Google or Don't follow the Followers, follow the Leader • Mark Madsen</b></h2><h5 class="post__date">2014-04-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-h-ccuUiv1w" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody this will be a very fast
session because i only have 109 slides
seriously i only have 109 slides this
has been through a lot of title changes
but essentially it's about persistence
performance speed and a number of other
things I pulled back some of the
technical detail but I did include a
list of references at the end of this
all of the papers and things if you
actually want to read up on some of the
things that I've said that I'm using to
back up the outrageous statements that
I'm going to be making most of which are
pretty outrageous so carry on just a
quick intro about me I've been a
developer I worked on unix kernels and
database kernels and porting databases
and I was an application developer and
I've held every job in IT I was a
janitor in a data center and I've been a
CIO and a CTO and the interesting thing
is that in doing that I've been able to
make mistakes across the entire breadth
of an IT organization and I've got
really really good at that particular
thing so I did become a CTO which was
great because then I could tell other
people what to do because I got tired of
the developer BS because developers
don't talk to database people in the
database people's BS with not talking to
developers and everybody's always
talking across each other without
understanding the underlying data
principles behind things and so what I
discovered then was that nobody in the
business understands anything and being
a CTO just means different people argue
with you so I've done a lot of stuff one
of the things that I'm very interested
in is the history and patterns so I'm
going to start this with a completely
non technical topic for about 10 minutes
which is a brief history of data storage
and retrieval which is is only technical
in the theoretical sense because if you
look at the problem we've been talking
about information overload and scale
problems well for a long time we don't
really have good records before about
1550 about the problems of scale so so
many books we don't have time to read
the titles which is sort of like I can't
get past
the first page on Google so we'll go
back to the beginning which is when when
writing was was created right so we're
talking about sedentary civilizations
we're talking about approximately 5,000
years ago and we used to use these
counting things we use counting sticks
and stuff like this and these are sort
of like coins each one means something
it's not abstract math and it's not
symbolic but once you invent writing
then you have a different thing because
now you no longer have this stuff which
you can lose this is actually a contract
you would put the recordings in the
shapes and the sizes dictate how much
and for what kind of product and then
you wrap them up in this thing so that
you have a little encryption envelope
over it so other people can't snoop on
your contracts and it's it's an
interesting technique now we did invent
writing so the first information
explosion was all about these these are
clay tablets Sumeria Mesopotamia all
through the Indus Valley and spreading
throughout the whole region they're
about hand size they're about this big
so you can see how much you can fit on
one of those using a pointed stick to
make these marks in this stuff and this
is actually I did learn to read a lot of
this stuff a couple of years ago just to
be able to interpret it but what you're
seeing here is really important to
software developers it is beer so we're
talking about a beer tally here and
we're talking about the amount of grain
that goes into it and other things and
so you've recorded all of this in an
abstract representation of letters and
numbers which is great now what happens
when you start to get a lot of these
things well first of all you know you
look at it you have storage and
retrieval and communication because this
stuff's heavy this is actually a letter
that people would mail and the letter
comes in an envelope and sometimes it
doesn't all fit on one page so you have
a little second page and it's still
recognizable today and it's in its basic
structures but when you get a lot of
them you need something you need
metadata metadata when you have lots and
lots of those tablets is about the
tablet so you're now creating tablets
about tablets and
categorizing them that the library at
Ashurbanipal which was one of the
biggest had different sections where
they organized information into
different units and really it was sort
of like classifying data and then
putting it all together and it's very
much like if you tried to deal with one
of these it's a lot like dealing with
HDFS because HDFS doesn't really have
any metadata and I don't count each
catalog it's a very primitive thing it's
sort of like one of these which is that
these and the data can become disjoint
and lie to you and if you've ever used
hive on top of data stored in HDFS you
understand what can happen because you
can count the stuff with the program on
the one side and you can query the data
via hive on the other side and you'll
get two different numbers because the
schema is sort of optimistic now what we
ended up with is some interesting things
they kept these in baskets so when you
have a basket full of these it's not too
bad when you have many baskets it starts
to become a problem so they drilled
holes in the tab let's put a little
papyrus tab on there and then wrote
things on papyrus so we actually had
tagging infrastructure and focus on amis
back then and eventually it got even
more complicated and we started to
create tablets about what was inside the
tablets not just the tax receipts are
over here and the barley production is
here and the beer dispensary is over
here it was things like synonym lists
and breaking stuff up and keeping more
detailed and deeper records and you'll
notice these things are kind of big now
because we're worried about what's
inside the documents as well as just
where the documents are because we're
dealing in aggregates we're not dealing
in one clay tablet for one farmer in one
field we're dealing with all the clay
tablets for all the farmers in all the
fields because they're trying to start
doing forecasting we're trying to use
the information to figure out who's
dodging their taxes and not paying any
money and so we start to create this
kind of stuff there's some seats over
here if you need it see
so what we've got then is more metadata
and more interesting things and we
discover some stuff about clay tech as
we're looking through all of these
little tablets one of the interesting
ones is some of the limitations that you
have very much like nine track tapes if
you ever worked with them which I did a
long time ago or punch cards you know
those things are all right once read
many you can't you can't write them more
than once kind of like HDFS is an append
only file system so what you see right
here is that when somebody makes a
mistake they have to chisel it out and
so it's not very effective updates are
expensive just like in databases now one
of the things about how they they
maintain this stuff that I find very
fascinating is these tablets also have
edges this one doesn't but that's called
an insipid and you can write on the
edges and somebody doing a PhD
dissertation discovered some decomposed
wooden shelving with a whole lot of
these and they were all inscribed on
three edges on one edge you had the type
of grain that was produced on another
edge you had the person and on another
edge you had the the year of harvest
what you essentially had was a
multi-dimensional OLAP cube they were
creating three-dimensional hypercubes to
index the data because then you could
rack these things up and somebody asked
a question like what was the barley
harvest in this district last year the
year before and the year before that so
that you could see if they were dodging
taxes or do a forecast and the only way
to do that efficiently is to have these
things organized and structured laid out
in sequences so they're storing these
things in sorted order now oh it this
goes on for a long time we have
thousands of years of this before we get
to paper the invention of paper tech
started with bamboo pressed paper we got
to papyrus and eventually to scrolls now
it's lighter right there's a lot less
atoms there a lot more portable it's a
lot denser storage meeting because you
can write much smaller on it and store
things bigger so capacities goes up
information density goes up and we end
up with the first real libraries that
include things that you might want to
read but also we need new metadata
techniques when information density goes
up by an order or in its case two orders
of magnitude you know the the atoms per
bit changes drastically and you have
things like this that require headers
and footers but this is very much a
serial scan based system you can't
random access a scroll and so we also
discovered some things about
impermanence you know just like disk
drives that fail periodically is that
whenever there's a revolution because
people don't want to be paying their
taxes anymore they burn this stuff down
now when you started a fire and it was
full of clay tablets it made them
permanent because it baked them in the
world of paper there was a little
problem of instability so now with
scrolls you have continuous readings
start here and here with codices and
books you have random access now the
interesting thing is if you make them
big like this and the random access
until you have invented some new
technologies for indexing like an index
or a table of contents or page numbering
until somebody invents those techniques
these things are not much different than
a scroll but once they invent them
suddenly we have a way to go right to a
particular place in a book we can begin
to record things differently we can
record mathematics and tax receipts and
a lot of other stuff we kept evolving we
moved from handwritten scrolls and
handwritten codices to printing so we
got full high-definition RGB graphics
higher you know smaller form factors we
got portables you know books used to be
this big now there are little chat books
and it keeps going on and on the
technology gets better until eventually
we were producing so much stuff that the
things that were printing become more
important in the printer and we're at
that point today we're at the point
today where the printer we're focusing
on technology but the printer is not as
important as what its printing the data
and so if we move forward into the more
interesting times the
right we go to the Elizabethan era and
now we've got all of this stuff perfect
copies we were creating topical
catalogues we've standardized fonts
nobody realizes how important this is
but when you were writing Latin there
was a priestly font there was an
aristocratic font there was a more
plebeian font and these things could not
be read the same and so they were
incompatible so you could write the same
letter in three different writing
schemes and it was like doing episodic
versus ascii versus unicode and so they
standardized these things so that there
was not a problem that took a long long
time and they began to deal with
taxonomy because there's so much
information we now have to figure out
how to organize and structure and store
it we go from eight million books and
fifteen hundred to two hundred million
books in 1600 so on that that time span
and of course commoditization and when
you have that you have overlooked so we
end up with even better stuff we've got
title pages and kala fonz and tables of
contexts and finally get to the Georgian
era this is the era of of Natural
History this is where things in my mind
get really interesting because now we've
got a big dispute between Linnaeus and
Buffon and nobody knows who Buffon and
does anybody here know who bouffant is
yes you get the prize I'll give you my
phone later so that's bouffant right but
who cares about Buffon well he was a
really smart guy he didn't believe that
species were fixed you see Linnaeus and
we use the Linnaean taxonomic system for
plants and animals today species you
know genus species designations his
taxonomic classification is fixed every
time you have to insert some new species
you've discovered into the tree you have
to rebalance the tree in a database
that's not too bad on paper it's a
nightmare unfortunately boo fonz method
was a faceted classification scheme name
value pairs is essentially how it worked
it's very flexible when you do it that
way but the problem is that the
technology can't afford that flexibility
because paper
when you have to rewrite to the index
every time you add new facets and
rewrite the things that point to it to
the actual data become very expensive
but his was very bottom up because he
knew that species were different and
species were changing all the time
whereas Linnaeus believed God created
them they're just like this and nothing
shall ever change and once we've
discovered all of them and there can't
be many more than her in Europe because
Europe is where everything started so of
course you know that this debate went on
for a long time he won bouffant lost and
we moved on and then in the Victorian
era you know now we've got steam driven
printing the Enlightenment massive
amounts of engineering and specialised
books on everything the perfection of a
stereotyping process and we end up with
this cutter the cutter classification
system for books and technical manuals
1882 bottom up it's a faceted
classification system tags it's a more
flexible structure than your standard
Dewey Decimal System which is the other
person on the other side of this
argument and he's saying well and so by
the way his name is Melville now
normally Melville is spelled Emmy lv i
ll e he took off the l on the e because
it was more efficient to write his name
so he was an efficiency expert this
that's actually true and so static
structures right the dewey decimal
system gives you numbers and the numbers
do not d reference to a book whereas his
system d references to a single title on
the shelf his does not his takes you to
a shelf and then you have to do a scan
across that shelf it's like reading a
page in a database you know which page
things are on but you don't know which
row it is until you've read all the rows
and the thing is this is static you
define it once you go to the bookshelf
and you throw new books on you don't
have to worry about where on the shelf
to put that book whereas in his system
there's a sequencing and an ordering and
so each thing has to be inserted now
when you take into account
this and the problems of steam driven
printing they were solving all sorts of
problems about ingest and consumption
simultaneously and this one lost in this
11 despite the fact that this one is the
better system and so you end up with
just like Linnaeus and bouffant a
top-down rigid taxonomic schema one and
the same thing happens in libraries and
so why did they win well Linnaeus versus
Buffon it was the limitations of paper
and it was the fact that good enough
wins the day you know this is good
enough for us to get our job done and
share things in an era when it might
take a month for a book to travel
between two cities with some new
information in it everybody's taxonomy
is get out of sequence it's a
replication problem when you have a
replication problem and you're trying to
work on scientific classifications you
need something that's going to remain
stable you can't have eventually
consistent doing biology and so that's
why he won if you look at at the cutter
classification system versus versus the
Dewey Decimal System it wasn't solving
the problem you think it was because by
that time they were producing so much
data that it took libraries longer to
shelve books than the rate of inflow of
new books and so the efficiency expert
figured out how to best shelve books the
fastest way possible so librarians could
get around to helping you find the books
in the library rather than just
constantly loading the stuff and letting
you figure out how to get there and it
also enabled some self service because
if you knew the classification scheme
here or here you could find the
information you were looking for you
could self-serve and so pragmatism being
pragmatic about this total set of
problems you're trying to solve is
important in the library system one was
not pragmatic because you had to change
so much stuff every time and the
technology didn't permit it the same
thing with bouffant bouffant losses for
that same reason it's not practical
and so that's where these things got to
now history's always the same these
patterns repeat and repeat and repeat
top down versus bottom up which is
essentially rigid schema versus flexible
schema do you give people autonomy which
means things can become out of sync
without mechanisms to maintain that who
controls it is it hierarchy versus
network all those tax autonomies and
library classifications are tree
structured whereas all of the bottom-up
faceted classification and tagging is
networks and so you've got this network
hierarchy kind of a problem and power
versus ease it's powerful to have
something which is network oriented and
flexible but it takes a lot of effort to
use it and so these are the kinds of
things you're making trade-offs in every
engineering decision and so this teaches
us a few things you know information
requires schema it requires changes when
scale changes when the information
density from clay to various types of
paper and Scrolls to codices to books
and the rate of increase of that that
changes organizing principles because
the old system was designed for an order
of magnitude simpler work and that's
where we are with databases and things
today storing and managing data and so
at some point you're going to create
enough stuff that it's going to tip and
the problem will no longer be production
which is oltp which is transaction
processing which is what a lot of us
here are dealing with application
development and it tips to the other
side data consumption in our case and
when that happens then you really have
to focus on dissemination and
consumption and how you get data back
out of these systems and so first you
record then you deal with the other side
of the coin now this has gone on for
thousands of years in each technology
regime change there was a and one to
several orders of magnitude increase in
information density and that's when
things get interesting
that's when we get to this this focus on
production to consumption and so to
repeat the grand cycle which is we
create a technology it enables us to do
really neat new things then we have to
come up with methods to cope with this
stuff and once we've come up with those
methods like libraries for example or
card catalogs then we can take advantage
of what's out there and use it and then
that creates the possibility of new
things which creates new technologies
which feeds right through if you look at
the database industry that's exactly
what we've seen and this is what leads
to big data it's just that in previous
versions big data wasn't digital so I
love this quote the most amazing
achievement of the computer software
industry is its continuing cancellation
of these staggering gains made by the
hardware industry so I'm going to take
us through just a little bit of scaling
history question why doesn't your
database scale who's having scalability
problems well why doesn't your database
scale the the problem of storing that he
said is normalization and taking the
data that's coming in from trades
breaking it out storing it that takes
effort and then pulling it back out and
having to piece all of the things back
together I mean anybody else problems
performance I would thought somebody
would just shout out relational
databases suck i'm kind of disappointed
in you guys and so which leads me to you
know some things and and that actually
is is a complaint not so much about the
relational model but about how sequel
was implemented with the relational
model which is very different SQL and
relational model or two different things
they actually came about at different
points in time but we confuse the two we
confuse the API in the system that runs
it scalability is a really challenging
thing and that gets us to a lot of
hipster which is the the
Silicon Valley and yes I come you can
tell I'm wearing a formal Silicon Valley
tuxedo here I can't get my sequel to
scale therefore relational databases
don't scale therefore we must use no
sequel
now that may be true when you're trying
to build a transaction system but it's
probably not true when you're trying to
get the data back out there are two
problems that work here one is
transaction and serving the other is
query and analysis so let's look at a
little bit of history where did we start
so I started building applications when
we built them on the same machine and
then and then we separated them when we
made a database server because many
computers became cheap enough that you
could run one machine for a database and
put all your application code on the
other and there were fewer conflicts and
multiple applications could possibly
connect to the same database early on
one database one application and that's
where we are with a lot of no sequel
stuff today and there's a reason for
this the reason is that no sequel has
gotten rid of logical modeling and the
physical and logical model are the same
thing they've recup 'old something that
in every prior instantiation going back
through time we decoupled and that's a
problem when you're organizing your
organizing principle in your physical
storage model are married you have tight
coupling and when you have tight
coupling your code is going to break a
lot it's going to break because things
change and that's one of the key
problems that we have yet to work
through because everybody works on the
easy 80% like getting things to scale up
and then starts worrying about things
like consistency and that's exactly what
we were doing back then the first time
we put two applications on the same
database realize the database needed to
change now I've got an optimized
physical path because that's what no
sequel databases do they give you an
optimal physical path to do only one
read for this thing and one right for
this thing rather than the normalized
problem of six different reads and six
different rights which slows down
performance and creates scaling
bottlenecks but when another application
tries to read that now you've got a
problem because it's not optimal for him
so somebody pays so we mucked around
with this stuff a lot and to scale it up
we started adding application servers in
part because the memory limit
shins here each database connection when
I used to work with Oracle version 6
took approximately two megabytes so a
sequel pipe from each application to
hear did that but you know these things
aren't all active at the same time
connection pooling so we're using an app
server and connection pooling to reduce
that part of the load back here and give
more resource to this and begin to
separate some functionality and then
then we throw money at the problem we
make make the database bigger so now
with a bigger database we can get to a
point but of course you're limited by
the size of your box so you know what
did we do next well you know starting in
the 90s with with web stateless web
architectures we began to do this you
know split things out stateless
architectures break it all apart load
balance between the first tier and the
second tier build your services get a
really big database back here and you
know this was the 1990s this was when i
was doing web 10 basically this is
exactly the same as the stuff we were
doing on mainframes and unix machines
you just keep making this bigger until
you're spending two million dollars a
year on oracle licenses and it's not
getting any faster and at that point you
know you've got scalability and
availability problems because it's a
much more complex architecture you keep
making it bigger and you you eventually
say okay fine we're going to do a
replica so now you can maybe read out of
this thing and only isolate rights to
here or just sort of split and load
balance and read-only replicas are great
except that now I've got to get data
that's going into here from there and
now I've got a possible consistency
problem where if I write a transaction
into here and read it from there I have
a problem so let's shard the data
because if we shard the data then it
matches the rest of the architecture
stateless architecture out here broken
up into pieces back here we break it up
what is sharding it's relationally
consistent local data sets so the
customer and the orders for that
customer and the products for that
customer all live in a particular
location it's all one place it's
co-located and that's that's a fine
thing it works wonderfully until you
have more than about
three at which point things get horrible
so if you read the Google spanner paper
which I reference they talk about
spending two years on a recharging
scheme for Adwords and AdWords by the
way is ninety-five percent of Google's
revenue that's a lot of money and that's
they have to be very careful with it and
it's pretty bad when it takes two years
so that's why they had to change that
infrastructure out so what happens is
this makes it more complicated because
now I've got all of this extra stuff and
I've gotta write code to do this and
performance takes a hit because even
though I'm only isolating I owe to
OneNote I've got all these layers to go
through and lines of code to go through
so let's cash it let's get the stuff
from my sequel or postgres or whatever
we're using and and let's use memcache
store or something like that up front
and this is great except that unless
this is as big as this you have a
problem again which is that you'll have
cache misses so you're optimizing
hopefully to get the data in cash that
smokes most likely to be used that adds
complexity so from the the caching thing
you know you could expand the cash just
by using a lot more machines and get a
lot more memory at which point you're
really just using this as a persistence
layer but it's still an acid compliant
you know persistence layer which has
problems and then you have issues again
of if I take the data and i write it in
here and then my my data is stale
because of the cash i can have
inconsistencies so operational
complexity goes up it becomes a
nightmare to manage and so you know more
things to break more management more
administration more software complexity
more parts more points of failure more
latency within the system every time we
added something in here in an effort to
improve performance we put latency
somewhere caching is deferred latency
right because some point this cache will
have to refresh or there will be a cache
miss that cash myths eats instructions
those instructions then say oh go fetch
the data now I do a physical I 0 over
here and I get the data and then I put
it in the cache and then I can access it
that's an extra code path so what you're
hoping is eighty percent of the time
it's the cash and twenty percent of the
time it misses and if there's a problem
you've just got a really badly
performing system and that's all the
kind of stuff we learned all through the
90s into two thousand and so finally we
got a distributed database that could
handle this right what what did most of
these no sequel databases do well one
many many servers distributed so we can
scale up and down with the rest of the
architecture but we make it look like
one database so we simplify the
programming semantics get some puts and
we don't worry about this the cash is
part of the database so we can eliminate
having extra cash layers now not all no
sequel databases do this but many do so
with the memory caching in this stuff
co-located we've solved the problem of
multiple pieces of tooling it's gotten
easier it's gotten more scalable and so
we're done except that there is no such
thing as a free lunch and you should all
learn that word because it looks sort of
like a Danish or a Dutch word it looks
very Nordic so tanstaafl would be you
know there is no such thing as a free
lunch right you get something but you
will make a trade off this is the
devil's bargain of Technology you can't
replace a relational database with a no
sequel database unless you're focused on
a particular piece of workload and so
you won't see these for a while and one
of my friends at Amazon made a great
mistake he's a statistician he's on the
analytic side and somebody said we want
to build a system in Mongo and he said I
don't care what you build it and I just
need this data and so they built their
system then they came back and he said
okay where's my data and they showed him
where his data was and he got his data
hoops and he got his data but he then
said okay understand this now I need
this data with it and they said oh
because in Mongo it's not a logical
schema you can't keep the view the same
and change the underlying structures or
rewrite a query you dumped the data
create a new structure and put the data
back there's other ways to do it but
most people
no those patterns like lazy rewriting so
they went off and they spent three weeks
and they did this and so now the
application was writing data in the way
that it could be consumed by the
statistician who then said oh this is
interesting there's a shoulder it's a
statistical anomaly in the data I need
this and this with this and then the
Mongo guys said oh and they went back
and spent two weeks and got him his data
and so he said you know this isn't
working we need to try a different
database so that is my mom goes story
the problem was we scaled this part
right Mongo or Cassandra or react or you
know all these wonderful databases they
scale serving workloads and transaction
processing online analytical processing
or query processing query does not equal
transaction no sequel databases are no
join databases now that means that we're
ignoring a whole half of the enterprise
the people who need data not the people
who create and serve up data the people
who think about it the finance
department the marketing people so how
did we scale this this is my career
living through these nightmares we
started again transaction processing
against the database and we wrote
reports against it every report is an
application just like a no sequel
database right each thing that you want
to report on ends up being an
application because you have to get and
lunch and do stuff with data or you pull
it out put it somewhere else so we
scaled by you know writing one report
optimizing each one of these things we
made the database bigger right we need
to add another core to the mainframe
when mainframes finally got
multiprocessors or more water pipes
because it's running too hot so then we
decided to replicate the data right you
take this database and you lift it up
and you drop it down over here now you
have two databases but you've isolated
workloads this one takes transactions
and every time a big report starts up it
doesn't slow down your transactions
slowing down transaction stops the
revenue of the company so that was
always a bad thing and we would get
yelled at so we do this now your only
thing is how and when you move data
here to here and maintain the replica
but then what you discover is of course
the real problem is not just that you
had to work loads the problem is that
this database schema is his problem and
he was just describing it's a highly
normalized transaction specific schema a
transaction specific schema is great for
transactions it limits the amount of i/o
that you're doing at the expense of
causing a lot of pain when you try to
pull all the data back together again
the more tables the more joins the more
difficult it is and so we re schematized
data warehousing is really just this
with a different schema in order to get
this you have to do something called ETL
extract transform and load take this and
this and melt them throw out this
denormalize this piece clean this up
standardize the data it's like doing
font standardization make sure that each
one of these references to a person and
a place and a product are all using the
same nomenclature the same value domain
so that we can link the data which is a
problem in a hadoop world as well you
have to do this to make the data
accessible and usable and then we
replaced handwritten applications to
generate reports with query tools
because this is a sequel database this
thing can generate a query based on what
you're asking so we can introduce a
metadata layer that separates it that
says I want this this and this a piece
of code in here says well that means I
have to go to that table that table in
that table and it generates a query and
the beauty of the relational database is
it takes the query and it says I could
get it this way or I could get it that
way and it tries to guess which way will
be faster and in things like Oracle and
sequel server and db2 it always guesses
wrong and so you you buy more hardware
and that's exactly what we did I spent
years doing this kind of work we started
to do caching does anybody know what
OLAP is actual multi-dimensional OLAP
yeah a few of you this is good sequel
server analysis services is OLAP
essentially you're taking data and you
are creating a model where all of the
attributes link to metrics on the
outside and it's kind of
you can implement it as a hypercube or a
bunch of different models but
essentially you're creating a highly
optimized retrieval system much like a
nose equals store that allows you to get
very quickly any pre-calculated
aggregate that's out there but you pay
the price by having to build that cash
and it's inflexible because it's smaller
than that and so if this wants something
that's not in the cache in an OLAP
schema good luck in a sequel base query
schema you can get it but of course this
is way faster than that just like its
transaction processing and so these
things began to take chunks of data and
cache and isolate and that's kind of
where we got to and then starting it
started in 1986 but that was when they
first one tier by query system was
shipped we created distributed sequel
systems and these took off about 2002
that's when a lot of venture capital
went into new models of parallel
databases teradata is the only well
teradata and sybase like you are the
only two that really have lasted since
that period except for a British company
that used to be called white cross it's
now called cognition and they are
distributed scale-out databases
multi-node fully relational in pretty
much every instance acid compliant you
bulk load all of your data in here and
then same model on the other side but
now you have the ability to not buy a
bigger box you just add more nodes as
you need more resources your data grows
and so we now have distributed query
databases which are different from
distributed transaction databases like a
no sequel database because they're
optimized for this one optimizes get in
when optimizes get out to workloads
similar architectures load balance front
ends distributed caching layers and
scalable distributed parallel databases
it's just that this one's relational the
no sequel one is not these two things
are hard to do 11 so the posit that no
sequel means i'm going to throw out
oracle only means i'm going to throw out
oracle behind my website it doesn't mean
I'm going to throw out Oracle for my
query schema because the workloads are
different you can't do that quarry
workload in
if you can't do it in Oracle you can't
do it well actually it's true you can't
do it in Oracle but that's probably
because you're using an EMC Sam my goal
here is to insult as many people as
possible so I hope I'm getting there
which means we need to look at the
stores right and the hype market big
data is unprecedented and I've been
mucking around with data that was big
and small for a long time and you know
one of the things is when you say that
you're assuming that there was no past
in our industry we tend to throw all the
manuals out every five years or so
because something new has come along and
we don't have any history and there's a
difference between not having a past and
having to invent something and just
rejecting that passed in favor of
something else you know one is a form of
creation and invention and one is a form
of being a teenager and so reinventing
the wheel is something we in the
software business do really well and
I've done it for a long long time and
this is a you know this is the history
of databases from the 1960s multi-value
databases nesting structures right so
customer order order order stored in one
record read once ims was at its time the
fastest transaction processing database
on the planet because it was multi
valued in hierarchical just like almost
all of these no sequel stores were
talking about and you know then we got
relational and system arc well and
sequel there was a little bit of a tiff
between these two guys so IBM renamed it
SQL got rid of the ease in the you
because none of this is about you it's
all about the economy and we get db2 and
all of these things and it goes on and
on and on and of course we go back and
forth right multivalue hierarchical
relational relational sequel gets
standardized truly wasn't standardized
until nineteen eighty-six we get object
orientation network databases things
like that none of this stuff actually
ever worked and so we threw that back
out and kept buying Oracle informix died
db2 sequel server and then we end up
with this stuff starting in the early
2000s which is which is interesting
we've got the parallel sequel databases
and the parallel no sequel databases and
then what's happening now is a different
workload computational analytic
workloads driving things like this
which are array processing and linear
algebra which is not the same as
relational processing and counting and
sets which is not the same as dealing
with each's and rose in a no sequel
database so the essential history can be
boiled down as in 1970 we have no sequel
in 1980 you should all know sequel by
2000 we don't want sequel by 2005 every
single no sequel database says oh people
want to join data we need a sequel like
query language and so everybody starts
adding sequel back in which is what
things like Impala and Hadoop are about
and now we're back to 2013 where Google
has told us no you need sequel and so
you know relational has a lot of great
stuff going for it but it's got some
really sucky things as a developer like
static schemas no rich typing only a few
data primitives everything has to be
designed up front and in advance it's
sort of the anti pattern for both
deployment and development of agile and
it doesn't do well for a number of
things including developer support and
so what didn't I list here I didn't list
performance and scalability because
bigness is not the problem this is a
chart from a few years ago a friend of
mine put together these are the publicly
announced now I know bigger ones but
publicly announced databases this curve
is traditional database market db2
sequel server that sort of thing you can
see that it's actually hanging in pretty
well around 100 to 200 terabytes yes
these things do actually run at that
scale but between here and here you're
talking about the petabyte range the
largest data warehouse is using a MPP
databases distributed query databases
like 'no teaser or terra date or a
vertica and then up here we've got of
course the the Hadoop kinds of things
and most people will fall very
comfortably in this range and if you're
doing query processing your kind of
crazy to still be using these things
because this is the performance bump the
scalability bump which is from hundreds
of terabytes to multiple petabytes I'm
not going to talk about how you emulate
a key value store but I'm including it
in the materials because it's
interesting because people always tell
me oh
we just have this one big thing and it's
log structured records well guess what
you have to query log structured records
and it's hard to do fast case in point
ebay friend of mine at ebay gave me the
slides that he was using it a talk and
it's talking about this particular
system which records log structured data
from six thousand different applications
it is this guy right here 40 petabytes
40 petabytes in a relational database
when you query this thing like these are
the query techniques I'm not going to
talk about but when you Clary this thing
you're talking trillions of rows your
filter set is 40 to 50 billion rows and
the response time out of this for the
hundred and fifty plus concurrent users
hitting it is approximately 30 seconds
on a query like that so to say that
relational databases don't scale means
that you have a serious scale problem or
you're doing something wrong this is how
you do it Hadoop is not the answer
because Hadoop is in fact highly
inefficient what Hadoop gives you is a
very inexpensive and very faster right
to storage layer from which you can feed
other things or on which you can operate
directly but you don't build interactive
query systems on it hive and Impala not
going to be there for a long long time
and so what you're getting is both order
of magnitude improvements multi order
rate this is what most people buy here's
EMC and then here's just buying some
disks and shoving them into nodes or
getting virtual machines most people do
not live at this end of the curve
Microsoft there's a paper in the
references studied 174,000 analytic jobs
how big was their data is anybody know
the answer to this or when a guess shout
out some numbers anybody how big was the
median size of analytics oh come on
300 gigabytes anybody else more or less
who thinks more less well less wins 14
right I got a petabyte of data and 14
gigabytes is my analytic result set all
right so the problem is probably not
what we think it is it's not bigness
bigness is only a problem down at that
storage and filter layer but once I
start working with it it's nested
structures and hierarchies and large
amounts and non-standard stuff it's deep
structure that's probably the single
biggest thing complex and hard to manage
this is piece of a core metrics tracker
I work a lot with this kind of stuff and
yeah there's embedded structure in here
so it doesn't fit nicely in a relational
schema because you have to unpack this
stuff and you end up with these
normalization problems everything on
this page refers to exactly the same
thing which is aspirin I have a headache
well take this or that or that or that
or that these are systemic nomenclatures
there's structure in there which you can
use to identify and extract things when
we talk about unstructured we really
mean unmod 'old because we haven't
constructed the model to hold that thing
in a consistent and repeatable
extractable way and this is just a
document this is all of the word
linkages in a document corpus now one of
the things when you get all of that
event structured data or all of that
data that you've extracted in a one big
long deep table is that there's deep
structure inside the data set it's not
this piece of a record with its
structure it's a hundred million of
these records that define a pattern and
so what you do with analysis is
essentially extract patterns which
themselves are data and then have to
store them back or you rerun the
analysis again and so you're generating
sets of data out of sets of data and
that gets us to computational workloads
because we forgot about this part which
is different from this which is
different from this queries transactions
computations are all different and the
Holy Grail that everybody thought Hadoop
was going to be was data storage data
retrieval and computation on one magic
platform
and that is one magic platform because
it doesn't exist today it is the Holy
Grail and everybody's trying to get
there by doing different things database
vendors on one hand big data guys on
another hand but you really have to
break the problem down are you talking
about a lot of data or a little data are
you talking about a lot of iterations
and floating-point calculations or a lot
of vector math or a little bit if you
have a little bit of data you have a lot
of options over on that left side if you
have a lot of data you're kind of over
here so it's analytics and data there's
big and little analytics and big and
little data and no technical solution
will solve them all databases have
solved the volume problem for query and
aggregation in fact ebay proved that a
teradata box was cheaper than the Hadoop
cluster to do sorting filtering and
aggregations and so they shift their
workloads now to favor that box for that
stuff and then Hadoop cluster for
different things so by the way block
synchronous processing is the thing that
MapReduce can't do because MapReduce
turns out to really suck for graph
structured data and so if you're using
graph structure data you kind of want to
look at bsp and cgm and things like that
but high computation low data
concurrency right lots of users what as
web app people deal with most products
could do one really well and maybe two
nobody does all three not at scale and
so what we have then is you know no
sequel has taken the relational and the
management system out and given us a
database Hadoop has taken the online
part out because everything is batch
Hadoop and pig is like mainframe and job
control language if you're old enough to
remember what that was if not that's
what the Internet's for so maybe these
aren't the databases that we're looking
for and the reason is because of all of
the stuff that the database does for you
standard API query layers transaction
consistency this thing right here is the
single biggest thing it gives you a
query optimizer a 3 table join means six
different ways that you could actually
order the joint each one of which is
going to give you a different
performance but you can join data by
merging it by using a hash structure by
doing a nested look up where you iterate
one set and
probe the other set so let's say you've
got three of those well now it's 36
different ways and each one of those has
a different performance characteristic
based on the distribution of the data as
it's been stored that's what a query
optimizer does a complex query that does
aggregations and group buys and things
like that can have millions of possible
things and what we've said is Oh mr.
Mongo developer you go figure that out
because that falls in your domain data
navigation domains you know all of this
stuff falls into your domain here and
we're going to give you access and
storage right it's not what it's
designed for and that's what a
relational database is designed for you
so you have to think about this but also
transaction consistency plays a big
factor now corey optimization as i've
said is very complex if you fail at it
you become a rocket scientist I used to
work at NASA and I tried to work on
database kernels so I'm the proof point
in that world this is you it sucks I've
been there most people don't realize
that there's more than one kind of joint
right there are many kinds of joints and
so take that 36 and multiply it by the
types of joins that you have possible
and that's every option for one query so
every program being a queries turns into
a problem the real important point here
is simply that work loads are what
define the platform operational analytic
and scientific have different
performance requirements different
resource requirements and it's very hard
to blend them one focus is on this one
focuses on aggregate queries and one
focuses on mathy stuff so you want a
platform that can support all of these
things and that means probably multiple
tiers right this is why Hadoop is so
interesting big base data tier can deal
with a lot of these things and then you
start separating stuff out and so you
end up with raw data standardized data
and then the enhanced cleaned up data
warehousing kind of data that's been
just the high-value data and my more
expensive systems and then finally my
derived analytic output so you have a
food supply chain kind of a thing going
on where some people need the raw grain
some people make dough some people just
want to eat doughnuts those are your
executives by the way and so what you
really have to ask is this question
what is the problem for which this
particular thing is the answer and the
answer is always it depends there's
nuance here and so you have to think
like a designer now the final point so
Google came along the no single fanboys
are a little bit of gassed at this
because they said uh f1 is the answer
what's f1 well we went from MapReduce
which was in 2004 to megastore and
dremel and spanner and f1 right so there
have been four evolutions and a few
asides it's a distributed sequel
database they said it couldn't be done
it's a distributed sequel transaction
database it does globe-spanning multi
data centers single database instance
with acid compliance semantics which
means full transaction control it's a
sequel database because they said guess
what it's actually kind of hard to do
this stuff it's synchronous replication
and transparent data distribution which
eases your operational problems which
you have with starting and replication
proto buffs if you know what they are
you can store a protobuf as a data type
in a column and you can actually query
proto buffs just like you query tables
we've blended structures which includes
nesting structures with relational
tables in the same thing with some
schema X schema and sequel extensions to
query them from a sequel statement which
has been modified which means it can be
optimized by smart optimizer people
which means you don't have to figure
that stuff out which means i can now do
big ugly queries and I can do
transactions in the same system this is
one evolution and it's a very
interesting one and the other thing is
you can still keep doing your MapReduce
stuff and so this is the user facing
latency of acid-base transactions it's
about 200 mega 200 millisecond round
trip right so it's not much different
than what you get out of your nose
sequel databases when you add in all the
code you have to go through to do the
transaction bits this is what they said
in the f1 paper just two quotes right
concurrency in the application as
opposed to in the database
very hard lots of edge cases eighty
percent is easy twenty percent is hard
the twenty percent is what most of the
these key value store kinds of things
make us deal with and the second part is
this which is that you have impedance
problems and mismatches and other things
getting data to and from proto bucks and
other stuff so we've got to fix the
relational side and we've got to fix the
notes equal gut side and that's what
they've attempted to do and so you know
why no sequel will fail has very little
to do with actually failing because it's
not really failing its evolving it's
merging back into the code lines of the
other databases and we're going to end
up with something new that's part one
and part the other and the reason the
relational database one the commercial
market war is because sequel was a
standard once you have a standard API to
a system everybody can implement a
different engine to execute to that
standard we can have a teradata that
does queries we can have a db2 that does
transactions we can have a whole host of
things in an ecosystem and then we can
build up tools around it query tools
data integration tools and other things
because they all talk to that same API
sequels not really a language sequel is
an API it's a programmable API and that
makes it different it's a declarative
programmable API so what we have is that
it's not really a revolution it's more
of an evolution and evolutions are
really all about parties and so the
bottom line here is if you go and read
these Google papers it also tells you
that if you procrastinate long enough
most problems will solve themselves
because somebody will build a product
that you can buy and that goes along
with the other thing which is that the
future will be exactly like the past
only far more expensive so thanks for
staying with me the references will be
included in the PDF here so you can link
to all of the papers that I'm talking
about that get into the gory fun part
which is all the technical details and
there's a whole lot of CC attribution so
those are there too and by law I'm
required to do this or they'll throw me
Jeff yeah
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>