<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2016 • Building a Modern Infrastructure Stack • Steven Borelli | Coder Coacher - Coaching Coders</title><meta content="GOTO 2016 • Building a Modern Infrastructure Stack • Steven Borelli - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2016 • Building a Modern Infrastructure Stack • Steven Borelli</b></h2><h5 class="post__date">2016-09-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/n8QGk4e3nl4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you for hanging in there this has
been I'm sure a lot of information to
absorb a one time so I'm so happy that
everybody is still here just a little
bit about myself if we can get this
going up there we go just so you know
who I am my background I was a systems
engineer for most of my career working
for big companies I worked for a city
group working on their mortgage
portfolio and a high-performance
computing and then before I started this
company I was working for a cloud
provider doing a cloud research and
development and during that time got
really excited about containerized
technology about schedulers and things
like that so in 2014 I found that a
company in st. Louis around those
technologies today we have ten employees
plus we're getting about three or four
interns this summer and we have a lot of
really great customer so just about me
on the systems engineer if we started a
company around a lot of this stuff so
we're going to talk about building a
modern infrastructure stack and kind of
i wanna thinking about what i heard
about love today because I too was very
overwhelmed by everything and kind of
what I want to talk about is the coming
infrastructure crisis so you've been
exposed to probably dozens of buzzwords
I got this from i just downloaded this
today and this is kind of like an
overview from december of a lot of the
players and the micro services and each
one of these is probably a VC funded
company and every single one of these is
invested in with the investors thinking
they're going to make you know 10 to 20
times their initial investment so a lot
of these products and things that you've
been hearing about today are you know
they're coming from companies that need
to make their money back and it's really
complex and I think you're hearing that
you know and then when i was looking at
this actually I was looking at some of
the things I'm like that doesn't make
any sense so this is what I thought
about right this came from boundary calm
we're like somebody was just putting up
logos there and the funniest thing about
this is that boundary calm got bought
out by BMC so I was trying to cite this
image and I couldn't because of another
promising infrastructure startup that
disappeared
so kind of what I want to say and you're
probably feeling it too it's like it's
incredible the amount of new tools that
are coming out and how are we going to
deal with it because it's probably
beyond anyone to actually manage this
but before we do that what I'd like to
do is really talk about who are doing
this for so we want its first talk about
our customers the people are developing
and using our systems and I think when
we think about the people who use our
tools first then we walk back from that
design software for them when I go talk
to a lot of customers we go in there
there's usually several groups of people
that have differing demands so the first
one is there'll be someone from the
developers group there's a lot of folks
from the analytics group and then
there's usually somebody from IT there
right so we go into an engagement to
talk somebody for a larger company they
usually have these kind of folks there
and when you talk to them they have
different stories the developers the
number one thing that you talk to you
they want continuous delivery they don't
have to go through apps and deploy
things are moving to micro services and
something that's very important to is
they're really moving towards API
centric right where everything talks to
everything else via API and this is to
enable things like mobile development
and they're using tools like they're
moving using tools like groovy they have
still some legacy Java there'll be no DJ
s now when you talk to the analytics
folks this is a whole different group
right it's a different part of the
company they report to different
management and traditionally these folks
were using tools like SAS and Oracle
right and now they're moving into big
data and when you hear what they're
talking about you know right now it was
big data kind of streaming is a hot
thing right now you know especially with
tools like Kafka and Cassandra and
real-time data they're moving from
really starting to get into things like
predictive analytics you know machine
learning there's a lot of open source
libraries there and of course events
like getting back to Kafka now you'll
notice it's a big data people and
container people are like completely
different worlds from each other the
tools they use are different the
languages and then finally this is
always good for a lot of tension when
you go talk to big companies is the IT
folks usually they're spending almost
all their time doing maintenance of
existing infrastructure and they're
being pretty much screamed at by the
other two groups how are we going to
move to continuous delivery how we're
going to move to the cloud how are we
going to get this Hadoop infrastructure
right so I've actually been in meetings
where people start shouting at each
other especially between the IT folks
you
because they feel pressure and they
really don't have the training of
personnel they have the ability to do it
but they're kind of trapped so that's
what we talk about when we talk about
these platforms like uber Nettie's and
mesas and dr. what we're really talking
about is like how does this actually you
know affect organizations like what are
they going to use it for so let's talk
about the problem infrastructure is
getting way too complex we have an
explosion I kind of show you that thing
but just just to get an idea of this
these are just kind of tools that have
popped up in just the last couple years
and what we're seeing is you know
especially on the code side there's new
languages like go is really taking off
on the infrastructure side I was saying
kind of the decline of Hadoop spark has
really taken over for a lot of analytic
programming jobs and we're seeing
basically a new JavaScript framework
pretty much every week at this point or
sooner on the data side what we're
seeing is really specialized databases
like in the old days you just have a
single sequel database and now what
you're finding is you have a database
for events you have a database for
documents you know you might have a
database that's like a ring database
like Cassandra and then finally run time
a lot of things we're talking about
today you had I think five different
vendors talk about you had no mad yet
Cooper Nettie's you dr. swarm you had
nacelles and get Cloud Foundry right so
you have five different platforms and
you know so we're seeing an explosion of
different tools and of course you say
hey we'll just go to Amazon or something
like that I'll make it easy but anyone
who has ever used amazon knows it's
incredibly intimidating right this is
what amazon and if you look at like what
the traditional IT thing is it's that
ec2 up there right deploying instances
right so amazon is like the first time
people go to amazon is like oh my god
there's so much to do and you can click
around and get things done but making
that repeatable not a good way of doing
it so basically the cloud is complex you
have to learn how to do the cloud and
there's a bunch of tools there's an
explosion of tools especially in the era
of github where every company now is
developing out in the open so bed pretty
much every week there's new things
coming out IT can't keep up we look at
IT today and it's kind of like this
right you know it's like a lot of folks
had talked about this today you have to
open up a ticket with somebody and it
takes forever and but all the talks
today to have been like very
aspirational right like
we want to get to this you know how do
we do it like we want to be like Google
we want to be like Netflix we want to be
like all those companies to talk at
velocity that basically or just you know
pushing a button and things are going so
that's the problem right like to get to
that level of that high automation it
takes an enormous engineering effort
like you talk to these companies like
Google or netflix they have multiple
sres working to automate their
infrastructure it's incredibly expensive
and for companies who usually have just
a handful of people to do this it's way
beyond their abilities so the question
that we have with this mantle project
it's like what if we made it easy for
normal people to spin up world-class
infrastructure in just a few minutes as
opposed to what we usually see for IT
projects dealing with containers is like
one to two years right so that's kind of
the goal of our project and that's the
project as mantle so that's what we're
going to be talking about after this
introduction and it's at mantle that I
oh it's Apache open source it's
sponsored by Cisco and really the goal
of this is to make it easy to run
containers and data workloads so just a
couple things before we get into the
architecture of it because I'm going to
spend the rest of the talk of being a
technical talk about how we do it our
first goal is we wanted something that
deployed in minutes right now it takes
about 20 minutes is a point most clouds
we want to cut that down when we talk
about supporting diverse of work diverse
workloads and tools what we mean there
is we expect a lot of these open source
tools to have a limited lifespan like
there might be one that lasts for
decades but most of them are going to
have a popularity curve of like three to
ten years when you look at like a lot of
example projects in open source a lot of
them don't have a che they don't have
security they're not integrated with
logging or anything right and that's
really the problem when you download an
open source project most of the time it
doesn't have that and then the vendors
want you to pay a lot of extra and then
finally we really are passionate about
making something open sores so this is
what a mantle cluster looks like when
you deploy this to any cloud and this is
a pattern that you'll see almost any of
the platforms you roll out there whether
it's May so sore cooper Nettie's or
anything else you'll have an odd number
of control nodes and you always and this
is a pattern you use if you're using
kind of any kind of consensus
stem like zookeeper or at CD or console
you always want to have an odd number so
if you lose a node you still have a
majority election so we have a set of
nodes that are called control modes then
we have worker nodes that could run
different types of workloads on them so
we have examples here of Cooper Nettie's
and May so so the way we run these
schedulers on mantle is that we actually
separate them like we don't run the
Maysles Cooper Nettie scheduler we
actually have a Cooper Nettie's
deployment and amaze hose deployment the
kind of work side by side on different
nodes and then finally we have we're
using a tool called traffic which is a
dynamic load balancer that kind of on
the fly will direct traffic into the
cluster right and one thing you're going
to see here is that we have a lot of
flexibility to pick the tools that we
like the best and integrate them so we
find and that's a that's really
important for us like we don't have a
strategy tax that we pick something and
then just because it has to work with
all our other tools and so we could lot
of people in in case he talked about
this and we're going to talk about for
the rest of this talk kind of the layers
of the stack so when you talk about hey
I want to run docker it's very exciting
it's easy to get up but then when you
actually start talking about what it
takes to run docker containers in
production and case alluded to a lot of
this you find out that you need to move
run your infrastructure like Google so
this is when I was talking about the
crisis and IT this is what we're talking
about you know you want to move to
microservices continuous delivery or
rollout kafka but then you realize we
have vm based IIT and to get to like a
really strong container based
infrastructure is an enormous
engineering effort so we're just going
to walk through these and I'm going to
talk about the open source tools that we
picked why we like them so even if you
don't use mantle there's a lot of these
tools that you could use to build your
infrastructure out so the first one is
cloud provisioning we base all our stuff
on terraform so um mantle pretty much
looks the same everywhere you run and
it's bare metal we terraform is a tool
developed by hachey corp and Seth was
here yesterday and what terraform does
is it basically abstracts out the api's
of each of the cloud providers and it's
got a really cool feature where it
represents everything is a directed
graph that means if you make changes
only the things that change get applied
on the next
it has really simpler syntax and things
like cloud formation or as your
templates and the way we do terraform is
very modular so you could do things like
attached of volumes to nodes and you
know have separate LVS and we set up
networks and security groups and
everything right so the first hurdle you
do when you're going to the cloud is how
do you actually set things up we usually
provision to most cloud providers just
the infrastructure from like networking
all the way down to VMS in about two
minutes so terraform is great and these
are other clouds we support right now we
just got try and support last week I'm
actually working on as your support
right now so we'll be able to deploy
almost anywhere if you've never seen
terraform before this is kind of what it
looks like so if you've seed cloud
formation it's very confusing um this is
hard to read this is how you would set
up a VPC and amazon so if you've ever
done it manually you know it's a huge
pain up there you see with the first
thing we do is we set up a resource
called AWS VPC see if that works and you
see this here there's variables right so
what we could do is we could feed in to
terraform different network values so
basically we have the same modules in
terraform when we pass in variable so
what we could do is have matching mantle
clusters in like us west and us east and
we change one variable and their exact
clones of each other in terms of
everything from like IPs and everything
well maybe not floating eye peas but
static ip's networks and everything else
so the cool thing here is we could we
also tagged it automatically with and we
pass on all these variables and the next
thing is we're going to create a subnet
right and we just take the idea the VPC
we just recreated this here it gets an
idea and then we set it then we set the
subnet and then we do things like
availability zones so in mantle we could
do cool stuff like when we deploy
servers if we give it three availability
zones you'll stripe the service across
daisies and this is something you do in
terraform pretty easily but we have it
and then of course if you ever done a
VPC you got to set up a gateway in a
route table and all that other stuff
that makes you hate your life until you
get it all working but it's all
automated and all you have to do is just
basically change some variables like
what a Z's you want what region and this
is the same pattern for OpenStack or
when Azure comes or giant now another
cool thing that we do because a mantle
is because we have multiple providers
we actually linked up dns so in this
example i'm actually linking up
CloudFlare with instances that we boot
up in any cloud and what that means is
here is we're going to set up a
wild-card dns right so that means that
anything that goes to like mantle
example.com will go into our cluster and
so that's the example of your app one a
nap too and then the way we set this up
in terraform is we have this module here
for CloudFlare round robin wright we
pass in the edge IP list and the can
adjust we have a go-to domain so here
we're going to do this for go to write
so I set up we're gonna have an example
a bit so whenever we build a new edge
host it automatically updates CloudFlare
with DNS so you could set it up every
time you build a new mantle mode it
updates you to CloudFlare route 53 or
Google DNS you just feed in the
variables of all your host so sudden
what we have something here how we
provision our host is going to be tied
into actually how we route traffic like
a lot of the examples you see people are
like going to fixed IP addresses because
I don't have that tie between dns and
everything so that's kind of terraform
if there's one thing you take out of
this if you're going to do cloud
provisioning I'd really suggest using
terraform other over other tools even
the cloud native ones that they provide
I'm going to skip the overlay Network
product and I'm going to talk about
service discovery because this is really
a fundamental it's been talked about
here but it's really it's really a
fundamental part of containerized
infrastructure and it's how do
applications find each other what we
have in mantle is weeks both service
discovery information either via dns or
via an API and this is what it looks
like if you're actually on a cluster so
let's say that you want to find the
pricing service you just if you do an
nslookup a comeback with what nodes that
container is running on and you also
have things like you could tag nodes in
DNS and you could also in console which
we're going to talk about you could
actually have different data centers so
if you link up your console clusters you
can actually have lookup services and
other data centers so when you're on a
mantle cluster basically everything is
registered into the service discovery
system so you're not hard coding ip's so
we use console for this which is another
hachey cork tool we think it's really
good we wrote the mesas to console
bridge so basically every time you
launch a maces task and registers in
console we're working with a couple
other companies right now to develop if
you know Cooper Nettie's it uses sky DNS
a net CD for its service discovery
engine right now when you deploy Cooper
Nettie's on mantle we're routing it
through DNS mask because we don't have
that integration console needs a lot of
changes internally before it could
support the Cooper Nettie's namespacing
if you go if you've ever used Cooper
Nettie's the DNS is like namespace
service closer local and console has a
flat or namespace so that's actually
working so right not soup dnsmasq boat
dr. supports console for service
discovery so our goal is we're gonna
have a common service discovery and the
other thing too is the things we install
on bare metal like mace ohs that's also
registered in constable so basically
every service and the cluster that we
put in we register via dns and another
thing we get out of consoles console has
this concept of health checks built into
it that actually feed into the service
discovery system so everything we put
into mantle we actually have it
constable check and get you know within
every few seconds and if there's
something down we'll actually get pulled
out of dns so this is why we chose
console in the first place because we
want to have pervasive service discovery
and health checks in our systems a huge
problem a lot of times is that you'll
deploy one of these systems and then
you'll go to your infrastructure team to
monitor it and they don't monitor a few
things but they don't know how to
moderate all these things so our idea
was since console has service health
checks built in every time we deploy a
component in there it comes with a
health check so the cluster is checking
itself all the time you don't need an
external system and another cool thing
is now we deploy mantle to a lot of
different clusters and how we unit test
it we built this cool tool called
distributive which is like server spec
but it's a single go binary and you give
a JSON that's it it's a simplest way to
test your infrastructure and when you
give it that you say hey I want the
systemd service enabled this port needs
to be open this file needs to exist as
file needs to have this code right so
when we deploy a cluster we actually
just put in all the checks with it and
the cool thing is since console has
health checks built in the same test
that we use for unit testing our
clusters runs within mantle itself all
the time right so a lot of times you
have how do people actually test their
infrastructure I don't think any
he's really doing this right now but
that's what we do right it's kind of we
think it's going to be very important
pattern going forward we have you know
infrastructure checking so we have kind
of a combination of monitoring and unit
testing in the same go like what we when
we deploy a clustering Travis we just
hit the console API we just have to hit
one console API and say anything
unhealthy in the cluster and that's the
same thing you can do so that's a
pattern that we're talking about like
this pervasive health check and
monitoring okay I know I'm going fast
but there's a lot secrets if you heard
Adrian's talk before which was really
good about dr. secrets this is if you've
ever used dr. containers and trying to
get secrets into them it's an enormous
problem there's a lot of hacks going on
right now it's really hard like there's
things like when people booed a
container they'll pull things from s3 or
you know in the traditional days you
only had a couple app server so you
could copy everything manually to the
servers nowadays if you have a larger
cluster you don't know which secrets
have to go to which nodes and either
you're copying everything so right now
there's just like not a lot of good
solutions for this and this is pretty
much everywhere i'm visiting right now
they don't have anything good so what
we're doing with in mantle we're using
another hachey corp too cold fault right
now it's part of a tech preview we're
slowly integrating it we're going to use
it for things like pki and storing
secrets in the cluster and doing other
things um and bringing up vault itself
is kind of a pain to so we've automated
it and we also have just developed this
release it as a 10 we have a vault FS so
what you do is when you boot a docker
container you just mount the this is a
virtual volume as a doctor so like let's
say you'll be mounted at / secret and
I'll pull the secrets out of vault so
when you bring up your doctor container
your developers will just know to look
at / secret and that's where all the
credentials and keys will be so that's
kind of how we're going to do it going
forward and I'm very excited about this
because I've worked with a lot of
customers on getting their doctor
infrastructure up and it's pretty
terrible right now the amounts of
security that they have so I'm very
excited about this so this is vault
effects just came out of 10 so we'd like
people to test it and we think it's
going to be really good solution and
well hopefully totally integrate it
within mantle in the next couple months
just a lot of security things we have to
do beforehand I took out all the slides
explaining what schedulers are I think
you guys have heard enough about them
right now we support two different
schedulers there's may so's and with
mace else we have integration with
console in calico which is an overlay
Network we're also looking at eve
which is cisco's overlay Network product
that's going to integrate with ACI so
you can have all kinds of enterprise
corporate strategies we just added
Cooper Nettie's one to support and we'll
also have console integration and and
calico and we just right now have to add
a curse warm and development and right
now when you deploy the cluster you get
both Cooper Nettie's and Mesa so you
just pick how many workers you want to
see ch the future of mantle is actually
not going to have any by default and
what we're trying to do is get man
thought to be an extremely small core
that you deploy with just like a single
binary and then you just launched
different infrastructure applications
onto it as an application so probably
when we start moving towards doctor
swarm will have that become more of an
example and dr. swarm when we add is
scheduler these are the kind of things
and we try to integrate across all the
different schedulers so that's service
discovery overlay networks it'll be
calico and conti the plumbing and
management and we'll talk about load
balancing in a little bit but that's
kind of can we have common tools that
work across the different schedulers so
that you don't get locked into one thing
and a big part of this is that the
different schedulers have different
strengths right now approaching these oh
so it's really good on the data side it
has a lot of good data frameworks like
Kafka elasticsearch apache spark was
originally developed to run on mace owes
so it has really good tie-in when you
look at the container side right now it
looks like Cooper Nettie's is dominant
it's really starting to pull ahead of
the other scheduler options
um I may do a little demo here to show
some of the API and interface so this is
what the mantle UI looks like and
there's this is actually dynamically
populated we actually are starting to
use the console kv which there's a kv
store at the heart of can console and
we're using this is an engine X proxy
here and it's dynamically updated by
things in the kV in the service
discovery system so as new services get
registered we can have some information
about how they're represented and they
automatically pop up here and another
thing you can see is that we have this
is SSL unauthenticated so like things
like mesos which don't have really good
authentication we have like links to the
mesas workers all out of all controlled
vs SL there's also all the services have
health checks built in so you could see
what the state of it is so we could talk
about some of these I don't know what so
this is if you've ever used maces before
this is like a simple application
launcher I just have a hello world here
and what I'm going to do is I'm just
going to scale this to like five
instances and once that gets up i'll
show you this is our load balancer oops
already up yep so basically as I said
because we have really good integration
through the UI as soon as you bring this
up and you see here there will be the
address right we have hello I could get
that but it's hello and we have go to
that sub domain that I put in when we
built up the cluster so it automatically
maps it and we just tell the traffic
load balancer right that's the domain
you have to listen on it'll match the
headers and they you can see all the
back ends here I could just go there's a
404 this was one I had to shut the
cluster down but when you start it now
you could see the different container
IDs coming on down here and when we
skipped on we when we suspend this it's
pretty fast like will just shut that off
and that's it right so we have the edge
nodes the edge nodes are actually
designed well we I'll talk about traffic
in a minute but we actually sponsor
development of it we thought is really
great and we added some things like
marathon health checks in it so if
containers up and it's unhealthy it
doesn't get routed
a couple of things on the mantel you
I've you've never seen any of these
obviously we have the Cooper Nettie's UI
that you can get to which is similar I
want to talk about elasticsearch because
it's a product that container solutions
develop the framework and it's really
cool we have good integration with it
including down to service discovery so
you actually launch this as a framework
as an add-on it's not part of core
mantle and when you launch this within
about five minutes it gets launched and
then it pops automatically comes here so
you can go there and if you've ever seen
the elastic search the container
solutions that developed from asos it's
really slick you could scale it you can
see the tasks that are running if you
could see and this usually comes up in
about five minutes um so it's really
good and we automatically register these
things in the UI and we have a cabana
that actually as I said before we have
automated logging so if you install a
okay a lot of the logs will go into log
stash and you'll see here they'll just
get populated for our logging story is
changing a little bit we're moving away
from log stash towards elastic beats and
we're also moving everything as much as
we cannot assist log in the journal d so
they'll be ongoing um I'll talk a little
bit more about events and logging later
but again this is something we have
built in and you could you don't even
have to point to the local log stash you
just changed a couple variables and you
could push it out to an elastic search
cluster see what else we have um
I'll make this a little bigger just an
idea of how things work you could
actually look at you know you could run
a cut we have this tool that we
developed called console CLI and I just
said hey is there anything warning in
the entire cluster and it comes back
with nothing so you could be an
administrator and you could just run
this and say hey is there anything bad
in my cluster or you could have like an
external system like Maggie O's just got
just pull the console API to see if any
health check is failing or if anything's
amiss configured and if I say hey what's
passing let's see here I had one yeah
you'll come back with everything right
and you can see some of the you see the
health checks here that we do so we have
built in health checks so a lot of the
components were built into so this is
live so again something you'd have to do
yourself if you deploy nacelles how do
we get a health check how do we register
it service discovery that's all
automated it's very easy to do if you
want to add services to console yourself
you easily either talk to the API with a
JSON or you just drop a JSON file into
the etsy console directory and reload it
so if you want to improve upon our
console insulation having your own
things that you want to deploy it's very
easy to add them into the health
checking another thing we do because the
terraform is we have an external volume
here that actually so the way we do dr.
storage if you've played with dr.
storage a lot is a huge pain there's a
lot of bugs in it we actually attach an
external volume to the system's like an
EBS and we format it with overlay FS on
XFS so you can increase it and we log
all doctor stuff to journal d and so you
it before he had JSON file which was a
pain or syslog which didn't support dr.
logs we're using journal d and we're
using the newest doctors or loose doctor
version so just kind of some of the
things we do there we also have a lot of
other cool features that I would show on
the low level because we have this
service discovery system built into our
thing we actually have dynamic IP tables
like the marathon instances between each
other can only talk when you bring up a
new mace houseworker it actually opens
up the firewall on the control nodes for
you dynamically and it's only a few
lines of code it's basically a bash
script that gets called the pipes and
some console template data
and it's all dynamic and it's actually
works really well which is shocking
because most things in infrastructure
don't right yeah well this is a worker
so it doesn't have it yeah you can see
here they see the Mesa leader there's a
rule there and it actually has as
workers come out the firewall actually
gets opened up on the fly so things that
would be really confusing like how do
you do dynamic firewalls and console
template it's actually very simple table
get back to the presentation may show
counts a little bit in the future
another thing we have is a mantle API so
basically this is kind of a it actually
stores all its data in the console kv
and it's a Galang service that sits on
the cluster and if you want to install
something I when Ken Stipe was showing
some of the things about D cos it's
compatible with a lot of the mesas for
your packages it uses some of the same
packaging format and we basically have
it via API so yeah within like the
elasticsearch framework that we just
brought up or costco or anything like
that you just hit the one API point and
it comes up as it may so it's framed you
can manage it so it's actually really
easy for bringing up data services on
vases I want to talk about load bouncing
so you saw a little bit about it this
tool called traffic this came out in
September from an engineer in France who
was working for a DevOps shop and when
we saw it we thought this was fantastic
so we started sponsoring a lot of the
development we actually encouraged him
to start his own company so I'm very
excited about that he just incorporated
in January and we sponsor a lot of work
on traffic we sponsored the crew Burnett
ease ingress we're sponsoring tcp/ip
support into it so it could be a TCP
balancer and I think you saw a little
bit about it we installed on edge nodes
it supports multiple backends this is
what we like about it if you've ever
used like a lot of places will use like
a che proxy and I'll do reloads we first
started using H a proxy to proxy our
traffic and we found that reloads were
really difficult reading from like
marathon although you know the data that
was coming out of Marathon changed a lot
there was a lot of things that were
broken so we started using this and then
a number of outages we had during due to
load balancers went down by an order of
magnitude it supports WebSocket s and I
support it just got let's encrypt
support but it's not multi-node yet but
if you have one traffic node you can
able let's encrypt for ssl the other
cool thing about this we talked about
not going through IT when you launch an
application you just said some labels in
JSON so the developer says this is how I
want it to listen to traffic this is I
want to pass host headers this is the
URLs I want to match against so this is
not something for IT the developer when
they launch their application like when
you watch a goober Nettie's manifest or
a doctor container there's some metadata
that you could attach labels and you
just the developer just updates that and
that affects the way traffic will route
the traffic so that's something we think
really cool it has multiple back-end
support a good community and we like
this dynamic labeling now the Cooper
Nettie support since we just got crew
just landed last week so we haven't
integrated it with mantle yet but when
we do we'll be similar there'll be
multiple backends and you could just say
hey this is a cooper Nettie's traffic
this is the mesas traffic so yeah I'm
very I'm very excited about this project
I think it has like 1,800 get up stars
on its own within a year so it's pretty
popular and he's adding a lot of dr.
swarm support there's console support
there's SED backends so you can
basically use this to route anything as
i said before with mantle we pick tools
that we really like that we think people
would use anyway and we integrate them
together next thing I want to talk about
is the community that's really important
for us just some growth of our community
the project came out of it started last
februari so it's a little over a year
old we first open source stood in April
we just got over it has decent growth
going on over two thousand stars we're
getting about a hundred a month and
there's a git er chat so if you just go
to the mantel page and you just click on
the get er button you'll actually get in
the chat and we'll help you in real time
if you have any issues installing it or
anything so for us open source in the
community is really important
so that's kind of a summary I have two
minutes and 45 seconds really what we
want to do with mantle is we want to
deploy it in minutes a big thing for us
as batteries included right we want to
have a lot of the things that people
need like logging security h a all
built-in and really important to us is
it's kind of different than a lot of the
stacks you've seen because those tend to
be vertically oriented because they want
you to all use their own stack we kind
of think ourselves something similar to
like a linux distribution like an Ubuntu
or red hat where we take open source
tools and we integrate them together
right like that we think that
organizations are going to have lots of
diverse needs so we're thinking about
how do we actually build a platform for
the next generation of infrastructure
where you could kind of more fit you
know to deploy different kinds of
workloads and when new tools come out we
can integrate it with the rest of the
stack want to talk about the future so
this is probably hopefully we had a lot
of this done within the next by the end
of this year we use ansible for a lot of
provisioning right now we don't want to
I just think in general the problem with
a lot of these DevOps tools like chef
puppet ansible is that they're extremely
complex and there's usually only like
one or two people who dares wants to
touch them so I just don't think that
they're going to be the future the way
people managed infrastructure single
binary deploy we're still guineas
terraform but we'll wrap it but you'll
have a single go binary this is mantle
install AWS doctor swarm right and I'll
have terraform under the cover so all
the amazing stuff about terraform will
still be there but we'll have that it's
very important for us to have that a
user experience move eps and I kind of
talked about this a little bit we want a
really small core for mantle we just
want to have just enough to bring up the
cloud provisioners and enough on it that
we could then start deploying all the
other apps so the first thing will be
things like schedulers you know like
swarm or crew benetti's or mesas and
after that we expect the other apps to
talk to those you know like there's a
cooper Nettie's package manager called
home you know and you can use that to
bring up to your next level of
applications and finally eventbus this
is something we're working on right now
this is a lot of work that Cisco is
interested in all the mantle components
are starting to be we're giving them
guy outputs so like dr. events marathon
events traffic events anything that's in
the cluster will spit out all its data
to Kafka and they'll be actually a Kafka
bus that's optionally built in so if you
turn this all on all the things will
start spitting out their events to Kafka
so you could start across the cluster so
again I don't think a lot of folks are
doing that but we hope to have a lot of
that work done Francisco live in July so
you'll be able to because a big problem
when you're launching apps in the real
world is that you like launch a
container and it'll get stuck somewhere
and you don't know where right it'll
just not run and then you have to
actually trace all the steps like when
you actually watch a container there's a
whole bunch of things it's like it's a
container bill does the image was the
image pulled down successfully did the
image start there's a whole bunch of
steps that happen what's it scheduled on
the right node we found the bugging gets
very hard so that's why we're putting
events into everything and that's about
it I got 15 seconds we'd love you to try
it out get on get er we expect our goal
is that everybody could install it
themselves maybe with a little help the
first time but yeah that's really our
goal so just go to Cisco cloud that
mantle thank you very much and please
rate this talk well so
apparently Stephen you lost someone a
along the way here because one of the
question was what is the big picture
here what what what problem is it that
you're trying to solve the biggest
problem right now is that there's a huge
demand to move to these next-generation
technologies continuous delivery
streaming infrastructure right and to
actually build up an infrastructure to
do that if your company is extremely
hard it's going to take you a very long
time even if you try to use one of the
services like if you set up an Amazon
ecs it's still very complicated I've set
up easy as for customers and you still
have to wire in things and ecs is very
limited and then to set it up for dr.
authentication it's very complicated so
you're going to find that most companies
don't have the time or the resources to
do this and in all honesty every minute
that you spend writing your own unique
infrastructure is a minute that you're
not spending on your customers and
products you know and that's what we're
telling so I tell my tell the engineer
is one thing but when i go to c-level
executives i'm saying every minute you
spend on devops on operations on
building your own infrastructure is a
dollar that you're not spending on your
customers and product so would it be
fair to say that mantle is like a set of
saying defaults yeah setting these tools
yep together it's like a linux
distribution you would not do your own
linux distribution today so the idea is
the same thing we're trying to get away
from this idea that everybody's going to
glue together their own snowflake
infrastructure of gluing these
components together and you know taking
forever and then having to deal with it
so how do you actually configure it
right we didn't see any examples of that
right now it's a lot of ansible one of
the things we're going to is and we
actually we're actually starting to move
towards kv based like using the kv-2
manager cluster so this is something
that will be in the future it's starting
to get there now but we have to move a
lot of the components out so if you look
here the key value store in console
you're starting to see do SSL we're
starting to put configurations inside
the kV so right now a lot of it's an
ansible but we're actually going to move
to is actually everything is going to be
managed other
k v store so we don't want that separate
DevOps tool so you'd actually hit the
console API update a key value and then
the nodes themselves would reconfigure
themselves okay so the way you do it
today is that you go in you modify some
files yeah it's a it's ansible base
today you clone the repository and they
modify and then okay and yeah we just
don't think that's a good pattern in the
long term so we're moving towards what
are the benefits I mean if you're
running something like Cobra tattoos
which already has a lot of batteries
included what are the benefits that I
get out of mantle compared to that well
there's things outside of Cooper
Nettie's that you may want to run right
now the data store in Coober Nettie's is
not necessarily great like a lot of the
big data frame works they're starting to
come like uber Nettie's is probably
going to have the leading container
ecosystem at some point but right now a
lot of things aren't there we're talking
about a different community so things
that don't run in Coober Nettie's your
services right like lower level things
or service discovery or as I said like
if there's a data frame work that runs
somewhere else our idea is more of a
generic and as we said before we don't
know which crew the winners are going to
be so we're putting together general
patterns for running any kind of
infrastructure betting all on old horses
it's not that we it's kind of like red
hat doesn't bet on my sequel versus
Cassandra right they provide a common
platform okay and that's kind of the
idea for us making all of these
infrastructure tools in AB last question
do you think chef and puppet are going
to die go away I don't think they're
going to go away but I think if you look
at any organization that use a chef or
puppet there's usually one or two people
who touch it and nobody else wants to
touch it because it's very error-prone
it's very complex and using get to
manage infrastructure it's not always a
great pattern we see that a lot with
like when we want to update
infrastructure like having to update
things and get you have conflicts and a
lot of other things so we like the idea
of moving you know containers that are
versioned packages that are versioned
that's kind of the the pattern that we
like okay Thank You Stephen thank you
thank you everybody appreciate it
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>