<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • TensorFlow in the Wild (or the Democratization of Machine Learning) • Kaz Sato | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • TensorFlow in the Wild (or the Democratization of Machine Learning) • Kaz Sato - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • TensorFlow in the Wild (or the Democratization of Machine Learning) • Kaz Sato</b></h2><h5 class="post__date">2018-02-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GZfJM7lhi8o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you so much for taking your time
for my session real-world machine
learning originally it is title as
tensorflow
in the world anyway I'll be talking
about the real world the world use cases
of intensive roll I'm Kaz I'm a
developer advocate for Google cloud team
so I usually go to many conferences and
meetups events talking about the
technologies and products and focusing
on data and analytics products such as
tents of rock which is an open-source
machine running library or bigquery
which is a data warehouse running on
Google Cloud and any other data
processing products I have been working
at Google Tokyo office over six years
almost seven years
and for the last four years I have been
working on Google Cloud and I working at
Tokyo but I usually got around many
different countries so for this week I
went to Vienna and the Paris and barring
and I was in Shanghai last week are we
going to India in two weeks so I'm going
around the world and talking about the
machine learning so what is machine
learning or AI or neural network so
there's no scientific profit definition
what is artificial intelligence but you
can say you can say that it is a
technology or or a technique to make
things smart make computers smart record
building an autonomous driving car or
written computer drawing a beautiful
picture and one of the approach is to
realize the vision of AI is machine
learning the what is machine learning
mathematically you can think machine
running as a way of automated
programming so instead of hiring many
human programmers writing Java or C or
Python code to instruct computer how to
solve each problem instead you can put
data to computer so that you can let
computer to solve a problem by
extracting certain patterns or features
from
later and there has been so many
different algorithms for machine
learning like a support vector machine
so random forest logistic regression and
one of them is neural network and neural
network has been used for many years
like 30 or 40 years already
but around 2012 we have been seeing a
breakthrough has been happening in the
area of neural network so that the
reason why Google has been spending so
much resource on developing neural
network technology so what can what kind
of problem yield you can solve with
machine learning on your network for
example if you have two fruits like this
and your customer comes to you and ask
you can you classify these fruits as an
OP apple or orange what kind of program
code you would write with Java or Python
or she any code may be easiest way is to
look at looking at the color or pixels
if this orange it must be orange if it's
an apple like we see red must be apple
but your customer comes you comes to you
again and said in production system is
actually the performance of the camera
is not so great so you would get a
monochrome image what kind of program
code you would write to classify this
route in this case you cannot rely on
the color or pixels you have to take a
look at the shapes or patterns or
texture and then your customer comes to
your game and actually in production
system you have to classify these images
to
they all look like um mops or a loom or
something but here if you're carefully
looking at some of the images some of
them are actually dogs
these are dogs what kind of Java code
you would write to cross by ZZZ
so actually in these cases the neural
network of machine learning does a
really great job specifically if you put
these images uploaded to the cloud
vision API the quad visioning API does a
pretty decent work on crossfire ZZZ any
machine learning algorithms cannot
achieve 100% accuracy it's really almost
impossible so usually machine learning
can gives you like a 70 or 80 or 90 95
percent accuracy not 100% but still it's
pretty reasonable and decent job it is
doing so how does it how neural network
can serve that kind of problem you can
think neural network as a function
function in mathematic or functionally
in programming language so you can put
any kind of data as an input and you
would get the article data and you can
train the neural network to solve your
problem whether it's an image
recognition or audio recognition or not
- wrong it's processing or even you know
if we can try training the neural
networks to solve your business problems
such as finding them throughout the use
cases from for the credit card financial
use cases or finding a premium user from
e-commerce website or finding a cheating
user for your gaming server so anything
can be represented other numbers in a
vector or matrices and try to use the
neural network to whether our neural
network cancer be a problem so let's
take a look at the real demonstration of
how neural network works in this case I
directly use two data two kinds of data
one is X 1 and another is X 2 and if you
plot this data as a data point in a 2d
space there's a patterns spiral patterns
orange spiral and blue spiral what kind
of code you would write to classify
these patterns so if you're a human it's
really easy to find the patterns for
example if you have a new data point
here must be blue new data point here
must be orange but it's very hard for
programmers to express or represent that
kind of the complex pattern with sequel
a query or Java called these logics
instead you may want to use your network
of machine learning this is an
demonstration called tensorflow
playground where you can actually build
your own simple neural network inside
browser and try training gene model by
putting many training data so I have
just started the training the neural
network and you are seeing that the
computer is trying to capture a certain
complex patterns gradually by looking at
the training data so these are the
training data if you must have to
provide and then computer tries to mimic
or capture a patterns that's right
humans do so by spending much computing
power and providing much training data
the computer is able to capture a
complex pattern just like the double
spiral patterns so in these cases where
you have the very complex pattern inside
data it's much easier to use machine
learning or neural network to capture a
certain partner from data instead of
writing many complex and fragile
conditions and equal statements in your
in your program and I have used two data
x1 and x2 in the previous example but
you can extend the same approach or
technique to cross by many of different
kinds of data such as the image data
example if you have a handwritten text
as a monochrome data you can flatten the
pixel data into a single vector with 784
or numbers in a single vector to train
the neural network
with a single Raya this is not a deep
planning this is a very simple muscle
simple neural network with single layer
but even this single layer neural
networks cannot recognize the
handwritten text at about 90% accuracy
so by training the model the neural
networks can recognize what picture you
have to what pixels you have to look at
to recognize digit 8 what it seeks or
justify so actually it works on a very
simple mathematics with multiplication
multiplications and additions but having
our multiple layers of those simplest
neural networks you can do much more
better job on recognizing complex
patterns from data that is so-called
deep neural network or deep planning's
at Google we are using deep neural
network model for image recognition with
about 40 layers or 80 layers between in
potato and art potato so this is
so-called deep learning and by training
the deep learning model you can see the
numerals in the lower layer can be
trained to recognize a very simple
patterns so-called edges of objects or
neurons in the middle layers can
recognize textures or patterns of in
images neurons in the higher layer can
get much much smarter so that it can
they can recognize an object parts of
objects record nose of dog or we in
automobile or eventually you to have new
ones that can be coming as the whole
object record it's a vehicle or flower
wedding party or mountain and so on so
this is the very basic of neural network
and deep planning and how Google has
been using the technology for
implementing our services they actually
we have already have over 100 production
project that has been using deep
learning not only the traditional
machine learning in production for
example Google search service has
introduced the deep learning model in
2015 so if you're using Google search
service every day that means you are
already using
be planning from Google everyday the
deep running at based ranking algorithms
can determine which one should be the
first or second or third in your search
result Google photos is one of the most
successful application of the planning
so now you don't have to put any labels
or tags on the images you have taken
with your smartphones instead you can
just let the photos recognizing the
object inside those images so you can
just type keywords such as dog or a
friend's name or the flowers to search
search for the objects inside images
inbox is a email application from Google
the mobile applications that has smart
reply feature that recognized what kind
of the conversation is happening on each
email thread and tries to show some
options to reply to each email thread so
if you are looking for the I feel
looking at the lower part of the
applications you'll be seeing there will
be a three options record no brands yet
I just sent you so that users can just
press one of those options to reply to
email thread and now for which were
present of all responses sent on mobile
application is already generated by AI
or the machine learning so humans is now
stopping writing emails anymore people
translate this entry introduce newer
machine translation model that has
improved the quality especially the
fluency of the translated text
significantly this is an different use
case in the Google inside Google in the
Google Data Center in Google test center
each data center building has record ten
or twenty or thirty thousands physical
machines in a single building and we
have been using human operations to
control the cooling cooling a resource
optimization but we have switched to the
automatic or automation by the deep
running algorithms by putting all the
different the various or major
from the IOT devices such as the
temperatures or power consumptions or
what was only on each service or even
the weather informations are coming from
the outside from the building or the all
the sensor data is coming from the the
power generator or power conversion
systems then the did the deep running
model was able to reduce here energy
consumption for power cooling for
cooling systems up to 40% the Google is
spending so much money on the deep power
cost for the cooling system and you can
reduce the 40% of that amount of money
by just turning on the switch of AI so
the planning is not an a hype or buzz
word or research project at Google
anymore it's a stable production project
that has been used in the over 100
production production projects and now
we are trying to East analyze the power
of the machine running to the external
developers and customers and we have two
different kinds of the products one is
machine learning API and another is
customized customizable machine running
model so let's start talking about
machine running abs first machine
running api's is a wrapper for the pre
trained model google has been training
the many different models for image
recognition or voice recognition or the
natural Rani's processing so you can all
you have to do is upload your image or
audio or text file to the API and that's
it you don't have to have any expertise
or knowledge about machine learning so
let's take a look at the actual
demonstration example if you go to the
product page of the cloud vision API
anyone can try the vision API without
spending any money or signing a signing
in with your account so you can go to
cloud.google.com and then find the
product page for the vision API so you
will find this and drive API box in the
middle where you can anybody can upload
your any image to try out the
API so if you upload the sheepdog image
then you'll be receiving the result like
this in a few seconds like so the cloud
vision API can become as it's a dog it's
not mop and also you can try division
speech API that provides the high acuity
voice recognition and also I have an an
accent in my English but still it works
beautifully for the accented English as
well Remy tribe although this is a
demonstration of the voice recognition
by Google steep learning technology like
this so if you have for example if your
customer has a huge call center where
the operators are talking of is New York
their customers every day you can just
record those voices and put those voice
data to the speech API to convert those
conversations into text easily and then
you can put desserts a colada text to
natural language API to have better
understanding what they are talking
about or meaning of each sentence so for
example by sending the text to these
natural language API you can get
entities such as the nouns of product
names of services for example the Google
the now the world goggle is recognized
as recognized as a world for popular
organization with a Wikipedia link and
you can also do the sentiment analysis
so in this case there's no you know
positive or negative meaning in the
sentence but if you gather a thousand or
tens of thousands of the tweets from
Twitter or social channel you can easily
put those tweets or social feedback from
it for your products or services and try
understanding what they are saying about
your products or services they are they
talking about anything anything positive
or anything negative on your product or
service very easily and also you
is redo the syntactic analysis you can
easily understand what are the part of
the speech for each words such as now
evolved or objective so nowadays people
are still using the database and very
simple the pattern matching for
analyzing user feedbacks or user
comments but by putting those the user
feedback to user comments to the natural
language API you can easily have a
deeper insight for those these the
comments or use a voice for example if
you have a product name or product
service name then you can try counting
what kind of the objective they're using
for your product name or service name
example this product is fast or is slow
or good or bad you can easily get the
relationship between those the words or
part of speech so these are the machine
learning aps so you don't have to have
any machine Linux parties for using
these aps these are available today and
you can just put your data to aps but
those ApS cannot solve all the problems
for example I'm getting so many
inquiries from hospitals or medical
institutes Institute whether the deep
learning can find the cancer from Shiki
or MRI images another customer from the
US coke dealers are trying to use the
deep runnings for recognizing the
carmaker model from the image of each
class those customer specific or
business specific requirements cannot be
solved by the machine learning API
because they are all generic
terrain degrees for which the general
dictator so in those cases I'd recommend
you to take a look at tensorflow which
is an open source tool for build your
own customized machine learning model
after how many people are harder about
tensorflow ah many people thank you so
much yeah
so what is tensorflow tensorflow is an
open-source machine learning software
developed by Google brain team and
actually this is the standard machine
learning - used in the Google for
developing any new machine learning or
AI services and products and we have
open sausage in November 2015
tensor flow is scalable and portable so
you can start trying the intensive flow
by using your Mac or Windows or Linux
laptop so down login tensorflow
is free anybody anybody can download it
to your Mac or Windows and try to easily
very simple the hello world kind of
these sample calls and if you find the
product tensorflow may solve your
problem
then you can start using GPU single GPU
or two GPU or ten GPU or 100 GPU to get
much much higher accuracy especially for
the image recognition and large scale
the language processing and audio
recognition you may find the training
time take it would be much much longer
than running the sample code for example
in the first demonstration I have shown
we skipped insecure playground there was
only two kinds of data X 1 and X 2 but
it took record one mid to train the
model but if you have pixels with for
example 10,000 pixels in one images then
you know if you are still using your
laptop or PC it takes forever you have
to wait few few days or maybe weeks to
finish all of the training for your
image later but if you just use the GPU
GP is usually much much faster than CPU
it's 10 times were sometimes 50 times
faster than XI PU for training the
neural network model but she P is so
expensive if you have Q by a single GPU
server with directed a 2 or 4 GPU card
it will cost Rica
$10,000 yeah it's expensive so that's
where you may want to
rent a GPU time from crowd because at
Google crowd we provide the GPU at about
0.9 dollar per hour for each GPU so you
can just rent one hour or two hour for a
few GPS and try out whether a deep
running can solve your problem on that
antenna Pro is designed to be scalable
so you don't have to change any of your
tensorflow code a little bit only you
have to change the little bit part of
the stencil for code to scaling out the
training you can start with your laptop
then move to the one GPU and then move
to the tens or maybe hundreds of GPS
without changing any major part of the
your tensorflow model and once you have
finished the training your model you can
copy your machine learning model to any
smaller devices such as raspberry pi was
not a phone tracker Android or iOS
especially recently we have announced to
tensorflow light which is an a new
version of the tens of long time is
specifically designed for the smaller
devices like the Raspberry Pi or Android
so that for example if you have a
factory where you don't have any
internet which ability or cloud
accessibility then you can run your
embedded systems or Raspberry Pi inside
your factory running the tensorflow
model in it so that that runs with a PI
or embedded systems can detect certain
patterns from IOT sensors or some object
on a Bert Convy or things like that
so with those benefits tensorflow has
been most popular flame up for deep
learning development in the world if you
compared it with the other frameworks
such as coffee or CNG k MX net it is
much much the popular framework and
there are so many customers who are
actually using tensorflow
including Airbus Dropbox eBay Qualcomm
and even IBM is setting the tensorflow
with their hardware servers and even the
Japanese cucumber farmer are using
tensorflow
how many people are harder about this
story cucumber farmer sorry oh thank you
so much thanks
I took this photograph visiting in there
puking more farm I think it was like two
years ago and they have son this guy was
actually an engineer for the embedded
systems until two years ago maybe a
three years ago yeah and he quitted the
company and started helping his parents
to keep on farming but he found the most
tedious task time-consuming task for
cucumber farmers is sorting cucumbers in
looking at the shapes and colors and
links and his mother actually has been
spending eight hours a day we'll just
work sorting cucumbers and his father or
himself didn't wanted to help her or his
mother's mental state were classifying
the thousand documents into nine
different crosses so instead of helping
her
he download the cancer crawl awesome
haha and took nine thousand photographs
of cucumbers and trained in intensive
role model with D levels chosen by his
mother and he's got the pencil for power
to cucumber sorter
he used to Raspberry Pi and you running
tensorflow on Raspberry Pi so that model
can crash by the cucumber's into nine
different cross crosses at a pretty high
accuracy and this system only costed
raka $1500 present two thousand dollars
so in a few years ago if you want to be
this kind of high quality high accuracy
imagery condition system for agriculture
use cases maybe your system is
integrator would have a quotation
service the $1,000,000 or hundreds of
thousand dollars but now you can only
spend two thousand dollars to build this
so the thing is that the d-plan
technology is being commoditized rapidly
by having the community and ecosystem
with tensorflow if you go to the
intensive rock community or meetup or if
you look up some tinsel all the problems
or keywords and you can easily find the
solutions for your problem but it's
still there's a challenge for bringing
the technology into production to solve
your problem especially I want to
highlight the comparative computation
you need much much computation power you
have to use a bunch of the GPUs this
solution is the data center the computer
that's the largest difference of the
Google crowd with the other cloud
because we have been designing our data
center as a massive repower computer it
has thousands of machines but I don't
have the offif stress to explain what
this data center the computer we have
two technologies one is continued
technologies that is called bulk Bo are
G so Bo RG or ball is the Google's
proprietary on container technologies we
have been using for over 12 or 15 years
for operating any of the Google services
in Google search or Google Maps or Gmail
so actually did almost all the Google
services like a Google Google magic
Google Maps or Gmail Google search are
not using any virtual machine at all
they are running directory on top of
Pisgah machines and contained by the
debug continuous systems that is one
technology the another technology is new
at the network we are not buying in
Cisco routers or juniper routers anymore
yeah just a few of them we buy for the
main use cases for the new audit
building the data center we are building
our own switch fabric the routers and
switches from scratch and that provides
the microsecond latency for combining
consolidating the server resources in
Google data center
so and the result is that a much much
faster throughput or performance on big
data processing especially for the deep
running training so by running the
tensorflow on Google cloud environment
you can get much much faster training
time then using the very few numbers of
GPS for example if you use 50 GPU you
can finish your training 40 times faster
with 500 servers you can shorten the
time for 300 times faster so what people
the majority of the deep running
developers and researchers of spending
few days or few weeks to finish their
training for neural network the Google
software engine has only spent are tens
of minutes you know he or she can just
go to the ranch and come back to the
office then their trainings have
finished already to that a huge
difference a huge reason why Google has
been so successful on deploying the deep
running technology into production so
it's not all about the data scientist a
mathematical model but also if the cloud
environment network and continued
technology is the most important factor
for bringing the technology into
production we even design our own LSI or
customized chips just for running tens
of Rod this is called tensile processing
unit or CPU this is not a CPU or GPU
this is an customized digital secretary
designed from scratch by the Google
engineers and its performance is is
almost equivalent to the latest
supercomputers so you can say that
Google has been building our own
supercomputers just for deep learning
training and prediction and now we
externalizing this power of Google Cloud
to external developers as a product
called ml ranging or machine learning
engine that is a fully managed platform
for tens of roll that so you can all you
have to do is upload your own tensor
flow graph to the cloud and Google will
take care of the all the hardest part or
the critical part
such as the this will be training how to
build on GPU cluster for this right
scale distributed training or hyper
parameter tuning so they take a look at
this some demonstration that is called
fine G or ng this is an integration of
sauce tensorflow Emeril engine combined
with speed C API and natural Ranga JP I
modified come on come on come on should
we gum and there the camera identified
extra long lasting watermelon gum now
the cameras so this is the one of the
year total possible total solution and
actually I have which in the designed up
for this demonstration from Google i/o
and the hardware part only cost record
$3,000 because I have chosen to use the
very cheap inexpensive robot ah and for
the software part I have asked our
vendor to deal with it and it costed
only Degas $13,000 it's quite
inexpensive and they got these systems
within 20 days so you can have this kind
of G the state-of-the-art deep learning
the imagery conscious system with inner
record 30 or $40,000 within one month
let me
okay
and let me show another example this is
so called what is a a queried smart this
is an integration of the data warehouse
and the machine learning usually data
warehouse such as Google bigquery or the
a de Bracy redshift or any other data
warehouse cannot handle image or the
other content so it can only execute SQL
but by combining machine learning with
those data warehouse you can get much
deeper insight on the data warehouse
queries because I put this ISM ok this
is an example of the image similarity
search so you can choose one of the key
images to search I have chosen the
elephant then the bigquery is running
and query against 1 million images to
find similar images and please note this
is not looking for an elephant's this is
not a label based or index based
searching this is actually comparing the
pictures to pictures for 100 image or 1
million images so that you can get all
these similar images with the same color
and shape and textures and patterns on
images and this is an only example for
the images but you can also apply this
technique to any kind of recontact you
can define the feature vector for
example the products or users Pro
natural languages anything you can
define and set certain features as a
vector you can use the data warehouse to
look into two equal acuity similarity
search so finally I directly show some
use cases of the machine learning in the
real world there has been already and
some enterprises and companies that has
been using tensor flow and ml ranging in
PLC or production systems this is a
project called global fishing watch this
is a project for or prevent overfishing
by watching how many vessels and ships
in each ocean is doing a fishing on that
and the product is tracking all the
real-time GPS position of
hundred thousand vessels in each autumn
and collecting those real-time GPS
position on Google Cloud Storage doing
some pre-processing and then uses
tensorflow
and machine learning engine to extract
certain patterns from those movements of
GPS positions so that the system can
tell whether it's ship or vessel is
doing trawl fishing or longline fishing
or paths and fishing at high accuracy
and actually this project was able to
put some fly on those violated vessels
or companies by using this data
processed patterns of row
QP is a one of the major food
manufacturer in Japan they have been
processing producing the baby foods and
the main concern is quality of the
ingredients so they're using the very
high quality potato cubes but then the
the hardest problem or how this
challenge for them is defining the bad
potatoes because they are already using
the high quality but potato cubes so
it's very rare to find bad ingredients
maybe a few cubes in a day so for the
existing image retention systems are
machines for factories it's very hard
for finding those the bad potatoes so
the happy has been using a human power
shipment workers watching the better to
convince all the day a wrong to finding
the those bad potatoes instead they have
recently introduced the tens of
role-based the image recognition system
so you can hear the sound of the
demonstration
this sounds like Super Mario Brothers
but actually it's not
so does Super Mario Brothers Rex bell
sound tells you the position of their to
compare where you'll be seeing the bad
potato chip will be coming so now before
human workers is much much easier
oh there's no more monomers also thank
you sorry about that so now it's much
much like wait tasks for the human
workers and they were able to reduce the
human worker cost a significant three
kakora is using the tensorflow for image
recognition for the serial numbers in
the bottle cap so that they're the
smartphone application can take a
photograph of the bottle cap and
recognize the numbers in a cap to apply
for some hours or or presents awesome
and the interesting point of this use
case is that the as I said machine
learning algorithm is is not perfect you
cannot get you 100 percent accuracy so
it makes mistakes but they are letting
consumers fixing those mistakes and by
getting the real images and the correct
labels from the consumers there they are
able to continuously improving the
accuracy by using the the feedback from
customers this is the last use case
demonstration by alternate organ it is
the largest real-time used curve auction
service in Japan they are handling over
5 million curves in a year but the
largest challenge for them is to
classify the images so many images you
have to upload 20 different images for
each car to enter to the auction and it
takes 15 minutes for human operators to
classify those images whether it's an
image taken from front side rear side
right left or image of the tire or
steering wheel and so on so they have
built the chance of fraud based car used
her image grass fire and by using this
the technique called transfer learning
they were able to reduce the number of
the training data set so you can
only have to prepare 200 images per car
model to get high accuracy and also
initially they were using just a single
instance on a crowd to train the model
but by introducing the MA ranging and
this will be the training they were able
to get much much faster 86 times faster
training time just like the Google
engineers are doing so the end result
for business is that much faster speed
for the classification they were able to
reduce the operation time from fifty
fifteen minutes to three minutes this is
the actual demonstration of the system
so you are uploading in the 20 different
images for each single car from
different year side then the system can
start classifying the images and the
most important point of this project is
that the organ didn't have any expertise
of machine learning or deep learning
when they have started this project but
because tensorflow
has a very matured community and
ecosystem so they were easily able to
find the best partner the machine
learning expert which Davidians of all
application expertise and they spent
about 3 weeks for workshop and training
and the technology transfer from those
expert company to their IT department so
now the production system is being
developed by only by the organizer
department so you don't have to hire a
very expensive data scientist to build
these kind of systems what you have to
do is to go to the center for community
and works spend some time is with those
expert data scientist and learn the
technology by yourself hey so summary we
provide two different kinds of the
machine learning products one is the
Amero api that could be used today
without any machine learning expertise
or experience you can just approach your
own content and you can also combine
this a mirror API with the tensile
rollbase to customize customizable
machine learning solution so we provided
several as the open-source
- so you can just start download
tensorflow to your laptop - or to your
on-premise devices or any other crowd
and if you find it's useful you can try
running it at very high scale with
current machine learning engine combined
with the other data warehouse or storage
or batch processing system ok that's it
thank you so much thank you I have a
number of questions from the audience
here let's start with an easy one
ok does the speech API recognize other
languages let learn English I think it
supports over 80 languages including
dialect yeah
if I use the online api's the cloud
services with my data
hmm does that mean that Google then has
access to my data that's a great
question and I have asked that question
so many times as I said no because this
is all Google cloud services and Google
service is a service for the commercial
enterprise customers and it has the
terms and conditions that state we are
not bringing any customer customer data
so that means you can you don't we are
not training the our model with your
customer data instead we are using
consumer data for example if you use the
Google Image Search it is a free
consumer services so it has a terms and
conditions that Google may use your data
for training our data or for our
development so we are using the data
acquired from the consumer services but
the we are not using in any of data you
are approaching to those ABS which
language language bindings are available
for tensorflow Java C sharp right now -
only Python only path and some of these
sheesh she prefers yes but Mary python
alone I have some
any questions here okay most of them
fall into those three that I already
asked so bear with me it's a simple well
maybe not that simple actually you talk
about energy savings in the data center
yeah
do you know which which parameters do
you react on like weather data actually
I don't know much about the details of
the systems because it said built by the
deep mine team and it's kind of the
heavy crash by information so we are not
exposing what the parameters it is
actually looking at but I can say that
we are looking at the hundreds of the
features or attributes to trend in your
network model I think that's it okay
thank you so much thank you so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>