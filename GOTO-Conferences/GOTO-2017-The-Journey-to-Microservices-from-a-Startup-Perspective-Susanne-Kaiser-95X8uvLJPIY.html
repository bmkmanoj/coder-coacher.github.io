<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • The Journey to Microservices from a Startup Perspective • Susanne Kaiser | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • The Journey to Microservices from a Startup Perspective • Susanne Kaiser - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • The Journey to Microservices from a Startup Perspective • Susanne Kaiser</b></h2><h5 class="post__date">2017-09-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/95X8uvLJPIY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so a large organization for instance
let's take Netflix I guess I don't have
an exact number but they at least have
more than 1000 software engineers in
comparison we have 12 so there is a big
difference between large organisations
and startups and unfortunately there
exists no golden rule that you can
easily apply damn so instead you have to
deal with a lot of trade-offs along your
way
Thanks slide please and before we go
before I go into the order into our
journey details let's give me you a
little brief overview of what we are
doing so my name is Ivana Kaiba
I am the CTO of just software we are
start applicated at Hamburg and just
software we developed just social that
b2b solution providing apps for
collaboration and communicating to
support teams working together more
efficiently and can you next slide
please and before I explain why we
introduced as a start-up was very tall
with very less resources we introduced
micro services I will take you on a
journey to our beginning so at the very
beginning everything was one single unit
and every aspect so we were one team
working on one collaboration product
implemented as one code base based on
one technology stack next slide please
and after a while everything evolved
which is quite well but try it's fine
because we added more and more features
to our product and we our number of user
increased and the number of you and
the team was growing so that's supposed
to be fantastic but instead reached a
point approximately one and a half years
ago where everything felt kind of clunky
everything was kind of tied together so
from the organizational perspective it
took quite long to get things done so
discussions meetings or decisions and we
had no really clearly assigned
responsibilities so it took a while
someone felt responsible for a specific
action for example when a pact arise so
who take takes the responsible for to
analyze and fix it so our processes was
kind of work we're kind of slow and our
productivity suffered and from the
products perspective we were
continuously adding more features on top
of it and so the user experience and
user usability suffered from the
continuous feature amendments because
instead of solving a loyal users
problems in a very easy way we were
constantly or incurring increasingly
confusing them so and from the software
attractor architecture perspective it
was not very easy to add new features
without affecting the entire system and
also not to release those changes that
we did without redeploying without
rebuilding and redeploying the entire
system so there involved a kind of need
to split and shift things next slide
please so product wise that was one and
a half year ago we were thinking of we
established the vision to divide our one
product or one big ball of mud into
single ads and each of them taking
taking care of a specific use case and
solving one problem and this one very
well so we split it our one product into
several several collaboration apps
taking care of document sharing or task
management or epinet for real-time
collaboration and also for exchanging or
sharing corporate news and information
with an enterprise social network next
slightly
organizational wise we divided our 1
team into smaller multiple teams and
with the goal to establish autonomous
cross-functional teams was well defined
responsibilities so we want our teams to
work on different parts of systems
independent furniture from each other at
a different speed and with minimal
impact impact across the teams we
assigned to each of these teams specific
collaboration tabs so that the contact
can take care of it at these of these
collaboration apps and develop and
deploy them at their own speed so we
want to release changes independently as
well and fast and without affecting the
entire system to gain autonomy we have
to get rid of dependencies and to
achieve this we have also two kabobs
within our software architecture so in
the long run we wanted to introduce
micro services and after we have
petitioned our product into single app
and split our one big team into smaller
ones we were as well defined
responsibilities we the let the logical
next step was to introduce micro
services to also gain autonomy and
flexibility in our software architecture
as well so this looks very easy at first
glance but it's a nice it's a lot easier
to say then do because micro services
make slightly come with a lot of
complexity that might not be obvious at
first glance so in a distributed systems
or your micro services are communicating
over a slow and unreliable network and
this means that these services can fail
and at any time and you have to
establish a mechanism to make your
system resilient and so you had to add
complexity to handle partial failure in
your system and since microservices are
dealing with partitioned data you are
losing consistency and a distributed
system you also have to take care of
handling eventual consistency in your
system and since you are now since your
operational complexities increases
because you have to deal with more
moving parts you have to add a complex
82-year to monitoring and deployment as
well and since your micro services are
communicating over an API yes - you have
to consider and refer to it in your
testing phase as well with consumer
driven contractors for example and with
all those complexities is that your
skill set is totally different than when
implementing a micro service and this is
kind of like expensive on the other on
the one hand because you either have to
learn the new skill set or you hire
someone and hire some consultants for
example and another thing that you have
to reflect is how to handle
authentication authorization and another
aspect is the development environment
because you don't want your developers
setting up all your services and said
you want to have an easy access so that
they can develop their services smoothly
that's likely
so untangling the monolith is hard work
and very time consuming so this
development process is at first slowing
down it's it's getting worse before it's
getting better and the transformation
process itself takes far longer than you
originally anticipated so at first when
we introduced them we missed a milestone
and that's the reason why you have to
take care of those complexities and take
your time to get your skills up to that
you can run a micro service in the
ecosystem and if you have if you're
dealing with core functionalities with a
lot of dependencies it's very hard to
untangle all these dependencies and you
don't can leave a side that you still
have running system that you still have
to maintain
and take care of so after if you look at
all these complexities and challenges of
microservices you might ask yourself
well shall I introduce Microsoft's
architecture or just stay on one of the
architecture well and it depends it
depends what you want to achieve and it
depends of in what what situation you
are and for us it was the my procedure
Neetu micro-services was not only
technical driven but it was
organizational and product written so we
first divided our product into single
collaboration apps and then also our one
team into multiple smaller team was ok
with the goal to establish autonomous
teams so and we want to assign to each
of the teams well-defined
responsibilities so that everyone can
work efficiently on their own
responsible services and in addition we
want to develop and deploy independently
so each team should have the capability
to implement it and to deploy it at
their own speed and rate without
affecting the entire system and also
without affecting the other teams and to
release changes quickly so that was our
motivation why we introduced micro
services and after you have decided well
next slide please
let's start with micro service about how
how shall we start with micro services
so we have your big ball of martin you
try to to decompose like service out out
of it and so what we then derived was a
kind of transformation process
existing consisting of different parts
the first one is to identify candidates
which are good candidates for my per
services the second one is the de coma
decompose decomposition process itself
and the third one is the establish the
micro services ecosystem that I won't
have to go sequential that can also be
in parallel as well
so let's start with identifying
candidates and before we do it
that's next flatly we have to consider
the key concepts of good modeling good
micro-services to achieve the main
benefits out of micro services and these
are the loose coupling between the
services and high cohesion within a
service so no sorry
so when services are loosely coupled a
change of one service shall not affect
the other services and you make changes
easily I can make changes early to one
service and deployed without changing
the entire system high cohesion is
reflected by related that rate related
behavior she'll sit together so when
when you change this behavior you want
to change this behavior at one single
point if you have two changes at
different parts of your system you have
to redeploy all these services that are
related to this behavior and then your
deployment process is coupled again
together and that's something that we
don't want to achieve so this is all
these are the key concepts that you have
to keep in mind to to to identify
candidates for micro services so next
slightly this related behavior is
usually reflected by the bounded context
we have heard of before it's a pattern
of the domain driven design and it's
reflecting the responsible cific
responsibility for well-defined business
function a well-defined business
capability okay
it's a half automated
miracle so in our case we used our
collaboration abs working as bonnet
context as the coerce grain service
boundaries and from that point we can go
in and to find a great services as long
afterwards so and now the next part of
the transformation process starts the
decomposition of the micro service
candidates the first approach that we
did is that we established a coexisting
service from scratch and we used our
drive collaboration amp with taking care
of document sharing and I'm spoiling it
it was not a good idea but generally the
speaking there's nothing wrong with
creating coexisting service from scratch
but I will do forget to be to the
disadvantages in the next slide but what
we did and this one's at the coexisting
service we were creating it from scratch
and and established a document sharing
service itself which has the data
authority over documents and so just joy
itself owns the data or thority over
that means and each document has an
author assigned and the author itself
it's still stemming from the profile
management which is still kept in the
monolith itself so the next question
arise so whenever we display a document
shall we then request the author
information directly directly from the
models or shall we then keep it
redundant in our and our drive app so
that's what we did we copied we kept a
redundant data of the profile
information in our in our new service
and to keep it in zinc we've established
a message broker that the monolith
itself is then publishing modification
events to to whenever a profile data has
been updated so that the marks of the
new one can consume it and update it
and a tech accordingly well to be honest
it was very very heavy undertake because
we did all at once as I was mentioning
before it was not an exact equivalent of
the existing service instead we added
more features in the same process step
and we introduced a totally new data
structure because we also had wanted to
cover some specific requirements as well
and also a new user interface to to
improve the user experience itself and
in the meantime we still have to
maintain and run the current system so
this took a long time and was kind of
frustrating because we didn't get those
results very quickly and we could not
really gain experience through the
process by taking this first document as
a service and destructiveness of the
service and adding new features on top
of it as well so instead we should have
focused on smaller chunks and so what we
did instead were the next service that
we the next collaboration app that we
used as a candidate for micro services
is that we split it in smaller chunks
and going from top to down so we have
identified the next candidate for micro
services and what we did first is that
we extracted the user interface first as
a separate app extracting the web client
and the business logic itself is at this
step still residing and then the
monolith and the web client itself is
the monolith it's introducing a numerous
API which can be addressed by the new
extracted web web client so this gives
us the advantage that we can develop and
deploy the web app independently and
that we can iterate on the
on the user-interface very very rapidly
so that's the first step that we did the
second step is then extracting the
business logic and that is more work
than extracting the web client because
you also have to take care of the
dependency that it had before in the
monolith so for every dependency that
you had and the ammonal is is that you
have to specify or provide an api that
on your new servers so for example if
the monitors are still accessing our new
service we provided for example a REST
API console could also be another one
and and at that point we are still
accessing the same data storage and
that's the one that we are untangling
the next because to become a standalone
decoupled service we finally need to
split the data storage as well so that
our new service is becoming the data
Authority or is getting the data
authority of its own business functions
and in case that you had keeping
redundant data that we did for example
with our drive app like that we kept the
author data redundant as as soon as you
do that you have to keep keep them
somehow and zinc and you for example and
we did it by establishing a message
broker so whenever the redundant data
has been updated and the monoliths and
the event has been submitted and the
consumer has been updating it
accordingly so when you're dealing with
several candidates for micro services
you ask yourself okay which one shall I
do first which I will show the first
address and the easy
principle is to extract those that are
very easy to extract because they have
less or very few dependencies and
because when you start with those that
are easy to extract you are gaining a
lot of experience in a short period of
time and so you are then also getting
experiences might
services but also with the extraction
process in particular and then you can
also focus on that one that gives you
the most benefit when extracting a true
micro-services for example if you have
some services or some candidates that
change frequently then it's a good
candidate to use it as a next one and so
then after you have created all you have
you converted into my per service you
can then deploy changes faster than
before
in other words another option is that
you are extracting those that are using
different resource requirements for
example if you using someone with high
memory consumption you can deploy it on
server with high what high equipped
memory so you can scale your micro
services world easily and other thing is
that you should stop feeding your
monolith because when you're carving out
your services on your one side and
you're adding new features or new
functions on the monitors then your
monitors not going to shrink instead
it's staying the same or in worst case
it's even growing and it slows down your
transformation process so the next thing
is that I would like to address is
establish a Microsoft ecosystem and it
might be kind of particular for us
because we are running our services our
product not only in the cloud but also
on-premises so and we have large
customers that require to run our
services on their own machines so we
have also established a ecosystem and so
the first is that after we have
untangled our micro services how do we
address them how do we access them from
the internet from the public internet
from the client from the user interface
and one thing is you could directly
access them through a user interface but
this runs into the problem that you are
exposing some parts of your internal API
that are usually related to user service
communication and in case of the
services are running on
on different domains especially with the
JavaScript liens you have also enabled
cross-origin resource sharing and also
your client might do instead in terms of
in case of retrieving information from
several micro services you have to do
multiple round trips and you also might
have different clients a mobile client
and a desktop client and they might have
different needs so what you can
establish then is an API gateway to work
as an adapter as a single point of entry
for you micro services world and it this
one eliminates your course requirements
and because we are now running on one
single domain on one domain and it keeps
your internal parts of your API inside
of your entire internal micro services
world and it might be a gateway as well
also handled like protocol translation
and also provides caching mechanism so
our monitors itself was mainly
implemented in Java and we used for our
ecosystem we use mostly Netflix open
source software and with the spring
cloud libraries and Netflix OSS provides
a lot of frameworks libraries to build
your own micro service architecture and
infrastructure so spring cloud provides
a very easy interaction with us
most networks OSS just was adding
dependencies to your class pass and
annotate something I really bring up
some examples later on so the API
gateway is the first citizen of our
micro services ecosystem now the next
one is like the authorization service or
there's a reservation handling and
securing a monolith is easy because you
usually have a common security component
which takes care of the authorization in
your request handling chain and then
propagates user
formation to your subsequent method
calls and they can trust this
information in securing microservice
instead is a lot it's a lot difficult
because you have to figure out how
services can trust each other and you
also have to avoid handling
authorization in every micro-services
and this something is something that can
be handled by introducing and global
authorization server which takes care of
this cross-cutting concern of
authorization so we established an all
whole server to be to run as a own
service and our API gateway so this all
servers assessing is as a providing
access token that the user interface can
use Texas specific resources to address
resources from the micro services
themselves and our API gateway in this
in this context it's been used as an OS
token relay that means that after the
the user interface has obtained this
access token it's probably it's
publishing the access token along with
the original request to the micro
services itself one downside is with
this approaches that the micro service
itself still have to check nabela G the
well validity of the token and
additionally have also to retreat user
information so the skin causes to hire
higher load on the authorization service
so that could be also another approach
that you introduced in JSON web token
instead to decrease the load of the
authorization service mm-hmm you have to
eliminate the token validation and also
the ritual of the user information and
we could instead carried the user
information as an identity claim on a
JSON web token in addition this JSON web
token is automatically be signed by the
authorization service so that the Micra
services themselves can trust this
information the able API gateway it
works as a
Constanza lations so was it does when
the user the user interface your client
requests an access token and obtained
after it has obtained this access token
it sends this token along with its
request to the API gateway and the API
gateway does do the translation so it
extracts the access token and used this
one to the senses to the authorization
server receives an JSON web token and
prevent publishes then forwards those
JSON web token along with the request to
the underlying micro-services so that
they that the Micra services themselves
only have to take only have to process
this this web token which is quite easy
to implement the next citizen of our
micro service ecosystem is the service
discovery and my microsomes architecture
can contain up a large number of micro
services and interacting with each other
so how can services elia easily identify
all the running instances it would like
to interact with a manual configuration
is totally impractical and is very
brittle and so a service discovery
instead provides a single lookup service
for each service instance registers
registering itself automatically at
startup and other services can discover
those retrieve those already wretched
services and discover them and then
afterwards connecting to it so some
solutions are for example Netflix you
agree Eureka console at cities or su
PIPA and we had we used in our case we
used Eureka because it's together with
Sprint cloud because it's really easy
integration it's very very easily to
integrate a bowler because it's only
there you only have to provide you only
have to provide the respective
dependencies to your class pass and
annotate on the one side your service
and on the other side your service your
clients that then automatically register
at startup the micro services that want
to use our service itself can also be
can create on their side for example a
load-balanced rest template and I come
to this one later and use the service ID
and to the related rest template method
to connect to your service so and what
happens in the background is that the
load balance rest templates contain
connector ribbon that's the client-side
dynamic load balancer to discover and to
connect your services automatically so
that's the next citizen of our ecosystem
that introduced a client-side load
balancer it traditionally little bundles
are our server-side components and the
client-side load balancer itself is part
of the would find application and so it
makes itself aware of what services are
available and makes it own choice like
what service to call at any given time
so we also in the service discovery
slide I was talking about the load
balance rest template and that is
automatic connects to ribbon and well
what ribbon itself it's a client-side
load balancer and also from the Netflix
OSS family and what does it does is
automatic in taghrida the service
discovery to obtain the server list and
youth Eureka when its present on its
last path and load balances
automatically if multiple services of
our Microsoft's are available so there
is no implementation called it's all
client site and you don't need your
service ID configuration when carving
out services
you have to in a distributed system you
have to face the fact that you have to
challenge where the face of the
challenges that we are interacting over
a slow and reliable network so we have
to to make it more resilient we have to
define for failure that meaning that we
have to introduce timeout handlings and
have to provide four legs and also
circuit breaker pattern and what's the
circuit breaker task we implemented as
with history it's another family of the
another family member of the necklace
OSS it monitors every remote call that
you defined as a hysterics command and
it tracks every request and creates and
counts the number of successful and
failed requests that you did and with a
specific threshold the circuit breaker
itself it opens and returns and failure
immediately it could be for example a
failure at fallback that you have
previously previously defined or an
exception as well so it's a fire fast
strategy I have to make it a little
faster so I go so this happens a
client-side as well so you don't need a
server you only need specific
annotations to it so you define a
history command and define as public a
message if you want to and you are then
automatically a history history is then
monitoring your remote call and what is
also very important is that you don't
forget to set your timeouts as well
because this is something that history
does not care care about it was taken
care of
instead you have to set time off as well
and what history does it does emit for
every acute event and its current States
an activity stream which can be
displayed as
through history dashboard that's kind of
a monitoring web interface which allows
you to monitor your services on on
service levels so we still usually have
monitoring animals on survey level and
hystrix
dashboard well together was turbine
that's another tool of the Netflix OSS
allows you to to display the services
the status of each service and Kampala
date the view itself so the current
ecosystem what we have covered so far is
an api guideway authorization servers
service discovery and monitoring
dashboard and you might think well we
are done but that's not the case because
there are a lot of more to cover for
example the central configuration
management that you can establish or
logging analyzing for debugging for
example that you can log across across
service boundaries and what's what's
also very very important is the build
process and this continues integration
continuous delivery pipeline which you
already have in your in your monolith
but now you have to apply it per micro
service and since the fact that you're
dealing with api's now and more than
before you have to extend your testing
with consumer-driven contract tests then
you have to make sure that you have a
fully accessible environment for your
development that you don't have to take
care as a developer for setting up all
these services themselves so the lessons
that we learned is that during our
journey and we are not there yet so we
are not at the end yet so it's that
starting was decomposing and big chunks
frustrates because it takes a long time
and before you get something done and
you return you receive a result and yes
establishing your ecosystem takes a lot
of times and a lot of time and requires
a lot of new skills and tools and so we
started at the very beginning with no
explicit explicit
infrastructure team and it was slowing
down the process because each team was
kind of finding their own solution and
so it was slowing down everything and
what also helps and which we didn't have
at the very beginning as a holistic
picture of the target architecture
because it keeps you focused on what's
to do next and well in the end it took a
lot of takes it took and takes will take
far longer than you originally
anticipated because you are now going
into this completely new world so as a
summary is that what we can derive from
our learned lessons is that it's better
just start small and split in manageable
steps so service by service instead what
we did in the beginning was kind of
mistake that our chunk were too too
large and established teams that for
micro services that we already did with
our collaboration apps but also first
infrastructure because that's the
ecosystem has to to run and yet you as a
developer I don't want to take care of
the ecosystem all the time instead you
have to have that's our experience what
we made an infrastructure team as well
and also define a target architecture to
keep to stay focused on what you want to
achieve next and well yes it's from even
though it's still a long way to go we
can say that's possible to transfer all
the models into micro services even with
limited resources and so having said
this not only on her product but also
our software architecture was made with
love sweat and tears a lot and now also
with micro services thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>