<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • Simplifying Container Management with Habitat • Michael Ducy | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • Simplifying Container Management with Habitat • Michael Ducy - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • Simplifying Container Management with Habitat • Michael Ducy</b></h2><h5 class="post__date">2017-11-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BmCIr6yWTi4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yes so at the end there will be again a
demo from the back of the room if you
want to do it yes so anything doesn't
make any sense to you I will give a
brief demo at the end of course I always
like to layer in a demo as we progress
but since we're having technical
difficulties I'm not able to do that so
I'm Michael Ducey I work for a company
called chef if you haven't heard of chef
chef runs three open-source projects one
is the original one that we got started
with called
chef another one is called inspect which
is created by some gentleman over in
Germany and then the third open-source
project which I'm going to talk about
today is one called habitat which helps
you package up an application and then
run that application in production all
right while I'm going through the talk
if you want to look at anything kind of
find out more information about what
habitat is and maybe look at the
documentation and other things like that
feel free to take a picture of this
right now and then you can have useful
links for you so you can follow along so
this analogy was made at another
conference where it's kind of like the
evolution of technology right so if you
look at the broom that's kind of how we
used to do things manually bare metal
systems in your own data center you
installed you know you put the ISO in or
the I'm sorry the DVD or the CD in and
you bootstrap the Machine and
kick-started and all those fun things
and then we got a little bit smart about
technology and we started having things
like VMs and things like chef and
ansible and puppet and other stuff like
that and that's kind of the vacuum
cleaner and you get a little bit more
automation but you're still having to
push it around manually and clean up and
then containers and container
orchestrators are more like the Roomba
right where you just kind of set it free
and it just goes and cleans everything
up and talking about the developer
experience of the Roomba or containers
it's usually pretty positive right so
that's the developer and you know using
containers and that's enterprise IT and
enterprise IT is like no you can't be
using containers and the developers just
get out of my way right and then you get
a little bit more cocky as you go along
and you have some other people that are
following you along and maybe you find
some more technology that you layer into
how you're using containers as well and
then what ends up happening is as
Enterprise IT tries to emulate you and
they build the enterprise container
Orchestrator or something like that
right some got awful horrible name that
doesn't do exactly what you want it all
right so you're still over there but the
reality of what actually what you need
to run containers effectively in
production are a little different from
that first touch developer experience
right and so this is well this is a dog
doing how many people have dogs Wow not
I have a dog one other person so for
those of you who don't know about dogs
sometimes they don't always go outside
sometimes they go in your house and you
can see he's done that or she's done
that and then he's also or she's
expecting yeah or inspecting what just
happened and this is important so you
should always look down to make sure
there isn't blood or anything like that
colon cancer is the thing but then here
comes the Roomba and the automation is
working the way the automation is
supposed to be working right and the
automation is kind of dumb to its
environment and of course the Roomba
sees a mess and wants to make sure that
the mess gets cleaned up and much like
when you just blindly deploy containers
into production you now have rubbed
all over your floor right so automation
is great and containers are great and
all of that but there are concerns that
you have to start to think about when
you actually go and try and deploy them
out into a production environment and we
kind of call this the learning cliff and
it's yeah you know you look at the
thread of this tweet and you'll see many
people replying and saying
well that's the same with any technology
right it that is true it's the same with
any technology is that you always have
to read through the hype and you have to
see where that cliff of despair is when
it comes to trying to go and implement
that in production right and the thing
with containers is it makes you rethink
or not just containers but any
technological advancement what happens
is is it makes you rethink the way you
do a lot of the work that you do today
and if you think of if you're in the
last talk in this track the server
lestrade talk it was very much like that
is that you have to rethink how you do
technology and your technological
processes around how you deploy code and
it's going to be different when you're
using different technology so one big
thing that you have to remember is that
when you're looking at containers is
that containers aren't of the right so
we the very first talk and this track
had kind of mentioned this idea and
there's a common when you need to
explain a container to somebody
typically what happens is well it's like
a little mini dam but it's not and don't
run it that way but you know you can
think of it that way but the worst thing
that you can do is treat a container
like a VM if you're actually gonna run
it in production and you know we like to
say that containers aren't VM but are we
actually sure that that's actually
what's happening in production so a guy
by the name of Gareth rush Grove he runs
a weekly email mailing list called
DevOps weekly he actually worked for
puppet over in Cambridge but he did a
study and he looked at a lot of
different things and one of the things
that he found is that 75% of containers
container a full OS container full of us
I've done this talk before and I left
that typo in there and I'm just kind of
like angry at myself that I was correct
that typo and then another study I want
to say this was a data dog study that
data dog just put out is that the
current usage patterns show that you're
only getting about a four to one
container to host ratio
right so for every VM you spin up you're
gonna be able to run four containers on
it so where are the two things that we
can kind of guess off of those two
statistics what how we actually run
containers and production those are VMs
right we're treating containers like VMs
there's no need to put a full operating
system inside of a container anymore you
all you need to do is package up your
application but the problem is is that
it's very easy to do the wrong thing
from how the patterns that are out there
especially the patterns and docker files
lets you easily go and do things like
this so what have you just done you've
just pulled in practically a full
operating system right now it's not a
full operating system over the years the
vendors have gotten better about
minimizing as much as possible what's
inside of these container images but
there's still a lot of stuff in there
that you don't need and then there's
also still a lot of things in there that
you do need that you're going to have to
go and build and put in there yourself
and if you think of it there's now this
movement called modernized traditional
applications that a vendor has that's
very heavy in the container world and
when you just take a can be a manned
convert it into a container all you're
doing is lifting and shifting your
technical debt right you've taken all
this old code and configuration and
other things like that and if you just
migrated over and we saw this in the
cloud environment when we were doing
virtual - cloud migrations we also saw
when you were doing physical to virtual
migrations six to eight years ago right
and you're taking with you all of those
problems that you had inside of that VM
and you're just turning into a
containerized format so that you can
move faster right and you're actually
not solving your problems so let's talk
about what modern applications mean
right in this concept of modern
applications and cloud native and the
cloud native tract of course is all
about how do we run modern applications
so this is going to be more operation
focus cuz I'm a by background I'm an
Operations an infrastructure person so
when I talk about things and think about
things I'm talking about it more from
the perspective of how do you actually
run it at scale in production whereas
for a developer centric crowd you might
all be thinking about well I just want
to get my code and throw it over the
wall to ops right as quickly as I can
so let's talk about modern applications
and what you need to run modern
applications effectively so modern
applications need to start with this
idea of API first and you start with API
first from a couple of different
perspectives from the application itself
the first thing that you should design
is having an API which people can
communicate with your application and
then if you have a user interface then
the next thing you put on is that user
interface on top of it right same thing
from an Operations perspective as well
you want to start with having an API to
go and query that application for things
like health reconfigure that application
and also standing up the services that
that application need you want to take
an API first approach and this is what
cloud is all about right cloud might
seem complicated there's lots of
different definitions about it but the
main thing about cloud is being able to
request compute resources over an API
and that's kind of the main common
defining thing that you see over and
over again in the cloud world no matter
if you're using infrastructure or
service or platform as a service or
service you need to minimize the area of
concern and we heard couple talks about
that today and this idea of breaking
things breaking the monoliths up into
micro services and having the smallest
area of concern possible for your
application you want your application
instances to be ephemeral as much as
possible so you should be able to go in
and kill one of those instances and
automation will bring it back up and it
will be able to pick itself back up and
join its peers and figure out what the
live running configuration is and then
bring the application up just like you
would expect right and also you should
be able to bring up new instances for
load and once the load goes back down
you can kill off those extra instances
because you don't need them anymore and
this should work for stateful
application
where you're actually storing state in a
database or something like that or
stateless applications as well and then
you should focus on artifacts so one
realization that I had a few years ago I
was actually in Amsterdam studying on a
day much like today outside on a terrace
somewhere having a drink with a friend
and it talked about this idea that
everything is moving everything in the
technology world all of our processes
are moving towards this idea that
everything is an artifact and it's all
about how you do artifact management and
so if you think of a container it's just
an artifact right and the thing if you
think of a VM it's just an artifact a VM
image it's just an artifact your
application code it's just an artifact
it's all gonna be dependent upon the
size of that artifact and what you're
including inside of that artifact but
you can use the same CI and CD type
processes to push that artifact out into
a production environment so habitat is
built upon this idea so kind of setting
the stage for you in the container world
let's talk about habitat itself so
habitat is built upon this idea of how
do you run modern applications and how
do you make it as easy as possible to
build package and then deploy and run
that modern application
no matter the environment so habitat has
this idea of API first so it has
technology in it when you package up the
application that package has an API to
it where you can query the configuration
of that package so if there's things
that you can change and get that
information you can also query the
package itself to find out your
dependencies and your transient
dependencies and then when you actually
take that package to go and run it in a
production environment there's what's
called the habitat supervisor and the
habitat supervisor allows you to do
things which I'll talk about more to
query the health of the running
application to find out the running
configuration to find out about peers
and other things like that as well and
I'll cover that here in a second it
focuses on artifacts so the main thing
about habitat is that everything's
treated as what's called a habitat
a fact or a heart file and when you
package up any of your pieces of
software it's all about getting the
right pieces together to actually build
the running application so when you
build your application artifact you're
going to declare what your build time
dependencies are and what your runtime
dependencies are and inside of that then
habitat will figure out what everything
it needs to pull in not only from your
dependencies but also transient
dependencies as well and then package
them all up into one package that you
can then ship and that could be in the
form of a container or another piece of
another artifact if you want to it
eliminates the operating system so you
might be thinking well you went off your
list wrong but this is actually reducing
your area of concern and having the
smallest area of concern as possible so
the main thing about habitat is that
you're no longer dependent upon
operating system components and
operating system libraries and other
pieces like that and that's often why
you have that line that says from Ubuntu
1204 because you need some version of
julep C or some version of software that
who bunt to is shipping in 1204 right
and you have to pull that library and
because you're dependent upon that
library habitat eliminates that for you
in that we essentially recompile the
world and have that artifact available
for you in an artifact artifact
repository and I'll talk more about this
here in a second so we have this idea
what's called an operable application or
an operable application container so it
kind of boils down to these seven
principles or seven ideas so they should
be isolated so you should be able to
make changes to it or redeploy it
without necessarily impacting others and
if you are impacting others you can at
least have a mechanism to notify them
that you're making this change the
application itself so the application
code yourself that you're shipping
should be treated as immutable right and
that's one of the principles of
containers is that containers should be
treated as immutable artifacts the thing
is is there's always going to be
last-mile configurations that need to
get changed somehow right so if you look
at the cons
of 12 factor applications and 12 factor
applications if you don't know what 12
active factor applications are good a
twelve factor dotnet it'll give you the
12 principles of 12 factor applications
and it really overlaps very nicely with
cloud native some people actually use
the terms interchangeably well one piece
of the 12 factor idea is that you have
to store environment configuration in
the environment itself because the
application when it comes up it'll need
to be able to reconfigure itself there
should be a common interface for
monitoring health you should rebuild all
of the artifacts that you need from
source and there should be a common
packaging technology that you can use
for those artifacts that that you have
rebuilt and then there should be what's
called run time independence so you
should be able to take this package you
should be able to take the package and
the supervisor or our component in this
idea of operable application containers
and you should be able to deploy it to
any underlying server technology and
habitats principle is that you can take
a habitat package that you create and
deploy it onto any x86 Linux based
operating system it doesn't matter if
it's running on a VM bare metal inside
of a container or so forth it'll run and
function the same so let's get into more
about the problems that habitat solves
so the easiest way to think of habitat
is that it solves to build lifecycle of
an application and it solves the run
lifecycle of the application so it's
almost the Devon Ops tool don't say that
I said it's a DevOps tool it's a dev and
ops tool so how many people have ever
done this how many people have built
software right so this is your standard
we just downloaded an open source
library off the internet or open source
something off of the Internet it's most
likely written in C or C++ if it's a
low-level library and I do this right
and it's going to fail and why is it
going to fail because I didn't CD into
the directory right there should be a CD
there no it's gonna fail because you
probably don't have a dependency
installed right you don't have some sort
of headers that this package and needs
to actually go and compile itself right
and then you go into this whole cycle of
downloading yet another tar ball running
through the same thing discovering
you're missing something else and you're
basically you're walking your dependency
tree right
and so what habitat does is actually
hides all of this for you so by default
when you start writing a habitat package
the default implementation is
essentially the build cycle for this
right now you can also do other build
cycles if you want as well so this is
really might be a little hard to see if
you've ever worked with Java then this
might look familiar to you so this is
the build cycle for a maven based
application right so you can see a lot
of the same things clean
you have tasks you have package you have
compiled right and this is a build
lifecycle of an application you have
similar things for NPM as well right so
NPM install which lets you vendor all of
the modules that you need to actually go
and run your application package as well
or publish and so forth right so what
habitat does is it defines the build
lifecycle and I'll show this in the demo
so the default implementation is C or
C++ you can provide other
implementations by providing what we
call a scaffolding and so we have two
scaffoldings right now we're in the
process of writing one for go in the
process of writing one for Java as well
and I want to say there's at least
there's a Python one that we're actively
developing as well and so if you use the
core scaffolding Ruby then basically all
you need to do is define one line in
what's called your plan dot SH file and
your it will override basically that
default implementation and it will
provide to you a standard Ruby
implementation of a build my cycle right
same thing with the node right you can
explicitly
clear your build time dependencies and
this is this is nice because before
there was multistage docker files you
had to make sure that you if you did an
apt get update and apt-get install and
and put stuff into that container
especially if it was like GCC or make or
other things like that then in the same
line the last thing you want to do is
remove all those build tools that you
need it or actually and a layer down you
might want to remove all of those build
tools habitat by default will not pull
in build time dependencies because it
gives you the ability to declare build
time dependencies and then runtime
dependencies separately from one another
inside of this package this will all
become much more clearer when I can show
you a demo so basically what habitat is
doing is it's kind of changing this
triangle and turning this triangle
upside down so how many people still run
Red Hat 5 in production for 6 right you
don't need to raise your hand but a
really old version of an operating
system and why do you run a really old
version of an operating system well
because the IT group is like this is
stable its secure we know what it is we
still get support for Red Hat but here's
the problem so there's a whole bunch of
stuff that the operating system ships
and the problem is is they have a
certain release cadence and a certain
velocity that how quickly they can
release things right and there are some
applications in some people's
environments that they made the decision
when they deployed the application that
they were going to use is the operating
system vendor version of a library and
then from there on out there basically
pinned hard to that operating system
version and they can't go and update
their operating system because they have
all of these libraries that they need or
for example Red Hat 6 ships with Ruby
187 right and if you need a newer
version of Ruby
then you have to go and get it from
Apple which is extra packages for
Enterprise Linux or some other
repository or you have to go and build
it yourself right
so what the operating system provides
and especially in the container world
there's a lot of things that we don't
need in here anymore and it's just
becoming a lot of waste you don't need
the kernel for instance most of the user
land that an operating system provides
you don't need either right and you see
this when you look at technologies such
as Google's
distro list or Basel where it's really
trying to get rid of the operating
system as much as possible from your
containers
well habitat does the same thing for you
so what habitat does is that it starts
with the applications so when you go
into that plan dot sh and you've
declared the dependencies what will
happen is is when you say I'm gonna
package this up in a container format
what it'll do is it'll start with the
application and then calculate its
dependency tree and then it'll take that
and I'll put it into the container it'll
put the habitat supervisor into the
container and then it puts a small
lightweight OS and it's not really a
lightweight of us it's busy box it gives
you the looser user land tools
I almost said looser the user land tools
that you need if you needed to get into
the container and just do basic
troubleshooting and other things like
that right and the interesting thing is
is that because we're doing dependency
resolution top to bottom versus this
method from bottom to top and you're
layering on over and over and over again
in this method you don't necessarily
know what was put into all of the
additional layers unless there was a
explicit manifest that's kept track from
layer to layer to layer right and there
are two lanes where you can tools out
there where you can actually go and see
exactly what's inside of a container
image but when you start from the
application you can automatically know
that information because all you have to
do is essentially calculate the
dependency tree of the application right
so the goal is is that when you're
building containers you want to try and
build in a container for your
application which you want to try and do
is you want to try and minimize the
percent of the operating system or
what's traditionally seen as the realm
of the operating system inside of your
container and have more of the
applications so if you
think of if your containers 100
megabytes then you want to try and have
most of that hundred megabytes be your
actual application code that you need to
actually run your application and your
language runtimes
right and if you look at that you know
the easiest way to do that is to have a
statically linked binary with virtually
no operating system right so if you're
using a language like go or something
like that that allows you to do that
so what habitat allows you to do is
close process packages so once i've
packaged up my application i can export
it in a few different format and it'll
do that dependency resolution the way
that I showed it'll put all your your
application your dependencies so it
would be your language runtime and
whatever other things you might be
dependent upon the habitat supervisor
which I'll talk about here in a second
and then also the little small
lightweight user layout for you as well
so let's talk about what applications
need to run so let's talk about the run
lifecycle of the application and what
habits app provides there in a container
world so you need things like the
lifecycle events right so every
application has a lifecycle on the run
side as well and those run those are
things like starting the applications
stopping the application
doing health checks reconfiguring the
application so forth you need
environment specific configuration as
well so you know you move from stage or
for development into staging into QA
into UAT into production
what's one thing that's probably going
to be 12 I hope it's different for each
one of those environments you hear this
story recently where the new person
started and he was going to set up his
local dev environment and in the
instructions it said to use the
production database string right so
that's one thing that's gonna be
different between every single
environment or at least it should unless
you work at that company so that you
know a JD JDBC connection string or a
database connection stream in string is
going to be the one thing that should be
different between every single
environment well how do you get that
configuration information in
password should be different between all
of those environments as well the
usernames and so forth so that
environment level specific configuration
information needs to somehow get
injected into the application so that it
can start correctly it also needs
knowledge of peers from time to time so
some applications need to know that I
have three other members that are
running that same application right
they're passing information between them
and so forth and then the other thing
that you need to know is knowledge of
dependent services so if there's a
service that you rely on you have to
know how you can go and get that
information about where that service
lives and then also basic information
about that service like maybe what IP
address it has what port it's listening
on maybe kin connection information or
anything like that as well so what
habitat provides is it allows you so you
create you the first thing you do when
you get started with habitat as you do
have plan on it and it's going to create
a bunch of scaffold or not scaffolding
it's gonna create a bunch of templates
for you I guess you could say I wanted
to say scaffolding but into and want to
confuse the terms it'll generate a lot
of stuff for you it's much like in Rails
when you when you do the generate in
rails and it gives you all of the
scaffolding that you need to start
writing a rails application except with
habitat you don't go and delete half of
it after you've run the command you
actually keep most of it around and one
of the things that it creates is the
hooks directory so inside of the hooks
directory all you have to do is write a
shell script of how you start the
application a shell script of how you do
health checks and all these other steps
that you can do as well in the lifecycle
of an application now you don't have to
do all of them if you don't have that
file there then habitat won't care but
then what will happen is is when the
habitat supervisor starts the
application it'll run the appropriate
things to start it and then if a file
changes if a configuration gets changed
then it can run the reload or
reconfigure and so forth so it'll take
care of all those lifecycle steps for
you automatically
it can also manage the configuration of
your applica
as well so by default you store config
files in the config directory which will
also get created for you and then you
can provide default values so you just
put any file that you need a
configuration generated for inside of
that dot or inside of the config
directory you use a typically 10 to the
template team language called handlebars
and basically what will happen is is
when the application starts up that
template will get parsed and any of
those values will get replaced with
either the default values or values that
you've overridden so you can get default
values from your scaffolding or from a
default optimal file that you create and
then you can override values by either
using environment variables you can
create what's called a user dot Tamil
and place it into a certain directory
and that will override it or you can
also connect remotely to the supervisor
and inject a new configuration into what
we call the ring so that last one is
actually kind of interesting because you
can also get defaults when you bring up
a new application instance and you can
point that application instance at its
peers and then it can get configuration
information from the peers and configure
itself correctly based upon the live
running configuration that's happening
in your environment right now and that's
what we call a ring so the supervisor
basically every single application
instance that you would be running is
running inside of a supervisor so in the
case of containers when the container
comes up what's actually launched as pit
one is the habitat supervisor service
and then the habitat supervisor service
starts any application processes that
you need right and then what will happen
is is you can bring up a second instance
and you say my peer is this particular
IP address and then you bring up a third
and the fourth and they all come
together to form what's called a ring
what we call we also call these our
service groups and so with this service
group you can do things like pass
configuration information like I already
said you can also encrypt secrets and
put it
to the ring and then the ring is the
only one that can decrypt it because
it's using asymmetric encryption I you
can also do things like leader follower
election which I'll talk about here in a
second so that's how you can pass
information and basically begin to do
service discovery you can also have
rings talk to one another so when you
start the application there's the option
to do a - - bind and this - - bind you
basically say if you have a database you
would say database : the name of the
Ring where it can get database
configuration from and then inside of
your configuration files you would just
simply reference database dot and then
the parameter that you need and then
what will happen is is that
configuration information will
automatically come from that other ring
go into your configuration file and set
up your database connection correctly so
the other thing that you need is you
need some knowledge if you have peers of
an application or an application service
you might need to have a certain
topology that you'd launch and write so
the one initializer actually we took
that out I need to update this slide but
leader and standalone or what you can do
right now and what will happen is in
leader is that the application instances
will come up if they don't have three
application instances up they'll sit
there and wait until three they've seen
three come up on the ring and then what
happens is an election takes place now
if you're curious about the technology
that we use with the algorithm that we
use it's all on the habitat dot Sh
website if you go to the docs and talk
about internals or look at it the
internals page you'll see all of that
information if you want to get into kind
of the distributed system theory that we
use here what will happen is is in the
configuration file all you need to
simply do is say if I'm a leader then do
this or configure myself this way if I'm
a follower do this or configure myself
this way and then based upon the results
of the election the configuration files
will get generated correctly so if
you're running something like Redis or
MongoDB then you can just have the
great configuration lines written into
those config files the application will
start up in that write topology for you
automatically if the leader dies what
will happen is is the ring will see that
the leader died and has went away if
there's enough members on the ring to
have quorum then it'll go and do an
election again and then bring the
application back up and that's why we
have that suitability hook that you saw
before because in some cases when you're
working and storing data you need to
know who is the one that who's the most
current and that person should become or
that instance should then become the
leader and that's what the suitability
hook is used for it influences the
elections so so we kind of call this
idea of self-organizing applications and
so the typical pattern that you see like
a good example is if you've ever looked
at kubernetes and if you ever looked at
the kubernetes guestbook application
which is kind of their demo application
well the way they solve this leader
follower problem is that they create you
create one container called Redis master
and it's hard-coded configuration to
always be the master or the leader and
then it also has one called the Redis
follower and that's hard-coded inside of
there to actually always be the follower
and then you just bring up the instances
or the containers right and everything
works fine the problem is is you're now
managing two different configuration
files for those two different containers
and while you know two isn't a hard
number to manage when you start thinking
about managing systems that's scale and
if you're going to have a hundred of
these different types of applications
that you have to manage in this way now
you're managing a 200 docker files
instead of a hundred docker files and
that starts to become when you think
about optimizing processes this is an
area that you might want to optimize the
process so in our pattern is you create
one container image you launch those
images with knowledge appears and the
application will automatically self
organize and I'll show you this here in
a second
and then what you can do is that when
that self-organizing organization
happens you can notify other systems so
in the case of maybe kubernetes what you
can do is you can then go and apply
appropriate labels based upon the
results of the election and then
kubernetes can route traffic based upon
labels that way as a selector so the
other thing that the supervisors provide
is a rest-based API to do things like
query health and status you can also do
bug the supervisor this way so you can
see the results of an election that
takes place and then it's also useful
for useful for external actors as well
so if you have a load balancer service
then that load balancer service can be
creating that endpoint to get the health
check back from the application and if
the applications failed then it can
remove that particular instance out of
the load balancer pool and then go on
its day so to summarise before I jump
into the demo so have a chat approaches
containers differently because we're
looking at building it from building a
container from the applications
perspective not from the operating
system perspective which is kind of the
current methodology that's prevalent
when you use a docker file you can
export containers in a variety of
formats so docker a CI a mezzos package
or just an ordinary tarball if you want
and then when you export that container
you automatically get built into it
things like service discovery
configuration management this health
check API and the support for doing
different clustering topologies as well
so you get a lot of benefits by building
that container with habitat than the
traditional method of using docker
docker files or JSON that a CI uses and
it's all open source so if you're
looking for a new open source project to
contribute we'd love to have you it's
written in rust the main components are
written in rust but all of the plans are
written in shell scripts so we chose
shell because it's a
approachable language and most people no
shell to some extent so if you're
getting started with a plan which I'll
show you here in a second it's all going
to be shell you're going to use other
languages as well so if there's a
certain interpreter that you want to use
for the hooks then you could use Python
you could use Ruby or any other
interpreted language if you want to as
well so here are links and then I will
run to the back and I'll give you a
really quick demo okay so I actually
have something I created earlier but
what I'll do is just go up a level and
let's just remove this application
altogether and start from scratch so I'm
going to use Express I'm just going to
create a sample site so if I go into the
expresso directory that I just created
you can see that I've got all the basics
for an application right on ojs
application so all I need to do now is
you have plan an it I'm going to pass it
a few flags and it's created the habitat
directory and you can see that it's fake
created the basics that I need to get
started with habitat so you can see
there's a plan dot SH the default amo
configuration and so forth so I can open
that plan dot Sh
and you can see that it fills out a lot
of stuff for you so if you were pulling
down from source code you would put code
where your source code is ash awesome as
well and then in the build life cycle
will automatically go and pull down that
package for you
check the checksum extract it and then
go about building the application so in
this case we don't need any of this
because we're doing a pattern where
basically the habitat plan is going to
live with my source code directly right
so I'm going to delete everything we
don't need here which is a lot and then
I'm just going to put one line
I wish we chose a shorter name okay and
they'll save this now when you're
building things with habitat you have
what's called a habitat studio and so
how many people well you know look I can
see your hands but I won't take a poll
but have you ever had the situation
where you do some development and then
you send it over to somebody else and
you're like okay let's deploy this
application and then there's something
that you installed and your development
cycle a library or something like that
that when you ship that application it's
not on the staging machine or the other
machines that you're trying to deploy to
right the whole works on my machine
ops problem now right so when you build
things with habitat what you do is you
build it inside of a studio and it's
really just a very basic environment
that pretty much has nothing installed
it has the very basic user land that you
need to get started and then if you need
to install anything you install stuff
via habitat packages so I can do have
package install core JQ static because
I'm going to need this here in a second
and what it did is it goes and it pulls
it down from the habitat Depot and
installs it for me and then now that
package is inside hab package core and
you can see the JQ static right there
that I just downloaded but what I want
to do is I'm going to build that
application so why was in my application
source code directory and when I entered
the studio so that's going to be mounted
up to slash source for me so all I need
to do is run build and so you can see
here what's happened is is that it's
validating my plan and then it's also
realized that I'm using a scaffolding so
it starts to download all of the
dependencies
for my scaffolding and you notice that I
didn't explicitly call out a certain
version or anything like that so it's
gonna default to the latest version now
what I could do is I could actually be
very specific and I could put a version
number on there if I wanted to put on
that
if I needed a very specific version of
the scaffolding or if I needed a very
specific version of my language runtime
or of node I could also call that out as
well and then you notice that it's going
and installing more things and we'll
also see at one point where it's
actually going to go and run the npm
install and it's downloaded all of the
dependencies that I have vendored them
for me and then in the end it goes and
creates this Hart file so if I look in
results you can see that it just went
and created that now what I could do is
actually start the applications so I
don't have to export this as a container
first before I actually go and run the
application now I could if I wanted to
but for time I'm not going to and now if
I run slog for supervisor log you can
see that it's actually went and it
started up the application so the
application is running so by default
what happens is is the supervisor runs
in the background inside of this studio
and then that way you can get a very
tight dev loop so you can bring up your
application inside of this studio get
feedback whether if it's going to work
correctly or the works the way you
expect and then you can just tear it
down later and export it in the format
that you want exported and whether it be
a container or ship it to a VM or
whatever so I should actually be able to
do a W get
and bite a foul is running on 8,000 and
sure enough so the applications up and
running and working the way I expect so
let's do this
so let's actually change the
configuration let's see if I can
remember
okay so it looks like it worked so let
me run slog again
and you can see sure enough you saw that
get requests that I made and then you
can see that the configuration
recompiled right so what happened there
is that I connected to the supervisor
using that HAP config apply command and
I injected a new configuration and then
the application or the supervisor
detected it it restarted the application
and now if I go and look on port 8000
what should I get nothing right so if I
go to port 3000 you can see now the
dynamic configuration happened so if you
can think of this in terms of if you're
running containers if you're running a
whole bunch of different application
instances and you need to very quickly
go and change a setting like that you
can do it very easily by injecting it
through the supervisor so one last thing
that I'll show you before we stop were
bumping up against time here so I need
to do one thing
okay so the other part that I want to
show you is the actual supervisor itself
and just kind of show you some of the
information you can go so I can hit this
and you can see it's a bunch of JSON so
96 31 is the API endpoint for Korean it
and getting information out 96 38 is
what you would interact with if you're
going to be working with the gossip ring
so if I just typed this through JQ I'll
get pretty printed format and so I can
see information about where the
applications running you can see what
version of the expresso application and
also the build time I can also see what
version of habitat I'm running in this
case the IP address the other thing that
you can see is the configuration as well
so there's that configuration if I would
have looked at this before I injected
that new configuration this would have
been 8,000 you can also see the topology
that you're running in and so forth you
can hit other endpoints as well so if I
do services expresso / default / config
I get the actual just the configuration
itself so this is a very easy way for
you to go and get information about the
application and how the application runs
and then lastly if I wanted to now take
this application and export it as a
docker container all I need to do is
export it like this
and then it will go and install
everything that I need dependency wise
it'll calculate that dependency tree as
I talked about and then I can do a
docker run on that resulting container
image that it's going to generate for me
so with that what questions can I answer
for you in the about five minutes we
have left
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>