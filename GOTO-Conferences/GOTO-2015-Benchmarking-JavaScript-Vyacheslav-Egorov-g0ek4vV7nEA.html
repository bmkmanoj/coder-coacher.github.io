<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Benchmarking JavaScript • Vyacheslav Egorov | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Benchmarking JavaScript • Vyacheslav Egorov - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Benchmarking JavaScript • Vyacheslav Egorov</b></h2><h5 class="post__date">2015-07-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/g0ek4vV7nEA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I worked on there
VMs in my life and as all people do in
VMs I started with a Java VM and then I
went and participated in the v8
development and I will be mostly talking
about v8 related stuff here and for the
last three years I have been working on
an optimizing compiler for the dart VM
and all of these VMs I worked on they
have one thing in common and its
complexity some people tend to think
that complexity comes from us VM people
trying to ensure a certain level of job
security for ourselves but that's not
the case the complexity comes in because
we have the VMS have to run all kinds of
weird code fast unfortunately there is a
side-effects to complexity and while the
MS run all kinds of weird code fast
sometimes they suddenly run simple code
slow and because VMs complex developers
usually have no insight on why that
happens and what can they do to fix it
and what I'm trying to do here is to
alleviate this problem for you provide
you with some methodology or some way of
thinking about performance that would
allow you to solve your problems just
recently I saw this question so this
question on Stack Overflow and I monitor
all kinds of social media closely
searching for people having performance
problems and somebody wrote chart one
implementation in JavaScript if you
don't know what church are Tony is
that's okay I did not know either so
it's a cypher like all ciphers it takes
some bytes and it spits some bytes out
and it does a lot of integer operations
and it looks all reasonable and then
performs reasonably fast for this
developer like we did 20 megabytes a
second and I don't know whether it's
fast or slow because I do know
cryptography so
probably it is slow but it looks fast
enough for me
but they did not look fast enough for
the developer who wrote it so he looked
at that computational kernel of his
cipher and he said Oh what if I try to
eliminate the overhead of the calls
inside the loop there so he took this
the function that was there and just
textually inlined it multiple times like
completely and you can see it's a lot of
codes I'm not even showing the complete
loop body anymore and what would you
expect you would expect either speed up
or a neutral performance change right
nothing should have changed but on
Chrome suddenly the performance dropped
by a factor of 10 after doing this and
of course nobody is very happy I was not
happy when I saw this question I said
something fishy is going on here for the
rescue and I looked at the benchmark and
I looked and I looked and I found this
function and then they put this comment
with a nice user awesome ASCII art
inside and lo and behold the performance
was restored so basically you take this
and you commit it to your repo and the
problem is solved to the next problem so
how did I know where to put this comment
and what to look for well that's because
I worked on the v8 team and I will keep
the secret to ensure my successful
consultancy career in the future
well let's backtrack a little bit and
talk about benchmarks in general most
people talking about JavaScript
performance or talking about
benchmarking something in JavaScript
world they think about GS / com if you
never saw this site well it's the best
for you but that's the place where
people write benchmarks for JavaScript
so they can write some code snippets and
then the the harness of Jesus birth runs
them and plots the nice graphs like for
example here you can see that on Firefox
there is a way so some in this
particular example somebody tried to
find the best two
to count the occurrences of the
character in the string so suddenly
there is a way on Firefox that to count
these occurrences that beats all other
browsers and all other ways to do the
same thing on Firefox and this way is to
split the string by this character and
then count the lengths of the array that
is returned by the split and then
subtract one and this provides like nine
and then eight zeros after nine so it's
very fast which is really
counterintuitive and another way to do
it which is relatively fast on all the
browser's according to this chess perf
is to take the string and then walk it
character by character but instead of
actually using the iteration variable
you slice it again and again producing a
new string until the string is empty
like how unless you come up with this
way of iterating the string I don't know
this is not taught in any university in
the world so if we were to approach this
stuff namely we would just go and switch
all our loops over strings to this nice
new way but I'm saying this is not good
and not good is a politically correct
way for saying so we should
doubt everything that we see on GS / F
or in any benchmark you write the
benchmark you get results first thing
you do you doubt it and you don't apply
it directly before you understand what
actually is happening there so let's
backtrack even more so this talk is back
to actually go in backwards from
applications to the foundations instead
of going from foundations to the
applications so we're trying here to
measure the performance of a single
operation
well how you do it well you do it with
this state of our benchmark driver here
you take the beginning of the benchmark
and then you subdue the operation and
then you subtract from the current time
the beginning of the benchmark right
what if the operation you try to
benchmark is actually faster than the
clock
you have access to like for example I
doubt that addition takes milliseconds
on the current hardware unless you are
running on a very very very very old
computer very old computer so this state
of art bitch bug driver is an upgrade
you try to perform the same operation
multiple times and then you just divide
the time spent on performing n
operations to get the cost of a single
operation this is basically mathematics
from the first grade like you do
operation n times then you divide by n
all magic happens and you get the cost
of a single operations okay it's similar
to the keynote where there was a lot of
mass right there is a lot of mass here
so let's take a look at what Jesus perv
does to this nice string case here that
we try to benchmark with a slice and
stuff like that
well in fact it wraps it in the outer
generated function like this so it
jesper generates the code around to
their snippets you provide and compiles
it dynamically using the function
constructor and if you read at all
several times so maybe one time
depending on how good you are or maybe
zero times if you're super good you will
notice that there is a loop here that is
performed multiple times repeating our
operation here and basically we never
initialize the string which are slices
slices slice it until it becomes empty
and then when I equals one we start the
loop with the empty string so all the
operations after the first measurement
of the first operation I actually
costing nothing because the string is
empty already so let me repeat the
mathematics we expect it to repeat the
same operation n times but what we
actually did we repeat it at once and
the rest is costing as zero if you
divide it by n well you get C divided by
N and C is very small and n is very
large because J's perf repeats at
thousands of thousands of times and you
get approximately zero that's why it
looks so fast because we
misusing GS perv and the measurement is
basically we're measuring empty loop and
the key lesson here to take away is that
you need to ensure that operation when
you repeat it is doing the same amount
of work every time okay so but let's dig
deeper so the problem is you are not
alone when you are running your
benchmarks there is somebody standing
behind your back and looking at this and
this somebody is your browser
essentially because the browser's are
very smart let's take a look at this
example so here somebody tries to
measure what's the fastest way to
convert an integer hidden inside the
string so a string representation of an
integer into an actual integer and it
turns out that on Firefox the fastest
way to do that is double till the
operator so you apply a tilde twice
tilde is a bitwise negation and then you
get integer out and this is very fast
like blazingly fast time to use double
tilde everywhere instead of parse int
well you probably already realize how
this talk is going to go I will say
something something something they say
no and that would be it
our browsers and the machinery inside
them is very clever though are very
clever because we have multiple browsers
and they optimize the code as it
executes and that means our simple first
grade model does not work we need to go
to the second grade of school and
realize that there are multiple costs
involved so first your application
starts the operation starts costing
something and then as the program runs
the cost changes it actually can be more
complicated that cost changes multiple
times as some browsers have multi-tiered
cheats like Safari has interpreted that
in a compiler than another compiler and
then another compiler for compilers in
total well Counting the interpreter so
and they can switch back and forth
multiple times so it's very complicated
and when you can
factor in all of this out the
mathematics really gets out of hand
and you can no longer approach it with
this first-rate mathematics at all and
you have to start thinking so you need
to start thinking and try to be smarter
than JIT compiler now I will show you
how to be smarter than sheet compiler
and to show you how to be smarter than
JIT compiler I have to show you what
should compiler actually does inside and
I will show it on this based on the
source representation of the program
compilers do not operate on the source
representation but showing you non
source representation of the same
examples would take me more time it's
basically would would require me
teaching you a compiler course or at
least parts of it so let's just use the
source so we tried to measure this
double till the thing and we wrote the
benchmark so this is a kind of the gist
or driver here and then there is
insulation here and compilers they are
trying to do the same as you would do to
your program so just think about
yourself as you were in the second or
third grade when you were not that
established JavaScript programmer but
you had already some basic reasoning and
you know that if you have a constant
here and you use it only once here well
you just put it there right it makes
total sense and then you can just
evaluate this expression step by step
and that's what the compiler does at
compile a time at compile time basically
that's what compiler arrives to it just
has the assignment of a constant to a
variable and that's it there is no
actual tilde operator left anymore to
execute
there is no parsing happening so you're
not measuring doing anything this
optimization is called constant
propagation and most or all now all
cheats even Internet Explorer because
Internet Explorer JIT is pretty good
these days or it's called edge in it now
I'm outdated so everybody does this here
people can become very optimistic and
say mmm I can trick the compiler because
I am smarter and I will make it known
constant there and it will not be able
to do the constant propagation anymore
well yeah it wouldn't be able to do the
constant propagation anymore but it has
more tricks in its sleeve it will just
look I is initialized one since outside
the loop and it never changes inside the
loop that means there is out of apply
until the operator does not change
either and that means it will screw you
up it will go there and say this is loop
invariant so this whole expression is
loop invariant and the loop invariants
can be moved out of the loop and placed
before the loop just like you would do
to your code manually and again you end
up with just assignment of some variable
to a variable essentially and you are
not measuring parsing time because it
will happen only once outside of the
loop this is called loop invariant code
motion again everybody does this without
this you cannot really reach any good
performance in JavaScript compilers can
go further they can look at this code
and say well it doesn't look like
anybody is using this variable and if
nobody uses this variable nobody needs
this computation and nobody needs this
computation that means nobody means I
well hasta la vista baby and some
compilers would go as far as just saying
well there is a loop that that's nothing
but looping well also see you so this
code this is called dead code
elimination
not every compiler will go as far as
eliminating the loops or example v8
right now cannot do it but there are
some new compiler infrastructure being
built in v8 as we speak or rather a
sleep now because they in Europe but
they will start building it when we
sleep so which will be able to eliminate
the loops as well
remember this example with the super
fast string splitting stuff for on
Firefox well it turns out that Firefox
is able to understand that splitting a
string by a string and taking the
lengths of that and doing some math on
that is at that code because the result
is never used and nothing has a side
effect here so it just disappears and
that's why it's so fast and is it runs
with such incredible speed basically if
you see anything on GSP running with an
speed like six and then eight zeros that
means nothing is happening it's an empty
loop and you have to reevaluate the way
you write the benchmark so what we
established here is that optimizer it's
all the benchmarks for breakfast
align your dinner basically all the day
long and then in the night as well you
can try to develop benchmarks that are
impossible for the optimizer to eat
because you are still smarter than
machine right machines dumber than
humans were at least for now until
Skynet comes and optimizes everything
away so my biggest suggestion on my most
common suggestion to people who ask me
how to write benchmarks that are smarter
than compiler is not to try to write
them just use the real code and
benchmark your real applications in
production or something like that
use your users as the experimental
hamsters so yeah back to the topic here
is three suggestions what you can do
basically you have to avoid the most
common optimizations by avoiding
constants avoided loop invariants and
the voyage in the dead code but the most
important thing you should verify
results when you actually do
benchmarking because that already
usually helps to trick certain
optimizations like dead code elimination
because you're actually using values to
verify them so here's what we could do
to this benchmark to avoid the problems
we could say initialize two strings non
constants and then start just swapping
them in the loop to keep them non
invariant in the loop and then you do
some check-in at the end and you throw
an exception if it fails and this is not
bad but might not still be enough if
your compiler is smart
for example compilers have this suite
optimization where they
say I see the loop what if I repeat the
body tries but do twice less iterations
and then you do one additional depending
on whether it's even or what what
happens here is that if you swap twice
within the body that means you did not
swap anything right
swaps cancel each other and compiler
propagates some values and the loop body
turns into that so base if you have two
dead assignments to some variables which
nobody uses and then you have an
assignment of a loop invariant and you
are not measuring anything again this
optimization is called loop unrolling
and nobody does it yet in JavaScript VMs
as far as I know v8 for example does not
do it but I like inducing paranoia in
people so they will become afraid of
writing the benchmarks okay so here is
the clash between micro benchmarks and
VMs and now we are switching to the
second part of the talk where I am going
to show you so previously I showed how
VMs find bugs in your benchmarks and
turn them into nothing now I will show
you how benchmarks find bugs in the VMs
and if you don't realize that benchmarks
can cause bugs in the vmsu will get
completely flabbergasted by the results
here is somebody trying to measure a
strange thing I don't know how people
come up with this ideas for Jesperson
sleep it's hard to read but what's
happening there is somebody decided to
measure whether it's faster to
concatenate strings defined as literals
or concatenate strings saved in variable
captured by a function and then you
concatenate these two variables and it
turns out that on v8 so this g8 thing
don't be scared by it on this dollar is
not a dollar so it's not money but it's
a shell prompt so the DA thing has just
a standalone version of v8 which is
running outside of the browser it's kind
of like nodejs but without note just yes
so I wrote this standalone benchmark and
I ran it and it turned out that the
inside so
you defined the string literals outside
of the function then you concatenate
variables inside the function is quite a
bit faster outside and the insight when
you just compute a string literals is
slower which is completely
counterintuitive because you just
concatenate literals right it should be
faster should be constant folded so I
managed to fight my instinct to move all
my strings out of functions and kept
them down and I started looking what
happened with my patented blaze so I
expect that both variants should be
completely dead called eliminated or at
least constant folded so there is a tool
to look at the things that I wrote in
dart advertisement so it's very
paradoxical so and if you click on this
link and watch it right now only I can
click on this thing but if you just
google this you will find it so it's a
tool to see the intermediate
representation used by the optimizing
compiler inside v8 and all the things
that I'm showing to you here available
as links inside this tool so it just
clean called click on it and it
downloads the stuff and it shows you
it's completely browser-based it has no
server side component stuff like that ok
let's let's take a look why outside is
so much faster so this is the tool so
there is a URL there you can go on my
site and find it deploy it there and the
example is sitting here so I just dude
click and then you see this kind of nice
UI or well you can obviously see I do 0
web development but looks nice to me and
you see the stuff that is like that was
optimized when the benchmark was running
on the site and if you click on like
each of these entries they represent an
optimization that occurred during the
run you click on the thing and then you
see a lot of strange stuff going on here
like write all this Phi
that came from Asian grease and all
kinds of stuff going on here
it's a little bit hard to read so the
forest of the stuff that is actually
happening with the code is hidden behind
all these miniscule details of the
compiler implementation so there is a
Olfa since our on I there which you can
click and it activates something called
interesting mode this interesting mode
hides all the details which are
irrelevant and it splices the source of
your benchmark of the source of your
JavaScript function into the IR IR S
stands for intermediate representation
or internal representation depends who
you talk to and this source is right
next to the instructions produced from
the from this source so for example here
you can see there is a loop variable
decrement and this is an addition
operation there and then there is branch
which is not a lunch and breakfast
combined together but go to instruction
essentially so and what you can see here
is there is also this red line here
which signifies the loop nesting so it's
very easy to find where the action is
going on in this benchmark and if you
look and you remember that you try to
benchmark concatenation then you just
cover that where the action is going on
the concatenation is definitely not
going on like there is no concatenation
inside there is some double addition
going on here for a loop variable but no
string concatenation so outside is fast
because there is nothing in there there
is empty loop we are measuring them to
loop it is fast because it's doing
nothing so the true phase v8 failed the
constant fault the case when you had two
literals together which is
counterintuitive
it was a back which was fixed so all the
backs that I show you here they were
fixed maybe so
this one I for example fixed myself
before it even was fixed in the v8 it's
pretty simple fix after you spend a
couple of years and v8 but I'm not going
to go into details of what happening
here
basically it's you can see it's like 1 2
3 4 whatever 10 lines of code eight
lines of code even better and after
fixing it inside and outside they become
of the same speed but we should remember
everything is that is this fast is empty
empty both are now doing nothing so
scratch this benchmark move to the
better one what we should think well how
the way we should think about all of
this stuff is we should assume that the
reasonable code we write is reasonably
fast they call it the presumption of
performance like presumption of
innocence so VM is always innocent until
proven guilty and you prove it guilty by
writing reasonable benchmarks and trying
to understand what happens and happens
inside you don't prove it guilty by just
jumping to conclusions but people
actually jump to conclusions all the
time so people think prototype chains
are slow and they write benchmarks to
confirm it to confirm their own
assumptions about prototype chains so
for example here we create a very deeply
nested prototype chain with this awesome
object dot create thing and we leave
some list tribute at the end for the
people who like Lisp and then we write
this nice benchmark with for whatever
even three loops because we have a lot
of letters in the English alphabet and
then we hoist manually the property
access and then we feed these two
versions together using our state of our
benchmark driver here and we measure
first one which does look up on each
iteration and then we measure the second
one which caches it outside of the loop
and we see that doing many lookups is
eight times slower than cashing it seems
reasonable right
that means we confirmed what we thought
the prototype chains are slow okay if we
assume that this is the truth let's make
it harder what if I fetch the creation
of this prototype chain and I say
instead of creating the data property
use the getter
what do you think will happen will it
become even slower by how much because
people know that accessors even slower
than the normal properties well it turns
out it becomes 8 times faster like what
happened here
voodoo magic happened so if we look
using the IR hider we will discover that
the property access when it's defined as
a getter is inlined
because Gator is just ultimately a
function and we are using the constant
in the addition operation down there so
the actual access to the constant costs
nothing and in the case of the property
the data property defined on the
prototype we suddenly discover that
there is this load named generic
operation which is actually a call and
there is no constant 10 inside and it
was not hoisted out of the loop either
because you can see this red line going
on here well it turns out that we were
benchmarking on note a note is well
known for being very outdated with v8
version and the person who wrote this
benchmark he used the even older version
of note like from whatever four years
ago and that version of v8 did not
support properly the data properties
defined on prototypes it only supported
immediate data properties but it had
support for getters defined on
prototypes that's why the Gator was
faster so if you try a new v8 then you
see they're roughly the same speed even
without the Gator without the Gator
trick so and the prototype chain
traversal as we saw God completely
looked out of the loop there is no
checks left inside for the prototype
check for prototype so the stability of
the prototypes ok and now for something
completely different this light was
there even before I saw the keynote so
this is not plagiarizing of the keynote
it's a pleasure writing of the great
British humor so
what if we run the same benchmark twice
like do many lookups measure it twice
look up and cache measure it twice well
it turns out the second time even on the
new way we eat it suddenly slows down by
a factor of roughly three like Oh what
just happened here again some would've
happened if we look in the IR hide right
now I'm not going to go into details
because I still want to tell you some
stuff before we all out of here the like
I told you that there can be multiple
optimized versions of the same function
as it runs and that's precisely what
happened here so first v8 came and
optimized their function so if you
remember what we were doing there we
were doing summation here so we have a
counter and then we just add the
constant ten again and again to the
counter so we ate first optimize the
code assuming that the counter fits into
31 bit integer which is called a small
integer and we toss my for short
then this counter overflows and we D
optimizes the code and then re optimizes
it using the insert a two for the
counter that is still not enough because
we are doing enough iterations to
overflow 32 bit range as well and then
it D optimizes and produces the version
with a double code inside for this
counter this D optimizes again because
we reached the end of the loop and v8d
optimizes when it reaches the code path
that were never executed before this is
so this is different kinds of the
optimizations they do I use color coding
to signify like this is a so called
eager the optimization which happens
when some assumption is violated in the
code and this is so-called soft G
optimization which happens when you
reach the code path that was never
executed and then the version substa
boluses and never the optimizes again
you can see it has no special color it's
just black so
but unfortunately stabilized in a very
strange state so now the counter is
stored as a tagged variable so tact
is the v8 the JavaScript is a
dynamically typed language so it has to
store things it can store things boxed
like because you need that type assigned
to the value and this is called tagged
in in v8 due to the implementation
details which I'm not going to go into
here but to take the number you need to
allocate the box for it and that's
precisely what happens here so you first
untag the counter so you take the number
from inside the box converted to the
machine number and then you do a
different operation and then you Reeboks
it back into the box and each time you
Reeboks it you allocate a new box so
that obviously costs you that's why it
slowed down by this factor of three I
could explain you why this happens but I
don't want to go into details because
it's again the back and the like
explained in box is not fun it's much
fun it's much more fun to show you the
result of this box what they do to your
code basically this plus operation at
the end of the loop was confusing the
way we thought about the counter
variable and you could walk around it by
adding two string for example to the
counter it's a little bit of magic
happening here the bug should be fixed
now as well so you don't need to do that
to your additions but before it was
fixed you could have walk around by
doing this so after you do this all of
them perform nice and fast and the
second run is faster than the first one
as we would expect so now let's do the
desert or not desert I forgot one s so
methyl colon function called that is a
very popular topic of discussion in our
world so somebody wanted to benchmark
what is faster this is taken from just
perfect game function invocation so
there is this function that does some
crash computation on the string or the
method invocation so he took or she took
the same function
and applied it put it on the prototype
of some empty object like it's a factory
adapter trampoline known for to us from
Java patterns of design yeah and then
you just benchmark the function
invocation or the method invocation and
you would assume that they would perform
the same but it turns out that the
method was completely optimized the way
but the function is doing like very
sluggishly
so somebody is calling me from los
angeles they hang up okay so I'm
becoming very popular anyway so why
method call was faster so I'm going to
show you the workaround for this bag but
never show it to anybody else
so I just took the setup of the
benchmark and I added this magical
concatenations in front of it speed your
JavaScript with this one vir trick and
lo and behold it did indeed sped it up
so again my patented blaze well it turns
out that before I did that
there was no function benchmark
optimized at all for some reason we it
was not optimizing it at all and of
course if you don't optimize it it will
be slower than the completely optimized
methods benchmark there is an
explanation here but it all boils
doubles down together yeah that stuff
and I am NOT going to go into details
but let's look at the code once I put
this things in front of it and it was
optimized so there is this source pane
in IR hider which you can use to look at
the source line by line and for example
lines that produce no code they are
grayed out and there is some special
things marking that the function call
here was in line and so on so forth so
it turns out that after we forced it to
optimize this thing here is completely
in line now
and if you click on the inlining marker
you will go and see the source of the
inline function which can be quite
useful and there is this strange wavy
background which is quite psychedelic
but I couldn't come up with a better way
to show it
this basically means this line produced
the code but it was hoisted out of the
loop where it was originally that is an
easy way to find the lines of code that
were completely moved by the loop
invariant code motion so here the only
thing that state and the benchmarking
loop was this stupid comparison and
return undefined thing that's because
the way it has historical language which
prevents it from removing or moving
around branches so but everything else
that you try to benchmark went away and
that's why it's so fast again so this is
becoming really a repetitive thing to
say but we are not measuring anything
here
move on so can the function called be
faster than the method call well it
turns out it can be so I said I work on
the dart team and we have a compiler to
JavaScript and that's what the compiler
sometimes produces we have this
concurrent so this is a loop-the-loop
well this is wrong here there should be
no I but let's ignore this this is a
loop iterating over the list and we
produce almost the JavaScript's loop but
it has the concurrent modification check
there which checks that if you modify
the length of the distance side the loop
then it will throw an error inside and
they came to me and said can you make
this code as fast as this code with no
concurrent modification check on v8 and
I said is it slower and they said yes it
is slower by 18% we would like this 18%
back and then I looked at it and I said
well there is a solution you just need
to write it like that put zero comma and
then the name of your function and then
some stuff after it so and they like
looked at me and then called the
ambulance so well internets in fact it
turns out that it actually makes it
stur why this happens well let me repeat
what I did I just got 18% speed up by
replacing method call with a function
call in the code that never executes
because it does never throw there
because this particular benchmark
iterates the list without changing its
lengths I just got the speed up by
changing the code that never runs during
the benchmark Wow I'm good
well it turns out that if you write the
code like this this was never executed
during the benchmark run and we does not
know where it will go if it will be
executed because it does not know it has
to assume that it can have arbitrary
side effects and it has to keep
reloading the lengths here and reloading
the lengths here and stuff like that and
that's why it is slower than not doing
the check because the rest of this has
no side effects it's only this call that
goes to some unknown place can
potentially have side effects so this
code also was never executed but
property loads are treated specially in
v8 if the property load was never
executed v8 would say this pass can
never be taken this does not apply to
calls for some reasons which are quite
deep so deep that I never dived deep
enough not okay anyway so because we it
assumes that that pass can never be
taken there are no side effects left in
the loop and it can hoist all stuff away
and optimize things like it will hoist
this length slowed and falls away this
branch you can see it's now completely
grayed out so what I would actually
recommend to not benchmark things and if
you need to benchmark things talk to the
VM people so thank you very much
well not wait wait there was another
example in the very beginning of the
talk so remember this guy here which I
sped up by the comment well it turns out
that if you look at it in the IR hider
you have this repetitively the
optimizing gate lock function so this
function is called get block and
completely goes of the rails
and this is where the optimization
happens for Hydra shows you everything
and repetitive the optimization is the
case where you call me from Los Angeles
and ask to file a back in V
it so it always a back in v8 if we talk
to Mises in again and again and again
and never stabilizes so again yeah they
got the explanation of what happened
there there is a more sane walk around
than the comment I just wanted to make
it funny because I know how it works the
same workaround is just to truncate this
value load here from the UN 32 array
immediately to in 32
but this back was fixed I fixed it and
so you basically should never assume
that something is slow if it is slow and
stuff like that all the things and I
said talk to the M people like me if you
need my help and this is a real lens I
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>