<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • Transforming Legacy Apps in the Enterprise: Société Générale's Story • Lee &amp; Gilles | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • Transforming Legacy Apps in the Enterprise: Société Générale's Story • Lee &amp; Gilles - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • Transforming Legacy Apps in the Enterprise: Société Générale's Story • Lee &amp; Gilles</b></h2><h5 class="post__date">2018-01-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8rlrjMXAwtw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so hello everyone
emergency power and the software
developed all right so Gennaro
hi everyone and I'm Lea Namba I'm a
solution architect at docker and today
we're going to be talking about
configuration management how many people
here know about docker yeah all right
how many people use docker in their
day-to-day lives okay good well today
we're going to be talking about
configuration management you guys have
to deal with configuration management -
environment variables that kind of stuff
yeah how many of you guys love that yeah
[Laughter]
well it's one of those things where you
have to it you know nobody talks about
it but everybody has to do it and
strategies for how to do it you know
it's it's it's not an exciting topic but
once you figure out how to do it
correctly it's it's really satisfying
and fulfilling so that's what we want to
share with you guys here today we've
worked together for the last year on
some on some docker projects at his
company so we're gonna hopefully give
you guys some good strategies and tips
today how to organize yourself okay so
three topics we're gonna go over today
is is what what goes in an image a lot
of questions around that what do I put
in what do I keep out doing Mount
volumes do i do environment variables
what do i do the second topic is once
you've figured all that out how do I
then manage all of those configurations
we're gonna give you some strategies
around that and then finally once I have
those configurations weirder than I
store them do I put them in version
control do I put them in some sort of
registry how do I do all of that all of
these topics as well are in a reference
architecture that you can find on the
docker website it's called development
pipeline best practices
using dr. EE now how we're going to do
this presentation is what I'll do is
I'll present the general topic and
different strategies that you guys can
can adopt and then Jim he'll go through
what they actually implemented which
strategy they chose at their company and
on their project okay so what I do is I
go into companies and I help them darker
eyes their applications and usually we
go in there have a meeting have a simple
application and in about 15 to 20
minutes we can get a docker file written
run it in a container on somebody's lap
top and they're super happy they're like
wow this is amazing
it just works just like this baby
they're pretty happy about that
and what we're gonna see is once you
have to then push that into you know a
real production environment across and
deploy it across several environments
development integration UAT staging pre
prod prod whatever I can get a little
bit more complicated than that and some
of the decisions that you guys will make
along the way can make that journey a
little easier or harder so that's what
we want to take you through that today
so Lee is right actually we which has
had a meeting and we decided which
service we would my way to docker and at
the end of the hour we had we had it up
and running so and this this is what we
came up with after like 20 minutes of
work and what most of it actually was
spent building that Java 8 image at the
top and but now we are in production and
I can tell you that it's quite bit
different than this now before diving
into our architecture just let me tell
you a bit more
so I work for sister general it's a bank
French bank and so we've built the
financing platform for pirate business
of the global finance division and this
division it provides solutions to
companies to raise capital to finance
the project to hedge their key
transactions against risk and we also do
business in a lot of sectors right did
you know for example we helped finance
the renovation of the of the Miami
Stadium for the Super Bowl back in 2007
so yeah whatever that was us we also
finance infrastructure projects like
bridges and universities and so yeah so
let's see now how we architected the
platform so it's built around
micro-service architecture because
because it's cool okay not only cool but
it's it also provides a lot of benefits
so these these micro services there are
business orientated they have basically
there is one per domain that per
business domain and if you are familiar
with that it's called domain driven
design or dvd for short since since they
have completely different time life
cycle you can update any of these guys
whenever you want so it provides quite a
lot of agility and another benefit is
that these these services there they can
be written in any language and because
they just have to to speak the language
of the system and and this language it's
just rest and messages so for example we
have built most of them in Java but now
a few of these are in Catalan and and
hopefully maybe in the future some will
be written in closure with which I heard
very much these services they are
stateless and there are spring boots
application today and actually we don't
have only these that you can see here
but
we have more than 30 of these so today
we are in a vm world we deploy in VMs
and we want to put all these services in
Dugger and we want the migration to be
nice and smooth so we don't want to do
Big Bang and also we don't want to
refactor the application to you know
adapt and and do something darker
specific and keep the VMS the VM stuff
in other branch or something like that
so we chose to to have a lift and shift
approach so we we will try to make no
changes in the code and basically no
change in no changes in the confirmation
and we want refactoring to to happen
later when we are in docker because
everything with me will be so much
easier so we'll need to do cannery
deployment so that means that we have
both darker and VM running side-by-side
production and will progressively fly
traffic from VM to darker instances for
some users for example and we also have
another challenge that is we have many
environments so we have deaf we have
integration or mono geisha UAT
production of of course and support also
250 begging purposes and so we had to
find a way to to keep track also of
which instances which copy of the code
were deployed and to into a summer
environment ok the first topic we're
going to go through now that we know
their context a little better is what
should go into an image what should go
in what should stay out
so the question and the answer is pretty
classic consultant answer is it depends
so I want to give you two basic types of
images
there's one type of image called the
builder image and this could be building
your application compiling it packaging
it you know assembling it it could also
be an image that actually builds your
docker image as well now on these kinds
of images you can throw everything in
there you don't care about size it can
get into the gigs you throw your tooling
in there you throw your scripts any type
of you know patching that you need to do
I wouldn't worry too much about you know
if it's ugly just because all it needs
to do is build something for you this is
a tool that usually is going to run just
once as a single instance if you have it
in any type of sea icd pipeline then you
know it'll run continuously but it's not
something that's necessarily going to be
going into production and so just like
this you know console you can you can
throw you know a bunch of stuff in there
now the second type of image this is
your image that will actually be run in
production and these are going to be
more long-lived
there they'll be out there running you
want to be able to scale them sometimes
so have multiple instances of them
running for redundancy or for
performance reasons and in this case you
probably want to just stick to one
component per image so that could be web
application server it could be a
database engine but just have one
component per image and now with the
multistage builds what you can do is
actually combine these two images into
one docker file where you have one part
of the docker file doing your build app
or your build image and then once you've
created that artifacts for that the
build then you can put that into your
run image okay
now let's double-click on these run
images types so there's still some
questions what what should actually go
into these run images I'm going to give
you three different types of images that
we categorize so the first one you've
probably all heard of this this is a
base image what do we put in the base
image it's usually you know your OS and
your middleware so some type of
application server or engine and the
things that you externalize that's going
to be the actual application itself so
in the Java world let's say that's a war
file or jar file or some type of node or
PHP s and then the configuration stays
on the outside as well where you you you
mount a volume so these are what we'd
call a base image and the other side is
what we would call an environment image
now why do we call it an environment
image it's because it's specific to
let's say you a tea or it's specific to
pre prod and at this point you bake
everything into the image all of the
configuration the actual application
everything and one of the advantages of
doing this is it's extremely portable in
other words you can take the same image
and you can run it in your production
servers you can run it on your laptop
you can run it in the cloud anywhere you
want because everything is baked in then
it's completely portable and also since
everything is baked in everything within
there is traceable now in between
obviously there's a compromise which is
a release image now this is where you
put the actual application or the
version of the application that you want
to run into the image and then the only
things that you inject inside are
or environment variables and we call
this type of image environment agnostic
and so this gives you a nice combination
of okay it's still flexible because we
can inject in things for just a
particular environment but yet it has
enough traceability and portable nests
that you can you know then apply it to
different environments so let's let's
take a look now and see what they did
with the financing platform which
strategy they chose so this was our
first try so we had an image per
environment and we tried to put
everything in that base image in the
base the Linux distribution maven to get
GDK no GS you name it
so and this kind of a talker price it's
quite difficult to maintain because if
you're familiar with the bob martin's
solid principle and the first letter S
stands for single responsibility
principle and this to occupy it's a
clear violation of this principle
because it tries to do too much and
besides it's not very reusable if you
build this and you want maybe some of
the team to reuse part of it they have
to take it all so we tried to put also
the environment configuration files
inside the image for what yeah for chess
ability like Lee said but but this was a
bad idea because now your image is tied
to a particular environment okay second
try we pulled out the environment
configuration out and now now it's
better because its environment agnostic
but but you still don't get much reuse
across teams
so finally we settled on this setup so
the GDS on the far left it's our ops
team and they focus on low-level details
like the repair
system security patches network settings
and in the - rectangle you have the
build only stuff it's it's only used at
built at Build time it's used for
building the jars for packaging the GS
applications and it's it's under risk
the responsibility of our transversal
architecture team and they also built a
gr e Java Runtime image to run in
production and my team it's on the far
right and so we built the release images
that you can see on the on the right and
also the spring boot micro-service which
is an abstract docker file that we will
dive into it a bit later on
alright so now we know we have a basic
strategy for what should go into an
image but we still have some questions -
where should I put my configuration I'll
give you an example of that in docker
you can set a variable right so let's
take an example let's let's do a simple
one okay so the first one that we
usually all learn is in the docker file
environment variable foo equals bar it's
pretty simple it's in the image that I
can live with but now let's say I want
to pull it out
I don't want it baked in the image so
now I'm gonna do it actually in the
command line so I can do docker service
create pass in an environment variable
that's great but now let's say I'm
getting sick of typing that in every
single time so we'll put that in a
compose file or in a stack file show you
guys all I've done that and we put that
as you know different slightly different
syntax environment foo equals bar that's
great but imagine now like in their case
they had about 200 because this was a
legacy application they had about 200
variables that they had to set so in a
docker compose file that gets a little
unwieldy
so we said okay we can actually split
that out let's put that in an actual
environment file so phuong but there
were some as well variables that that
they didn't know beforehand and they
were they were stored in an external
configuration so if that's your case
what else can you do well you can you
can actually use an entry point script
and you can call out let's say with curl
or you can do any type of calls outside
call out to that external service and
then actually set foo equals bar writing
your entry point so that's another way
of doing it and finally sometimes your
configuration is secret right so yet
another way of doing it you can use
docker secrets to to store these
variables so how do i how do you know
how do you choose which one of these
strategies to take when we want to just
set a simple variable like foo equals
bar and so my advice to you guys is
think about the lifecycle of these
variables okay what do I mean by that
let's try to think about buckets so on
the first on the first type of variables
these are things that are long-lived so
stuff that will change you know maybe
yearly these could be more like
enterprise type tools or policies or
libraries that you want to include in
more in a base image these could also be
things across let's say an application
program where you know you're gonna
you're going to actually have you know
not only your enterprise tools but just
for your program it's tools and these
are things that everybody across your
program is going to use so you can put
all of those types of things directly
into your docker files they'll get built
into your images
and they're not going to change that
often so you don't have to update them
on the bottom part these are things that
will change more often so what are these
these are things like you know your
environment variables which environment
you're deploying to as as as we'll see a
little bit later they had many different
things to configure are they changing
weekly are they changing daily are they
changing per environment per release of
your application those are things you
can put in directly into your
environment configuration within you
know your doctor compose or your or your
even on your command line and then at
deploy time what you can do there is you
can then put things like secrets you can
put it in your entry point script you
can even mount it as a volume so these
are our things that really at deploy
time I want to inject in and then
finally there's actually runtime things
that you might want to change so this is
your container that's actually running
and then what you want to do is while
it's running maybe change some things so
that could be service discovery that
could even be debugging or profiling or
changing your logging configuration so
think about things in terms of life
cycles and that will help you structure
out where you to put different
configurations so let's see what let's
let's see what they did here okay so let
me show you some of the darker files we
created so this one is from our ops team
GTS so they get to decide which base
Linux distribution will be used so in
this case this is reddit Enterprise
nex-7
and they also put some some
configuration for the yam repositories
which will
decide which packages can be installed
in our island aquifers obviously not all
of them are authorized and also which
certificate authorities can be trusted
and this kind of stuff we don't we don't
expect this to change very much over the
course of the year next one the Java
Runtime environment image so it's
maintained by the architecture team and
they choose which Java 8 Update is safe
to use in production because they know
better they run security tests to check
the compatibility with the underlying OS
and they also check which bugs have been
included in the latest latest releases
updates and they also install a more
stronger encryption policy with than the
one which is bundled by default with the
JDK which is us specific and this this
is our microservice base image the
abstract one and we wrote it we choose
which user will be used which group they
will belong to and which ports also gets
to be exposed and please know the entry
point shall script at the end because
I'll get back to it in a few slides
and finally the release images the
release images are the one that were on
the far right and the previous big slide
with all the images and actually they
don't do anything in particular because
well they all these microservices are
just look like now so these images they
are built by our CI CD pipeline
automatically when whenever the source
code changes so they get published
published to the DTR which is the darker
trusted registry
this is an excerpt of our darker compass
so now we call it dr. stacking instead
because dr. introduced the stack concept
which is a bit more high-level and you
can see how we specify the name of the
environment that we want to run this
service in we configure also some just a
node for collecting metrics and there's
also a credential side which actually is
a dr. secret and we will source it once
we are in inside and our entry point so
let's have a look at the entry point
that I talked about earlier so first we
source the credentials file that was in
the previous slide and so we can use
everything which way which was inside
for the rest of the script as I said we
use VMs today and we want to migrate to
docker so for the VM world we use a
deployment tool I don't know if some of
you use that kind of of tool also but
this tool is also responsible for
configuration configuration management
so it's called the CMDB
and this tool it requires to be
configured in a certain way and the data
has been certain shape and the
application say oath they also have to
use some placeholder format so that the
CMDB the deployment tool can replace the
placeholder when you deploy services
onto the target machines so we we have
this because we want full traceability
we we don't just put stuff in the CMDB
and and hoping that the CMDB will keep
track of everything automatically
branches and so on usually it's not made
for that so we have a git repository
where we
all that confession data and we just
upload these data to the CMDB whenever
the git repository changes or oncoming
time there is a hook and we launch
Jenkins job to populate the CMDB right
so this format actually it's a era
format I don't know another here or
family of it it's a ruby gem which is
used by puppet and we use puppet to to
populate the CMDB so now now in the
darker world actually we don't need this
develop deployment tool anymore right
but we since we wanted to have both
running side by side in production we
had we had to find a way to continue
feeding the CMDB and keep it happy and
having some way to pull this
configuration and and feed it to the
darker to the darker containers right so
and this is exactly what this entry
point does when we say convert tmdb ya
know to properties actually it's just a
script behind that and you just pull the
configuration out of the git repository
converts that into different properties
file properties file sorry and it feed
that into the Springwood application or
we can even maybe and and subst that
into our shell script if you want and it
works just very very nicely so yeah all
right that's a lot of work right from
our first 15 minute docker file as a
baby wow it works - now it's like whoa
we had to break this up into all of
these things we got to really think
about parallel runs and you know it it
took some time to get all of this going
properly right so now what we've seen is
they know
they've broken up all of their
configuration into do I put it in docker
files in images do I put an environment
do I put it as secrets do I do it at
entry point at deploy time you know
where do I put it so they figured all of
that stuff out right but there's still
some questions which are I've done all
that now how do i how do I put all of
this into some type of version control
or configuration management and so let's
look at that now and the way we think
about it is it's just like it's just
like coding so as Jill mentioned before
they had a CMDB and in this view of the
world we're looking at configuration as
data right I'm gonna take all of my
configuration throw it in a big database
it'll be running and then when I need it
I'll go look for stuff and I'll query
the database and it will give me all of
my information and what usually happens
around that is these are these are big
products they're complicated to install
and usually only a few people mainly the
ops teams sometimes the CI CD teams get
involved with that the developers
sometimes they touch that sometimes they
don't so it's a different tool than
developers use now with docker what the
way in which we view the world is
configuration as code so we can make
this you know this vision actually come
true the reason why that is is because
all of our configuration is simple text
files their doctor files their their
compose files their stack files their
environment files so you guys can treat
this just like how you would treat it
would treat code and one of the other
advantages to that is once it's like
code then the Ops guys start use the
same tools as the dev guys so let's say
in this case get they're both just
pushing things in to get and all sudden
they're talking the same language and
that really helps them to break down
that barrier
between Devon ops and really get them
speaking together so this is just
another advantage of thinking about
things configuration as code so now once
we've said okay all this configuration
is just like code we still need to
organize it and well what I'll give you
here is as far as strategies is still
think about the life cycles of all of
these different configurations what do I
mean by that let's take your your image
files so everything you need to build an
image that's most likely going to have
the same life cycle as your as your
application so I'm coming out with a new
version of my app got some new code
going to compile it create a new version
oh I added in a new environment variable
that should go into my docker file that
might go into an environment variable
somewhere
I should probably commit that and put it
right next to my code so I can have one
repository which is more about the build
time I can put that right next to my
source code now what I would recommend
is then putting everything that has to
do with actual running of these images
anything that you're going to inject at
runtime which is environment specific
put all of that into a separate
repository why because they live a
different life cycle one is building
images the other one is I'm gonna run
something and I might inject different
things when I run it then when I build
it where I want to kind of keep
everything the same and one other pro
tip that I'll give you guys is I worked
on a project where we put all of our
different environments so we had I think
ten or eleven environments
and we put all of that configuration
into one big master branch and we
separated out each environment per per
folder so we had dev you know all of our
testing even performance testing etc and
then we were introduced new versions
because new versions of our application
were coming you know every two weeks and
so we say okay we we put it in the new
version up in here add a new variable
deploy that to this environment but then
we're we're a couple versions back in a
different environment and trying to port
different environment variables in two
different versions on different
environments in this one gigantic master
branch it just became a nightmare and so
we tried several configurations and
finally what we what we figured out the
best way to do is they just put each
environment in its own branch and the
advantages of that are what it allows
you to do is you have in one branch
let's say it's it's some type of pre
prod you can then start tagging versions
and I know every single version that's
been deployed in my pre prod and if I
want a different version on on a testing
platform then I just have a completely
different configuration for testing and
I can tag and version all of that now
you might be saying okay that might get
hard to manage as well right because you
have all of these branches how do I port
one one change throughout all of the
different branches well that's where the
tool comes in handy and which is why we
recommend putting it in some type of
real version control like a git you can
use the tool then to do all of your your
merging or your cherry-picking into
different into different branches and it
just makes your lives a lot easier so
let's see if they actually took that
advice or not so as I hinted earlier we
tried to bake in bake their environment
configure
to the image so first we just clone the
repo into the build directory like I'm
Jenkins before building the image and
just use the copy directive so as a
benefit you get through traceability
because everything is in the image but
now you just have to make sure - you
have to keep track of which image tag
has been deployed into each environment
especially into production that there
are downsides you must you must copy all
configuration to environment to be
environment thank mistake and and you
you have to reveal all images whenever
your configuration changes and it's not
very big binary only once which is a
fundamental concept in the in continuous
delivery so in my opinion the best way
to to cope with environment
configuration it's it's via the the
entry point and using this technique the
images that and very non elastic so you
don't need to rebuild image when the
configuration changes you just restore
the container and then you go new
configuration is here as the downside
you need get but and you can lose out of
about traceability unless you you log
somewhere maybe by some environment
variable which confusion come it was
used when you deploy the micro service
to container and yeah so a few a few
ideas of where where we are going so we
listened very carefully to Julie and as
I said we we used for the big big
configuration git repository we use the
master branch approach and and it was a
total mess as I said because when we try
to change something refactor some parts
of the application etc you can have
the previous version working with the
newly refactored configuration stuff so
it's very very awkward so in the end we
just made some branches and we could not
avoid this because as you said they
sometimes these this environment they
have different life cycles maybe you
have some training environment and it
will stay up and running like for three
weeks because you are just training new
users you just can't
pushing new versions on to it and so we
which shows lightly which we chose the
run repository approach so we separated
separated the the environment into
environment configuration into their own
repository and this we did we did that
for each domain so when we want to
change the environment configuration for
I know for integration we just check out
the NDA run repository and we check out
the integration branch make some
modification commit push and the CI CD
just redeploy everything and just check
out shut down these the NDA integration
stack and just restart it with with the
correct information so it yeah once once
you have the tools as we said it's very
very easy you don't have to do anything
just don't do it by hand for like
thirteen microservices because you will
die and yeah one last thing is one
particular interest that we have is to
to do Bluegreen deployment and so we are
still invading investigating that and
hopefully there is something which is
coming in the next version of dr2 to
handle that more out of the box you know
you know out of the box wait alright
okay so in conclusion here we looked at
the three different topics and they
chose to use release images as
the nice compromise between flexibility
and traceability and portability they
went through and they did the exercise
of thinking about configuration buckets
and life cycles where to put different
things put it in images put it in
environment variables or as secrets or
in an entry point and then finally to
store all of that they separated it out
all of their build into one build
repository and then all of their
configuration at runtime into a separate
repository once again because they live
separate life cycles so we're hope that
just some of these tips right here on
strategies will help you guys so that
you'll be like this baby
you'll stay nice and happy and you'll
enjoy your journey thank you thank you
you guys have any questions yeah so the
question is how do you handle secrets
because you just can't put secrets in
plain text into version control actually
we did that but we did not put that in
plain text
we encrypted these with gem which is
called yeonil like encrypted ya know
and where you can encrypt the values of
some-some
era key some Yamabuki so this this is
what we did for until today actually and
these these dot these secrets they were
put in plaintext but inside the
container so the container we pushed the
the decoding key the public and private
keys in in darker secret and thus creat
just pulled the key and just run the ER
mechanism that you saw can
IML blah blah blah and it's unencrypted
the keys and and spit out the property
files and they they have the plane the
the the secrets in plaintext but you
can't access a container from the
outside unless you are authorized so
it's secure enough for us now we we are
considering maybe migrating this stuff
to to vote but the main problem remains
that do you want to put that in in vault
and just say everything will be will be
story involved and nobody can maybe read
by this back the secrets and maybe you
can't even decode it actually for
example in Tucker you can't read a
secret if I remember correctly we're not
completely we have not completely
decided what we want to do with the
secrets and it's an ongoing topic also
in the docker community because there
are a lot of bad practices and people
are uncovering new ways to do it but
there is no definite answer so we're
still investigating
I'll follow up on that is if if you're
staying just within the darker world so
you're using docker secrets the best
practice today is to just version those
secrets so you'll write in a version my
secret you know docker
secret create and you know the the name
you'll give it give it a version so that
could be a date it could be a tag it
could be you know any anything version
one and then if you want to rotate those
secrets then you create a new secret
version two and then you adjust and that
and that way what it does is your
secrets then become traceable as well in
other words it's not just you know my
MySQL password and it's the same
variable every single time you can know
exactly which version of that password
based on a date or based on you know a
shower or or any type of or sequence
that you want to use
okay the question is we use console and
how do we use it actually we don't use
it for a configuration management right
now and but we but we plan to and the
question remains do UPS or they have use
cancel directly and just cow
some some key information into it and
that's it but my opinion is that we
should for a conversion management
especially when it's not secret
you should have full traceability so
gate is a I'm a my opinion it's the best
place to put these because now you can
review maybe in a pull request somebody
who is trying to do something and we
want to do maybe you want to say oh no
don't do this because there isn't some
better way or no no you're not allowed
to do this we are like sixty developers
and some of them are engine yeah and and
sometimes there is a little like wool of
confusion between teams because we don't
work very closely and they don't they
don't know what we are trying to achieve
because of the distance and the future
whatever you want and sometimes they did
in the in the CMDB is they did
modifications and with now we were not
aware of and then like two weeks later
who did this and we didn't know that
they had changed something in summer
environment which worked for their
environment but not for the other one
because they were just responsible for
this environment and they felt that it
was not the job to update all the
environments and that kind of stuff and
when it went like crazy and we just
spent days to debug problems so let's
put everything in gate and let's just
use commits and for triggering update in
another system so for example console
so we use console only for service
discovery today so we register
services in council and so other
services can look up services by a
console and also with some we use some
of the key value store in console to
store some specifics about the service
like the contract that they provide
mobile there is a debate so we would
have these debates with between the
devil and the ops teams were where to
store and you know console comes up all
the time
so some of the the advantages of of
using or I would say the the main the
main thing that comes up is everybody
says yeah but forget what if get goes
down right and whereas console you can
make it you know high availability and
disaster recovery and all that so there
there's a sort of debate that's going on
should you introduce another system
there and as you was saying it's you
should probably only have one golden
source so use git as your golden source
that way you trace everything because
what happens with if you go to console I
would think of it more as a cache of
your golden source what happens if you
go to console then let's say you need to
start rolling back things then all of a
sudden you're like oh well let's start
versioning things in console and then as
you said it's like well who changed what
in console okay let's start assigning
you know role based access control into
console and and then you start doing
traceability and diffing and everything
you end up redoing get in console right
so if that's the case what's the better
thing to do is to just make a git and if
you have to create a Enterprise get or
highly available disaster recovery get
just for configuration management for
your runtime but as we see today I mean
if the developer platform org it goes
down you know your company loses so much
money anyways that the big trend right
now is is is that house it's it's just
as valuable as production right it has
to be up all the time I just want to add
that when we say git actually we say
we mean github because we have a github
enterprise on-premise yeah so the
question is is there there's build apps
and there's run apps and what if and the
build apps are usually bigger and the
run apps you optimize them the question
is is what if in your CCI CD pipeline
you have a lot of build apps as we do
yeah and they actually do so so this is
just two ends of the spectrum obviously
you can you can then have something in
the middle and you can actually start to
optimize your build apps as well it all
depends on what your frequency is of
your CI CD pipeline do you want to add
anything to that yeah yeah we actually
are running into some problems about the
build Abid not so much because the build
up are too big it's rather that for
example we use we are we are in Java
right so we use maven so when we say may
even we're a company we use Nexus or
active factory or whatever and we have
trouble with for example the local repo
which will hold all the dependencies
thanks to be it tends to be very very
large
and we are we have run into problems
with that because the host can be very
there is not too many too much space and
it can be a bit and cumbersome to to
have all these build images all over the
place maybe some team will have that
part of these libraries and other team
will have like these libraries but you
won't you don't want to share these
right because you don't want side
effects we're doing bills so each one
should have his own volume this volume
and so on so on so it's it's difficult
to to to to decide which strategy do we
have a shared volume or volume mounted
do we in some days build image do we
just
pull every dependencies that we can and
have that as a layer in the docker image
it's difficult to say and also we also
had some problem because some bills were
running on nodes in the docker swamp
where they were not supposed to so we
are you know still finding some
solutions to that and we are we have
some actually yep did that answer your
question but but if the problem is the
size of the building edge you can apply
the same technique techniques then for
the the run app obviously you can I
don't know if you don't don't need some
part of you can obviously there are some
techniques you can remove avoid to to to
have big zip files or cross layers just
remove them whenever you can and so on
its own one command that's very helpful
for optimizing images is you do a darker
history and then you don't you give the
name of the image and it'll print out in
reverse order all of the the layers
basically and all of the commands that
go into it you and and also the size
that it adds very quickly you can see oh
I did like a copy and then unzip whereas
I could have just done that in one thing
and I can minimize the size of my image
okay
thank you guys don't forget to vote</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>