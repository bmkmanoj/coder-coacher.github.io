<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2013 • Knowledge is Imperfect - Acting on Stale, Inconsistent or Missing Data • Ulf Wiger | Coder Coacher - Coaching Coders</title><meta content="GOTO 2013 • Knowledge is Imperfect - Acting on Stale, Inconsistent or Missing Data • Ulf Wiger - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2013 • Knowledge is Imperfect - Acting on Stale, Inconsistent or Missing Data • Ulf Wiger</b></h2><h5 class="post__date">2015-10-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VUy0cgZ87cY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I thought that maybe I could talk
about some of the experiences I've had
through my career in I you know working
with imperfect data and after agreeing
to that I realized that's pretty hard
topic to talk about we'll see how it
goes I'm mainly gonna go through war
stories I'm not gonna give you any
algorithms or extremely concrete
examples there will be some concrete
examples on how we've solved a few
problems whether they apply to you I
couldn't help but mainly I would like to
focus on just the process of
understanding what the problem is
problems are with your knowledge your
knowledge of the data you're working on
and also the knowledge of the problem
you're working on and so I guess this
would be my version of Steve Ritchie's
hammock time problem that I also tend to
be the kind of programmer that will go
you know you may find me in the bathtub
hopefully you will not find me in the
bathtub
but apparently not working at all for a
long time because I'd like to understand
the problem to the point where I can
almost see the code in front of me
before I sit down and actually write it
down that is sometimes a bit
embarrassing when you try to explain to
people that you are actually working
so my experience briefly a few years in
my youth I was in Alaska of all places
working with first the US Air Force and
then the Alaska Division of Emergency
Services and working on military command
and control systems and then disaster
response systems and so I got to know
that is a picture I took of a MIG 2029
I believe it is that was visiting the
Elmendorf Air Force Base outside of
Anchorage in 89 it was part of the sort
of the changes after the Wall fell
so essentially command and control is
all about trying to figure out what is
going on and forming decisions based on
that and so the system that I was
working on was a reasonably global
system near real-time the graphical
information displays would update about
every 10 seconds with information about
troop movements information from radar
feeds all kinds of stuff with no single
point of failure and attaching to a lot
of different systems using lots of
translators and and trying to normalize
data it was an interesting first project
to work on after that I joined Ericsson
the reason for joining Ericsson was
partly because they seem to be doing
fairly cool stuff too I had learned that
mission critical was cool it felt real
in some way and Ericsson was into
mission critical systems but most of all
I wanted to find a company that where I
could work with Erlang and there weren't
that many back in 96 I think there was
exactly one so I joined Ericsson and
there I spent 13 years there which is
which means that you barely sort of
graduate from junior status in the
company actually during the telecom
crisis after after a while there they
were actually firing people who had up
to 10 years experience last in first out
so I I just barely made the cut so
that's how senior they made you feel so
one of the things we built was
I guess nowadays it's voice-over-ip
back then it was voiceover ATM but
voiceover packet if you will sort of the
migration from the old-style telephony
systems over to IP telephony and so I
couldn't say that we invented the soft
switch because that was actually
loosened that is they called it that
they were the ones who called it a soft
switch we were the first ones to deliver
something that actually worked in in
hardcore systems like the British
Telecom transit network and in Spain and
French Telecom and a couple of places it
was good fun about two million lines of
Erlang code now I work in a small
company we are three developers building
connected device management services and
I guess it's a bit too soon to share a
bunch of experiences from that work
because we've been going at it for about
a year and a half so some of the traits
of these systems have been working on
for example C 2 you know the military
they're very big on acronyms and it all
has to be all caps always so they call C
to command and control one of the
interesting things about military
command and control is that you have to
assume that you have an enemy that it's
actively trying to make your life
miserable so you have requirements like
your system should work even if most of
your sites are bombed out of existence
and you have people who are actively
trying to feed you false information now
that really feels like a modern
requirement for web applications to we
have to deal with denial of service
attacks and spoofing and everything
another thing is that you have to be
prepared to you know go where the the
war is which means you have to be
prepared to deploy to some pretty nasty
places where they may or may not have
electricity communications and another
thing is you may have to be you also
have to be prepared that once you try to
deploy you get there your system may not
work at all or it may get broken by the
enemy so you have to have a fallback
that is completely manual and of course
it's very mission-critical the sort of
the saying was or the the bottom line
was you screw up people die and that is
interesting because it does keep you
sober sometimes I missed that at
Ericsson because it was sort of
mission-critical but not the way I had
come to think of mission-critical
like life-or-death mission-critical so
this was like 89 and early 90s so you
know technology then wasn't quite what
technology is today this was before the
web so we needed no single point of
failure full redundancy everywhere that
meant we had to replicate they
practically were no replicated or
distributed databases at the time a few
but they couldn't distribute data at
that scale they actually tried a few and
mostly they I think they actually
escorted some some of them to the
airport and told them never to come back
so they were a bit disappointed with
sort of the cutting edge technology at
the time so they built their own
replicated database management system
using asynchronous replication update
trigger-based
asynchronous replication using a process
control messaging system from digital
called Pam's
now for synchronization they actually
were using optimistic concurrency like
you have a before image and then you
were editing stuff and then if if the
the database had changed before when you
try to commit it would just come back
with an error this worked really well
because this is the military you don't
mess with other people's data it's very
well-defined what pieces of information
you are responsible for and when you
will touch them and under what
circumstances so actually a lot of the
concurrency control and a lot of the
consistency control were guided by the
manual fall back which was you have to
be able to do this manually just people
talking to each other on the phone
grease boards so they essentially
automated that in the system so what
about split brain well you would
continue with every all the data cached
and then if connections were restored to
another system
again this is strict partitioning on
roles whatever information there was
about another air base for example that
was theirs their data so you would just
throw away everything you knew about
them and just suck in new data and it
kind of worked
now replication was a challenge because
this was Alaska and they have some
really funky atmospherics up there with
the Northern Lights and everything that
that mess up your your communications so
one replication link they had was 19
well actually it was a multiplexed to
multiplex 19.2 modems so during some of
their big exercises with 50,000 soldiers
in the field they actually they filled
that pipe they couldn't replicate all
the all the status information so then
they had to go back and prioritize all
the data items so when a lot of things
were happening they were only
replicating priority-one items and then
they would buffer the rest and and fix
it later this was an extremely pragmatic
system but as far as I could tell it was
the only such system at the time that
actually worked which taught me a few
things about politics because of course
they had to shut it down but that taught
me another thing about the US military
the people who have operational
responsibilities like the flight line
commander you don't just go and shut
their system down because these guys
were patrolling the US border Alaska
borders to the Soviet Union and or did
and so that was real work so no one
could touch their system and less they
could prove to them to their
satisfaction that they could the thing
that they would put in instead would
work as well or better and they couldn't
so the system stayed much like Erlang
survived at Ericsson during the dark
years so telecoms one of the things
about telecoms is that it's a ubiquitous
service like everyone knows how how the
phone works and they expect to be able
to use it and they expect it to always
work this was basically back then mobile
telephony wasn't quite as big this has
been somewhat changed by mobile
telephony because that doesn't always
work and it's are not always good
quality but the the old fixed lines
actually you know how often did that
fail until you started getting a cisco
voice over IP modem in your basement
then it actually would fail but before
that it pretty much always worked every
once in a while like once a year
possibly you would pick up the phone and
you get no dial tone you would put it
back pick it up again you would have a
dial tone
that's how reliable it was
one of the things that was exciting was
that emergency calls should always be
serviced the requirement was even if you
have if the load on your system is a
hundred 150 percent you should always
service all emergency calls and our
modified requirement was that we should
service all emergency calls even at five
hundred percent load so we could reject
other calls but never emergency calls
so another thing was that if your system
fails it has to fail in a way that is
acceptable to people we had some
complaints occasionally when our DSPs
failed and they would actually send all
once which essentially translated into a
primal scream on the phone line that was
not popular it was not the kind of
failure that people had come to expect
from from a telephone system another
thing is when people expect it to be
reliable you try to this has also been
changed by mobile telephony you you dial
a number and then you wait a few seconds
and if you don't have if you don't hear
a tone you just hang up because it's not
working so you have a few seconds where
you can connect the call otherwise your
user is gone a little bit worse than
when you're waiting for a web page to
load you will wait for a minute or so
but another thing is if you have delays
in speech then you have sort of the
cognitive boundaries where you can
tolerate some delays without getting
concerned but if it's too much then the
user will get very uncomfortable and if
he gets worse than that then actually
people will not be able to communicate
because they will they will wait and
then they will both start speaking it's
called the pardon pardon problem because
you always say you're excused
making excuses because you're
interrupting each other and you never
really it becomes like a you know
simplex radio communication you have to
one has to speak and then say over and
then the other person gets to speak so
so you have to fail gracefully and the
other thing was legacy when I started in
96 I saw are a risk request from for
proposals from the Swedish tailcoat Elia
and they still had electromechanical
switches from the 1940s in the system
that they were facing out so that was
another requirement that you really had
to be able to work with some very old
systems so so now in connected device
management there are actually quite a
few challenges there is the integrity of
the messages that you send from server
to device there is the consistency of
configuration data there is the
interesting challenge of upgrading
software over-the-air and trying to
figure out if it actually if you're
upgrade worked and often if the device
fails it tends to just go quiet on you
so you sit there and you just wait and
say oh is it gonna this is gonna come
back should I wait some more how much is
enough a minute when should I just get
in my car and drive out there and try to
salvage the device you have the problem
with connection quality remote debugging
sandboxing in it but most of all in the
area of it the Internet of Things the
problem is you don't really know what
the users want and the users don't
really know what they want they they
kind of know that they want something
like this but basically we have to make
things up and try to tell them this is
what you need so so I've come to think
that the sort of the basics for decision
support is sort of good foundation for
dealing with uncertainty now in decision
support they used to talk about the four
WS this is sort of the core of the whole
thing who what when where why is usually
not interesting when you're reacting to
something that's something you can save
for late nights with a glass of whisky
or something so the who who reported
just learned in the previous talk that
it wasn't interesting anymore but when
you're trying to assess information it
actually can be what happened when did
it happen where did it happen and the
short form that the kernel in Alaska who
was responsible for the c2 system was
where are my resources what are their
what is their status that's what he
wanted to know so in terms of the who
like I said you may want to protect
yourself from false information so you
need to authenticate and also the
quality of the information may depend on
the the source for example in if you say
we're still talking aircraft here there
or military so you've spotted you have
information about an enemy aircraft well
if it was from some guy who saw
something and then called in that's the
kind of an untrusted source it may be
true if it's an actual feed from the
radar station then you trust it pretty
well so and one this is actually a
picture from Canada somewhere but we did
have one of the things they had problems
with in the last
it was flooding and so I was there
during one particular flood that was
very interesting from a Disaster
Response point of view the the
communications officer informed the boss
that when he heard that the what the
water level was expected to be he said
well okay the alas calm backup generator
is actually lower than that so it's
going to be under water soon and we're
not going to have any communications now
the problem was the boss hated this guy
so he wasn't gonna listen to him so the
the generator flooded they didn't have
any communication they had to fly up an
NMR satphone and of course everyone in
the village was talking to their
relatives on that mr Sat phone so the
phone bill for that particular rescue
operation was seven hundred thousand
dollars so sometimes it does matter who
actually reports the information and not
always in a good way now that particular
picture is the FBI building in Oklahoma
City we were asked by the Red Cross to
try to figure out how many Alaskan
relatives were injured during that time
and it was very difficult to get some
information because basically this would
that no one was prepared for this and
one of the things that happens at every
disaster is that everyone wants to
figure out what happened to their
relatives so one thing that often
happens is that the whole phone system
breaks down because he gets overloaded
and a lot of people don't practice this
and the Swedes didn't for example when
there was this tsunami and and pockets
the Swedish the phone switch for the
foreign ministry broke down and no one
could find out anything so I ended up
sitting there scraping the web because
people
were putting up makeshift websites where
they were they had copied transcripts
from different hospitals they were
running triage and it was pretty chaotic
so some people could be checked in at
one hospital and then they were checked
out at another hospital or listed as
dead and so you had to sit there and
actually deconflict and try to pair
people people try to figure out who were
family and that was quite interesting
but not fun so figuring out what has
happened is often surprisingly hard and
I think this is also true in many of our
software systems I used to especially on
the telecom systems that at Ericsson one
of the things that I had to work on
what's cluster control partly because we
thought that would be part of Erlang OTP
but apparently they didn't know that so
they didn't build a cluster controller
so someone had to sort of jump in and do
it and that was me so I had to do a lot
of work the Deacon or trying to figure
out or diagnosing split-brain and and
things like that
and
also different levels this is back to
command and control that's different
different people they've need different
views of data so one of the challenges
is to serve just the right level of
abstraction so the the approach that
they had up in Alaska was basically put
everything into the system they would go
out to all the different services on the
airbase and it was the hospital's flight
line mechanics everyone and asked them
what they needed and then they were
doing rapid prototyping of database
views and eventually everything got into
the system and then they figured out how
to aggregate that for different levels
so people in the field would need a
certain view the people in the command
center would need another view but one
of the things that was really important
here was that it was all the same
information at the bottom so the general
could actually drill down into sort of
the maintenance logs even if he wanted
to know what was actually going on why
didn't he have any radar coverage for
example and now we get into a little bit
about sort of organization as well so at
least when you're giving a presentation
you can you can define your own laws and
and named them after yourself one of the
things I found especially after some
years set at Ericsson is that management
likes the view of the world that they
are telling people what's going on and
and what they need to do and people on
the floor may sit there and say well
yeah we already knew that because we
read the papers too and we hear the
rumors but we actually know what can be
done and what is being done
which you don't seem to know especially
in a big company this seems to happen
and one of the problems is that
information gets disconnected you report
to your nearest manager who wants to add
value so they rewrite what you report to
them
and summarize it to the next level and
then that level also wants to add value
and appear original so they will rewrite
it a little bit so once it gets up to
the upper management
it doesn't really resemble what the
people on the floor actually told their
managers and there is no way to drill
down because it's been disconnected at
every level so this is one of the big
things in in a big organization even in
a small organization but in a growing
organization it gets more and more
important that you you don't want these
disconnects and information this also
bears on the design process if you have
a big project how many of you have
actually worked in a big project like
more than 50 people okay about half so
one of the things that can happen there
is that you have analysts you have
people who are maybe architects or
whatever who look at the requirements
and they think about the problem and
they decide how you're going to build
stuff meanwhile the programmers are busy
on another project you can't use them
for the analysis phase because they are
doing important stuff in the the systems
we built the analysis phase could take
several months which is basically
stealing that time that the designers
should have gotten in order to get
acquainted with the system and and sort
of let the the the problem descriptions
and the abstractions and the ideas about
how to build it sort of settle
conceptually it takes a long time to
sort of get a mental grasp of a complex
system and so I used to call that mental
gestation time you know how do
you even get a grasp of a very complex
system will you stay in it for a very
long time
and eventually we'll all feel natural to
you but if you just jump in everything
will be seeming called incomprehensible
so I found that many bad decisions are
made by very smart people because they
don't have the full picture and and
often that is becomes the case because
too many people are reporting and
everyone wants to add value or not
bother others with things that they feel
are unimportant so so an effect and I I
was reading the book weaving the web
when I was at Ericsson and I I felt that
this was really applied to me and this
book was about how the web came into
being and one of the things he wrote was
an organization loses its intuition when
the person who has the answer isn't
talking to the person who has the
question and then that rang true for me
because I had been there for several
years and I had not once met a customer
because other people were doing that so
when you actually sat there and you were
trying to build the system you really
would have wanted to talk to a customer
but usually especially managers don't
want developers to talk to customers
ever because developers tend to say
things that are inconvenient so you you
need to keep them away from the customer
but that often means that you don't
really get the cut and the answers to
the questions like is this really what
the customer wants have they really
thought this through don't they really
mean something in else entirely but
still you have to build something you
have to build it on time and you have to
test it and you have to prove to your
managers that this actually works and it
passes all the test cases but you can't
say with confidence that what you built
was what the user
he wanted now this is where agile
methodologies are extremely important I
think but one of the things that Bjorn a
Decker who was one of the fathers of
Erlang you could say the the guy who
actually started the computer science
lab at Ericsson he used to say that
software development is a top-down
bottom-up activity so you can't really
solve it with just bottom-up methods and
you can't solve it with top-down methods
either so I've seen a lot of agile
methodologies applied to big projects
caused a lot of chaos because what you
what you missed was the architecture
view you get a lot of feature teams and
you get a lot of efficiency building
something you have this component and
and you have your view which is
basically formed by the people the
knowledge combined knowledge of the
people in your feature team and you go
with that knowledge and you build
something but what you don't necessarily
know is whether it fits into the major
into the big architecture and so I was
impressed by tawny horse Turing award
speech I'm probably not the only one
have you read it how many people have
read tawny horse Turing award speech to
the rest of you homework it is excellent
and he talks about how he failed
completely on on a certain project that
suffered feature creep and but to his
surprise he was put in charge of of the
cleanup project after they had gone out
to all the customers and told them that
they couldn't deliver and so after that
all the managers paraded into him and
told him him their view of why things
failed and finally the biggest boss I
pictured a Thomas who came in
and shouted he always shouted apparently
you know what you did wrong you let
other people do what you yourself did
not understand and Tony horse first
reaction was that he's completely out of
it
how could anyone possibly understand a
complex software application like the
the Hughes modem application but finally
he figured out that this was actually
the key to the whole thing so one of the
things they did in order to rescue this
was that everyone who wanted to build
something had to come to Tony Hoare and
explain what they wanted to do and that
he wouldn't let them do it until he
understood what they were talking about
and we talked a lot back and forth at
Ericsson and decided that this probably
would fix a lot of our our problems as
well you know we weren't sure that we
could get away with one person since it
was a hundred-man project and like four
million lines of code in total but we
thought that maybe a team of a handful
of people and the the gating requirement
was that the design teams should come to
us and explain their proposal until we
know it and says said yes we understand
not necessarily yes this is the best
solution but yeah we understand what
what you're trying to do and an ideally
in order to make this work they should
come to us early and talk about their
early ideas so that if we did not agree
at all it would be easier rather than
spending three months in your cubicle
writing a hundred page document and then
saying here this is what I'm gonna do
which was usually what happened and you
and then you had a documented review you
got the document to wait two days before
it was a really complex hundred page
document and you were supposed to have
an opinion
you could have an opinion about the the
headers the footers the spelling the
table of contents and if all that was
okay you pretty much approved it because
nobody else and people would sit there
and page through the dark
and as they were sitting in the the
review meeting because you got ten of
those every day so how could you
possibly read them all
so sometimes you really have a very
exact information if you have
specifications you really should make
the most of them and it really would be
great if they were also correct which I
found when I was building a diameter
stack at Ericsson date
this is actually an extract from a
diameter specification and I thought it
was really smart I just copy pasted the
formal parts of the specification into
my code generator so I would generate
code from the specification so that my
codecs and and everything would be
exactly according to spec but for just
about every specification I did this
with I got a compiler error because the
spec was not syntactically correct it
wasn't consistent there were typos in
the variable names all kinds of stuff so
I were even and this would be 3gpp it
would be Etsy these were you know stable
draft specifications and they didn't
work so and I would send these reports
back and they would not really
understand what you did what you you
tried to compile our specification and
then I had to run Interop tests and and
of course they didn't work and
eventually we would arrive at some we
could you know two systems could talk to
each other but of course you had to
wonder so what is this mean so I have he
has a specification I have the
specification I know my specification
was buggy because I had to fix it and he
has his interpretation and we so
essentially you just test until it seems
to work and then you do the same thing
for the next system you have to connect
to but if everyone did this
if you would actually require these
specifications to be formally correct
and also require other people to use the
specifications and use them as input to
your software and you can generate tests
from specifications as well things would
be a lot better and you will find that
the spec is broken but pay file a bug
report make sure that the spec gets
fixed so where would you do this
so we used to say maybe this is just
obvious to everyone but essentially you
have your boundaries and that the
external boundaries you verify the data
as much as you can so if you have a
specification for the protocol for your
data structures put that schema in there
and do as much validation as you can and
once it passes the validator it should
be correct and then you trust the data
and you trust internal users of the data
you don't trust external users of the
data then you do all the checking at the
boundaries now an interesting part of
this is that usually you will have a ton
of information inside the system and we
tend to sort of get tunnel vision we
look at the state in our processes or in
our objects or whatever but what is
really the the key information that
drives our system I think that it's that
is the data at the interfaces the data
models that we have there and we should
have specs for those and those are the
ones that we should all never forget
about that should be the the defining
feature of our system now back to the
for w's the when this can actually be an
interesting part of software design
since I have to restart my machine I
don't really know what how much time I
have ten minutes different data has
different lifetime qualities
some data really should be persistent
some data should not be persistent it
should or it should persist as long as
the system is up one of the examples of
that was current alarms tables so in
these mission critical systems you need
to be able to display alarms and in a
sufficiently big system you'll always
have alarms or events some things that
are not working if the system goes down
and comes back up again that table
should be empty and be repopulated so
what we would do is we would replicate
the current alarm status in RAM on all
nodes to make sure that when we came
back up we didn't have any false alarm
information so then it actually is
completely empty and it has to be
reissued part of that is you don't want
to notify people of something that is
not true anymore and we also found when
we were talking to developers and
optimizing the system that at least
initially there was no discipline in
keeping dynamic or transient data and
persistent data apart which can be a
performance problem when you keep
storing transient data persistently and
it can be an integrity problem when data
outlives its usefulness and so the
things we used to talk about was the
persistently persistency levels of data
like whether if it resided on disk it
should be written replicated otherwise
why store it on disk you could replicate
things in RAM like I said and also you
could talk about how much you should
replicate and replication factor I'm not
going to talk about that so much because
the no SQL people talk about that at
length now one interesting thing is when
you when you actually program things in
Erlang you deal with a lot of
lightweight processes and these
lightweight processes have their
dynamics
and you have automatic garbage
collection so you actually you you deal
with a lot of transient data and you
don't really do memory management
explicitly so this kind of gives you a
different approach to date a lifetime I
mean most of the time you don't really
think about it if it's transient data
you do need to think about what data you
need to keep especially since Erlang has
a let it crash philosophy you do a lot
of pattern matching which are sensory
assertions and if something fails you
just crash your process and anything
that was on that heap is gone so if you
wanted to outlive a process crash you
had better store it somewhere else to
and one of our optimization experts
actually is that picture above there is
sort of a schematic of our session
control processes we would when we would
establish say an ATM session we had a
processes that did a lot of work they
had lots of data but when we wanted to
save memory we started looking at how
much we could compress this data because
we only had like 512 megabytes of RAM
and we needed to support like 30,000
simultaneous connections so we needed to
be a little bit frugal about how much
data we actually used so he came up with
that model saying you have the the
session management process in the middle
and it needs to talk to below to the
resource management because it has to
allocate resources in the switch and
these are the information bits that are
needed for that it needs to talk
upstairs to billing and these are the
information bits that the billing
services need and then it needs to talk
to the calling subscriber and the called
subscriber essentially the the endpoints
and those bits are defined in the
specification and these are all the bits
that we really need in order to for
example take this if we take this
process down and we want to reestablish
it these are all the bits that are
required everything else is just
transient data and can be reconstituted
from from these bits so that is kind of
your your interface to the outside world
and it really helped the modeling so
when you have to report failures and do
some proper fault management it can be
really difficult to know what has failed
there was an interesting mishap on a
Qantas Airbus in 2010 we were involved
in that a little bit because some
reporter called us someone was wondering
whether the problem might have been that
they were not using windows in the
aircraft control system not using
windows they were using the the green
hills separation kernel which is a
really really good real-time operating
system the thing that had happened was
that the engine exploded and fragments
from the from the engine actually cut
off the cables so that the control
system was just sensing failures all
over the case all over the place because
it just simply couldn't see anything so
the cockpit just lit up and signaled
massive failures of everything so the
pilot has had to just ignore everything
and just try to land the plane which he
was able to do so absence of signal
really is a very difficult problem and
of course it's a part of the split brain
problem which I said I worked on a
little bit these were two problems ways
that we try to solve it in the control
processors we had control processors
that were dealing with a lot of device
processors that were essentially the
data plane of the system
so we were monitoring them so we had
this ping process that would monitor the
do a heartbeat on the device processors
so what we did was we put a virtual
device in the control processor so if we
could ping ourself
through the switch at least we could
talk to the switch which told us
something so if we were losing or
couldn't see the other control processor
but we could see ourselves it wasn't a
communication failure on our part but we
eventually moved over to this we were
using tcp/ip for the distributed Erlang
toward the nodes talking to each other
but we were also sending metadata via a
UDP ping and it didn't really matter if
it got there we would just keep sending
it and if you got a UDP message from a
node that was not part of your live set
then you had a split brain system and
what we did was we didn't automatically
connect these so we found that it was
really hairy in a very complex system to
try to sort things out once the nodes
had reconnected
so we preferred to keep them separate
and then used the UDP channel to
negotiate who should restart because
that's how we resolved it some one side
got to restart and just sync from the
other side and one other thing that I
haven't heard that much from in other
places was something called knockout
units essentially that was your gonna
fail and you're gonna lose data so you
need to model for that and you need to
think about what is a suitable unit of
loss that you can survive so for example
if a call set up fails it's okay if you
drop that single call if you drop an
entire processor for example how many
subscribers can you knock out for us it
seemed to be 2000
another thing was to save to increase
performance we would do a synchronous
replication of data but then an
important thing there was how many
messages do we have in flight so if we
get a crash there how many replication
messages which is essentially sessions
that we would lose are acceptable so
then we would take that to the project
managers or the the network planners and
say okay this is the failure that we're
talking about how many sessions can we
lose you tell us and we'll will tune the
system so and you will have some cases
where you just simply can't recover so
these are essentially invariants like
you can never build a system that are
going to recover from every failure you
have to just make up your mind that if
this happens we're dead and we can't
really do anything about it and
hopefully that's not something that
happens too often anyone really
recognize that the Xerox copying problem
I was I was reminded of it at lunch if
you're gonna fail
you had better fail in a way that's
recognizable as a failure so the problem
here was that Xerox copies scanners were
a little bit too ambitious in their
compression so they would they would do
block level recognition and in some
cases they would actually what's
happened here is that they would replace
a six with an eight and of course it's a
perfect eight so you don't you can't you
don't suspect that that's actually a
scanning problem so if they if it had
been a blurry six or a blurry six that
almost looked like an ad would you would
eyeball it until you figured out or you
wouldn't trust it at least but here
there's no reason not to trust that but
it's actually wrong and and we have this
tendency often to want to serve a useful
result but but a distinctive crash is
often much better
than a useful or apparently useful but
wrong result and so I think that's about
the worst thing you could do to serve
the wrong data to to the user just in a
misguided effort to try to be helpful so
last slide so I think that often when we
try to model systems we forget to model
failure modes and we don't always model
data lifetime we don't think so much
about how long data should live and we
tend often to forget to model how much
data we can afford to lose and under
what circumstances and the last one
there invariants I think that's
something that is also something we
should think about more I think of
invariants as sort of the supporting
walls of a construction we often make
those decisions implicitly we don't
really talk about them we should
actually write them down they these are
the assumptions I'm making about the
data
if they're not correct then basically
all bets are off
and very often we will have problems
like that and we especially need to
communicate that to the product managers
or the people who feed us requirements
very clearly say these are the
assumptions we're making worse this will
not change if you change this we have to
start over and usually we will know what
those are but we don't write them down
and we're almost embarrassed by them but
we shouldn't be those are the supporting
wall architecture ok I have no sound I
have no more slides so any any questions
I'm not getting any in on the app here
so oh here we go
how do you know data is wrong if it
looks right like the Xerox problem yeah
so yeah how do you know data is wrong I
mean you can there are there are
certainly techniques so in this case I
mean it's a very subtle case I mean it's
presumably valid compression technique
that produced unwanted results or
confusing results but but of course you
can because it's actually I mean what
they're doing is in that case is that
they are just estimating or hand waving
a little bit this block kind of looks
like that one and and they simplify and
hope that it works out but in case of
digits it's it's a very it can be
disastrous obviously but otherwise I
mean you have crcs and all kinds of
stuff we have a lot of techniques
for verifying the data doesn't get
corrupted let's thank all and thanks to
all of you for a great q con hope you
come back next year</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>