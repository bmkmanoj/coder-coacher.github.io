<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Rethinking Data for Intelligent Computing • Julie Pitt | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Rethinking Data for Intelligent Computing • Julie Pitt - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Rethinking Data for Intelligent Computing • Julie Pitt</b></h2><h5 class="post__date">2015-10-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WVck7IPOzFs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you so my name is Julie Pitts as
you now know and today I'm going to be
talking about a possible future for
intelligent computing and how that might
change the way in which we think about
data so I want to tell you a little bit
about why I'm here how I got where I am
today my first exposure to artificial
intelligence was in 2005 actually Jeff
Hawkins had just written a book called
on intelligence has anybody heard of
this book a couple people okay so you
may have heard of Jeff Hawkins he
created the Palm Pilot back in the
1990's
but his lifelong passion is machine
intelligence and in particular he's
studying the human brain as a means for
understanding how we can build
intelligent machines so in 2005 he came
to my workplace and he gave this talk
and in his talk he said something like
this let's suppose you're walking down
the street and you're thinking about
everything going on in your day you know
it's my spouse gonna pick up the kids
did I leave the oven on oh I better get
that report ready for my boss
all of a sudden though your foot sinks
right through the pavement you're really
surprised by this well why are you so
surprised because your brain made a
series of predictions your brain
predicted the exact moment your foot
would make contact with your with the
ground your brain predicted how much
resistance the ground would give you and
your brain predicted how far your knee
would be bent as you were walking and
when these predictions were violated
you're surprised so your brain must be
some sort of a prediction engine I was
absolutely fascinated by this thought
because it seems so simple and it made
so much sense and I remember thinking
you know I would love nothing more than
to go off and work on
problem but I was early in my career and
I had no experience in this area
and so I decided my career would take a
different turn so I ended up joining
Netflix right around the time that
streaming started to become popular and
I focused on problems of building
distributed systems and scaling them and
eventually I turned my attention toward
building teams and that's when I had
that realization wait a minute I'm not
the only one that's making it up as I go
along and so last year my colleague and
I got together over this common interest
in machine learning and artificial
intelligence and we decided to form a
company which we call the order of
magnitude and the problem that we're
trying to solve is building machines
that are capable of intelligent behavior
and I hope that by the end of this talk
you'll know exactly what I mean by that
so over the last 18 months we've had to
explore some pretty fundamental
questions starting with what makes us
intelligent and from there we had to
break down the major components of
intelligence perception and action how
do these things work how does learning
work and one when we took a step back we
had a very different perspective from
where we started on artificial
intelligence and data in general so I
like to share with you what we've
learned along the way and how that's
changed our thinking about artificial
intelligence and data so I'll warn you
that I'm going to give you a lot of
background context so that the points
I'm going to make about data will
actually make sense so please bear with
me as I go through these so the first
question what actually makes us
intelligent and to find the answer we
had to go back to the beginning of time
the Big Bang cosmologists Sean Carroll
puts it like this he says the origin of
the asymmetry of time that we experience
can be traced all the way back to the
orderly
so the universe near the Big Bang Wow so
what is he talking about there he's
referring to the second law of
thermodynamics which states that the
universe becomes increasingly disorderly
with time if you're gonna make an omelet
and you crack your egg the egg becomes
scrambled and it doesn't become the egg
again it becomes more and more
disorderly another word for this would
be entropy the entropy of the universe
increases with time but we have this
paradox on our hands because I'm
standing before you and what appears to
be an orderly state that I'm maintaining
and you're all sitting in front of me
facing relatively the same direction
paying attention to this talk I find
that rather curious professor Carl
ristin puts it like this he says the
defining characteristic of biological
systems is that they maintain their
States and form in the face of a
constantly changing environment so Carl
Freeston is a neuroscientist and he's
done some groundbreaking work on brain
and imaging but over the past few years
he's turned his attention toward
developing a mathematical basis for
intelligence which he calls a free
energy principle so I'd like to share
with you the idea behind the free energy
principle because it's been the basis
for a lot of our work let's go back to
the second law of thermodynamics so if
I'm an intelligent agent I'm gonna be in
a very small set of possible states for
example I need to maintain a very
specific body temperature 37 degrees
Celsius I need to maintain a certain
blood glucose level say 140 milligrams
per deciliter or less I need to maintain
a certain blood oxygen content these are
very very specific states out of all the
possible states I need to make be inside
of this box
if I decide I'm gonna jump in the ocean
and live out in the ocean my body
temperature is going to drop outside of
these acceptable levels and I won't last
very long so I need to essentially make
these very specific States be high
probability so let's break this down if
I maintain these low entropy states that
are high probability I'm not gonna be at
all surprised by this and I will survive
if I go out here I'm gonna be in this
bigger high entropy bubble and I'm gonna
be highly surprised because each of
these possible states is much lower
probability because there's more of them
I should point out that surprise really
is in the eye of the beholder because if
I were a fish living in the ocean would
be perfectly acceptable and unsurprising
and living on land would be very
surprising so is this all there is can
we say that intelligent agents minimise
their surprise is that the objective
function for intelligence well the
answer is yes but there's a catch
and the catch is that surprise cannot be
measured directly why is that well
unfortunately we cannot observe the
world directly what we have is a whole
bunch of asynchronous data streams
coming through our senses they're noisy
and imperfect they're not an exact model
of the world and so all we have left to
do is take these sensory data streams
that we're getting and construct a model
of the world that we hope is accurate
and represents the true world but all is
not lost because we have a quantity that
Carl frisson has introduced called free
energy and if you take nothing else away
from the slide take away that free
energy is an upper bound for surprise
and that if we minimize free energy we
actually are in turn minimizing our
surprise
does anybody here know anything about
Bayesian inference sorta kind of sort of
okay well if you know a little bit about
it essentially this first term don't
worry if you don't understand this by
the way because it's not a prerequisite
this first term essentially is surprise
it's the negative log probability of
Bayesian model evidence so maximizing
your Bayesian model evidence is
equivalent to minimizing surprise and
this term really shows the error between
your model of the world and the true
world so as long as we make sure that
our sensory information that's coming in
is unsurprising is matches our model of
the world then we actually maintain this
low entropy state so the free energy
principle states that intelligent
systems minimize free energy which is an
upper bound for surprise okay wow that
was very philosophical so how does this
actually work how do we minimize free
energy let's look a little bit more
closely at our model of the world so our
model of the world actually consists of
beliefs and beliefs are used to form
predictions for example going back to my
story earlier you're walking down the
street you have a set of beliefs about
moving your body about walking you have
a set of beliefs about physics and
gravity right if I drop this remote it's
gonna fall to the ground and you weren't
born with these beliefs you learned them
they're encoded within the synaptic
connections of your brain and so as I'm
walking down the street the first way
I'm going to minimize my free energy or
my surprise is I'm gonna use my beliefs
about walking to predict my myself
moving and predict the way that the
ground feels under my feet and I'm not
gonna be surprised when I feel the
ground under my feet now I wasn't
passively doing this I was actively
doing this I had to actually change the
world in order to walk across the street
because my
actions my physical body are part of the
hidden state of the world and so I also
need to change the world in order to
make my predictions come true and then
the third way that we can minimize free
energy is forming beliefs so what if I'm
walking down the street and then all of
a sudden the ground is squishy and my
feet are sinking through the ground and
I keep being surprised cuz it looks like
a solid sidewalk the ground is squishy
in the ground is squishy well that's odd
maybe my beliefs about the ground are
wrong and I need to incorporate the fact
that sidewalks are squishy into my
beliefs so these three things actually
correspond to the three components of
intelligence forming predictions is
perception changing the world is action
and forming beliefs is learning and so
these three things are all side effects
of minimizing free energy minimizing
more surprise so in the next three
sections I'm going to be going through
each of these in turn so how does
perception work I'm going to start with
a little demonstration I'm going to show
you all an image and I want you to raise
your hand as soon as you identify
something in the image please don't
shout out what it is that you see
alright here we go okay so I see a lot
of people that haven't raised a hand yet
okay good okay so now raise your hand if
you didn't see anything but just looks
like a bunch of dots okay let me give
you a little hint now that do you see
anything now that you didn't see before
that didn't help apparently okay one
person okay out of curiosity did any of
you see anything other than a dog or
specifically a Dalmatian no okay so
everybody saw the same thing when you
did see something so I want to point out
two things about this experiment
so first of all you did not despite what
you might have thought use just your
vision to see what was in this image to
perceive what was in this image you
actually used another major sense you
are actively sampling this image so your
actions may have been very subtle you
may have slightly turned your head you
may have moved your eyes around you
needed to take that stream of data about
the movements of your body this is
called proprioception and combine that
with the visual inputs that you are
getting through your retinas if you've
ever seen a video taken by somebody with
a camera on their head while they're
running you would have seen a very shaky
video and yet when you're running and
looking around it's a very stable image
that's because you're putting together
the fact that you were moving your body
along with the visual input and your
brain was forming that stable model of
the world so even though it appeared
that you are just sitting there not
doing anything you were actually
actively sampling this image and the
other thing I want to point out about
this experiment is that it took time to
perceive what was in this image I didn't
see you all raise your hand at the exact
same moment and you had to take multiple
samples over time so that you can
leverage your beliefs about dogs or
Dalmatians to form this prediction let's
look a little bit more closely at the
model itself right I just have this
belief box in a prediction box but what
does that actually entail this model
that you've constructed is hierarchical
if you've if you're familiar with deep
learning at all this will look pretty
familiar so let me explain why should it
be hierarchical well as I mentioned you
have all these different senses with
very different information coming in
right you got photons hitting your
retinas you've got electrical signals
coming through your nervous system
you've got sound waves and you need to
put all these together into a coherent
and so not only do you need to associate
these but you need to abstract from this
very low level say visual information
into this abstract idea of a Dalmatian
and you can't do that in one step you
need to abstract several times so if we
call this level zero I'm gonna say
somewhere up in this hierarchy at level
n you've formed a prediction that what
you are seeing was a Dalmatian how do we
form this prediction though there's
really three steps involved the first
step is you need to form hypotheses
about what you're seeing given the
evidence that's coming in through your
senses the second step is you need to
select the best hypotheses because
you'll get some that are perhaps
conflicting and then you need to explain
the evidence that you're seeing and as
soon as you can explain that evidence
you perceive so let's go through to
these steps in order to perform these
steps we actually need to pass messages
throughout our hierarchy so forming
hypotheses involves a message of
evidence that's coming from your senses
this is really just your raw sensory
readings coming forward and in order to
select the best hypotheses we have this
message called the inhibition which I'll
explain all of these don't worry and you
can use these to sort of disambiguate
and then the third one is once you've
selected the hypotheses about what it is
that you're seeing you then say AHA this
is the cause of this evidence and so you
send a message back down the hierarchy
so let's look at how we form hypotheses
if we look at an individual node of this
hierarchy what does it represent it
represents a belief and a belief is
nothing more than a learned coincidence
so you have you have some beliefs about
dalmatians or dogs perhaps you'd
frequently seen evidence of these lower
level features always happening
together which allows you to form this
belief so you might have C floppy ears
four legs and spotted fur happening at
about the same time you're gonna form
these connections I'm not going to talk
about how these connections got here
right now I'll talk about that when we
discuss learning but suffice it to say
let's assume you already have this
belief how do we form a hypothesis that
this is in fact what we're seeing
oops so we do this by passing a message
evidence forward so these things are
lower level features and they're saying
uh I have evidence of these three things
and that allows you to formulate this
hypothesis so the next step is we need
to select the best hypotheses because
you know about other four-legged animals
that also have spotted fur maybe you've
seen cows before with spots or bunny
rabbits or horses and so what's gonna
happen is that some of these features
are shared and they're gonna both form
competing hypotheses because the world
is full of ambiguity and you need to
select which one of these best matches
the evidence and so the process by which
we do that really is to say these two
guys on the same level of the hierarchy
pick the one with the most evidence or
the most inputs coming from below so
dalmatian has more features to match
than cow so we're gonna decide it was a
donation once the donation wins this
competition it gets to feed its
information up and down hierarchy and
the cow does not so now that we've
selected we're seeing a donation we need
to now explain what we're seeing down
the hierarchy so I'm introducing some
new information here there's some state
that we've stored in this belief and
that's really the prediction that you're
making this is kind of your short-term
model of what you're seeing
right now in the world so I'm I'm
predicting everything going on in this
room right now so if assuming that
you've selected a hypothesis that is
predicted what you're gonna do is send
back a message saying well I've inferred
that the dalmatian is the cause of this
evidence and in turn when this
explanation goes down the hierarchy you
can actually form new predictions now
that we've seen the three steps though
let's review and look at that all in one
slide so from the context of a belief
node the first step is that it gets some
evidence and and it's gonna compare that
evidence against the prediction is there
a match there yes or no if there is a
match then you can say AHA this belief
explains the evidence it's the inferred
cause but if there is no match what you
do is you forward the message up the
hierarchy say I'm sorry I can't explain
what I'm seeing I need some other higher
level concept or belief to explain this
and so at some point in the future there
may be an explanation coming down which
in turn forms this prediction now
meanwhile let's say you're the cow and
you have weaker evidence the donation
may in fact inhibit you this is sort of
this lateral message coming in and so
the inhibition has the effect of
removing this prediction saying no it's
not a cow I've already seen this
dalmatian and also please stop
forwarding messages up and down the
hierarchy so we have this in the context
of a belief but what is what does it
mean in the context of the entire
hierarchy so what happens is you may
start with some prediction up here
that's very compact and very high level
and you start moving your predictions
down this hierarchy until you get this
very high-dimensional parallel
representation this is a fundamental
difference between the way computers
work and the way humans work because we
have this hierarchical memory structure
we have no conflict in perceiving I can
perceive all of you at once I can
perceive the screen the walls there's
no there's no conflict there and I'm not
surprised because and I don't need to be
conscious of these things because all of
these are predicted at a very low level
of my hierarchy so that allows many
tasks to become subconscious because I
don't need to if I call this my
prefrontal cortex up here I don't need
to bother my conscious brain or my my
attention with this kind of information
now how does this relate back to the
free energy principle that I said and I
said earlier perception is a side effect
of free energy minimization well in fact
that message that I was talking about
that evidence message that gets sent
forward over the long run if you average
that out over time that is free energy
and really in essence what we're sending
forward is only prediction error because
we only propagate that evidence message
forward when our predictions don't match
what the evidence was and so if we can
fully explain the evidence especially
very low in the hierarchy then
essentially over the long run we are
minimizing free energy and I have used
the word explanation and prediction
somewhat interchangeably they are
basically the same thing the only real
difference is that a prediction is just
an explanation of future evidence it's
evidence that you expect to come soon
okay that was a lot so we talked about
perception now what are all the various
inner workings of action how does this
work well I'm not going to tell you that
because I already did for the action is
really just a special case of perception
if you understand how we form these
hierarchical predictions then you
understand how action works so if you
form this high level prediction and it
happens to have a connection all the way
down to the motor area of your cortex
which we're calling
deception then you can cause action to
happen that's really all it is let's go
back to our model of the world when
you're a baby
you don't really know how to move your
body you don't know how to walk and all
you can really do is read this motor
state which is part of this hidden state
of the world that you cannot directly
observe so you need to read three years
proprioceptive sense what your body is
actually doing and in turn you need to
form beliefs about your own actions and
about movement which then in turn
eventually allow you to form predictions
about action and a prediction is then
made true by your nervous system so not
speaking from the point of view of a
neuroscientist so I'm gonna gloss over a
lot of that detail but suffice it to say
let's say my arm is at 90 degrees and I
predict that it's gonna be straight
guess what that that is made true it
happens
now the predictions of your motor states
not not necessarily always made true
let's suppose I'm walking down a dark
hallway and I want my arm to stretch out
but what happens when I read my next
proprioceptive input is that my arm is
still bent and so I get some surprise
some error signal coming through and I
have to change my predictions to match
the fact that oh there's a wall here
it's preventing my arm from moving so
that's how action works at a low level
how do we form high level goals well he
probably would guess that we're using
this hierarchical abstraction to do so
over time I have formed a belief that
when I'm hungry I'm going to eat so this
is a high level abstraction and so I get
evidence of hunger coming through my
proprioceptive sorry my interoceptive
sense and that forms this prediction
about eating and eventually we use the
same process of explaining
down the hierarchy that eventually forms
as proprioceptive prediction that's
going to cause me to go get food so the
action plan is going to unfold over time
right it's not happening all at the same
instant so at the top of my hierarchy
say my my attention my prefrontal cortex
all I'm really thinking is oh I want to
get out of my chair and get food from
the fridge and eat and that's all I'm
really thinking about but oh but this
unfolds into these lower-level
predictions about my movements until
eventually I am down to the level of my
muscle movements right these things
don't all happen at once because only
one thing really has an affordance at a
given time if I'm here sitting in my
office chair there's no way I can open
the fridge because the fridge is not
there so all I can really do at that
point is stand up so this action plan
really unfolds over time going back to
how this relates to free energy action
will minimize free energy by making the
world match your predictions action is
really your perception of future motor
states you perceive where you're gonna
be before you get there and it does take
time so you need to be able to learn
these causes these temporal transitions
from one action to another so how does
learning work how did we form these
beliefs in the first place well the
prediction error of our model is what
triggers learning right when there is
something that you didn't quite predict
it means that you need to alter your
beliefs so that you can better predict
in the future
you take these evidence messages coming
up and use that to modify your beliefs
remember that minimizing for energy is
not a momentary thing it's a long-term
endeavor and so incorporating new
evidence into your beliefs has long-term
you so that you can better predict in
the future in our brains this is
implemented as heavy and learning
anybody ever heard of heavy and learning
okay has anybody ever heard the term
fire together wire together
no yes a couple okay so essentially what
it means
your brain is consists of billions of
neurons and they're firing at any given
time and if two neurons frequently fire
at the same time they're coincident
they're happening around the same time
then they form a connection and we can
model this and software by saying
whenever the evidence comes in we we
form or strengthen a connection between
these two nodes because we'll these
features indicate that there's a
Dalmatian here on the other hand if you
see some evidence that's not there you
want to weaken those connections so that
eventually what you get is a really good
average over time of the evidence that
you're seeing so relating this back to
free energy learning alters your beliefs
and it will allow you to reduce your
uncertainty about the world in the long
run now learning can actually be fast or
slow because if you have yet to form
beliefs and you're forming new beliefs
well all you have are the samples of
evidence that you're getting now so you
can quickly form new beliefs on the
other hand if you have these beliefs
that are very strong let's say you're
very much into dogs and breeding dogs
you have a lot of very strong beliefs
about dogs it's gonna take a lot longer
to change those beliefs a lot more
evidence and that really explains why
children learn much more rapidly than
adults okay that was a lot and we talked
about intelligence in general but let's
get back to how does that relate to
computers machines data so if let's say
we have an intelligent machine that can
minimize for energy and interact with
the world does that mean that we don't
need today's computers anymore
well they cease to
does anybody know who that guy is
anybody seen that guy before
couple people okay he's a fictional
character he is his name is Commander
data and he serves aboard the USS
Enterprise and so if anybody's heard of
Star Trek this is one of the Star Trek
series he's an artificial life-form and
modeled after human beings and when I
when I when I I'll I'm a big fan of Star
Trek so when I watch this show I think
it rather odd that an Android a machine
would be interacting with a computer by
tapping on the computer screen by
talking to the computer and by reading
the screen I thought well well he is a
computer you know why do I need to why
does he need to interact with a computer
like a human would well after exploring
these questions it actually makes a lot
more sense now because this guy
commander data has to form a model of
the world just as we humans do and he
happens to be endowed with senses that
are modeled after human senses right eye
sight touch hearing etc and so it would
only make sense that he interacts with a
computer just in the way that a human
being would when it when it comes down
to it these intelligent machines are not
going to be particularly good at the
type of operations that today's
computers excel at don't ask an
intelligent machine to add to
floating-point numbers right I challenge
you all to do that in your head add a
you know 10 decimal digit number in your
head you know in nanoseconds these
computers will be much better than
intelligent machines and executing
deterministic code and there will be
much better at intelligent machines than
storing and recalling data right we
humans are terrible at remembering data
so I imagine in the future that
intelligent machines will actually use
the computer architecture of today as an
augmentation
there's no reason to think that they
wouldn't be able to use to query
databases just as humans do today to
augment their capability so what will
change I've talked about intelligent
computing I've said the word intelligent
machines several times what do I
actually mean by that why I define an
intelligent machine as one that has an
environment that interacts with a set of
sensors and a set of actuators and the
intelligent machine will learn through
its experience and apply that learning
to minimize free energy ok the free
energy part is a little bit abstract but
guess what it's a design choice that we
now have how do we define free energy
how do we use that to accomplish our
goals I'll give you a little bit of an
example later on so bear with me on that
one who's gonna be the judge who's gonna
decide whether these machines are
actually intelligent or not well guess
what if you can build a machine that's
going to judge intelligence then you've
a solved the problem of intelligence so
it's left to us humans is this going to
be like the Turing test where we try and
convince human beings that they're
talking to a human rather than the
computer I think a more realistic test
to do in the short run will be based on
a let's say rodent or rat intelligence
test that might be performed in some
scientific lab right can the Machine
perform a variety of tasks and
demonstrate that it has learned from its
environment let's say navigating a maze
for example and what a human being
judged that to be intelligent behavior
I'm gonna do a quick time check here 13
ok so in the future what might machines
be capable of if you have a machine that
has an environment a sensor set of
sensors instead of actuators what can it
do
that we can't do today machines will be
able to go beyond human timescales for
one thing if you think about it
a machine does not constrain by our
human biology the lifespan of a machine
can be much longer or perhaps much
shorter than a human being
we're also limited in terms of how we
perceive time we have a certain sampling
frequency at which we're sampling in the
environment which leads to a certain
perception of time well what if you had
a machine that would make one
observation every decade that machine
will perceive time very differently than
we do and will be able to see
regularities that are completely hidden
to us so maybe these machines will be
able to observe what are the long-term
consequences of the decisions that we
humans are making you could also have a
machine that compresses time in a way by
taking an observation every nano second
or microsecond this machine would
develop superhuman reflexes if you've
ever seen time-lapse photography where
maybe an image is taken every 30 minutes
or an hour you may have seen some
patterns in that photography that you
didn't see just look just sitting there
watching in real time so I expect many
different different many new temporal
patterns will emerge if we have machines
that can sample the world at these
different frequencies what else these
machines will also be able to explore
new sensory dimensions in a way that
humans haven't been able to do we humans
have always been explorers sensory
explorers ever since we picked up a tool
ever since we put a pen to paper
we're awed menteng our capabilities and
our senses but what we can't really do
is live in a virtual world so if you
have a machine that lives entirely on
the internet it can sense and react to
internet traffic machine can also live
into inside of a virtual
old as a video game or VR character and
then the machines can live on an
entirely different scale on a
microscopic scale or perhaps a global
scale so imagine one of these machines
that has weather patterns seismic
activity financial markets as its senses
it's gonna see some very different
things than what humans can do these
machines will also be able to do boring
work for us right they don't run out of
attention they don't get tired and so if
you're an astronomer maybe you're gonna
have one of these machines watch the sky
for you
look for interesting phenomenon if
you're in the security perhaps you're
gonna have one of these machines look
out for intruders
because guess what intruders are very
surprising so that would be a great use
case if you're a historian perhaps
you're gonna have one of these machines
read centuries of literature and
reconstruct what the world might have
looked like at some point in history the
machines will also be able to develop
communication and I think that will
emerge as a direct result of minimizing
free energy in the context of
interacting with human beings or other
machines so in cases where predicting
fellow agents including humans is a
value machines will ultimately develop
communication now developing language is
a tricky business in order to have
language you need to have a sufficiently
rich and detailed model of the world
this is an entirely different thing than
what we call natural language processing
today which largely involves some
statistical analysis of text so machines
ultimately will not develop true
language I think until they can form
this very rich model of the world which
will require lots of horsepower you know
billions and billions of the leaf
capacity because that's what we humans
have so if we have machines that can do
all this amazing stuff finally what
you're here for
how does data need to change well first
of all we need to start thinking about
data as being in the present these
machines are actively sampling the world
they act in the presence they can't act
in the past and so they need to take
sensory samples that may be that are
completely parallel an asynchronous from
their senses so that they can learn this
coherence and time data also will need
to inspire action and this gets back to
the idea that sensory input is free
energy and it's a quantity that we
designers we engineers can define to
suit the goals that we're after so
imagine you want a machine to maintain a
specific temperature range one way you
might do that is to inject a lot of free
energy when the machine is either too
hot or too cold and in that so we can't
directly control the actions in the
machine but we can inspire action using
this free energy quantity data can also
be noisy now because the world
inherently is noisy and our senses are
noisy and that there's no problem with
understanding regularities in the face
of noise so we don't need to worry too
much about cleaning up our data when the
noise actually exists data doesn't need
to be human readable anymore either you
think about it we put a lot of effort
into making it easy for humans to
understand data translating it into
prose visualizing it but what if you had
a machine that had some sensors and
actuators that interface directly with
some API there's no need to translate
that into say visual data or language
before the machine can understand it we
don't need to label data anymore either
in machine learning there's a lot of
effort put forth in constructing
canonical laid
datasets that involves a lot of human
effort what if you had a machine that
could instead learn through experience
so it's going to be up to us human
beings rather than creating these
datasets to create learning experiences
and by the way learning is happening
online with these intelligent machines
they're constantly updating their
beliefs and so we don't have to worry
about a separate training period like
you would with a traditional machine
learning problem dataflow will change
when it comes to processing today data
flows say from disk to memory to CPU to
memory maybe over the network in this
case for these machines the data will
flow through beliefs and a belief is
really a single unit of memory and
processing so the processing power is
really distributed across this hierarchy
so we'll need to think about what kind
of hardware architecture do we need to
create to enable this parallel
hierarchical processing well think about
scale differently as well how do we
scale intelligence rather than how do we
scale CPUs or machines how do you add
belief capacity so that the machine
becomes more intelligent so you imagine
starting out maybe you're gonna occur
we're gonna start out creating machines
that have the intelligence of a bug
maybe a small rodent they're not going
to be as smart as humans to begin with
we can also crowdsource as another
alternative instead of thinking in terms
of horizontal scaling where you're
adding more machines perhaps you're
going to take one machine that has been
trained and clone its beliefs so that
then these beliefs can start diverging
with different experiences and in the
way you can crowdsource so with all of
the this fun yeah ok so what are all the
challenges
so the first one challenge is
non-determinism the results that we're
getting from these machines are not
reproducible the the environment is full
of noise which always changes every time
the machine acts it's changing the world
and every every interaction affects its
belief so in terms of a safety critical
environment this might not be the best
way to go in terms of gaming and
entertainment this could be great we
also have this problem with lack of
transparency we won't actually know why
the machine acted the way it did we
can't set a breakpoint and say well it
was line 3:23 and that's why the machine
acting the way it did right so we may be
by surprised by the behavior we'll need
to think about what kind of telemetry we
should add how do we do testing we can't
write deterministic test perhaps we need
to create laboratory environments in
which to understand the behavior of
these machines and of course there's a
lot of concern in the media about how
low artificial intelligence affect
humanity does this pose a threat to
humankind and it's really smart guys
Bill Gates Elon Musk Stephen Hawking and
others have said hey we think that this
is gonna be a big problem
now I'll point out that this is not the
first time in history that some really
smart folks have said a new technology
is going to be a big problem plato was
very concerned about the advent of
writing and how that would infect the
way that we think he couldn't have
anticipated the advances in society that
have come because of writing that said
though we shouldn't ignore these
concerns we need to figure out how can
we instill an unshakable belief that
humans will not be harmed one way to do
that would be to say any any time the
Machine comes close to harming a human
there's this overabundance of free
energy which the machine will
instinctively avoid I would say we're
still pretty far off from Arnold
Schwarzenegger coming from the future
and telling
that mankind is being destroyed by
machines we better stop it in the near
term I think a goal that we could reach
would be to build something that's as
smart as a small rodent and imagine what
you could do with the whole army of
these guys so I really appreciate you
paying attention today and coming to my
talk if you have your curiosity's been
piqued Carl Freeston has written written
many papers and one to start with maybe
his free energy review principal paper
all the links to these are all in the
slides if you want to look at some code
I did do a toy implementation of the
learning piece in Scala this was
inspired by the new pic project which is
an open-source project by Jeff Hawkins
and his team so thank you very much
and don't forget to rate so
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>