<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Reactive Systems: 21st Architecture for 21st Century Systems • Dave Farley | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Reactive Systems: 21st Architecture for 21st Century Systems • Dave Farley - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Reactive Systems: 21st Architecture for 21st Century Systems • Dave Farley</b></h2><h5 class="post__date">2015-10-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RuHkNGrwD5o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I don't usually introduce myself or my
work very much before going straight
into my presentations in this case I
feel that I probably should slightly
need to give you a little bit of
background of where some of this stuff
comes from so first of all I have a
confession to make I'm not a functional
programmer I'm I'm an I'm an old-school
programmer I do object orientation no no
no I like lambdas and I do some of those
sorts of things but I'm not a functional
programmer so I'm not going to talk
about algebra I'm not going to talk
about monads I'm not going to be talking
about those sorts of things
I think this separate concerns when
we're talking about this stuff and I
think often when we talk about reactive
programming the concerns get conflated
the reason that I think that I've got
something to say on this topic as well
as helping to edit the reactive
manifesto and making some contributions
is as I worked on her on one of those
projects that kind of comes along so
once in your career and this project was
to build a low latency high frequency
trading exchange from blank sheet of
paper at the time when we started
writing this we didn't know how to do it
we hadn't got a clue and so we did lots
of things in order to try and learn what
it was that we needed to do and part of
what we evolved through our experimental
approach was I think what you described
as a micro service reactive architecture
but blisteringly high performance and I
want to describe some of the reasons why
that is and some of the reasons how it
works and I'm going to sort of talk a
reasonably high level about some of
these stuff so there's not a lot there
is no code in this presentation it's not
detailed tich it's kind of detailed kind
of at the computer science he level
maybe but but there's not there's no
math so either I can think of so so part
of the reason why these stuff matters is
because our world is changing and people
keep saying this to you at this
conference I think but it's but it's
true
if you look at you know where we were
just ten years ago the typical system
was tens of servers maybe it had seconds
of response time and hours for offline
maintenance and probably dealt in
gigabytes of data that was a kind of
normal sort of reasonably large
enterprise scale system in those days I
think now large applications now have
thousands of multi-core processors
milliseconds of response time or faster
100% uptime and petabytes of data that's
that's not unusual these days if you
just look at if you just look at memory
I'm not quite old enough to have
programmed ferrite core memory but if
but but but I used to have one of these
in my wife threw it away I was really I
was really disappointed when she did but
but this this is a ferrite core memory
unit each of these each of these little
magnetic rings is about three
millimeters in diameter and each of
those represents a bit so so that block
of things there is eight bytes okay this
is a an SD card micro SD card that's
eight gigabytes so that's kind of where
we come so this is a bit longer than ten
years ago this is kind of 1970s
technology these sorts things are in
using you surround around those sorts of
time but we've come a very long way this
isn't this is another one this is just
ten years so this one is 128 megabytes
this one is 128 gigabytes the game is
changing and the tag line for the
reactive manifesto is 21st century
problems and not best solved with 21st
20th century architectures if we're
building into your architecture is
backed by relational database that's not
a really scalable option it's not as as
Yanis was saying in his in his
presentation that kicked off this track
that's not how you build resilient
systems it's now how you build scalable
systems it's not how you build systems
that you can deploy to all over the time
it's not how you build systems that can
be elastic and that can grow and
can shrink so we came up with I was
involved in the rewrite of the agile
manifesto many of the ideas were in
place before Lynne book we came up with
a way of talking about it and this is
part of what we were talking about so if
we want our system to be responsive we
want them to be able to react to out to
our users efficiently and quickly and in
order to do that they need to be
resilient they need to be robust in the
face of failure and continue delivering
services if we want them to be resilient
we also need them to be elastically able
to stretch and move and and grow and
shrink to meet demand and we need met
them to be message driven to support all
of those things that's the underlying
substrate that has allows us to do these
other things and I want to describe a
little bit about why I think that's the
case so first reactive systems so we
spot a reactive system is responsive
that means it responds in a timely
manner this is the cornerstone of
reusability this is this is really what
people mean when they say often when
they say it's unusable you can have you
can have poor usability in terms of a
mental model of the system underneath
but if it reacts well it will get a
better response than something that's
got good usability and reacts badly it's
also quick to detect problems we want to
be able to understand when something's
going wrong and and be in a position to
do something about that we need them to
be resilient we want them to be
responsive in the face of failure we've
got the obligatory microscope the Monty
Python illusion here we want them to be
responsive in the in the face of failure
resilience depends on on replication
containment and isolation and delegation
in order to make sure that we're we're
able to contain failures and you know
gracefully degra get degrade the
behavior of our system in order to meet
demand and to be responsive elasticity
is important and it's kind of growing
like growingly important in in the the
world of the cloud where you know if
you're using Amazon ec2 and you just
kind of provision all your servers and
you just leave them all running you can
get a very big bill at the end of the
month you want them to scale down as
well as off you want you want to have
the right number of the right amount of
compute to service the needs of your
system
and to do that we need to have a
decentralized architecture with no
contention points and we need to be able
to push behavior out and shard it in
different ways an asynchronous message
passing is is the foundation of this
approach of all of these properties and
that's what gives us the loose coupling
the isolation and location transparency
that allows us to do these other things
if you go away from this presentation
with one idea in your head I want you to
go away with the idea I want you to go
away with two ideas back in your head
nod the first one is that asynchronous
messaging is the answer to many of our
problems in computing and the second one
is it's not as scary as it sounds so so
what are the properties of a reactive
system so they're flexible we can
compose them in different ways they're
loosely coupled there they're not
tightly bound to one another so parts of
the system can evolve at different rates
to other parts of the system they're
scalable we can increase provision of
service by adding new compute compute
nodes new certainly new new versions of
the service they're easier to develop
and I think that you might doubt me on
that one but I'm hoping that by the end
of the presentation you won't I'm hoping
I'm going to demonstrate some of the
reasons why I believe that to be the
true the truth they're more tolerant of
failure because we can they're
asynchronous and so we not cut boarding
time so something can go down and we can
respond to it later when it comes back
up as long as you get the messages and
all that kind of stuff they respond to
failure gracefully and they're
responsive to users though that's that's
one of those four principles that we're
aiming for the weird thing about this is
is it's kind of fractal in architecture
this these ideas operate at all scales
I was recently attending a course on
lock-free low latency programming run by
Martyn Thompson my friend that we were
talking about earlier
and one of the things that he that he
was describing was the way in which
modern processes inside them are message
driven asynchronous computing units each
of the cores are connected by a bus and
they pass messages between between one
another to get the memory into cache so
at the level of the silicon on which our
code operates the way in which the code
code is decomposed into parallel
execution paths by the by the processor
that's a reactive system it's a it's a
message driven asynchronous system but
it also scales to the largest this is
the way that Netflix works and Facebook
scales and those sorts of things are
built this way because this is what you
need to do when you've got the sorts of
levels of demand that we've been talking
about the levels of data processing and
CPU and the large systems are composed
of these smaller reactive components
well that doesn't mean that we've got to
be doing very weird programming styles
at every level of granularity and I'll
talk more about that later yes it's one
of the things where I think I think the
conversation gets confused when we
confuse the conversation about reactive
systems and functional programming there
is some crossover because we're both
talking about the use of often talking
about the use of a synchrony when you're
talking about reactive functional
architectures and reactive systems but
they're not necessarily the same thing
you can do one you can do one without
the other so I'm gonna go through
various pictures like this and just try
and decompose this a bit so first I want
to talk about synchronous messaging now
if you look at the world I think it's
pretty much hard to refute that the
world's pretty much asynchronous and we
programmers have kind of layered
synchronous thinking on top of the world
because it's easier for us to reason
about it so it's easy it's much easier
for us to think about I want I want to
add add to my account balance so I'm
going to tell you what how much I want
to add and then it's going to tell me
that it's added in that's easy to
understand it's simple and my program
stops and waits for that response to
come back but there are problems with
that model so let's imagine we've got
these two components and component a is
invoked with some behavior and it
delegates part of that behavior to
component B so if we're talking this
synchronous model now then there are a
number of places where this conversation
can go wrong so there might be a bug in
component a there might be a problem
establishing the connection to the
communication channel to community to
component B we might get a loss in
transmission as the message goes between
components a in component B there might
have been a problem with component B
connecting to the communication channel
at its end there might be a bug in
component B and we've got the same set
of problems on the way back to now in
any distributed system we have all of
these problems so if we're making a
synchronous call we have all of these
problems now there's a difficulty with
this with with synchronicity because
from the perspective of component a it
can only know well it can only know if
there's a failure of its own or if it
can't establish a connection everything
else it can't tell the difference
everything if it doesn't get a response
it doesn't know where the component B
was broken with the message was lost and
so it's got all of these error cases to
cope with worse than that I mean in the
same situation and component a is doing
some processing you delegates the
component B it's now got to weight of a
component B to finish before it can do
anymore processing I only have two
component these done can components they
can continue processing there's the kind
of definition of a synchronous call
right the way that we get so we're we're
building multi-user systems what we the
way that we get around that is that we
start thinking well we kind of it block
on just one thread so we'll have to go
multi-threaded right so now we've got
lots of problems so now we're added
complexity to our implementation of
component a we've got we've got to worry
about all the problems of
multi-threading contention
avoiding shared state concurrent
programming is one of the different most
difficult things that we do in our in
our industry and we have to do all of
that just to get around the problem of
because one of these threads is waiting
for an answer back from component B
synchronous communication increases the
coupling in both location and time
between the components it makes it more
difficult for us to scale and it makes
us more exposed to more failure cases
let's do the same experiment and think
about what it looks like with the same
thought experiments and think about what
it looks like with asynchronous
messaging so now we've got the same
situation there's some behavior that's
been asynchronously invoked on component
a and a is going to do I'm sorry I'm
getting ahead of myself this is still a
synchronous case so this is a
synchronous case where component B is
now delegating to something else in this
case it's talking to a database and
we've got additional failure modes which
are also hidden from component saying
we've just compounded the problem in
terms of the failures that we got to
express back and get back to component a
so components a is even more at risk now
worse than that if there was a failure
in the channel on the way back what
states the data ring we don't know it's
indeterminate and so we've got a code
for all of those error cases if that's
if that's if that's our world so let's
talk about asynchronous now say
asynchronous case now so component a is
invoked it delegates a an asynchronous
call to component B it's done it can
carry on processing messages it can
process a new incoming call or it can
wait for a response it's not got
anything it's not got anything else so
where can this for a component B
sometimes later sends a message back to
component a so where can this break it
can break in all of the same places
except the only two that matter are
those two and those are the two that
components they can know about it can
know whether it's got a connection to
the to the communications channel it can
know whether it's got a bug itself the
rest as long as it as long as the
messaging service whatever the
communication protocol whatever you're
using will deliver the message
eventually
it doesn't care could he send the
message it's gonna get there eventually
it doesn't matter win because it's
asynchronous it's not blocked it's not
waiting for anything else so all of
those other failure conditions component
a doesn't have to worry about we don't
have to code for those error cases we
don't have to worry about whether the
databases in there in an invalid state
or not our code gets simpler it also
means it can be single threaded so it
gets even simpler we can write these
things efficiently that just process
messages they just flow through the
messages flow through our system we take
an input we process it we generate an
output and we move on to the next thing
whether that's a new input or a response
from from from an output they're all
just messages coming in and we all just
process those messages on a single
thread this goes blisteringly fast this
is aligned with the way in which
processes are architected these days
this this means that your caches are
likely to be more coherent it means that
it means that you're not going to get
contention you're not you're never going
to get shared state all of these things
if you do this efficiently so let's talk
a more concrete example because I know
these abstract things can be hard to
work out and forgive me for being a bit
cheesy but I'm gonna buy a copy of my
book so let's imagine that we've got a
book store and somebody places an order
for the book continuous delivery okay in
the synchronous case and we're going to
need to go to the inventory to to
reserve that copy of continuous
deliveries is stock control kind of ID
so in this case in a synchronous case at
the point at which the order is place
that we've got to stop that thread and
we've just got to wait until the books
reserved what if it's out of stock what
if it's what if the system's down what
if it's never heard of that book all of
those cases you've got to cope with if
in this synchronous case somehow
now it's imagine the asynchronous
version of that same conversation so we
can order continuous delivery and we're
going to ask for the inventory to
reserve us a copy sometime later we will
get a message back saying that the copy
is being ordered and we can pass that
message back up
to the user ultimately to say that the
books been ordered this kind of turns
into if you imagine the code in these in
these things what you end up with is
kind of some some relatively
straightforward state machines that just
manage the state through the flow of
messages as the conversation goes on
what I like about this too is that the
implementation of these things tend to
start to look like that ideal kind of
pure domain model I'm a big fan of
domain driven design and this is the
closest that I've ever got to really
implementing that software simulation of
your problem domain inside each of these
services which is very nice to reason
about easy to test all of those good
properties so let's imagine let's just
walk through this case once more so now
we're placing an order and we got we've
got a model of a book in our domain
model and it's in the state of reserving
because we've sent the reserved message
maybe that's down maybe it's broken
maybe it's out of stock we don't care
we're in we're in a valid state and we
don't nothing more to do right now maybe
there's a maybe there's an order for
another book in this case I'm ordering
better aerobatic which I was expecting
you to be a bit more cryptic about
giving Jonas's introduction so that's
also in the reserving state the
inventory doesn't even have to be
working it can be broken or it could be
just just slow we don't care
sometime later it could be nanoseconds
or it could be days we're going to get a
message back from the inventory and
we've changed the state of our book
saying that the books they're being
ordered this is in a consistent this is
in a consistent pick this has a
consistent view of the world it's in a
known good State it's simple code simple
message exchanges are allowing us to do
these of course the trick as people that
talk about these sorts of architectures
will always say is getting the protocols
right and getting the level of
abstractions right I want to dive just a
little bit under the covers to just kind
of reassure you so so this all sounds
nice and easy you've got these things in
memory just processing these messages
and passing on but what about when you
turn the power off what about
if something does fail how do you give
forgive the reliability now the system
that I worked on because of the very low
latency and high performance demands we
built our own message a reliable
messaging system I'm just gonna describe
a little bit about it because I think
it's useful to understand the properties
behind the sort of architectures that
I'm describing I hope that you wouldn't
have to implement this sort of stuff
yourself in order to make this work
because you ought to be able to get this
out of a box but but for now I just want
to describe what's going on so here's
our components again and component he's
fronted by a ring buffer and it's got a
ring buffer on the outside on the
outbound Channel - the ring buffer has a
cursor and and a series of slots so when
components a sends a message it's going
to populate one of the slots and it's
going to move the cursor on to the next
slot as so at some point when the thread
becomes free or whatever a separate
thread that's set independent from from
here so this is I said we avoided
concurrent programming we avoid it by
pushing some of those concerns down into
the infrastructure a little bit at some
point we decide to forward that message
on to component B that's going to be
placed into the input slot for component
B now when we design this system one of
the reasons that we did it was because
we wanted to be able to journal these
things in cluster them so he could we
could as part of the mechanism behind
this we would write write these messages
to disk and we would write into a
cluster pair before they were forwarded
to component B so this meant that we had
a durable system we had a system that
was capable of fault tolerance let's put
some more messages into the Q now we've
got a case where we've lost a message in
transmission
we've sent message for this was an
expecting message for there's an
expecting message three so it says no
that's the wrong message so I'm going to
send back an ACK saying I expected
message three so this one resets its
cursor and then reset it can be
populating more messages into the buffer
but next time it sends its going to
resend three four and five this way we
get idempotent messaging we get reliable
messaging we get the ability to cluster
and stuff as an infrastructural concern
it's outside of the business logic of
our component that's not a concern that
we have to worry about
so all of these nice properties we the
system that we built was essentially
essentially a kind of application server
we could write plain old Java object we
could write in process tests against it
and we could expose it as a service
using the these mechanisms to allow us
to communicate between the services and
give us these properties that allowed us
to build this these asynchronous
reactive systems this sort of this sort
of ability kind of allows us to decouple
that our components both in time and
space we don't care where they are we
can be broadcasting messages the
location doesn't really matter and we
don't care when they respond because
we're asynchronous that they will
respond at a time that's convenient
maybe they're down at the point at which
we send the message doesn't matter maybe
they're there and they respond in
microseconds doesn't matter we'll just
respond we'll just have a message like
any other message come in when in
response this is one of the key
properties that gives us the ability to
to make elastic systems to be able to
scale them up and scale them down we can
have observers of our system looking at
what's going on and decide this this
one's doing quite a lot of work we need
more versions of that in order to share
out the work differently
part of part of this isolation it's
important to be able to for these
components to share nothing the only
mechanism exchange of information
between them is via the messaging
channels that's again what gives us this
resilience and elasticity so let's talk
a little bit about isolation so this is
kind of a classic pattern you have two
components and you share a database and
now now we don't have that isolation now
we've got a point of failure contention
and potentially point of failure we've
got to code things in a way to make sure
that this is
efficient we can't upgrade these things
independently and so this isn't a good
pattern this isn't a good way of
building distributed systems that have
the properties that we're looking for
what we really want is that we want to
separate these concerns we want to be
able to if this thing needs a database
and that thing needs a database give
them a database but they're their own
databases they can be within the bands
of the component the service that its
business for how that works if one of
them needs an object database and the
other ones a relational database that's
fine that's not a problem so we need to
we need to firm up these boundaries and
make sure that the only means of
exchange of information is via the
messaging system if this if we're if
we're going to retain the properties of
location and tempora transparency that
we're talking about you can't isolate
stress ultimately if a systems under
stress it's going to show some where
he's going as things go wrong it's going
to it's going to come out somewhere
along the line so the system as the
whole needs to respond when it's under
is under stress it's unacceptable for a
stress stress component to fails
catastrophically and lose lose
information that's the importance of the
rest of the system so we need that those
sorts of failures to be isolated the
example that I gave of the reliable
messaging system is one means to provide
some level of that of isolation so that
you can kind of replay messages that
happened earlier the other points that's
kind of it surprised me the first time I
learned this but cues represent an
unstable unstable state and I'm going to
show that in a moment so we need to work
we need we need the idea of back
pressure really to to resolve this so
let's first look at the queues so let's
imagine we've got components a and
component B again and let's imagine that
component a is slightly slower and
component B is slightly faster in this
situation the queues always empty
now let's imagine the reverse of that so
let's imagine that component a is
slightly faster and component B slightly
slower so apart from the start the
initialization of the thing then the Q
is always going to be full the so a
balanced load in the Q
he's an unstable state it's kind of on a
knight knife edge that can only occur
when both of these are perfectly in step
in terms of the rate at which they're
processing things and that's just not
that's just not a stable condition
that's not a normal condition this is
this is a problem what happens to
component a now well for most of us what
happens at this point is not good what
usually happens is that component a
falls over maybe if we're doing well we
logging system let's our operations team
know and they all kind of set off alarm
bells and start running around trying to
figure out what to do next that's not
that's not a resilient system that we
need to react differently what we need
to do is that we've got to pass the
problem back up the line there's nothing
else we can do we can either fall over
or we can say we can't do any more work
at the moment so we need to apply back
pressure and that back pressure needs to
go all the way back up the line
ultimately that probably means to the
user you've got to find a way of slowing
down the user there are all sorts of
different ways of applying back pressure
I came across a lovely one recently
which is start doing work on the thread
that's coming in with the messages and
then you're consuming the resource of
the thing that can send new messages to
do to do the work and the people
starving at the the supplier but you can
build in protocols that pass the
backpressure up and stop giving an
exception if you know shouting a problem
means some manner at the point at which
you're trying to send communications
because that because the the system's
under stress one of the ideas that's
often talked about in these sorts of
distributed systems is the idea of
eventual consistency
and it makes people nervous and it's
kind of understandable and I think I
think there's a key idea
that's often missed when we talk about
it so let's let's let's imagine we have
a user and they've got they've got a
view of the system and they've got a
view of components a in component B
usually component B is going to
producing a slightly different
reflection of the world and that's going
to be reflected somewhere in the user
interface these could be on the same
same user interface they're just kind of
different aspects of the system okay and
the user makes a change in one place and
that's communicated to component B now
at this point there's a there's a
there's a difference in the in the in
the perception of the state that
different parts of the system in now
that makes a problem only if your
separation of concerns allows you to
make a problem so let's imagine now that
what we're talking about is let's say
it's the Amazon bookstore okay so this
is your this is your basket your your
shopping basket and this is your order
history does it matter that they're
slightly out of date in that context I
think it doesn't it doesn't matter if we
have to wait till sometime later for
that change to get picked up and
reflected in another part of the system
as long as the boundaries of your your
design r-la are kind of within
appropriate bounded context that
separate their concerns appropriately
then eventual consistency doesn't matter
it's it's a rare occasion when it does
and I think that's an important part of
the design of software systems is to
identify the bounded context and make
sure that the states stable within the
bounded context and that that banded
context makes sense in a business
context it's an important part of the
design of these sorts of systems we
talked to look we've talked a little bit
about location transparency but elastic
systems need to be able to react to
changes in demand as we've described and
if we want to do that location
transparency is a really important idea
because that's the ability to be able to
figure out that we haven't got enough
computer horsepower launch something
else that's going to be able to deliver
that computer horsepower and start
forwarding traffic for that new thing to
service if you if everything if every
component node knows where every other
component is by you know location
specific addresses you don't have that
ability to scale up because then you've
got to distribute the address and
address map all around everywhere so you
need these things to be able to send
messages and not care where the receiver
is I think that the thinking is going
further than that we're getting to the
stage where the infrastructure that
people are talking about and he's in
some cases is there it doesn't matter
whether whether one service is on the
same box as another or a different
continent they can communicate with one
another effectively I mentioned already
that you know distributed computing is
becoming competitive a Civ and to be
honest as human beings we're not very
good at it we're not very good at
thinking about it that way so we've got
to find models that allow us to work in
this way without having to worry about
the very difficult concerns of
concurrent computing and that kind of
thing I think I think if you're unless
you're a specialist if you're if you're
working at that kind of level it's gonna
be very very difficult and even
specialists wouldn't become floating the
concerns of working worrying about
multi-threaded computing and concurrency
alongside working worrying about the
domain problem they're trying to solve
those are concerns that need to be
separate even by the best programmers if
we go to build efficient systems and
again this is one of the reasons why
ideas like a synchrony message passing
and location transparency are important
so let's talk a little bit about today
that idea of scalability so we again got
components a sending messages to
component B
okay so that's one model we've got a
version of component B that can
processes all the messages and that's
fine what happens when component B can't
keep with keep up with the demand
well we can build in the ability to
figure out based on the content of the
messages where to send them and have two
versions of component B that's services
different parts of the messaging maybe
that's on certain ranges of accounts
maybe it's on different types of
messages don't know but being able to be
able to break that apart is an option
that's available to you when you've got
this separation between the messaging of
the messaging of the system and location
transparency so I think that modern
hardware should change our assumptions
of the way in which we design and
develop software one of the biggest
problems that we face is the cost of
moving data remote rams not random
access disk is not random access SSDs
aren't random access each of these
things in terms of performance has a
variable profile discs the easiest to
understand do you know any any time when
you touch us
to try and get a bite from a disk you've
got to wait for the disk to spin around
to get the right sector you may have to
move the heads to a certain location to
pick up the right track and so on Ram
because of all the caching
depending on whether you get a cache hit
or a cache miss miss there's a dramatic
difference in the performance of that
thousands of times different SSDs are
block devices they they rot they if
you're writing data that is a
dramatically different time penalty to
reading data and all of these things
it's not straightforward it's this stuff
is more complicated in it than it seems
the other big change that I certainly if
you're as old as me there's kind of the
inbuilt assumption that I grew up with
in my programming camp
career was that was that Ram was fast
network was slow and disk was somewhere
in the middle and that's just wrong
Ram slow networks slow disk is slower
there are some networks that are can be
faster in some circumstances we're
getting to the point where there are
certain network topologies that can be
faster than a Ram access there are
certainly disk is dramatically slower
than networking Rams changing RAM RAM
change I think we've got massive
non-volatile Ram he's knocking on the
door he may be a few years down the
track but he's not very many years down
the track and that changes the game too
so we need to be thinking about new ways
of architecting our systems the old ways
are built on the compromises that were
imposed on us by certain performance
profiles in the hardware that we were
all used to and those compromise those
assumptions no longer hold this is the
obligatory Conway's law slide if you
haven't heard about Conway's law the
idea is is that the the architecture of
your system will be mirrored will mirror
the organizational structure of your of
the organization that created it so if
you have a hierarchical organization
with siloed teams you'll probably build
a multi tier architecture like like that
if you have a distributed teets a group
of small distributed cross-functional
teams you'll probably build something
that looks more like that this is kind
of microservice territory this is kind
of these are the sorts of systems that
we're talking about we were talking
about these these discrete units of
processing loosely coupled from one
another using asynchronous messaging
which is micro services plus plus to
give us the elasticity resilience and
scalability that we and responsiveness
that we demand I've mentioned this idea
a couple of times already and it was
mentioned in the by the previous speaker
as well bandy context the kind of key to
this in terms of being able to draw the
lines around the components that we
build appropriately I was chatting with
Jonas at lunchtime and he was saying
that it's often difficult to kind of
figure out what the best programming
model is to present for some of the
things because people take too
simplistic view sometimes and are sorry
I'm putting words in his mouth that he
didn't speak but but they they will just
make everything a remote communication
call you've got to think carefully about
what the boundaries of a service sell
what what what encapsulate this thing
and those should be aligned with
business context you need to think about
carefully about though the boundaries of
the team's and what their
responsibilities are and they should -
should be allowed aligned with bounded
context those moat might be several
components within that bounded context
to make it sensible distribution of work
but it's important to get these things
right what we're looking for all the way
down the line is to minimize coupling
we're trying to minimize the coupling
between teams and we're trying to
minimize the coupling between services
so that when we get to the point at
which we have these asynchronous
conversations they make sense there
since they're simple and straightforward
they're not chatty they're not give me
this bit or give me this byte or you
know give me that number and that number
and I'm gonna add them together we need
to design the protocols to make sure
that they're they're sensible and
loosely coupled the kind of mental image
that I have of this is if you imagine an
organization without any computers and a
series of offices doing different parts
of the job of their organization within
those offices it's down to the people to
organize themselves however they like
and the offices communicate with one
another by messages now imagine what the
you know how you would design a system
like that to work that's kind of how we
want to design our services we want
these simple exchanges of information
ideally if we were able to visualize the
messages that flow between these
components he probably makes sense if
they're kind of the sorts of things that
a somebody understands the problem
domain a business user would understand
as part of the conversation we want you
know place this order this thing's been
ordered reserve this this item those
sorts of ideas these sort of relatively
high level exchanges of information
between between the systems
and we should we should be looking to
one of the key ideas of banding at
bounded context that's really important
is that at the points at which we
exchange information between bounded
context that's a point of translation so
even if both that in two bounded context
we have the concept of account they're
different they're they're different
versions of account they might share a
common key they might be referring to
the same count but one domains version
view of an account is going to be
separate from the other so here's here's
a high-level typical kind of
architectural diagram of the system that
we built this is quite a notice getting
quite hold this system now it's still
one of the higher performing exchanges
in the world so we we had our services
and our services were kind of reasonably
large on the micro-service scale for
some of those things but they were
sensible bounded context we had matching
engines for for where we would do deals
where we would do trades we had account
service account management services
where we would manage the live position
of people that were trading we had
account history service where we would
record what was going on further
historically what trades people had made
and so on we kind of divided these up
into three groups so there's the idea of
course services those were the services
that were these were the seriously high
performance things these were the things
that were doing doing our business logic
these things were these were kind of the
systems of record lis the system of
record was the in-memory state of these
things and these things could fly they
were servicing hundreds of thousands of
messages per second very easily in in
microseconds we had general services
these were kind of the slower more
traditional kind of services now most
organizations I think these are the
sorts of services that they would build
in this kind of model these things were
often backed by a database but as I said
before the the separation of concerns
that we had as a result of the way which
would organize their banding context the
live data for trading was only existed
in here in order to trade he didn't have
to you kind of went through the layers
to get to here but this is where trades
happened and you didn't have to go
anywhere else in the process of
performing a trade you didn't have to
ask anything else to do that if you
wanted to look up your account history
on the other hand which was kind of what
trades you did before that's here now
eventual consistency means you know that
that would eventually be correct but he
would at the point that the live point
of trading this wasn't precisely up to
date with what was going on here
but he didn't matter because nobody
cared if their account history wasn't
microsecond in line with the trade
they're live trading at present their
separate concerns we also had a bunch of
what we call gateway services these were
translation services so it so we were
interacting with different protocols
different systems different endpoints we
were providing public web access public
API is you could write your own BOTS to
get to trade against the system we were
providing institutional aid to bi so you
would use the fixed protocol which is a
financial information exchange protocol
that's common in the industry and lots
of other places and so of all external
cans trans communications came in
through one of these gateway services
these things were kind of Border Patrol
so they would translate messages into a
form that the rest of the system would
understand the rest of the system would
kind of talk using broadcast
asynchronous messaging between all of
the services and then they would
translate messages out to whatever
protocol was relevant in order to make
this work this was not only a very high
performance system it was also the most
efficient system that I've ever worked
on in been in in in terms of being able
to do new work because each of these
services were single threaded even the
seriously high performance high-tech
things because all of it was single
threaded it was it was straightforward
to reason about because it was a rich
domain model ace
simulation of our problem domain in
memory it was simple to reason them out
and it was simple to test we also had
the really lovely property that if we
saw a bug in production we could take
the D messages that were from production
replay them through the system in a test
environment and get it back into
precisely the same state and then debug
it in a test environment there were not
many systems that I've worked on where
you could do that to the same degree
this is a completely deterministic
system in that case it was also
exceedingly scalable because we could
just shard the messaging the messaging
messages at whatever level if we were
needed more matching engines we could
add more matching engines if we wanted
more account services we could do that
all of those things
wherever looking at the contention point
was also where to start
sadly I don't think that there's
infrastructure that precisely does what
I've just described I think that this I
know of two or three people that are
working on stuff like that akka is one
one version of doing things it does more
than I've described and in some ways
less there's a new thing from cat show
called Barrow time which was influenced
by the Lmax architecture that I've been
describing to you and they've taken some
of the ideas that to does some things
that I think are wrong including
supporting synchronous messaging which i
think is a mistake I don't think we
should be supporting synchronous
messaging in these sorts of systems so
if you try it try these things I think a
cure is by far the most mature and
robust but take a look at these things
if these ideas appeal to you and explore
but remember to remember that the key
constraints are around designing your
services within those bounded context
and making sure that you're like the
myth the the points of exchange are
loose coupled at the protocol level not
just at the technical level that's me
but that's that's the end of my talk so
I think I do have a few minutes for
questions
thank you any questions hey how can you
make the the user interface asynchronous
is that a question
good so it's if it seemed it seems
natural to be synchronous but you've
just asked me a question you're still
you're still thinking you're still doing
other things and now I'm coming back to
you with an answer sometime later so we
can push three asynchrony out we can do
we can design our interactions to do
that now the protocols on which you know
commonly we work aren't necessarily
built with those assumptions in I think
that's something that ought to change
I'm writing some software right now
which has kind of got a web interface
and I've got push both ways so I've got
I plug in something to to the my message
channel and when a service wants to
notify the user of something it can send
a message in that will asynchronously
delivered to the web page that too is
the way that the Elm apps model worked
so then you can write a model in your in
your web page in whatever your favorite
web development language is or your user
interface whatever nature of user
interfaces and respond to those events
now 99.99999 percent of the time this
will be as fast or faster than a
synchronous call but those few percent
of the times when something's broken it
doesn't really matter it's still be
going to be okay we'll catch up sometime
later you're going to avoid coding for
awkward error conditions it takes a
mental switch it takes a change in
approach I think a little but I do think
at least a simpler code but it just take
it just a dis lightly different way of
thinking about it more questions
it's the but I'll repeat the question
are there any are there any benefits in
using this kind of approach in a local
system we you're not distributed not I
mean to distribute it I think I think
that there are so I think that you gain
the benefits of Inc simpler coding
practices because you avoid these error
conditions and you also get performance
this is a higher but this is a higher
performance architecture by measurement
I mean you know we we measured it
measured the hell out of this stuff to
get to get levels of performance that
we're talking about for the exchange and
we tried all sorts of different things
before we got to this and we tried we
tried all sorts of classic architectures
we tried doing clever things like
allocating work to threads and we spent
more time allocating work to threads
than we did actually running work on
threads which is why we ended up with a
single threaded thing this is this is a
very efficient way of computing it's
also the way that our processes work it
also aligns really nicely with the way
that hardware's going so I think it I
think it's an efficient use of hardware
so I think that there are many pi
believe that there are benefits if I'm
honest I don't I don't want to write
code any other way than this because
this gives me the freedom to write the
rich to my domain models that I like to
write as part of my my development and
the freedom to be able to scale that if
I want to and distribute it if I want to
so I think that there are benefits this
kind of architecture even for single
even if you're rocking mobile phone app
so I tend to start thinking about
writing in this way we've got to get to
the level where there's a better
supporting from the tools and
infrastructure around this and as I said
are now a couple of projects that are
working on building that support in
various areas and I hope it's coming
soon because I think this is I think
it's a an interesting step in in in
programming approach
that's a great question
I'll just repeat the question if if
we've got two teams looking at different
bounded context and they're coupled in
that they're exchanging information by
messaging who's responsible for the
interchange between them it's a great
question and I don't think anybody's got
an answer there everybody's talking
about micro-services at the moment the
organizations that are probably most
mature at microservices at the moment is
starting to feel the pain and
micro-services give you some wonderful
things like Yui they give you the
ability to scale that have lots of
people working on independent things but
the protocols over time get more and
more important and I think that Netflix
Amazon and people like that are starting
to realize that and they started to
worry about how they can be more rigid
in the definition of the protocols and
the management of the dependencies the
other way so for the classic kind of
micro service architecture many small
teams you get the greater the great
scalability great independence of the
teams and at the cost of who's
responsible for the Cross Pro the cross
team communication the other way of
doing it is to build a monolith mil you
can still build a micro service
architecture you still be a reactive
system then the L max system was a many
individual services but actually it was
owned by the whole team and it was
released together as one so we ducked
that problem by because the protocol was
always version it was always at the same
level we'd avoided the dependency
problem between multi versions of the
protocol by having it released by one
team and you can do that and that that
works well too but that comes at the
cost of you go in the direction of a
single monolithic deployment a bigger
test infrastructure if you're doing
continuous delivery and all of your
tests you need to scale that up better
you need to invest in that too
to get that working and that's some
level although you can still have quite
a lot of autonomy in small teams there's
a little bit of compromise with that too
so I don't think that there's a silver
bullet answer to that question I think
is a genuinely hard problem and I don't
think anybody's got a perfect answer
it's a compromise either way and you
kind of takes you money you places your
money and takes your choice
that's a good one I tend to hide it in
the Gateway so try and make the Gateway
hide the synchrony from the rest of the
system and that could be tricky but it
means that the Gateway will be ugly and
more complex than you want it to be but
that's that's life kind of thickness
that's what you'd have to cope with in
that circumstance but I'd want to
isolate it as far as I could at the
band's of the system the the kind of
pure ease of you is that you can't hide
that a that that that's increment that
secret synchronous style so you want
that's why you want you know once you go
down the secret the asynchronous route
it's got to be almost a basic course all
the way but you can kind of compromise
it it's kind of the same problem with it
you know a database commit that's kind
of a synchronous action and for me
that's usually too slow for me to want
to take the cost but you've got to limit
the data to database so there are ways
of isolating it using a the more I think
about it agent Lee's kind of a
fundamental communication protocol so
you can kind of build other things on
top of it so you can't hide hide that
synchronous and ness with a synchrony by
some clever tricks but the gateway
gateway service will be more complex and
more ugly than you want it to be sorry
repeating myself any more questions no
ok I'll be arrested
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>