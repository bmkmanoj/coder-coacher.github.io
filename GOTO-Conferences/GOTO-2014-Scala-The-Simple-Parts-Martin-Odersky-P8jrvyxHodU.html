<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2014 • Scala: The Simple Parts • Martin Odersky | Coder Coacher - Coaching Coders</title><meta content="GOTO 2014 • Scala: The Simple Parts • Martin Odersky - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2014 • Scala: The Simple Parts • Martin Odersky</b></h2><h5 class="post__date">2014-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/P8jrvyxHodU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so
you for the invitation to help me speak
here
what I'm going to speak
obviously and I'm gonna speak about
Scylla the simple parts and that implies
that maybe not all the parts as simple
as has been applied but implied by many
others before so SCADA is actually
celebrating its 10th anniversary so time
flies ten years ago there was the first
announcement we would never have dreamed
to actually have a language that has so
many developers that is so popular now
they can't do that so when the
announcement came out is we said that we
have a new language that has three
innovations so the ones we mentioned
were abstract types and mixing
compositions that unify ideas from
object and module systems that's
something that hasn't had a lot of press
so object and module systems was one of
the main important points at the
beginning the second one was pattern
matching over class hierarchies unified
functional and object-oriented data
access and it greatly simplifies the
processing of XML trees so XML was very
important when when Scala came out and
was very important industry-wide it was
a time when everybody
IBM many other companies announced the
language that would have built in XML
support because XML was so important
well now of course times have changed
and maybe we can explain XML with JSON
and even ten years we can replace it
with something else I would imagine but
at the time it was very very very
important and important in particular
was important because it supported
pattern matching so pattern matching is
a functional technology and XML was so
sort of the showcase because I'm till
then the object-oriented dogma which was
very strong everybody believed in that
was that to say well you should put your
methods where your data is and
object-oriented hang-up encapsulation
and if at the time if you propose
something else you were a complete
heretic people just said no no no you
have it all wrong so we're the times
have changed quite a bit and and the
opinions have changed quite a bit but at
the time it was like that and when XML
came out it was the poster child for why
functional programming my
be useful because you couldn't put
methods into an XML tree it wasn't
possible XML was pure data but you still
had to analyze and parse it and that
pattern matching was very good for that
so that's why it's an elbow sort of at
the at the beginning of Scala it played
a big role but now it stops the third
one was a flexible syntax and type
system enables the construction of
advanced libraries and new
domain-specific languages so that sort
of shows these the theme that Scala is a
language that has sprouted quite a lot
of domain-specific languages on top of
it okay so that was the announcement and
ten years later we Scala has grown quite
a bit we now have about a hundred
thousand developers hard to count but on
the ballpark figure more concrete
numbers are two hundred thousand
subscribers to the Coursera online
courses overall 13 number thirteen in
the red monk language ratings which are
based on number of github projects and
number of Stack Overflow questions and
beyond the numbers what I think is more
important many many many successful
rollouts and happy users so this is
great to see that so many people find
this a language that that they can
express themselves well in and that
makes them happy to write code but on
the other hand Scala has also discussed
more controversially maybe then can be
expected for language its age and the
question of course is why I mean Scala
is probably big they're very big
compared to what could be expected ten
years ago but compared to say a truly
controversial language like C++ or Java
it's tiny so why is everybody talking
about something that in the big grand
scheme of things is so insignificant
well I think there are both internal
controversies that doesn't help and then
there the external complaints the
internal controversies are that actually
we have quite a few different sub
communities in this gara language who
don't agree what programming in Scala
should be and quite often they really
don't see the point of the other
communities their parts that don't
the point of object orientation at all
and their object-oriented program is who
don't see the point of the fine of these
the more advanced patterns of functional
programming and the two communities
sometimes clash and don't mix and then
they're the external complaints like one
you hear often is catalyzed to academic
when you hear also often is Skaar I sold
out to industry so what is it
scholars types are too hard that's what
you often hear but another subset of the
communities as scholars types are not
strict enough we need more types we need
stronger types and a lot of people say
skylights everything and the kitchen
sink and that last point is the one that
gets me most upset because when I
created SCADA that's precisely the
opposite of what I wanted to create I
wanted to create something simple and
because the language is a community
effort many people contribute to that
and also for historic reasons the
perception of Scala maybe is sometimes
not that so what I want to do in this
talk is go back to the simple parts of
Scala to what I believe the core of my
talks I had this diagram which says that
search in Scala is a unifier it unifies
object-oriented and functional
programming and with that you've got at
the same time a unification of
essentially scripting languages and
systems languages so Scala can be used
as a scripting language it even won the
script poll at JavaOne one or two times
and it is also of course the substrate
of very large deployment millions of
lines deployments at Twitter for
instance and many other companies that
use it essentially as the backbone for
their the whole business so Scala in
that picture was meant to be a scalable
language as the name implies already and
if you ask what is scalable then in fact
it you could say it has two meanings the
first meaning is a direct meaning to say
scalable means growable so Scala is a
grower language
it's a language that can more be molded
into new languages by adding libraries
these libraries then become
domain-specific languages that are part
of Scala and if you want to find out all
about growing a language then by far the
best talk about that is guys deals 1998
oops lucky note called growing a
language if you haven't seen the talked
and by all means do it's a absolute
piece of beauty the second meaning that
I'm also going to talk about is a
language that enables growth so scalable
in the meaning of enabling growth that
means that the same constructs can be
used for small as well as for large
systems and that they allow a smooth
growth from small to large
so first drawable language Scala
definitely is has a lot of features that
make it a growable language it has a
very flexible syntax as a flexible type
system has user definable operators as
higher-order functions implicit and all
these things together make it relatively
easy to build new domain-specific
languages on top of skyline many people
have done that and where this fails you
now have macros which are still an
experimental feature so strictly
speaking you shouldn't use macros for
production use but that has never hold
back anyone who really wanted to create
his own syntax and language so a lot of
people have jumped on their bandwagon
and used macros to create even more
refined and advanced domain specific
languages on top of Scala
so that has indeed led to quite a lot of
interesting and successful
domain-specific languages that we have
here so there's chisel for hardware the
s of course spark for Big Data there
spry for HTTP dispatch they're shapeless
and scholar Z libraries that essentially
do lift Scala on the level to the level
of type level programming they're slick
for database success or squeryl as an
alternative their specs and Scala tests
for testing as akka for actors dispatch
another HTTP dispatch library and as SBT
which is essentially ad scalable tool
that uses SCARA as the language for
writing a bill
so definitely this idea of global has
worked out that a lot of dsls on top of
Scala and that's of course just an
example there many many more that that I
couldn't fit on the slide here but it's
growing but good is it always good well
in fact I believe it's a double-edged
word on the one hand definitely it lets
you gives you the freedom to express
yourself to move the language into new
fields and that's great but on the other
hand it also can fracture the user
community there's a essay that I
personally found very good that will be
definitely rang a bell with me which is
called the Lisp curse to say well why if
Lisp is another very growable language
but the Bliss curse is essentially that
precisely this property leads to a
fractioning of the of the user community
besides of course no domain-specific
language is liked by everyone alike just
like no general-purpose language is
liked by everyone so that again leads to
a such a partitioning of the user
communities those who like SPT those who
hate SBT those who like spark those who
prefer Hadoop and so on so and the other
problem is that host languages often get
at least part of the blames for the DSL
stay in bed
so in summary growable is great for
experimentation for the more adventurous
among us but it demands discipline shall
remain conform to some standard when you
want to use it for large-scale
production use so the second meaning has
been a little bit overlooked with all
the the attention on the first one on
the stairs else and grobel and we can
make better put new things on top of
SCADA but I think it's even more
important in the end so that SCADA is
really a language for growth you can
start with a one-liner you can
experiment quickly and then you can grow
without fearing to fall off the cliff
because the same language constructs
that helped you write your one-liner
still apply when you write your million
line system it's just objects all the
way downs and functions all the way down
there's not other things that
you have to learn that then kick in for
programming in the large sale it's
really the same language constructs that
scale up from scripts to large systems
and scale deployments indeed now go into
the millions of lines of code and the
best characterization what what that
means a large system like that that I've
heard is this one here to say a large
system is one way you do not even know
that some of its components exist so
that's that's the definition of a large
system you don't even know that certain
things exist in that system where you
work on some part of that and we will
find out what that means for software
construction so the language works
indeed for very large programs the tools
are challenged the larger the code bases
get for instance the higher the pressure
on build times and we're working very
hard to make the tools catch up in the
latest version of Scala for instance we
have dramatically improved incremental
build times and I hope we hope that this
will help a lot of people out there that
that are struggling with large cut Scala
code bases so what enables growth so
what is this thing that makes Guerra
enabling growth so I really do believe
it's this four other unique combination
of object-oriented and functional
because large systems that we see out
there they really rely on both so they
generally take to be tend to be quite
disciplined and functional and that's
good but when you compound in the
components of course they use all the
tricks available in the object-oriented
system because functional alone doesn't
really give you the the glue the the the
composition the grouping mechanisms for
large systems a problem with that is
that there's no established name for
this should we call this language object
functional some people have proposed
that but I don't like terms with a slash
in them it reminds me too much of pl/1
so so what do we do well what we would
like to do but we would prefer it to be
like this to have functional and object
programming in harmony sitting on the
beach but in actual reality is
unfortunately more often like this
that's how many functional people see
object-oriented
the evil manager that leans over your
cubicle and says well you haven't
written your UML the eye diagram in the
right way and that's how many object
when people cease functional programming
as the the mad scientist that cocked
something that can't lead to any good
and probably will threaten the world and
that's unfortunately where I find Scala
often to be so between the two chairs
falling between the chairs and getting
their blame from both sides
another quote which is rather funny is
James Irish quote that scholars wrote in
a role in history as how James has
written this brief incomplete and mostly
wrong history of programming languages
it's hilarious if you haven't seen that
yet so here's what he writes about
Skyride say last time free as far as I
know a drunken Martina desk he sees a
Reese's Peanut Butter Cup at feet -
featuring somebody's peanut butter
getting on somebody else's chocolate and
has an idea he creates collar language
that unifies constructs from both
object-oriented in functional languages
this business of both groups and each
promptly declared jihad
so that's amazingly prescient I didn't
when I came out okay many came out I
didn't actually I thought it was
slightly funny but now I'm actually not
sure whether I should well first it's
actually true and second I should I'm
not sure whether it's that funny anymore
but okay so so much for a functional
object-oriented you see it's a tough
it's a tough area to be in so what I
would like to propose is actually to
slightly shift the viewpoint or if not
the viewpoint and at least the name we
give to this thing so another way to
view Scala is as a inherently modular
language so what that means is that
Scala is still a fusion of
object-oriented and functional but it
achieves that to go from small scripts
to large systems because it is very
modular so what does modular programming
mean exactly well modular programming
means simply that systems should be
composed from modules okay and what are
modules well modules should be
simple parts that can be combined in
many flexible ways to give interesting
results simple parts that can be
combined in many ways and simple often
means and capsule eights one
functionality only one but you could say
well that's old hat modular programming
that's an early 80's phenomenon we had
languages like modular to them and
indeed time I have a I have a certain
fondness for modular two because it was
the first language I programmed
seriously and I think indeed modular 2
was great for its time but these are not
the early eighties times have changed in
particular in the early 80s most
languages which and most computers were
phenomenal angwa jizan for norman
computers so that means that essentially
a computer was a memory in a processor
and a bus of one word wide and the
languages reflected that so they had
variables of a simple type or a pointer
both we do today fitted in a word and
you're the hole every API parameter or
function was just one word wide so to
manipulate the system you had to do it
word by word and at the time there was
already John Backus the inventor of the
first high-level anointment language
that was Fortran when he got the Turing
award in the 70s he gave a touring Award
lecture which he said she coined this
term the von Neumann bottleneck because
he says well languages have to evolve
beyond that because they have to speak
about higher-level things not just
single words they have to speak about
graphs and polynomials and texts and
things like that and to do that you need
a mathematical theory of these things
and if you look at mathematics and those
ta theories are always immutable you
never modify something in place in
mathematics and because of that you need
functional programming so that was sort
of the wake-up call for functional
programming in the 70s okay so if you
believe that then definitely functional
programming is a part of modular
programming and indeed if you look at
the second most important foundational
paper for function programming then I
would say it's this one here
why functional programming matters John
use 1985 and his case is clearly a case
of modularity so what John use says
is well in an imperative program you
have an algorithm in the algorithm he
looked at was just as newton-raphson
iteration for square root could have
been any algorithm you have an algorithm
and it has a loop and it has an
iteration step in there's a termination
condition in there all mangled together
what he could do with functional
programming is he could split these
elements into different modules
functions that could be combined within
a mix-and-match approach so he split
these apart into separate functions and
could combine them clear argument to
modularity so does that mean that
functional programming is really the
same as modular programming well it has
as I said it helps a lot but it's not
synonymous synonymous it's not exactly
the same thing
some concepts in function languages are
at odds in with modularity so for
instance sometimes functional languages
or some functional languages assume in
some areas a global namespace an example
are type classes in Haskell you can only
have one instance for a class in your
whole program and if you remember the
definition of what a large system is you
don't even know the certain components
exist that's a problem because you don't
know whether the components that you
don't know exists might have an
implementation of your type class that
will conflict with yours and there are
other things some functional languages
have very strong module systems for
instance SML or Okemo other half module
systems that are rather weaker for
instance a Haskell or or closure let's
let's pick those two and then you can of
also discuss whether dynamic typing is
actually something that is at odds with
modularity because it gives you a weaker
way to check your interfaces or not but
that's a completely different discussion
and I'd rather steer away from that one
so objects and modules what what's their
relationship so in a sense you could say
object-oriented languages we're sort of
the successors of modular languages
because there was this idea to say well
instead of having single modules let's
be more flexible
let's have classes that can create these
things at runtime where we can have an
arbitrary number of instances let's have
traits or interfaces that be
are the api's of those so that we can
have a single module a single class has
multiple interfaces and the single
interface can be implemented by multiple
classes so it was in a sense a more
flexible way to be modular but on the
other hand object-oriented doesn't
always imply modular either so for
instance we see we see things in at
least old ruby monkey-patching adhering
the ruby community steering away from
that so that's very good because
monkey-patching of course is not modular
it has the same problem that you can of
you can patch the same name only once in
your whole program and if somebody else
does try tries to do that you have very
weird bugs and very hard to track down
problems we lines on mutable state is
not modular because it gives you a lot
of hidden did repentance ease and then a
lot of mainstream object-oriented
languages have rather weak composition
and decomposition facilities so the
effects of that is that they then need
to rely on external dependency injection
frameworks so that's something that in
principle the modules in your language
should do but if the language can't do
it you need something else that uses
aspect oriented programming or bytecode
rewriting and the decomposition
facilities often encourage this idea
that you should put your methods where
your classes are which sometimes is the
right approach but not always so I want
to come back to SCARA and it's simple
parts if we now look what the simple
parts are modules and parts so they
should be simple and they should be
combined in flexible ways before looking
at modules how Scala can write modules
as a library components let's look at
the language itself what are the simple
parts in Scala that can be mixed and
matched in a flexible way what I'm gonna
do is I'm going to propose seven simple
building blocks I sort of took a bit and
an overview of like the programs and the
classes I wrote in there in the past
years and says what are the things I
can't do without what I really rely on
because of course when I write code in
Scala I find it rather simple
you'd say well of course he does but I
still think I want to sort of give you
my viewpoint why I find it simple and
what I use whatever I think that that
thing's combined well as always of
course simple is not the same as easy
so quoting rich Hickey here some people
confuse to still confuse the two easy
means it's something that is pretty
close to what you already know it's
familiar and therefore you can quickly
adopt it simple means something else
simple means does one thing only and can
be combined well and the two are
sometimes the same but not necessarily
so and a lot of people confuse one for
the other so let's look at the simple
parts and the simple parts are actually
rather boring but they're nevertheless
important so I thought it's important
that I stressed them so for me the first
thing which is important is expressions
and the fact that everything is an
expression so that means I can plug in
everything in everything else because an
expression of course can be a function
call or operation and it takes
expressions as operands and because
everything is an expression it means
that I can compose everything with
everything else if I had a language that
had statements and expressions like many
mainstream languages do I couldn't do
that I would live in one world or in the
other and when I live in the statement
world I have to write these statements
one in the one after the other and I
have to sort of connect them with
mutable variables so they they sort of
act on these variables is a much more
indirect and less composable way to
treat things so here's just some simple
code that shows how that works so the if
else has the same syntax as in Java but
it's an expression this thing will give
you a string grown-up or minor and the
same thing happens for match expressions
which are the analog off switch in C or
Java and tries and all the other forms
of statements that you would usually see
our expressions and that means they can
be put inside each other and can be
nested good so that was number one
number two for me would be this
principle of nesting scopes so
everything in Scala can be nested
everything else and there's a static
scoping discipline and that's again very
important for just be able to refactor
programs freely so in Scala you can
write a method inside a method in Java
you can't do that you can't write
methods inside methods but you can write
a class inside a method and then a
method inside the inner class so if
there's a single class in between then
you're okay
so I would write a class here I'm okay
but I can't mess directly why there's no
read no good reason why it's just the
way it is right but it's a big
impediment to actually structure your
programs feeling so instead of the two
namespaces terms terms and types and
they have exactly the same rule for each
one whereas in other languages like
again quoting Java you have four
namespaces fields methods classes
packages and you have different
resolution rules for each one so just to
say that sort of a difference between
simple and easy I think this color the
Java rules are for someone who comes
from Java easy because that's what
you're used to so you don't see the
complexity in all this but it's far from
being simple it's rather complex for
namespaces different rules for age okay
so what this principle leads to is
actually a quite a powerful principle to
simplify your programs so the first tip
I give everyone who says well how can I
get on the right track and writing clean
Scala code is you shouldn't pack too
much in an expression it's a rookie
mistake for people who are new to
functional programming because it can
pack things in an expression often
people do so that's actually code I saw
in our code base it's a single
expression it does has an amazing amount
of functionality but it doesn't mean
that you have to do it that way so just
for the sake of it I said well let's
let's just refactor this thing see what
we get so here's the same expression but
now I have just factored out all the
meaningful intermediate results so it's
C you see we actually produce a set of
sources and then we have a workspace
root and then you have a function which
says foreign given
entry which is a set of files we give
you the files that correspond to the
entry and then what we do in the end we
iterate over all the sources and for
each one of them diggy get the files
that correspond to the entry and we
concatenate them all together if you
don't know the the vocabulary of course
this might still look complicated to you
but anybody who has sort of a
superficial knowledge of SCADA for them
definitely this would be much more
legible than the thing I've showed you
before and the important thing is that
yes I can do that I can write valves so
just local definitions but I can also
write functions that get called all only
on-demand and I can put them right where
my result expressions is I don't have to
pollute my enclosing class so that makes
it very easy and really a no-brainer to
do precisely this thing if your language
didn't let you do that and you'd have a
choice to say I have to create a new
method in my class to factor this thing
out but then I have to pass a lot of
parameters to it and I have to write a
document and my whole thing will be much
much bigger than there's a trade-off and
you will be sort of more pushed towards
writing very long methods that have a
have a super loops or a long expressions
or things like that so that was number
two nesting I think is very important
number three is patterns and case
classes or decomposition and composition
so here's a classical example of that so
if you want to have a threesome tax tree
that represents arithmetic expressions
and you would have a base trait called
expression and then you would have two
classes one for numbers and one for plus
the posix extend the base trait and they
have the parameters that you expect so
number gets an int and plus gets two
expressions that's the two operands of
the of the plus and then somewhere else
in a different module at a different
time you can write an evaluation method
if you want and the evaluation method
would simply say well let's let's look
at what we have here if it's a number
let's return the M if it's a plus then
let's evaluate recursively the two sub
expressions and sum them so that's
simple and flexible functional
programming aficionados coming from ml
or Haskell would probably say it's too
verbose it can be done more concisely in
Haskell or ml and that's true because
haskó and ernõ have special types for
these things called
algebraic data types we've chosen not to
do that because a we wanted to stay
simple and uniform everything in Scala
is a class there's not a separate set of
types that express these things and
second because I don't think in actual
code is matters that much because if you
compare the size of your type
definitions with the size of everything
you do with them then I would believe in
every program the types are a really a
tiny minority so optimizing on the types
isn't isn't isn't worth that much so if
you look at the traditional
object-oriented alternative for that it
would of course be this one here so here
we now say well because we don't have
parenting it's actually very awkward to
figure out what the class is we'd have
to use a nice instance of or as instance
off for a visitor pattern or things like
that everything is rather clumsy and
heavyweight what you would typically do
is to say well let's put eval in the
trite expression itself and then in our
number class and in my class class I
have the right implementations of IVA
and that's okay if that's what your
application domain is that means that if
you have a set of types at the main
model and you know already exactly what
you want to do with it namely I have
expressions to evaluate them and maybe
to pretty print them but I'm sure there
won't be anything else on the other hand
you have often situations where the data
model is given maybe from a database
schema or an interchange format or
something like that
and you don't know what you want to do
with it and it might change next year
and then the object-oriented approach
here is actually the wrong one because
you'd have to sort of touch all these
things all the time to change your
business logic where what you really
should be doing is have a pure data
model that's fixed and stable and put
your business logic elsewhere in
functional programming and pattern
matching you have the choice you can do
one or the other of course choice is
always some
that it's also a responsibility for you
you have to make the choice but I think
in this case it's actually very very
important very good because there is no
best default it really depends on your
application
so number four for me would be recursion
that's of course we all know what
recursive functions are they are sort of
everywhere but in imperative programs
they're rather underused people use
rather loops instead and use variables
for that and in functional languages
what people usually do at first is to
replace a loop with Combinator's like
map and flatmap and filter and things
like that and that's great that's
exactly the right approach that you
should be doing but on the other hand
there's always a time when your
Combinator library doesn't have what you
need to do so you need a fallback you
need a fallback to say well what if my
Combinator's really don't give me the
right vocabulary and then the fallback
in functional programming I think is
really great to have this idea of
recursion in particular tell recursive
functions that with that can simulate by
a very systematic way any state machine
you can throw up with you can come up
with and that do so in particular very
efficiently so that's the other thing
that sometimes you're concerned that all
your higher-level operators they might
actually cost you too much in general
they're plenty fast enough but it could
be that you are faced with essentially a
hot spot where you say well I have to
squeeze every last cycle out of it and
then it's a it's great that you can
specialize by hand and with recursive
functions and particularly recursive
functions they're sort of the natural
evolution of what you would use a look
for in imperative languages so now that
I've said that and of course the the
number five that you definitely will use
a lot in functional programming is
function values so that one is pretty
uncontroversial by now you could say
almost all the languages out there have
some form of function values sometimes
they get the scope rules a little bit
wrong like this the the meaning of this
and JavaScript closures is a little bit
funky but by and large it's it's the
right thing and that's great
number six for me would be collections
so collections definitely are the
backbone of programming in in functional
languages we have immutable collections
as our defaults or persistent
collections that where your program is
then a transformer from collections to
collection so it takes collections it
produces new collections and it's not a
crud program a create read update delete
program that pokes into collections
element by element and SCADA has a very
nice library of immutable collections
which happens to be very very simple to
use and it's simple to use in particular
because it has a single vocabulary of
powerful operations such as map or
filter and they apply to any collection
that you could think of that out there
including collections that you write
yourself so here's a little example in
action so we have an array people an
array of persons and we map the function
that takes the name of the person over
the array of people so that's that's
essentially a screenshot of a worksheets
Kalibak sheets or you write new type
expressions on the left and you get here
the types and the answers that the scala
wrapper would throw back at you so this
thing is integrated in the Eclipse IDE
and IntelliJ has a very similar thing so
it would respond to say well I go back
with an with an array of string you get
back an array string and it's barb and
Karla you could do the same thing with
sets so we have a set of one four five
seven and you could map it by saying
well apply a division by two to each
operand so that's the canonical map of
assets and you would get a set of zero
to three note that the size of the set
is different and that's correct because
sets are not sequences if you map as I
have a map over set and it's something
different than a map over a sequence the
important thing is the concept of map is
exactly the same it's a mathematical
concept here and here we have a third
one a map actually of Roman numerals so
it Maps the characters to the
corresponding numbers and what that map
here does it reverts that it inverts
this map here so it swaps essentially
the key and value pairs so here you have
a key
Elland value D and you return a value D
and key L and what's important here is
in every case the result is of exactly
the same type as what you started with
no friction so if I work in sets
I want my map to apply to sets I don't
wanna convert to sequences
iterate and then convert back that would
be essentially three operations instead
of one so really the maximal simplicity
that he could have here so I'm sort of
making the case for this form of
collections because it has actually been
criticized a lot in the past so I want
to sort of give you the counter-argument
why I still think it's the right way to
use collections like this so the
counter-arguments are essentially two
but I'm only presenting one here the
counter-argument that you hear sometimes
is to say oh the type of map is so
complicated well let's look at the type
of map here's what you see in this
Caradog
it's a function it takes a function from
A to B so that's the Scala talk for
Araya
for the type array of a and gives you
back an array of B that's what you would
expect right well the problem here is
that it's there's a thing which says use
case and that's sort of a red flag which
to say well that's actually not the real
type that's the type you see as a user
of arrays which actually should be the
only type that matters for you because
there's a user of arise you want to see
that type so what's the real tight well
let's open this thing up the use case
and here you see the full signature of
map and it is rather intimidating so you
have a second type parameter that and
you have an implicit parameter of type
can build from it says well if you start
with an array of T and you have a type B
then you can you and and and you have a
recipe to build from an array of T and
there be a type of that then that's a
result so that's something that is very
very abstract and indirect but the
reason why we have this type is that we
want to have only a single
implementation or print in principle a
single implementation of map in the
whole collection libraries before we had
to start
type we didn't do that we had like 20
different implementations of map one for
arrays and ones for lists and things
like that and the problem with that was
that often these implementations they
diverged some of them were buggy others
were not
some of them some sometimes people would
implement a new method on a certain
phone collection then it was missing
from the others sometimes the same
functionality was was present on
different collections under different
names because different developers found
that any do the same thing so we so
essentially we said now stop all that
what we need is a very strict framework
that has a single implementation of map
for the whole thing and then it would
work automatically for all the
collections and to actually be able to
do that you need something as flexible
as that which you'll see in a second so
the counter-argument would be well why
didn't we define map the global map like
this so we said these collections they
are functors so functors are essentially
things that have a map and if you look
up the the type that you would expect
here and a functor is the type of map
would be very much that like the first
type that you saw so it takes the new
type the old element IP and the new
element type U and it gives you an F of
U where F is essentially your
constructor your type that that you
parameterize over that's the factor I
problem with that is that that map
doesn't work for a race since to build a
new array on the JVM you need a class
stack and there's no way we can smuggle
a class tag into the signature it's just
not possible
it works over all types not just types
that has class tags so it won't work
that way would it work for sets no I'm
afraid it won't work for sets either
because to build a new set you need a
way to compare the elements of that set
to avoid duplicate and again there's no
way you can actually smuggle in an
element comparison function into that
map so the reason for can build from is
it's essentially a generalized way to
express all these collection specific
constraints you say you would have an
instance of can build form to say that
would itself demand well for sets if you
give me in equality I can build
set the array can build from would say
if you give me a class tag I can build
you an array and that's essentially the
sort of the generic glue that you find
in the collection libraries as a user
you never see that so it's actually
quite quite miraculous that all this
clever machinery that builds the right
collection for you at runtime actually
doesn't leak out into the signatures
that's why I'm actually very fond of
kind built from so number seven and last
would be variables hoops
I'm variables empty functional here they
are and aren't variables empty modular
well if you hope with if you overuse
them and misuse them yes global mutable
state often leads to hidden dependencies
between objects and that's very very bad
on the other end I think part of the
appeal and the traction that SCADA has
for me is that it's this rather cute way
to combine mutable state with functions
and if you do that cleverly and wisely
you can get great benefits from that so
I looked at where in my last project
where did I actually use state so my
last project was a is a new compiler for
Scala called dot C and that compiler is
in principle it's a functional program
it's very close to a complete functional
architecture and the concern for for
doing that is on the one hand it's nice
it's very clean the concern of course is
will not that be slow and the idea of
this compiler is it's a compiler that
should be much much faster than current
Scala C so a slow compiler is not what
we wanted but on the other hand there is
a nice thing to say well if your program
is purely functional then it actually
gives you a lot of new optimization of
possibilities okay
opportunities that you wouldn't have
otherwise the first one is caching at
you say well if you have a function it's
a pure function it will give you give
you the same result every time you apply
to the same arguments well if the
function is expensive it means that you
can actually cache that you can memorize
the function as well the first time I
applied the function I put the arguments
and the result in a map and the second
time I need the function again I look up
the map to do that that could be a big
speed-up depending on how fast or slow
your function is
but caching is an art by itself so you
can't imagine you can't assume that your
language will do it all for you because
it will just give a single single
version of caching and that's often not
good enough so what I actually found in
the compiler is that the lazy vowels
that the language gives us but then
they're the memorized functions and
sometimes you put them in a normal map
sometimes in a weak map depending on
retention policies there are interns
names so that's sort of like spring
intern but for our own structures and
they even LRU caches too because here we
wanted to bound the size of a cache to
prevent it too from from from from
growing too large so all these things
are rather sophisticated uses of state
that in the end could remain completely
hidden the fact that you cash your
program aggressively doesn't change the
semantics of your program at all it's
still a purely functional program even
though it uses a lot of state in the
caches internally and we can verify that
because we can actually turn these
things on and off by configuration and
after that that way we can actually
verify that the program runs just as
just as well it'll be the same result
about much much slower if we turn the
caches off the second one usage that I
found was persisting so that idea is
that if you have a value in a map at
some point often the value stabilizes so
the value of the map won't change any
more if that value for that key will
always stay the same in the rest of the
program and then there you might get an
efficiency improvement if you remove the
value from the map and put it in the
object right there because the access is
faster and you don't have to the problem
of leaking memory that you have in a map
so that was number two
again it's unobservable if you choose
your time when you want to persist
correctly
third one was copy-on-write so they and
these the compiler has untyped trees so
that's essentially the the task of a
type checker is the takes a syntax tree
and it doesn't have types and it
produces a syntax tree and it does have
types and in the current Scala C
compiler essentially we did that by
mutation so these syntax trees they have
a slot for types and then there's a some
sort of traversal that
puts the type in the slot and that
pouring types in the start of course is
something imperative that's sort of the
traditional way it's been done in
compilers so far but it's not the purely
functional way because you can't just
put types in these slots so what you
want to do is of course you want to
transform these immutable trees to type
trees and there would be two different
data structures the problem with that
again is performance because these trees
are very very large these deep trees are
typically the largest data data
constructs in here in a compiler so to
copy them all just to add a type field
is inefficient and there you observe
well if you start with an type trees and
there's this type field sitting there
then the first time you sort of want to
give a type to the tree you might as
well reuse the tree you started with and
of course the second time you see this
tree in a different context and pieces
now right now that on type tree is a
different type you shouldn't override
your type that would be an observable
side-effect so at that point what we do
is copy and write you say a copy on
second write there's a different type
that you want to associate it with the
same an immutable tree at that point but
only at that point that's copied the
tree again it's a rather sophisticated
use of imperative state that's not
observable and finally they're fresh
values so fresh names and unique IDs and
if that's that's also something that you
it's pretty pretty standard so you have
to click generate fresh names and that
means you have just a global counter
that you're update and that your that
gives you a number that you add to your
name and unique ideas will work the same
way
and if you've done that if you've done
all that then actually it turns out that
we are left with exactly two variables
the two variables give you the current
constraint for type checking
so essentially but my constraints is for
type inference and the current
Diagnostics so the error log when I
write errors and it turns out that this
state needs to be version so there is
essentially a tree of possible
explorations where you can backtrack and
things like that so it needs to be very
strictly controlled okay now you could
say well all these are interesting uses
of state which you could hide but the
last one you couldn't that's really sort
of the essence the
essential state in in a type checker so
shouldn't you use a monad for that so
that's sort of the classical functional
approach nowadays if you have stayed
encapsulated in a moment well if you
have a look at that then that's what we
would have to do so that's what we do
now so that's two of the core operations
that we deal with as this operation type
which takes a nun type tree and an
expected type and gives you a type tree
and there's an operation is subtype to
pick another example which takes two
types and says it gives you back a
boolean weather one type is a subtype of
the other but I just pick in this mind
the real code base that sort of the two
most fundamental operations that I have
here so in the monadic approach because
both of these things can produce new
constraints and type can produce new
errors I would have to put them in the
type of state monad
so that means with a result now it's a
type of state of whatever else they
return before and under the covers a
type of state is in principle the
results that you return and the new
state consisting of these two variables
but you hide it in this in the state you
hide the state and they monitor any
monarch instruction okay so if you do
that then here's the typical use case
use usage example so what you would
right now primo narak in preborn attic
code something like that where you say
well let's see whether there's a type t1
is a subtype of the type t2 and that's a
type t2 is a subtype of the type t3 and
if yes then return some result with
monads of course you can't do that
because the result of each subtype
wouldn't be a boolean anymore it would
be a type of state of boolean so what
you would have to do is you have to have
to pull out the type of state you'd have
to pull out or in the boolean from the
type of state and deal with it
afterwards
and Scala is a very convenient syntactic
sugar for that for these monadic things
which is a for-expression it maps into
map and flatmap operation and you can
use it for any monad anymore that has
map and flatmap
which is which are monads so it would
look like that
but the question you'd have to ask for
self well how is this better this is
definitely longer you could argue it's
more in
narrative because I I see something that
smells like statements here right so
things that operations that return
results so in a sense I'm back to to
imperative programming only on a monadic
level and third it still doesn't do or
in the naive setting it still doesn't do
what I want because definitely here if
the first is subtype is false I want to
immediately return false not to the
second one and I think I can I can rig
up the monad with laziness that that's
true here but it's not the thing that
you would immediately immediately do and
that would be very simple or efficient
to do so for me the important thing of
function programming is not so much that
we hide things in Moniz but the
important thing was this we would use
the state to to VARs we were very very
economical with the Bears with us before
introducing one you really think hard
about it do you need that why do you
need that how do you version it that's
the important part the weather then
afterwards you say well I put this thing
behind essentially a type wall like a
monad is secondary and there are sort of
practical considerations whether
sometimes it's a good idea and sometimes
it isn't it is not so I think actually
this question of typing and monitor a
part of that it's very much a question
of trade-offs so I believe all these are
fine languages and none of them is right
in their approach necessarily so you
could choose to say well I don't really
want to talk about types at all in my
language it statically at compile time I
don't call the compiler does is
essentially it's a syntax checker that
verifies that my syntax makes sense or I
could say well I talked about types in
the traditional sense arguments and
results of functions and I have a very
flexible type system in a very precise
type systems that let let let me express
that or I could go further and say well
I want to also talk about side effects
like state what state modifications do I
have what I owe more efficacious do I
have and then when you do that and you
have the B Haskell language or I could
go in a different direction and I said
well I also want to talk about
properties of values
like whether this value is the same as
that value or this value is in and it's
given interval and then you get a
language with dependent typing like
Idris or you could go all the way and
say I want to talk about total
correctness so with my program I want to
have a correctness proof of my program
and then you have something like an
interactivity or improve I like or
Isabel and all these are valid
approaches and none of them is right
none of them is better than the other
and it's always a practical argument
until what
to what degree do your types help you
more than they hinder you by including
introducing additional boilerplate and
additional restrictions in in the way
you can cook and definitely most
programs aren't written as quickly in
Cocke as they are written in closure so
there's also a speed argument in a
productivity argument and Scala what
scarlet type system really is it's very
essentially it's firmly here so scara's
types are rather refined but they refine
the idea of having refined types is not
so much to be able to express a lot of
properties with them at least not right
now I think you might go there in the
future so but it's rather to say where
we have a very flexible alternative for
languages that don't use types that are
dynamically typed so we want to say
wherever we want we want to have a
language where the types are flexible
enough and expressive enough so that
they're not a big burden for people who
might otherwise have chosen dynamically
typed language that's why the type
system in Scala is rather refined and
the idea that we can actually move it
there is an interesting one but I
wouldn't
emphasize it right now so I think that
over the next five years or so there
will be exciting new developments in
effects to the to to express effects
there are jabrai effects it's a very
active research topics there's several
other research on effects and I believe
in five years probably will come to the
conclusion that no monads are not the
right way to talk about effects so
that's also why I would be very hesitant
to use monads for effects right now good
so I'm quickly go through the rest forms
of modules so we've seen seven simple
parts of Scala
and how can these parts then keep you
combined to write modules in the user
code in fact I believe that modules if
we talk about modules that take a large
number of forms so I am very open to
different ways to write a module module
could be a function could be an object
could be a class that means a template
in which you can have many objects it
could be an actor it could be a string
transform could be a micro service so it
depends on what you want as long as a
module is something that is simple and
where the ID focus lies on the way mod
the module can be combined with others
for me it's a module so a module is
something that exists primarily to be
combined with other things and less in
isolation for what it can do so SCADA is
a fairly modular language it's modular
roots are modular too I mentioned that
already it's first language I programmed
in intensively and the first I wrote a
compiler for a long time ago modular 3
was also very interesting language
introduced Universal subtyping haskell
from haskell scala picked this idea of
type classes which and made them more
modular by transplanting them into
implicit parameters and I believe the
biggest influence and the initial
announcement on the first slide really
pointed to that was SML modules so Scala
really inherits a lot of ideas from SML
modules as a rather direct
correspondence to say what SML calls a
structure we call an object a functor is
a class with parameters a signature is a
trait abstract types are the same and
what SML calls are sharing constraint we
call a refinement so the features that
scarra has for modular programming i
believe our first a rather rich type
system that gives us the vocabulary to
talk about the things that go in and out
of modules then I believe static typing
is a very important tool to verify
encapsulation then you have the
essentially core abstractions for
modules objects so that's essentially an
atomic module a class that can be
parameterized and be exist in many
instances and at write that is
gives you a slice of module of a module
API and that can be essentially combined
with mixing composition with other
slices so classes is parameterized
trades are slicing and then there are
abstract types and abstract types are a
very powerful way to actually to
abstract things to make them more
generic more general so a good example
here is a graph library where which is
actually amazingly hard to do that you
know in a truly generic way so here's
something that we had in recently in the
ACM communications in a paper where we
had our own stab at producing a graph
library so what we would do here is to
say well there's a trade graphs which
says well I'm talking about graphs now
and talking about grass means I have to
have a type of nodes and a type of edges
but I don't know what they are there
could be anything at nodes and edges I
only know that I have an operation print
assessor that given an edge gives you
back a node and successor is the same
thing and then I have a graph which is
again an unknown type it could have any
implementation but I know it has these
methods so that's this graph stick upper
bound of graph so I know for a graph I
can find out what are the set of nodes
what are the set of edges for a given
node what are the set of outgoing and
incoming edges and finally the set of
sources the set of sources of a graph so
that's my essentially to establish my
vocabulary to say well that's what we're
going to talk about now and then if we
want to write a simple graph model then
that's what we could do we could now say
well inherit the straight graphs and
slot in the type of graphs so here with
the type of graph was something that I
haven't told you I just told you it will
support these methods so what we say
here is now we have a concrete class and
it has some nodes and it has some edges
which I pass as parameters and here are
obvious are by very inefficient
implementations of the three remaining
methods so there's a powerful principle
here at work and that's when when I
start with this I have several have many
things which are abstract
Edge's previous as a successor in graph
at any point I can say well now and now
certain things and I define those and I
don't still don't know other things I
had just leave them abstract just define
what you know leave abstract what you
don't it's a very powerful principle
that in Scala works universally for
everything values methods and types so
in this abstract model I still haven't
told you what a note and what are the
edges but I don't have to it works
exactly the same way so if I want to
give you the concrete types of nodes and
edges and that's what I could do I could
give you a concrete model again extends
graphs and here and now say well a node
let's say it's a social graph it's a
person and an edge is a pair of persons
and here are the implementations of
successor and predecessor so that's just
one particular instantiation of that
which I can mix freely with my abstract
graph model and that gives me the
complete implementation so what's
interesting here is that the same
principle can be used for encapsulation
so arguably that's a case of
encapsulation there's a type node but I
don't tell you what it is and
parameterization so here I've given you
the type in the concrete model so that's
what I would usually do under the name
of parameter so it's a very powerful
principle that you can mix those two so
talking about parameterization generics
of course is a staple of typed languages
now everybody has it and so it's callous
or parameterize types it's very
important there's this sticky point of
variance which I probably if you have
written Scala you know what that is it
depends how whether a set a list of
apples is also a list of fruit or not if
Apple is a fruit and it's a list of
apples of a list of fruit so in SCARA
similar to c-sharp we express that by
annotating the declaration point with a
plus here for covariant whereas other
languages like Java would force you to
do that at the usage point and that
typically gets more complicated one
interesting bit here is actually that
the two things parameterization abstract
types can be combined or more precisely
parameters can be mapped in
abstract types and one other interesting
bit is that that actually explains what
this variance thing is about so just to
show you what that is parameters can be
mapped into abstract members whether
they are types or values doesn't matter
and arguments then are refinements so
let's have a look for how that works so
here we have our class set and I would
say well instead of parameterizing it
let me just give you a type field here
so it's it has a type and I manner the
name slightly because I don't want to
essentially produce producer name
conflict if several classes are
parameterised with T so then a set of
string would be a set where now I define
what this type is type T equals string
so that shows that this thing here can
be treated as syntactic sugar for that
thing here my language gets simpler then
for lists I would do the same thing but
because lists a covariant a list of
number actually is a list where my type
T is a number or a subtype of that
because lists of integers are also
possible as lists of numbers and that
means my element type is actually just a
subtype of number so it gives me a
rather nice way to express a lot of
different features and map it into a
common core okay and number seven and
last one would be implicit parameters so
implicit parameters we're sort of
initially thought to be a poor-man's
type classes that was my first
characterization for them to say well
Haskell has classes and type classes and
instances and we have all these things
in object-oriented languages so all we
need to get type class functionality is
implicit parameters so indeed they can
model that so here you would have a
minimum operation that works for all
things that are ordered so you just need
to give an ordering and that's implicit
so the compiler will do it for you and
you can then express a minimum a minimum
operation over that set but they
actually can express a lot more than
just type classes so for instance they
can express a context so a context is
something that essentially everybody
should get to see and sometimes it
changes but most of the time you still
you
you keep it the same so at some point
the context changes but most of the time
it's the same and that's again a very
useful use of implicit parameters that
by the way is that's how I nowadays do
dependency injection I think that's
that's the ideal way to do that this way
and finally it can express a capability
where you say for instance if I need to
access a customer ID then I need some
admin rights so I need to demand that as
a parameter and again it makes sense to
make that parameter implicit because if
I have admin rights and you need them
and I call your operations then that's
all we need to know the precise way in
which I passed this parameter to you is
boring and clattering if the important
thing is I have it you need it and that
means we can pass the capability along
and that's okay okay so to summarize
simple parts everything is an expression
everything can be nested compose and
match with parametric recurse function
values immutable collections and VARs
for me that's it that's the seven things
that we can keep in our heads that
represent the the core of what I see is
Guara and in the modules we have two
things that I talked about so the other
parts then there's actually much more to
Scala than that and a lot gets written
about the much more parts there are
things like implicit conversions
existential types structural types Hayek
Anna types macros and all these things
for me they are far from being the
simple core they are not the simple core
and in fact if you look closely then
they're not even in the core language
because to enable any of these things
you need a language feature flag so you
have to say for instance import language
dot existential x' before you can use
these existential types and my advice
would be well don't just avoid them
unless you have a unless you have a
clear use case often the use case is you
want to use scar as a DSL for some other
language and that's ok but if you want
to say well what is the core of
functional programming in Scala what's a
core of modular programming in Scala
then that's not necessarily it ok thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>