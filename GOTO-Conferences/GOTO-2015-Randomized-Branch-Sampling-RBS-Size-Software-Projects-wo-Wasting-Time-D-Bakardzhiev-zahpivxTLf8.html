<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Randomized Branch Sampling RBS: Size Software Projects w/o Wasting Time • D. Bakardzhiev | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Randomized Branch Sampling RBS: Size Software Projects w/o Wasting Time • D. Bakardzhiev - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Randomized Branch Sampling RBS: Size Software Projects w/o Wasting Time • D. Bakardzhiev</b></h2><h5 class="post__date">2015-10-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zahpivxTLf8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">everyone today we will be speaking about
randomized branch sampling but first
like I have to remind you to engage and
range and rate this decision and so so
what what is the what is the the purpose
of speaking about forecasting projects
project size so when we start software
development at least in my experience
the two questions that I I hear all the
time are how long and how much how long
will it take and how much will it cost
us to deliver a piece of software and in
order to be able to answer those
questions we need to know how much
software will be delivering right when
we have to have a way to quantify this
how much and usually that this we call
it like sizing so sizing in this
presentation in this context is is like
for us to to be able to quantify the
size of the project a piece of delivery
and not to focus the effort needed for
delivering so these are two different
thing because things because usually
when we say sizing we usually think it's
a it's about how how much time right did
some unfortunate i would say and and
it's what i want to emphasize on that
size estimates the probable size of
piece of software while effort
estimation estimates the effort needed
to build it will be speaking about
sizing here in agile in a gel we we
usually use t-shirt sizing and story
points O'Doyle initially back in the
previous century when
they started with software development
they were using lines of code written
and then it was function point analysis
which actually even made it to be
codified in several ISO standards but
again in agile we are using t-shirt size
ink story point too short sizing kiss
it's very easy to start with as
especially for for immature teams one
thing with with t-shirt sizing cadets
it's not additive like readily additive
we can add it up by substituting sizes
with numbers but it's in short it's
difficult to say that our project is big
like two M's 3 l's and something like
that right that's why most of the times
people we are using these people are
using close story points and story
points here is presented by my cone for
instance he claims that story points are
about effort about time about ours again
in this presentation we will be using
like sighs in story points only a tomb
tomb in complexity in in any way some
complexity right but not about the horse
so when I say story points it will mean
relative size and not relative effort
okay that's just in the context although
I know people that actually claim that
my cones definition is not correct at
all and but it's it's depends on the on
the team so for us like because
software's i think is different from
software fault estimation when i speak
size and story points it will mean more
or less complexity in income bond people
what people are doing their sizing kin
just counting the number of stories
for instance some some people use they
count the number of tasks but in general
whatever we count it is the the way the
way it is supposed to be done is the
like we have to identify all like we
have a product or a piece of software
that we need to deliver we have to break
it down into epics or bigger chunks and
then we have to break down each epoch
and story boy it's been stories and then
we have to analyze each of those stories
into story points and then we sum up and
we end up with the total size of the
project which is time consuming but not
only time consuming it's really most of
the time it doesn't make sense because
requirements change context change its
and it will read it it will not work the
effort right for analyzing a bunch of
uncertainties right and especially when
we have to make portfolio level
decisions for instance which projects to
work on to accept to commit to or to
make quotations to our customers like
spending such an effort it's people
don't do it literally and that's why I
was looking for a way to speed up this
sizing activity and I had thanks God I
found like a technique which is from
originated from horticulture estranges
it is not sure why it's moving but I'm I
have to move it back all the time the
slides so this this gentleman is Code
Red Raymond Jason and in the 50s and
1950s actually he established a method
for
a technique for efficiently for
estimating the total number of fruit
found in the canopy of a tree while
counting to select part of the canopy so
it is it is a method still be still in
use today in horticulture although they
don't use it for orange trees as
originally they use it mostly in
estimating the total biomass of trees
including like everything not only the
fruits but it's still being used mostly
in Europe I would say like people are
interested in biomass or something like
but anyway it's very useful it is a it
is it is a multi-stage an equal
probability sampling which is I would
prefer in the context of this
presentation I will not focus on the mat
I will focus on the applications the mat
you will be able to read if you are
interested in the day's an article in if
you can i'll show you 2 i'll show it at
the end and all the mat is there right
so here just focus on the applications
i'm not sure what most of the time
people just don't like Matt anyway so so
what is the idea so the idea is that we
we present a product backlog as a
branching system so that's a that's a
fictitious product so we have some bike
lock we we have broken it down into
three epochs a B and C and a PK has two
stories a pig be has another two stories
a pixie here's a CL here's another three
story so that's a fictitious product
backlog and it's it's a branching
structure and because it's a branching
structure we can actually apply our
beers to this structure this is the mat
it's called Horvitz Thompson estimator
and it works actually it works by
computing the unconditional selection
probability for four
terminate terminate shoot which means
that if we start from the if we start
from the trunk which in our case is
product backlog and we just pick a part
into the inside the branching structure
inside the tree and we calculate some
probabilities for a terminate shoot
where fruits are located that's in short
right and it's how it looks it's a so we
have this disguise of a structure which
we have the product is the trunk and
then they pick let's say are our
branches and then the terminal shoots
are where the user stories are and the
fruits in our case might be story points
tasks whatever you think of right any
what what it does actually it's it's a
it expands the size of the story x the
size of the epochs in order to find out
through the total size of this rectangle
but again let's not focus on the mat
here what's important in it that was the
Jenner the main question when I actually
started playing with data using car
basis why rbs works for sizing software
development projects so this question
stands because when they apply it in
horticulture they estimate something
which is there right you go to a tree
and the number of fruit on the tree in
the canopy of the tree has a here's an
objective value in current abstracted
from its interpretation objective value
number well there will be accounting
error right if we count all the fruit
but more or less it's the same number
right when we apply our bees to our
product backlog there is nothing there
right there is nothing this
this size is we call it is the proxy for
all the functionality and capabilities
that we will be delivering eventually in
some future point I see the the
difficulty here at how to apply so so
the question is from what universe we
are sampling there is nothing there
right and then and then when I apply it
like I used real data and it show that
actually it's it's applicable and and
here is my my explanation right so the
assumption the assumption behind the
assumption behind you think our beers
for software development is that the
project size depends on the context in
the context is a very broad concept but
it includes the customer the people
developing the product in the
methodology they will be using when
breaking down the product into I pick
stories whatever they do and if there is
such a methodology and they apply it
consistently and the methodology itself
is cohesive again that's a very
important it's cohesive then somehow and
it's we used to see with the data later
on somehow we are able to find something
tangible in the future because people
are applying consistently a cohesive
methodology for breaking down an idea
into chunks so that's that's the
difficulty here if you have just an idea
and you have no data to prove it right
it's it's nothing right I mean it's just
a fiction and I'll show you some
applications so the most important
application not sure what it is doing
this but the most important application
at least the ones that the one that I
find it most in the most important is to
to check if if our team is applying the
methodology consistent so if we follow
this idea that we are actually checking
an application of a methodology in the
methodology doesn't matter what the
methodology would be it could be
planning poker it could be behavior
driven development it could be featured
driven development it could be even
probably function point analysis right
if there is a methodology and you see
with the data we can actually claim and
check if the methodologies had been
applied consistently so the first
application is that if we have some
historical data for our team or teams
with sizes let's say they are sizing
each and every sprint and we want to
check if the team members actually are
not generating random numbers for dell
for the size but are doing something
right thinking and sizing right we can
use our BS to check this we can use our
beers to see the effect of a coach for
instance if we if we if we hire a coach
to teach our team into a planning poker
we can compare before and after because
we are comparing we are we're sampling
from from an application of methodology
in here I might get in something like a
bit like fairy tale but you'll see the
data later on so that's one very
important application and what I did
last year I asked like a frenzied scrum
do scrum do is a tool for managing scrum
project
incumbent project with mostly scrum
projects cranbourne project these days
and I asked them to provide me with some
random data so okay they have plenty of
teams there plenty of teams plenty of
projects and they they were able to
reach an agreement with some of the team
so that we can use the data right of
course it's on under my anonymous right
but so we actually we got 13 real
projects from 13 different teams and i'm
not sure what they are doing i really
don't know what they are doing but what
is common for this project is that old
all projects they have they have epic
story task breakdowns they have
successful release history and they they
are stable teams so they work for a long
long time together and they have an
active scrum to coach or scrum master
this is very important because remember
we are discussing here application of a
sizing methodology right so they have
something somebody there which actually
is guiding the team and actually
controlling this these are commercial
projects and they have like a minimum
size of 12 epics right so that they are
not that small right so see these are 13
randomly picked projects and what I did
I got the data so they have their sizes
for releases in sprints and I decided
let's let's run RBS on their real data
and compare the estimate the forecast
with actuals just to see if actually
days there is something in our base
right so that was lost you so see here
it that's that's sorry mhm this is
stories of gay story points not sure why
it is doing this so so here what we have
on the x axis we have the estimated
project sites in story points for those
13 project the y axis we have the
actuals so again what i did i took the
actuals i sampled which means i picked
using car base of only a small subset of
all the user stories those teams sized
last year i got a size for each of the
project and I compared the estimated
size with the actual size and I here oh
well it's it's mad anyway but you can
see this R squared over there like it's
a it's called a correlation coefficient
and if it's if it's close to 1 it means
a very strong correlation so here we
have 0.6 97 which shows a very strong
correlation almost like impossible if
like it's a really strong correlation
again these are 13 different teams 13
different projects I really don't know
what they're doing and it shows that all
13 teams have a very good application of
a certain methodology for when did sighs
their projects I really don't know what
they are using I haven't worked because
the other data is on anonymized I cannot
go and ask right but that's not the
point the point here is that because
again if you if you if we get back here
so these are stable systems they
definitely apply some methodologies they
have a coach for to guide them so they
are stable and they do something on
purpose it's not random numbers
definitely these are not random numbers
so again this is one of the application
so if you have if you have teams or a
team with a certain history release
history very easily you can actually
check if they are applying something or
they're just like well we always assume
that people are doing their their best
and they are not cheating right but I'm
when I when I say consistent application
of a methodology you may not apply it
consistent because you are not well
trained right you are you just don't
know what to do so we are not speaking
cheating here we're just comparing what
the people are doing and if if what they
are doing is consistent whatever they
are doing so if you have teams with
release history you can check if you
have teams and their release history
let's say it's not like the correlation
is not that strong and you may think
about draining them you can check after
the training what the effect is now
because these teams actually they they
had also they they they they used tasks
and this is the correlation when we when
we estimated the number of tasks with
the actual number of tasks and you see
the correlation coefficient here is not
that drunk it's only 0.7 lights on 93
let's say again it's a very strong
correlation
and the first thing is like the number
of stories because again in some teams
like incumbent we just count the number
of stories and I run RBS to see if the
actual number of stories will match will
correlate with the estimated number of
stories and again very very strong
correlation so what this means is that
by using car base with a simple sampling
we can very much forecast the size of a
project deliver and again here and I
have data to show it's not only about
projects it can be applied even if you
here for release no I pics at all let's
say a hundred user stories and it worked
the same way because it's again a
branching structure we have a release
releases the trunk and all the user
stories are the terminal shoots right
and actually I used AC Esper's data for
this because it's that so so this is one
of the applications right so these are
the conclusions from scrum do comdata
first of all all 13 teams consistently
apply the methodology for slicing the
requirements into the stores and sizing
them using story points and tasks that's
the conclusion so very good for those to
all those 30 then the the quite
important conclusion is that they
somehow managed the emergent and I
change risk requirements you know when
we start a project the scope usually
grows and some people call it like scope
creep other people call it like learning
now but anyway the scope usually gets
bigger so they somehow managed and that
the third and most important like
conclusion is that execution is
more important than planning because
here with our bees we don't speak about
we don't speak about like planning on a
daily basis we use our beers only for
let's say a high level or a budget level
planning right in order to make a
portfolio level decision again
quotations to to check if the teams are
consistently apply and commit to dodge
and things like that we don't use RBS
when actually we start executing the
project but the team if we're if the
team is really agile and actually they
did they don't start with a full backlog
or let's look like a bunch of work right
it's it's the team that will will have
to continuously and consistently apply
the same sizing methodology and that's
why execution is more important than
planning this is just planning here
right so here don't don't think that
it's like that's the Holy Grail or
anything like that it's just a very
useful tool to start a software delivery
or to compare different sizes again if
they come from the same team right but
it is it you said at this level like
it's very high and then it's up to the
team to deliver right and then of course
the next application is for sizing new
projects and we can size for instance we
can estimate the total number of user
stories in a project so in common use
really that's what we are interested in
we are interested in the number of
stories we can then apply our best for
estimating total story points as I
showed and then we can apply it RBS for
estimating number of tasks and we can
estimate the number of BDD scenarios in
the project that's what i am using it
for because when I my teams usually with
they use scenarios which is almost the
same
right i mean that's the same idea we can
apply to I don't have data for function
points but i'm pretty sure that it will
be applicable there as well if somebody
is using function points i know people
are using it at least in the United
States and GOG project it's mandatory to
use to use function points and here like
a bit of Matt right just to to show I
have 30 minutes so we have plenty of
time so again here we want to estimate
as the number of stories in our project
and we have a product and then we happen
we will break it down into epics and
then each epoch we will break it down
into user story and that's our branching
structure and it's like just for the
sake of clarity that's the same
structure right so we have an apple tree
and we have the trunk and then we have
branches and what we are interested in
are the terminal shoots which are the
small branches with the fruit on them
that's the mapping so product is that
it's the trunk epic is the branch and
user stories of terminal shoot and here
is the formula right there is no need to
remember the formula again there is an
article in you and I'll show you
some excel stuff but so it's it's a very
simple formula in order to to estimate
the number of user stories we actually
we we follow this particular algorithm
and why it's moving ok so first first we
divide the project scope into epics so
that's mandatory so if we have a product
or a project that will hear 4000 epics
we have to know there will be a thousand
epics right if we have this structure
which is product backlog epic stories
right so we we have to find the number
of epics that's it only the number
without any analysis just the number
then we randomly sample one of the epics
which means really at random so the key
word here is at random so we cannot
sample the most riskier or the easiest
or whatever we want it has to be at
random so random means at random and
then we analyze how many stories are in
this epic which means that we have to
break down this particular I pick into
stories just break it down and then
using the formulas I showed we
calculated the estimate of stories so
this is for stories and then we repeat
the points from 24 7 between seven and
11 times that's a seven usually works
and then we can estimate like the same
rbs.l applied for estimating total story
points in a project again this is our
this is our branching structure and here
what we have is like we have the project
and epic then the user stories and then
we have the fruit at the bottom which
are the story points and then again it's
the for clarity so the mapping he is
drunk is the product of branching the
branches are epics user stories are
terminal shoots and story points per
storia the number of fruit on the shoot
that's how actually the these are the
algorithms used for the scrum to data
the same oh and i'll show you next so
how it can be done this is the mat and
this is the this is the algorithm so we
first again divide the project into
epochs that's a mandatory step and many
people say well if I if if there will be
a thousand epic so it's a lot of work
yeah it's a lot of work but is there any
other way I mean if you go story by
story you'll have to break it into a
pics anyway right
so if you have a project of thousand
epics it's a lot but it anyway it will
save you a lot of time then again we
randomly sample one of their pics then
we analyze how many stories are in this
epic and will just write down the number
of stories and then we rammed an example
one of the stories only one of the
stories for this particular epic and
then we estimate the story points for
dead story only for this particular
story we have to analyze we have to know
story points and then we use the formula
we calculate the project sites for this
particular epic then we do it between
seven and eleven times again and I'll
show right now in Excel so what is the
sort of conclusion so RBS's is it's a
sizing techniques for forecasting
techniques for sizing software projects
without prior prior identification and
all assistance Isaac of every single
user stories project size may be
measured in story points number of tasks
be deduced another's whatever function
points whatever as long as there is a
methodology being applied it can be used
we found like by running car based on a
historical data we found that there is a
very strong correlation between the
forecast and actress really strong
correlation and of course using carb
days we can we can ask answer the
question how much software we will need
to deliver some point so here is the
here is the article and I'll go there
and I'll go there just for you to see so
here is the article you can go in and
read all the math it is a lot of mud all
the formula is here sample calculations
and then watch like the scrum do data
and then what's important is here at the
bottom it's
I'll show you the the scrum do data and
it is at the bottom when you click like
the click the link and then you go to
the bottom of this article it's from
their site right because that's their
data at the end it says the results and
it goes to google doc spreadsheet so all
these 13 projects if you want to check
how it's done again it's like it's a non
mi so X come on 234 like you can go on
and for each and every project so here
is the data here is the data here is
thus the calculation itself for each of
the project which of the projects and
then we go to the end no todo to the
first slide where the summaries the
results are also that the red here are
the results again on the x axis we have
the estimated size on the wire on the
y-axis we have that choice so we have it
comes from this Doug tools and
estimating is he they are not the same
see the actual size is not the same with
the estimated size and it might be a
disappointment to somebody but again
it's an estimate it's a forecast and
again during the project execution there
most probably were new requirements and
changing 0 requirements but anyway
what's important is this the correlation
it's a very strong correlation so if you
have let's say like 13 releases for a
team you can you can use this the same
Google Docs document and you can
actually send me questions if you have
like my I prefer like
direct messaging come on Twitter because
my mail address is very long so my name
is Damita bugger Jeff it's like it's
it's impossible to communicate so
Twitter two things better and you can
see like let's see what's the difference
like the actual is 5733 and point five
story points the estimated is 500 297
254 here is a big big a difference here
is a very big difference he is like for
a very small project it's almost no
difference see but they are not the same
and we are not expecting the numbers to
be the same yes
this point you mean well it's done
automatically it was its debts that's
the point 3040 something 9000 yeah
that's the point yeah I have it in excel
as well into the same correlation I mean
that it is what I'm not sure what but
it's the same correlation I mean that
the table comes that this diagram comes
from here and you can check it yourself
again go to the article then go down
then click on the scrum dual link and
then go and see the data is there you
can check it yourself if there's a bug
in google spreadsheet then there is the
same bug in excel yeah I can I can show
it in XO as well so that's again we are
looking for correlation right we don't
expect the same numbers it will be
absolutely impossible if the numbers
were the same I would be the first one
to say it it's a fraud right it's
impossible to be the same only due to
the fact that they are emergent
requirements it's impossible to have the
same numbers but we are very close and
again this is not for detailed planning
to bet your house on this it's for
high-level planning right because if you
have a new project coming and you are
not sure can you fit it in your
portfolio and you can do this
calculation for 10 minutes literally and
again budget budget estimates according
to p.m. i seventy percent accurate it's
it's it's more than eighty five percent
accuracy again for me it's useful then
what I'll show you next yeah so here's
of an excel file that Martinez Braley
prepared based on the article any and
i'll show you how it is to be done so
here he is probably using it in in his
own projects anyway so we have the
number of APIs in this these are
absolutely random numbers right it just
for illustration than the method so we
have a hundred epocks and we will be
estimating in store
points what we are doing here you see
the formula we add we add picking at
random one epic number so we have 1 2 3
4 5 200 and we are picking one axle is
picking one 11 times so these are the
epics we pick at random which actually
means that we have to have this hundred
epocks at least with their names in
front of us right we have to have a list
of epics that's a mandatory step and
then because the way excel is doing if
whatever whatever change I make these
random numbers will change right so what
we are doing we are coming here we are
copying this thing here and we pay stink
lonely the values anyway is if I am
paste it we paste only the values and
then we go there and we the next step is
break down each of the sample epochs
into stories and for each of the sample
epics we are breaking down they pick
into stories so we are doing first of
all we are so done so thinking from an
effort perspective so we have to first
break the product into a hundred epocks
which probably will have to do it
anywhere you later but that's an effort
right and then 4 11 of those hundred
epocks we have to break it down into
user stories just break it down and then
that's the estimate of the total number
of user stories in the project thousand
682 so if we have to break down the
whole project just arrived at the number
of stories only we will have to come
like eventually we'll have to have a
list of a doubt fifteen sixteen hundred
user stories now with it like a very
very limited effort we arrive at the
same
again it's a it's a forecast and right
it's a forecast execution is most
important than more important than
planning right so now we have this the
number of user stories then we randomly
sample one story from each epoch and
again it's done in depth Excel right we
we sample one just a number of the user
stories like one two three or five and
here the the number the indexes of the
user stories and we copy and paste only
the value so the texel will not like
generate new numbers all the time that's
how it works and then we go and for each
of the wrist for each of the randomly
sampled story we only for that
particular story we will do any kind of
analysis or sizing correcting only 4 11
stories in total we would be doing any
kind of sizing up to now we are just
breaking down right we are not sizing we
are not Anna like we just break although
it's again it's it it's a process in it
should be a methodology fold for this
but again it's not analogous it's not
sizing and then eventually that's the
total number in this case it is almost
11,000 users tourism
again it's these are fictitious numbers
just to illustrate them the method if i
put the real numbers it will be for real
project okay so just think about like
just to come up with this number what I
never would be how many days I really
don't know I've never done it so i
really don't know like estimating so
many epics anyway and that states the
think we can do it the same if we don't
have epics if we don't have literally no
key of epic so just using the same file
so this time this is actually this is
yes / one of the iceberg projects and it
hit 92 stories of something I we don't
record and again we sample this time
only seven right I decided to be like
smaller number seven out of this 92
epics actually did they are no tip is
they're just stories or pieces of
functionality right but because i'm
using the same XO file it's right now
it's epics but it's just pieces of work
and then for each epoch we say that
every epoch sl1 story right which means
that we don't have stories and we have
so that's the estimated number of
stories which actually is the same as
the number we started with which is
expected right but it's not our goal we
want to know the size of this thing and
again with at random we pick one of them
which is against seven stories we
estimate we analyze those seven stories
only seven out of seven of 92 and that's
the number of story points so for that
particular project the actual number was
774
I know nothing about the project neither
the project nor that you might know
nothing so there is a difference five
percent difference between actual soon
forecast well it is what it is right we
cannot be like on the spot but it's five
percent quite good I would say so so
here we have four minutes 44 questions I
believe right I can take questions we
here for more minutes right
because when I use the data the effort
along with the size for any kind of
projects I found no correlation between
the number of user stories or the number
of story points especially between the
number of story points and the effort or
the delivery time if your project if you
when you it's it's a very easy thing to
do just plot the user stories for the
project like for each story and then the
time that it took to deliver and if
there is a correlation then you can use
the same method for forecasting the
effort if there is no correlation which
I bet there will be no correlation
unless you have very small team with a
very high flow efficiency coefficient
which is like like how come knows what
many people hopefully no there will be
no correlation so I always try to be
rigorous and if there is no evidence
that actually can apply to effort
estimating then I will I will say we
cannot apply if you can do it you have
more than welcome it will be a
groundbreaking effort or event like but
even the size as such is very it's very
important right and it's that's probably
the answer to this question
so so i'll be running a forecasting
workshop in paris in on november second
at lincoln bang france so if you are
interested to see how we can use the
sizing and then estimate the effort and
the delivery time it's a it's a
different story but it can be done right
it can be done but it's not for today
and there are other ways like you how i
do it i run monte carlo simulations
based on historical data about delivery
times right that is suitable for for RB
it's not suitable for RBS like it just
like it is the other way around so and
they'd say they'd it's a big question I
have personally experienced like I go to
a team and say give me your data and
I'll run RBIs and i'll tell you if you
are consistent they never provide the
data right because this Darby eight is
like a mirror like it and it will
reflect reality if if there is no
correlation which means that they are
actually following they don't fall enemy
to dodge right and the reality will be
ugly and people we as humans we don't
like ugly things we don't so the mage
the main obstacle to you of you think
matrix in general my point is that
people don't want to see the truth so to
answer the question it is not that our
base is suitable harpies will show are
you following anything or you are just
be generating random story points
because somebody asks you to do this
right or tasks or whatever you do
I
well I have some like people I know so
they're working Connor like 200 million
projects for Department of Defense and
they claim the agile and they are and
they there is no way to shrink 200
million into two million right so if
reality is big if you have big projects
that's it you have big project and you
can still be agile because I jalate to
the size it's the way we approach the
issue right it's not about the object
it's about how we approach it okay okay
thank</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>