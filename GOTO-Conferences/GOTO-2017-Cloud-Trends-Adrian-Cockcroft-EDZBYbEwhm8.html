<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • Cloud Trends • Adrian Cockcroft | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • Cloud Trends • Adrian Cockcroft - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • Cloud Trends • Adrian Cockcroft</b></h2><h5 class="post__date">2017-10-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EDZBYbEwhm8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well thanks very much it's great to be
back at go to conference again I'll be
doing this one and Copenhagen this year
so good good times and I'm good to meet
so many old friends here as well so this
is what I'm gonna talk about talk about
culture because this is one of the key
things that changes when you go to cloud
the migration and how people migrate to
cloud in particular the way Netflix did
it and then some things about untangling
the data tier because I call the new D
normal denormalizing that leads to
monoliths to micro services to functions
to service and then I'll end up talking
about the things I'm currently working
on and focusing on which is around open
source and artificial intelligence so
culture this is this is a nice summary
of why culture matters if you want to
build a ship don't drum up the people to
gather wood divide the work and give
orders instead teach them to yearn for
the vast and endless sea then there
build a better boat than the one that
you had in mind right so if you have
people that really are committed to a
purpose they will figure out
collectively how to build a better
product and how to do better work than
if you try to centrally control it
this is from this quote is directly from
the Netflix culture deck it's something
that Reed Hastings picked out as an
example of why Netflix is able to do
things and do things more quickly and do
things better than their competition
because everybody is aligning themselves
to the purpose not being told centrally
what to do however there's quite a few
other culture decks Nordstrom has a good
one this is from Nordstrom's technology
culture day and they boiled it down to
one thing and this is an interesting
thought use good judgment in all
situations and this is the essence of
what you want if you're trying to fill
that builder culture a lot of cultures
come down to judgment and what I'm what
i mean by judgment is if you put someone
in a situation and you give them enough
time to think and the correct context
the information they
should make a good defensible decision
that's good judgment that's the exercise
of good judgment but what we do in big
companies and sort of traditional
centrally managed companies is that we
put you in a process and your job is to
follow the process and if your job is to
follow the process then when something
happens that isn't in the process all of
a sudden you're supposed to figure out
how to use your judgment but you haven't
had any practice of using your judgment
and so the trick here is to not have
processes not have rules but have
everyone collectively deciding that
we're going to do things roughly the
same way because that is our
collectively we all have the same good
judgment we all have the same contacts
context and we all have the same purpose
so if you look at some of the things
that if you look at what Netflix is
doing and the way that those cultures
work and the kind of some of the ways
Amazon works what you see is what looks
like processes but they're actually
artifacts of systems of people just
following good judgment so think about
how judgment applies to the culture of a
company when you when you're creating it
so the Netflix culture looks like this
it basically says that the culture
itself is important that's why values is
what we value high performance and
freedom and responsibility is really the
core here that's the one that we really
keep coming back to from the Netflix
days what that means is it's a trust but
verify we're going to trust everybody to
do the right thing but we're going to
check that they are doing the right
thing so you know that somebody is going
to be watching what you're doing so
you're always holding yourself to a high
standard and that is the principle that
everything works on so that's an
interesting way of doing it that this
culture works for a start-up for a small
company Netflix is a very homogenous
company they deliberately have only two
locations in the world of any of any
size they have a fuse like one or two
scattered marketing people around the
world but they have engineering in Los
Gatos and they have content production
in Beverly Hills slightly different
cultures in those two places but
extremely concentrated everyone in one
building and everybody able to
think about what they're doing in a very
concentrated and homogeneous way the
Netflix has never acquired a company as
almost as Netflix itself is about 20
years old they have never acquired a
company which is crazy compared look at
all other companies acquiring companies
why doesn't Netflix it's because they
don't want to dilute the culture they
want to keep a very good they want to
acquire the best people out of a
competitor and not acquire the whole
competitor and all the baggage and weird
culture stuff that could come with it so
they acquire people one at a time
reprogram them to the Netflix way of
thinking about it that works for a
company of a few thousand people that's
grown up in the Bay Area where there's a
lot of people to steal people from right
so you spend five ten years a you know
Google or Facebook or somewhere and then
Netflix sales you when you want to go
and play with the you know the very
experience it's a small number of very
experienced people is what they're
targeting they don't have any graduates
there's no interns there's no very few
contractors it's basically a very
concentrated thing so that works for
that but you can't apply this culture to
a large multinational organization so if
you look at the Amazon culture Amazon a
few months ago I remember the last
number but it last time at number I
remember was 350,000 employees right
scattered around acquired lots of
companies scattered everywhere in the
world incredibly diverse culture how do
you put your arms around a culture like
that and still have it innovate and move
really quickly and be able to take on
the latest things that these 14
principles are taught to everybody at
Amazon but they're also used as a hiring
filter if you want to go work for Amazon
you have to internalize these 14 things
because the interview process tests that
you re you have got these ideas that you
live up to these principles and when you
go for a but when we evaluate bonuses
they're evaluated against these
principles and promotions and everything
internally so I could go to anybody that
works at Amin's any of any of those
350,000 people and start talking about
customer obsession or dive deep or earn
trust of others and they would know
exactly what I'm talking about it's a
it's a
gathering principle that gathers
together hundreds of thousands of people
into a single organization so that is
the power of having these cultural
statements so think about that because
this is what frees up the company to
innovate incredibly rapidly while still
having a single purpose and set of
principles and those principles are kind
of the things that are typically
blocking people when it when I talk to
executives for companies that are doing
the cloud migration some you have to get
this culture right otherwise your waste
your time you will be blocked internally
by because of your centralizing too many
decisions and what cloud lets you do is
decentralized those decisions because
everything is moving so fast that you
get to have the autonomy of self-service
so culture should be intentional it
should be appropriate and at the bottom
of all of these cultures is something to
do with judgment so think about how that
applies to your own organization if
you're creating a new organization be
really careful how you create a culture
it's much harder to change a culture so
I'm going to talk a little bit about
migrating to cloud and some of the
lessons from the Netflix cloud journey
and a bit of a few updates on this 2008
we had a shock we had a 2-day outage
where we didn't ship any DVDs it was
because IT had assumed that they could
make the systems perfect and developers
just had to us didn't have to think
about hardware availability everything
was just gonna work
they were gonna buy high-end Hardware
high-end software make it just work and
we could just implement our software
over the top and just assume that the
stuff underneath was going to work had a
silent data corruption in ass and it
just corrupted all the databases we
restored everything it corrupted them
again and you know the whole thing was a
big mess what happened out of that was a
change of assumption we questioned this
assumption maybe availability had to be
handled at the application level and it
had to be a concern of the developers
and we can't to bring it right up there
and think about it and then if we were
doing that could we use low-cost cloud
infrastructure to go and build that
rather than this very high-end very
curated expensive hardware we could use
off-the-shelf low cost ephemeral
hardware
and that was the mindset change that
came through so this was quite often I
see when people are moving to cloud
there is a an outage or a thing there's
some major kick in the butt that happens
to management though they start
questioning assumptions so that's the
beginning of a lot of cow journeys added
to that there's usually an existential
threat and for for Netflix it was that
we needed a massive increase in data
center capacity we couldn't tell how
much how where we'd need it and we
didn't have time to build it it takes
about nine months to provision a data
center and we had no idea what our
capacity needs or where we were going to
need it in nine months time and it was
because streaming was replacing DVD this
is happening across industries we're
seeing systems engagement dominating IT
used to be that IT was about looking
after employees and factories and maybe
point-of-sales terminals and things like
that but you didn't have your IT systems
scaled with the number of customers or
shops or factories you had it didn't
scale with the number of customers you
had now because our customers are
directly connected to our systems sort
of whether you call it IOT or Direct
Marketing or whatever we know about all
our customers so now we have IT systems
scaling with a number of customers you
have and that's why systems of
engagement are over running everything
else
my other favorite example is NEOWISE
Netflix like BMW what's he talking about
BMW make cars and it used to be that
once a year you would take your car in
for service and they'd probably get an
update saying this car is now at this
mileage and we fix this thing and
whatever once a year you'd get an update
about a car you built the current cars
are directly connected through an AWS
service back to BMW they know exactly
where they are they are downloading map
updates they are using the car as a
sensor this thing is called Caruso and
it's a car as a sensor they're finding
out about roadworks as they're happening
they're finding out about congestion as
it's happening and sharing it across
their customer base they're also
collecting a lot of data about how these
cars are driven so think about how much
traffic that is back in
to the central systems compared to
seeing a car once a year scaled across
all the cars you've ever built I mean
right now this is only in their sort of
seven series and working down the range
but that's what I mean by systems for
engagement dominating IT and you can
pick an industry you can play look at
how the Internet has let us connect
directly to our customers so the DVD
business for Netflix look like this
every once in a while you would say I'm
gonna pick up some DVDs maybe on every
Sunday night you'd say these are the
DVDs I'm gonna watch next week and you'd
put your TV's in the mail and new ones
would come next week and next weekend
you'd actually get around to watching
some of them and then you do it again so
the interactions were roughly once a
week a little bit of browsing so we had
a system set up to support this and we
had a decent size machines and whatever
but it wasn't really huge then if you
look at the streaming business people
start binge watching you know a whole TV
series in a day and then watch another
one then or watch another one and the
system isn't just doing picking them
it's logging the data it's saving your
cost quality of services being monitored
continuously there's a progress
heartbeat so if you stop halfway through
something they know where you are when
you resume there's a huge amount of
traffic going into the system compared
to the DVD side right so what we found
if we just pick up make some up some
numbers it's about a hundred times more
views per week it's maybe a hundred
maybe a hundred it's over ten times the
views per week and a hundred times the
number of requests per view even if you
just take those those are pretty
conservative estimates that means it's a
thousand times more traffic for every
customer that stops using DVDs and start
streaming all right so as Netflix
shifted from a DVD shipping company to a
streaming company this is what happened
that's our DVD capacity that's our
streaming capacity the point where we
were spending half our capacity
servicing streaming was when one tenth
of a percent of our customers had
started using the new capabilities right
that was when we had 5050 in our front
end web services and API services when
we'd hit a tenth of a percent so again
this is why we were going we
we're going to be the next Twitter fail
well you know internet meme and we
needed to figure out how to deal with
this does that give us a choice either
recruit world-class data center
operations people guess the capacity
we'd need and build a huge data center
and put a huge amount of money down
front into building that data center
infrastructure talking tens to hundreds
of millions of dollars size data center
investment here or use AWS where we
could pay for it the month after we used
it and put that hundreds of millions of
dollars into content that made the
product better and that's the choice
right and obviously the choice they made
was hey let's go buy another season of
house of cards or instead of building a
data center you know one of those makes
your cost slightly lower perhaps if you
do it exactly right and the other one
moves the business forward
that's the choice and that's the big
choice that lots of people are making
now as they decide they shouldn't be
spending time building data centers so
in 2009 I wanted to mitigate some risks
first of all understand how AWS and
prime were related and they were
separated there was a phone call between
you know Reed Hastings the CEO of
Netflix and FB Zeus the CEO of Amazon
tuff just what's this AWS thing is it
really separate and they're not gonna
feed all our data into prime and all
that kind of stuff they got comfortable
on that and then ever since then Netflix
has been used as the example by AWS of
yes you can run your competing business
on AWS and it's it's fine and Netflix
does it and other people do it and you
shouldn't worry about it the way Netflix
used thought about it was that we were
going to use the strengths of our
biggest competitor against them it's
like a jujitsu move right you tip over
you use the weight of your opponent to
make them fall over so we Netflixed it
turns out used AWS better than Prime
ever did to compete with Prime we did a
whole of the capacity experiments one
time we went and wonder what happens if
you ask for 4,000 machines at once well
get an order scaler said 4,000 instead
of you know four back we don't need
tried a hundred or so at a time and
about hour later 4,000 machines were
running so that was good
now this is in 2000
it's much easier to do that now but at
the time that was transformational the
idea could create four thousand machines
in an hour just just by asking for it it
was crazy
we signed up for an enterprise license
agreement because you don't want to be
running a bit major business on a
click-through license and a credit card
turns out and this was before this was
the first time AWS actually had an
enterprise License Agreement it was sort
of created by the first few big
customers going hey guys now we're not
doing this on a credit card and a
click-through and we did this publicity
story in the New York Times that was
kind of the launch the results of this
the story where people thought we were
crazy at the time there's no way we were
ever going to make this work that was
the prevailing opinion first thing we
did try out some things that were not
customer-facing that were not critical
we were coding movies and we didn't have
enough capacity so we moved it to ec2
that's where we grabbed these four
thousand machines to process this it
worked fine and then once we process
them we shut them down and it costs the
same amount to have four thousand
machines for one day is to have one
thousand machines for four days or a
hundred machines for 40 days we had 100
machines before in our backlog was a
month so we shrunk it to a day by just
having four thousand machines see the
finally the next thing was all of these
streaming services were logging back
into the system and our database that
was handling the logging of the quality
of service just got overrun by all the
streaming capacity so we moved it to s3
which is a really unlimited storage
space just just to give you a reference
point more recently we just ran a
benchmark where we created an exabyte
sized bucket in s3 just to run a
benchmark an exabyte that's a billion
gigabytes or a million terabytes all
right okay just if we we can talk about
that the actual thing itself but the
fact that we had a spare exabyte just to
run a benchmark tells you that this is
quite large and some of you might have
an exabyte and we have customers with
exabytes but it's a lot it's quite big
now 2009 it probably wasn't quite this
big but it's huge so unlimited space I
mean we've blog analysis and we used to
dupe to process this this is in 2009
using the EMR this is one of the first
where we said to Amazon you've got the
wrong version of Hadoop and you we need
this hive thing and we need these
feature set and they went ok we'll build
it up to the versions you wanted and
then we said if you do that we'll use it
so we kind of they they built the
version based on our feedback to make it
a usable stack of things to solve our
problem and then Netflix has used it
ever since so that's part of the
feedback loop when we do that with our
customers all the time you say well
really we'd like this thing and these
features and we go oK we've talked to a
few more customers pull it in and that
that customer obsession that's what AWS
runs on and that's why there are so many
products coming out from us so in start
of 2010 we decided not to build any more
data center capacity so we had to move
to the data center by the end of 2010 to
survive so we kind of went through and
we kept converting front ends out move
out front ends out to the cloud and by
the end we had our backends had grown to
fill all the space that was created by
moving the front ends out and our front
end was huge while we were doing this we
had this nice slide that we showed
internally it's like we really have a
deadline on this because we are not
going to build another data center and
Netflix you got a choice you either go
to fly in the cloud or you going to hit
those trees at the end of the runway
there's a limited runway problem we knew
there's a big increase in capacity need
to get through the end of the year and
we weren't going to build it out on the
data center so we had to move to cloud
so this forced march conversion was one
of the key things that made it get done
right it's another thing I see when
people doing cloud migrations you set a
real goal target you this data center is
being closed here it's out of lease it's
being shut down
you've got a hard hard stop those kinds
of things are what get these transitions
to happen we started with the simplest
possible API service then the simplest
web page and then just api's and pages
one by one and we did it by just doing
redirects so you'd hit the old went
that's hit the data center and it would
choose whether or that page existed in
the cloud and whether you were in the
right test cells and things and what
percentage of the customers we want to
send there and just redirect traffic so
it's just redirects
GDP redirects and that work fine
eventually we had to move data so we
start copying some data back and forth
and nowadays we have some tools called
database migration service which will
actually continuously copy data out of
things like Oracle or Terra data or
mysic sequel server proprietary
databases in particular and you can use
them to migrate to cloud and you can
move them to post grows on my sequel or
DynamoDB now in 2011 we cited okay we're
going to shut down the data center as a
system of record and move to the cloud
as the source of as the the primary data
source so we needed to be able to back
it up and we wanted to replace our
off-site tape backup so we created a
separate account in a separate region
and that's became very secure durable
way of doing this and we set it up so we
couldn't be deleted it was automatic
purging and we nowadays there's long
term archive using glassier so we
replace this off-site tape backup with
you know put it in another region in
another account do you want to be guard
against account takeover and a whole
bunch of other internal sort of employee
disgruntled employee kind of things you
want to make sure your backups are
really impregnable but this is the
replaces tape backup as a mechanism
finally all in there close down the last
data center this happened after several
years corporate IT moved billing moved
stuff like that and now everything is
running on the cloud so that's the
migration it takes a while this this
last time the tidying up the last few
things takes a bit so if we're moving
databases we start with these monolithic
databases let's dig in a bit on this and
then the trouble is that databases if
you've been running them for a while
turn to this kitchen sink of all the
schemas and all the tables and all the
junk and all the queries that sort of I
have a table I needs to go somewhere
well a well we have a database so I'll
put it there
well I am supposed to normalize that
into everything so it ends up tangled in
even if it shouldn't really have been
based in you know if even if the
workload really had nothing to do with
that and what we really want to do is
move to something which has a larger
number of
databases no sequel more clean simple
relational databases that are on a
simple single conceptual thing sort of
the micro-service front end for back-end
kind of model you want to build a bunch
of backends that are single purpose so
you've got your monolith it's a bit
complicated it's hard to run your a
monolithic database and it's got a
schema in it
and after a while it gets more
complicated and it gets more complicated
and after at the time we hit this
Netflix we'd been modifying the schema
every two weeks for about eight years
and it was became unmodifiable there was
just bits of PL sequel and Oracle sort
of oozing out of the seams of this thing
and it just became something that no one
wanted to touch anymore and it was
slowing down the business so we had to
do something about it so here's my
analogy there's your kitchen sink
think of this as sort of a student dorm
room kind of thing there's some flies
floating around it some of that stuff's
been in there for months right so
there's a kitchen sink what we want to
do is clean it up a bit so we're gonna
have a few other places to put things
we're gonna pull out all the forks and
knives and spoons and things try not to
cut ourselves on the sharp knives and
cut ourselves onto the broken glass and
there's all these broken plates and
stuff so we're just going to give
something a place to live where it
should be and tidy the thing up right
now this causes a new problem turns out
we don't have we're missing a spoon
right so you've got it you have to now
figure out distribute a consistency
across datastores
right it's not the end of the world it's
possible to do it turns out this is an
easier problem to solve than the problem
of actually modifying
a huge consistent database right so
you're swapping a problem that's
difficult for a problem that's less
difficult it's still a problem but it's
a more solvable more tractable problem
in many cases and there's a number of
different techniques you have to learn
when your developers are being weaned
off the yes you can use transactions and
joins and all these things to the no
sorry the data is in five different
databases so you can't use
join and you can't transact across them
you have to do some application level
work to tie it all together and there's
a number of patterns for doing that
which we could get into but I don't have
time today so we're going to fix this
and next thing we can do is out a new
use case and the right thing to do here
is not to put it in the same database
it's to create another database to put
it in right don't keep adding stuff in
make it really easy to create a new
database for each new use case so what
does that look like it's easy when
you've got one of these big complicated
systems to just add more things around
the edge because with dynamo DB or RDS
or in the cloud you can create a new
database with an API call in a few
minutes or even seconds you've created a
new database a new place to put things
so use that capability to make sure
you're not tangling things together that
shouldn't be there and DMS this database
migration service will help you untangle
things and put and migrate things to
open source databases so we can untangle
the schemas we can keep working until
we've got the system in a state where
each datastore has just the things that
should have for basically a single
microservices worth of kind of
conceptual you know whatever you know
they're bounded context should be here's
the datastore here's the piece of
business logic that implements this
business service so that's what we're
trying to get to so gone through this
let's think about what we're doing at
the data above the data though the
business logic starts off as a monolith
now we've untangled our data tier we're
going to untangle the top so we're going
to figure out how the monolith has moved
to micro-services and why this happened
and then look at what's happening today
as we move to functions so years ago we
had mono lists and the reason we had
monoliths that was the best thing you
could build because we had one gigabit
networks and slow CPUs and we were
sterilizing things with XML and soap and
that takes forever to deserialize and
serialize so you could only send a few
messages a second if you have a second
to
respond to a web request or an API call
it's going to take you too long if you
have if you're using soap XML slow
networks and slow slow encoding
mechanisms but that was the ten years
ago we've got better systems now so what
happened when we moved to cloud like
five years ago
we were started using JSON we have ten
gigabit networks we have much more
efficient encoding systems in JSON or
and you know simple binary encoding if
you want to go for the fastest thing out
there but what that gives you is the
ability to break things into smaller
chunks because the overhead of doing it
was now orders of magnitude less so you
could have instead of having two or
three monoliths cooperating on something
you could have hundreds of microservices
and still respond in that one second or
whatever your pale whatever your
response time wanted to be so other than
the very very lowest latency
requirements ystem x' we're able to
build micro-services based systems
because everything sped up to the point
so the ideas around service-oriented
architecture haven't changed the
implementation got efficient enough that
we could build it to have a single
function service instead of having a
more higher-level thing with lots and
lots of bits and pieces in it so we're
able to build this we're able to fire
off all of these different things and
build much more complicated systems
where this on the left hand side is an
it is an internet endpoint and on the
right hand side you've got a whole bunch
of data data stores or caches or
something like that and you're just
sending traffic back and forth so that
was five years ago but it turns out that
the services around the edge just became
common services they were open source
packages or they were things that we
built ourselves in the old days but just
turned into an off-the-shelf service you
know something like sqs for queuing or
DynamoDB or SNS for network for
notifications or s3 for an object store
so a whole bunch of the things that we
used to build that used to be parts of
our monolith have now become
off-the-shelf services and our business
logic is now sitting in the middle as
glue between these building bricks and
there's business logic is actually going
through another revolution now
as we simplify that into individual
functions so those functions we Sable to
split the business logic and turn each
one into a different lambda function but
the cool thing we're able to do with a
dubrow's lambda in particular was make
them all completely ephemeral
so I've grade everything out here
there's actually nothing running because
I didn't give it any work to do I've
defined my application I've defined the
functions but there's no work here and
every time a request comes in the lambda
functions come into existence just for
long enough to run that code and then
they shut down again you get charged for
every hundred milliseconds that they run
so when the systems idle it cost nothing
to run so this is for a large number of
workloads that are relatively spiky
particularly corporate IT workloads are
a great example of this because people
they work on the speed at which you know
depends how many employees are at work
at any point in time or their spiky off
businesses or anything driven by say a
TV ad where you want to respond to
people hitting a webpage that that's in
a TV ad those kinds of spiky workloads
are perfect for this there's certainly
cases where you've got a constant stream
of traffic where you'd want to just
build a service to process it but
there's a large class of applications
where your systems are idle most of the
time because they are just waiting for
the next spike in with traffic to turn
up and these systems are always on
represent utilize so that's the cost of
running its site and that's one reason
why service is interesting the other one
is the cost of the time it takes to
build these applications is incredibly
short because you're just gluing
together the building blocks you're
building the API logic that ties it
together and that is very quick i if you
go to a hack day almost every hack day
I've been to recently people are
building service apps with lambda
because they can build so much in one
day with that that they're just way
ahead of if you're handcrafting your
application any other way
it's it's ridiculously I was just
staggered when I was seeing what people
were building in a single hack day
concentrated effort and build incredibly
large scalable complex systems by just
assembling all these components now so
we've seen how business logic is if our
I'm not going to talk on a little bit
about the things where we're going next
and the things I'm currently working on
so I'm spending quite a bit of time
thinking about serverless and where
we're going there but my new role AWS
I'm responsible for a few things as well
as the sort of Mike the strategy of
where we go next but particularly open
source so I'm going to talk a bit about
that and the Apache MX net project which
is a machine learning deep learning
system so we'll talk a bit about these
different areas and I'll tell you about
my my self-driving car that I've built
myself at the end well it's a little
less impressive than it sounds it's kind
of fun these are some of the projects
that we contribute to basically all of
the Apache Hadoop ecosystem we're
contributing continuously multiple
updates per week we run when you use EMR
you're typically running a build that's
one or two weeks past year old right if
you take the current state of Hadoop
patches and bugs and fixes we were very
up-to-date automatically updated version
and there's a whole bunch of other work
going on we contribute to Linux
remembers the Linux Foundation the Xen
hypervisor those contributions there
Postgres
with we've recently built an accelerated
Postgres system we also contribute to
the Postgres project by giving them free
AWS resources to do all their testing so
there's a number of plate people we do
that for contributions to docker and
other things right then there's the
repos that we build that we put out
there that uh you know AWS code and
there's a few of these blocks as a
container one
remember when open SSL had all those
bugs in it we got we got kind of annoyed
by that and somebody said I can do a
better job writing it again from scratch
so that's what s 2n is s3 when use s3 in
a secure mode TLS HTTP access you're
going through s to n so it is a
cleanroom verified secure replacement
for open SSL that you can go and use for
your services if you want to be more
highly secure and isolate yourselves
from the next open SSL bug when it comes
the most recent one this came out
earlier this week is Sakai it's a neural
machine translation library system work
built on top of MX net so if you want if
you're playing around with machine
translation this is an open source
framework for doing that quite a
powerful way of getting some quite good
results already it comes out of whatever
the AWS office is in Germany they've put
it out there as open source so you can
go look for Sakai on the AWS repos worth
taking a look at and I'll talk a bit
about more about MX net net later a
whole bunch of other stuff here some of
the oh that actually Sakai comes from
the Amazon retail side not from the AWS
side it's related more to what they're
doing with things like a lecture I guess
and then there's all those open source
projects that are paying to run that we
just make it easy for you so since 2009
I've never had a problem installing
Hadoop just make an API call the cluster
appears have to install it that was
crazy
so ElastiCache my sequel post grows all
of these things that we're just making
it easy to use and this comes from
customer saying wherever it's annoying
that we have to go build this thing can
you just make it easy for us to consume
it so we're always listening to
customers about which open source
packages we should just build as a
service in this at this database
migration service I've mentioned a
couple of times
22,000 databases have been converted
with that already so it's like a deep
learning why is this taking off now I've
still got time yep everything's digital
then huge data sets are available
there's a huge amount of compute power
available so even though people were
talking about deep learning applications
10 years ago they didn't have the
compute to do anything more than toy
applications and training took too long
now you look at this Baidu's Chinese
speech recognition system 4 terabytes of
training data and they're running 10x o
flops of processing power to have it
recognized tiny Chinese characters and
Chinese speech that's a huge amount of
capacity
if you think about what the now there's
you know overall if you look at the
capacity of cloud what is it running
it's running the mixture of different
things right but the people are running
deep-learning are running a
disproportionate amount of compute
resource because when you go to train
their systems it's just a huge you can
spend as many machines as you can
possibly get for weeks or months just
training a system to get it better and
better at what we see in the future if
you just extrapolate this out there'll
be a point in time in a few years when
you could think about the major workload
on cloud the dominate workload on cloud
is training deep learning models all
right that's why this is important
right that's why we're paying so much
attention to this this is probably the
endgame for what cloud is used for what
compute is used for in the world is it's
going to spend most its time trying to
learn stuff about what we're trying and
you'll learn it based on all this data
we're feeding it and it's getting more
and more affordable to do this think
your training takes months but the
classifier that you get out of that
training can happen in milliseconds or
seconds it's very quick so it's a very
asymmetric model once you've trained
something to classify you can deploy in
a raspberry pie or of iPhone or whatever
but the training model probably needs a
back-end so that's why cloud is
important this is the kind of stuff
we're saying it's Multan of us driving
examples these are in China somewhere
but you know you can just see it's
tracking people it's tracking cars
there's somebody walking across the road
trying to kill themselves but they seem
to survive you know this is this is kind
of state-of-the-art missus what's going
on if I live in the Bay Area and there
are cars driving around all the time
with pinning things on top and doing all
of that self-driving stuff and we've
seen them for years but they're just
becoming everywhere now so people are
starting to get used to them and they're
starting to get pretty good so wallet
what's a customers using AI today on on
AWS a whole bunch of people here I won't
go through in great detail but there's a
lot of them this is just a few so what's
the challenge first of all you've got
petabytes of data you've got to get that
data into the system you've got to train
them on tons of GPUs
you want elastic capacity you wants you
to give that you want you want to it's
the same thing as I mentioned with the
process that was batch processing you'd
rather have a hundred GPUs for an hour
than one GPU for a hundred hours because
you get your answer in an hour right but
it costs the same by the area under the
curve is the cost so you just want to
get the most scalable system that can
scale to the largest fleet of GPUs that
you can assemble process that then give
it back and then find out how good that
is and crank it through the system so
that's why this is important and the
actual prediction itself we're starting
to see GPUs to use for that but you can
use it on pretty low-end systems at the
edge and server so we're deploying
lambda functions that contain trained
models that have been trained using
these weeks or months of CPU time so
this is the kind of stack a bunch of
open source AI engines in the middle
apache MX now I'll tell you about in a
minute but we have tensorflow cafe torch
there are no CNT que caress a long line
of these things they're mostly open
source at the bottom you've got cloud
hardware and demand the p2 is a 16 GPU
on a single machine we can get there's
machines with a single GPU there's
elastic GPUs you can attach to machines
we have ECS for containers lambda green
grasses our IOT platform for deploying
this stuff and if you really want to get
clever you can design your own hardware
and deploy as an FPGA design on AWS now
and that people working on that for deep
learning as well more coming
recently Nvidia announced their
next-generation GPU chip that's going to
be out late this year AWS is the launch
partner for that chip so we get it first
that means you get it first through AWS
so we're going to be out volume first
with that chip and that's the kind of
because our buying capacity we can just
go and do a deal like that on top of
that there's an AI platform machine I am
as a machine learning is a just feed it
some data and get predictions it's
useful for recommendation engines and
that's been out for a couple of years
we're doing more things in that area
that's platform layer stuff a bit easier
and on top we have the easy to use
if I took a photo of you right now and
fed it to record you say crowd of people
sitting in a room with lights you know
it can tell what's in the scene Polly
you give it some text and it says it in
a lifelike way Lex is the core of the
Alexa service you can build the chat
BOTS with it with audio or text input
we built a call center around it so you
can use it for call center front end
those kinds of core things and there's
more applications coming in that space
so we're just going to keep cranking out
more and more and more use cases the
latest thing on recognition is we added
celebrities so you can show it a picture
of Wonder Woman and it tells you the
name of the actress that's playing yet
not forgotten her name got something
which is after remember that when I'm
going to Israel next week and I know
I'll have to remember it if you're
getting into this this is the easiest
way you can get in there's a deep
learning ami ami you basically have
everything pre-installed you fire up
this image and it's got all of the
versions of Python you need all the
versions of all of the different
libraries and toolkits it's got
pre-built drivers that know how to talk
to the GPUs we've been tuning it all
there's a team of people working nonstop
on making this work reliably testing it
and integrating it don't replicate this
yourself it's a total waste of time
you'll spend ages just trying to get the
right version of Python installed for
all of these different things but we
have all of this stuff built into it so
let's do a quick overview of MX net it's
got a simpler syntax with lots with very
broad language support one of the
reasons there that we decided to get out
to double down on MX net was the
language support it's very portable it's
efficient it works well on ARM chips on
IOT devices its high-performance we
figured all of the things we tested it
has near linear scaling across hundreds
of GPUs that's the multiple machines
your multiple of our p2 machines all put
together we got great scalability on it
and you know pretty good scaling on
hundreds of them so that's very nice
their last January it was proposed as an
Apache project and
in the incubation process so it's still
working through it's not fully you know
there yet but it's working towards that
and the teams of going there and we've
been tuning on AWS so here's here's
what's going on it's a pretty diverse
community about 35% of the contributions
to our Mex net come from people who
currently work at AWS format at Amazon
but there's people this is you kind of
think of this as a university research
team where people hired people out of
those teams and those people are still
contributing back right so being sue
went to Apple and somebody else went to
I don't know am I know if Tesla or
wherever there are a number of places or
the Microsoft at the bottom nan sue
though these people went off in
different directions but they were came
out of the original research teams which
were at UW and CMU I guess so lots of
different contributions here and just
some summary from the Apache incubation
process 51 offers with 165 commits you
know there's a fairly large group of
people here it's a diverse group we're
trying to gather we're trying to sort of
push Jen you know heard Kat heard 150
contributors into all these different
people into the Apache process so that's
what it takes time so it's going to take
a few more months to get through one
update recently you may have heard of
the caress front end which is a
easy-to-use front-end on top of
tensorflow Francois Shelley is the guy
that wrote that it currently works at
Google but in Baden we now have MX net
as a crass back-end so you can still
take all the things you wrote in caress
and you can basically plug in MX net
instead of tensorflow and you can get
access to any of the you know
performance scalability things that
we've been investing in on the MX net
side so with its early days we're still
figuring out some benchmarks to really
show what the difference is but with
it's coming up as a relatively portable
front very high-level front-end for
building these networks
some comparisons here we've decided to
go with an Apache community model here
for governance there's some interesting
things with programmability that MX net
has an imperative mode most of the other
systems are declarative what that means
is we have easy access from Perl MATLAB
are in when you're building a ripple and
you're just typing something in and you
want to try things out you can actually
do that with their max net it's harder
to do that when you're building a
network and feeding it through and the
code link that's it's concise it's
closer to caress in its API than tend to
flow which is quite verbose when you get
into using it and we found for some of
the workloads that we got a much smaller
footprint which makes it easier to
deploy on small devices so here's the
strategy
integrate this with a whole bunch of
services use it as a foundation for more
things that we're doing and leverage
this community and go you know broaden
the community to take it up these are
some of the things that Amazon's using a
mixed net for Applied Research all these
different things some where it says
machine translation so that's that
project that just came out as open
source lots of different options here if
you think about everything that Amazon
does and supply chain logistics robotics
all those things plus all the stuff
that's going on in AWS so a quick look
at the API there's an indie array very
similar to the kind of thing that you'd
use in numpy a net multi-dimensional
arrays also known as a tensor this is
where tensor intensive flow comes from
it's a multi-dimensional array and a
symbol is how you create the expressions
for the flows that you're going to pump
this through so you create a tree of
processing steps it used by creating
these symbols and that's the flow part
so tensor flow is basically just a you
know combining together the description
of the way these things work so all of
these things are basically tensor flow
type things and MX net is very similar
to tensor flow in the way it works so
that the API is a little different in it
so you can basically this in this isn't
you know what is this one you know two
times two or something
but pros for this it's easy to do an
imperative thing and in a debug what's
going on because you can stop it you can
stop it step by step and see what's
happening it makes it easier to debug
but it's less efficient if you're trying
to pump huge amounts of data through
this so it's better for data exploration
it's not as good for training and
classifying the more declarative model
you build this tree this is the this is
the flow plant or the symbols and you
compile this tree and then you feed data
into it and the data flows through and
it becomes it's very efficient because
it knows which nodes you're no longer
using and it can collapse things and
optimize it and this is the structure
that's then labeled out across laid out
across the GPU for high-performance
processing it's pretty hard to debug and
figure out what's going wrong in the
middle of something when you're pumping
data through here's the models I'm
almost done now from the load of time
here a bunch of different types of
inputs and outputs this should be fairly
familiar to most people fully connected
convolutions pullings l STM's along
short-term memory those are used for
mostly for tech understanding things
like text and then there's this cool
thing at the bottom you try and explain
this basically if you're trying to
understand language you end up with a
vector of weights for each word and
those they represent the word and it
learns the way so once you've trained
your language system so somebody figured
out that if you trained your system and
it figured out what you the the the
vector that you had for Queen was
basically the same as the vector for
King if you subtracted out the vector
for man and added the vector for woman
so it's like the system has figured out
there's this idea of a regent and there
are male and female Regents and their
subclasses of it so you can actually
there is some symbolic manipulation and
basic understanding but it's all done by
the weights of these vectors of numbers
and this sort of conceptual
understanding is actually what's going
on inside these models so that's what
that's about is kind of weird why's it
say cos King Queen anyway that's the
story Lots going on here I'm just going
to give you
this little thing here so this is my
project this is my self-driving car it's
about this big it's a radio-controlled
four-wheel drive truck thingy with the
radio unplugged and if brahs berry pry
jammed in the top of it the software it
runs is called donkey so I called my car
Hotei so it can be Don Quixote and I'll
show you it's an example of it in
gauging in Don Quixote like behavior
this is tilting at windmills
unfortunately it luckily no damage was
sustained to the other truck yeah so
it's a fairly where we think so this
this is an example of it actually I
basically trained it to be scared of
white lines I think and it just goes
it's got the thing sticking out the top
is a camera and when it sees a white
line it goes and runs away from it and
this was trained on a different vehicle
and on a different track but even though
the training was completely from I got
scared of the chairs at that point and
ran away completely even though it was
trained on a totally different
environment
it still had basically figured out that
it was it could figure out how to drive
around a track so we've there's a team
that means DIY Robo cars is the name of
the whit Twitter handle but there's
groups starting up around the world you
could probably start one in Amsterdam if
you guys want to do it this is a great
way to play around to learn how to do
this it's all available I you know this
is a $200 US toy that I've built and
I've spent you know five ten dollars a
month on you know building this thing
running it the way it works there's an
AWS instance which is actually way to
your training that's there's connect the
car is connecting to and then your phone
connects to that instance and you
control it through the AWS instance so
it's powered through that all
open-source and mostly written in Python
and it's a fun thing I encourage you go
play with this yourself play with your
kids this is where the world is going to
be five 10 years time understanding how
these things work is going to be really
important at least having a conceptual
understanding what you can and can't do
with them so this is me trying to learn
all that stuff so this is my kind of
last slide afraid of a lot of time here
but lots of blog posts
lots of benchmarks the slides I'll give
a PDF of the slides to the organizer so
it'll be up pretty quick so you can
click through on these things but Julian
Simon who's a jabber evangelist based in
France has done a whole series of blog
posts on the MX net API go follow him if
you want to really be up to date and
soon Amalia works on the MX net team
sort of producing lots of blog posts
like some of these MX net1 Lander kind
of things so that's that thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>