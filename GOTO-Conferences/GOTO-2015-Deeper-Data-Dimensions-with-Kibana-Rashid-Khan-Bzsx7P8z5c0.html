<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Deeper Data Dimensions with Kibana • Rashid Khan | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Deeper Data Dimensions with Kibana • Rashid Khan - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Deeper Data Dimensions with Kibana • Rashid Khan</b></h2><h5 class="post__date">2015-06-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Bzsx7P8z5c0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">microphone alright cool so yeah as
Leslie said we are here to talk about
Cabana specifically I want to give you a
little bit of history of how come on I
got to be where it is where it is now
and kind of where we're going with it
just real quick just so I know how many
people have used gabadha in the room
before okay how many people were at the
elasticsearch meet up the other night
you can probably leave if you want cuz
it's like exactly the same so I did I
don't want to bore you here oh okay so
no biggie okay great so so about half
the room has used cabana already which
which is great but for those that
haven't let me give you an idea of what
it is and how it got here kabana is a
application for digging into data I used
to be specifically for time series data
but now we just kind of deal with
anything it was created because I was
working at a chain of newspapers in the
US and it was this company that owned a
whole bunch of newspapers I know we all
like to think of our little hometown
newspaper as having a bunch of people in
a little room digging up dirt on what
not that was not this company they had
dozens of newspapers across the u.s. as
you can imagine there are two things in
the newspaper industry right now a
nobody reads newspapers and B when you
do read them you read them on the
internet and so this company generated
an enormous amount of web traffic much
more than you would think these things
tended to come from you know kind of
referral sources and we didn't tend to
get a lot of direct traffic but
nonetheless we got a ton of traffic uh
and it was very very spiky traffic right
like nobody goes and reads every single
news story every single day just because
they want to know everything about what
the reporters think they read something
because it's interesting they read it
because their friends said something
about it
and they ended up there and they all
ended up there at once and so we were
constantly having to deal with this and
you're probably like oh well you're your
infrastructure for dealing with is
probably great it wasn't great it
constantly had problems and we had no
idea what they were because this was
years and years ago when there really
wasn't anything great especially in the
open source space for figuring out what
was going on in logs right so we had
these like collections of shell scripts
and then they were on a wiki and only
the jerk me that wrote them knew how
they worked nobody else ever used them
and half the reason they never used them
is because by the time they went to get
to them we had changed the log format it
was out of date anyway and they didn't
work anymore so I was constantly having
to write new ones and I got tired of
writing them so i wrote Kabana so that I
could stop writing shell scripts so
that's where come on it came from real
quick people who used Cabana used have
used version for the current version
real quick a few used version 32 okay
sweet add 1 i'm not even gonna ask
because i know nobody used it although
there was somebody at the meetup the
other night that had which was very
impressive okay so most of the Pope
folks in the room have used three so
when we went to build for we wanted to
take the best features of three and make
everything a little bit better and so we
looked through three and we needed to
identify okay what's good what could be
better and what could be a lot better so
we studied okay how are people using
Cabana these days now the first way they
would use it was of course for discovery
they were searching through logs or some
other kind of data right data discovery
was what it was all about like okay we
need to make that better we need to make
the whole thing perform better if we
want better data discovery the first
step in that is just getting the answers
quicker so we can make the interface
better yes and we can make the whole
thing just plain faster right make the
easy things easier once they're easier
make them faster which was really
important the other thing that we saw
when we when cabana three had been out
for
little bit this was something that we
hadn't necessarily anticipated was that
people weren't just using Kabana they
were building new things with cabana
which was just incredibly cool to us
when I first built come on 23 I was like
okay well I need a kind of dashboarding
platform I want to be able to make some
some visualizations and have some charts
of stuff it turns out people saw a lot
of promise in this and because we're
open source they started to dig into the
code and they said well if he can do
what I can do it and and they were
completely right and often they could do
it better for that matter so they
started building new applications on top
of Cabana they started adding new
visualizations they started even adding
a new ways of doing queries or like okay
so what we get out of this is that folks
really want flexibility in cavada so
when we go to build Kabana for let's
build it in a way that lets them have
that flexibility without just having to
hack at it so those were kind of the the
core but the biggest difference we
wanted to make was in discovery cabana 3
was built with what elasticsearch had at
the time and what elasticsearch had at
the time was facets I has everybody here
is everybody here pretty familiar with
elastic search facets a lot of heads
nodding I don't see any shaking okay
anyway so facets facets are basically a
way of aggregating data for those that
aren't familiar right so find me the top
5 of something or get me the average of
some field and in particular that first
thing that was the terms facet and then
there was this other thing called the
stats facet and if you remember in
cabana 3 these things were pretty easy
to do there was a panel that could deal
with terms and put them on a bar chart
or something and then there was a panel
that could deal with stats and it would
show you the min/max and an average and
whatnot of things and that was because
it kind of mapped directly back to these
elastic search concepts the problem was
is that facets weren't very flexible so
remember I said we had that terms fast
and that statistics facet well somebody
once decided that okay well i found the
top five requests to my site it would be
super helpful if i knew what the average
time to load each one of those was and
somebody said we can't really do that in
elasticsearch right now you can get one
answer or you can have the other answer
pick one and somebody said well look I
need to do this a lot I can't do it with
round trips a lot so what did it have
happened it was somebody copy and pasted
a bunch of code out of the terms
fastened and then a whole bunch of the
stats fads and they created this thing
called the terms underscore stats facet
super I can see how that will answer
every question so when when we went to
build elasticsearch 1 point 0 we said oh
okay that that facet thing it's not
really working out and sew the elastic
search team built something called
aggregations and aggregations are
basically do the exact same things
facets but in a very composable way
which of course got me really excited
about doing composable visualizations in
cabana so when we started to look at how
we could improve the concept of
discovery we took that kind of level of
composability and those steps to solving
a problem when somebody says I need the
top five or even heck I just need this
one thing and we said how can we break
that down into steps that make sense for
solving a problem so step one of solving
a problem is often very very
one-dimensional you have a pretty good
idea of maybe what you're looking for
you maybe you think you know what you're
looking for specifically you're just
looking for one thing right you know
okay I need to go to my logs and I need
to find that failed ssh login and so you
go there and you find it and sometimes
that's all you need but maybe you end up
with a bunch of them maybe you end up
with four of them if you end up a five
of them maybe you end up with four or
five hundred thousand of them when
you've only got one of them or you've
only got four or five of them it's not
really that big of a deal right like so
if I jump over to the discover tab of
Cabana and I'm going to jump into my
users index here and get rid of a couple
useless fields that aren't actually in
there I so i end up with something like
this right and the
is a really kind of familiar view it's
basically just a list of things that are
in my users index it's really easy to
find stuff in there obviously I just got
a little search thing up here and I'm
going to search for the JPL news user
and sure i can find that user and this
is a very kind of one-dimensional way of
finding things there it is there's the
document i was looking for and even if i
want to find what that user was was
doing that's still pretty easy right if
i've got a log of everything this user
does that's still really easy to find so
if i were to like jump over into my USA
gov index by the way the data set i'm
dealing with is the bit ly US government
click stream every time somebody
generates a link to a US government
website bit ly publishes that to a web
socket that you can connect to and and
log if you want to I I was lucky enough
that somebody else had already done this
and made a nice big archive of them for
me because it's a ready source of very
real logging data anyway so I can now
see everything that the JPL news user is
doing everything every last unreadable
thing right I basically have no idea
what this user is doing sure I can see a
few things in there uh sort of oh they
did something at May twelfth and they
were using the z new link sleuth user
agent this is super hard to read I mean
even if I did something like had time to
it and checked where they were going
this is still really hard to read even
if I sort this by time right it's still
hard to read this is basically just logs
I'm not really doing anything
appreciably better than grep at this
point it's just I can see that over the
last time they were active is maybe june
thirtieth or something so this can be
useful for limited cases right when I'm
just doing search and I really know what
I'm looking for already and I don't need
to
see patterns in anything I don't know
you but I'm not super good at just
looking down a list of things and
finding patterns in it so we really need
a another dimension to look at
essentially here right I don't just want
to see this like scattershot of stuff
right I want to see some additional
dimension to it I want to see things
over time I want to see the ebb and flow
of my data what that user was doing or
what other users were doing or maybe I
don't even know what user I'm looking
for right I knew I happen to be looking
for the JPL news user there because I
honestly don't know I just kind of
picked one what if I didn't know what
the most active user on my site was is
it the JPL news user by the way I don't
actually know it would be awfully
helpful if i had a chart or something to
to help me figure that out if i could
find the top users so of course come on
is good at doing both of these things
and Kabana three was good at doing both
of these things to income on afore we
said hey look that needing to see that
ebb and flow of things that's common
enough that it's worth just throwing a
chart at the top of the screen every
time somebody is dealing with time data
you're dealing with time data you want
to know when it happened and you want to
know how much of it happened just put it
at the top there and so we did and we
also added the time column by default if
you happen to be dealing with it so I'll
drop that other time stamp column I had
added earlier and so there we go we can
see a big spike in the JPL news user but
of course at this point we could go and
look at a whole bunch of other data to
because we have a chart that helps us
figure out when things went on that said
what about if I wanted to solve the
other problem what if I wanted to see
what are my most popular users right I
could sit here and I could type in every
possible user and sit down and record
you know which one it was but that would
be a big waste of time so instead I'm
going to drop into this little field
list over here and I'm just going to
quickly visualize my popular users okay
so there are my popular users oh and it
turns out that the JPL news user
actually is one of my like the top five
users
but there's a slight issue with where we
ended up here when we were back on the
other screen we could understand the ebb
and flow over time of our data when r on
this chart I can understand in that
entire time span which which happens to
be the last two years at the moment I
can understand who my top users were in
the last two years but now I don't know
when it happened I don't know when they
were active which is kind of a problem
to me I want to be able to understand
why the JPL news user is popular how did
they get there you know what what kind
of things do they post and so I need a
way of melding this chart with that
other one and if we think about this as
dimensions we can think about the idea
that we have essentially two dimensions
here right we have how many things the
user did and who did them before we had
you know what time is it and what
happened at that time so I need a way to
meld these together I can do it on a bar
chart but I'm not going to I'm going to
drop back over to the new visualizations
section I can either just click the new
visualization thing or I can wreak lick
on the visualize tab at the top here so
I'm going to drop into a line chart and
I do this from a new search and i'm
going to pick my USA gov index and I'm
gonna get a big white expanse of
nothingness which isn't actually totally
true I do actually have something on
there I've got that tiny little green
dot right smack in the middle of the top
there what basically just says hey look
there's like four hundred and fifty
thousand things in here I don't know
what you want me to do with them this is
all I really know about this index so
unless you tell me you need something
else i'm going to give you that so we're
at one dimension now let's add another
one i'm going to add an x-axis right now
all we're representing is all on the
x-axis so i'm going to add a date
histogram alright so now we've got a
chart that is very similar to that bar
chart that we had before back on the
discover screen it's a it's a
right we've got the same big spike that
we had seen on that other one but now
we've got it in line for him and my goal
coming over here was I wanted to meld
that user dimension with the time
dimension so how could I do that well I
could just show the same chart right so
I could like maybe I could add another
access to this but that really wouldn't
do much for me yes I'd be able to see
who the popular users were but I
wouldn't be able to see like what time
they did stuff I could add a like it
cadet is Z dimension right so right you
got act if you've got X and you've got Y
and then one of the really popular
things when you're trying to you know
create another dimension is people like
to like throw another dimension at you
I'm not a big fan of three-dimensional
charts in general I I don't generally
believe things should leap off the
screen I don't have a 3d TV and I don't
much care for 3d movies because you
can't get behind the things right you've
got this chart but you don't know that
the smallest things are always going to
be at the front and the biggest things
at the back which means that there's
things that get lost and you can't see
them so I'd rather than having the chart
leap off the screen for the third
dimension I would much rather pick a
better dimension that and I'm going to
so right now if we look at the visual
dimensions of this yes we can go with
length and width but one of the other
dimensions here ends up being the color
and right now we just represent
everything is green because it's
pleasing and calming and reminds me of
trees but we could probably give it more
meaning than that so let's let that
green line into multiple lines so I'm
going to add sub buckets and you'll see
in a minute why they are sub buckets I'm
going to split these lines up and I'm
going to use an elastic search terms
aggregation to do this and I'm going to
do this on my user field so give me the
top five users over time and I'm gonna
hit enter that's a lot more than five so
as you can see down here I definitely
just asked for five users but why did I
get a whole lot more than five so those
of you familiar with elastic search
aggregations might actually understand
what just happened
what happened was yes I asked for top
five however I asked for them as a
factor of the time and so when
elasticsearch did was said well you
asked me for time and that was the first
thing you asked me for and then you
asked me for the users in that time
while I had broken down your data set
for you and I'd broken it down to these
buckets in this case I'd broken it down
into weekly buckets and so when you
asked me for users I said well in each
one of these weeks what's the most
popular user so it went and found the
top five users in each week of course
that changes from week to week and so
I'll cabanas new was well you told me a
whole bunch of users were popular here
they are and here they are per week and
you told me who was popular in each week
that's not necessarily what I want in
this case if you actually look at the
elastic search request you can
understand how this came to be skip past
is it very vaguely familiar with elastic
search requests and how they work more
or less ish nodding heads no no shaking
I'm still going to assume that you just
don't want to tell me know so I'm going
to explain it up here we have the query
section this basically describes hey
this is the data I want to get basically
I want to get everything between these
two impossible to read unix time stamps
and then down here i have my
aggregations section and so within this
aggregation section we can see how
elastic search structured this request
on the top level we have a date
histogram and below that date histogram
we have a terms of the user field so
again here we're taking into context the
time that the thing falls into to figure
things out what we actually want to do
is run that terms aggregation first so
find me my top five users and give me
those five over time so what I need to
do is I need to raise this to be above
that other one which I can do pretty
easily in qivana if we go over to this
side we've got these little buttons here
for increasing and decreasing priority
so I'm going to increase that and rerun
the aggregation okay so I have my top
five users over time now and it's it's
much much cleaner although i still find
this to be kind
of a visually distracting sort of thing
mostly because I've got all those lines
in there and I don't really need to know
the slope of anything right now so I'm
going to drop those out I'm just going
to completely get rid of all those
connecting lines so now I've just got a
bunch of dots and while this makes it
kind of hard to see where things go to
and from I'm more interested in kind of
where they were at and what I can see is
way up here I've got a dot that says JPL
news and JPL news was apparently very
popular within this particular week what
I don't know is why why was it popular
why was there a big spike in JPL news
and the way this data set works is that
these are all the clicks through bit ly
right which means that a lot of people
clicked through bit ly for links that
the JPL news user had created at some
point right they created these short
URLs and somebody clicked on them so
there's two possible explanations for
this right explanation number one JPL
news got really good at marketing and
they created a ton of content right they
just created a huge amount of links
maybe they published a whole bunch of
blog stories something they just tried
to hit a really wide market and hoped
that a whole bunch of people would want
to click on their stuff the other thing
could be that they published one really
really popular article and that shot
them straight to the top how do we
figure out which it was what happened
okay so we're at three dimensions now
but we want another dimension that
explains to us what happened so what
we're really looking for here is how
many unique articles did they end up
publishing basically the unique count
with in that bucket we can see that
there were 6593 clicks but how many
unique destinations did those represent
so we need to pick another dimension to
represent unique destinations and we've
got three dimensions now so we need
another one we've already got color
we've got X we got why I what about
those dots right now they're all the
same color
instead right now they're all the same
size instead of having those all be the
same size let's vary that size depending
on how many unique sites or accessed so
I'm going to add another metric
aggregation here and I'm going to decide
the dot size kind of flows off the
screen a bit all right so i am going to
vary the dot size based on the unique
count of the destination field ok let's
do that all right so interesting thing
the JPL news dot didn't really change
much in size ah and doesn't look like it
changes much in size in general in fact
many other users publish a lot more
stuff than the JPL news user does so
it's not like they're what they were
doing just kind of exploded all of a
sudden they were still doing about the
same stuff they were usually doing in
fact we can we can get a better view of
that because we've decided that we we
are interested in this user now they've
become very popular and we're interested
in what they're doing so what I'm going
to do is I'm just going to narrow this
down so I'm just looking at the JPL news
user for a while so I'm going to click
on this and cabana's going to generate
some filters for me so I don't actually
want to change the time I still want to
see what the JPL news user had done for
the last couple years I'm going to
deselect that filter and I'm only going
to apply this JPL news one here cabana
said look you clicked on something and
it represents a couple of different
dimensions that I've been able to
identify represents a week in time and
it represents a particular user which is
why it said hey do you want these two
filters or just you know some subset of
them so I'm going to hit apply and just
bring this down to the JPL news user so
we can see that actually without the
context of all those other dots that
were going around the say the bitly user
kind of outweighing everybody in fact
they did seem to generate a few more
things let's see they generated about
well exactly 39 unique sites however
they usually generate Oh 14
3119 somewhere between like 10 and 30
ish and things but they also usually
only get 0 200 ish click-throughs but up
here they had over 6,000 despite the
fact they generated double the amount of
links they got you know a 60 fold
increase in how many users are much more
than that actually a fold increase in
how many users how many users clicked on
things so chances are they just had
something that got popular they generate
a few more articles but they received a
whole ton of clicks through to that okay
so we know that they probably had a
couple of popular articles at least they
published a few more but they're a
couple of we're obviously very very
popular how do we figure out what those
were so i don't really super need the
splitting by color here anymore right
i'm only looking at the JPL news user so
i can get rid of this and it won't
really change anything so i'm going to
remove my split lines and that won't
change anything at all because i was
only looking at you one user anyway um
and I don't really care about the time
anymore either in fact I'm just going to
zoom in on this and get a better idea of
what went on in this specific time
period really I want to know what went
on in that time that they were
particularly popular so I don't need
time as a dimension anymore so let's put
something else on the x-axis instead
tell me what their popular destinations
were I don't know give me the top like
not 51 give me the top say 15
destinations all right
oh okay so we're back to having little
tiny dots again why do we have little
tiny dots again well we asked for the
top destinations along the x-axis and so
each one of these only represents one
destination and our dot size was
determining unique destinations within
the bucket of course since each one of
those represents one there's only one in
each which is actually to our benefit
because we've managed to reclaim i
destined a dimension we can reuse that
dimension for something else so if we
look at this we can see that yes they
had a few particularly popular things
how did those get to be popular uh well
this dataset works a lot like the data
set that i had at the newspaper i was
working at in that very few people came
through the front page right very few
people go to bit ly and just click on
some links because they're short they
come to bit ly they go through bit ly
because they saw something on another
site that happened to use a bitly link
so what sites do people see it on and
how was the traffic driven to the site
was it driven because one particularly
prolific site link to it right did this
hit the front page of the New York Times
or was did something happen like it was
shared through facebook or twitter or
something and a whole bunch of users
posted links to this thing let's find
out let's reclaim that unique count
destination but instead of doing
destination let's grab the referer
header and refer tells us hey where did
these people come from and actually I
want to show you a neat trick in
elasticsearch who's used the cardinality
aggregation in elasticsearch anybody
know basically nobody so cardinality is
the thing that does unique counting
unique counting especially across
distributed systems and very large sets
while we're not dealing with a huge set
here elasticsearch is built to handle
really large sets unique counting of
very large sets is very hard right in
order to determine if something is
unique you need to know if you've seen
it before if I'm just Sam sweeping
through all my logs and I want to find
you know the unique referrers so I need
to know if I've
seen something before so I know if I
should count it again the problem is in
order to know if you've need if you've
seen something before you have to
remember that you saw in order to
remember that you've seen something you
have to put it in memory if you have a
lot of those things it's going to use
all of your memory so there's this thing
called proximate counting an approximate
counting is what elasticsearch does if
the data set is really really big and
the way it does it is it essentially
folks familiar i don't like you best
people to raise your hands but familiar
with the hyper log log algorithm rates
good nobody cool hyper log log the way
it works is you generate a bunch of
hashes and you use those hashes to
determine essentially probability what
is the chance that there's something
like this and how many of would there be
so elastic search has this optimization
where it can generate those hashes ahead
of time so I'm going to pick the pre
hashed version of this which I happen to
store just because it's fast it doesn't
really matter as much on this data set
but essentially the way storing hashes
works is you're trading a little bit of
disk space for a whole lot more
performance okay so refers okay so what
we can see here is that their most
popular thing not actually all that
widely shared however the next most
popular thing actually very widely
shared the unique count of the refer
hash in this case is 187 so 187 a
different desk different sites referred
to this this page so what happened
likely in this page was that it got some
how relatively popular on social media
maybe was posted on a variety of news
sites I'm just kind of curious what that
actually is so I'm going to open this up
and I'm going to resort that and I'm
going to look at this one so what this
one actually what actually was that okay
so it is apparently a curiosities heat
shield in detail this apparently got
very very popular I'm I guess I'm not
all that interested in it but okay I
guess I could see how that's that's in
its bars that's pretty cool anybody see
this sin be seen this image before
by the way I I had never seen this until
the other night that I gave this really
maybe you were one of those clicks I bet
you you were I bet you were I bet we
have a like especially if you got to it
from Twitter or something because this
contains a lot of TCO lengths as well so
there's actually an excellent chance
that you are in that data set somewhere
that's neat okay cool back to that all
right so anyway that's essentially how
kabana deals with a whole bunch of
different dimensions it lets you map up
some dimension of the data to some
visual dimension of stuff and it's a
work it's a it's kinda it's kind of a
flow that we found that we went through
a lot when we were using cabana 3 we
would first start searching then we'd
realize that we didn't actually know
what we were searching for and so we go
and we'd create a whole bunch of these
panels right the problem was is that
Qabbani three was really designed to
search and have a dashboard but
sometimes you just didn't need that
answer over and over and over again you
didn't actually need it on a dashboard
which is why we built the whole
visualization aspect of this sometimes
all I needed to know was that a picture
of a heat shield was a really popular
thing i'm not going to need that to know
that tomorrow and i probably won't need
it on a dashboard if I got to an answer
that I would need to know repeatedly
such as things like how big of the files
i'm serving how many unique visitors do
i have every day those are the kind of
things i end up putting on a dashboard
the ideas we were trying to build a flow
that allowed you to get just the amount
of information you needed without
forcing you to save it in some way or
keep it around for later put it on a
dashboard or put it into kind of a fixed
panel so of course Qabbani lets you save
these visualizations and reuse them if i
had needed to see that you know chart of
the JPL news urls i could have saved
that and put it on a dashboard i could
have put it on multiple dashboards I not
only that but right now i'm mostly
looking at my USA gov data if I had
other data I could put
that's stuff on a dashboard to come on a
three you could only link one index to
one dashboard Qabbani for as many
different indices as you want which
actually brings up something kind of
neat let's go over to my dashboard real
quick and I'm going to get rid of the
JPL news user because I don't really
need to know about them uh so an
interesting bit here is that yes I can
put multiple things on over here I
actually want to see more than just that
tiny slice of time that JPL news was
active okay so interesting bit here is
that I have these two indices I have the
USA gov index and I have this user's
index and they both share one common
trait and that that's that both
associated with a username and so
because I have that field user in both
places I get this neat kind of
client-side joint effect essentially so
let's see I have down here a table of my
top users and again we've got you know
JPL news user there and all these other
ones but i'm going to pick on JPL news
again and i'm going to click that bar
and since that only represents one
useful searchable dimension come on it
just goes ahead and creates the filter
for me and okay so now i can see where
the JPL news user was popular so mostly
in Europe turned out that most those
link clicks came from Europe and because
i have on the same dashboard the users
index and a list of all the users that
gets filtered at the same time so now i
also have all the details about that
user even though it was stored in a
separate index from all the event data
that i was normally looking at I get to
get all the context about that user
because we were making dashboards this
much more powerful and because we were
introducing so many new visualizations
and because we were using aggregations
and because the questions we let you ask
got more complex we really needed to
speed up the way that Kabana did things
so in come on 23 here's what happened
you had 15 panels on a dashboard which
is a pretty complex thing what kemana
would do is it would say I deal with an
elastic search and it would just chuck a
bunch of HTTP requests at elasticsearch
now there was an issue with this and
that's that it often didn't chuck them
directly at elasticsearch with cabana 3
you had to have a web server and many
people decided well I'd rather set up a
proxy and have Kabana talk to
elasticsearch through that totally
totally reasonable the problem would be
is that a lot of people would grab an
example for say Apache or something off
the internet an example of a reverse
proxy and that reverse proxy
configuration would have this line in it
that said I don't let any more than
three connections per user through at a
time so I've got 15 things and the
browser just generated 15 HTTP requests
so the browser is going to sit there and
spin it's just going to sit there and
wait until it can issue more requests
which means it thinks it's going to
issue 15 Apaches going to say no you're
not you're going to issue 3 and so
what's going to happen is in order to
get to that fourth request it's gotta
wait for one of the first three to
finish to get to the fifth requests it's
gotta wait for one of those three to
finish so on and so forth which means
that you're constantly sitting there
waiting for stuff and while you're
sitting there waiting for stuff there's
new data coming in to elasticsearch
right so by the time we actually get to
like the 15th thing who knows how
consistent our answers were besides the
fact that it took a really long time so
how do we solve that in cabana for a we
got rid of the need to set up a proxy we
just build back end in we do the the
essentially the proxying ourselves with
a minimal amount of
restriction on it so we keep things too
like non-destructive get requests we let
you write to the doc abana index but
that's really the only index that you
get to write to the other way that we
solve this is we said don't chuck 15
HTTP requests all at the same time
that's not particularly efficient
elasticsearch has a better way of
dealing with that we just bundle
everything up into one big requests now
so instead of issuing them all
separately we put them all into the
elastic search em Search API and we make
sure that elastic search runs them all
at the same time right it never made any
sense to just run three at a time when
you've got you know five or six
elasticsearch nodes and each of those
have multiple cores why am I just
running three just run them all and let
elasticsearch figure it out which it
does quite well we found that on complex
dashboards things that we're asking a
lot of questions we were able to reduce
the query time from a annoying 30
seconds down to a slightly less annoying
10 seconds a pretty decent increase not
only that but because all the questions
were asked at exactly the same time they
all have the exact same view of the data
that's essentially how we addressed both
the data discovery and the performance
aspects of things as well as some of the
flexibility and we did most of that in
Kabana for we recently released cabana
41 41 came with a whole bunch more
performance improvements the big one
being that when we went to design Kabana
for we're like okay we need to cash a
bunch of stuff right we're doing we're
moving a lot of data around and it's
important that that we cache things of
course the problem with cash is that
cash is essentially again you know
remembering what just happened and
remembering things again takes memory
and so we did a pretty good dive into
okay this caching that we're doing how
effective is it really and we turned out
it wasn't as effective as we wanted it
to be so we got rid of a lot of the
caching that actually ended up speeding
up a lot of things in fact in some
places kabata for one is
more on the order of like 10 times more
memory efficient than four was now a lot
of that was cleaning up some code that
we in law of a lot of it was just
getting rid of caches that we weren't
using kemana for is a lot faster of
course we brought our come on for one is
a lot faster of course we brought in
some new new features to such as filters
we've made them better we've added some
functionality to them I for example
geographic filtering right I can do Geo
filters now so if i want to see just
this point on the map i can get just
that point on the map another thing that
we added was a filter pinning and this
was to solve the problem of i answered a
question here but i have the same
question somewhere else i'd like to use
the same data in another part of the
application i created all these filters
I don't want to create them again can
you just keep them around for me so we
added filter pinning which basically
just says keep this filter so I'll
select little pin icon and wherever I go
from now on keep that filter so when I
go over here I've still got this geo
filter which means that all of these
things are still relevant to that
specific geographic area fied selected
you know user time range all that stuff
just sticks with me of course I can
still get rid of them and see everything
the other thing that we added was filled
formatting so you put stuff into
elasticsearch and it's in a format that
you need to be able to search on it
easily right so I do something like I
have a bites field I don't store that as
80 kb right i don't start as 80
kilobytes I store it as 80,000 but when
i go to actually look at it i don't
constantly want to look at 80,000 i want
to look at 80 kb so that was something
that we added was the ability to have
custom for matters so if I add bites
here I can see that yep I actually get
that in the proper format and I also
added URL links
so we have these field for matters that
let you say exactly how you want the
thing to be displayed so in this case I
was storing URLs there I want to show
them as links that URL for matter
actually does other stuff even though in
this case we happen to have URLs in
there you don't actually have to have a
URL in the field in order to create a
link to it for example let's say that
you stored the ID of something right
maybe I've got user ID in that list and
I've got some other application that i
use for managing users this URL for
matter is actually templated so you can
use that value and insert that into a
URL so you could say link off to another
application or something for for context
this is one of the places where we first
started introducing real flexibility
into Qabbani on a developer level this
is the first place that we've really
started to document the API for doing
this yourself because we said that look
we can hit like a really broad use case
of what people want to do with showing
values of fields but we're not going to
get it all we need something so that
people can do this in a custom way which
we added so now if you go in and look at
our existing field for matters you can
come up with your own they're all
written in JavaScript they have a
differentiation between looking at
things in text for example in tool tips
and such and then having them
represented as HTML for something like
this so you can do things like make
images in line or you could code a field
with some color depending on what its
value is any other of custom logic that
you want to introduce and we plan to
kind of continue this trend of making
things expandable where we're
documenting the AP is that we use to
build features in cabana very constantly
now so the next thing that we're
building in cabana that we're really
excited about is authentication this is
something that we're working on right
now and we started working on it we
again said this needs to be flexible
people need to be able to do this their
way
sure we can build authentication systems
that hit a pretty broad spectrum right
we know that we can integrate with
elasticsearch shield because that's easy
it's like the thing people use to secure
elasticsearch but we know that that's
not the thing that everybody uses so we
want to make sure that for
authentication you can integrate with
say your corporate off system so we're
building this in a pluggable way if you
go to the github repository there's a
ticket explaining all about how we're
going to build pluggable authentication
something that we've already started on
the other thing that we're doing is
we're trying to allow you to extend
other parts of the application for
example building your own visualizations
we're starting to document the
visualization API so that if you have a
particularly niche thing you've got some
way that you want to see your data maybe
you've created a visualization as a
standalone thing you want to bring it
into Cabana it's something we want to
start allowing you to do in addition you
may have noticed that I haven't been
swapping back and forth between like
keynote or PowerPoint or something
during this uh before I gave the talk I
wanted to see well how easy it is it to
extend cabana to add completely new
functionality so I built a slideshow app
for cabana which is why I have that
little slides tab at the top this is
built with reveal jas which is just a
really simple JavaScript framework for
making slideshows you don't actually
need to know anything about reveal j/s
or JavaScript to use this they have an
online builder for these that's all nice
and point-and-click if you grab the
stuff in this github repository and drop
it in your plugins directory in kabata
it'll add a new slide step for you if
you replace the I think it's called like
offline dot HTML if you replace that
with your own slides that you build on
the online reveal j/s thing you'll put
your own presentation in there and it'll
just kind of work ah but it's it's about
the simplest app you can imagine if you
are a developer you can go into it and
you've got kind of a very lightweight
seed for building your own stuff into
Kabana
we also want to make sure that all of
these things are always available to you
we're an open source company everything
we do is in the open we haven't closed
source anything come on and we don't
plan to which means that we want you to
be able to use stuff as soon as it's
available so we started publishing
snapshot builds and well I just gave you
a nice diatribe about how we want to
share everything mostly these are
self-serving we really just want to
sucker you into being beta testers for
us which has been great for us because
we started publishing these right before
Kabana 41 and we got tons of feedback
I'm actually shocked at the number of
people who are willing to to use
something like way before we've qaid it
at all but served as a great test bed
for us we fixed a ton of stuff that hey
maybe we wouldn't have found we also
improve the behavior in a lot of places
people said hey this could be just a
little better here it's because we give
early access to everything in an easy to
consume way so please grab it let us
know how we can improve find bugs fix
bugs and that's about it
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>