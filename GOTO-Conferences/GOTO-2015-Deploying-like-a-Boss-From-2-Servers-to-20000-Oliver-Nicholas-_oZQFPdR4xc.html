<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Deploying like a Boss: From 2 Servers to 20,000 • Oliver Nicholas | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Deploying like a Boss: From 2 Servers to 20,000 • Oliver Nicholas - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Deploying like a Boss: From 2 Servers to 20,000 • Oliver Nicholas</b></h2><h5 class="post__date">2015-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_oZQFPdR4xc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome we're going to talk about
deploying like a boss from the journey
really from two servers up to tens of
thousands so my name is Oliver Nicholas
sometimes known by the handle big o for
obvious reasons if five-foot-nine and
you know we're going to talk about
deployments which is a is really a
thrilling thrilling topic most of the
time in this context we're basically
talking about the act of taking your
code from one place and then putting it
in another place you'll have to excuse
my absurd use of transition effects this
isn't my first rodeo but these are like
too much fun not to use so it's a little
more exciting than just moving bits
around we also need to touch on load
balancer management which is another
really terrible dinner table
conversation topic and also the
distribution of these build artifacts I
know this is the last talk before lunch
I remember reading a study that was like
if this was a Parole Board hearing I
would have a really low chance of
getting of getting parole so just just
stick with me I promise it'll be sort of
interesting so first off quick
background who I am and what right I
have to talk about this for a little
while I work as a staff engineer these
days with uber Technologies Incorporated
we are what's known as a TNC
transportation network company and that
we make this remarkably popular app
which connects independent operators
with folks who are trying to get places
we do this in 311 cities across 57
countries over a million times per day
more relevant to this talk on the back
end we do that with about 300 separate
micro to macro
services these are sort of different
orders of magnitude of traffic that
these services serve deployed across
somewhere around two to three thousand
servers / data center and we're sort of
constantly changing this but it's
between two and four data centers right
now always be scaling and do you mean we
do at least tens of deployments per day
across all of our services so it's it's
very active environment and code is
moving around really frequently and we
need to be we want to keep agile we want
to be able to make make deployments all
the time not worry too much about them
crucially want to be able to roll them
back as well me personally made my first
webpage in seventh grade I was really
proud of that sometime around 96 so I've
been working on this problem of how do
you get your code from one place to
another for a pretty long time I took my
first job at a tiny incubator in San
Francisco called Google Labs we were
like five guys in a room big enough to
hold four guys I think and our
deployments they're pretty frequently
brought down the site i took my second
job in 2008 at yelp in my second week of
there actually i took down the site by
deploying soon me some code that worked
with the version of python that we had
in the dev and staged environments but
didn't work with the version of python
that we were running in the production
environment which was a real good lesson
learned about how you test code before
it goes out and then in 2012 i joined
uber which as I mentioned we have a lot
of code to move from place to place when
I got there a little ways into the time
I got there we had scaled to a certain
point at that point I rewrote kind of
the main deploy script and then I gave
it to other people so that they could
use it to bring down the site from time
to time so that's sort of I like to I
like to think of this is like a
lessons learned through drastic mistakes
and millions of dollars in lost revenue
it's a good way to internalize it all
house that's a bit about me so what do
we mean by deployment system this is the
vague broad term I guess by some
measures you could include build servers
see I servers any other integration pre
flight tests that you might have the
entire production surveying
infrastructure the load balancers but I
want to talk specifically about the
evolution of the piece that does the
copying of the bits and sort of brings
them live so that as distribution and
orchestration so let's dive in and look
first at sort of a nascent typical
nascent deployment system when you first
get started on a project I find that
that's brutal but I find that frequently
this is basically the the first
incarnation of a deploy script for most
most projects that are out there you
just press like up in your terminal or
search your bash history for the for the
last time you executed this command from
your local like development box and use
this this old-school tar SCP combination
in case there's anybody who's like not
familiar with this tar is this tard
dates to 1979 and is literally it's like
tape archive it does lots of things in
our use case it takes a directory and
combines it down into a single file
which you can then copy over to another
server and then untoward and sort of
rien fait the original directory
structure SCP really hope everyone knows
that one the secure copy just sends your
bits over a ssh connection if you want
to get like real janky you could use our
CP and not bother with all that pesky
encryption but then this the second
command that we see in this pipeline
which does a tar
the output of that to an SSH command
which then execute some code remotely
the second part just untargeted on the
destination host and then the third
piece at the end there just like
restarts your code it starts the new
code up and actually this is even this
is a hub you can build on this there's
actually programs that do a few of the
combine a few of these steps down
there's our sink that's a pretty typical
one you'll just you know you're writing
your code you hit that go back to your
bash history hit your arsenic command
and it just sinks the changes that
changed files this is basically what our
sink is good at it examines the mod x on
your files and maybe hashes of them and
then decides what actually needs to get
transferred over the wire so then the
last part there right is just restarting
the the process the drawbacks of this
it's not atomic you're changing the code
files while the code is running which
means if you get you know some module
that hadn't been loaded yet that is
suddenly loaded by a new request that
comes in you'll get mixed versions of
your files running like in in in program
space there can be a performance impact
during this during this process because
you're doing a bunch of work on the the
host that's actually running the code
before you even do the deployment
there's no load balancer management I
mean this restart right here depending
on how you've written it that might just
like kill the process and start it up
again so you might drop existing
connections you might have your a P and
accessible for a while while this is
happening it's just sort of a brittle
process the great thing about this is
that it's real damn easy to do and at
this stage you probably don't care about
dropping traffic you may not have that
many requests coming in or it might not
might not cost you any money if you drop
some some hits so this is really how I
think most projects start out and it's a
totally appropriate way I think to start
most projects especially when you only
have a single server that you're
deploying to but
if you're lucky the project grows up and
so move here to the the Middle Ages I
call them where where we have some
existing projects out there that help us
do deployments that are really really
like relatively speaking quite robust
and could take you pretty far and in
fact can take you like can take you a
little too far and that you you end up
with some pretty painful situations as
you start to scale up the middle stage
deployment systems you really you end up
with these these third-party libraries
like Capistrano and fabric this is
really identifiable as a evolution of
this tar SCP pipeline these libraries
are just these dsl's written in
higher-level languages capas Ruby fabric
as a Python library and they basically
are just encapsulating your ssh session
management they come with all these
convenience methods for things like
unattended pseudo passwords copying
files around capturing and parsing
standardout even rollbacks you go pretty
far on these typical setup could involve
all the stuff we see here like build the
code sink into the deploy targets take
the the target out of the load balancer
shut down the app swap out a symlink to
to put the new version of the app in
place start the app up heart checks
health checks warm up put the target
back into the load balancer and then
move on to the next host and these
things are so like Capistrano fabric
there's so much convenience to them that
with about this much code this is I
don't know 10 15 lines you can actually
get all of those steps that are right
there so these are this is this is
pretty powerful stuff that really takes
you takes you pretty far the the pros
here is that these are open-source
libraries they've already been written
for you they're really easy to use
there's lots of recipes out there for
the special like any sort of special
case you may have pretty much any weird
deployment workflow you want to do
somebody has probably already written
the code for
you and realistically they are good
enough for really into the tens of
servers after that you start to run into
weird issues things are always going
wrong with at least one server when you
have more than tens of them or even like
50 of them maybe then your script one
day does something really stupid it
tries to open one hundred SSH
connections at once overload something
or other things really start to fall
over and so you have to do a lot more
tuning a lot of careful work after tens
of servers I find and then the cons this
is so this is really not good enough for
hundreds of servers you're still
essentially utilizing this old-school
tar SDP pipeline which is to say that
you have a single node that has your
canonical copy of your code on it and it
becomes pretty easy to knock that or
something else over like an entire rack
if when you have 100 200 300 production
servers and all at once you ask all of
them to download a 300 metal from this
one central server you can extend away
from that i think when i arrived at uber
the deploy scripts generally speaking
would ssh to each machine and do a git
pull they're actually keeping a local
copy of the of a git clone of the repo
and then do a build on that host but
that's got all sorts of problems with
where you're doing the build work it's
very expensive it's not particularly
secure bunch of issues there and then
these have poor support for multi-user
environments there's no there's no lock
around the deployment process although
you can resolve this you can you know we
have a deploy 01 and that's your
deployment server and you have to ssh in
there and it uses some f locking to
prevent multiple people from running it
but really this doesn't this doesn't
feel good once you're sort of tens of
employees it's harder to coordinate your
deploys and you have a lot of servers to
go to it really starts to get quite
brittle a quick aside here build
distribution this is the actual copying
of the bits until now we've been running
SCP rsync whatever from a single host or
maybe doing this really weird thing with
doing get pulls
remote host but you're still then
pulling the git repo from a single get
server this is really not going to last
very long before you start to run into
some some difficult situations we really
want to avoid this single point of
failure because those single points of
failure especially when you're running
your own full racks you can frequently
you can really knock over other pieces
of infrastructure as well which is not
pretty to do so more scalable approaches
we can do the tiered arson coast so we
can instead of just having the the code
go to one server we can arson get two
three or four intermediate hosts I'm
like logarithmic number of the total
number of deploy house and then you're
deployed targets randomly pick one of
those hosts to rsync from probably more
popular as you get a little bigger you
can stick these in some sort of
equivalent or some sort of distributed
file system HDFS would be the popular
one I wouldn't advise playing too much
with NFS for this but perfectly doable
and then you get more into the more
exotic options I know Facebook does uses
BitTorrent to distribute their build
artifact now their build artifact as I
understand it is a single multi gigabyte
executable so you know BitTorrent is
good for this because it's good at
chunking up large files and efficiently
distributing that around you could all
sorts of really neat stuff like make
sure it prefer peers that are on the
same rack as you so you get a lot of
benefits from from network locality but
this is this is a little more you have
to write your own BitTorrent clients and
servers for this but really these these
sort of tiered hosts or distributed file
systems are are a definite need once you
get to hundreds of servers and then
they're an absolute requirement once you
get to thousands okay so the the early
ages out of the way we've looked at the
intermediate systems let's see what we
can do after tens of servers for the
actual orchestration how can we
reimagine this this whole model in a
more scalable way the real underlying
issue here is that all of these systems
were push based in general anytime that
you are doing work from one server out
to other servers where the number of
outbound connections is a factor of your
scaling of your service you're going to
you're going to run into into problems
this is just sort of a general scaling
principle I think when you have servers
become inaccessible during the
deployment with these old school systems
you get all these weird structural
issues especially if you're hitting them
serially one after the other if the host
isn't down of it's not responding if
it's overloaded if the rackets on is
overloaded all sorts of stuff can happen
and then when that happens you have to
make pretty difficult decisions about
what to do a server doesn't respond do
you abort the whole deploy do you roll
back the whole deploy you keep rolling
forward how long do you wait for does
this mean that all of your deployments
take six hours because you sort of hit
the button and walk away and they don't
realize that there's five hosts that are
internal and then if you do keep rolling
you end up with this in the push model
you end up with this painful consistency
problem where when your old servers come
back online they don't they miss the
message that they were supposed to
upgrade and they're running old versions
of the code and nobody really knows
about it and so you've got mixed
versions in production so we can resolve
this by inverting the logic to be a sort
of pull based model where our leaf nodes
the app servers
going to ping into a central server and
say what should I be doing here rather
than relying on this push this is pretty
typical I think inversion of control
typical I think scaling property this is
sort of a goal based system where the
these leaf servers are going to say what
what what state should I be in and then
they're going to do the work on their
own they're going to orchestrate it on
their own to get into that state also
once you get past a couple of apps and a
couple of servers that you're 2.2 it
starts to get pretty inconvenient when
those old-school scripts where you have
this hard to go back boo where you have
this list of servers you know this app
deploys on servers 165 that it starts to
feel really really ugly to work with and
the data is hard to get to it's not easy
to share between scripts that might need
that information about which service is
deployed where so specifically at uber
we solve this with essentially this
Hardware management database called
custo this is a project that was written
by the guy's a day go back in the day
and it's really just this this
management database that consists of
server objects and pools and then you
can either look up information by pool
or by server so you can tell from this
data here that a PO one is in the
production rack double oh one service a
and service be pools and then you could
also look up and say which are the
servers that are in the service a pool
and so you get this programmatic
interface to finding out how your where
your hardware is custo itself also these
these server objects are pretty pretty
rich and so you we actually store all
the information about you know how much
memory is on this machine how much disk
space would CPUs that kind of stuff I
highly recommend this once you get to a
certain size of infrastructure if you're
running your own servers a little less
relevant if you're on AWS or something
somewhere
okay so we have this pull model and how
do we put that into play we built our
own thing called you deploy which is the
specification for it is only slightly
less fuzzy that it's showing up on here
so basically there's a coordinator in
each data center which is the box inside
the box on top there and then these big
black boxes are data centers the
coordinator on the bottom is called an
intermediate and then a worker on every
deploy target every app host that we're
running we put one of these workers on
the workers are pulling the coordinator
every so often for their target state
what what what should I be doing what
versions of the code should I have
locally what should I be running that
kind of thing the coordinator hits this
custo database and has this you know a
priori concept of which machines are in
the service pool and then it can use
that and a associated deploy policy for
every individual service that it knows
about to decide how to instruct these
servers when they do make requests how
to proceed so this deployment policy is
customizable so you can say things like
you made the coordinator can proceed
with actually kicking off the deploy
once ninety percent of the servers are
downloaded the code and so this allows
you to sort of automate the the
consistency issues that you might have
with a really large infrastructure and
machines that periodically come in and
go out of availability and then the
intermediate coordinators take a cue
from the primary as soon as deployments
are kind of started so we actually
perform our deployments in parallel
across data centers this becomes pretty
important you know it since every new
data center is essentially you know
another two thousand machines so we have
to think about so this is the the goal
based system incidentally the way we
haven't configured these coordinators
are pinging or sorry these workers are
pinging the coordinator every 30 seconds
or so and then as soon as you start
kicking off a deploy in the YouTube boy
UI which I'll show you in a second the
next time one of those workers pings the
coordinator for a state update and the
coordinator knows that that workers from
a machine that's going to be involved in
this deploy it says go into overdrive
ping me every five seconds and that way
we can sort of reduce in the general
case we we don't have too much load on
the on the coordinator but when we're
actually doing a deployment the machines
that are relevant to it we can they'll
ping more often it we can more tightly
coordinate the timeline to do a faster
deploy so I'll show a couple pieces here
this is sort of the the first page you'd
see these are all the things that have
API and the name and it's kind of nice
you get the the app itself the type of
app you know there's a node app and
there some Python apps some some basic
static pages you see how many instances
are there and health of them so we can
see on this third one down that four of
these instances are in some bad state
and the rest are in a good state which
is pretty cool we see what we've what
we've actually deployed when we did it
status of the current deployment I guess
this is this is sort of the the control
the control dashboard for pretty much
all deployments at uber this would be
the where you drill down into a single
service you're basically impossible to
see but you're seeing that you can
actually deploy between stage or
production environments you can target
these separately and then on the bottom
here you're actually seeing state of
every every server that's running this
code so when those leaf nodes are when
those workers are pinging in there
they're giving status updates to the to
the coordinator and the coordinator can
show them in this UI so it's actually a
pretty rich system that has that works
well for sort of in the hundreds of
servers I think I think there would be a
bunch of issues once we got into tens of
thousands for any given service but
works good up to this point so you go
into the coordinator and you would kick
off a deploy and what you're seeing here
is for that one of those API services
you hit the build button and it actually
it's pretty cool it goes and hits the
the git repo and shows a list of the
last commits and you can pick one of
them and that's the one you're going to
do a build of hit the button so let's
say in this in this case it's version
ABC and it's going to go do a build and
create the the build artifact in this
case it would be a Python virtual end
but it could be you know could be a
docker container in some cases or could
be anything any sort of any sort of
artifact then next time the workers that
are involved in what's the build is done
next time the workers that are on this
services machines as cluster reports
next time they call in the coordinator
is going to tell it hey the list of the
versions of code that you should have
includes this version ABC and then once
the coordinator by its deployment policy
is satisfied that enough of the servers
have the code can move on to the next
phase of the deployment where it starts
activating them in tranches and they're
gonna they're just as they ping in it's
going to say it's the coordinator is
going to know oh I've already done you
know the first two windows so now i'm
doing servers 20 through 30 so when
those guys come in give them an updated
indication of which version of the code
that they should be running and then the
deploy the poi targets actually manage
their upgrades from there remove
themselves from the load balancer
activate the new code warm it up and
then return themselves in the production
pool so it really pushes pushes work off
of the off of the coordinator so that
it's only really doing passive work in
the order of the number of workers that
are out there also while this is
happening the coordinator is talking to
other systems which are monitoring the
health of the service that's being
deployed so we can look at things like
response times the change exception
rates going up and and then it can
the coordinator can then from its angle
initiate a roll back so we can as those
workers are pinion in every five seconds
it can it can say oh we gotta we gotta
we have to either to abort or we can go
back to the last version of the code and
we keep multiple versions of the code
present on the deploy targets so that
it's very quick to do the rollback so
there are some drawbacks we still be
static server pools there in custo
rather than in a file but it means that
the deployment kind of relies on having
this weird static mapping of service to
server slow to update kind of awkward to
to deal with and then it also means that
the deploys have to be windowed rather
than like a full red black deployment so
if I have 10 servers in the API service
pool when I go to do a deployment well I
can I can take like two of them out
upgrade them put them back in take two
more out upgrade them put them back in
the most that I can take out at any one
time is essentially you know how it's a
factor of how over provisioned my
service is and how comfortable I am
reducing capacity so if you tune this
wrong a deployment that goes fine during
low traffic could actually knock out
your service during a high-traffic
period and so because we only have those
ten those ten service to work with so
it's it can be a little constrained so
this is sort of the fun stuff this is
actually my current area of focus this
is what I'm myself working on right now
the future well where are we going to
take this so that we can overcome the
remaining limitations until we find some
more limitations how many Quick Poll how
many people here are familiar with
mezzos a good number okay cool well
mezzos is this resource management
engine pluggable conduit for scheduling
tasks jobs against server resources the
mezzos people call it a distributed
systems Colonel there's a lot of
there's a lot of great nomenclature
around above the mezzos ecosystem this
is kind of what it looks like it is a
it's essentially cluster management it's
in the Apache foundation right now it
consists of this I'm afraid this is a
power button or a laser button I'm not
going to risk it it consists of a
high-availability set of master nodes
which are coordinated by a zookeeper
core and and then a slave instance
that's running on every worker node so
that's that's actually in some ways kind
of similar to how you deploy it works
this is where it gets weird these slaves
make resource offers to the master they
say I have so many CPUs so much memory
so much disk space available it's kind
of cool you can define custom resources
that get offered through as well and
then the master is going to pass those
offers on to these frameworks that it's
configured with this case I've put
marathon up there but there's Jillian
others and then that merit that
framework gets to decide do I have a job
that I want to run that fits into this
resource offer that I've just been given
I have the server it's tagged as having
you know kernel version 313 and I've
been told that I have 12 cores and
twenty four gigs of ram to work with do
I want to schedule something here and if
it does want to accept it then it passes
back this is how many resources my job
needs this is the job I want you to run
and this is the this is droplet which
run so then there's these sort of
acknowledgments that go back and forth
some sort of magic happens and then your
code starts running and then the the
slave decrements it's available
resources so the next time that it makes
an offer it's going to reflect the fact
that you've just used up some of those
cores and some of those some of that ram
and this doesn't really deal with the
code distribution part so all that stuff
that we went over is still sort of
relevant to to this is quick examples so
slave might make an offer this you know
22 cores and 32 gigs of ram
the master sends it off to the
frameworks the framework might accept a
portion of it and inform the master so I
want one cpu and I want 64 megs of ram
and just run the command yes it probably
familiar with the yes is like my
favorite command to do this because it
just chews up one core the man page for
it is probably my favorite man page in
UNIX its be repetitively affirmative is
the only thing it says yes just prints
yes to standard out in a tight loop and
then the next offer would have taken
that into account this is all quite
magic its fault tolerant if the slave
crashes it's doing some check pointing
locally and then it when it starts back
up it can usually figure out where it
was you can also configure it so that if
it crashes and it starts back up that it
can just say it can just declare
bankruptcy kill everything that's
running start over if the master crashes
then there are these other other masters
in this quorum that can take over from
it and then the frameworks it's kind of
interesting so the framework is the
thing that cares about what's actually
running mezzos is tracking individual
instances but the framework is the one
that scheduled the job in the first
place so the frameworks the one
ostensibly that cares about it the
framework is expected to make a durable
commit about what it thinks the state of
the cluster is just before it tells
mezzos this is what I want you to run so
if the framework crashes when it starts
back up it has this list of tasks that
it thinks it's scheduled and then it can
ask for this reconciliation process
where I can say hey mezzos what do you
know about you know task a and mezzos
can check its state that's been
communicated between slaves and master
and say this is the state it's it's
still running it's good to go or it's
lost it disappeared while you were gone
and you should update your own internal
state to reflect that and so that is
mezzos pretty much it's actually this
remarkably simple system for
apportioning out physical like cluster
resources to these frameworks that want
to do work and you can really run
anything you want
you can run containers you can run
processes you sort of configure it
anyway you really you really want to
they've added in a bunch of really cool
support for automatically setting see
groups so you can get resource isolation
it's it's it's pretty great still sort
of in the early days though lots of work
going on here so we at uber are
specifically looking deep into starting
to deploy a particular framework called
marathon so this is one of those mezzos
plugins essentially they described it as
a cluster wide in it and control system
for services in C groups or docker
containers it has built-in support for
various deployment policies similar to
you deploy it does its own health
checking it does automated rollbacks
that are all configurable which is
pretty sweet and I'll talk more about
the overlap between this and you deploy
in in just a second but it also has this
really sweet constraint system so i can
say something like given a nap I want
you to distribute this evenly across
racks which is great for you know
reducing the sort of failure modes of
your application you can tell it don't
put more than one instance of this app
on any given server if you need that for
some reason where you could say only
deployed machines that have this certain
tag on them like a kernel version or a
Python version or anything like that so
it's a pretty richly defined way to to
get specific constraints on your
deployments so this example I have right
here is like a really quick way to like
burned electricity you can with just
like a few clicks of this button a few
few taps at a click of a button you can
you can deploy 300 instances of yes
running across your infrastructure and
this is this is basically how I test
things all day long it's pretty fun it
also has this great rest api so this UI
your scene is really just a just a toy
really okay so how do we integrate these
two things what's the what do we want to
do by integrating them you deploy has
some awesome fee
it already it's got this beautiful
interface for browsing our code repos
and for kicking off builds it has
authenticated authorization support you
know if you're under PCI requirements or
if you have an organization of six
hundred engineers like we do this stuff
starts to become more important and also
probably very custom to your own
organization you deploy gives us
coordination across multiple data
centers that is not a feature that's
really in mezzo mezzo siz not designed
to run across datacenters zookeeper is
definitely not designed to run across
data centers so this becomes sort of
important and we get this higher-order
health checking rollback functionality
we can cost we've customized it to look
at our particular infrastructure and
know what we think is a bad deploy look
in our you know exception tracking
systems that kind of stuff but mezzos
marathon have some suite features as
well it already they already built all
this stuff for high-availability masters
with zookeeper coordination it's kind of
nice to have that done already as most
really shifts the focus from individual
instances to like clusters of work the
mezzo slaves are tracking individual
instances but when an instance dies it's
not like oh this is the machine that was
dedicated to run that instance we have
to restart it in place it's hey that hey
something died and the slave reports
that back up to the master master report
set to the framework the framework
decrements its run count by one and
those next time I get an offer I need to
schedule a new instance of this job
somewhere on the infrastructure so we
don't really care about those individual
instances because in a big enough
infrastructure things die all the time
like you run into fatal exceptions left
and right you know you'll get I don't
know you get a cosmic ray bit flip and
suddenly something crashes it just
happens so your your ops team will will
definitely appreciate this
characteristic it also homogenizes the
cluster resources so you're not really
thinking as much about individual
servers so much as a vast sea of CPUs
and rams and disks and stuff
and that's probably I just sit so what
do we do how are we going to combine
these two we're just going to mash them
together and good old composition what
we're actually going to do is we let you
deploy kind of be the brain and the UI
that decides what gets deployed and when
it gets deployed and it keeps watch over
like cluster health and then we let
mezzos marathon handle deployment
strategies resource allocation instance
health that kind of stuff first order
approximation in this diagram okay so
another neat thing is this makes auto
scaling much easier by shifting the
focus from where do you explicitly want
instances to run to just give me some
operating restrictions and tell me how
many instances to run mezzos marathon
really helps solve this doing the work
part of scaling it's easy to scale up
the app so what we want to automate is
the doing making the decision of scaling
so we're sort of starting to still work
in progress I guess we're starting to
deal with this basically we're we're
looking at running our everything that
we deploy under a sea group or under a
docker container the infrastructure
really supports both cases but it gives
you hard resource isolation among your
running processes this gives you fine
grained utilization metrics for every
service that you're running across your
your infrastructure and then from that
you can derive scaling decision so you
can look at sort of global resource
utilization for you know the API service
and say this thing is getting too like
ninety percent of its CPU utilization
that probably indicates that it's it's
serving too many requests for
the amount of workers that are out there
let's scale up the number of workers
we're still working on this it's
obviously you have to be very careful
that you don't write something that
accidentally scales your server service
to nothing or uses all of your cluster
resources because of some downstream
dependency or momentary blip there's a
lot of damping in there but this is
between these two between doing the work
of scaling and automating the decision
to scale suddenly your operations team
has a lot less stuff to do which is
which is pretty sweet I spent two years
at uber as the ultimate on call for
every escalation policy and I can tell
you that this would have been this would
have made Friday nights a lot more
enjoyable for those two years so this is
all you deploy a marathon interaction
and it's actually pretty easy to write
your own oh god to write your own
frameworks for mezzos the the the the
interface is really quite
straightforward and so someday we might
just take you to play and promote it
into a full mezzos framework for now
marathon has a lot of this stuff already
built in so we're just using that now
there are a jillion other mezzos
frameworks out there people are really
like it's really fun to see in the
infrastructure world some there's a ton
of focus that's going on to this cluster
management space so there's mezzos
google has Cooper Nettie's that's just
sort of gone out what am I missing here
docker themselves have just released a
swarm which is a similar type of
orchestration engine so people are
really starting to to catch on that like
we're really as a as a world as an
infrastructure world we're moving away
from well we're moving away from small
systems we're moving we're moving
towards eating large clusters of compute
capacity and a lot of people are putting
effort into this and so people have
written a ton of mezzos frameworks which
is pretty cool there's these task
schedulers there's marathon twitter has
their own which is
fantastic I mean it's pretty much
feature comparable with marathon called
Aurora you can run Hadoop on it spark
storm Chronos Chronos is an airbnb
project for running cron type jobs on
your mezzos cluster people are doing
file file systems or data stores so you
can get frameworks for HDFS twitter's
just released one called my Zoe's for
running my sequel on mezzos imagine not
setting up individual my sequel servers
and just having this giant mezzos
cluster that runs all your various
workloads and you're saying and you're
like click I want like my sequel and it
automatically deploys in you know
replication topologies to appropriate
machines it's pretty it's pretty amazing
with like the resource isolation that
you would need their hyper table
Cassandra you can get elasticsearch
framework there's a Jenkins framework so
you can just spin up your Jenkins slaves
really easily on ms-dos cluster and then
there's these cray this Chapel language
there's these parallel programming
languages that have been essentially
ported to work on under the mezzos
framework to use that portion resources
out the mesosphere guys are doing a
pretty amazing job with this there in
San Francisco venture-backed group of
some I think Twitter employees and
people from all over and they are there
really they're really focused on
advancing the state of the art with with
mezzos which is which is pretty cool to
see so the long journey to get here we
start from this simple shell pipeline
advanced to these higher high level
language dsl's that that automate a lot
of the nitty gritty nuts and bolts of
these systems for us then once you get
to a certain scale you really need to
invert the control flow so instead of a
push model you have sort of a pull model
then you sort of want to once you get to
even greater scale you kind of want to
start abstracting away even the concept
of individual servers to some degree as
much as you can building on the blocks
you already have
have so that that's so that you don't
have to you don't have to think about a
million things going wrong at once you
just think about the health of the whole
and then you also have to work on these
higher availability distribution models
as you get there since one server will
will not be able to feed out code to
your your thousands of servers in your
infrastructure which of course is a good
problem to have so go forth and deploy
like an evil genius and we're a couple
minutes early happy to take any
questions if there are any on this
titillating top I guess sir sorry for
your auto scaling framework for May so
sir using like some sort of complex
event processing system for that light
drills fusion or a great question i have
an intern who started on a week ago
today who's like a junior and he we're
going very simple to start with we we've
set up monitoring essentially so that on
each worker node on each slave node we
are reporting in to our central stat
server utilization metrics for all the
instances running on that particular
worker node and then there's an
aggregate in that stat server you know
on a graphite server that says you know
95th percentile cpu utilization for
service a is seventy percent and we are
right now it's literally pull that out
or maybe look at the five-minute
ten-minute trailing average and then and
and have a target in mind oh I want this
to be this should always be at sixty
percent utilization and then if it's off
from that calculate based on the number
of CPUs that each instance gets and the
number of instances that are currently
deployed either need to scale up this
much or scale down this much so you know
first revision it just spits out a
recommendation second revision will have
it actually like make the change itself
and then we'll sort of make it more
sophisticated let it react more quickly
you know first you want to be really
very careful with this because I have
you know this kid sitting next to me he
was controlling like ubers
infrastructure which it turns out the
management is sort of sensitive about
and so yeah that's that's sort of our
model I think it'll be a little while
before we get into sort of a more
sophisticated like you know controller
mechanism for doing that and make that
make the math more interesting but
that'll be there for sure at some point</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>