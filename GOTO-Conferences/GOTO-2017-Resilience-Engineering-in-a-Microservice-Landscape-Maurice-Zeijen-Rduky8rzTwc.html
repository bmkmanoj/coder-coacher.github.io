<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • Resilience Engineering in a Microservice Landscape • Maurice Zeijen | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • Resilience Engineering in a Microservice Landscape • Maurice Zeijen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • Resilience Engineering in a Microservice Landscape • Maurice Zeijen</b></h2><h5 class="post__date">2017-08-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Rduky8rzTwc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you very much what an awesome
introduction so let's get started
like I said I'm going to talk about
resilience engineering in a microservice
landscape that's what we do at Bolcom
but first let me introduce myself my
name is Marie Sian I've been a Java
developer for over 10 years and
currently I'm a hands-on lead architect
at a bullet comm so for those who are
not familiar with bullet comm very
quickly becomes one of the most popular
web shops and the Netherlands and in
Belgium and we have about 8 28 million
visits per month sell about 14 million
products - about seven active million
active customers and I have about 1200
colleagues and as I 350 in the IT
department so what am I going to talk
about first what is resilience and why
do we need that what do we care then
we're going to see how history is going
to help us in that area and implement it
all for us and then we're going to take
a look at some resilience techniques via
an interactive demo I'm gonna see what
happens if you don't apply those
resilience techniques and the difference
when you do finally I will get some tips
and tricks that we learned at both calm
and we'll look at some operational stuff
and some general experiences so end with
a wrap-up so what is resilience so it's
the ability of a substance or a object
to spring back into shape or the
capacity to recover quickly from
difficulties well that's real world like
for instance of bungee cords like if if
you're jumping and the cord stretches
then that cord is really resilient
against those tensile strengths and but
when it returns back to shape well it's
it's really resilient against that so
that's cool or like you and your
colleague are sick you take only two or
three days to recover and he takes about
a week you could say that you are more
resilient against the flu for instance
than he is but we're in an ID system
so what does it mean for IT well it's
the ability of a system to handle
unexpected unexpected situations without
user noticing preferably or at least
with a graceful degradation of service
and really important that needs to be
able to automatically recover as if it
never happens you don't want to restart
your application just because some error
occurred so that can be a really broad
definition so what I'm now going to talk
about is this situation where you have
an application like the bullet Camacho
webshop which is still a monolithic
thing and it talks to about 40 back-end
services and it does that via rest
direct calls and it's mostly still a bit
of a blocking architecture and in those
cases you need certain resilience
techniques so if you're in the eventbus
situation or a messaging system then you
probably need something else or you need
little less of these techniques so why
do we need it
so failures in today's systems certainly
with a lot of Microsoft microservices
interesting that are it's not you
exceptional its normal it happens a lot
certainly if you have a lot of systems a
lot of things can happen let's see this
this helps a bit okay so for instance
what what does complexity mean at both
gone well we have more than 50 user
facing applications which are talking to
about 120 back-end services and about 60
IT teams that are messing with that so
you can already expect a lot of problems
occurring there you know we need to be
resilient against that so what can
happen well one of those back-end
services would simply fail and go down
or maybe that team implemented a new
version and it's version the new version
has certain box or if it's even not
backwards compatible but it can also be
the network that can degrade or fail but
it can also be your own application
having issues with that new client
library that you're using to connect to
the back-end service and the most worse
thing that can happen is that a back-end
service becomes slow and the reason is
that latency so it
it can it's infectious you can spread
through your whole microservice
landscape even to parts that don't
really have anything directly to do with
the system that is actually slow and it
will demonstrate that later on in the
demo so we need to be resilient and this
is an example of Texas in 2008 where a
hurricane came by Hurricane Ike and this
was a nice neighborhood on the coast and
only one house is really built to
withstand those hurricane conditions and
well of the rest is the result you see
here so like I said I have a demo
running it's actually running on my
machine now and it's a mini service
landscape so we have this fake web shop
and it has a product list page and I'll
probably switch those products and it
talks to a product service to get those
products and if you click on a product
you get to the product detail page and
it talks to the product service to get
its product details but also to review
service to get a number of reviews this
is the example shop so it's really nice
proud of it I like to see we can we can
click on it let me see and I has a
couple of freebies oh nice
and in my demo I can start messing with
the review service so I can make it slow
I can make it fail I can turn it off and
we're going to see what happens to the
rest of the webshop when I do that
but first I'm going to talk about how
I'm going to also going to protect it
like I said we're going to use history
for that
and this works is a library built by
Netflix and it is there to protect you
against latency and fault-tolerance
faults and it provides a means to be you
know graceful in your failures and it
measures about everything it does which
is gives you a great insight and we'll
see that later as well and it's fairly
easy to use and there are similar
libraries on different languages or even
different versions on the JVM you should
check them out but this is all based on
history so in hysterics where do you put
in history well you put it in the
applique
that you're trying to protect so here is
going to try to protect the back shop
and we're going to put it in front of
the client library so the client library
adds mostly in HTTP clients and every
call to the HTTP client is going to go
through his legs first
when History X has this flow of doing
things to give that protection and you
don't need to remember this flow now
we'll walk through it during the
presentation so let's start with the
most basic stuff and this the history
command TS which command is that what it
is encapsulating your call to the
resource and if that everything is fine
it will return the result to your
application and if we look at the most
basic way how you implement that and
there are less bloated ways to do it but
we're not going to look at that now but
this is the most basic way to do it is
that you create a Khmer class which
extends the history commands in this
case returns a list of reduce you give
it fields for everything it needs to do
the 2d a call and then you create a
constructor to get all those fields into
it and you implement one method called
the run and in that one you simply do
the call to the client so here we have a
review client says get reviews and you
provide it with the product ID and it's
return to a list so you do this for
every endpoint not one command for a
whole service no for every endpoint and
if you want to do this in a non-blocking
style because it is blocking then you
can implement the history of the
observable command but I'm not gonna
look at that as well there is a lot of
good documentation on there so he can
you can take a look at yourself but
first how do you execute it so you
create a new command provided that
everything it needs and you say execute
and this is the synchronous and blocking
manner and you do this every time you
want to do a call you're not gonna reuse
this command it's a bit weird but just
how Netflix works mystics works if you
want to do in an asynchronous blogging
manner with a future then you can do
that you do you create the command say
dot Q and then you get a future and you
do your thing with it it's rather a
normal future it's not a computable
future so you can probably forget about
it we also have the asynchronous manner
using rx Java and then in that case you
say dot observe
you get an observable of the list of
reviews and you do your thing with your
observable and this is our ex Java 1
there is no support yet for rxjava 2 or
4 react or if you're interested
hopefully at some point it will start
with history 2 and it will it will have
that support you can also do a streaming
where it's it's similar but then you
implement that hystrix observable
commands and here you see again dot
observe but now you get a callback for
every review that comes over you don't
have a list anymore again here back
pressures not supported too bad but to
be honest often you don't need that if
you're in this style of application so
don't worry so let's look at these
resilience techniques that history gives
us first the fallback
so the fallback is the way to gracefully
fail and windows in the past wasn't that
graceful
we all know this scream right so the
goal of the fallback is to try to give
the user which can also be a different
system to give the best to give the best
possible experience when your system is
having issues you know that in several
ways and a couple of examples are you
you hide the feature it's very simple
you use a default which is called the
static fallback or you try to get an
alternative which is called a stopped
fallback or a fallback via network and
not always a fallback makes sense and
we'll look at that in a couple of slides
so where does it happen in this scheme
so we have this call to the resource and
when it fails which can be an exception
then we go to the fallback so the
fallback if it's implemented and it
doesn't fail itself then we're doing the
fallback very simple if the for work
itself throws an exception or you don't
have a fallback then we will turn the
exception as normal so now let's look at
the demo shop again so we're going to
look a lot of these graphs to see what
is happening within the webshop so here
we have the about a detail page and the
number of requests it's getting and the
same thing for the list page and below
we have the distribution of reviews over
all the detail pages so we see that most
of them have about three reviews
and if I go to the shop again then we
can see if I go with the first products
that it has three reviews oh nice so now
let's see what happens if I turn off the
webshop and to prove that's actually
something that's running on my machine I
have the spring good application that
I'm simply going to kill and now we see
arrows are happening it's not that nice
so if you go to the webshop again and I
click on the first product then we this
is not what we want like we don't want
to give the user this experience this is
not really nice too bad so my demo set
up like I said I can enable and disable
certain historic features so let's
unable to fall back in this case
now we see oh all the calls are
successful again all nice but the review
distribution is zero we have no reviews
nowhere so we go back to the demo shop
go to the first product and indeed it
works again but we don't have any
reviews so this is a really basic
example of a fallback another example
that we also apply a bullet comb we have
a lot of them now but this is an example
that's called a stopped fallback and
it's about this title page on a on a
product list page that we have this
title actually comes from service and
the service uses the category that
you're on and the filters that you have
applied within your search to determine
which title in which text it wants to
display so what happens when that
service simply is down or slow or
whatever we simply fall back to
something that we gave the command which
was that category and we simply show the
category title it's it's really easy but
the customer probably won't notice so
like I said not always a fallback makes
sense and a couple of situations where
you don't want to fall back it's for
instance for a write operation it would
be really awkward if you would say to a
user that you accepted this order when
you actually didn't because there was a
failure so it you simply want to inform
your customer that that it failed you
know you don't want to lie in that case
but it can also be if you're starting
some bets job or something else
in the background you want to inform
that that didn't work
and we've also noticed that within a
back-end service so certainly more the
core services it's really hard to define
a decent fallback so often what we do in
a back-end service is we don't have a
fallback we simply still throw an hour
or we give at the fallback or a partial
results the data and give some meta data
back that informs about you know okay
here is some data but it's not 100%
correct maybe you want to do something
with that at least you fail fast that's
really important you're you're not going
to wait for late timeouts and other
things so where do you implement this
fall back again we have this get reviews
command and hystrix commands that
extends Ezra's command and you add this
get fallback methods that's it and in
this case we're returning an empty list
it's really simple what if you don't
have a fallback as well in that case his
fix will throw away his weeks runtime
exception so you want to catch that
somewhere and to get the actual
exception you say exception get caused
so next thing latency so every call to
the resource is being monitored on how
long it's running so and when it's
running too long you will get a timeout
and if the time what happens then it
will try to do the fallback and well the
rest you know so again back to our demo
in this case I'm going to any fallbacks
I won't do any timeouts let's see what
happens in the when we do that so let me
increase the latency to one and a half
to two seconds so we see a couple of
things for one
we're not processed we're not handling
so many requests anymore everything is
becoming slow because this is the client
latency you see here so we get a latency
of more than seven seconds for the
clients and here below we see the thread
usage and we see that the product
details page is now using more than or
49:47 threats it's not that good to be
honest I
intentionally limited my system that is
not using so many threats at a normal
system would do because I don't want the
thing to catch fire so it has a limit of
50 threats so this isn't really this
isn't really good right so let me first
make it recover okay
now simply set a timeout for one second
and enable it again
oh now we see what's happening because
well after a second we get an error and
I don't have to fall back enabled but we
see that the the time that your customer
is now waiting is a lot less it's still
I'm a big amount it's two seconds but
that's because we're still having a lot
of threat usage and that's what I'm
gonna talk about next and that is we
want to prevent that and to prevent that
we're gonna use Bock heading and low
chatting so here we have a ship and it
has pockets so if that Titanic was one
of the first but they didn't really
implement it correctly
later ships it was more successful but
the bulkheads are these well Blockheads
in the ship that prevented from sinking
when you have a hole because the water
can't flow throughout the whole ship
where do we have this bulkhead in the
schedule Wow if you're executing the
commands before that we go to the
resource call we have a semaphore or a
thread pool and that's going to limit
the number of concurrent calls you have
to the route to the resource so let's
say we set it to 10 that means that if
10 calls is our are in this area here
reticle resource then the 11th comes in
and we're going to reject it and when we
reject it we're again going to go to the
fallback so again a lot of graphs
product detail requests the latency of
the product detail page the distribution
now also the list page and the list page
latency and a threat usage so now if I
increase the latency I'm gonna go and
increase it really really high to 5
seconds we see something interesting
happening so ok that the product detail
page will become slow we know but we
also see that the product list page is
becoming slow
really slow actually that's weird
because the product list page is not
doing anything with the review service
but all the threats are being used by
the product detail page so yeah this is
bad and this is where the whole
cascading effect comes in and even if I
set it to one second so let me recover
it quickly
set it to a second try it again
even now I give it a bit but even now we
see that a broad list page is becoming
slow we're using not as much threads
anymore
but still yeah it's affecting the rest
of the system so this is where this
cascading effect comes in so let's say
we have this landscape with a couple of
services and the root service becomes
slow it has a lot of latency then of
course you can expect a direct effect on
all the services that are calling it
directly but because all those
connection pools are filling up in those
other services if they don't apply any
resiliency you will see that all the
other endpoints also become slow well
then it explodes
so you have a big problem of course this
is only when you have a really high load
on your system and you don't have any
things like caching or other mitigating
parts in there which which make it less
worse but this is not like the perfect
storm so we can protect against it using
a bog heading so let's enable bog
heading say ten threats timeout on one
second again it's fine give it a huge
amount of latency and enable that so now
we see a huge difference yeah okay the
product detail page we still have those
errors and I can you know fix it with
the fallback but it's not slower than a
second but the list page is not affected
doesn't care there are still enough
threads left in the system to handle
those requests so this is this is huge
this is important
so I talked about that you have to that
you have semaphores or threat pools so
with thread pools I want to talk about
the difference and you can have both
with Erics at the end per command you
can choose so if you're gonna choose
four threats it has a couple of
advantages versus semaphores so when you
use threats the calling threats you can
always walk away if the time what
happens it can simply continue with its
other work and no problem and history
can also try to interrupt its own
threats that is just doing the call to
that client and I hope that the client
will will quit doing its thing the
disadvantage however is that every
threat adds a little bit of
computational overhead and memory usage
but to be honest we do this a lot within
our webshop we have more than 40 thread
pools and we notice nothing we have no
problems with this it's just fine a more
bigger disadvantage is that a thread
pool is harder to tune because a thread
pool can be shared by multiple commands
so semaphores they are awesome because
they have a very low overhead and
they're also easier to tune because
every command has its own semaphore
always however it he'll of course has a
number of disadvantages it only limits
the concurrent calls but it doesn't
fully isolate so the calling threat it
can't walk away because it's the same
threat it needs to wait until our client
is finished and interrupting is also no
possibility in that case so that's why
when you want recommendation then I
would recommend starting with threat
isolation except when the threat usage
is really the the overhead is really too
high or using a client where you are you
know a client that you trust and that
you can do client of a request based
timeouts on and if you're in a more
asynchronous non-blocking environment
using this fixed observable command then
you are using the semaphore by default
because then mostly the client is doing
the threat handling that's fine
so before we going to the last
resilience technique halt with circuit
breakers I wanted to look at metrics
that history is exposing so this is an
example of one command from the history
dashboard and it gives you a lot of
information like latency information for
that commands the number of calls that
were successful or failures and also a
cluster view so what does it mean within
our overview so all these different
parts of history are generating these
metrics and they are simply reported to
the outside world you can use that and I
want to give you an example of the
actual bullet going back show up at this
moment so this is this is what is
actually happening on our shop this is
this overview of all the commands and
you can scroll through it you see we
have humongous amount of them and this
is a live view and mainly just use to
give a feeling of what is happening with
your system if you want to doing more
analysis you can go to more history or a
historical view we use kevanna for that
and hopefully loads yeah so here we see
an overview of what is happening with
this command this day today so we have a
number of executions we see some
failures coming by timeouts and we see
the latencies coming by well this is
really useful because you get an
completely new overview of what your
system is seeing versus its back-end
services so now I need to yeah okay so
these metrics are really useful and you
can use them for monitoring and alerting
but they're also used for the circuit
breaker and the circuit breaker is like
a fuse in a fuse box
if it's closed it will that's a current
through but if it opens then it won't
let anything through and you don't have
power where it does this thing fit in so
you execute the command and then the
first thing is going to look is at the
circuit breaker and the circuit breaker
determines by looking at the health of
the resource if it is open or not and if
it's unhealthy then it will open and
everything will short-circuit to the
fall bank so how does this look how does
this work so we have three states closed
open and half open when it's closed
everything is fine but when we see too
many failures which by default is 50% of
all calls
if they're a failure then it will open
and everything will really feel fast
because everything will go to the phobic
immediately but we need to automatically
recover so sometimes it will try one
request I think every couple of seconds
and then then it comes into the
half-open states and when at one request
fails we'll go back to open but when it
succeeds we'll go we'll close the
circuit breaker immediately so last demo
again all the the graphs page requests
product detail latency distribution
request for list page but now we also
have a circuit breaker overview and
again it's the thread usage so now let's
immediately enable certain resiliency
things but not a circuit breaker yet oh
not this one let's make it a little bit
slow so we see now is that the error
percentage of the circuit the command is
going up and up and up but because I
haven't enabled a circuit breaker yet
it's still closed you know and we still
see this threat usage of ten threats
yeah so what happens when we now unable
the circuit breaker well as well a near
immediately open but the big difference
here is in the threat usage all the
threats you know they're gone are not
being used because the historic thread
circuit breaker says well this this
thing is not healthy and not even going
to try to call it and because it's not
even going to try to call it the backend
service actually has a breathing room to
recover it's a nice side effect but also
every customer hitting these commands
you know they will get awesome
performance it's perfect so when we
reduce the latency again let's say to
20% then this should start recovering in
a second yeah so we see oh the circuit
breaker closed again we still have a
little error percentage left okay so
these are all the things that history is
doing now that for us now let's get into
some tips and tricks that we encountered
well well well
well building us into our systems so
first make sure when you start with this
from the beginning that you set up
monitoring a lower thing because if your
circuit breakers are open then you the
only way to know that is because
customers starts complaining that
certain features simply are not working
or are always empty or whatever you know
if you have a fallback so you need that
monitoring to discover what is going on
in your system and we actually split it
up in to certain types of monitoring we
have critical and non-critical commands
because certain commands like for us
searching in our webshop if you don't
have that then our webshop doesn't
really do a lot we make them critical
which means if those circuit breakers
open or the failure rate is too high
then our ops guys and the team
responsible we immediately get getting
messages hey guys you need to do
something but certain things like
reviews they're not critical enough that
we want to wake up somebody in the
middle of the night so in that case is
just a non critical service and we get a
warning screen somewhere on them on a
monitoring screen or whatever so another
thing is don't forget to configure those
clients those HTTP clients because they
have also timeout settings you still
need to set them correctly and also the
connection pools need to be big enough
to be able to handle all the requests
this is something that is often
forgotten at our company so why is it
important so here you have a normal
execution where you have an application
threat calling the history command on
that same threat and it's going to start
this history threat and do the actual
call to the resource if the resource is
slow in its timing outs on the historic
level but the time it has not decently
been set on the client then that history
threat is still being used it can't be
released until the client simply while
it is done so this will cause
unnecessary load shedding if you don't
configure this correctly and with
semaphores is even worse because it
semaphores this calling threat can't
walk away so you will still have this
whole latency problem well less because
you're limiting via debug heading
yeah but it's it's not good so two
things you can do you can make his sex
time out of the client timeout before
hystrix does that's fine
the only thing is his fix won't know
that it is a timeout causing this so it
will simply return an exception and the
metrics you also see it just as a normal
failure if you make the client the
timeout just after his risk then history
will understand hey this was a timeout
how nice and it will also register that
as a timeout but you can also do a
different thing and it is implement a
hook because history is really pluggable
and what we do is we have this map this
mapping function is time of exception
and it knows all these common Java
timeout exceptions and it will map it to
a history timer exception and that way
his switch also knows oh this was a
timeout and this makes a lot easier it
doesn't really matter anymore anymore
who times out first it's always
registered as a timeout and another
trick is what you can do is make the
client timeout always have the same time
orders to command because then you need
to configure one time model unless so
what you can do in your history command
is get the properties of that commands
you can get the execution time or the
milliseconds they really love their long
method names you get the value of that
they simply pass it along to your client
you client must be able to deal with
requests based time on settings though
not not all not all do the same thing is
it retries some clients tend to do
retries automatically you need to be
careful with that you don't want to have
too many because then you have the same
effect as having a really long time out
setting for your clients so what if you
really want to have retries do it most
one if the second one fails then
something is probably really wrong with
your system and well let it fail next
thing a commands groups and thread pools
have names and those names are really
important here you need them for
configuring your commands so they need
to be unique but also you see them
everywhere in your monitoring systems
and your loading systems so you need to
be really descriptive and tell what that
command is doing so we
do is we incorporate the service ID to
the the short name of a service what
we're calling and the command name and
the command name should always say what
a command is doing so for instance we
have this pcs service product content
service which gives product information
we have this medical product by ID if
you see that in a monitoring system then
you immediately know what is going on
tuning really quickly when you're tuning
is really important for history you need
to do that you can't ignore it and
certainly if you have high loads or long
latencies and you should be tuning based
on production information and you need
to behave a unit on the behavior of the
resource and not be not on what you
would like the timeout to be so if you
have a survey research that you're
calling and it's normal behaviors to
have a timeout of one second then that
needs to be the timeout for your
commands but if you don't want to wait a
second but maybe only half a second then
you need to add an extra layer of
timeouts around that and say oh it won't
only want to wait a second half a second
else the timeout will always give arrows
because you're what thinks that the
resources are healthy and again don't
forget the time as it declines so I have
this overview of different formulas for
these timeout settings and concurrent
concurrency settings I'm not going to go
through them now if you download the
slides you can take a look at them and
as similar ones are also on the historic
s-- wiki so you can take a look at there
as well and for the client timeouts
something I noticed is the connect
timeout people tend to set that to
seconds a connect timeout is when you
the timeout if you need of the time a
service needs to connect from one
service to another service service but
not to deal with the actual call often
within our network 100 milliseconds is
already a very long time so issue you
can use that or even lower if you go
into another network it can be a
different thing in that case measure
these settings before you're setting it
to seconds and for the Reta timeout
we've already seen it when you're not
using retries you can set it to the
command time out and if your using
retries one retry you can
okay take the 99.5% I'll resource
latency oh it should be the plus the
median resource latency because you
expect the second call to succeed
so small things about operations when
you're having run it when you're running
is on production you will see jitter and
failure you already saw that an example
on from the board convex shop there will
always be some timeouts and that can
because of garbage collection or maybe a
new machine is starting up and it's
warming up or you can have different
payload sizes or sometimes the payload
size is simply to bake and it takes too
long to handle and some many other
reasons so for example this is the PCs
service again and it handles about
200,000 requests in 30 seconds what do
you see that it also has about 250
timeouts in that case and when History X
is starting to report failure a circuit
breakers prince is open then don't
overreact by trying to retune that
circuit breaker immediately first see
what is going on determine if it's not
really a problem in the backend service
and if you determine that everything is
fine with the backend system yet then
maybe you want to do a reach you in
session so some global experiences at
both comm it already prevented a lot of
small outages and a couple of big ones
and because of that we sleep a lot
better now so it really helps our
operations guys are really happy with
this and history in itself is a great
library although it's starting to get a
little bit outdated but in general it
does its job well it integrates really
well with our tools because it's
pluggable and it's easy to learn and
implement however tuning is often
overlooked by our teams and it's not
trivial if you if you're going to do
that so we often see incorrect timeout
settings or thread pool sizes that are
too big and the client is also often
forgotten so things to watch out for if
you're if you're doing is and in the end
it was probably mostly an organizational
challenge than a technical one so we we
have a lot of teams so we had to train
them
we had to make the business understand
that these fallbacks are important and
better than big failure messages but in
the end I think it really was worth it
and it probably saves a lot of money of
saves already a lot of money with these
big outages so to wrap up failures are
really not the exception we need to we
need to deal with them they are normal
so we need to be resilient against those
failures and a couple of techniques that
we've seen to be more resilient is to
implement these fall backs manage
timeouts carefully also for the clients
use block heading alo chatting to
prevent that resource hijacking and add
circuit breaker to skip those few tacos
to services that aren't healthy in any
case and adding resilience in the end
doesn't really need to be really hard
certainly not with libraries that do it
all for you so that's it I'm not sure
how much time I have for questions but</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>