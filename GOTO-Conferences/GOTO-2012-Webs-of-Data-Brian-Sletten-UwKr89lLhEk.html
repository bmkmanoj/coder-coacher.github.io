<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2012 • Webs of Data • Brian Sletten | Coder Coacher - Coaching Coders</title><meta content="GOTO 2012 • Webs of Data • Brian Sletten - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2012 • Webs of Data • Brian Sletten</b></h2><h5 class="post__date">2013-03-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UwKr89lLhEk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm going to have a quick
introduction and this is the first time
I've taken this particular approach on
this so I would appreciate any feedback
I've tried to couch it in technologies
and approaches and disciplines that you
are already using in most cases as a way
of motivating the approach which on its
surface seems very strange but through
this path I'm trying to make it seem
less scrimmage then I'll take a very
brief time to introduce the resource
description framework which is a w3c
standard for just sharing information in
a networked environment where that
network environment can be your
organization or the entire internet and
web it's designed to scale in both cases
and then I'll end with an introduction
to the concept of the linked data
project and talk a little bit about its
successes and then in the next talk
Martin is going to talk about how IBM
kind of came at this from another
direction which was we have this problem
of integrating data and all of our
products and services and we don't
really know how to do it well and people
are yelling at us for not doing it well
what do we do and he ended up with these
technologies so he'll be talking about
some more applied approaches and some
cautions and considerations as well so
when sharing information we require a
context we need to know how to interpret
it we need to know how to serialize it
we need to know you know what does this
information mean and it's thrown at you
without any kind of context you have
idea what to do with them so this is
general idea that data is raw and
information is data that has been put in
relation to other information it's been
contextualized somehow and then suddenly
we hit too much information so then
knowledge is contextualized prioritized
information so now we're at the problem
where our knowledge is too too
voluminous and we need some ways of
handling it but if i say to you that
this data that i just threw up there had
something to do with me as people with a
shared understanding and culture and
everybody has one of these you'd be able
to guess
somebody would be able to guess doesn't
it's my birthday and if I say that's
what it is every single person in this
room has a birthday every single person
in this room understands what I mean and
that's sufficient but if I wanted to do
this if I wanted to share this
information in a machine processable way
without using facebook how quite do it
and that's just a weird problem that we
haven't really run into much because
we've tend to think in terms of code oh
I'll write some code and i'll write a
service and I'll invoke a service and
i'll do some integration and a large
part of what we've been doing has been
pushing this burden of integration into
the application developers particularly
once they start spanning multiple data
sources and so we're going to talk about
that a little bit so where do we do our
data integration obviously in our
databases so I could start to create a
table for people and capture things like
a unique identifier a name and a date of
birth and what's interesting about these
identifiers is these this number one two
three four is guaranteed to be unique
within this database but even between
multiple instances of the same data
store that number could be repeated it's
not a unique number brian is an Irish
name sletten is a Norwegian name and you
know we tried to conquer the UK a couple
years ago never really happen so there's
not a lot of brine Sutton's running
around but I do know that there is at
least one more in the US and he has
reviewed every Star Trek episode ever
and that's not me I like the Star Trek
that's going a little bit too far so we
understand that there's a context to how
we're capturing this information in
terms of both the structure of the data
what's useful to us what are we trying
to capture what are we trying to share
and then now everything that fits within
this table is going to have to fit into
that structure and the context of this
table is going to be scoped just our use
because there's no identity that moves
beyond it that being said this is how
we've been doing things for 40 years now
and we're able to take a table
and we're able to map it into some kind
of object through hibernate or something
like that and then we're able to put
that object into some kind of component
a library of some sort and then we're
able to deploy that library component to
a computer it's what we do but I want
you to remember this chain this
structure of the information that gets
mapped into an object that gets mapped
into a component that gets mapped to a
deployed system and then think about how
do we change things how we add things
how we bring in other sources of
information and it all has the same
pendency problem it all has the same set
of upstream dependencies if we make
changes there we end up making changes
here which could break things could
cause unexpected results and that's
generally problematic so our software
tends to be a little fragile a little
brittle and when we deploy things into
large organizations we kind of have to
have everybody agree all at once what
things are going to mean and that
doesn't scale very well along the way
but 10 10 15 years ago we started
thinking all right we could be smarter
than this we don't have to deploy all
the code everywhere I can put some kind
of behavior in a component and invoke it
over the network so i can say hey give
me the identity for this they give me
the name for this ID or give me the
birthday for this ID and then reality
hit and we realize that these remote
procedure calls you know this
granularity are kind of bad so we
started thinking larger in terms of all
right well i'm going to invoke a query
i'm going to define a custom message
that's going to say please go out and
get me this person object and bring it
back to me i'll pull back enough that i
don't have to hit the same service over
and over and over again to get
individual pieces i'll just get the
majority of the information i want and
get it back as xml and this was a huge
step forward it did minimize some of the
dependencies but everything is still
pretty tightly coupled through contracts
and whatnot so in this
in this context we saw the emergence of
a different way of doing this known as
rest where rather than writing custom
messages to ask for information we use a
semantically meaningful action that
means hey I'd like to see this thing and
we give that thing a name and one of the
things I think is developers who don't
give enough credit to is the fact that
these names are unique in a global
context but they're also a handle so its
name and as identifiers and name is
handle if you have the name of the thing
you know how to interact with it you
pull on it and you retrieve information
in this case maybe the xml
representation of a person well web
application developers don't
particularly like xml that's fine we
have the ability in this infrastructure
because of the separation of the name
and the form that it takes the ability
to accommodate people who want to see it
as Jason bar as an Excel spreadsheet or
as an HTML document or some other format
so we have the capacity and this is
basically what we would call a level 2
restful system it has support for
information resources it has support for
HTTP as an application protocol for
manipulating those resources perhaps we
support content negotiation and most
things that you see labeled as rest are
about this level of sophistication if
you want to update information about the
person you can put or post information
back if you wanted to remove a person
that sounds bad but you know if it's an
employer to make that you could issue a
delete request to that thing and it
would go away but the interesting thing
about this is it doesn't matter what
type of information we're talking about
the web works the same regardless of
whether you're logging into your bank
logging into some kind of chat room or
bored or excuse me news a news site or
sports scores it doesn't matter because
the resource abstraction encompasses all
and what we want to do is to start
moving this direction where this
resource abstraction and the ability to
change the shape of the information
allows us to apply this predictably
across it
wide variety of information it counts
and orders and regulations and documents
and all kind of stuff but to be fully
proper level three rest we need to have
linkage we need to have the hypermedia
we need to be able to follow our nose
from one document to another just like
the web works again the web is not a
single document it's a document that
connects you to another document that
connects you to another document and you
know try to find the end you won't so
here I could imagine a person maybe that
attends a school has a link with a
relationship type of school and from
there on the client I can discover the
connection unlike how a lot of people
build restful systems I'm not building
up the URL to invoke this and finding it
in the body of what I get back I follow
my nose and then I end up in some kind
of information resource about the school
and from there I can maybe find the
admissions department from the
admissions department i could find the
forms to submit information to apply to
the school and this roughly represents
the state of the art for most
organizations in terms of the adoption
of these technologies web oriented
restful technologies in the management
and manipulation of their information i
could spend hours talking just about
this stuff but there are limitations to
what this does for us it's a huge step
forward but we run into some problems
particularly once you start thinking
about multiple forms of information or
multiple data sources and what where
this information comes from and how we
combine it if we start to think about
specific types of people it can imagine
a student is a type of person and so in
object-oriented programming we can very
easily imagine extending that class and
adding new capabilities down here so up
here we're managing names and date of
births and things like that down here
we've got student identities and GPAs
our grade point averages and what year
they are they a freshman sophomore third
year fourth year whatever this makes
sense to us in the object ronnians
because
to reflect reality however remember
we're putting over it in tables and
tables expect things to be a certain
shape and everything has to be in the
same shape so we have to introduce a new
table to capture portions of the
students that are now separate from the
person and then we have pointers between
them but we still can do it we have
multiple tables representing the
multiple aspects we have multiple
mappings and we can ratify that
information into a student into an
object model or even into a new restful
endpoint a resource as a student that
has its own identity where I can order
the distinction between those tables on
the back end I can collapse all that
information into a single resource and
say when I view this information as a
student I want to have a single view and
I want to know their name the date of
birth the GPA and their year again we
can do this and this is a huge leap
forward in terms of clients not having
to care how you store your information
and when you can separate them from
having to care about that then your
capacity to adopt Mongo and Cassandra
and all these other great new
technologies on the back end makes this
even easier because nobody really cares
about whether using a document model or
keyvaluepair that's up to you and that's
how you organize your information how
you store it are you searched end users
don't care that is an implementation
detail not something that anybody but I
cares about other than you have the
capacity and the growth potential to
manage the amount of information they
want so we can learn those distinctions
and get people composite views
regardless of where the data comes from
however it doesn't scale we can't keep
doing this if we start talking about
employees as a type of person and say
all right well employees have names and
date of births as well and they also
have employee IDs and supervisors and
salaries and so now we have another
table that captures that information
set in and if we want to talk about
student employees it just starts getting
crazy and the problem is if we think
about this structure and we think about
the dependencies between the schemas
which are fixed snapshots and time
normalized into a particular structure
good for processing not good for
modeling good for requesting and storing
not good for reasoning over so we have
to end up writing a lot of custom
software because as useful as the
relational model is it doesn't mean
anything what does eid mean what is SAV
mean what a salary mean we have to write
fat meaning into custom code into custom
mapping into custom objects to be able
to use it when we control everything
that's fine when everything you can fit
into our data store that's fine but once
we start crossing data sources and
domain boundaries and where the
information comes from it's game over
the data model that we've been using no
longer works if I wanted to overlay
social networking information how do we
do this well if we were forced to use a
data model we would have to do an ETL
and extract the transformation and load
all that social information into another
data store that then fits into our model
we can't do that we can't take all the
world's information and consume it and
hoard it and hold onto it just so that
we can interact with it that we can
connect it that we can integrate so we
need a better way of managing this
particularly because we still have this
problem as we make changes as move
things around as we integrate stuff that
has this cascading approach in terms of
how stuff has interpreted how code is
deployed versioning etc all right so
what is what is this all mean we have
this idea of a resource as a thing can
be a document can be a document about
the weather it can be a document about
news it can be a document about you it
can be duckin but your organization a
resource is just a conceptual way of
representing
something that we care about and so we
can take this resource abstraction and
we can say all right we have a resource
it will call one two three four four
right now and what I have here is an
encoding of certain properties about
that resource and that encoding relies
on the fact that XML is a tree structure
and I can embed things hierarchically
and so that i can to interpret those
things as these are attributes
associated with this outer element but
this is all this is just syntax this is
just an expression of a particular
worldview that I then have to write code
to interpret this is why XML did not
solve all of our problems it required us
to agree on what these things meant and
on a point-to-point basis you know you
and I could agree you and I can agree
but there's no way we're all gonna hurt
and so everybody's constantly what
you're doing these one-offs and
everything it's just it's not going to
skip but what's being expressed here is
not all that complicated the thing
called 1234 is a person that's a fact
that i would like to capture the thing
called 1234 has a name the thing called
Butchie 34 has a date of birth the thing
called 1234 is connected to this other
thing called 248 these all follow this
sort of propositional statement form
something is connected to a value
through some kind of relationship it
just so happens that historically we
have used a table structure to represent
that something this row is connected to
this value through this relationship the
relationship is the column name the
identity is generally the candidate key
or the primary key and then the values
are what are in the cells through that
relationship so we can see that a table
structure and a tree structure are
interesting but insufficient I can't
take two tree structures and shove them
together and still have a tree I can't
take two tables and arbitrarily shove
them together I have to sort of come up
with some normalized ways of mapping
them together into a larger table
structure but what we're trying to say
is really not that difficult we're just
trying to say
here are some facts here are some
entities here are some attributes here
are some values and I'd like you to be
able to consume them and if there are
entities that are not captured here like
your favorite color or your blood type
or your favorite band or where you were
born or just any kind of arbitrary piece
of information then why is it so hard
why do we have to write custom object
models custom schemas custom mapping to
learn one more thing and the really
distrust of the disturbing part is all
the real value opportunities in these
things comes from the unexpected in
terms of business opportunities a
scientific research and market
opportunities and catching terrorists
and things like that it's the huh that's
strange kinds of things that we would
like to be able to do and if our data
model forces us to say all right
everybody's going to have this structure
in order for you to efficiently process
it this is not good and this is this is
limiting our capacity if I look at the
more complex composite model here I have
two identities there's the student
identity and the person I did but
because I've equated them through a
foreign key relationship I can just pick
one as well as long as I understand the
context in which im using it then either
one applies right all the facts that
come from the one table are associated
with it all the facts from the other
table are also associated but so I'm
just going to pick the person one
because I think person this is a more
higher abstraction than student this and
I could say this is a person this person
has a name this person has a date of
birth it's linked to something as a
student as a GPA the senior the blood
type as a friend was born here watch
this movie the point is I can just keep
saying things and really what I'm
talking about is capturing a graph
structure if I have this thing
represented as a resource I can say this
thing is a person and this thing is a
student and this thing has these values
and oh by the way this thing is
connected to this other thing and a
graph structure is much easier to
capture arbitrary relationships about
that's why we're seeing things like
neo4j being so successful and very
efficiently capturing arbitrary
information because this graph structure
makes it very easy for us to just learn
new things now there are scale issues
and replication issues and even at the
end of the day we still aren't going to
put all of the world's information or
even all of your organization's
information into one place so we need to
have a larger context than just a single
graph a single identity space and we've
already seen an example of something
that works really well about that the
notion of a URL as a global dis
ambiguous all verbal identifier is a
very compelling idea for assigning
identity to resources that only is it
resolvable you've never seen it before
pulling it you'll get some
representation of it but the interesting
property about global identifiers is
they are completely portable every
single person in here could come up with
a global identifier could strain to a
domain that you have control over I
can't publish into your domain you can't
publish into my domain but I could take
all of these identifiers that everybody
puts together drop them in a bucket
shake them up and there's no concern
about collision that is incredibly
empowering that is incredibly freeing
because now what's in your database and
what's in your database in which in your
database can be commingled at an entity
level and there's no concern about
conflict so I'm going to use the kind of
xml q name representation here because
otherwise these graphs get ugly and hard
to read so in the res namespace I'm
going to point that to some particular
URL predicates and then I'm going to
talk about raz one two three four as
HTTP HTTP colon slash slash server
resource / 123 for this entity now has
unique identity in a global context
and I could say all right this resource
is connected to that resource that's
pretty cool but we still have this
problem about the attributes and the
relationships what can we do to improve
the situation there is there any reason
we couldn't also use URLs to refer to
those absolutely not and as it turns out
there are lots of these collections of
resource identifiers for concepts and
terms and relationships and classes
they're generally bundled into something
called the vocabulary and published on
the web and one of them is called friend
of a friend both in the friend of a
friend namespace grounded at xmlns calm
/ both / of diversion a one there is a
term called me and it probably means
what I want to mean as far as capturing
the name so i don't have to come up with
a new relationship i could just use
theirs and unlike a lot of xml schemas
and object models and things like that
where you're in for a penny you're in
for a pound i mean if you are committed
to that schema if that was the only
thing i wanted to use from that
vocabulary that's the only thing you
know i choose to use nothing else
matters if i use this term somehow
you've never seen it before you can pull
on because it's europe and you can find
a human readable description of what
this relationship means the name is
unique its global its resolvable you
pull on it you find out what it means
but it's also available in a machine
processable way i'm not gonna spend a
whole lot of time talking about that but
i can pull down a description of what
this resource means in the resource
description framework rdf is used to
describe itself which is a little bit
difficult right after you know the first
cup of coffee in the morning meaning it
and a couple more cups of coffee but the
point is there's no separation between
schema information in instance
information I
we have in databases databases have a
schema and then we load data into schema
xml documents have schemas then we have
instance documents that we loaded to
those schemas in this model everything
is a resource so we can describe
everything including the relationships I
could say this resource is a functional
property and if you understand that
means then you can enforce if I say name
is functional property or birthday is a
functional property and I say Brian's
birthdays may 26 Brian's birthdays may
27th you can use custom tools I mean
sorry standard tools to enforce
constraints over custom environments is
it doesn't know what a birthday is but
it knows you're not allowed to have two
of them it doesn't know what is in as a
relationship means but it knows it it's
a transitive relationship and a
transitive relationship propagates
across the graph so if brian is in this
room and this room is in our booths and
our gooses in denmark brian is in
denmark standard modelling language
standard reasoning language standard
query language arbitrary domains and
that's where the stuff stuff really
starts to get power so I'm going to use
the name property from foe and I'm going
to use the birthday property from folk
and this also tells us you know it
should be in the month month that year
year and now I can say all right I have
1q name Raz to the resource another one
called both points to that and now res 1
2 3 4 has a folk name of bryan sutton
and has a folk birthday event rdf is
described in terms of itself so there's
one called type in the RDF vocabulary is
a relationship called type that allows
us to assert that a resource is an
instance of a class so are you look back
at folk I see that there is a class
called person and these again this is
just an organizing way of saying things
that have similar properties a person
has certain properties kind of like an
object-oriented programming although
don't get too
amer to the similarity because there are
some pretty serious differences but now
i can say with the rdf vocabulary and
its name space res has both name evoke
birthday and an RTF type of faux person
so I'm able to reuse concepts from a
domain that a bunch of people got
together and described social networking
talked about people things they're
interested in where they work where they
went to school how to contact them who
they know so all that kind of stuff I
don't need to create new terms for that
I can reuse them now these other things
year GPA I don't know how to necessarily
yet reflect that I'm attending a school
maybe I can find a relationship for
these things maybe I can't but the point
is I can just create one I can go
through and say alright these are the
relationships that I want and if five
weeks from now a year from now I come
across a more standard representation of
these terms and relationships that's
fine because they are also resources I
can connect them and I can say the one
that I used a year ago and the one that
I'm seeing now are the same relationship
and I can then for all intensive
purposes forget the fact that i created
my own and just start using the new ones
anybody who knows the new ones can ask
questions of my data as if i'm using the
new industry standard so there is almost
really no bad choice that you can make
because we can always fix it in the
future so i'm not going to go through
and talk about coming up with our own
terms of relationships that's a whole
separate set of skilled but that would
be the next approach we would have
relationships and classes for students
and teachers and those kinds of things
and connect a student into that what i
want to do now is show you this graph is
sort of conceptual it exists in some
state whether it's in a file or to
generate it on the fly from a relational
database or extracted from a document it
doesn't matter people understood people
always ask like hold where do you put
this stuff and I'm reminded of the joke
the American comedian Stephen right he
says I've got the world's largest sea
shell collection you may have seen it I
leave it on the beaches of the world and
that's the same with this information we
were so fixated on big data stores and
putting everything into one data store
that only goes so far right beyond that
we have to imagine all right we've got
some information here and some
information over there and I want to
connect them and because I'm connecting
them using resolvable relationships and
resolvable identifiers the fact that
it's over there is largely irrelevant
obviously there are some network latency
issues but we have ways of managing that
as well so consider that this is a
conceptual relationship of all the
information and I don't care where it
comes from and I don't care how its
produced and I don't care how it's
stored as needed I will resolve these
pieces and do something with them now
one way that we can do this is to
serialize that graph in a particular
format and this is a particularly hated
format called rdf XML because when they
did it everything had to be XML so the
problem here is putting a graph
structure into a tree is a painful
process and so we end up with a lot of
ceremony about this but we still see
we're talking about resource one here
before it's an instance of a person
class oh what's which class is that go
over solve it go find it out it has a
name and has a birthday here's a more
human friendly serialization called
turtle it's the terse RDF triple
language it's the same information its
losslessly converted from one form to
another but it's easier for us to see
exactly what we're talking about none of
that ceremony nonsense so we have a way
of serializing all of these facts in
some format whether they're stored
natively on a file a location like this
or we content negotiate a REST API into
RDF or convert it on the fly this is a
w3c standard called r to r ml that shows
you how to convert relational databases
into our day
on the fly the data stays where it is
but when you ask for it it can be
ratified as RTF so let's assume I have a
file at this location and as it turns
out I do with this in it this is a
self-contained RTF XML document that
captures three facts this thing is
person has a name as birthday I can now
run a query against it so we use Sparkle
Sparkle is the sparkle protocol and rdf
query language i'm only going to focus
on the creole language part i can do a
query that says give me all the subjects
all the predicate sand all the objects
from that data source where and I don't
have any constraints I'm just basically
saying tell me everything that's there
and so my Sparkle engine goes out
fetches that file asks for it determines
that it's in a format it knows how to
parse it's already of XML reads it in
and it doesn't know anything about
birthdays or Foe or anything like that
but it's able to just accept whatever is
in that document it can accept here's
the crazy thing with these global
identifiers for our entities and our
relationships any RDF system can consume
RDF from any other RDF system try that
even within the same relational database
with slightly different schemas hey it's
not going to work any RTF system can
consume data even though it's not
expecting say go through and I add
information about bands and blood types
and music and stuff in that in there the
same query using a standard query
language fetch the data serialize it
discover all the new relationships all
the new subjects all the new predicates
all the new values even for things I've
never seen before and I go what is this
both named go resolve it figure out what
it is I can now ask questions of the
data so here I'm not asking anything
particular i'm just doing Star Trek you
know good tell me everything about
everything which is not generally
query I want to ask a more detailed
query in this case I'm going to specify
in the where block a graph pattern that
I want to find in the graph so I want to
know the name and the date of birth and
I can call these variables whatever I
want from that same data set where the
subject is connected to the name
predicate their name value through the
FOFA name predicate and it's also
connected to a date of birth through the
folk birthday predicate both facts have
to be expressed in the graph in order to
find a graph pattern that looks like
that but if once it does it says okay
well brian has a birthday of May 26 I
have run a meaningful query against a
remote data source and I may have never
seen the data ever before in my life but
here's the thing here's where we get
another leg up on rest rest is cool for
standardizing and making your
infrastructure predictable but it also
puts the integration burden on the
client you give me XML you give me Jason
at the right custom code to do something
with it whereas if you give me RDF and
you give me RDF simply by asking for it
select name and date of birth from this
data source and from this other data
source as expressed these two data
sources are automatically converted into
a single graph and then I look for the
same patterns in the graph maybe they
connect maybe they're separate doesn't
matter I now find oh I've learned two
things now I don't know necessarily at
this point which came from which if I
care I can manage that but the point is
it's a zero effort data integration if
the information is available in this
form of network available arbitrary
domains using standard modeling
languages standard query languages
standing reason reasoning language this
is incredibly powerful
now where is this rdf going to come from
so what's gonna be native see blood
storing this there are there are triple
stores now for storing RDF triples the
subject predicate object relationships
are expressed in terms of the triples
our culture holes or let you just be in
a fire or they can use content
negotiation give me information about
the account but give it to me as art
yeah I think about this for a second if
you're in the retail space and you have
product information and you surface that
product information is RDF pricing
imagery manufacturer cost though cyclic
and stuff and have another data source
over here that has ratings and reviews
as long as this information can be
generated in RDF and we have a
consistent way of referring to our
entities then I can just simply say find
the top-rated consumer electronic
devices by Sony that have at least three
star rating stars data source ever hear
a data source over here automatically
added run a meaningful query over it i'm
not writing custom software to do this
now that's a lot more to this right I'm
obviously having to brush over a lot of
details but that's entirely possible we
have the ability so in these cases I'm
pulling the data to me which for large
data sets you can imagine it's pretty
painful so Sparkle endpoints are ways of
allowing a data store to expose an API
that allows</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>