<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2012 • Dynamic Lang. in Production: Progress &amp; Open Challenges • Brian Cantrill &amp; Dave Pacheco | Coder Coacher - Coaching Coders</title><meta content="GOTO 2012 • Dynamic Lang. in Production: Progress &amp; Open Challenges • Brian Cantrill &amp; Dave Pacheco - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2012 • Dynamic Lang. in Production: Progress &amp; Open Challenges • Brian Cantrill &amp; Dave Pacheco</b></h2><h5 class="post__date">2013-03-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5TFILa4ju9U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone I'm Brian Cantor
I'm here my colleague Dave the Chico I
from Joyent so we're gonna talk in
particular about deploying systems into
production and I know that that
sometimes people run for their lives
when they hear the word production so
we're gonna try to ease in by bringing
up hopefully what is a familiar figure
to some of you maybe so this is John
McCarthy and of course he and it's great
to see you know hands go up and so many
recognize one of the truly one of the
programming language pioneers John
McCarthy passed away recently and but on
John McCarthy invented Lisp of course
and Lisp is I believe feel free to
correct me from if I'm wrong but Lisp is
the first interpreted language it is the
first dynamic language or the first the
beginning of a dynamic language and it's
actually very interesting to read the
history of Lisp it was an interpreted
language almost by accident I actually
didn't realize this but they were trying
to design a compiled language I mean
this is for the this is the IBM 704 back
in the day they were trying to design a
compiled language and it was only they
kind of fell out that it was actually
just easier to implement things to make
it interpreted and then they made this
incredible discovery that once the
language was interpreted you could
actually move faster the existence of an
interpreter and the absence of
declarations makes it particularly
natural to use lists in a time-sharing
environment it is convenient to define
functions test them and re-edit them
without ever leaving the lisp
interpreter and again this was first in
the in the late 50s that list was being
developed and the first Lisp
interpreters about 1960 so this is a
very long time ago and the thing that's
kind of interesting to me about this is
that from the very beginning the dynamic
languages interpreted languages were
about programmer productivity that's the
reason we use these languages the reason
we don't write everything in C or
actually even assembly all the time is
because it would take us longer it would
take us longer because certain aspects
of it are harder and there's certain
things that are more tedious in these
lower-level languages so these higher
level dynamic interpreted languages of
which
javascript is one are all about making
us more productive as programmers now
for many years I mean you've Lisp is is
an interpreted environment in 1960 but
interpreted languages don't really enter
the mainstream until the mid-1990s now I
know that you know small talk is
mother's milk and a sacred here and I so
I want to I want to respect that but the
reality is we weren't all programming in
small talk in the mid-90s I'm so sorry I
it's not because small talk wasn't
obviously superior to everything that
was being done ever in the history of
humanity because I'm sure it probably
was
I'm sure it's wise to say that now
anyway but we worked dynamic languages
hadn't gone mainstream and that's for a
lot of reasons and now I'm gonna I'm
gonna tread very lightly and sensitively
but I'm gonna say that part of this was
the fact that CPUs were were actually
underpowered relative to what these
environments are trying to do DRAM was
under sized relative to what these
environments are trying to do and yes
you could and there's our terrific
papers on small talk ad being
implemented on very limited resource
machines but the reality was that wasn't
the mainstream of dynamic languages in
the mid nineties and then but things
were improving and things were getting
better and faster and the world was
ready for a kind of a breakout dynamic
language and we saw that in Java for
better or for ill when Java was
introduced in 1995 it so quickly became
one of the world's most popular
languages that I think you can't help
but argue that the world was ready for
it the world was ready to be at a higher
layer of abstraction and Java was
terrific because it especially when when
in you know five or six or seven years
later when other languages began to
flower on top of the JVM that we now are
in an environment which is terrific
which is that dynamic languages are
everywhere and they're being used for
real production software which is great
because it makes us so much more
productive we can go do these things and
build things so much more quickly today
than we could even ten years ago because
of these languages so this is very
important
that there's also a darker side there's
a darker side to these dynamic
environments yes it is very fast to
build things and this to introduce this
darker side we're gonna go to another
pioneer does anyone know who this is
so McCarthy is your tribe
this guy is mine so Dylan oh this is so
this actually he won his touring before
McCarthy won his this is Morris Wilkes
Morris Wilkes is on it is one of the
very earliest computer pioneers
he and his team at Cambridge developed
the EDSAC which was the first real
stored-program computer yes
ENIAC was a machine but edsac was really
the first true embodiment of Von
Neumanns vision a very important machine
and Wilkes is a tremendous pioneer in
many regards but this quote from Wilkes
when I first read it as but a lad I felt
that Wilkes was speaking to me across
the decades that as soon as we started
programming we found our surprise that
it wasn't as easy to get programs right
as we had thought debugging had to be
discovered I can remember the exact
instant when I realized that a large
part of my life from then on was going
to be spent in finding mistakes in my
own programs that is as true today as it
was on the very first stored-program
computer it's actually I would make one
small adjustment to that which is I
remember the exact instant when I
realized that a large part of my life
from then on was going to be finding the
mistakes of others we don't just find
our own mistakes we find the mistakes of
others as well and I think that I am I'm
sure there's like a car there must be a
caramel balance to the world I mean I
think that don't all of us feel as if
we're often finding the bugs and other
people's code but in order for all that
to be true there have to be people who
are introducing many more bugs that may
themselves are debugging it's true I
don't know I have no explanation is it
like one dude
one guy if we could only find him let's
go find that guy he is problem he's a
problem but so the I mean the reality is
we're probably all wrong and probably
it's all it's you know like you
everyone thinks that our own flatulence
smells fine right it's that kind of
thing you you forget about your own bugs
we're all spending time in each other's
codes right so so you know we have 10
people on a team we're spending a lot of
our time in other people's code anyway
so I guess that kind of makes sense from
that perspective it kind of makes sense
so these dynamic languages um have a
very serious debugging problem I mean
that they are they're terrific that's
terrific for programmer productivity but
actually trying to debug these things
when they head south can be really
really ugly now in the the reality is
that that in order to debug your so
you've got a program it's running in the
VM and the program has moved sideways
it's doing something you don't want it
to do in order to be able to reason
about what that program is doing you
need there's a great deal of VM
specificity that you have to have and so
in order to be able to debug these
things we have historically had these
integrated development environments and
they allow us to do very powerful things
I mean to be fair the IDE s have come a
long way in the last 10 to 15 years and
the developer in development is able to
actually debug and understand their own
software and that's terrific the problem
is that has been the exclusive focus of
debugging dynamic languages that when
the when that software shifts from not
running a development but to running in
production the debugging tools that we
have are not just anemic but
historically non-existent for these
dynamic environments and you have this
this black box the VM in which you
cannot reason about what is running
inside yes it's executing instructions
on the microprocessor but those
instructions are our at such they're so
far down from the actual high-level code
that's been generated that it is
excruciating to actually get to that
high level code and so what are the
constraints of developing an approximate
form what is a production part what do
you mean by this
so a brought suit environment is code
that people are depending on right and
in though those that that environment
you can't simply modify the application
to add debugging statements
you can't often you can't even restart
the application but this code is
actually actively being used all the
time and it's very difficult to add to
actually go deploy modified versions to
get more debugging information you can't
assume that the failure is going to be
reproducible those of you who are
software developers versus with the
focus on the OP side you know that when
you've got a bug in production the first
thing you want to do is go reproduce it
in development the problem is that our
production systems are so complicated
now that we have many many bugs that you
simply cannot reproduce in development
and even if you reproduce the bug in
development how do you know you've
reproduced the right bug and not just
the symptoms of the bug so you can't you
can't assume that you're gonna be able
to reproduce these things at all let
alone in development and the failure
modes themselves may not even sometimes
they're explosive and you get a stack
trace and try to reason about it but
oftentimes they're not they're transient
or the app just goes into the black hole
misery right i whatever reason Airlines
seems to do that more than I mean I
don't wanna pick on airline but Airlines
seems to love the black hole of misery
Messenia but you these environments go
in and they just they're off doing
something rabbit is consuming all of 16
cores and a hundred percent
it's like rabbit you are executing 32
billion instructions per second that's a
lot of compute what the hell are you
doing please tell me what you're doing
we've got no idea so the we need to
these are the constraints of the problem
is it we got to be able to walk up to
this thing that has failed transiently
the failures aren't reproducible and we
need to be able to understand it so I
mean I don't know these constraints that
seem impossible I mean how do you
possibly debug anything Dave how do we
possibly debugging anything abruption
good question Brian so for this we turn
again once again to history and this is
a quote from a paper from 1951
essentially you know the dawn of
computing as we know it this is Stanley
Gill from a paper which is an excellent
paper called the diagnosis of mistakes
in programs on the EDSAC I'd strongly
recommend reading this if you're at all
interested in this stuff you know it
doesn't require a lot of background on
the machine or anything but it's it's a
terrific paper but he
this observation in a way that sounds
very euphemistic he says experience with
the EDSAC has shown that although a high
proportion of mistakes can be removed by
preliminary checking there frequently
remained mistakes which could only have
been detected in the early stages by
prolonged and laborious studies I mean
that that's obviously a euphemism right
this is like we there's no way we could
have actually figured these things out
unless we spent like years studying the
code looking for everything that could
possibly go wrong and he says some
attention therefore has been given to
the problem of dealing with mistakes
after the program has been tried and
found to fail and and then he goes on to
describe something he calls the post
mortem technique which is a way of
essentially figuring out after the
program has failed what the state of the
machine was and understanding the
problem from that so we've had this for
a long time obviously since 1951 at
least and it's on modern systems you can
do this with native programs write
programs you write in C you can get a
core dump and with a core dump you can
look at global variable state you can
look at all of the threads that are
around you can you presumably in a lot
of cases you have a little bit of extra
information about the objects structures
offsets that allow you to examine in
extreme detail every piece of the
program state how many people have
looked at a core dump okay that's great
I knew we were in the right room this is
great sweet so and there's there's two
important properties about this too
which is that when a program fails
fatally and dumps core yeah a native
program a C program say this system
immediately I mean the process exits
right so if you're using some kind of
restart er the system immediately
restarts the service and restores
service right and importantly you can
take the artifact of that which is the
core dump and copy it off to some other
system where you've got very
sophisticated tooling to figure out
what's happened so you're you know you
don't have to wait for an engineer to
get on that system and you know enter a
debugger and sort of poke around
meanwhile production requests are not
being serviced because this program is
halted or the state is changing from
underneath it so the programmer is
getting confused this is a extremely
important property right this is the
crux of what we're getting at and it's
not unique to us right I mean this is
called forensic engineering another
domain
other domains have forensic engineering
and indeed forensic engineering in the
ability to do forensic engineering is
what allows us to deliver life critical
safety critical systems you look at like
aviation right there are only four
unsolved plane crashes in the United
States all four of those predate the
flight data recorder and clock cockpit
voice recorder literally every other
major aviation accent and this is now
since the 60s has been route caused and
that route often you know there are many
root causes these are cascading failures
and we use it to fix the system as a
result can you think of the top of your
head the last time a major airliner went
down in the United States the airliners
no longer crash it's actually pretty
amazing that we just because these
systems are so mature but we it's
because we've been able to do forensic
engineering so French against hearing is
critical to all engineering domains not
just software yeah so yeah and I guess
that you know the question I'm from our
perspective is is can we actually do
this with dynamic environments and
formal right you know Dave and I are
we're oh s kernel guys this is how we
develop the kernel when the kernel
crashes we always get a complete
snapshot of State and kernels crash so
infrequently that you only have one shot
to debug many problems and that that is
that that crash dump you can't have it
crash again so can we do it with dynamic
environments that's the question
historically this has been pretty
difficult right if you just take the
same tools that you would apply to a
native program you know you applied gdb
you apply P stack you don't really get
anything that useful right you don't and
there are a lot of reasons for this one
is that the if you look at the things
that are in a core dump
you've got the symbols you've got mapped
memories so right there you got all the
native functions and you can disassemble
them and see what's going on you know
again you've got some metadata
describing the offsets the structures
and stuff so you can print those things
out but you don't have any of that for
the dynamic environment if your Python
program dumped core or your Java program
dumped core you don't have anything that
resembles a java class or a java method
or you know a Python object in order to
actually build these abstractions you'd
have to do a bunch of work on top of
that to essentially model to basically
resynthesize all those abstractions from
the information that's in the core file
there are also some things that you
want to include that don't even exist in
the language itself so in JavaScript
you've got the event queue this is this
list of events that is going to that are
going to be executed as soon as the
current event is finished being
processed that doesn't even exist in the
language there's no way to introspect
that and see what's on that queue let
alone so if you want to present this
this to a user you have to sort of
figure out how to even present it and
then you have to dig that information
out of the core file and the other
really important thing about this that
the the real crux of the constraint is
they these tools cannot assume that the
VM is currently running that's the whole
point the program has already crashed
maybe the VM has crashed but even if it
hasn't you want to be able to do these
things after the fact on a different
system you want to be able to do
sophisticated post-mortem analysis
techniques which we'll talk about a
little bit later but things that might
involve brute force they might take a
really long time so the VM is you cannot
assume that the VM is still running when
you do this you're operating on a
snapshot of memory so we took a
particulate we took a stab at this for
nodejs
we had a particular interest in nodejs
but this is actually not you know we
we've looked at other dynamic
environments and this problem is not
really solved in any of the ones that we
looked at any of the major ones yeah so
we're gonna wage somewhat deep way in
the node here how do people use node
I've heard of node okay good many people
have deployed it in production ok good
and there's a lot of hands going up on
have used node and have debugged from
cornell so this is this is good yes
we're gonna bring we're in the right
class together and we're gonna unify
this one and out that the origin of this
in terms of our particular interest is
that we at Joyent had developed a new
service david developed a new service to
allow us to understand the latency of
our running cloud infrastructure
software so we we are an infrastructure
as a service provider and we developed a
facility to allow our customers to view
the latency of their app the background
that doesn't necessarily matter what's
important is that it's a node.js app
that we were getting ready to deploy
into production and I swear it was like
it was like the day before we were gonna
play with doctrine it was a day before
we were planning to go so we're
literally just about to go live and the
thing is rockin and it's working and
we're all excited and excited a little
bit nervous you know a little bit
nervous that everything is going to be a
flaming disaster when we deploy into
production
but you know basically excited and we're
just doing some kind of like final demos
to one another or whatever and all of a
sudden one of our aggregator processes
it's written in node all of a sudden
starts spinning out of control on CPU oh
what's this and doesn't seem to be
coming it's it's in CPU and it's on CPU
in user land in the black hole and the
symptom by the way is the user that's
looking at the graphs the real-time
graphs of their of their program it just
it stopped the the graphs stop the user
interface completely locks opposite so
it's definitely a this is a particular
problem is scaled out but if you are a
user who happens to have been assigned
to this aggregator what you're seeing is
no data coming out of you
so okay let's go to bug this so we've
got Dave and me and then yn doll who was
the inventor of node who's that joint
and so the three of us go to debug this
problem now Dave obviously wrote the
software Ryan wrote node and I at Sun
along with two colleagues had invented a
particular technology called dtrace that
allows us to dynamically instrument the
system in arbitrary ways you got to
think between the three of us we get
this thing nailed and we were such dummy
dumb chimps staring at the laptop like
scratching ourselves trying it reminds
me of the bad old days of kernel
debugging when before we had this
tooling and we had no idea what was
going on and we're and no ability to
figure out and if we looking at the baby
it's worth pulling up like a stack trace
from that problem just so people have an
idea of when I say no idea I've actually
got a because we actually took a cord on
hoping that we would be able to come
back to this thing I've got you here so
yeah let me let me when I say no idea
this is what a we did a gee course we
can take a cord up of a live thing this
is the actual stack trace that you see
so when I cuz you may say oh well they
have no idea but I'm good I'd have an
idea okay smarty-pants all we need to do
is find whoever wrote fc2 1 a 0 c 5
because that guy's our problem actually
it's even more frustrating that because
we actually didn't know that that was
our problem we actually did know because
we after observing this for some period
time it's like actually as it happens FC
2 1 a 0 C 5
is the problem we had no way of
determining if I could just know what
function just tell me the file just to
actually just tell me some letters
present in its file name I just have a
really please anything anything I'll be
good I'll be good I promise but we're
looking at this and they're just like
this is actually hopeless and we and we
had that there is a node debugger and
right was so so Ryan had suggested
trying to use the node debugger at the
time the prot so you could send sig user
one on node and it would open up a debug
port and you could attach with the v8
debugger the problem was it only did
that when you got back to the event loop
so we were stuck in that loop
yeah it's funny story about the event
loop it's like okay I'll open up that
debug port just finish up what you're
doing
as soon as you're done doing whatever
you're doing it will open up this
debugger we can figure out what you're
doing it's like yeah I'm not gonna
finish up I'm doing because I don't know
what I'm doing do you know what fc2 180
or c5 is so this is frustrating and so
we had that so we didn't do bug it
we took a core but couldn't debug it and
then the question was how quickly after
we deploy into production are we going
to see this everywhere and the question
I had was will this be milliseconds or
microseconds after we deploy into
production right you figured out that is
gonna be a meltdown flaming disaster
when you go into production right you've
got this highly concurrent system and we
were able to trigger this bug by just
like playing around with exactly it and
but Dave's I recall you you were much
more optimistic than I was I think I
might have been at first I mean I barely
remember I mean maybe I figured we'd go
like a week or something like that but I
think you talked me down to like
certainly within the first day well I
think I talked you down because we need
to actually get a bet in place I don't
know if you guys do this in your in your
work place you got to make people
actually put money on their assertions
that's the conversations get much more
focused so Dave and I had to make an
actual bet and yeah within a day that
was easy money so okay we deployed in
production we're gonna see this all over
brace for impact we don't see it
anywhere that happened yep days pass
Dave at this point is gloating weeks
pass at this point Dave is like
forgotten to gloat he's trying to
remember to go it every day but just
like it does the gloating has gotten old
months pass literally six months later
now we just forgot about this thing and
of course and this is the difference
between amateur and professional by the
way amateur says hey great we must have
fixed the bug professional says oh no no
no no I know we didn't fix that buck
that is a bug it's in our software and
it is lying in wait to us at our
most inopportune moment on the very
worst day of our life the very worst is
lying in wait and it will pounce on us
to make that day even worse that is what
will happen and sure enough I was in
front of a customer of course demoing
this of course and using it all of a
sudden it locks up again and you get
that kind of fight-or-flight reaction
you know you have a demo go south on you
hopefully won't happen here but and it's
very alarming I kind of made up
something was hopefully this probably
look this exact same symptoms but now we
can actually go we could actually a
reason about we're gonna show you demo
that a little bit later on but so this
is the problem the problem is we look at
this thing and we've got absolutely no
idea what is actually truly going on so
I we just talked about no chance just
just a little bit because just too many
people have heard of it one thing you
might find a little bit surprising is
that a lot of our software at join our
core software is being written in node
stuff that was written in safe stuff
that we would have overwhelming biases
to run and to write and say trust me if
there was any case to be made for
writing these things and say we would do
it we love to say C++ not so much C yes
but but from from any of these things
and I mean this the services are
actually simple enough and v8 is fast
enough that it actually makes a lot more
sense or I didn't note so I mean and and
David mean you get considered C for the
service you're building but it just it
just doesn't make sense talk me out of
it I did know it was absolutely the
right call we were able to get a
prototype up in like two weeks and it
was in production in like two months I
think and you know we expected that to
take a lot longer and definitely would
have taken a lot longer if we'd done
that in C and so we've done this with a
bunch of services now you know we've
rattle off the list up there
and it's just kind of crazy just as an
example someone asked me DHCP really you
wrote a DHCP server
node it's like well yeah actually so
what joint does is we write this we
build this product called Smart Data
Center which runs the joint public cloud
and so you've got you're essentially
managing the servers that make up a data
center and one of the important pieces
of that is managing the platform images
the operating systems that each one is
going to boot so you can go in the web
UI and you can say I want this to boot
this version of the kernel and then what
you know I want to have this other
server boot some other version I want to
make the new this new version default on
all new systems when they reboot so you
basically want when these things boot
they netboot the platform image from the
head node of the data center well the
easiest way to do that is if you control
DHCP but the source of that information
is this dynamic source which we have
which is the set of OS images and the
configuration and stuff it's like why
not just have a little node server
that's speaking DHCP at one end and
talks to our back-end on the other side
and it actually you know it's a few
hundred lines of code it's really not a
big deal well so it was not our first
thought by the way our first thought was
of course I'm just gonna take is CD
httpd out back with a baseball bat and
I'm gonna beat it with an inch of its
life and get it to do this make sense
but he was amazing after basically a
week and a half of doing that the
engineer who was doing this Josh
Willesden was like you know what I think
I could actually just write this thing
in node from scratch and it would be
faster and it was three days to write a
DHCP server from scratch in node which
is an amazing testament to three things
one JavaScript I love JavaScript I'm
loud and proud about that as a kernel
see an assembly programmer it took me
many years to come to grips with my
attraction the JavaScript it felt like
the forbidden fruit for a while but I
know I'm loud and proud I love
JavaScript a lot of things I love about
it it in particular javascript has got a
first-class support for asynchrony
thanks to closures so you can it's very
easy to build an event oriented
asynchronous system in JavaScript but if
Java scripts not enough we needed v8
huge debt of gratitude to v8 not just
for v8 but for taking off an arms race
with all the other VMs every time we
have a high-performance JavaScript VM we
owe it to v8 because v8 is the one that
actually kicked us off there and that is
critical and then also we've got what
note is is basically those two things
JavaScript plus plus v8 and then taking
the UNIX system abstractions which
or the sister abstractions that God
intended I'm speaking on a regular basis
on these things so he wanted me to
convey clearly that yes this was my
intent it got confused there a little
bit that's why he called Dennis home I
think that he wanted to so the the
system abstractions that that are
actually the right system abstractions
which are UNIX you take that together
and that's what that's what note is so
note for us has been terrific with the
asterisk of how do you actually go to
bug these serious production problems
which like the problem that we had yeah
so before we get where we're going to
talk about our you know our approach to
postmodern debugging for nodejs before
we talk about it we need to talk about
this tool that we have on our system is
called MDB this is the modular debugger
this is a debugger initially created as
part of Solaris kernel development for
post-mortem analysis of kernel crash
dumps and what's really important about
the kernel is that it's got a very large
number of subsystems each of which is
pretty complex and so and they of course
they interact with each other so it's
very important to be able to build tools
to iterate sort of the the object of a
particular subsystem and you know figure
out what the connections between these
things are so MDB really focuses on the
ability to build tooling and build
tooling on top of the other tooling and
the way you interact with it we'll be
demoing in a second is you've got this
thing that looks like a shell and you're
you know you can pipe commands together
so you can walk though some set of
objects and you pipe that to some other
D command that you know prints out
information about those and then you
pipe that to something else
this is extremely important and again
the ability to layer these things so
Brian's gonna demo on the live do but
the live kernel so MDB of course can
also operate on the kernel that's
running on the system what he's demoing
now is a command called stacks what
stacks does is it goes through all of
the threads on the system grabs a stack
trace and then coalesce as those so it
counts how many have the same stack and
it gives you a representative pointer
for each one which is a pretty simple
idea but it's incredibly important to be
able to do this on a system with
thousands of threads and you can filter
that by kernel module by function or
whatever you want now he's gonna walk
proc so cold walk box so that the syntax
for m2b is definitely
a little bit strange just sort of put
that aside for a second so walk croc
it's just going to iterate over all of
the proxy structures in the kernel and
now he's piped that to that PS yeah : :
PS you can pipe that to print proc TP
user you come and now you're getting
that field from all the proc structures
so it's just it's really important to be
able to just quickly iterate through the
state of the system and it may that
natural platform for building
post-mortem debugging for node because
it's already designed with the idea of
building new tools into it and and being
able to put these things together so
with that should we dive right into the
core file for that way yeah sure so we
talked about the problem where we had
this node program spinning on CPU that
we didn't mention we did check a lot of
things we checked like logs
we checked what system calls it was
doing right because a program has a hard
time doing a lot of interesting things
without making any system calls
you're not talking over the network
you're not writing file so it's like
you're not outputting anything so it's
just running on CPU we took the core
file in hopes that some day later we
would be able to figure out what it was
now Bryan's opened up this core file
this is the core file we had from
production the very first time that we
saw this problem that we literally could
not analyze for something like eight
months yeah just to correct you one
thing you said we took the core file in
the hope that we would be able to debug
it that's actually it's actually miss
read of history because we had no hope
that we were ever gonna de bug it and we
took the core file because this place
isn't expensive and you might as well
have the information but Dave in
particular was like man we've got to go
do post-mortem debugging for node and I
knew how complicated this was and how
brutal the VM state would be even for a
a much easier VM a much lower performing
VM it's like that's impossible that's
actually impossible I mean yes it's all
software bla bla bla but this is I mean
truly some software is impossible and
this was definitely in the impossible
bucket for me um but I feel ready to
solve a new machine by the way Tracey
Kidder's soul of a new machine um
excellent excellent book and I I would
say must read for every software
engineers the soul of a new machine and
it's a must read because has also two
nuggets of wisdom and one of the nuggets
of wisdom pertains directly to this that
they brought in a junior engineer and
nobody wanted to actually deal with this
guy like everyone's busy not because he
was a jerk but because everyone is busy
with this undated general 1979 they're
all busy on this next computer and they
just can't afford to mentor this guy so
they just kind of go tell him to go
solve a problem they tell them to go
write a simulator for the new
microprocessor because they know it's
impossible to write a simulator and
it'll keep him busy and alert a lot and
then you'll come back and you'd be
frustrated and you'll figure out how did
they can help out he comes back two
months later and says okay I'm done I'm
done with what I'm done with the
simulator you told me to go write the
simulator I'm done with the simulator
and there's this great moment where the
engineers look at one another and they
realize that each had forgotten to tell
him that it was actually impossible he
did it because he didn't know it was
impossible and I didn't want to like
tell Dave that this was impossible even
though I firmly believe that it was so I
would cut oh yeah sure yeah maybe day
and as they've got excited about this
like oh yeah it won't be that bad Dave
was like you know I don't think it's
gonna be that bad and I'm like it won't
be that bad
no of course not it won't be that bad it
won't be that bad and of course like
three weeks later it's like oh my god
this is awful like they've come on
you're you're you're three weeks in now
you got to keep going on so Dave did an
incredibly difficult thing here and what
were you what I'm doing now is I'm
loading the the v8s Oh module and so
this was a long time ago because it's
it's pointing out that this was node vo
for yeah exactly you know this actually
an actual dump for a long time ago this
is I know I'm sure Casper and folks must
have a seizure when they see the three
point one point eight point twenty six
but yes this is an old version of the
eight so we that's the stack trace um
actually much more interesting is the
JavaScript stack trace so what we have
here what we're looking at is the same
stack trace we had before with just a
bunch of hex addresses but now for each
one of them that's annotated with
information about what the JavaScript
level frame is so for the JavaScript
frames we actually have the name of the
function the file where it was defined
the line number where it was defined if
that's been computed but at least the
position information and then we have
some of the v8 internal frames and stuff
like that - V with a - V option on this
it like an apparition from the future
tells me all where exactly I am for
every frame of the stack I mean this is
much better than the number of vowels or
whatever and
file name this is everything and even
better we actually have the arguments
and unbelievably we can actually decode
these environment these arguments as
JavaScript objects I don't want to print
that sorry sorry let's try that actually
the computer is actually even very
excited about this it's like wow did I
just see what I thought do you want to
print this out this is amazing I got to
tell someone I gotta go tell someone
about this I'm just gonna go print this
out you keep demoing
I know you're on stage but wow that's
amazing and it is amazing and in
particular this was gonna allow us and
now as as we had all of a sudden it's
unbelievable information this is gonna
allow us to to resolve another
discussion we had which is whose butt is
this anyway because Dave and I are both
being gentlemen so we this code I've
written some code in the system Dave's
are a bunch of code in the system both
being gentlemen
we each insist that it is a bug in our
own code of course we also honestly
secretly believe and hope actually that
it's a bug in the other guys code you
actually don't want it to be a bug in
your code oh I'm sure it's a bug in my
code oh no no I'm sure it's a bug in my
code please don't let it be my code
please don't let it be my code
um so this is and unfortunately this
actually did not necessarily settle
things when you look at the stack trace
because this is actually code that I
wrote and this is code that Dave wrote
so this could go anyway still so let's
use the unbelievable j/s print on what
i've done is i've taken one of these
arguments the the JS object argument
there and I'm gonna actually print that
out that is the JSON that we actually
that comes from the program this is
meaningful in JavaScript we've gone all
the way up from the sewer to what we had
for dinner if that smells like a stinky
task it is and I don't know if you can
see it me obviously you guys don't know
anything about this code necessarily but
do you see anything near that that looks
suspicious but you might correlate with
an infinite loop min and Max are the
same
yeah now all right now is that was the
argument like so okay my code definitely
was not checking for min and Max being
the same so okay the infinite loop is in
my code but Dave as actually what this
code should never be called with minute
a max being the same
now both being
we each insist that it is a bug in our
code it is bug in my code that's right
it's bug in my code but I go fix your
bug III am gonna fix my bug we're both
gonna I think we both agreed to fix both
of our bugs
that's right and so the other key about
this was the function that is at the top
of the stack is completely stateless
which and we have both of the arguments
which means we actually got a
reproducible test case just from the
core file so even if you know it wasn't
totally obvious that main equals max is
gonna cause this thing to go nuts we
could very easily test it at that point
which was huge so it we've got a bunch
of other stuff here as well Coquelin v8
function actually heard an easy way I
can get a v8 function on this yeah there
we are there we got one so that will
actually print out a function like and I
should be able to do - D - that right if
yeah
so this actually and this matters to
probably slightly for your view but if
you work on v8 this is stuff that you're
familiar with because this is actually
taking us from the the actual object
that is that the J's function down to
the actual generated assembly and then
disassembling it oh my god it's gonna go
on for a long long time you actually
want to hit Q because it'll take five
minutes yeah we do a lot of work Wow
thank God computers are fast so anyway
allows you to get a level of
introspection that we've never really
had before and so Dave had had delivered
this to us like like Prometheus and we
were trying to think you know what are
some of the other things we can go use
this for actually no that's not even the
way we're thinking about what we're
thinking of is we have an excruciating
problem that we don't know how to
debauch different excruciation
excruciating problem we also had no idea
how to figure out right and that is
memory use so if you've deployed node
productions and put in in programs in
production or frankly any dynamic
language in production you've been
burned by memory utilization at some
point right and people love to OH I
blame the GC
oh it's the GC um it's virtually never
the GA especially with the a terrific GC
um even if the GC is running really hard
it's probably not the GC the problem is
you're not generating any garbage it's
looking everywhere for garbage you but
you have references to objects that as
far as v8 is concerned as part as far as
the VM is concerned Java whatever else
the objects are still
it's not actual garbage the garbage man
does not come by your house break into
your house and steal yourself and throw
it out that's considered to be
ungentlemanly you don't do that
so it's not garbage now you may think
it's garbage but it's not so how do you
actually end the problem in v8 is or in
no this is especially acute problem
event oriented system and the difference
between your ability to do work and the
incoming work that you have to do will
be memory so if you just can't keep up
your memory will begin to grow and you
need to know desperately is my memory
growth because I can't keep up or is my
memory growth because I actually have a
leak here I've got something that is
semantically leaked that I'm not
actually freeing and we wanted to go
like walk the the and because you were
thinking about how to do this with VA
right now we could actually go walk the
heap I spent a lot of time thinking well
you know this this debugger modules will
talk about has a lot of knowledge about
how v8 structures things like but boy it
would be a whole nother level of
complexity if it knew if it had to
figure out how to iterate the heap
properly you know starting from GC roots
following all the objects that are
referencing and you know following that
along and this is you know how young we
we become you know cynical veterans so
this this problem today was already like
oh my god this is awful on and then but
I was in in this code and and we're
helping extent us and so on and I know
it's like actually in order for
something to be a v8 object a lot of
things have to be self-consistent things
point to things that need to point back
to other things that need to be a
particular types and so on so if you
just look at an arbitrary bit of memory
in in your process you can actually
reason with a very high degree of
certainty about whether it can't be a a
a JavaScript object so the question we
had is like what if we just go through
memory and try to treat everything as an
object it's like what is so filthy it's
a great example of the kind of brute
force that you can do if you have the
luxury of operating on a core file you
know outside the critical path of
restoring service and I've say I love
brute force on a core Dom be it feels
like the computer is doing work for a
change
you know so you go out you the the human
it's overlord to go out for a cup of
coffee well while the computer your
servant does all of this work those I
love it when it we go
a core dump and I don't know how long
were to be out here so there we are I
just ran it Coco and find Jay s objects
and actually you know what let me I'll
run that again but with the the minus V
option we're just going to give us lots
of solder times B which will give us
actually more information about the the
amount of time one second the number of
objects the the and this is the number
of reads of types and it did the number
of JavaScript objects have found and
process object to the unique objects
that unique if eyes the objects by their
actual properties and now there's
there's definitely some improvement we
need to make here you can see that we're
identifying things that look a bit odd
but we're also finding a bunch of
legitimate stuff here as well so let's
just take kind of one of these randomly
and now I can J s print one of these
guys and you can see this is actually
this is a little obviously a legitimate
JavaScript object and we've been using
this so much that the I know that people
have been complaining more and more
about the performance of fine J s
objects me Dave Dave
this one wait a minute this one took one
second but when you actually have I mean
this is a 27 Meg core file when you
actually have a memory problem in this
core file is actually several hundred
Meg's it took a little bit longer yeah I
took a little bit longer like it took
like a minute or like two minutes and
I'm sorry that prometheus is held up in
traffic okay that's gonna have to be a
little bit patient I'm on my frigging
way with the fire the with with fire
exactly but the on because the reason
that day was complaining about it
actually is because we've incorporated
it into the way we develop node programs
and whenever anything goes wrong now the
program the first thing we do is G core
it let it run just G Cora take the core
dump and do a fine J s objects and you
like to do - P right Dave
yeah so let's see I should be able to do
like - P exports so that finds every
JavaScript object that has an exports
property oops
darn it sorry communi and then what I
can do is actually go pipe that through
and we can actually look at all those
objects so let's run that again and
sorry quit there so if I do find J
objects - P exports was that exports
sorry I can pipe that through to find J
s objects that gives me those are giving
me the reference
those are all the objects that match it
and then I if I want I can pipe that
through J s print and these are the
those are the two kinds of objects that
have exports members this is useful as
it turns out and we use this a lot in
developing our own node programs to the
point that now we're complaining about
performance which is good that's like
that's actually got a great position to
be in so and we've actually I think most
importantly we've actually used this to
debug real honest-to-god problems so we
had a really nasty problem where we
consuming way too much heap then we were
able to use fine jazz objects and Isaac
was Issac Schluter works for trying it
was able to actually use it to to
actually confirm the hypothesis that he
already had so tremendously useful stuff
and the owner if you may briefed you
want to touch on what's going on here
but yeah so you know we basically we
spent a while talking about how hard
this was and then we just kind of showed
it it's like well this is kind of magic
how does it actually work well obviously
at some level our debugger module just
knows a bunch of stuff about v8 it knows
how to walk object properties for a
given object it knows how to walk stack
frames and it knows how to decode heap
objects but it was really important to
us that it not be so brittle that
anytime v8 changes at all
that the thing just totally breaks and
so what we did is I think you can
actually go to the next slide we encode
it in Lib v8 and then we propagate that
into node we encode a bunch of I mean
this is really pretty half-baked we
basically just encode a bunch of offsets
describing the structure of these heap
objects and other useful constants like
you know the the JS function argument
being used in each frame has always
stored it you know offset two words from
the frame pointer like that was just
something we wanted to be able to
parameterize by so that if we were doing
this on a different architecture or 32
64 or whatever it would still work and
this this was very useful it means that
when small changes are made
we don't just totally break all the time
but it continues to be a thorn in our
side that if if bigger changes are made
to v8 you know if those algorithms that
I described change about how you walk
properties of objects that breaks our
debugger module at the moment because
the the module is built separately from
node itself and this is kind of what we
see is one of the bigger open problems
in the future is how can we embed
knowledge in the VM how can we encode in
the VM enough information about how to
debug itself that doesn't rely on the VM
still being running and we've taken a
baby step for that and slava and the v8
team have been terrific on helping us
find ways to better encode that
information from the 8th to break us
slightly less frequently but we still
get broken yes and it's it's hard the
logic exists in two places so there are
actual problems with this approach it's
not completely perfect um it we think
it's a great approach it's comprehensive
it's got zero overhead but you do have
the this problem that it's brittle and
we we want to work on making it less
brittle we've got some ideas to actually
go do that the key is that when we're
when we have the technology to do this
it must not rely on the VM running so
that's the I think the difference
between this and most other debugging
technologies that have come before it
for dynamic and the nice thing about
that too is that as soon as we've built
this tool immediately all of our node in
production became debuggable in this way
we didn't have to go modify the
application to do that which i think is
also pretty significant so so that's MTB
and postman debugging I want we don't
have a huge amount of time left but in
the time we do have left we want to talk
about kind of another axis of debugging
and that's debugging transient problems
problems that are non-fatal problems for
which a a snapshot of state is
insufficient to debug the problem now a
snapshot of state can be sufficient for
lots of different kinds of problems but
performance in particular can be very
difficult to debug from a series of core
dumps and I spend a lot of time trying
to do this in kernel development in the
kernel we used to and in the kernel we
don't have a g-chord
equivalent I mean you actually take a
core dump you have to actually bring the
system down and the tooling was so bad
historically that this if a system were
performing badly we would want to
actually go an amide the system merge or
actually get a Cordova crash dump on the
system and reboot the system which is
like saying oh you you have a cold
okay I'm gonna shoot you in the brain
and then we'll know exactly where your
cold came from it's like but I will be
dead it's like well yes you will be dead
but we'll know exactly what happened to
you it's like okay what this is this is
like a sadist you're talking to and yes
sure that kernel developers also are all
sadist at some level but so we had this
problem of
how do we actually go instrument the the
colonel ugh the colonel and in
particular how do we understand why the
system is sucking and and we had this
problem again a decade and a half ago
and I along with add eleventh all my
Pharaoh at son developed this technology
called eat rice so DTrace allows us to
dynamically instrument the production
system its design center is around
production systems how many people have
you use DTrace oh okay that's pretty
good actually that's good so folks have
used tea trays those of you haven't this
is a facility that that we first shipped
in 2000 I was 2003 that we first shipped
that I was open-source 2005 it's now in
all aluminous drive systems like smart
OS from giant Omni OS also Eris drive
systems it's in bsd it's in freebsd and
it's on your Mac Linux ports are in
progress so that's finally happening
after many years of excuses for why that
couldn't happen but that's now moving
forward as well so um it is a technology
that is it is slowly becoming ubiquitous
certainly on Mac FreeBSD and illumise
drive systems so dynamic environment
suppose the same kind of problem for
dtrace that MDB posed and in postpartum
hugging which is say now I want to
instant the system and I want to
understand what's going on at the
highest level at layers of software when
we first developed DTrace and when I
first did this I embarrassingly was only
thinking about the carnal I mean who
cares about applications applications
just exists to put load on the beautiful
operating system there but as we
actually went in and we went kind of
forth in the world with dtrace we
discovered that the much larger
performance wins to be had were not from
making the kernel incrementally better
on these pathological loads but
understanding where the pathology was
actually coming from up stack and C and
C++ environments can do a certain amount
of damage but oh my gosh the dynamic
environments can do a lot more damage
you've got a perl script I can't tell
you the number of Perl scripts written
to monitor the system did themselves
become the problem with the system when
you go up on D trace like what's this
proscope oh that's supposed to be on the
monitor the system
yeah it's killing the system actually a
very fine line between the policing mind
and the criminal mind when it comes to
monitoring software so
we needed to get up into these dynamic
environments understand what's going on
but now we're from we're from the kernel
we're looking up from the the lowest
layers of the software up into this VM
that we can see nothing into how do we
actually go do this well one of the
things that we added were something
called statically defined tracing and
you could have these things called the
uset providers but you instrumented the
VM itself and said here's where I'm
making a function call here's what I'm
doing this here's what I'm doing that
and some Ruby Python PHP airline took
that approach it works for some bluntly
it does not work for higher performing
VMs for lower performing VMs this is
easier for higher performing VMs it
becomes excruciating to even have
additional code bloat even though
they're knobs where you're actually
doing these function calls so we need to
take a different approach or we just
decided to make a different tack for
node
the first thing that we did is we added
uset probes in note itself and this
allowed us to get for example probes are
when we're doing a GC which is useful
right I mean if I I think it's time to
yeah the example on the next slide of
using node of instrumenting GC start and
GC done and actually I'll just hop onto
the box here and show you what this
looks like so let's go back over here
and we're on a box that's got that's
running lots of node all the time I'll
go on here and I'm just gonna instrument
on GC start and GC done so if I do node
node star GC start I'm gonna see output
whenever any node process starts doing
GC and fortunately we have enough node
processes doing enough non-trivial work
I'm even on this VM that someone just
did GC now you may want to know who
actually did GC so you could say printf
% d % s started a GC dot dot and we'll
make that pid' and kurpius info points
to PR PS args might and make that quiet
so now when of course now I'm sure won't
obliged for now no one will do a GC but
the next time someone doesn't you see
there we go we see that that that node
process the workflow runner is just
started a GC then you can look at things
you can instrument you see Sarge's he
done measure the latency across it and
so on so there we are now we got a
everyone doesn't you see ok party on my
laptop
so and we can get these kind of
histograms they are strong believers an
ASCII art you can get these great
histograms to actually understand where
this this latency is actually coming
from and actually Dave you've got a good
little actually a good little program
that Dave wrote where is it it's it's an
NH EP Snoop right yeah so this is a
little goober that Dave rode this is
just a shell script and what this is a
shell script around all these node
probes so I think I could just run this
and without any options right there yeah
that'll show you HTTP activity that's
that's what I originally built it for so
anytime a node process does an HTTP
request or serves up HTTP I think as
well oh there we go okay so the the
workflow again which is kind of this
little goober we have the student work
on this just did a put a cat again you
can see the actual latency and the kind
of the cool thing here is and this is on
github by the way if you look for n HTTP
snoop
I think it's minus n right Dave yeah
there we are that actually prints out
the D script that it actually generated
filthy in some cases but it's a
complicated a script but so this is a
this is just a descriptive Essure script
that instrument server request server
response measures the light and say
prints it out in kind of in a pretty
format and so on so this was this has
been good and we've we've used this um
this has been very helpful we've used
this to debug real problems to really
understand notes latency GC latency and
so on actually was great to share some
of that production dated with a v8 guys
initially because the numbers we thought
looked great and the v8 guys like wow
that's really nice that GC it actually
like is actually doing GC for very short
for it's a time like yes yes he did a
very good job so it was great to
actually see the data from production
systems that it could feed back to them
and in that case there wasn't an issue
so it's great we wanted to allow people
that those were adding probes
effectively in C++ in node because
that's what's bound to v8 we wanted to
allow people to add probes in JavaScript
itself Chris Andrews did terrific work
on the no dtrace provider this module
allows you to define your own probes in
JavaScript and then fire them
selectively
and this has been huge for us our
colleague mark cabbage has uses
extensively for his I he did notify and
LDAP das
is a from scratch implementation of a
sn1 parsing to implement an LDAP server
in node no this was not a punishment
this was actually elective and yes it
was done for good reasons it's been
terrific but so we've been using this a
lot it's allowed us to measure the
latency in these systems one of the keys
when you're looking at dtrace is
correlating system activity deep in the
system to what's going on
way up the stack and you know again we
have that same problem that we had when
we were talking about postpartum
dividing where if you go to do this you
actually have a hard time seeing what's
going on so I in particular I've got my
I think I've got a little script here
like mr. spinny J s so I'm gonna if I
run mr. spinny is mr. spinny is just
gonna go spin around and let me log into
that box
and what we're gonna do is I want to
understand what's going on there I I
could I could see for example that if I
run PR so that I can see that okay he's
spending on CPU I want to understand
what he's doing so maybe I want to let's
actually run a profile probe and
historically what you do is run a
profile probe and say exact name equals
node let's say let's just get aggregate
on a user stack back-trace if I run that
and you control C it I in me I'm into
this old problem again remember this
this is a so we're seeing again stack
frames that in hacks we've had this
problem historically in dtrace and we
knew we had this many years ago with
Java in the JVM and so we're trying to
figure out how to solve us with JVM and
if anything it was actually even harder
to solve it in dtrace than it was an MDB
because we didn't have the luxury of
being postmortem we rinse it you would
you say we're executing in the kernel so
in the kernel this thing has done a you
know and say it's done an open system
halt or what have you or it's being
taken off CPU we need to at that moment
go walk up at stack and and correlate
these hex addresses to actual proper
frames that is brutal to do in sich you
and so we couldn't find a better way to
do this we invented this crazy ass
mechanism called you stack helpers that
allow you to write this very weird piece
of software that we compile and glom
onto the executable when the executable
runs that gets
i octal downstairs into the kernel and
that software which is written in a
touring in complete language D allows us
to in a totally safe manner actually
translate in six you stack frames to
JavaScript frames now that's a lot of
light talking
so let's actually just see it in action
if from your perspective someone's
developing software I want to understand
and owe me a another option there to
allocate plenty of stack size for it I
misspelled store size so now if I run a
J stack the J actually is not for
JavaScript it's for Java because that's
what we originally developed it for I
can now see where I am mumble calling
froths and so on I know exactly where I
am we can take this data and then go
visualize that in actually some really
interesting ways so one of the things
that our colleague Brendan Gregg did is
and I'm all kind of come back to that as
needed but so this is the profile
provider one thing I'll call you Brendan
Greg did is took this and visualized it
as a this thing called a flame graph and
the flame graph allows us and let me
bring up the full version of that David
you want to explain this why yeah so the
idea is okay you're running this profile
probe 100 times a second on say 32 CPUs
for 60 seconds you have an enormous
number of stack traces but how do you
actually visualize them well you figure
most of them probably start with main at
the bottom right and then they start
diverging a little bit well the node
ones will all say node star evie run UV
run and then they start diverging and
then there'll be a couple of common
frames in this silo and then it starts
diverging again and so the question is
well how do you actually visualize it
this is what we did
well Brendan Gregg did actually and so
you have these silos that represent
places where it diverged relatively low
in the stack and you can zoom in on each
of these things so if you can like if
you zoom in to the corner you can hover
over each of these things and at the top
it'll tell you which function that was
and how much of the overall time was
spent in that function so for a
cpu-bound process it's a process that's
on CPU like say a hundred percent of the
time you can see exactly how much time
was being spent in each JavaScript
function and it's actually a little
better than that because you actually
have JavaScript and C++ functions and
anything else you're doing so you know
if you're using Lib ping as we are to
generate other types of images you see
the Lib ping frames too you see the SSL
in there as well and it's
if you look in here so these are all
just is Davis saying these you got some
c++ frames in there but then you also
got the JavaScript frames and it allows
you to actually debug where you are in
your JavaScript and visualize it and
importantly for a production system you
know we didn't restart the program we
didn't run it with any special Flags
that cause the VM performance a decrease
this was just the program was running at
full speed in production right this has
and this is the most important axiom of
D tries other than safety safety and
production and no probe effect when not
enabled the important thing is that you
can take D trace walk up to a system
that is totally optimized and without
restarting anything use D trace to
answer questions about what it's doing
so this is a really key technology we
got a bunch of other real world examples
and obviously be putting our our slides
online but we won we obviously mindful
of time I think you know from from our
perspective the this technique of post
form the bugging of of node in
particular has been huge and I if I
could get in a time machine right now I
would go back just a year ago and tell
us that we are going to go and be
presenting this unbelievable work that
we have done because I didn't think it
was possible I mean I it's amazing to me
that we've been able to do this and it's
been incredibly useful we've already
used it to nail these really nasty bugs
yeah problems that we literally could
not debug before like the infinite loop
one that we described like we had no
idea how to debug that before so this is
not taking something that's hard and
making it easier this is taking
something that's impossible and making
it possible and that that's been
terrific for us we're using in our own
are our own development now that we've
got kind of things working with it
working so well there are some open
problems still we want to make it less
brittle we want to package it with the
VM there's a lot more we could go do I
think one of the questions that we'd
that Dave and I always have is if you
were designing a VM from from ground
zero from day zero and you were
designing it for debug ability what
kinds of things have you your design
into it without sacrificing performance
and frankly there's not really a VM that
have been designed with that in mind
with production debug ability so it's
really exciting that we've been able to
get all this working with the aid and I
I think that we've been a little bit
surprised that the post-mortem approach
is actually worked at all for heat
profiling yeah I don't think we really
anticipated that it showed a lot of
promise that's a very hard problem what
we had to find yes objects is
large forward but there's a lot more yam
to be done there and with that thank you
very much and we'd welcome your
questions sorry I did from the core dump
can you on exec um no is the short
answer
um that on exec is a brutally hard
problem that works under extremely
isolated conditions and it works when I
mean as soon as you have a connection
open to another process of which node
has many you're why it's very hard to go
and actually go rehydrate all of that
that dynamic state so there has been
worked on the UH exact in fact the the
v8 you guys use it to take a snapshot
and part of the build process you can do
it when you know that that is a very
kind of confined environment I don't
have external state I don't have to I I
don't have connections I can go do it
there in a process in production this
process we could not Donna thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>