<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2012 • Bottleneck Analysis • Adrian Cockcroft | Coder Coacher - Coaching Coders</title><meta content="GOTO 2012 • Bottleneck Analysis • Adrian Cockcroft - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2012 • Bottleneck Analysis • Adrian Cockcroft</b></h2><h5 class="post__date">2013-04-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2iLx3XBeUBo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I know about bottleneck analysis
and I'm talk about a very important
aspect of bottleneck analysis which is
the delivery of beer to large numbers of
conference attendees some of you were
were there I think and it's very
important to keep them in this happy
state you can see as opposed to this
fairly grumpy state that we had also at
the night and what you tend to run into
is this problem where you'll see a
bottle and it's empty okay so so you
have to figure out how you're going to
manage and maintain full bottle necks so
that people can stay happy all the time
so let's assume that where we've
deployed a netflix based cloud service
because we would do that kind of thing
to collect lots of data on on how much
beer people have consumed and how long
it took them to get it so we have this
be a service that's monitoring things
and it's riskier and we just have it to
the URL so we can put some our code in
here so people can figure out how to
read files from her and and we plot the
response time of how long it takes to
get your beer and you know it sort of
okay but it looks like there's these big
spikes every now and again we run out of
beer or they or something and the unit
of time here is the jiffy because you go
to beer in a jiffy but it's a unit of
you know one jiffy is a good amount of
time to get your beer if it takes too
many trophies it's too long obviously
you know spending 60 jiffies is a very
long time so how would we summarize this
response time it's this is the hard part
right so let's try summarizing it with a
few different ways of doing statistical
things in this you know it may be sort
of well the mean is 3 so that's sort of
okay but the max is 67 and then we are
quantiles and response standard
deviations and means and to stand you
it's this is all hard stuff so what we
really want to do is make it easy to
deliver large amounts of beer very
quickly and I have a great example here
from q con london who was at q con
london so this was this was the best
beer delivery system i'd ever seen
basically there was a room with maybe
you know something like 500,000 people
in it and there were these waiters with
trades of grolsch just making forays
they were just appearing and dashing
and when their tray was empty they went
back for more and it filled this room
with be extremely efficiently and so
that's that's made easy so so let's
let's sort of do some modeling around
what that actually looks like there's a
some code I wrote in our once called CHP
which draws interesting graphs and I
tried fitting it on a slide and it
didn't fit so you just have to go and
find it but if you if you create this
artificial scenario where we actually
let's see how much let's scan let's
that's bits try putting the throughput
of more and more beer by sending these
guys with trays these guys in faster and
faster to see how much beer we can
deliver to a crowd in one go this is
what the chp plot looks like so what
I've got in the top right is a ramp of
throughput I'm just testing out all the
possible throughputs I could have in
terms of delivering beer into a crowd
and what I have along the bottom is the
response time versus Headroom well the
big space here is a distribution of
response time versus Headroom right and
it's a scatter plot but in this case
I've got a very controlled input and I
get a straight line this is a
well-behaved system but it seems like
whoever is putting beer on these trays
as a bit of a bottleneck there and it we
run out of capacity for the purpose as a
pudding beer on these trays so it gets
slower and slower it takes longer longer
to respond as you put more people in and
these funny blocks on the side are
histograms of the distribution so I've
got a very even distribution of
throughput because I was kind of just
doing this sort of test theoretically
and I have a distribution of response
time that shows most of the time it's
nice and fast but it gets you know
there's a smaller and smaller amount now
that's not very realistic so let's say
you know let's say we were measuring a
real system and it would look something
like this it's roughly the same so I've
got a roughly constant distribution of
throughput and I have a sort of a
distribution of response time it's a bit
more varied but it still got this sort
of up and to the right hockey stick
curve kind of thing so as this is what
you expect as you put more throughput
into a system its response time slows
down that's the bottleneck right so
that's the computer version of the
bottleneck right
and you can see I've got them mr. sort
of three days worth a fairly noisy
looking data the top right part of this
graph is the throughput over time just
give you some context for what this
looks like ok so we figured out what a
normal-looking response time looks like
if you happen to be delivering large
amounts of beer into a large group of
conference attendees but what happens if
instead of this being go to 0 who's its
go to Hawaii let's say we're in Hawaii
and instead of beer we're trying to do
the Mai Tai's to people and mai tais are
much more complicated they have
umbrellas in them and let's say there's
only one person that knows how to put
the umbrella in and and and that causes
another different kind of bottle if so
we've got actually we end up with a
distribution that looks like this and
this is what happens when there's lock
contention in the system because there's
a serialization point we're only one
person can figure out how to get that
umbrella and there's lots of people that
can make mai tais lots people trying to
drink my toes there's only one person
who's got the stock and can get that
umbrella in exactly right so if you ever
see that distribution and it's got sort
of it's flat but it's it's going up so
here if I double the throughput I double
the response time now and just basically
blocking up on one thing so that's
that's a very different shape of graph
so well let's sort help solve this
problem by bringing in the same guys we
had in London and have them deliver lots
of beer to people but and that lets us
do simple drinks and complicated drinks
and if you if you're in Hawaii you can
get this really complicated drink which
is an entire pineapple it takes quite a
long time to make you start with a
pineapple you hollow out the pineapple
you put rum and stuff in it and then you
decorate it to look like a Dalek when
you've drunk half of it let's get sort
of instead of saying exterminate it says
inebriate inebriate right it's sort of
that's the general principle here so
what we now have is a mixture of work
going on we're trying to we have one
group we have one guy delivering
extremely high you know extremely high
volume very simple things in your
bottles of beer very easily and we have
some other people making these
incredibly complicated drinks and if we
do them both at the same time
we get this very strange-looking
distribution if we plot it using our
special beer you know drink delivery
monitoring service that we're still
running obviously because it's in the
cloud and it can see what's happening
somehow and what's going on here is that
let's say we have a number of servers
and they can either be filling trays
with beer or they can be carving out
pineapples so the fact they start off
like a the mixture of these things but
eventually they all end up carving
pineapples because it takes forever and
there's nobody filling trays with beer
and what happens then is the throughput
goes down and it goes really really slow
and you're up on the top left side here
you're right up there and and eventually
somebody finishes carving pineapples and
there's a big stack of guys standing
there with empty trays you start filling
trays and the system starts delivering
lots and lots of trays of beer and then
gradually more orders of pineapples come
in and you oscillate back so this system
is not stable it oscillates back and
forth between delivering lots and lots
of very fast things and a few very slow
things and this is a static
characteristic which is quite hard to
observe but when you do these trent
deezer distribution plots it's easy to
see that this is happening and when you
see a system oscillating it's quite
often because you've got a mixture of
very slow things and very fast things
that you're giving it to do it once and
that this is this is the characteristic
of a thread starved system right there's
plenty of spare capacity in the system
but you don't have enough threads you
need to add more people that can cover
pineapples until you have an excess of
people and you have some spare people
left over there can also deliver beer
well the full possible number of
pineapple carving is going on at the
same time so the way you solve this
problem is by adding threads right so
now we can see we know when we have lock
contention and we have web out of
threads and we have normal behavior but
I want to show you something else that
happens which is that if you manage to
build systems that order scale that grow
and shrink with capacity which is sort
of you know this was a good example I
think you know I have a scalable set of
beers here that are being delivered I'm
getting multiple beers but the only
example I could find was actually a
netflix on this is actually one of our
internal services that auto scales
AppDynamics has a way of plotting this
so if this is the throughput and this is
the response on this one Sam looks a bit
weird but one of the things you can see
is that the lowest response time occurs
when the throughput is dropping and then
it goes up a little bit later now if you
do the distribution plot for this
there's this weird sort of set of dots
here but what's actually happening is
let's start at the peak peak throughput
okay the top of that blue section that's
the bit to the furthest to the right
when over time what happens now is
there's a circle you're going around a
circle so you go down the bottom along
the bottom lowest response time to the
lowest throughput and then what actually
happens is you do I have a yeah there we
go I now have very few machines or very
few bottles of beer or whatever in front
of me and so as capacity increases it
actually goes up in a sore tooth because
it gets a bit slow and then I add more
machines and it drops and so there's
this sawtooth going up here as I'm
throwing more capacity as I'm increasing
and then it comes all the way up here
and then I'm throwing capacity away and
it sort of comes back down here so you
get a big loop in your in your thing so
if you see a loop you know you've got
something that sort of auto scaling all
right and so that you can use this
little CHP code that I wrote years ago
to do the diagrams or if you happen to
have appt dynamics I might persuade them
to add this to their product which made
me happy all right so this is basically
my summary plot these are the hard
things figuring out whether you have
lock contention whether you have a
well-behaved system whether you're
oscillating in our thread shortages or
whether you have some to looping order
scaled system and if we have to do is
draw a graph look at it and decide which
kind of you know what shape the graph is
and you can see what's going on all
right so that's it and we can finish
with some liquid Aloha and
kaskus you also observe that when the
system changes performance
characteristic then that the system
itself is used in another way so then
your data also changes because for you
of course the users for example go away
and then you have auto scaling because
yeah you can certainly move between
these different things you could have a
system that starts off well behaved and
you put and all of a sudden say maybe
it's well behaved in tests but when you
go to production there's more latency
because real customers are further away
and all of a sudden you're out of
threads and system that starts off well
behaved starts becoming oscillating so
you and you sometimes see this there's
these graphs which show sort of
throughput like this except the high
point so this is a beautifully smooth
top right but if the top looks like
Gilbert's head it goes up and then it
oscillates like this and then it's got a
nice smooth dip right you know Delbert's
haircut it's kind of so spiky on top
that's oscillating and then at low load
it's actually nice and smooth and
sometimes you see throughput graphs that
do that and that spike enos means that
at peak you're out of threads but at
load load lower utilization it's being
well behaved so you're actually moving
between these two positions on the left
and and when you average everything out
you can't see those oscillations it's
one of the problems and it's odd to
think that a system would have an
oscillating behavior it's a it's not
normally something you see so but it's
very confusing because the first time I
saw this graph at the bottom is I
couldn't figure it's not supposed to be
that shape it's supposed to go up into
the right</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>