<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2012 • Real-time Analytics with Apache Cassandra • Richard Low | Coder Coacher - Coaching Coders</title><meta content="GOTO 2012 • Real-time Analytics with Apache Cassandra • Richard Low - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2012 • Real-time Analytics with Apache Cassandra • Richard Low</b></h2><h5 class="post__date">2012-11-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6aPHD7xDq90" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I don't want to talk to you today about
real time Cassandra so I'm going to
start off for a completely abstract
beginning thinking about real time what
is real time what are people want house
in real time what are they need moment
or X on of at all just what we might
want and I'm going to think what that
means for your database how are you how
do you store your data how should your
your database perform to give you those
aspects of real time and then I'm going
to show how I cassandra has a lot of
those properties for real-time ways we
built for real time applications it will
concrete talk about a little bit about
some of the internals of cassandra and
why it's really good choice for a real
time application and then yeah a bit
about how do you actually write a real
time application on top of Cassandra so
they almost start by asking the question
what is real time everyone uses the word
or what the hell does it mean so I
googled it as you do and you've got you
there's there some sort of different
kind of answers there's some that give
you a time like me settings or
microseconds there's some that say
immediately than or what that means but
presumably that's fairly quick someone
says it should be predictable yeah you
probably wanted to be reasonably
predictable no maybe you know it's going
to be less than a second that's all you
care about but you can never be more
than a second yeah that's useful too so
one of these things actually me so um
just before I try and answer that
question just sort of what what things
maybe may you be familiar with one real
time so one is this sort of web
analytics thing where you're looking at
who's on your side now what is now me
you're not going to find that someone's
access to your site you know a
nanosecond ago in Australia because it's
quiet even speed of light isn't even let
you let you find that out so it's not
sort of now it's mainly in the last
second another thing is stock prices so
if you're a trader sitting in the
let's not be staying somewhere you want
to know what the price is now you don't
want that to be old because then you'll
make a bad decision but of course it's
not now maybe in the city maybe it's
like a few microseconds old that's
that's pretty quick so maybe that's what
they mean by real time left and what
sort of what sort of queries do we
actually do so i'll talk about how these
queries actually work later they're just
some sort of query that you may want the
answer to in real time is give me
something his is a key give me a value
or you know give me the stock price okay
you want that to happen quickly or you
may want a range of things give me
everything between a and D is the same
sort of with or you may want to know
stuff about something like how many of
these things are give me that answer
quickly what is the top 10 people
visiting my website or top 10 countries
visiting my website now give me that
answer or how many unique visitors have
I had in the last out give me that
answer quickly questions like this are
things that people want to know quick
okay so now i'm going to go an answer
what i mean by real time it's on a
mathematician by the way so I'm sorry
about formality of this it's not going
to be forward for the rest of it um so
so what I think we all time people mean
by real-time is how long it takes you to
get to the answer so if you're asking
for something enormous like a movie you
want it to start downloading quickly and
then it downloads at two megabytes a
second then you get it in half an hour
I'd say that's real time for my move if
it took like six months to get it and
that's pretty slow okay so if you ask
for a stock price that means it's going
to have to come really quickly so the
reason why i'm saying i'm making this
definition right
that is so that the more you are all
along is going to take if you ask me for
the stock price history for every single
stopping for the last 10 years you still
want to know that quickly because I'm
going to make some calculation based on
it but I can't give it to you in a
microsecond because it's just going to
take longer than so community than that
so let's limit it by the network which
is the thing that's actually you've got
to be limited by the network so let's
let's use that as our limiting thing if
we much slower than that then we're in
trouble so so so yeah so the the real
time the sort of time scales were
talking about is how long it takes me
together and everyone so there's so for
small things there's a sort of there's a
round trip time there's a pain of like a
few milliseconds maybe with it's over
the internet and yet obvious thing no
quieren can take less time than it takes
you to receive it which is just off it
so I'm not really saying very much it's
reasonably obvious but I'm just trying
to sort of formalize it to actually give
you a time scale and we're going to use
this to deduce some some aspects of a
the real time solution must have so some
other reasons why I think this works
quite well is if you're on a faster
network you probably expect a faster
response so if you think back to the
first time you ever went online you're
probably using a and a 14.4 k modem dial
up in your it take you a minute to
connect and then you go to a web page
and live and the graphics come really
slowly have these progressive jpg things
that gradually get better and better to
take you 30 seconds just to get a small
picture and like the minute load a
webpage the first time you did that you
probably thought wow that's really quick
because before you know you we've had to
go and buy a book or whatever you know
something that's very slow find out
something um so so then you would have
thought yeah that's pretty quick but now
if you go to a web page and it takes you
five seconds to download you think
that's really something i'm going to
give up i'm not good I'll get using this
so if you're in if you if you pay for
space in the London Stock Exchange just
to get that micro second pain then if it
takes you a me second storm at much time
you'll be very upset you know you'll do
manual so so yeah so so I think this is
the sort of captures captures this sort
of growing towards real time getting
faster so let's have a look at some
implications of this with an example so
this is the question I want to ask I
want to get back the arm say in real
time so how many page views have I had
from France in the last 24 hours okay so
I want a number number say it's like a
million it's not very palpable with some
overhead some packet of information
whatever maybe states of kilobytes of
data or what I'm asking for and I've got
a reasonably fast internet connection so
I like my round trip time is amazing 10
megabit connection i can download a
kilobyte in about me second as well so
the network traffic should take two
milliseconds so the the database has got
of the order of two milliseconds to
answer this question maybe it's going to
take five maybe ten but not 100 you know
if I had that constant that you need to
have that concert in there but let's let
you probably want it to be small
certainly it's constant so if my traffic
to my website goes up and up over you
know make it grows exponentially then in
10 years time I ask this question it
still needs to take two milliseconds
that's a really important thing so let's
try and design a solution to do this so
let's say I've got some log files let's
prep them for fr that work so say I mean
it's an hour seven that means I've got
about seven gigs as long as they and
I've got say one disk storing them on
it's going to take 70 seconds to read
that so if I need to solve this in two
milliseconds I don't have to have all
this in memory and a super fast
you or a lot of disks or something and
yes as my hit rate keeps on going up I
need to have more and more bandwidth for
my desk more memory to answer this
question in a few milliseconds it's not
going to work basically this solution
just is not a real-time solution so
second solution is let's maintain a
counter so every time with its all goes
to our website i increment a counter so
I say I have a counter / country so yes
on UK comes in and that one to know if
I'm strong leader in that one and then
what I want to find out how many people
from France through our just read the
counter I get back an answer maybe I
have to do a dissipative computation but
I can do a distinct in a few
milliseconds so i can i can get the
answer in a few milliseconds and i can I
can satisfy my my constraint for real
time and yet as the traffic goes up my
counter doesn't get bigger so it doesn't
take up more space or very little more
space so it what it works so this is a
this is a real time solution so to sort
of generalize that's a little bit a real
time solution can only read about as
much data as it's going to send its
breeding significantly more then it's
just going to take too long on a scale
nastily with the amount of data so so it
doesn't work so that means you need to
pre-compute some of these answers so
that sounds bad because it means i mean
i don't know what question I want to ask
well if you don't tell if you don't tell
the database anything about the question
you want to ask then you just can't
answer in real time and it's like if you
don't remember to add your index into
oracle then it's going to do a table
scan just a fundamental facts it's got
its got to do that so you any database
you have to tell it something about the
source of queries you want to do and if
you do something outside of that it's
going to be perfectly slow so yes you
need to say something about previously
but not everything you don't say I want
to know the hitch from France in the
last 24 hours maybe you maybe you say I
just want to know the hits from any
country are in any time buckets and then
you could ask Ashley or was it last year
what was it in the last minute so you're
not you're not just maintained that one
number it's in the UN you have multiple
ones you sort of have a have a sort of
pattern for your queries maybe you would
do so it's not it's not a disaster but
you do need to know something um so
you're storing your your data how you're
going to read it not having the right it
that's the sort of shift from like
traditional databases to to to real-time
things ah ok so the form you want to to
solution just want to clarify a point
that people get look a little view
confusion back to this there's sort of
two times here one is how long does it
take me to get the answer and one is how
old is the data that is being queried so
I so so maybe with those stock prices I
want to get the value now quickly you
see there's two times there or maybe you
you want to get historical data maybe
you want to say what was the price 24
hours ago you still want to get the
answer that quickly but it's old data so
there's these two different times here
and then people say real time they
generally mean both but it's not
necessarily the case so if it's if it's
historical data for example you could
you can pre-compute these answers you
know you could you could run a Hadoop
draw every night to give you the answers
to these things and then and then you
sort of query this summary which is
there you that you could do that if you
if you only want to Reno later but in
general if you're if getting a quick
response to a question is valuable then
then the value probably decays over time
so you probably want to you probably
have some value in getting our answers
about the current data as well so i'm
going to assume both aspects of the real
time here
valuable current data and getting a
quick response for current and
historical news okay so what are some
solutions to this you know we saw one
solution the counters but let's let's
talk a little bit more generally like
that because there's other sort of
questions that we want to ask so the
fundamental thing I've constraint i said
is that you don't want to read more data
than you have to do to get the eyes so
here's his three things that you want to
make sure you do so denormalization that
basically means store the data in the
order that you're going to read it
organization of data yet make sure your
data is organized indexed in the right
way so that you don't have to get to a
table scan or whatever and use counters
so we saw we sorted the counters as an
example there there's other things too
but these are sort of some some well
known techniques so the idea of
denormalization well its most relevant
for spinning disks but it's also rather
than for ssds as well and even even
memory because it's you know even random
access in memory as not as quick as just
doing a big men copy um so let's let's
use disk because that's when it's when
it's most obvious so yeah this can read
say 100 megabytes a second but they can
only do 100 random reads a second so if
you've got your data just split randomly
across the disk you can only read 100
things exactly which means effectively
if you're going to read a little bit of
data you may as well read a megabyte
because it doesn't you've always you
already see to that point so you may as
well wait a megabyte of data
approximately because of the hundred
megabytes 182 second so if you if you
seek to a point on the disk then you
effectively read a megabyte so even if
you're just reading one byte of data you
actually ready to make one so that's
going to violate my my constraint I've
read much more data than i'm going to
send out so seeking is not allowed and
not allowed to see very much sleep one
once or twice but not / thing that we're
going to send out that's not going to be
real
so so you used an organization which
means the things that you want to read
in anyone within one query is stored
next to each other on disk so the in
general that means you have to copy the
data because maybe you want to read in
some other order for a different sort of
query so often yet often you do you do
copy your data but let's not be scared
about popping in it you can you can buy
this like one hundred dollars a terabyte
this cost nothing for capacity but for I
oh you know I'm buying 100 iOS a second
for a hundred dollars and I'm paying a
dollar per hour per second that's quite
a lot so let's err let's try and that
let's do some blocking so a related
thing is what if I guess it's a bit more
general than the demonization is making
sure the data is laid out in the right
using the right index on on a disk are
so yes so you're not doing the random
access so one one aspect of this so
remember one of the queries list of
people might want to do is get a range
of data maybe this is a time range or
like a range of you know all it on
strings or something so a very common
thing you want to do is this range query
you don't know the key exactly that you
want but you know it was in the last you
know it was this time range between you
know 24 hours ago in today so let's do
this range query great okay let's get
the keys from E to I but then when
someone doesn't update we have these
extra keys the red ones are going to be
keys that have been added so we have
some new keys well if you just stick
them on the top then they're not stored
in order anymore i'm now going to have
to seek around to read it ah so that's
that's going to violate my dream
straight it's not going to a real time
so i have to have a method of getting
from the left to the right i have to
maintain this order thing in a way that
doesn't involve seeking when i insert
stop what i could do is you know insert
g oldest let's find out where it is
let's put it there but that's going to
involve a seat on the right as well
that's not that's not allowed so how are
we how do we get from there to there so
I'm going to tell you later on how /
Sondra solves that problem very well and
yet the final thing is catalyst between
which we've seen so yeah if you're if
the query that you're asking is counting
something then yes just maintain a
counter so we want some something in our
database that we can increment and
decrement and we're going to have
multiple counters for those are
different things ok so these techniques
let's talk about Cassandra little bit so
I'm sort of going to introduce features
of Cassandra as we need them to say how
it solves these are these problems so
are the three three features right away
are it's right optimized what that
really means is it's super fast to
rights and the same speed as any other
database for reads the reads are tiny
bit slower in some cases but you
wouldn't notice it so so basically super
fast writes very cool breeze um and yet
does this this fast emerging so if you
when you insert your keys they end up in
order pretty quickly we're not very much
I oh and cassandra has a distribution
counter support I guess the distribution
that means you can scale properly but
about skating here but assuming that
most people want to scale their database
again so the saga has distributed
capsules as well so the right
optimization in in Cassandra is because
all the rights are sequential so you
write whatever you want in any order
they end up in order on disk without any
seeks so it's not magic um but it does
involve writing things multiple times so
the the thing that you're trying to do
is get it slide I had before you've got
some keys and you want to insert the
middle how do you get from left to right
so let's talk about some of the data
structures in cassano to see how this
works so basically you insert some data
in fact we've got memory disk we've got
two different storage which have very
different properties can do random stuff
memory and you switch and stuff on disk
so let's use those properties to do what
we want so we've got some data on disk
that's that's happy that's classified
bit and then we get some rights so we
get these two keys Jean cube let's put
the memory there is a commit log in
Cassandra that just writes them out in
case because if we lost power now that
we lose those two values but there's a
commit log to make sure that doesn't
happen it can it can then replay it but
you don't want to be reading from that
because they're not storing order there
so don't worry about losing data if the
power goes off
arm okay so we've got we've got those
two let's inserts more so in this case
when we get six keys we stay right six
is too big I'm not going to store that
in the memory anymore I'm going to flush
that out to this so I've created this
sorted listed memory and then I write it
out to disk so now everything I've got
on disk is still in order but now I've
got two files here rather than rather
than one so if I kept on doing this then
it would just carry on building up with
these files that's still no good
something and after it was secret file
which is still still not allowed so I
actually didn't need to merge these
together so there's this process of
merging also those compaction in
Cassandra that does that so so so these
two things are then version 2 1 in the
background so you only ever end up with
a few these files on disk so so yes
notes that the keys were written well
like these keys were written twice to
disk rather than rather than once that's
okay it doesn't matter too much because
they're all written sequentially you
know we're doing this merging like 100
megabytes a second doing you know the
million keys a second or something in
this merging is really fast so if we
write it out a few times it really
doesn't matter but what this gives us is
every bit of i/o for writing is
sequential great and the reeds well I've
got this sorted thing I just go and find
it in here or I can do my range query
there's no seeking in there's a like 12
seat / read as well so everything's
great this this means i can solve why
for my queries like get me something or
get me a range of something very quickly
and in real time so how fast can we
actually do this well I assert some
stuff and you can certainly 50,000
Keesey site pretty good and this is this
is another this is why I'm Saunders
great for doing denormalization because
you get your one insert that goes to 10
or something and then because
can do fish thousand things a second
well ok you know maybe I've got ten
things whatever we have a certain
question obviously what was the Kip you
think that on yeah it's going to say
what kind of hardware would you do ah
this is a a call box 24 weeks around
eight disks costs about 2,000 pounds or
something nothing this wouldn't this
wouldn't carry on for forever I mean
obviously it's going to drop off a bus
yeah I mean that the moment is just
sharing like the CPU costume for
processing the inserts a new a 50
deficit that's just Cassandra a box no
chili ok so those those are the sort of
data storage requirements that we have
from real time and cassandra has it has
pretty good properties there are there's
a few other requirements which I think
are also important are so so just a sort
of drove thought here so we're doing
real-time analytics that means we've
said we've got high value in getting a
quick response if we get a slow response
then you know it's going to cost us
something we said we wanted to fast so
that means if the service is unavailable
we're losing money we're not we're not
doing our quick queries anymore it's
going to it's effectively like it's
going to take and how to do the query if
it takes or now to bring the server's
back up so there's a high cost of the
service being down so we need a high
availability so it gives you high
availability with replication
multiplicity and support
and all that stuff so so yeah I think
there's no point in building a real time
system that doesn't have high bail
ability on a related thing is again we
want to quick response which means we
need low latency and in particular a lot
of people are building application and
queried worldwide so Sandra has multi
dates and support so so that the data is
going to get replicated around your wall
state your datacenter so you can have
one in Australia one in Hong Kong
one-and-done than or whatever close
enough to people so that they don't have
to go you know halfway around the world
to get to get the answer so I think yeah
I think having having that home data
geographically close is important for
some application indeed and there are
people who use Cassandra just for this
feature just so that they can easily
replicate data around blow to get to get
low latency um so um I guess how is
Cassandra achieve these things so so
there's no single point failure in
Sandra hasn't that's necessary for high
availability are you can sort of fairly
unique feature with Cassandra that I
think is pretty useful is you can choose
your point on the consistency and an
availability curve you don't you can
trade off your assistance II prefer
available as if you want so a lot of
these analytics that people do actually
it doesn't matter if it's not quite
right you know if I ask if I know that
there's a million approximately a
million visitors from France and it was
like 900,000 last month that's all I
care about out of character is like a
million children 87,000 whatever so if
the if the value is not quite consistent
I probably don't care but if I can't get
the answer it says arntz not available
then I'm very unhappy so so for a lot of
analytics I think people have prepared
to trade off some consistency for higher
availability but for all the things you
can't but the great thing about
Cassandra's you can choose that with
each query you know if I want to get
this value and I want to make
sure it's the latest value that I can
say make sure you read from all of the
replicas but then if a note it down
obviously I'm gonna troll oh yeah the
more sense was it um so a little bit
more about low latency so you have the
the multi-day send support gives you
gives you low latency but then there's
the other things with the caches so you
can you can say oh I want this
particular bit of data to be stored in
cash preferentially over something else
to decrease the latency there and you
can you can do your reason parallel
across disks and whatever are the bulb
right application okay so that's sign of
stuff let's talk a bit about writing our
action how do you write these
applications in Cassandra so I think
actually this is the weakest part of
cassandra is actually writing something
on top of it the the interface the
client interface to Cassandra isn't
great so it used to be really bad this
thrift interface that was very hard to
program against then someone wrote some
client libraries made a bit easier but
it still is still a bit painful and
foreign now there's cql cassandra query
language which again is better but you
still have to write quite a lot of code
to get things working and in general
your code is quite ties to your data
model so if you if you decide to change
how your data's a bit you've got to
change code which is is a little bit
painful so so it will be be nice not to
do that so I'm going to be a little tiny
little bit about what hakuna does to
solve this arm so hakuna bring something
for latino analytics that sits on top of
cassandra which we hope bites a good
programmer interface to sign if you're
doing these sort of real-time queries
are so it's a it's a restful HTTP
interface you post jason events to it
and you post to do some queries and you
get back answers so the sort of code you
need to write is is pretty
not existent to do those things so what
it does is you get you get events coming
in and you you feed them into kinetics
which then works out what it needs to do
to be able to answer your questions so
you tell it a little bit about what you
want to do so I want to answer get
number of counts per country or
something or or here I'm I'm worried
about those times and I've got I've got
I want to know how many people access
certain pages so you say something like
this you say these are the sort of
queries I want to answer in real time
and then when an event comes in the kuna
magnetics works out which things need
updating to maintain this query so so
you don't have to write this code so i
think read this counter that scene where
the farms calculating around the 2012
counter let's increment this one because
it's not that hard to do that stuff but
it's very fiddly to pass the dates and
the moment to get the time zone to
correcting and not get off by ones and
whatever so this this does it does it
for you arm so yeah what sort of stuff
does it do um yeah in current analytics
the work is done on the ingest which I
said it's what you need to do is do
real-time um sort of stuff that does he
has some counts sting stuff average
stuff for his statistics and deviations
min and Max are some of these things you
can do approximately as well so if you
want to know the number of unique
visitors to your website to do that
exactly you actually have to store all
the visitors you need to know if they're
unique or not um so you can't actually
do that sort of query in real time but
you can do it approximately in real time
where maybe the answer you're going to
get is a little bit wrong on but you
probably don't care so so yeah there's
some approximation stuff there to
actually make this stuff real time um
yeah you can do grouping
stuff so that it's a little bit more
powerful just getting a single number
out you can get by groups per country or
whatever and yeah this was on top of
Apache Cassandra so come to the end what
have I said are so I told you what I
think real-time means our and work towns
what that means the storing data we
don't have a choice about how we store
this data if we want it in real time so
yeah what must we do how much we store
our data arm so then why how does
Cassandra give us those properties the
superfast rice the merging the counters
high availability low latency to sondra
pretty good choice if you want if you
want a little time and then yeah told
you about going back to around six there
we go thank you please ask any question
yes yep talked about the right button
there is into memory before eventually
flushing to this yes and there's also a
situation you said where there's a lot
father's willing to allow you to replay
those events back into around if no goes
down for enemies yes how often are those
beds rip to the log and if they're
written often enough why couldn't you
just wash them straight to death right
what's the balance between those two so
the default is to write it every 10
seconds I obviously yeah if you wrote it
after everyone then you're essentially
writing it indicated so yeah the default
is every 10 seconds leave the sort of
rationale behind is and you've got some
replicas as well so within 10 seconds of
writing it to lose it you've got to lose
power to all of the replicas I see so
when it writes to random on one note is
it distributing that right across to the
replicas to disk and it knows to flush
those two discs
no it's in it's in RAM on all of them
but it's also in the law on all of them
and then the log gets flushed every 10
seconds on ya so if you're going to lose
it then you have to lose power to all of
the replicas within ten seconds of
Ingrid so you know if you've got it all
in one data center and you just make a
right then you can lose it but you can't
do anything about that unless you're
going to seek on every single right yeah
so you can't you can't make you do that
if you want but most people don't lat 43
bitch yep you know sorry have a question
I forgot to ask you about your your
benchmark was how big were the rights
that you were doing 50,000 per second
they were like I can't remember for
their but they were small order of like
you like no like 10 bytes per value or
something probably like 10 by keys 10 x
factor's up says it's peaceful but we
just kind of a single event type things
yeah yeah and if you are doing counters
in the way you talk you subsequently
talked about it encounters then those
would be multiple then we further rights
you'll be doing so yeah I'd like two
encounters so counters the rights are
the same but the problem is the
replication of the counter so so when I
want to increment a counter I just write
that increment so it's just one right
but then the way that's replicated
around is actually to make sure they
can't stay cement stay consistent
exactly not exactly so so four counts
unfortunate enough to read them to
replicate them around so if the counter
in cash it's not so bad if they're on
disk then yeah you have to do some seats
but in general you're incrementing more
recent counters so remote so emotional
increment cash that's an unfortunate
property of Cassandra countin
replication right and have you guarantee
a consistency of the counter with
current writers
so it's reasonably complicated but the
summary is when you there's actually a
counter / replica so you talk to one of
the replicas and then you increment that
one and that that that knows knows that
you know those that this that incurring
him there's another one going on over
here but these are treated separately
and then and then when you read they're
actually sums together are so so that's
that's how you can you can avoid any
sort of distribution locking because
it's done like replica okay with that
that means you can only do one right to
that node one counter aren't they to
that node at the time you could do
another counter update to another note
but if you do them to the same note how
do you guarantee um so ah let me
remember how that works basically it's I
mean you could do it by doing a lock on
that load but it doesn't work like that
it stores its store seeing the
increments and then merges them down to
two just two just the one value yes is
it very point in this log structure if
you were all on some state this if
you're on solid state disks yes there is
still a point to it because you know
your your your your block size on a sort
of say this is a like 4k or something so
you store don't want to be seeking
around too much a new you install you
can still do get more megabytes per
second doing sequential reads on the
nessus thing that you can do random
fries so there's still a benefit but
obviously much much less so yeah so so
Cassandra was designed to run on spin
with this that's for sure but it still
worked it's still benefits on
but not not so much you have any tabs or
even teared so I'm guessing well with
Ram solid state is it in between buffer
and then writing this so our song does
now you support for that I guess you
could you can fairly easily do it we're
more recent stuff would be on the SSD
and all the stuff and beyond on disk you
could do that point is if you want
anything more complicated here like most
more of an access stuff then that would
be reasonably hard what you can do
though is say certain bits of data
should be on an SSD in certain bitch
beyond on a lot of disk so you can say I
really care about these counts but they
don't care about this historical data
here you can do that
more questions
okay thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>