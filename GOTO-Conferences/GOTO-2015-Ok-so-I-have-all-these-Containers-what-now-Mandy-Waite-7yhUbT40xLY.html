<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2015 • Ok, so I have all these Containers, what now? • Mandy Waite | Coder Coacher - Coaching Coders</title><meta content="GOTO 2015 • Ok, so I have all these Containers, what now? • Mandy Waite - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2015 • Ok, so I have all these Containers, what now? • Mandy Waite</b></h2><h5 class="post__date">2016-01-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7yhUbT40xLY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so right thank you thank you so much for
coming to my talk having your attention
it is an honor absolute honor and I
really appreciate you taking the time
out of your day to listen to me prattle
on about containers how many of you have
too many containers no probably not all
of you but many of you will eventually
because believe me this is the thing
that's going to sweep everything away
and change the game for all of us so one
day you will all have too many
containers if you don't have today so
once you do have lots of containers what
do you do and really it doesn't have to
be having lots of containers today this
kind of stuff we're going to talk about
is applicable anyway and feel free to
use the tool to ask questions you can
also tweet me about anything you like
bright to date I have to run off because
of tricking them I lived that way and
apparently is going to be an absolute
disaster this afternoon so I'm gonna run
off by about two o'clock but i'll be
there for lunch if you want to chat talk
about cube negatives or Google cloud or
anything else not android though I've
been working late away feel free I'll be
there so yeah to meet questions anything
hashtag go to London so please tweet
about the event and make it successful
because this is a really cool event and
we should promote it as much as possible
so what's this and I'm learning Japanese
so I did this talk in Tokyo recently
quad a1 and Oscar and it's pretty much
like insane talks I'm I know kind of low
Japanese but I'm not regular speaking
yet so I'll keep on trying but what is
this this is a data center a google data
center it seemed Council Bluffs Iowa
wherever that is somewhere in the
Midwest in the US and this is what we
call a cluster of machines and there's
lots of machines and if I left it up for
a long time you might get a count more
on by one but this is what our software
engineers our developers use some run
their stuff so how do they run their
stuff what do they do do they kind of
select a machine in a rack in the data
center and say let's have TP internet
send my binary over
SSH into it stand up my binary maybe do
that many times across a whole number of
machines no they don't that's not gonna
work right just absolutely nowhere they
can do that it's not the best option so
what do they do so what they do is this
they create a configuration file called
a balk config will talk about ball more
shortly configuration file has a name in
this case it's a job it's called hello
world so this is how I world for the
data center and they can say what cell
they want to run in and a cell is a
subdivision of a cluster it's ten
thousand machines say which they
combined their stuffs that is saying I
want to run it on this cell so the cell
is is the targeting on a machine they
can see where their binary is and the
binary would be a statically linked
binary remember those eight they're
coming back they're coming back all of
that dynamic Lincoln is going to go away
so starting the links and it includes
the web server in this case this is
hello world it has its web server
embedded in it it carries it around with
it so we can just move this around and
run anywhere we don't have to worry
about what's on the machine it will just
run ultimately a run inside a container
we have very lightweight containers at
Google and we've been using them for a
long time and that's one of the reasons
why we worked with linux to implant see
groups and namespaces which we're not
going to talk about too much today but
i'm happy to answer questions and so
this is the binary we had that arguments
as well this is a web server we need a
port requirements resource requirements
this is interesting okay how much ram
does it need what do we think it needs
oh it's disk does it need how much CPU
does it need point one of a cpu that's
pretty good and we can also say how many
copies of it we want to run 2.5 maybe
although this is google scale so maybe
10,000 10,000 is pretty good right so
there's one temp out in li things
amazing engineer at working at Google I
could do this I don't need any special
privileges I can go off and run this
thing and nobody will complain you're
being the same please doing running
Sinbad's in our world because that's
fine apparently so that's what we do
it's all decorative we create de binary
obviously we have
old system the build system is now
available external II called basil on
the github so you want access valve
distributed parallel build system that's
available as well and why am I telling
the audience I'll tell you why I'm
telling you always win it the developer
you of this so after two minutes 40
seconds we ramped up and we do ramp up
we don't try to start more at once which
doesn't make sense that you know the
binary is 50 megabytes inside so we have
like two gigabits per second a dated
move around lots of caching going on but
we have to wrap this up reasonably
slowly so that's all part of the system
ramp up two minutes 40 seconds we have
10,000 of these or so maybe not quite
10,000 I don't go I'm going to go into
details of that but there's another talk
online where I do and there's various
reasons why we may not reach 10,000 but
that's because of the sheer number we're
running say but I can tell more right
out as well if you need to know more so
what just happened this is a typical
cell d what the cell looks like Borg is
our schedule is our cluster scheduler it
scheduled our containers for us so this
is the thing that replaces the guy
having to SFTP into a machine and stand
up a binary or girl should say and what
we have here is a bald master this is
the finger controls everything in the
cell and it's highly replicated it's
very resilient five copies and we have
lots of machines down here these are the
nodes or the machines in Iraq do you saw
earlier right cities will run in a thing
called a bullet so what happens is this
the developer compiles the binary it
gets pushed out to some centralized
store for to sell cell level storage and
then they create the configuration file
and they run a command bulk CFG on the
client line and push that configuration
file out to double master this goes into
a persistent store this is
practice-based consensus-based and with
these impacts of em got call them raft
yet i'm not going to get into kind of
religious debate about that either
though and then we have now a state of
the system this is what it
is currently and is what we want it to
be so we've just now said we want 10,000
of these and the scheduler comes along
and says what's the state of the system
compared against the state of what it
should be oh I should have to empower
these women they're not running I was
fix that so it goes off and fixes it it
creates a plan then it talks for each of
the machines its chosen to run this job
and says please run this for me the
machine will go and get the binary from
storage and it will run that and then
ultimately we have that we have lots of
hello worlds right okay so why is that
relevant because basically kuba natives
which is what we're talking about today
is our attempts to give everybody that
kind of thing allow everybody to do
exactly what we do will be totally
within Google because this is the way
we're going to do these things in the
future this is the way it's going to be
things will change those machines that
you have before they're going to go away
you know we're going to have clusters of
machines and we're going to be running
cluster schedulers things that will
intelligently run our stuff for us
somewhere it somewhere we don't know
where well it's not exactly it's a bit
like Heisenberg's uncertainty principle
we know how big it is but we tell me
where it is and so we're going to use a
typical application base very typical
lampe lampeter deserve such a visa lampe
stack so it's a lamp EMP stag that has
PHP many PHP front ends and mysql which
will cover lately later how do we do
this with classical without containers
traditional memcache and we have a
client consuming or clients consuming
those services exposed by the PHP
application and by the way I'm side
introducing me I'm Mandy Waite and the
developer advocate I know we have a side
left out I'm a developer advocate for
google and i work on cloud exclusively
if you want me to talk to me oh go to
London slipped off go to London should
be on all my slide a punk side Nicki g
OT o LD n hash ashtag so you can get me
on at tech girl if you want to talk
about Cuban eight is generally hash
queue Benitez okay so I talked about
contains how many of you are familiar
with containers
docker specifically how many of you have
spun up your own container actually
crazy container many of you okay I'm
going to run free us very quickly just
for the benefit of people who aren't as
familiar but I won't spend too much time
and what containers are seriously the
old way we used to do things we have a
machine next to our desk and it moved
into a server room we probably had a
name for it we could probably log into
grande by machines name is called grunt
and if anybody knows what the references
please let me know because Lord of rings
so shared machines we would run
everything on the machine stand up the
machine money stuff and the green app
the green application in this case may
be are really important business
critical application and the red one may
be something really silly and the red
one may one day go completely mad and
consume all of our CPU and all of our
memory and take the Machine and take
down our production machine production
services completely no isolation we
can't go and see that one application
won't break another there's no namespace
in they all have exactly the same view
of what the system looks like there are
no common libraries what sorry that's
not what I'm interesting there are
common libraries these libraries are
shared so with dynamic link in pretty
good works pretty well but sometimes you
may find you may update an application
will install a new one and something
changes your libraries and may break
something for something else that has a
specific dependency on a library doesn't
have them very often if it's
well-written it shouldn't have them it
does happen occasionally and ultimately
the applications are highly coupled to
your prating system so then we have
virtual machines we have basically now
introduced a hypervisor a layer of
idealized hardware on top of the actual
hardware so it looks like hardware it's
not really hardware but two operating
systems running on that system it looks
like a piece of hardware idealized
hardware hypervisor now we can run
individual virtual machines for every
single app if you wanted to so we could
have one machine 40 readout one machine
put a green app and they won't
impact each other now when something
breaks there's some possibility that it
could happen but very unlikely but if
anybody's had to manage a large number
of virtual machines you know that that's
quite difficult as well you had to
actually install these things configure
them I just like you would any kind of
normal machine also the application is
still highly coupled to the guest OS and
this whole setup scenario can be hard to
manage the new ways containers and now
we move up the stack we take this ideal
it idealized piece of hardware we move
up a level and now we have an idealized
operating system on which we can run
things and those things we run our
containers often docker containers in
the future there will be standards
around containers we will have many
different container formats but
hopefully there will be a open container
initiative standard container format
that they will all comply to they will
add value doctor will add value core OS
will add value of rocket etc and so
containers are the new thing and they're
great why does this quickly mention this
as well because we know about volumes
shortly containers docker containers
specifically are created from images and
the images are built up in layers so we
have read read only layers upon layer
upon layer and we have a read/write
layer at the top which is our
application so that's how it's all built
up in this case we have Debian we have
libraries we have PHP and apache then we
have our application code sitting on top
of it and this is all copy and right at
the top layer so the whole process will
be to build an image push it to a
repository and this could be hub calm
more hubs or iOS it's called now and it
could also be some private repository
something that's specific to you then
you'll pull it back to the execution
house which could be different for the
machine you built it on then your start
the container from the image that's how
the whole process works and images have
layers as I said I'm not going to go
into too much detail I was going to but
I'm kind of worried about the time so
let's move on and ultimately we can
mount a host our x-ray as well this is
important when we get to databases
shortly so it's important it's possible
to mount a host territory into the
containers file system it's view of its
own party
and these are completely mutable they
don't outlive the container and are only
available on one specific case on the
actual hosting Mountain one you can move
them around and they can mount a
different directory maybe the same path
but it will actually be a different
directory so there's a possibility that
the state of one container run on one
machine may be different from the state
of a container one on another important
note then we have a doctor example so
docker is the canonical container format
that everybody's using and it's pretty
impressive name I saw some hikes talk
two years ago at scale in Paris and it
was extremely impressive the way he
compared it so shipping containers so if
you've heard that analogy it works so
well and here so we have some containers
we have application code one on top of
PHP and apache we have memcache d and we
have mysql for the PHP and apache
memcache case we have those layers some
of those layers are common in this case
the library the lower level libraries
are common between both but I also have
their own libraries and mysql is
completely separate it has it always own
dependencies beneath that we have some
more freedom system and we have server
and server a server which could be a
bare-metal server it could be a virtual
machine it could be your laptop it could
be pretty much anything you can run
docker on and the doctor engine is the
runtime effectivity for containers and
it's the thing that manages running the
containers and also manages the
processes of creating them the docker
command pretty much less all things and
that's kind of crazy so why containers
where I gave it is quite a lot but
basically containers awesome so just
let's use lots of them right that's the
best thing to say we can go back to that
but you know this probably okay it's a
performance they're quick to create once
you pull down an image in cash it
locally they're very quick to spin up
they offer repeatability so whenever you
create an image you can pretty much
guaranteed every time you run the image
it will be the same quality of service
you have resource isolation you can
allocate resources like we saw the
Google engineer earlier she would
allocate X amount of memory X amount of
cpu or would at least request that
because so we can specify quality of
service for these things when they're
running accounting is very easy these
things are small easy to spin up and
easy to manage and easy to track
portability is probably the most
important part you can move these things
from one machine to another from a
laptop from a testing server to see a
production server so all away from dev
to protests abroad and that's a very
important use case for docker containers
today but one day everything will be in
the container believe me really and
everybody google knows obviously not
contain with it yeah i'll put chrome
into a container yeah because then stop
it from eating all my memory which is
pretty cool I love Chrome this is a
fundamentally different way of managing
applications and it's going to change
your life and I've said it some people
many times now that in a couple years
time I'll talk somewhere if I'm still
able to and your say to me Mandy you
told me about Cuban agency years ago and
you were right it's changed my life
everything's different and no longer
have a job no no you might say that
hopefully you'll say I do have a job
because man who told me back who this is
really early on and I got on the
bandwagon really quickly so it seems
awesome that she was lots of them demo a
demo I was going to do a demo we'll get
her down and yeah ok so I'm cheating
because i'm using my history but my
typing is absolutely appalling and it
would take me like half an hour just
right it's one command so what we're
going to do here is use a command called
tube cottle and this is going to allow
us to actually deploy a container to
cube natives and we'll talk more about
cooking this is shortly we're going to
use a docker image as the doctor images
here memcache d version 1.4 when you
specify ports and we can specify some
labels and we talk about labels shortly
and i have here if it's still running
which is not stopped internal server
error no we have a proxy basically with
a web UI that is talking to the cube
natives api and not resizing window
which is kind of weird ok
like them and if I run this now we
should see a container so this of
memcache yellow currently which means
it's pinned in and it has what we call a
replication controller we talk about
these more shortly one day I'm going to
get rid of all my slides and I'm just
going to use this to go from my entire
talk not quite there yet with it so we
have a container which is a great one
and we had this thing called a
replication controller and we could
potentially and I have to make this
command up as I go expose that as a
service and we're going to getness or
services as well shortly but we can do
this and that will create a service for
us and effectively allow us to access
memcache the through this shim layer
called a service and we'll talk about
that more shortly but now we have a
whole configuration we have an endpoint
of an IP address we have memcache
running and we have something to
actually manage our memcache processes
so let's go on delete that because I
know it's going to break later if I
don't so I'm going to do you bottle it
RC cool memcache some surprising and
tube Cottle's RC memcache d i keeps
dropping the d at the end right so they
should be gone now and oh the service
isn't gone what isn't
and that's also called memcache d well
services I always forget that seems
logical just the same delete memcache d
right okay I did that today probly a bit
mysterious let's talk about Cuba natives
and let's do some live editing of slides
it should you should really create your
slide while you're giving your talk I
mean that's really the best way forward
it's just so much more interested in in
a way right and the Wi-Fi is working
great isn't it it's really cool we don't
notice it we don't say when it's working
great we go to conferences it never
works and we swear and we tweet and we
say horrible things were only works
brilliantly we notice anything that's
working brilliantly so to Pilatus how
many of you have heard accumulators okay
right I mean if you actually want to
know more about it well just probably
know so much about it that we don't care
anymore all right so to blazes is
something that some open source project
basically that we launched last year and
which is open to everybody and there's
lots of contributors and committers from
all over the place Microsoft from amazon
from core OS mesosphere from Red Hat
everybody's contributes into this thing
so it's not just Google it's a real or
not we're not like a single contributor
kind of model for an open source project
and the word itself how many of you know
how to say tenacious because I'm quite
happy to stand outside late and help you
say it probably it's harder to do with
other people Japanese have real plant
dis really easy because it's made of
Japanese and syllables so good mateys is
effectively a orchestrator or a schedule
of a docker containers and it supports
multiple cloud environments you'll run
on amazon everyone's on microsoft azure
it runs and Google Cloud wins until
mesosphere Red Hat use it for open shift
and there's many many different use
cases and there's a lots of new stuff
coming along in the pipeline you're
going to be quite amazed how many people
are going to be using cube native this
is inspired me informed by everything we
saw earlier what about stuff i showed
you earlier actually you had a point is
basically we've learned for our ball
scheduler how to build a cluster
scheduler or a container scheduler and
we think canate is ultimately going to
be better than what we built with balk
because we have technical debt everybody
has technical debt and there are things
we would change about Borg if we could
go back in time but we can't be changed
now so now we can sub introducing cube
Nexus and while it doesn't do everything
the Borg does today it will do
eventually it's open source Brittany go
and it's basically there for managing
applications not machines forget about
machines we don't care about machines
anymore concepts we're going to go
through these one by one but we have
containers pod services volumes nodes
replication controllers and labels well
there's a lot that's quite sad really
but we'll try to do our best to explain
them so a developer view cube natives
this is what we saw with a ball girlier
it's very similar these are the same
colors at least and we have a clue
benitez master true belief master is
there to schedule our containers for us
it has a scheduler component he has this
thing called a replication controller it
has an API the api's brilliant that's
what we're using the 4d visualization
the API is used by all the external
tools thing called couplet order kumar
me ran the proxy that we're using to do
the web UI your application we use this
as well we have a cube user interface
which shows you the utilization of your
nodes and your cluster where your pods
are running which is connected via web
browsers and we have nodes nodes very
similar they don't run bullets they run
cubelets and we also have a thing called
to contain the registry so this is like
our cluster our levels so level storage
this is where we push images to and we
could push into docker we could push
into I'm private container registry in
the cloud and we have the ability to run
this stuff cube natives on a laptop
using VirtualBox we can build a highly
available multi-node multi-node cluster
it can be hosted so we provide a hosted
version illuminators called google
compute competing google container
engine or you can manage it yourself it
could be running on your own print
on-premise services services are your
own premises over you'll have like 100
servers lying around doing nothing
because you moved up into the cloud you
give just one clue bladers on it it's
been really really good use for them now
you can write in the cloud on bare met
virtual machines and there's many many
different options and you can see those
options in the matrix there so if
anybody doesn't have time to get a link
I'm happy to point you to it later so
what do we run on the nodes containers
that's when you should have done the
demo now so that demo I did earlier was
this demo here but I added out on the
train this morning so pods this talk
about pods so what we saw earlier we ran
a container we said this is AG image I
want you to run a container for me what
it actually did was create a pod a pod
is a the atom of scheduling for
containers on proven a tease so when we
scheduled early think it will be in a
pod and we could have a container in a
pod one container or we could have two
containers in a pod like peas in the pod
or we have more to where it makes sense
to Andy I think of these pods has been
like logical heights when you used to
install a machine with Apache or maybe
with a CMS so nice a natural Jekyll when
it makes sense to run them side by side
then that makes sense to run them in a
pod where they live and die together
where one does it make sense without the
other so when you can pull the plug in
this one it goes away you haven't got
some container there's no longer do
anything running the way it makes sense
the run them together you put them in
the pod these are ephemeral they can die
and it can be replaced so no state they
don't insane state they can say simply
state but they shouldn't contain
important state business critical state
and we've already seen that a single
container pod can be created directly
from the container image and so here's
an example of how we would couple them
together how we'd have a logical host
running and no Jace application and also
slightly synchronizers would get so this
is a typical push to deploy scenario
where your developers will push
something out to get maybe it's a github
and you have something running the
container that's saying I'm looking at
this git repository or this github
repository and whenever I see any
changes i'm going to pull those changes
down store them on a volume within the
pod we talk about volume shortly and an
oj s application will now pick up those
changes and start serving no change
there's push to deploy effectively
deploy your changes to get and they
automatically get deployed to your
running application so that continuous
deployment almost insane is are tightly
coupled they live and die together and
they have a shared network IP imports
namespace local houses the same to them
so they can talk to each other on ports
it looks like they're one knowledgeable
host effectively so think in terms of
services that you would usually run on
the same machine and if you have any
questions about pods let me know I used
to have more slides but I've cut back on
them because too many pod slides bad so
we talked about volumes we have
different kinds of volumes and these
allow effectively individual containers
to write data they like to write to file
systems or for multiple containers to
share data between them and in this case
we have two containers the symbol it the
giro is a pod symbol and a volume and
what they're actually backed by this
volume is backed by as determined by the
volume type the first one is empty
directory and this is basically backed
by a position storage on the disk but
only temporarily effectively so it lives
Wilder pods alive and goes away when the
pod goes away so this is for pods
showing data temporary data between them
it doesn't persist after the pod goes
away so empty dirt is useful for having
that kind of transient data don't really
care about second one is mapping to a
host path you can map to a directory on
the system a node in which the pod is
running and that's quite you saw but
again it's a little bit dangerous
because what it's mapping to maybe
different one machine and it's on the
other may have different data make
different conditions probably not but
it's an important consideration and the
next one is volume and the volume up on
NFS volume or just or FS we can mount
that and also we can do cloud provider
block storage so for Google we have
google positioned disk and amazon has
AWS box storage labels labels it a
single grouping mechanism of include
natives in this case we have type equals
fe so this is arbitrary metadata that's
important to you but not to cuba natives
so key value pair side pickles fa the
label and you can build dashboard
applications that
select on the label give me all the pods
nameless give me order of replication
controllers with this label and you can
build your own dashboards oh you can
build another dashboard that looks at a
different label so this case we had to
dashboards two different labels each
one's looking at if enabled so you can
build your own tooling around this and
then there's a developer view which is
going to run through very quickly which
is very similar to what we saw before
because especially by resource limits in
terms of CPU in terms of memory
container mappings and how many copies
we want so in this case we want 10,000
replicas 10,000 those pods running
replication controllers are there
basically to keep keep the pods up and
running so basically we have this notion
of desired state we say we want to have
two of these containers running or
chilis pods running which could be
multiple containers and here's my
template for building new pods it could
have two different containers
definitions free one but this is the
template you're going to use to create
new ones and so we create a replication
controller and say you're interested in
pods with version equals v1 if any are
exist it will pick them up if any don't
exist it will create them up to the
number it's been told to have in this
case pods equals two so we'll have two
pods vs equals v1 being arbitrary
metadata and we can have another
replication controller we have version
equals V 2 in this case one pod and it
will make sure there's always one pot in
that case and so this is just an example
of a control loop it will continuously
check to make sure that the desired
state is what we have you know this is
what the actual state is what want it to
be and it will fix it it has too many
running take time away there's not
enough yeah it's insane like this we can
do health check in there some basics I'm
not going to talk about this the zombie
is really cool they're not green in the
walking dead though are they maybe there
will be one day nightly season 10
whoever services services are the things
that sit in front of pods and
effectively aggregate them as something
that can be consumed by clients so the
bottom here we have free identical pods
they would always have the same label
and we talked about that shortly when we
create a service we create something
that has a virtual IP address and a dns
name
and clients can attach that they can be
internal clients or like me external
clients and effectively what the service
will do will load balance requests
randomly across each one of the pods it
has session of in DC client IP affinity
so there's a session in progress it can
go back to the same pod Babel load
balance randomly across world APOD and a
constituency of a service oh I delete
the other slide and mind the
constituencies of the services made up
of labels so in this case we had to
replication controllers version equals
v1 but one of them version equals to be
two for the other and each of the pods
also has a type equals fe label and our
service cares about pods with labeled
type equals fe so as a label selector
type equals a feed so all of those pods
belong to that service but notice there
are two different versions of the pod
here so we could roll out a canary here
we could roll out a one pod that's
different from all of the others just to
do some kind of a/b testing so we're
giving you some of our trafficker answer
the new version some that goes a gold
version that has the virtual IP address
and this could be consumed by external
clients or internal so mapping tsukuba X
is like D keeps dropping off down there
no TD this is what it looks like in
terms accumulate is we have pods volumes
services which is the long rectangle
replication control around here and a
client which is exposing has been
exposed as a service border clients in
serve the state I'm glad to run free
disp resided this this morning I didn't
realize wouldn't have enough time so
database everybody asks about database
and I can talk about this later in a
cluster of ephemeral containers the
application state must live outside of
the container right it can't be in the
container so how do we solve them first
point is we can have the database
outside of the cluster so we have all of
our pods when applications in stage
three different applications different
colors and the MySQL ways effectively
managed by a DBA or make some kind of
managed cloud service so that's one
solution the other one is to adapt your
database of running
cluster in this case mysql run as a pod
and it will mount a file system when it
becomes live link when it fires up it
will mount a file system and that will
file system will be provided by the
cluster or we can do cluster native this
is things like a sander or react which
understand how to run in a distributed
system and these things can just have
multiple instances running pods and they
can talk to each other and communicate
with each other and the way networking
works to impose that is very very simple
to do simpler than containers generally
so the real demo and by my shell window
which is now much bigger than it used to
be right or in a different position
you're hiding where are you come here
waukesha window stop it ah come on hey
smoke hello right so let's go back to
our visualization and close the console
so first we're going to do oh those
we're going to do is create a disc so
one thing always in Japanese I'll use
this one one thing we need to do is go
and see the developers console and
create a disc and we're going to go into
Oh compute computing June disks and then
we had to find out what the name of the
disc is and that I will resort to adam
and i will look at my configuration file
from my container on my pod and i know i
have to announce demo mysql disk so i'm
going to create that disk new disk give
it name the name is important this is
going to mount it based on the name i
put it in the right zone in this case
and sorry this is kind of advanced
google cloud stuff so 500 gigabytes
should be enough for our MySQL
effectively and we can create so that's
been created we have a 500 gigabyte disk
in the cloud and that's not actually
nodes currently do will be shortly
so the next thing to do is to go away
from the Japanese stuff because I want
to see that and i will use that to
Cottle command again once f 0 mysql
server and that will create must slip me
a service and a pot the pod is my girl
we have namespace in here we won't talk
about namespacing today it's yellow
currently he's penned in hopefully it's
going to mount the disk and everything
will be okay if not how to recreate it
was I didn't say it wrong but hopefully
I didn't do anything wrong so in the
meantime we'll create more yeah it's
working so it's now running so we have
mysql running very quickly right that's
probably the quickest you ever seen my
scroll up and running right so memcache
memcache the next one say memcache and
this will create a pod and a service
just like before again main spacing
don't care much about and next thing to
do is create a front end and the front
end will be our PHP stuff and this is
going to be a replication controller
remember you mentioned oath we create
that and what we see is a replication
controller which is the blue box here
we've seen them before and two pods two
replicas of our PHP application money
everything is running now but we don't
have a service for a front end we have
to create that so next thing we do is
that and we'll create a service for us
and now we have a service we can plug
that in so now we can see that the fun
things here are talking to memcache d
because they will go to memcache tea
first if it's not in memcache need or
retrieve it from where Joel and stick it
into memcache d so that's all process
the front end needs to be exposed to
clients it has an IP address but that's
a cluster local IP address so things in
the cluster can see it but nothing else
can but there's a special instruction in
the configuration file that allows us to
create a load-balanced endpoint that
will be exposed to clients depend on the
cloud provider so Google Cloud supports
that and others do as well so this case
if you say ty
pickles load balancer it will say oh I
need to create a new Celyn one point so
on if it's run the system it can have
such an endpoint like Google cloud
platform or sure maybe yeah because sure
does well you can have it create a low
balance in point that takes a little
while so let's fall back to the slides
and all that steroid e okay will do
we're going and I'll click on that it
would take me to this the brand new
mysql set up my colleague roberts
actually automated this and i should do
it but we have to one set up to create a
table so we have created tables and a
database with mysql and we can run index
dot HTML and we can see a container camp
oh no it's the wrong one that's no good
right so but secretly we've had our
techies actually create one to
specifically the go to London so but
they haven't rolled it out yet which is
bad a little more so I should be able to
store something now and this is a way
risking them I'm a dunce ain't wrong but
ok so I'll sort it so if you access this
IP address now you'll be able to make
send your messages and no rude ones
please right so that's great we want to
update this my wanting the magic things
about q22 Benitez's we can do a very
quick update so let's do a quick update
and we're going to do a rolling update
and i'll move this up rather than clear
my screen again rolling update we just
say what the name with the fun samesies
SRC one which we can see you go back to
our visualization it's over in a minute
minus f is the file new configuration
file and the update period one second I
better go back to my localhost so I can
see the biz this is the visualization
we're going to do a rolling update i'll
move this down and we can see the magic
happened happen so we have one front-end
controller two pods and we want to
replace those two pods with our new
version of our application and first
thing creates a new front end controller
it creates a new 2.0 pod and then it
will take one of the 1.0 plugs away the
next it will create another 2.0 pod as
if by magic
now we have two 2.0 ports and now it
will take the other one point very pod
away we've completely rolled out our
update so one of our pointing this could
be a hundred pods many more and finally
last thing to do is remove up sorry I
got free in that there's I didn't change
it there's no what free pods because the
configuration file had replicas equals
free and now it removes the old fronting
controller and that's it for now wish to
go to our application and see our
changes fingers crossed exciting yay
awesome right and people are trying to
do we come and look I work for Google
and so you're not going to be other do
it right yeah we don't let that happen
anymore so that's pretty much done we
wrap up now there's some other things
I'd love to show there's more this talk
online as well and I'm changing the talk
every time so make sure that people seen
it before get some new stuff all the
database stuff is no and we're going to
have more in the future and I'm going to
start talking about this slightly
differently more about use cases as
opposed to anything else the
visualization is something like this we
have a proxy on our cluster which we can
connect to the API buyer so the proxy
codes will run on my laptop the open
container initiative was introduced as
con on july twenty first basically
everyone's going to agree on the
container format and I expected this to
get really bad there'd be many container
formats and then somebody would say we
had to have as a standard no BS land and
all come back together but it's happened
earlier than I expected so now we have a
standard so everybody can build
containers that comply with that respect
we can bind any container on communities
information is open source we want your
help you can contribute to this thing go
to KU blazes diodes to see the
documentation go to the github projects
and sign up as a contributor talked
about our people our engineers and they
are seriously on IRC on hash Google dash
containers this is not a wasteland this
is quite a bit of a nightmare in fact
and tweet us on a cuban a desire and
questions hey similes over
arda master components HHA all right
okay good question so two places at one
point zero and it probably went a little
bit early to 1.0 it does not have one
set of question these is that thing that
master thing that we saw earlier is it
highly available and let's talk let's
look at that this thing here is it
highly available because we saw five
copies of that in bulk is it highly a
highly available and the question is no
it's not currently if you want high
availability currently recuperate is you
would have to have multiple clusters or
you can run it on something from a
provider and I'm going to suggest google
cloud platform but you could try others
Google container engine which is our
implementation of Cuban eighties hosts
your master for you so we take it away
from you you build your trust that we
take the master a we look after it we
feed and water it like a puppy and you
have to worry about anymore so we are
responsible for keeping it running and
we have some tricks and stuff we can do
behind the scenes to make sure that is
always running like Gmail and search so
we can pretty much not worried about
your masculine and Google container
engine if you run it on your own
machines you probably should fall back
on multiple clusters currently but this
will change there will be high
availability at some point is that is a
question anybody know moccasins look any
other questions hey oh just left Lebanon
or seal Crescent with Dana's and how
with replication now can those or the
deck each other their siblings ah
alright so do the pods know about each
other no not really that's not a waiter
designed that will create a complicated
at any time then interaction right so
basically things would communicate to
the pod by the service they won't know
which point I talking about these pet
did is a pet versus cattle energy which
I really hate i prefer crops versus
flowers you give your flowers names so
these pods are like crops they don't
care about them
come and go and be replaced by something
that he can be equally identical so they
don't know about each other that we can
probably set some environment very much
to say how many there are passed
information but it starts getting sneaky
you start getting tighter couple in that
way so it's probably best to avoid those
kind of scenarios provision in mysql was
very impressive have you tried to verify
his age of a sec like oracle what do we
do let me think about no no I I one day
I'm pretty sure it will be running on
this kind of trust I mean Sun basically
invented all this stuff so I was
containers when I didn't I'm BS details
as well I use were the Sun as well and
left minori call purchased us which I
had to so I know we don't see what
Oracle or db2 I think didn't even the
requirements for access to file system
the way it does something it will be
extremely difficult to have oracle when
Don kinases but maybe one day any more
questions alrighty so again I'm hoping
that I Justin kind of inspired you to
look at this thing it's probably a
little bit a lot of its are too much to
take in and what kind of thing but you
need to look at in and play with it
tweet me ask me questions find me out
there I'll be drinking tea and exiting
coffee I gave it up there drinking tea
and talking to people and doing stuff
and i'll be leaving to escape the rugby
hordes around two o'clock but i will be
here to answer your questions so thank
you for giving me your time of your day
I really appreciate it and by
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>