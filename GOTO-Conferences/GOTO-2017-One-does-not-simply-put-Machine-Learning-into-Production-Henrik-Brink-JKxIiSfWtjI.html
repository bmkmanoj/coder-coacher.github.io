<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GOTO 2017 • One does not simply put Machine Learning into Production • Henrik Brink | Coder Coacher - Coaching Coders</title><meta content="GOTO 2017 • One does not simply put Machine Learning into Production • Henrik Brink - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GOTO-Conferences/">GOTO Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GOTO 2017 • One does not simply put Machine Learning into Production • Henrik Brink</b></h2><h5 class="post__date">2017-12-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JKxIiSfWtjI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so first of all just want a quick raise
of hands how many here have worked on a
machine learning project okay good
number and how many here would say
they've actually they have a working
machine learning system in production
okay handful okay so it definitely a a
discrepancy between those two so last
question how many here knows about Lord
of the Rings
okay okay everyone's with me so actually
I want to apologize this I think this
meme is taking a bit over in this
presentation but I think this is the
right crowd okay so I just quick a brief
introduction to some some of the
projects that that I've worked on
started in working in astronomy and
physics and starting using machine
learning to to work on some of the
problems that we had there to do to do
research one of the problems that we
that we had was we had these telescopes
looking at the sky every night a big
part of the sky
and you would basically get you know
terabytes of data every night and what
you want to do is you want to see if
something changed because if something
changed that it could get really
interesting so um so you know you qu
couldn't really show all this data to
you know hundreds of graduate students
right you you had to basically figure
out some clever way of doing it and
there's some really heuristic algorithms
that you could use but we build this
machine learning system that could that
could really do this with extreme
precision and we ended up you know being
able to detect things much earlier and
much better than that was possible
previously so another project that I
think is interesting here is you can see
the so 2010 UI here but we had this you
know with supernovas as in the previous
project
you know you had a light curve that was
basically quickly up and then going down
right and with a bunch of other kind of
variable stars you'd have a periodic
light curve and there's a lot of
different versions of those and they're
all correspond to some physical process
in the in the Stars and you want to
basically classify your catalog into
each of these in each of these classes
and so we build a machine learning
system to do that but because there's so
many classes you'd have a lot of them
that had very few examples and you'd
have to think about you know how would
you actually go about and and build a
model that was good on all of the
classes so we started building
algorithms that could ask the model hey
model what what what should we actually
try to investigate for you to become
better and so the model would return
some places in the space of variable
stars that we should actually look at
and so whenever we saw any of those we
would present it in this interface to
expert astronomers that would then gonna
help the model and it improved much more
rapidly than it could have done
otherwise so that's that's a process
known as active learning and it's
starting to become interesting again now
and what then happened was we decided to
start a company we've gotten some
interest from from industry even though
we were working in in in academia and
what does any group of nerds want to do
they they want to build you know a
system that can handle everything and so
we're gonna build a machine learning as
a service and you could just put in your
data and you get answers and that turns
out to be hard and there's I don't think
anyone has solved this yet I think some
of the big players have some good
services now but but in 2012 there was
definitely too early so so what we ended
up doing is trying to focus on something
and what we really wanted to show was
you know you could actually take these
state-of-the-art machine learning
systems and put them into a
plug-and-play framework something that
you know the user doesn't have to know
that it's that they're actually working
with with the machine learning system it
just gives them value and so what we
started doing was integrating into these
support systems so basically you know
this is an example of of an interface
where you get you know this support
email and we would say look here's the
most likely answer to to give the best
answer to the customer and if we could
figure out how confident we were in this
answer we could actually start
automating a lot of emails and so that
sounds a bit scary you know to send
emails automatically with with actual
you know intelligent text in it but
turned out to work pretty well at least
if you can control for your uncertainty
and one kind of funny story about this
is you know customers would be kind of
confused when you know an actual answer
to their question would show up like a
second later and so we actually had to
introduce this five ten minute delay so
that it would seem more natural and that
just shows kind of the power of it so
last year we were bought by General
Electric and first when I told people
about is they're like what because that
doesn't really rhyme with customer
support but turns out that they actually
worked a lot on you know many different
things
machines that basically run our world so
you have everything from factories to
you know trains and wind turbines and
health care machines and factories and
power plants and all of those things is
something that they work on it turns out
all of those things generate a lot of
data and all of that data can be used to
to do a lot of interesting things
optimizing
and making things safer and and and our
technologies fit very well into that
into that area so by now everyone should
be kind of ready for you know starting
building their their machine learning
pipeline and this is where you know the
the title of the talk comes in there's a
few things that that we should that we
should think about before we do so so
first of all you know it's really
important to understand what you want to
optimize for when you build your machine
learning system right so one thing is
the most traditional is accuracy so this
is an example of something that's not
very accurate but but you know this
could actually be stated or close to
state-of-the-art object X detection
system a couple years ago and obviously
those systems if you if you had like a
super deep convolutional neural net are
extremely expensive to to to build and
and probably more expensive to develop
and and this is the answer you'd get
right so it might be better than
anything else you can get but it also
costs a lot more so there may be some
methods that you can use that are that
are much better at this because you can
constrain your problem space in in some
way right so in the same way as Michael
talked about right you know usually you
deploy these things in a very narrow
field so you have some problem that you
can actually define and you have some
knowledge about that problem that you
can actually use to to make the to make
the model much better but nonetheless in
in in in the world we live in accuracy
is kind of the most important parameter
for for a lot of a lot of people so I
don't know if you know Kaggle was a
competition site for data science or
machine learning and you know everything
that they do is based on accuracy so you
if you have the most accurate model
doesn't matter how many models are
stacked together or teams or how crazy
large it is but but you win if you have
the most accurate model and and I think
more than more than a few of the of the
companies hosting competitions on Kaggle
have actually found that that the
winning model is not necessarily the
best one to to deploy and so another
example of that which is a famous is
kind of the the Netflix price so that
was kind of what bootstrap this whole
machine learning competition field and a
good quote from from Netflix was that
you know they evaluated all the models
and especially the winners which took
you know a long time to find winners
because they were battling about the
last point oh one percent improvement to
win the million dollars and turns out
you know they had to stack ten different
models to to get the to win and it turns
out that model was way way too complex
to actually put into production and
would would take too much time for the
engineering team to implement so so the
lesson is of course you want to kind of
think about how far do you want to go
for the last percent right because you
may be able to get a really good model
that is one percent less accurate but
cost you know one percent of the cost so
another great example of this is or
let's say what I was talking about
before was kind of the implementation
cost right and so what I want to show
here is kind of run run time cost so
you've probably all heard about alphago
from deepmind and google that that beat
the world's best go player and the point
here is that you know it beat the
world's best go player but it was using
almost 2000 CPUs and 300 GPUs real-time
to to do that and so I don't think that
any of the companies that you work for
would allow that in kind of a regular
project with a normal ROI so that's kind
of that was cool but definitely not
applicable when when you actually want
to run your your model and make money so
obviously they've become a lot better
and leaner and and and and continue
improving but for the point still holds
so another dimension that you should
probably look at is you know
interpretability so from these have
neural network deep learning areas you
know one of them is is called
convolutional do deep neural nets and
what you'll see there is that if you
work with images there's actually some
logic to how the how the layers are
built so if you were a computer vision
person you know five years ago because
probably there's not many left now you
would you would actually do exactly what
this this model is learned by itself in
the layers you would your start doing
edge detection you start doing texture
detection you start doing you know
object and shape detection and then you
would find objects right so this is what
the neural net has kind of learned to do
in its layers and and and then you can
start thinking about you know previously
what we did was we defined features and
feature processes that would that would
take raw data and transform it into
something that the model could
understand and what you do in this case
is basically you take your understanding
of how you actually do computer vision
and then you build a network that can
mimic that right so so in in the space
of neural networks I think we're moving
from you know feature processing to to
kind of network architecting and and and
you have to start being clever clever
about that especially in in in the name
of of interpretability and kind of
transparency to how
how the results were made so that one of
the the really tough parts of of neural
networks is that they're so complex you
cannot you know figure out what's going
on except in these special cases and
that's something that you would usually
meet in your in your business in your
clients in your organization that they
want to understand what is why did you
actually make this prediction and
sometimes it's even you know regulated
you can't tell someone that they can't
get a loan and not tell them why so you
can't use a nonlinear machine learning
algorithm to do credit scoring for
example so you have to do something
that's that's more interpretable
so there's a lot of work to do here and
obviously something like Bayesian
Bayesian machine learning will actually
improve this a lot but there's methods
and and research in in how you can do
this on kind of more blackbox systems
and one of those is kind of the climb so
stands for local interpretable and model
agnostic explanations it's basically
just you run a bunch of permutations of
data through your model to understand
what what comes out of it and so it'll
tell you which which parameter were
actually meant the most in in the answer
and our argued that this is actually a
probably a good thing to do just in
general as kind of a diagnostic step
right because you want to understand
what is coming out of your model and why
is it coming out before you actually
start deploying it blowing it for real
so that you understand you know what
knobs can you actually tune to to cheat
the model or if it's something that's
actually is sensitive you want you
especially won't understand this another
kind of dimension to think about is do
you want to kind of automate which is
what I think most people think about
when we talk about machine learning or
do you actually can you actually do
something that ought ments the the user
right so in
in the case of the self-driving cars you
have this five levels right which is
basically from nothing to automatic but
you have all these levels in between
that's kind of augmenting you in some
way and in the same way with what I
showed you in in in our support
application you could actually you know
we would just show that showed the
answer to the user and they could click
on it but in the end when we're
confident up we could actually automate
some of it and that comes back to a lot
of talk about you know what's the risk
of making your prediction what's the
risk of being wrong and so you want
understand that to to to make the best
decision here so just to run down of the
of what I just talked about and you want
to kind of try to get a holistic view of
what your problem is and what do you
actually want out to Mai's for before
you start
and so one kind of just advice and then
is to talk about the way that we can
approach problems mostly so the first is
kind of you want to go into a problem
and really define the problem and you
want to understand what you actually
expect to get for results for answers
and so this will this is actually you
know a lot of people just start working
on something because they have a hunch
that something can be done and there's
you know there's plenty of fields where
this is actually useful and you know you
can do unsupervised learning you can do
clustering things like that but if you
actually want to solve you know a real
problem and if you want to do use
supervised learning you you should
actually think a lot about the results
that you want to get and so the second
bullet point here is you need to collect
of course but you need to understand the
data really well before you start
building any models so I'll go through
these points a bit a bit
in the next slide so let's just jump
into that so on the first one with
identifying the problem
you won't understand you know what is
the cost so this is kind of a you can
set up a cost matrix basically of you
know a wrong answer
in in various scenarios or a right
answer what is the gain from that and
first when you understand you know these
things you can actually define kind of
an optimization metric that takes into
account these specific these specific
values so one example of that is the
project with finding supernovas is that
we would be flooded with false positives
so basically you'd get thousands of
candidates every night that wasn't real
it was just some there's just some
effect of the process or the image or
noise or whatever have you in in in the
real world and so our optimization
metric couldn't be just you know the
best a you see under the the best a you
see this area on the curve we would have
to actually define optimization metric
that took into account getting a smaller
amount of false positives so our
optimization metric that we used to
build our model would be what is the
accuracy at you know 1% false positive
rate right because then you're sure that
you would have a manageable number of
things to actually look through and then
whatever the accuracy was at that point
would be what you could expect to to
optimize and the next part about you
know collecting understanding data I
think there's a few pretty funny graphs
here from Forbes that shows you know
what is data science spend most of time
doing and that by far the largest part
is cleaning and organizing data and so
that's great and then the question is
what is the least enjoyable part of
doing data science and overwhelming
number of people are saying cleaning it
in organizing data so you know it's just
truth that in the real world there will
be a lot of messy data
and you have to have good practices and
good methods for for dealing with that
and the great example here is of
understanding your data so this was
actually a I think it was a recent paper
where they were claiming they could
detect gender from iris scans and so if
you if you're not looking at the data it
could be the case but if you looked at
just a few of the examples you'd have an
idea of what was going on so what what
do you think was going on there
detecting mascara so that's not a very
good model especially if we want to
detect it from the iris and there's and
there's you know there's a bunch of
those examples I think another one was
they during doing some conflict they
build a model to detect you know tanks
in in the landscape from satellites and
they get a really good model out of it
but when they needed to apply it it
didn't really work very well and they
went back and figured out that the model
has actually learned to detect clouds
and for some reason that is correlated
with all of the tanks in the dataset so
you want to understand the data before
you start building your model and then
the next advice is to take the most
simple built the most simple model you
can think of that solves the problem so
you don't have to look for fancy
algorithms or you know understand tensor
flow to to build machine learning models
there's plenty of old-school models that
work very well and you should get it to
work and to end so basically get it into
the application whatever you're trying
to do and get get results out of it get
feedback and from there and from there
you can you can start improving the
model and maybe and you can show that it
would actually be cost-effective to
start using tensor flow or rnns or
whatever have you but a lot of times
you know you can actually get really
good results from for more simple things
and and it's much more important to
understand you know the feedback and
have that entire loop in place because
then you can move fast so I guess that's
just simple agile but in the data
science world you know we don't always
understand all the normal engineering
practices so I would say we're getting
closer to to to being ready one thing
that we are missing though is you know
to to deploy this and to use these best
practices it's really important to have
a good kind of infrastructure to do it
on and that doesn't mean it needs to be
complicated it just means again that we
should learn from you know decades of
experience in building software and so
one thing that we all know is this
notion of continuous integration and
this whole fancy loop of steps that you
should go through and continue on and I
would say it's not really that
complicated
we just need kind of one more step to
look at some data in in the machine
learning version of this because you
also want to do testing you also want to
do releases you also you know want to
operate it properly and measure it and
so forth so that's just something that
I've seen a lot of data sign as machine
learning practitioners forget that this
these things are not you know these are
still services these are still things
that you are actually building and so
when you build something and you get
artifacts out of it that sounds like a
built system so you can use Jenkins or
whatever have you right that you
probably that you probably already have
installed and the other thing I'd say is
we've gotten a lot of really good good
things out of using containers so I was
happy to see a docker container and the
previous talk as well and
we're gonna go through these kind of
three reasons that I think containers
are really important for for machine
learning so one is packaging so I don't
know if you've done this search but I
think a lot of people have and gotten
results like this so some numpy version
is not compatible with some tensorflow
or GPUs or whatever and you know
containers are really good at solving
this problem right so you can install
any any number of packages and you are
sure that they won't conflict with
whatever you have on your production
servers or anywhere else for that matter
so the the next one is inheritance so
you can actually use this and I don't
know how much you're familiar with
docker but you know they have kind of
simple inheritance based built into them
so basically you can take a tensor flow
model you can build your specific model
on that and then you say okay I want to
actually specialize even more and you
can take your special model and build
whatever special on top of that so you
can start having kind of a tree of of
algorithms and models that you can then
you can use and deploy kind of in
specific situations and so that becomes
really useful when obviously when you
want to minimize the time it takes to
build a model you can actually apply
these standard standard models and the
last one is this notion of immutability
so really you know a container makes
kind of this complicated pipeline that
you know supervised machine learning is
look looked pretty simple right it's
just something that where data comes in
and answers come out and so the most
important part is really that you can
use the same pipeline or you have to use
the same pipeline when you build your
models and when you make predictions and
this sounds simple right but you see a
lot of instances where you deploy them
separately you have some some code that
actually is is transforming the data but
there was a separate repose or separate
services in your system and you start
updating the code because whatever you
found box or you have new developments
but the model is still the same making
predictions that means you can't trust
the predictions coming out because you
don't have the same kind of data coming
in and so you really want to make sure
you use the same the same pipeline and
you want to put as much of the pipeline
that you can into the container and so
this is really a good reason to have you
know in darker images where you where
you get a kind of a unique ID for a
specific specific container image and
whenever you change something in there
this ID will will change so it's a hash
based on what the content is right and
that means if you apply the same exact
ID to the predictions as you did when
you build your model you know that the
pipeline is is equivalent okay so the
last point in kind of the infrastructure
part is you know you should use kind of
great frameworks and services that
already exist right so we already talked
about Jenkins and and and kind of
thinking the data science machine
whirring pipeline as a as an engineering
process right but obviously you know to
actually build the models just some of
my favorites if you want to get started
is you know second learn is really good
if you use Python you can actually build
these incomplete pipelines in
scikit-learn and and have optimizations
done over the entire pipeline and that's
something that's that's really useful to
do when you're getting getting started
now that may not scale for exactly what
you what you want to do but you can also
use something like tensorflow which is
more of a steep learning curve you have
to understand what's going on
there's a lot of things to get right but
again with docker and containers that
becomes much easier
and since Flo has these really nice
things with you know a actual kind of
dashboard where you can go in and you
can understand what's going on with the
model kind of acid is building and
afterwards and the other thing that
tends of flow has is this you know layer
that you can actually use to produce a
prediction service from your model and
that becomes really useful when you want
to run things in production and then
lastly it was great seeing the the
patient talk but when I want to work in
in that kind of field I usually use PI
MC and I find that really interesting to
to play around with so I want to mention
just a new project that I think is
really interesting in this world of
putting models into a production setting
and that's something from a new lab
called rice lab and if if some of you
know the previous version of this was
called the amp laughs was basically the
lab at Berkeley that built the build
spark and and a bunch of other tools so
this iteration of the lab is called rice
lab and they have this new project
called clipper and so this does a lot of
what you want to actually do with your
models you want to be able to deploy
them with kind of your framework of
choice you want to have it easy to
update and and and and add models and
you want to try to understand when you
should upgrade right so it's not
necessarily the best thing to just
upgrade the model not even if the not
even if the accuracy is is is better on
paper because you don't know if the
problem actually changed along the way
so you could actually you might want to
deploy a model that has worse accuracy
but but does better on a new data
because the the problem changed so
so someone notion that they that they
have here is trying to dynamically
select the best model and so that that's
an interesting approach where you know
multiple models can be running at the
same time and you run your data through
it and you check the answers afterwards
and then you kind of select the model
that works the best so that's that's an
interesting built-in part of this and
obviously a lot of kind of other
interesting things in this project so I
think that'll be interesting to to watch
and lastly of course some really
interesting things can be done on the
kind of public clouds and the big
players all all have kind of machine
learning platforms and one you know
obvious thing to do if you're working in
tensorflow is obviously to use the
Google cloud platform which is just kind
of tensorflow as a service but the
others actually have really good
environments as well that's worth
checking out if you wanna if you want to
work on that so just to recap the
infrastructure part here you want to
certainly use kind of best engineering
practices use continuous integration
containers can actually be really
important in in this field and then
obviously wherever you can you should
use something that that that others are
using so I want to have time for
questions as well so I want to wrap up
just by telling you a bit about kind of
book I rode last year so this has a lot
of kind of the advice about data and
models that's not actually going into
specific models and then a couple of
groups that I've been part of here so
one is the data science and machine
learning group in Copenhagen and if
you're interested in kind of the
nitty-gritty of you know practical
aspects of building and deploying models
I should definitely check that out on on
Meetup
and there's this interesting
organization called Nordic AI where
we're starting to do a lot of events and
getting some some really interesting
folks to speak and with that take
questions so there's no questions from
the end but if anyone has one in the
audience please raise your hand don't be
shy
okay that's one I think refer to talk
and can you talk a bit about testing
machine learning models and how you
automate that yeah so it's obviously a
bit different because you have this
whole notion of data coming in right so
you kind of want to you want to do your
testing on more levels than you do in
normal software so you probably want to
do testing at the data level as well to
kind of understand what's coming in and
then you want to do testing at the model
level to understand you know are the
results that are coming out what I
expected and this goes back to kind of
some of the first things that I said was
you know try to understand the problem
and what do you expect to get out of it
because you can actually you can
actually think of you know doing kind of
test-driven development where you where
you to find that upfront and you can
write those tests and then you built
your model to see to see what it's
saying right obviously there's some
usually in these models there's some
randomness to it so so you can't just
have you know actual values but you can
have some range of numerical values or
you can have some general understanding
that you can code in your tests but then
of course you usually you're building
into this building this into kind of an
application or a pipeline and and and at
that level you can also test come to
full end-to-end so something comes in at
the application level API
or UI or whatever it is and you actually
test the model by putting data kind of
all the way through that pipeline hello
thanks for the talk
my question is once neural network is
deployed to production do need to
retrain it at one moment and if yes how
often okay so
mmm that that really depends on what
you're modeling so if your data changes
a lot you should understand the timeline
that the data is changing on and that
should be you know that should that
should kind of tell you a bit about what
the what the proper rate of rebuilding
is now obviously that also becomes kind
of a cost question right do you it it
can take a lot of compute power to to
rebuild the model so you want to
understand you know how often do you
want to do that compared to the savings
that you get so that that doesn't yeah I
think that's the best answer I can give
anymore doesn't seem to be the case well
once again everything much thank you
hendrik thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>