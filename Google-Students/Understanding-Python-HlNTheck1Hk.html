<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Understanding Python | Coder Coacher - Coaching Coders</title><meta content="Understanding Python - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Students/">Google Students</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Understanding Python</b></h2><h5 class="post__date">2008-06-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HlNTheck1Hk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello yes hi welcome to the latest in
our series of talks and advanced topics
and programming languages today we're
very lucky to have Thomas pouter's who's
here to talk to us about features that
are currently available in Python but
are but our advanced features last week
we had we were very lucky to have cuido
then Rossum talked about upcoming
features today we'll be talking about
existing features right yes I wanted to
as always this is the latest in our
series of talks I always want to make a
pitch so that people will actually give
talks of their own it's a really useful
thing to do if you have specialized
knowledge or if you have interesting
knowledge to share that knowledge with
as many Googlers as possible and
potentially even the rest of the world
so please come and see me and we can set
up a talk and you can give yet another
in our series of talks here and with
that I will turn it over to Thomas who
shall give a very interesting talk
thank you stay song right although
there's an echo but so I'm going to give
talk about advanced Python which is a
not an easy subject in that there's a
lot of Python that can be considered
advanced I'm not sure what your level of
advancement is so I'm going to cover
basically everything from the start
until the end and we'll see how far a
world will come these are the subjects
I'll be covering I'll certainly be
explaining about the Python design
objects iterators and generators and
hopefully decorators everything after
that is a bonus I'm going to keep the
pace pretty high so if there's any
questions just wave your arms and I'll
stop and explain but if everyone can
keep up then we can probably cover the
more interesting topics at the end as
well and if there's specific interest in
any of the topics especially for
instance Unicode I can skip over the
advanced stuff and jump right to Unicode
so first of all python python was
developed by guido as a middle system
language between shell scripting and
system programming so it was intended to
be easy to use by normal programmers
would still allow more complex
structures than a shell script scripting
language
it turns out that it's also convenient
for library programmers people doing the
actual programming for end-users because
you can hide a lot of smarts inside of
objects or modules and just expose a
very simple API to end-users this has
gotten progressively better with later
releases of Python there are multiple
implementations of Python C Python is
the one everyone uses except for those
that are developing the others JSON is
has been around for quite a while hat is
actually used by a lot of people but not
as much as C Python or in Python and pi
PI are still actively being developed
although ironpython is apparently very
usable it is designed with
implementation in that if you don't come
up with an implementation of a feature
that you want implemented it's not going
to happen but it's not a slave to the
implementation and it doesn't mean that
if you implement an idea it'll get it
it's still a very designed language we
have feature releases every one to two
years it used to be every year or so now
the last ones in the works for two years
and there's a lot of bugs bug figure
releases as well important note about
the feature releases if you do not get
any warnings in using a particular minor
release upgrading to a newer minor
release the one following that minor
release will almost certainly work any
anything that changes semantics or
possibly breaks code will be warning for
at least one release and bug-fix
releases have a similar requirement that
you can always upgrade to a newer bug
figure release of the same minor version
and nothing will break that wasn't
already broken important in realizing
how Python works is that everything is
one-time even compile time is actually
run time as you may know there are
cached files pyc files that are cached
by code that's basically borrowed
runtime someone else's runtime that you
can skip also important is that all
execution happens in a namespace and
that namespace is actually a dict it's a
dictionary object with keys and values
modules functions and classes all have
their own little namespace and they
don't affect other new spaces unless
they
explicitly do so and modules are
executed top to bottom scripts start
running at line one and they run all the
way down to the end and or until loops
or whatever make them wait so in that
regard it's very much like a script when
you import a module it does the same
thing it just starts executing line one
and runs on down until at the end and
then the import is done and another
import aspect is that the DEF and class
statements don't define a function or at
compilation time it's a runtime thing it
actually happens when that statement is
reached so some more about functions and
classes as well because there are
important features at compile time which
is runtime the code for the function
will be compiled into a code object it's
a separate object from whatever the rest
of the code is compiled into and then at
the F time when the DEF statement is
executed it'll be the code object will
be wrapped into a function object along
with whatever arguments it takes any
defaults to those arguments and
essentially death is an assignment
operation if you look at the bytecode
you'll see that it just uses the same
bytecodes as normal assignment
operations so here's an example of a
function the red part is the actual def
statement that gets evaluated when it's
reached including the part in blue which
is an argument default that part gets
evaluated at the moment of death so the
foo object is constructed or the foo
function is called if it's a function at
the moment that death is being actually
executed and the green part has been
compiled at that time because compile
time has been in the past but it's not
being executed until later which is when
you call the function so this is when
you call the function there's an inner
function in there so what happens is
that the the green lines you see here
they've been compiled into their own
code object and when you call func the
inner func gets created at that time and
again the default argument of the the
defaults for the arc 3 argument is
evaluated at the moment you call death
if you look after the definition of
inner func you'll see that our Guan and
r2 are reassigned that means that
whatever our two was will be assigned to
inner films arc three and not whatever
it is at the moment you call inner func
however inside inner func we also use
our Guan which is using nested scopes
which I'll be mentioning later as well
which means that it will be using the
outer functions our Guan and that will
be whatever our Guan is at the moment
you call inner func so there's a very
big difference between those two uses
yeah no it's just returning function
object so it's not calling anything only
the parentheses do actual calling yeah
sorry yeah the question was is the last
line actually evaluating inner func it
is not it's just returning the function
object that is inner func so class
segments are very similar but also very
different a class statement is followed
by a block of code that's wait that's
executed when the class stage statement
is reached right away
it is however executed in separate
namespace addicted n and then after that
code block has been executed the
namespace is passed to the or is used to
create the actual class object any
functions that you define inside the
code block then get turned into methods
by magic basically and well as people
who are already programmed in Python
will know the self argument that this
for for Python is passed implicitly when
you call a method but your methods still
have to receive it explicitly as the
first argument and an important thing to
realize is that the code block in a
class is actually a normal code block
you can do whatever you want in here for
instance at the top I create a class
attribute which is just something stored
in class result of calling func a find a
method which is just a normal function
but it takes self as first argument and
it's
signs to an attribute of self when it is
called I also define a helper function
which just does some silly arithmetic
and call that helper function inside the
class block itself to calculate or
recalculate the class header and at the
end I delete helper because otherwise it
would end up in the class and since it
doesn't have self as first argument it
wouldn't do very helpful things other
important parts about Python variables
aren't containers like in other
languages they're not allocated memory
that you can use to store data people
often say about Python that everything
is an object and they also sometimes say
everything is a reference that's both
true but both are not true when you
apply them to variables because
variables are not objects and variables
are not references variables are only
labels everything concrete everything
that allocates memory everything you can
toss around is an object and whenever
you hold an object whenever you store it
anywhere you're actually storing a
reference your you don't actually own an
object you only on references to an
object variables don't have type
information they don't have information
on the scope of a variable or how many
objects live around or when they were
created the only thing they do is refer
to an object and that's it if you want
to look at it from an implementation
standpoint it's a dict it's a dictionary
mapping names to objects that's it so
scopes also related to namespaces Python
has a very simple to scope rule which is
actually three scopes names are either
local or they are global or built in
local means it's it exists in the
current function or class or module but
it doesn't exist outside global means it
exists in the current module
it doesn't mean exist everywhere just in
the current module and built-in is a
special namespace that is used by
built-in functions that you can actually
modify it's just a special module that
you can modify yourself if you want when
the
compiler examines a function and
compiles a function it keeps track of
whatever names you assign to and assumes
correctly because by definition those
names you assigned to our local you can
change this by using the global
Declaration which is the only actual
declaration Python has but don't do it
too often it's usually a sign that your
code is incorrect
all other names that the compiler finds
are either global Global or built-in and
the lookup is it looks in global and
then it looks and built-in so if you you
if you have a global of the same name as
a built-in all the code in the module
will find the global of that name
instead of the built in you can actually
use this on other modules as well if you
import a module and then assign to an
attribute the attribute of the module
you'll be assigned signing to a global
name in that module and you can mask
whatever it things is a built-in name by
assigning to that attribute there's also
a trick with nested scopes which were
added later in Python I think in Python
2.1 where you can as I pointed out
before you can refer in an inner
function to a variable in an outer
function but that is a is only read-only
you cannot assign to a name in an outer
function this isn't really a mechanical
problem in Python it would be possible
to assign if we added it but there's no
syntax to say I want to assign to an
outer outer scope variable global only
assigns the global name and not to outer
scopes apparently pi3k might be getting
python 3.0 might be getting syntax for
this
so I mentioned modules modules are there
to organize code they're very convenient
because they have their own namespace
with global names they also keep the
rest of the modules tidy they're always
executed on first import and then cashed
in system modules this cache is just
about everything that you import in your
program and it's also the only thing
that keeps track of what you have import
so if you toss something out of six
modules and import it again it'll get
executed again input is just syntactic
sugar just like basically everything in
Python is syntactic sugar it calls the
under under import under under built-in
function if you want to do an import of
a module whose name you have in a string
object you use under under import if you
want to replace under under import you
can just write your own function and
replace the one in the built-in
namespace another trick is that system
modules does not have to contain modules
it's a mapping of name to whatever
object you want import to return so you
can toss in any any old object in there
and then importing that name will return
your objects storing none in system
modules just means this module couldn't
be found so if you want to prevent the
module from being imported you can
insert in system modules none under that
name and then it'll raise import error
whenever you try to import it Python
objects in general are described under
in various terms
mutability is a common one that means
the object is changeable lists for
instance our mutable tuples are not
mutability is very important in python
because everything is a reference if you
have a mutable object and you end up
changing it by accident and changing it
for everyone that's rather inconvenient
so you have to keep in mind whether
objects are mutable or not fortunately
this mostly happens by accident
correctly anyway a related concept is
hash ability whether you can take the
hash of an object in a normal operation
mutable objects are not hashable at most
immutable objects are hashable for
instance tuples are hashable but they're
only hashable if all their values are
also hashable as hashes are being used
just for dicks and sets right now so any
dict key has to be hashable
and any set item anything you want to
store in a set has to be hashable as
well but it's not inconceivable that
more stuff uses hashes
and then there's the imaginary abstract
base classes that are often referred
saying that an object is Phi like or
it's a sequence or it's a mapping those
are abstract concepts that are somewhat
like protocols or interfaces or whatever
you want in another language but they're
just informal they're just saying
whenever an object is sequence or it has
the sequence operations implemented you
can look in it you can iterate over it
and say to et cetera some of them are
overlapping for instance sequences
mappings and files are all iterable so
the interval interface applies to all of
them and actually all of the objects you
define all that you're defining is
implementation of syntax Python defines
syntax and you can plug in whatever
implementation you want in that syntax
and you don't do it by and in other
languages you say you implement the less
than operator in Python you say you
implement the less than operation so
that it can be used even when you're not
actually using the less than operator
here's a short list of hooks that Python
supports I'm not going to go over all of
them most should be should be common
enough and the one thing that's worth
mentioning is conversions you can define
a few hooks that define how your object
gets converted to other types that just
works for built-in types of course
because the hooks don't exist for
arbitrary types but most arbitrary types
that want to do something like this can
just say if you have an under under foo
method I'll call it turn you into a full
object if I want to but it's not very
common these things are not Python hooks
these things you cannot configure on
your object assignment assignment is an
operation that changes the namespace and
not the object since an object is just a
reference to an object you have no
control over where your references are
going another thing you cannot control
our tight checks
going to control when people are
comparing your type or doing is it's is
instance checks you can control what
they get as a result related identity
comparison the is operator it checks
whether two references are pointing to
referring to the same object you have no
control over that and and or and not our
boolean operations and they just call
the one truth value test that your
operated your object can implement and
you have no control over what they
actually return as some may know and
then or in Python return one of the two
values whereas not return is always a
boolean and method calls you cannot
define in a single operation whatever
will happen when someone calls a method
on you because methods are getting an
attribute followed by calling that
object there are two separate steps so
in order to implement method calls on
your object you would have to implement
get adder to return sum in go between
object and then have that go between
object do something when it's called
sorry
so on to some implementation details in
C this is just the applies to C Python
of course Python objects are implemented
in struct that holds various bookkeeping
information like ref counts the actual
type that an object is as well as
arbitrary C data it can be pointers it
can be instant can be an array whatever
you want types are what describes what
an object is and how it behaves they're
separate struct which is also a PI
object struct the arbitrary data in a PI
type struct is the function pointers and
various other things that describe the
type the PI objects trucks are not
relocatable you cannot move them around
once you've given them out to anyone
else it's a blog of memory that's
allocated and that's it if you want to
move it around you have to destroy the
object which means you have to get rid
of all the references to it this also
means that variable size objects like
lists that have a portion that needs to
be reallocated and might move around or
just use an extra layer of indirection
it's just a pointer stored somewhere in
and of course because it's C it doesn't
have ref counting by nature so ref
counting is on manually whenever you
receive a reference you Inc ref and when
it's over whenever you toss one out you
Dec ref it's sounds simple it can get
quite complicated but the Python C API
is mostly clear enough that it's not too
hard once you get used to it another
feature that is done reasonably manually
is weak references weak references are
reference references that get informed
when their object goes away so that they
can do some cleanup and not crash the
weak references are just callbacks
basically in the PI object struct
arbitrary data one of the major problems
with ref counting is reference cycles
that is two objects that refer to each
other causing them both never to be
cleaned up two objects referring to each
others of course to the simple problem
the complex problem is a huge loop of
objects referring to objects and
everything Python has a cyclic garbage
collector which keeps
tract of objects that might participate
in cycles for instance lists and dicts
and walks them every now and then to
find object groups that are not
reachable through anything but
themselves and then it cleans up the
entire cycle this is all done in C if
you're right AC extension or C type you
don't usually have to bother with it too
much there are some methods you have to
implement if you want to participate in
cyclic just see GC when you think you
might be participating in cycles so in
Python when you have a an object what
you have well you have an object that
has two special attributes the
under-under dict attribute which is a
dictionary holding per object data and
you have younger class attribute which
refers to the class and like in C the
class defines behavior and in newer
pythons the class is actually a PI type
of object it all matches the way to
define the behavior is not through
function pointers because Python doesn't
have function pointers it's with
specially named methods methods that
start and end with under under those are
special to Python they're not special
because they get allocated differently
they're just special because some of
them get called by Python automatically
in some situations you can define your
own on or under methods and use them
whenever you want there's nothing
special in that regard it's just the sum
of them signals of Python this needs to
be called whenever that happens in
general you should not be calling
another objects under under methods
yourself not directly you should always
use them through whatever mechanism
wraps them so for instance if you want
to have the string representation of an
object you shouldn't be calling object
got under understood under under you
should be just be calling stir object
another feature of python is that class
attributes that is attributes of the
class object are also reachable through
the instance if you do instance dot
adder and it's not defined in the
under-under dict it'll be fetched from
the class and the class might have
parent classes so those get searched as
well
and of course in Python the whole point
of Python is that you don't have to do
stuff that Python can do for you so ref
counting weak references in cycling GC
are all done automatically you never
have to worry about them
typical Python code does not use type
checks because partly because it was
never possible until a couple years ago
to subclass built-in types so pretending
to be a built-in type meant that other
people would not have to use I must not
use type checks or you could never
pretend to be a built-in type it's also
very convenient
it just means you can pretend to be
whatever type you want implement the
right methods and it'll just work the C
layer sometimes need specific types if
you want to multiply a string by an
integer it needs to have actually have a
string and an integer or there won't be
any multiplication in C so the C layer
has conversions when it wants an integer
there special methods that say I need an
integer at this argument it'll convert
whatever gets passed in and it will
convert whatever get passed in to an
integer or a string and do the
multiplication that way if you really
must use type checks for instance
because you're faking C code or you're
wrapping C code or whatever use is
instance instead of type checking type
for a specific value means you can you
only accept objects of that type whereas
instance does proper instance checks so
that someone is a subclass whatever type
you expect works the right way functions
become methods by magic in Python it
happens when you get an attribute off an
object or rather when you get an
attribute of a class through an object
whenever you get an an attribute of a
class that is a function it get turned
gets turned into an unbound method which
is a method that knows it's a method and
it knows which class it belongs to but
it doesn't know which instance so when
you call that method it it knows that
the first argument you pass must be an
instance of that class and they'll it
complain if it's not an instance of the
right type of course that tie check uses
is instance so when you have a methods
or you have an unbound method you can
pass a subclass of whatever Placid
Express expects and it works bond
methods on the other hand are methods
that know their instance and they will
be passing that argument automatically
so you call them without the first
argument you start at the second
argument and it all looks normal so any
questions so far
no all right on to iterators then
so iterators in Python are really simple
their helper objects for iteration they
encapsulate if you will the iteration
state and they're created and used
automatically if you don't want to
bother with them
you don't have to and it all just
happens by magic if you do want to
barter with them you can do a lot of fun
stuff with them even more so if you
combining with generators which I'll be
talking about next iterators are two
methods under and Ritter and next notice
that there's no under under round next
because next is actually intended to be
called directly sometimes so there's no
under under around it or people would
think that they should be calling it
because they're simple iterators in
Python are not rebind able they're not
reversible they're not copyable none of
that they're the lowest common
denominator and iterators there are
however ways to write reversible
iterators if you want you can just write
your own iterator class and add methods
to rewind or reverse or whatever you can
also just nest iterators and iterators
themselves are interval they're just
actually an iterator is required in its
own under under inner method to return
self or it wouldn't be an actual
iterator so in the example I have here I
create explicitly create an iterator
over a range which is a list of numbers
from 0 to 10 not including 10 and then I
call zip on it which takes a number of
iterables and takes one element of each
interval and wraps it in a tuple and
stores that in a list which it returns
so I create a single iterator pass the
same iterator to zip twice and as you
can see is it takes one element of each
iterator consuming the iterator as it
goes and ends up with having two
elements at a time basically from the
original list of 0 through 9
so generators are a convenient way to
write iterators they're lazy functions
that get executed as you iterate over
the result
basically generators use the yield
keyword instead of return it works very
much the same way except after a yield
statement execution continues there the
next time you call it or the next time
you iterate the function with yield in
it will return a generator it will
return an iterator that you can loop
over and this is terribly convenient for
under under error methods because you
can just write what you would expect and
it'll just work in python 2.5 generators
were complexified and they can now also
receive data and you can use them to
build co-routines very easily nothing
you cannot also do with 2.4 and earlier
iterators just more conveniently and
with extra magic there's a lot of
generator like iterators in the inner
tools module which is i think new in
python 2.2 or 2.3 there's a whole bunch
of stuff in there you can use to chain
and filter and whatever with iterators
that is really convenient for chaining
various combinations so here's a
generator example the bottom function is
map as you may know it except it only
takes one iterable the built-in map
function it creates a list of results
from applying the function to every item
in the Iberville interval the in the
bottom there's a two line function that
is the generator version and then
there's a one line function that is the
original map implemented in terms of the
generator as you can see you just
basically lose half the function if you
use a generator because you generate
items each item on the fly and you
return a generator instead of an actual
list any questions
I do it can i define that what a
co-routine is and how I would do it in
Python a Kol routine is a routine that
is basically like a generator it stops
execution passing data to someone else
but where a generator returns results to
its caller a co-routine returns results
to someone else another function so you
can have two routines where they both
consume the output of the other and then
the end result is handled data how you
would do him in Python well as I said
you can do me in python 2.5 with new
sending data to a generator thing before
2.5 you would write a class that was
itself an iterator and just write it in
bits and pieces and it wouldn't be as
convenient as co-routines in actual
languages that have Co routines because
you don't have a single block of code
you have a whole bunch of separate
pieces of code that get called at the
right time I wouldn't bother
implementing them in Python right now
maybe with 2.5 out or two five one out
and people getting used to the new stuff
you can do with generators we'll get
actual Co routines in Python
and fire gem
and the white
the question was if generators are lazy
can you write a generator that loops
infinitely and just keeps on yielding
results as long as you ask for it yes
yes there well what do you ask for a
finite number you can if you use the
itertools module you can slice iterators
you can say up to so many items in this
iterator and it'll return an iterator
that starts consuming the original
iterator until the slice ends but you
don't have to do that the iterator is
something you loop over so if you have a
loop that loops over two things at once
and it stops whenever the condition is
met
if you don't and you can just loop over
an infinite object and rely on the fact
that your loop will end itself for other
reasons then that the iterator stops
there's actually an infinite number of
infinite iterators in the inner-tubes
modules like itertools dot count which
starts counting in zero and just keeps
on counting forever and ever unless you
stop for some reason so on to decorators
decorators are syntax in python 2.4 for
a feature that's been around forever
which is function wrapping decorators
are just func function Zoar colobus
rather that take a function as argument
and return a replacement callable or
they can return the original function if
they want however the syntax means that
it can get confusing if you have a
decorator that also has to accept its
own arguments because then you have a
function that should return a callable
that should accept callable and then
return the original color so we'll see
some examples of that another problem is
that because functions are special when
there are attributes of a class they
become methods when you have a decorator
that returns something that's not an
actual Python function but something
that acts like a Python function for in
most regards it won't get turned into
method unless you implement the same
magic that
methods are that functions have that
turn them into methods which is under
under get which I'll maybe explain later
so if you write decorators make sure
their methods or make sure there are
functions or they won't get turned into
methods and well as I said simple
concept but the Devils in details and
we'll see about that
here's a simple decorator it's a spam
decorator that says whenever the
function that you decorate the sing
function at the bottom is called it
actually calls the wrapper function at
the top which loops for ten times
calling the original function so in this
piece of code the original function gets
called gets called ten times and there's
no return value of the actual function
call which is which there isn't in the
original either here's an example of a
decorator with an argument the decorator
is spam ten which is not no longer Paris
no longer the decorator it's rather the
decorator generator that takes a number
which is the number of times to repeat
and then in spam we define the decorator
function which accepts the function as
an argument and then has a wrapper
function which close the original
function and then we turn return wrapper
and then of course we turn the decorator
from the decorator generator so that all
looks looks okay I mean it takes some
getting used to the nesting and
everything but there's another problem
what about introspection maybe Python
users don't care about the name of their
function but some tools do like PI dog
for instance which is the Python
documentation tool it actually looks at
function objects and looks at their name
and their signature and their dark
string and whatever and because we
replace the original function when you
ask for the documentation of saying
it'll actually say it's called the
function wrapper and it has a signature
of star args and starts our keyword args
and it has no duck string that's
probably not what you want another thing
is that if you have another decorator in
there you can change the craters that
changes attributes of the function those
changes will go away because you're not
doing anything with
attributes of the function so some
people write code like this which is the
original spam with a repeats argument
with the decorator function in there
with a wrapper function in there and
then after defining wrapper we assign
the name the dark string the module and
and the dict
of the original function back to wrapper
so that all those things will actually
be the same for the new function and the
old one and assigning dick like that
actually works you can you can copy it's
not a copy it's a reference assignment
the original function all the original
functions dicks are attributes will be
accessible in the wrapper function and
when you ensign to either one of them
it'll appear in the other one as well
they just share their attribute space
now this is not the easiest way to write
a decorator so in Python 2.5 in the func
tools module there is a decorator for
decorators that does this for you so you
have a decorator that you apply to
decorator or to decorator generators and
then that decorator generator decorator
gets applied to whatever function you
have so as you can see the devil is in
the details they can get confusing
somewhere quickly any questions all
right how works for time we got all
right new style classes when I say new
style classes when anyone says new style
classes they actually mean old new style
classes because they were added in
python 2.2 which was released I think
six or seven years ago something like
that they're old and it's a unification
of the C types that I explained and the
Python classes because before or
actually still in classic classes
instances and classes are distinct C
types there is a C type called class
object or class object that implements
all the magic that I talked about about
turning methods into or turning
functions into methods and there's the C
type instance which make sure that
instances work as expected with the
under-under take 10 everything
so there are separate types and if you
ask for the type of an INT it'll say
it's an INT but if you ask the type of
the about the type of any class that
tries to be an INT it'll say it's an
instance so you have no way of checking
all that and another problem with the
original approach was that you cannot
subclass built-in types so Guido worked
on in Python to tattoo on unifying si
types and python classes and the end
result is pretty good you can mix them
and match them and everything it worked
good but it only works because a lot of
new general mechanisms were added they
were all necessary to bridge the divide
between C objects and Python types and
things that you assign from Python have
to be inserted in as a C data type in AC
struct rather than as a Python object
pointer classic classes are still the
default so if you write a new class and
you don't specifically make it a new
style class it'll still be a classic
class and that was for compatibility
reasons because there's a lot of stuff
that's slightly different between all a
lot of stuff there's a couple of things
that are slightly different between
classic classes and new style classes
mostly with multiple inheritance and you
can check if any class or actually any
instance of a class is an instance of a
new style class because it inherits from
objects instead of nothing so you can
who actually do is instance my thing
object you'll know that it's an instance
of a new style class the first of the
mechanisms that I'm going to explain is
descriptors
the Scriptures are a generalization of
the magic that happened with functions
to turn them into methods the scripture
is any object that lives in the class
namespace in the class attribute space
so he's an attribute of the class and
that has under under get under under
under owners head under under under
under delete methods it doesn't have to
be have all of them I think you can just
do with under under get or under on set
or under under delete for specific
operations whenever an attribute is
retrieved it attempted to be retrieved
from an object whose class has an
attribute with a descriptor in it those
methods on the descriptor will be called
and the result of those calls will be
passed back to the object same for
setting it'll call the set method no
result course and deleting it called a
delete method the delete method is not
called under under del and runner
because that was already taken for some
other hook apparently it's now the
method behind the mechanism behind
methods so if you want to have a
function like object that behaves the
same way as functions do becoming a
method you can do that by defining under
get under under and it's also the
mechanism behind property which is a
trick of hiding accessors behind normal
attribute access so here's an example of
properties we're not going to give an
example of actual descriptors because
it's too boring and you won't be using
it anyway but here's a property we have
a class we define a function get prop it
takes a self argument even though it's
not going to be a method it takes itself
argument it does some stuff there and to
return whatever the value is of the
actual property and then we wrap it in
property and store it in a local in a
name that'll eventually be a class
attribute oh I see I have an error that
right there
so we instantiate the class I should
have had foo instead of X there and then
we do food up prop for the prop calls
the get prop and because it's property
even though it's not a method because
just a function up inside the class
block the property type knows that it
needs to pass the instance for
convenience the instance that it
actually caught is called on on to the
function that wraps it if you look at
this you can say all this could be a
decorator too and it's true you can just
say add property at the top of Def get
prop except that probably takes multiple
arguments you can also pass a set prop
and a del prop if you want to I didn't
do it in this example for brevity but if
you just have a getter you can just say
at the top as property instead of
properties property get prop at the
bottom any questions about this alright
so the other are general mechanisms kind
of related there also descriptors class
methods and static methods before Python
suda2 Python only had instance methods
that is normal methods methods that take
self as the first argument they got
called in an instance and if you try to
call them on a class without having an
instance you get an error so in Python
2.2 we got class methods and static
methods class methods take class as the
actual class object as the first
argument and that's terribly useful
I'll show why in a moment static methods
take no magic argument and they're not
very useful even though Java and C++
programmers coming to Python often say
oh I need static methods for this
generally not they only useful for one
particular thing and I'll show that in a
minute so here's a class method again
it's you can if you're using Python
tutor for you can use class method after
class method it's up for the decorator
syntax if not you'll have to use it at
the bottom so say we have a fancy dict
that subclass of dict and we define a
method to create a dict from a set of
keys with a single value so we don't
have to generate this list of key value
pairs we just say generate it from keys
so what I have here is we create a list
of that key value pairs and pass that to
the class and because it's a class
method and gets the actual
class past we can call it on any
subclass of fancy dict
without anything in particular happening
in the subclasses and it'll create a
subclass of fancy dick instead of a
fancy dick itself so whenever you think
oh I should have a static method and
I'll do something with my own class you
should actually use a class method and
do something with the first argument now
this is a rather silly example because
dick already has this exact thing
implemented there's already a from Keys
method that is a class method in the
dick type and it's very useful whenever
you sell plastics which is not too often
anyway at the bottom it's shown what
happens when you use it so static
methods they're not very useful the main
use is protecting dependencies from
becoming methods when you use dependency
injection as I do here in the example
you don't know what you are actually
injecting into your class if it happens
to be a method or if it happens to be a
function or something that does
something magical when used as an
attribute of a class this won't do what
you want it to do it won't do the same
thing it's calling send mail dot sent
mail where I'm now calling self dot sent
mail so you can wrap it in a static
method to prevent it from becoming an
actual method that's the only thing I've
ever seen that made sense for using
static method although as we'll see
later Python actually has a static
method itself which is a good example of
something that should have been a class
method another new feature under under
slots under under which is for emitting
the under under dict attribute for
arbitrary attributes it basically
prevents you from assigning arbitrary
attributes to another object it reduces
memory used because the dict ism
allocated and it's a more compact form
to store the same number of attributes
as a dict but it's not going to be much
faster than a dict
even for a few at
the main reason to have it is when you
want to emulate or actually implement
immutable Python classes like we have
immutable types where you don't want
attributes assigned to them arbitrarily
and they here well there's a tiny tiny
tiny class for showing slots that right
there if you actually try to assign to
something other than selves the value
either in it or anywhere else ill
actually throw an exception except for
stuff that's already in the class but I
mean under honor in it the DEF statement
won't be throwing exception of course
because Python knows that it's already
there another new thing in Python to
tattoo is the actual constructor before
python 2.2 there was just under runner
in it which is an initializer and not a
constructor it gets called after the
object has been created and it's your
job to initialize it and set the right
attributes and whatever but the data is
already there the objects already there
so under under new is called to actually
construct an object allocate method or
allocate memory for it make sure it's
alright in Python it's used actually
just for implementing immutable types
because if you have an under owner in it
set attributes it's too late because the
types are being created so it can't be
immutable if you can assign to it and
under under in it so you need to do it
in under under new and this is the
example of a static method that
shouldn't actually be a static method
it cannot be an instance method because
its job is to create the instance so
there's no instance to be a method of
yet so we donated a static method before
he added class methods in a development
cycle of python 2.2 i think it could
have been a class method but well it's
too late now it's a static method that
takes the actual classes first argument
and you need to pass it around
explicitly whenever you call the super
classes new when you want to actually
implement and render new you generally
always call object under new
you or your superclass under under new
to do the actual allocation because
there's no other way to allocate memory
in Python however you're under new
method or static method can also return
existing types existing objects you can
just return any object you want from
under under new whereas under in it
either has to return itself will return
none because there is nothing else you
can't actually change whatever it
returns under new you can return
whatever you want and that's the result
of instantiating your class there are
there's one caveat there when you return
a instance of your own class whether
it's an actual instance of your class or
a subclass of your class the under in it
is still called even if it's an already
created object that's because python
can't know that you're under under new
is returning an old object or a new
object so it always calls under under
init of course if you return something
that's not your type that's not a
subclass of your type it it knows that
it's already been initialized so it
doesn't call on run reynad so here's an
example of an under under new wrapping
in it which is an immutable type in
python we said slots to the empty list
so it doesn't get arbitrary attributes
and then in under under new we check the
value which is whatever our constructor
was called with we modulo it so it
doesn't go past 255 or 256 or whatever
and then we created we actually create
self by calling the parent class the
method as you can see here it's a static
method because even though we're calling
it on a class we're passing the class we
were passed as well
explicitly any questions so far
yeah how you define class how do you
create a class and make sure it's
immutable by not providing any of the
things that are that mutate the object
so for instance this is an easy example
because int is its own value so you're
not storing anything in the value we
don't have we don't accept arbitrary
attributes and we let our parent create
the object and it's done if you want to
not subclass a built-in immutable type
you have to do a lot more work because
you need somewhere to store the data and
then provide properties to read the data
but not write the data that's basically
how you create so you do the same thing
as here and you have some magic in here
that sets a hidden variable basically
that then properties can get out but
nobody else can can get right access to
it's not easy and it's not usually not
worth it
mostly Python classes just are just
implemented in terms of existing types
and if you want an immutable type you
either want something that is int like
string like or tuple like and you can
just subclass in string or tuple and be
done with it
any other questions all right is there
any interest in metaclasses so I mention
them all right so meta classes are these
theoretically satisfying and
mind-boggling concept where you can draw
all these graphs between what a classes
and it's meta class and what the class
of the metaclass is and then what
instance where objects it's an instance
of the the general idea is that the meta
class is the class of a class it's the
type that a class is it's whatever
implements a glass and of course I'm the
medical as is an instance of something
so the metaclass has a medic lass and
they're all in Python
the basement of class is called type and
types type is type and type is actually
an object the parent of type of parent
class of type is object and all objects
have a base class that's object so you
can see how it gets confusing of course
the type of object is type so you can
draw a very funny grass that way but
it's all you know it doesn't matter
because in Python everything is simple
and you can just you can just say the
cloud the meta class is the class that
creates the class so of course it
doesn't apply to type or object because
they're created secretly in Python by
magic but every other class you define
its meta class is that whose job it is
to create the class from that namespace
that is the code block of the class so
we go and see if yeah if we go back to
all the way up to the class here this is
all done before the meta class is even
looked at and then when this piece of
code the blue parts and green parts are
all compiled in nicely wrapped up in the
namespace executed nicely wrapped up in
the name space then that dict
is passed to the middle class along with
the name and the parents whatever you
want to subclass and it says you know
create me a class and return it and then
the result of that in sensation is your
new class
so it's practically simple and whatever
you want to use it for in Python you can
use it for the stuff that you normally
define a class to define how an instance
of the class behaves you can do the same
very same thing with the meta class and
it'll define how the class behaves so
the magic that creates for instance
functions which is hidden in the class
the stuff that calls descriptors which
is hidden in the class is actually
called by get a tour or get attribute
which is I should probably should have
mentioned under under new and under an
innate are called to construct the class
and to initialize the class that all
happens the same way you would expect so
you can override them and you can do as
many things as you want the thing they
are most useful for is post-processing a
class just doing some wonderful renaming
or mangling or other stuff with a class
after it's been defined before it's
visible to any other Python code without
requiring an explicit post-processing
step as I said you can do evil stuff in
get out or get attribute if you want
it's probably not worth it it'll just
make your code much more complex so
here's a meta class example in Python we
surplus type because it's convenient and
I think it's necessary as well you
define an under under new which is this
static method as usual I forgot to
mention you don't actually have to
explicitly make new a static method but
you can if you want to the under the
meta classes under under new gets passed
the class that is actually ourselves
because it's a static method of
ourselves or a class method of ourselves
the name of the class that needs to be
created the basis which is a tuple of
the basis that are named in the class
statement and the dict that is the
namespace that of the code object it's
just a dict with attributes so what we
do here is we go over all the attributes
we skip any that start with on the run
or because you don't want to by accident
do the wrong thing with the magic
methods and then we name mango
whatever attributes are left over by
appending or prepending foo under to
them to make them look funny we delete
the original attribute and then we at
the end we call the base class new with
the same arguments but with the modified
attributes and then to use it to use a
meta class you have to explicitly tell
Python to use a different meta class
than whatever's the default which is
type you do under under meta class on
runner is Mangal type in the class Dix
or if you want at the top of the module
now metaclasses get inherited so if you
subclass mangled class you automatically
get the mangled type as meta class if
you want a subclass and have a different
type your or a different meta class your
meta class has to be a subclass of your
superclasses
meta class so if I wanted to have a more
mangled class and with a more mangled
metaclass I have to subclass mangling
type to get a more mangling type and
have that as my meta class so any
questions there
yeah sorry that's a typo then it should
say mangling type at the bottom and of
Mangal type yes I don't have an example
right now I have some Jango code and
it's very interesting how it works in
Jango sorry the question was Jango uses
meta classes and how is that done Jango
has an API where you define a class with
various attributes to describe your data
model and then you can have some extra
classes inside the class to describe
admin options and display options and
whatever what it does is it actually
just like this it goes over all the
attributes that were the result of
executing the code inside the class
statement and examines them and the
order doesn't matter to Jango for the
most part but where it does order it
abuses the fact that when compiling a
class or executing a class it executes
stop top to bottom so it calls a field
let me see you do a field is a
particular type and the type is a is an
instantiation of a class so you say
field is in field and field two is car
field and it keeps track of in what
order those types were created by
keeping a global counter for instance so
it knows which order the fields are in
the class statement that's about the
only magic thing that the Django thing
does and then for the rest is just it
just examining whatever's in the adders
dick that gets passed at a meta class to
write down the sequel that's whatever
the database back-end needs to store and
whatever options there are etc does that
answer your question all right any other
questions
all right so I'm going to cover multiple
inheritance unless everyone here goes no
no don't ever use multiple inheritance
all right so multiple inheritance in
Python and in other languages is
something that's frequently argued
whether it's good or not or sane or
insane
well it's generally not a good idea but
occasionally especially in Python it can
make stuff a lot easier new style
objects have a different way of doing
multiple inheritance in that they use
the c3 method resolution order which is
an algorithm described I think in a
Dylan paper describing how to do when
you have multiple inheritance in
particular involving diamonds where
multiple super classes inherit from the
same super super class how to handle
that correctly and the algorithm is
pretty simple it just goes a depth-first
left-to-right search through all the
classes but then it removes all
duplicates except the last one so if a
class appears two times it'll be visited
not the first time it appears but the
last time it appears and in Python we
also have a convenience convenience e
object called super which can help you
continue method resolution
is all your parents
classes are visited after you were
visited and all your subclasses are
therefore visited before you're visited
but you might they might not be the next
base class if your superclass might not
be the next superclass to be visited and
your subclasses might not have been
visited right before you that's rather
important to realize so calling your
base class method directly saying my
parent who whatever is never right
because there's always going to be some
situation where that'll do wrong thing
and skip classes when visiting methods
so the way to do it in Python is you
have a single base class with a full
interface of whatever your tree is going
to implement so that any object can
always call whatever method it wants to
call within that tree on any other class
within that tree but in in usual cases
those those functions will probably do
nothing functions they shouldn't raise
errors because then you can safely call
them all the time
but they should if any things they
should do nothing the signature of those
methods should never change because you
cannot know which order classes will be
called in if you have to change the
signature of a method in a particular
part of the multiple inheritance tree
you should have a second master
basically in the multiple inheritance
tree and make sure that it's a separate
section of the multiple inheritance tree
and then you should have you should use
super everywhere you want to have
anything from a base class anywhere and
that can be annoying because all of your
code has to follow it in all of the
classes and you're usually not the only
one
developing all those classes so you have
to convince everyone to use super
everywhere and as I can show here using
super is not actually convenient right
now you call super passing this class
your the current class the classroom
coding in and the instance or class if
you want if you have class methods that
your you were passed you were called on
that's their returns a proxy object and
you can you can use that as if it was
cell
of to call the original method it's not
too convenient and I hope we'll have
syntax for doing super calls in Python
3.0 maybe sooner but I'm not holding my
breath any questions by this alright I'm
going to cover Unicode then if we have
time this month
so unicode it's somewhat longer topic
though no just twice as long as a
previous topic or whatever so unicode is
a standard for describing characters the
way byte strings describe bytes you say
a is represented by 65 a Unicode you say
a is code point 65 and it there's no
relation between Unicode as such and
bytes on a disk in Python that means the
oldster type the string holds bytes it's
a byte string we call it a byte string
nowadays and Unicode objects or unicode
strings they hold characters which is
for ASCII is actually the same thing but
for non ASCII it's entirely different a
Unicode has no on disk representation as
such so if you want to store Unicode and
disk or even in memory you need to use
an encoding Python internally uses
either either utf-16 or UCS for encoding
x' or ucs-2 and UCF for depending on how
you exactly define what python does but
it uses either 2 or 4 bytes to represent
each character where it's byte strings
they're always used one byte for every
character or byte when you have a byte
string and you want to have a Unicode
string the Unicode object you have to
decode the byte string into Unicode and
if you have a unicode string you want to
store it somewhere you want to pass it
over to the network or you want to write
it to disk
you have to encode the Unicode into
bytes a convenient encoding is utf-8 and
some people confuse utf-8 with Unicode
for instance Postgres the database has
an encoding called Unicode which is
actually utf-8 and not Unicode it's one
of those mistakes many people make but
utf-8 is not unicode utf-8 is a Unicode
encoding and it's unicode encoding that
looks like asking to all Americans or
people who don't care about
or funny characters but it can actually
encode all of Unicode and it does so by
basically screwing Chinese and Japanese
people by having all of their characters
be like seven or eight different bytes
so in Python Unicode is pretty
convenient except where it mixes with
strengths you can have Unicode literals
which look just like string literals
except you have a couple of more escapes
besides the normal backslash escapes and
backless oh and bachelors zero I mean
you can have backslash U which is a
short Unicode escape and the bachelor's
capital u which is a long Unicode escape
the short U has as you can see two bytes
and then the long u has four bytes and
the long u isn't really necessary until
you start working with the higher code
planes that were added last to Unicode
and everything also instead of CHR the
heart to create a single character you
have unique R which creates from a
number any character any unicode
character and we support in the compiler
at compile time unicode names you can
use backslash n and then in the curly
braces the name for any Unicode code
point Unicode defines all these names we
have them all in the interpreter at
compile time that actually results in a
single character Unicode string with the
Euro sign in there it's a single
character Unicode but when you encode it
in an encoding that supports the Euro
sign it'll look actually a entirely
different character or multiple bytes or
whatever if you want to do these name
lookups in Reverse
if you have a character you want to look
up the Unicode name the unicode data
module does that for you if you have the
name you want the actual character
Unicode data does that too so Unicode
objects they behave exactly like strings
it's very convenient you can slice them
and you actually slicing characters
instead of encoded data the length is
right you can iterate over characters
everything is great except when they mix
with non ASCII byte strings when they
mix with ASCII byte strings
Python will automatically upgrade the
bite string into a Unicode object which
is with the ASCII encoding so that works
for ASCII byte strings but if there's a
funny character in the byte string
that's not ASCII it'll blow up because
it tries to interpret it as ASCII and it
sees that it's actually not asking and
it doesn't know what you want to do with
it so don't do that another problem with
the Python approach is that the decode
and encode methods of strings and
Unicode objects are generalized they
don't just do encoding to byte string or
decoding into Unicode object you can
actually convert strings into strings
and byte strings into byte strings and
integers into whatever you want or to
integer it's it's inconvenient and I'm
not entirely sure if that should be
fixed or not but it's inconvenient when
you only care about Unicode on the other
hand they do have convenient features so
using Unicode in Python is very simple
never makes Unicode objects and byte
strings it's a very simple rule if you
do that everything will be great
except of course it's not always easy
not to make spikes in Unicode if you
write libraries you might get past the
string when you don't expect it or you
get might get past a Unicode object when
you don't expect it if you have your
applicant view right your application
you have to make sure that anywhere you
get a string you get it as Unicode
object or you get it as a byte string
and you translate it yourself
so decode best way to do it is decode
byte strings into Unicode when you get
them an encode Unicode into whatever
output you have when you're outputting
and of course you have to remember to
use the right encoding so you have to
remember what the encoding would be like
when you get input or should output and
there's no way to detect an encoding
because it just bites and there's no
marker in there that says this is utf-8
or this is a Latin one or whatever or
utf-16 for that matter
and it all looks vaguely familiar when
you're actually looking at the bytes but
that might not mean that it's the
correct thing to decode with that
encoding fortunately if you can figure
out which encoding to use Python does
have some conveniency functions and
modules the codecs module in particular
codecs module has an open function that
behaves like the built-in open function
except it takes an encoding and it'll
automatically decode data as it does you
read from it so when you read from
codecs with open objects you're actually
reading unicode and you write unicode to
it it'll automatically encode it into
whatever a coding you passed in if you
want to wrap existing streams like
sockets or files you partially read you
can use gothics the get reader or get
writer to transform the on-the-fly
transform the stream from byte strings
unicode or the other way around and
lastly when you do write stuff like that
and you're you're debugging your code
and there's some problem with mixing
Unicode and byte strings pay attention
to the exceptions because there's two
exceptions you could get there's unicode
decode error which you get when decoding
a byte string into unicode goes wrong
and there's unicode encode which is the
other way around and if you use stir dot
encode so you're trying to encode a byte
string into a Unicode encoding what it
will actually do is silently try to
decode the string first into unicode and
then encode it with the encoding you
gave it so that actually tries to apply
the default encoding which is ASCII to
stir and even though you call stir that
encode you will be getting a decode
error if it ends up that stir is not an
ASCII string so that was it that was all
my topics I'm glad we went over all them
here are some more information if you
want descriptors metaclasses and super
all described in Guido's original desk
err intro tutorial for python 2.2 which
is still very relevant iterators and
generators are
well described in under Cooling's
tutorial on functional programming you
don't have to follow the whole thing if
you don't like functional programming
but the parts about iterators and
generators are very good and if you want
to learn about writing C types the
standard documentation is great source
as well as the Python source the actual
Python modules are all in the same API
and they're very readable source even if
I do say so myself in it's highly
recommended and always the Python
standard library and the Python C code
are all great sources comes it any more
questions the previous presentation I
guess was a bike we go about the future
of a Python is there any record of that
somewhere there's like a four or five
different movies sorry it's on my left
open a little oh okay any other
questions what's the resource for module
II or
like when you're changing we're moving -
my place - an hour - to result watch
there is there like standard way and
probably
show me for one team to another from one
phase to another phase and I can start
missing it be wise like libraries it's
got to be like when you do refactoring
if I can throw that crosses are there
any tests or anything that can come
repairman</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>