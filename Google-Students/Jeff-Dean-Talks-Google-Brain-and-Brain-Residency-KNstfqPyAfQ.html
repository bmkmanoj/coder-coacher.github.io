<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jeff Dean Talks Google Brain and Brain Residency | Coder Coacher - Coaching Coders</title><meta content="Jeff Dean Talks Google Brain and Brain Residency - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Students/">Google Students</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Jeff Dean Talks Google Brain and Brain Residency</b></h2><h5 class="post__date">2016-09-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KNstfqPyAfQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone I'm Justine and I'm here
with ping Turner and Leslie Phillips who
are the program coordinators for the
brain residency program our plan today
is that ping and Leslie are going to be
moderating the chat and selecting
questions and answering them as people
go and I'm going to give a talk about
some of the research that we've been
doing in the Google brain team some of
the things that we've been doing to sort
of push the frontiers of artificial
intelligence and also talk about the
brain residency program and how that
works and we're going to be discussing
at the end how to apply for next year's
program and sort of the mechanics of
that and then at the end I'll bring in a
couple of brain resident current brain
residents to discuss their experience
and ants and we'll collectively answer
any questions that can you mostly think
should be answered live so here we go
I'm very excited about this and there's
a couple of there's gonna be a lot of
URL links in Jeff DeAnza presentation
and you can find them in the video
description box and we encourage you to
post questions throughout the
presentation I ping and I will be
moderating and answer as many as we can
okay there we go
Thanks alright so first the thing about
the Google brain team is that our
mission is basically to push the
boundaries of artificial intelligence to
make machines intelligent and then to
figure out how to use that research in
constructive ways to basically improve
people's lives build better smarter more
intelligent products develop new and
interesting directions that are now
possible given that machines can do
things more intelligently that weren't
possible before and we bring together a
really good mix of sort of computer
systems builders people with lots of
machine learning research experience and
collectively we kind of work on
difficult problems and we sort of
manifest our work in many different ways
so one is we conduct long-term research
we've published a large number of papers
in
sort of different machine learning
conferences and other kinds of
conferences we've built an open-source
systems that have helped support our
research so that we can also help the
rest of the open research community push
boundaries and work of machine learning
and artificial intelligence we've been
doing a lot of collaboration with others
at Google and alphabet other product
teams and other research teams to get
our work in the hands of many different
users and we've been training new
researchers we'd take a look on a very
large number of interns every summer in
our group and we've this year we've
started a thing called the Google brain
residency program that were about
two-and-a-half months into and we're
starting the application process for
next year's residents and so I'll tell
you more about that so over the past
decade or decade and a half we've
actually got a pretty good handle on
large-scale computer systems to store
and manipulate data basically storing
data in large data centers and running
large-scale computations over them is is
now sort of a pretty well understood art
and what we really now care about is not
just being able to move bits from one
place to it to the other but building
systems that can really get to a much
higher level of understanding things
that you would consider as kind of human
level understanding so if I showed you
as a human this this image you would
have no trouble describing that image in
a sentence or two you could say oh what
a cute little girl she's holding a pink
teddy bear and her bottle and she's
sitting in a chair and we really want
computer systems to be intelligent in
the same way that humans are we want
them to be able to understand perceptual
data like images and photographs at the
same deep level that humans have no
trouble doing
similarly we care deeply about
understanding text text is something
that sort of only humans of all the
species out there really deal with and
it's one of the reasons we're incredibly
powerful and able to communicate really
well is we have this language for shared
understanding and so we want computers
to really be able to understand text at
the same deep level that humans can so
if I showed you this query car parts for
sale
you know if you just naively looked at
how often different words occur in the
two documents you might think document
one is a great match for that query but
in truth a human would have no trouble
saying well document two is clearly much
more relevant because it's talking about
transmissions and pickup truck parts and
automobile parts and I know that's
related to car parts and selling them
and so we want deeper understanding of
textual data as well and I think one of
the things that is happening is as
computers become more capable the things
we expect from them become more advanced
right so you know these are the kinds of
queries that people want to be able to
ask of machines and some of these we can
do today with pretty advanced techniques
some of them are just kind of a bit
beyond the state of the art in terms of
what we can do but they're aspirational
in that we want to be able to build
systems to handle these kinds of
questions um so one of the things that
we've been doing in our group is using
deep neural networks for a lot of
solving a lot of these kinds of problems
so many of you are probably already
familiar with how deep neural networks
work but I'm gonna give you a very brief
integer introduction and so neural nets
have actually been around for quite some
time and one of the things that you can
think of them as is very powerful ways
of approximating very complicated
functions so not like y equals x squared
but like a function where you put in
pixels
and you get out you know a thousand
dimensional vector that predicts which
of a thousand different kinds of objects
is in that image just from the raw
pixels and one of the ways that they're
able to do this is through hierarchical
building of interesting features so if
you think about a neural net here's a
model a very simple kind of model you
might use to solve a problem where you
want to say does that image contain a
cat or a dog and so the basic way you're
going to use a neural app is you're
going to feed in the raw pixels of that
image and then it's going to sort of
progress upwards through this model and
activate some of the feature detectors
in in these layers and each of the
layers kind of builds on the layers
below it
and activates neurons these are sort of
software emulated neurons that are very
loose interpretations of how we believe
real neurons work and then finally the
model can use the high level features
that have been computed by this model to
try to make a prediction of whether that
contains a cat or a dog and there's lots
of different settings for machine
learning but one of them is what's
called supervised learning where you
have a large corpus of example data
where you have the image as input and
you have labels that a human is assigned
and says that's a cat but the dog got
the dog that's cat and for a particular
image you know we're supposed to say
this is a dog and maybe we got this
wrong so we said that's cat and so one
of the ways that these machines can
learn is through supervised learning
where you say oh no actually I need to
correct your mistakes here this should
actually say dog so I'm gonna make
little adjustments through mathematical
formula essentially using the chain rule
and back propagation which is a
technique for correcting the errors of a
model to make little adjustments
throughout the model so the next time I
see this image or an image like it I'm
more likely to say dog and that's one of
the very basic techniques that we use to
learn things we can use large
collections of labeled examples we can
use large amounts of computational power
to solve difficult problems and I'll
show you much more complicated examples
as the talk progresses so one of the
things that's been really nice about
these kinds of approaches is they're
very applicable to lot lots of different
kinds of problem in this graph you can
see how how widespread our use of deep
learning has become at Google across
lots of different kinds of product areas
so this is a plot over time of the
number of different sort of source code
directories at Google that contained
configuration files for our machine
learning training systems and you can
see there's been essentially exponential
growth in the use of these techniques
and part of that is because we've been
working on building software tools that
make using these kinds of approaches
easier and so Kent
Flo is kind of the second generation of
the system sure and this is a system
that we built that allows us to perform
the research we want to perform but it's
also quite good for deploying real
production systems based on our research
and we actually open-source this last
November and it was a joint effort of a
bunch of people in our team you can see
how many people are involved on just one
of the papers that describes the core
underlying system but it's been pretty
well received in the open-source
community as well so you can see one
measure of kind of how much interest
there is in a particular project on
github is how many people have started
or forked the project and so tensorflow
in the first 72 hours we had 50,000
people installed and we've had about a
half a million people install it since
November 2015 it was actually the most
for new repository on github in 2015
even though we only launched it in
November we're pretty proud of that so
it's been really nice to see the
external community also pick up using
tensorflow and trying lots of different
things just the other day there was a
Japanese cucumber farmer who used
tensorflow and an Arduino machine to
actually sort different varieties of
cucumbers from his cucumber farm so
machine learning is really impacting not
just sort of traditional computing
things but lots of different things
around the world and one of the really
important properties of neural nets is
that the results tend to get better if
you can throw more data at the problem
and use bigger models to train on those
larger datasets and obviously this
requires a lot more computation and also
we're doing a lot of work on finding
better algorithms to train these kinds
of models more quickly and use different
kinds of insights into what kinds of
models are more easily trained and which
kinds of models are sort of more
difficult to train on different cuts
problems so one of the things we really
emphasized in our group is the ability
to turn around research experiments
quickly as a machine learning researcher
one of the things
you really want is to get your
experiment time down low enough that you
can be incredibly productive by trying
something out getting an answer perhaps
you know in a few hours or a day and
that allows you to then figure out what
the next set of experiments are that you
to toot like to run and so we actually
emphasize in our group using large
amounts of computation to reduce the
cycle time for machine learning
experiments if you have experiments that
are gonna take you know a month or
several months to run you're essentially
not going to run those experiments or if
you do by the time they complete you've
kind of forgotten why anybody started
them in the first place and so one of
the benefits we have at Google is we can
actually take the large data centers
we've built up over the years to serve
our products we can also use the
computational resources in those data
centers to essentially Train large
models quickly and so just to illustrate
how much benefit you can get from this
here's an example where we're training
an image model and this shows you how
many hours of training have been
performed on one GPU ten GPUs or 50 GPUs
and what the accuracy of the model is so
higher is better here and you can see
that if you're able to use 50 GPUs to
train this particular model you get your
answer to the same level of accuracy
about 30 times as fast so it's not 50
times as fast but it's still a really
good benefit because that means your
experiment that would have taken a month
now takes only a day
another thing we think is really
important and one of the reasons we
built tensorflow
is that we want to be able to run these
kinds of models on not just data centers
but all kinds of different sort of
computational environments and so we've
built tensorflow to run on you know
mobile phones single machines with CPUs
or maybe a GPU card or a few GPU cards
on large distributed systems and also on
custom machine learning hardware so
Google has actually built this card that
you see in the bottom right that is a
custom processing unit for running the
kinds of models that we actually are
deploying very quickly sort of faster
than much faster than our GP or a CPU
can run them and other hardware
manufacturers are
are going to build interesting kinds of
custom hardware for neural-net models
simply because these models are very
very good at different kinds of
perceptual tasks and have been shown to
be able to do really interesting things
okay
so what are some ways that deep learning
is really having a big impact at Google
so I'm going to just kind of walk you
through a few of the product things that
we've done and then I'll walk you
through some of the research work that
we're doing and without any particular
product in mind so one of the first
areas that we worked with our speech
recognition team in is to deploy deep
neural nets in the speech recognition
system for Google so this is the system
that is active when you're talking to
your phone no you say Palo Alto
restaurants and it's supposed to just
understand what you said and know that
you so then you don't have to type
anything which is very convenient in
mobile devices and by deploying deep
neural nets in the speech recognition
system we're actually able to reduce the
word error rate very significantly more
than 30% which is the equivalent of sort
of several decades of progress in just a
year in in the speech recognition field
and so that's been really really great
another area that's been sort of very
dramatically transformed by the use of
neural nets is image recognition and
various kinds of computer vision
problems and so this is the paper that
some of our research colleagues have
published a couple of years ago about a
model called of Inception which is
actually quite accurate at doing these
sorts of things there's been a lot of
progress in this general area of better
and better
computer vision models and so you see
the progress over the past few years
before people were using neural nets for
the image net competition the error rate
in top 5 so lower is better was you know
hovering around 26 27 percent for the
last few years before this and then in
2012 Alex krajewski Ilya sutskever and
Geoffrey Hinton
who eventually ended up at Google
developed a model that
dramatically dropped the air rate so
this is Alex net to 16.4%
and you see this progression over time
has been quite dramatic you know now
we're down around three point five
percent error rate which is actually
better than human performance Andrey
Carpathia is a graduate student at
Stanford and he decided he would test
himself in a proper machine learning
setup to see what the error rate was for
humans and so he trained himself on a
set of test images for quite a while you
know 100 hours of training where he sort
of look at an image and say okay that's
a that's a border collie that's a you
know ping-pong ball and some of these
categories are quite fine-grained and
pretty difficult for humans and so he
actually with the proper you know
training process and then he would look
at the test images that he'd never seen
before and try to give the correct label
to them he actually got 5.1% errors and
a lab mate of his that he couldn't
convince to spend a hundred hours on it
but only spent ten hours got like twelve
percent error so you can see this is a
pretty difficult problem and we're
already sort of better than humans at
this particular visual task and that's
important because in in real products we
can actually use the ability that
computers now have to understand what is
in an image to do useful things for
users so Google photos is a product that
allows people to upload their photos and
you can then search your photos by
essentially just typing queries and we
understand the contents of the pic of
the the photos that you've uploaded and
can help you find your pictures of cats
or can group your photos by your
birthday party photos or pictures of
mountains and that kind of thing
another area we're really excited about
is the use of machine learning for
healthcare and we've been doing a little
bit of work in the medical imaging
domain in particular using these kinds
of computer vision models for a problem
of detecting diabetic retinopathy and
retinal images so if you go to the eye
doctor the ah the eye doctor will take a
picture of the back of your eye and will
then want to interpret you know the
little spots you see there is that a you
know is that just fine or is that early
signs of a disease called diabetic
retinopathy which can lead to blindness
and it turns out that this is a very
difficult task for for doctors they you
know generally don't agree that
well on you know whether this should be
a two or a three in fact they only agree
about 60% of the time if you asked two
different ophthalmologists to grade the
image on their rating of one two three
four or five and so we now have a
computer model that is actually
considerably better than a whole bunch
of ophthalmologists looking at the photo
of the the retinal image we're pretty
excited about this and other kinds of
health care work okay so let me switch
gears a bit and tell you a bit about
some of the recent research projects
that we've been doing in our group and
what some of them you know some of the
details behind them and I'll give you
pointers to papers were appropriate so
one of the things we care about is being
able to understand sequential data and
so Ilya sutskever Oriole venules and
Kwok Lee in our group came up with a
model called a sequence to sequence
model which is essentially taking an
input sequence and I'll show you
examples of what those sequences might
be and then using that sequence to then
predict a target sequence essentially
given the input sequence you want to
predict a probability distribution over
likely plausible target sequences and
one use of this is for language
translation you can view sentences as
one input sequence you know one word at
a time in French and then you hit a
special end of French token and then you
want the model to be trained to then
spit out the corresponding English token
and with enough training data and a
powerful enough model you can
essentially learn a complete machine
translation system from scratch that's
actually state-of-the-art quality
without ever telling the system how to
translate from one language to another
it just sort of learns to do this from
observing patterns that it sees in the
input and output training data and so
this is quite a quite a powerful model
for translation and so you know if you
look at the training process we have
this French input sentence which is sort
of think about as an encoder is trying
to encode some state and then given that
state we want to then decode from that
state into the
corresponding English sentence and so
here you see decoding one word at a time
we're going to kind of be able to decode
that and then because this is a
probabilistic model over set plausible
sentences at inference time you want to
do a little bit of a beam search for you
keep a bunch of plausible candidates in
mind and then try to find out which one
is the most probable given a little bit
of exploration of this this space and so
that's that's pretty exciting it's
actually getting very good results and
it's it's been quite useful this has
actually been deployed in the context of
our Gmail system where we can actually
use as the input sequence a message that
someone an email messages someone has
received and as the output sequences we
try to predict short replies that might
make sense in the context of that input
message and that's been pretty useful so
most of our research within the group
falls under one of these main areas and
you know I'm going to give you some
examples of most of these today but in
general we have a pretty broad set of
different kinds of things we we think
are important and some of them is very
long term research without any
particular application area in mind just
understanding the sort of theoretical
properties of machine learning models
I'll show you some examples of that some
of it is a little bit more applied work
where there's deep machine learning
problems in the context of things like
robotics or healthcare or other kinds of
areas so let's look at a few examples of
things like that so one interesting
example is that original photo I showed
you if you think of the sequence the
sequence model and instead of
initializing the state of the decoder
with a sentence you instead initialize
it with the state of a complicated
vision model that is able to actually
build very powerful high-level features
and understand what is in the pixels of
an image you can then decode by having
training data that is an image plus a
sentence about that image that humans
have
and you have some examples of those you
can actually generate a model that is
able to take a new image it's never seen
before and generate sort of quite good
captions for this they're not quite as
good as human captions like the human
captions tend to have a bit more
subtlety to them so here's an example of
a test image as the model that was not
trained on and an example of what the
human wrote about that set that image no
as I said it's a cute little girl asleep
on the sofa kind of like a stuffed bear
and here's two sentences that the model
can generate from its probability
distribution over sentences you know
it's a close-up of a child only stuffed
animal or a baby is asleep next to teddy
bear so pretty good right like five
years ago computers were definitely not
able to do anything near that level of
understanding of data from just raw
pixels and now I can't here's a few more
examples you know you see a human would
probably give a more detailed
description than a man holding a tennis
racket on tennis courts like you might
say a tennis player is about ready to
serve the ball or something so that's
where it kind of lacks some of the
subtlety of human we have when it messes
up it's kind of funny you know I assure
you there is a man flying through the
air while writing snowboard there if you
look really closely you just can't see
the snowboard but you know these models
are quite powerful another thing we're
interested in is using neural nets to
take some context text some textual data
and then a question and then be able to
answer and reason about the text that
the context text that is seen and so
here you see the building is constructed
in 2000 and burned in 2010 and a human
has no trouble answering this question
how long did the building survive and
you're like well of course it's ten
years but this is actually a pretty
difficult task for machines because you
actually have to know that those are
years and then you want to subtract them
and so we give the model the ability to
use different kinds of operations and
then from observing training data of the
form context in question as input and
then the correct answer is output it can
learn to use these operators in the
appropriate ways and pick out the little
bits of the text that are that are
important
okay so I'm gonna continue going through
more of these examples I hope you're
finding this interesting and I hope
you're getting your questions in to the
live stream and some of them are getting
answered I assume here we are right
so um another thing we're very
interested in is rather than training a
sort of bespoke network for every
particular task we we want to accomplish
we're very interested in systems where
we jointly train the model to accomplish
many different tasks so here you see an
example where we're actually you know
being able to feed in French data and be
able to translate the data feed and
images and be able to you know caption
them feed in a sentence and be able to
generate a parse tree of that sentence
and be able to accomplish all this with
a single model which shares a lot of its
features that seems like it's going to
be very very important for building
truly flexible things because it's not
often the case that you have just one
thing you care about doing you really
want a flexible system that can apply
different kinds of techniques and
different kinds of approaches and and
leverage the ability to train on
different kinds of tasks and transfer
that knowledge to other tasks another
thing we're interested in is using
computers for creative endeavors this is
sort of something that's traditionally
been uniquely human is the idea that you
can paint interesting pictures or create
new and interesting artwork or music and
we've actually been exploring the use of
machine learning techniques to produce
new and interesting artworks and so this
is a model that was developed at Google
where essentially we take a neural net
and you essentially can continue the
back propagation you would normally do
to train the model all the way into the
input pixels and so you can say take
what you're seeing and emphasize it a
bit more and so if it's
see if it's seeing ah those clouds look
a little bit like a chicken and then you
can say well if you were seeing a
chicken tell me what a chicken would
look like there and do something that
will cause it to see more chickens and
it will kind of emphasize this and
depending on where you do this in the
model you can get very strange effects
or very beautiful effects very
interesting kinds of things we're also
exploring the use of machine learning
models to generate music that's pleasing
to people hopefully it's kind of
pleasing to people now which is good
we're hoping to make it better but
that's definitely an area that we're
interested in another area that we think
is really interesting is now that
computers can see being able to combine
that ability of visual perceptual tasks
with control mechanisms for robotics and
so one of the things we believe is
pretty important and kind of unique for
robotics is that you can have a whole
bunch of robots trying different things
and they can kind of pool their
experience so unlike humans you know as
little babies grow up they kind of
independently learn motor skills and how
the world works and that kind of thing
and in the case of robotics we can
actually collect log files and and
perceptual inputs and what happened when
they move in a certain way and actually
learn in parallel by having lots of
robots so here's a robotics lab that
we've set up in our group in
collaboration with some of the robotics
people in Google X to explore the use of
large-scale parallelism in training
robots and so this particular task I'll
show you a short video the robots are
actually just learning to pick things up
and this is a this is a a supervised
task so if I'm trying to pick up my
water and I do that and I fail my
gripper closes all the way and so I get
a signal that that was a failure whereas
if I tried to do that I pick it up and I
my gripper doesn't close all the way
that's actually a success so you can
actually turn this into a supervised
learning problem and so here let's take
a look at the video we have all these
robotic arms and you can see that
they're essentially just
learning to pick things up they just try
to grab something and if they succeed
great they get a cookie and if they fail
they they they remember that they're
like oh that grip didn't work very well
for that kind of object and so we
actually just bought a bunch of variety
packs of toys and tools on Amazon and
dumped him in front of the robots and so
they they just reach out and they try to
grasp things and they've grasped
something like 700,000 optics and we
just released a large data set grasping
data set much bigger than any other open
data set for robotic grasping so other
people can play with with that another
important thing in our group is sort of
theoretical understanding of deep
networks why do they work what what
kinds of properties cause them to be
able to learn efficiently and which
kinds of properties cause them to not
we've done a fair amount of this of work
in this area this is just a quick
visualization of some of the work that
we've been doing where it turns out if
you look at in the vertical direction
here this is sort of the distribution of
weights in the initial conditions for
training a model and if the weights are
sort of very small and don't have very
much variance you get these very smooth
kinds of behaviors for a variety of
different initial conditions and that
actually turns out to be fairly hard to
learn in there's not enough sort of
variety and the kinds of things the
different units can do and if you have
very wide variance in the weights then
you get sort of much more chaotic
behavior so one of the tricks is to get
kind of roughly the right amount of
variance in your initial learning
conditions to get things so that you
explore enough in variety but you're not
sort of completely chaotic another thing
we're sort of interested in is
adversarial examples so some people in
our group looked at how could you fool
an ER lab and essentially you have a
nice clean image and an image
recognition model says that's a bird it
turns out that by doing particular
perturbed
where you know what the weights of the
train model are you can actually craft a
very subtle perturbation of the pixel
values of that image and get something
where now to a human that looks like
almost the same image but the image
classification model will say something
completely different about that thing
might say airplane or it could say you
know garbage truck or something that
looks completely different and in more
recent work people in our group actually
demonstrated that this sort of effect
can be transferred even if you take that
image you perturb it you print it you
then take a picture of it with a cell
phone camera and then you feed it for
crossfire and that still is that an
adversarial example so there's
definitely something interesting going
on there and this is one of the things
that we want to be able to understand
better as we deploy these kinds of
systems and wider and wider settings and
more generally we're very interested in
the work on how do we actually take
these kinds of intelligent systems where
they're essentially learning from data
and then being asked to operate on data
that they've never seen before
usually they behave in predictable ways
but how can we ensure that in various
ways and so there's a number of concrete
problems in AI safety as we get to
deploying these systems particularly in
you know environments like health care
or self-driving cars and robotics where
they're actually taking actions in the
world and it's not just you know I might
have mislabeled your your dog photo as a
cow and this is pretty important work we
think and one of the things we believe
strongly is that AI safety is a sort of
the responsibility of the entire
community so this is nice that we have a
bunch of different authors on this paper
from a bunch of different organizations
we think that's pretty important okay so
now I'd like to just switch gears a bit
and tell you a bit about the brain
residency program so the residency
program is something that we started
last year and I'll tell you about the
details but we're very excited about it
because it really brings in people with
a wide variety of different kinds of
backgrounds and new ideas for research
directions into our group and has those
people
we'll work side-by-side with our
researchers to learn how to conduct
research to take their ideas and explore
them in the context of you know are our
research group and it's been a really
successful program so far we've been
running the program for about
two-and-a-half months since the first
batch of residents showed up in June
this year and we're really excited about
it and so we're gonna be running the
program again next year and what it is
practically is basically a 12-month role
within our group with salary and
benefits so you're paid like a software
engineer it's good and it's really an
opportunity we think to to take a career
that you think you might want to have in
deep learning research and get a lot of
experience in applying these kinds of
techniques and in doing learning how to
conduct research and at the end of the
program our hope is that residents will
have published a couple of papers
hopefully in sort of top machine
learning conferences are posted them on
archive and hopefully be able to apply
to strong graduate programs or be
eligible for conversion into full time
machine learning roles at Google and so
we have a little bit of information
about the first class of residence the
educational mix tends to be a mix of
people with bachelor's degrees and some
have masters and some have PhDs or
postdocs and about half are coming to us
directly from from school and half have
some industry experience and one of the
things I really like is that the the
fields of study that are represented or
not just computer science we have about
a third computer scientists you know
about a third people people with
backgrounds in mathematics or statistics
and the rest are kind of a mix of other
different kinds of science backgrounds
physics biology health economics and I
think that mix really adds to the
diversity of research ideas in our group
so these are just a few of the examples
of different kinds of resident projects
that some of the residents with us now
are undertaking and you can see there's
a pretty good variety some are in
robotics some are in genetics some are
sort of on scalability aspect summer--
sort of more theoretical understanding
and you know this is just a sample
there's probably 30 or 40 different
projects each resident typically has one
project a few of them have two that
they're working on simultaneously in
terms of the application criteria
basically we want people who have the
requisite background to be successful in
doing deep learning research so
basically that means you you need a
degree in some stem field typically or
equivalent experience so we encourage
people with diverse or non-traditional
backgrounds and experiences to apply to
our program one of the things we're
seeing is that a lot of people in other
sort of science fields are seeing that
this kind of approach can really make a
big difference in their field of science
and so they want to learn about how to
use these kinds of approaches and say
genetics or you know other kinds of
endeavors and we think that's really
exciting and important and then
essentially some way of presenting
evidence that you can program and that
you've taken appropriate prerequisite
courses so calculus probability
statistics these kinds of things and
ideally you demonstrate to us that you
have a strong interest in the field this
might be a research project you've done
at school or some papers you've read and
that kind of struck you is interesting
and maybe you write us a little summary
and your cover letter lots of different
ways of doing this but essentially
something that makes us believe that you
are really interested in learning how to
do deep learning research this is the
timeline this is all on the website but
essentially applications are open today
and until January 13th of next year and
that's the last day to submit
applications we also ask for letters of
reference and so your letter reference
writers should get them in ideally by
January 13th but will accept them a
little bit after that but your
application materials have to be in by
the 13th in February in March we'll be
doing some interviews for sort of the
final selection of our residents and
March and April will be telling people
yes or no you're in the program and then
will expect you to decide by roughly
April whether you're gonna be joining us
last year we had a very good acceptance
rate Pete offers that we made and then
in July the program is gonna begin
we're actually shifting the start date
by a little bit to accommodate different
kinds of college schedules so in
conclusion deep learning is really
making really significant strides in a
lot of fields of artificial intelligence
and machine learning speech vision and
language understanding and robotics and
healthcare all of these things are
really making significant progress in
the last few years and our residency
program is really designed to take
people who want to learn about how to do
research in this field and to come and
join us for a year and we're really
excited there's a couple of frequently
asked questions there's probably more we
will sponsor visas we'll do our best to
sort of try to to get you the right visa
as long you just have to be eligible to
work in the US if we can get you the
right visa the basically the first
couple of weeks in the program are sort
of introductory and orientation kinds of
lectures but after that it's basically a
very hands-on one-on-one or one on two
kind of mentoring program where you work
on an individual research project
project and mentor assignments basically
there's a lot of flexibility we have
some ideas about things we think would
be interesting residents come with their
own ideas and we kind of sort it all out
so now I would like to introduce a
couple of our residents so let me bring
them on here so we have jasmine and I
have a little slide that shows their
background so there are two of our
residents that have just started in the
last two and a half months so maybe
Jasmine you can tell us about a little
bit about how I just graduated college
and I majored in neuroscience and
computer science the University of
Pittsburgh I chose these two things
because I really would like to do work
at the intersection of these two fields
um and I became interested in deep
learning because I was really inspired
by all these recent advances that I was
Jeff talked about a lot of them image
recognition the classification and
natural language processing and so I
wanted to get involved because I hope to
in the future make these great strides
at the intersection of deep learning and
neuroscience cool yeah I'm many I did my
undergrad at UC Berkeley and she has
spent a year at Stanford in research
information extraction a couple years in
industry as an engineer before I joined
the residency program I was actually
working in Japan and Korea for
healthcare startup and on the side I
always did my own projects of deep
learning and try to keep research so I
thought that presented program was a
great opportunity to do this full-time
oh and you want to tell us about what
your experience has been so far like
what kinds of things that surprised you
sorry yeah the experience has been great
um I was surprised because it's a lot
still like being at school but in the
best way so I was like oh I'm gonna work
the company but actually I'm still
learning so much every day at this
alarming rate and so I have to make
projects right now the first I'm looking
at different era and architectures so
Alice teens your youth vanilla and so
I'm looking at the trade-offs between
capacity and learn ability for these
different architectures of different
sizes and then my other project is the
ultimate goal is protein structure
prediction using deep learning but we're
starting small so right now we are
working on secondary structure
prediction from amino acid sequence cool
so one kind of more theoretical problem
and one sciency project cool yeah I'm
working on improving sequence of
sequence arm ends for conversation
models essentially trying to build
really good systems that can have
natural conversation I'm working on that
with her luckily it was one of the
authors of the original sequence of
signals paper I think it's an exciting
field because a few years ago we had no
idea how to build systems but then the
last couple of years we made rapid
progress so now they a lot of open
research problems I research challenges
that lead to a lot of improvements yeah
so at this point I believe our
moderators can
Leslee selected a bunch of questions so
they're going to essentially shout them
from off-screen there and we're going to
do our best to answer them great
excellent so people are very curious to
know what the interview process well
maybe I'll describe the weeding out
process when we get down to the people
who interview and so we get a large
number of applicants for last year we
had more than 2,000 applicants for the
27 spots we ended up taking it's a lot
of work to go through all these
applications but we sort of divided it
up among all of our research people I
looked at 800 of them and each one was
read by multiple people and essentially
we're looking for those people who have
the right background in qualifications
but also that that sort of interesting
you know background that really makes us
think they would benefit a lot from
being in the program and so we've
narrowed that down to about a hundred
and forty people that we did sort of a
phone or video interview with and then
brought that down to sixty people that
we brought on site you guys can tell
about the gunsight oh yeah the on-site
interviews were great we got to meet
research scientists at brain and
believed there was two interviews and we
were on site one was a coding interview
a technical interview and then the other
was a research interview where we all
just got an opportunity to talk with
somebody on brain about something that
we were working on or had worked on in
the past probably roughly the model will
fall out for this year it's great and
people are wondering what is the typical
educational and professional profile of
a Google brain resident and is there an
ideal profile yeah I think I kind of
covered that in my talk we're actually
the backgrounds are very quite very you
know we have a lot of people that are
fresh out of a bachelor's program we
have some people who've already done a
PhD or a postdoc and want to treat this
more as a a postdoc in our research
group and the Ranger fee
the big study is also quite varied
neuroscience denny's science background
a lot of people have other kinds of math
or statistics background so there's no
one profile that's right for the program
we're looking actually for that
diversity of background an opinion and
an experience that actually sort of
enriches our own research great can you
tell us what level of research
experience and machine learning and
neural networks is required so we don't
have any hard requirements we do want
people who ideally have got at least
some experience because we think they'll
they'll get up to speed and be able to
be productive in doing their own
research more more quickly so ideally
they would be you know someone who you
know maybe has done a little bit of
research or they've at least taken a
machine learning class at school or on
their own with some of these very very
popular online courses at Coursera
Udacity or something to to at least give
you a little bit of background some
people obviously have a lot more
experience but we're really looking for
that diversity of different kinds of
candidates you know people who you know
might be thinking about going to
graduate school people who have already
finished graduate school with a lot of
experience the other question is with
the projects that one undertakes during
the Google bring residency resemble more
of an academic research program or a
commercial R&amp;amp;D goal
so I guess both well having only
experience being academic side of things
I've never been on an R&amp;amp;D project at
Google
but this is very much similar so I would
say you're reading a lot of papers and
you're catching yourself up in the area
and there's lots of open collaboration
between different members on brain and
between you and your mentor and yeah the
expectation is nearly all the residency
projects will be published on our
or submitted to top machine learning
conferences and hopefully accept it
there and will appear as sort of normal
academic style research projects in many
cases we'll open source the code that's
really affiliated with with the project
that allow others to reproduce the
results we think it's actually really
important to engage with the whole
machine learning stamping or not sort of
keep things to ourselves great and so
people are curious about project
selection so how did you go about
exploring projects and ultimately
deciding what to work on yeah I can take
that I think is a fast pass to a lot of
talks at Google we can attend by current
researchers to talk about their project
and then we have a we had a document
that has a long list of projects that
available you can also come up with your
own if you want to and you can talk to
people who are working on these projects
essentially find a mentor to work with
find a group to work with
and yeah it's pretty it's pretty
flexible so whatever you're interested
in there usually is something there that
somebody good yeah essentially before
the residents started this year we had
researchers generate a lot of
interesting ideas that they thought
would be worth exploring working with a
resident and so we produced you know 60
or 70 such ideas and in many cases as a
resident where pic would say hey I'm
interested in that and they get paired
up with the mentor in many cases they'd
say that sounds interesting but what
about this little twist and they kind of
agree on a slightly different project
but at least it kind of got the
discussion started and in other cases
residents came in with very clear ideas
about what they wanted to work on it and
found mentors who were you know happy to
work with them on that great um somebody
to you Denny and Jasmine can you tell us
what is your favorite part of the
residency so far I think I think funny
is that I feel like I'm still learning
so much like every day coming from grad
school I feel it's like they're really
good and why I'm in for right it feels
like that's cool but you also see a lot
of different viewpoints from like the
perspective of how these systems output
production so I feel like I'm learning a
lot of new things that I didn't
necessarily think that's well um I agree
wholeheartedly I'm learning so much and
everybody around me is very smart one of
my favorite things that for example a
lot of the brain residents come from
different backgrounds and so you can
have somebody who has their PhD in
physics and they can give you a physics
perspective of these types of concepts
that we talk about every day and yeah
you can learn a lot from everybody
either it's just sitting right next to
you I think my sense is the residents
have kind of great um so I guess people
are also very curious I know you touched
on this already how to prepare for
interviews or if there's one thing in
particular you would encourage people to
submit along with their application what
would that be I think it's good to get
some basic knowledge of how deep
learning works maybe how physical works
though the basic basic project with it
just to get your hands dirty a little
bit yeah that's my advice I read I think
you should have maybe if you have no
formal training in machine learning or
deep learning you should at least try
and go play with it basically even if
you haven't as of today you can start
now and then have it ready in time for
consultation to see if something to talk
about and you have something that you
can show your interest with right
there's a really wide variety of sort of
educational materials all kinds on the
web few things like everything from the
tensorflow
tutorials that come with the tent employ
distribution are quite good at
introducing you know particular kinds of
machine learning models there's you know
younger fellow and your field engineer
and Aaron Colville's
deep learning textbook is quite good
there's Jeff Hamptons Coursera course
which has great videos about neural nets
and earnings machine learning more
general machine learning course at
Coursera all of these things are useful
I think if you have some artifact that
you can point to and say here's
something I did with machine learning
maybe it's not like a full-fledged
research project but something you've
tried and you've plagued with that's
gonna be useful considering grad school
can you maybe tell us a little bit more
about what went into your decision
between that and I guess just talking
about how that experience now a BA yeah
um so like Moses and I'm planning on
applying to grad school I did apply to
grad school actually the last round so
at the same time when I was applying for
this program um and that was fine I was
planning to go straight into grad school
but in your applications you have to
write a personal statement and I kind of
just discovered deep learning and I was
just introduced to machine learning I
knew I really wanted to do it but I had
nothing concrete to really talk about
because I was like I would just like to
do this thing but I have no experience
in it so this program is excellent
because now when I'm writing my research
statements in the future I will have
these very concrete projects that I've
worked on and now I know for sure that I
do very much enjoys e-learning and it's
something that I would like to pursue in
the future and yeah so thank you all for
tuning in this is a unique experience we
have very hot lights boiling at all and
we hope you've enjoyed the preservation
I would refer you back to the websites
so if you go there you know these the
brain GTO slash brain is our general
team website which shows you a lot about
the research that we've been doing GTO
slash brain residency has all the
information about the brain residency
program and we'll take you to you know
more questions that have been answered
about what the programs like and how to
apply and then there's an email contact
to address brain - residency at
google.com where opinion does Lee and
many others will be standing by to
answer your questions so we hope to get
lots of applications and you look
forward to our
here's a class of residents we're very
excited thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>