<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building a self driving RC car by Bert Jan Schrijver and Tim van Eijndhoven | Coder Coacher - Coaching Coders</title><meta content="Building a self driving RC car by Bert Jan Schrijver and Tim van Eijndhoven - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building a self driving RC car by Bert Jan Schrijver and Tim van Eijndhoven</b></h2><h5 class="post__date">2017-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OL0vg1WmI6I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right welcome everybody and thanks
for joining Tim and me at building a
self-driving RC car who would have
thought when you were playing to go to
deaf folks that you were sitting in a
room with I don't know a few hundred
people looking at two grown-up men and
that quiet toy car Wow here we go so we
might as well make the best of it before
we introduce ourselves we're going to
start with a demo so we're going to spin
things completely around start with the
accelerating demo right away and I must
say that this is the scariest damn I've
ever done
we stupidly when I demo stuff my hands
are on the keyboard and I can control
what's going on and in this case I can't
touch the keyboard because the car
should drive itself right so if the car
filmed here what you're seeing on screen
is our web interface where you can
control it we'll talk all about this
later and you're active now is that the
car will I will start the car it should
drive itself stay between the white
lines and then stop when it's not seeing
any lines anymore so everyone will cross
their fingers now right see if it works
if you're up front I would advise you to
lift up your legs because we have well
well we have an idea what's going to
happen but unexpected things happen all
the time so let's see when we connect it
here we go
we were sweating it a little because
we've practiced with floors that are
even have an even color like the black
carpet up there and the floor here is
spotty
so it was detecting all these white
spots as little white things that might
be lines so it was a bit troubling but
we luckily we could tweak the thresholds
of the line detection a bit but a lot of
more about that later
so let's start with with the beginning
my name is victims - I'm a soft across
from the J point in the Netherlands an
agile point we typically build stuff for
various clients router Netherlands using
Java web stuff and all stuff I also work
at open value which is small Java
startup in Netherlands and I run the NL
jerk which this Java user group I know
we're not in the Netherlands without any
n object members in here all right way
to go I'm here together with Tim yes my
name is Tim's 912 I also work at J point
and I'm currently hired by a mom we're
an educational publisher where we do
other cool stuff so is this what we do
all day
building self-driving cars no I don't do
well I've been for the past days but
there was got a more conference to
riffin delivery so how did this all
start as I said we work at a point and a
J point we typically do a fairly serious
stuff for clients so job development web
development bit of contingent livery
DevOps you could even call it enterprise
but well just stuff stuff for clients in
the Netherlands and everything every now
and I want to do something completely
different so we get around with the
whole team and we spend a day working on
our project so for liking so one or one
of our colleagues once transformed his
Roomba vacuum into a control ball device
that could play the dead march was a day
well spent
we've done some other miscellaneous
projects but one of the coaching we
worked on is this protein I think
actually the idea came from our bosses
who said well let's let's do something
cool and challenge ourselves a bit and
dive into them feel that we don't have
any experience with and see if we can
make a car to drive itself so it started
with this we formed four teams and we
all got a basic
RC car kit and some hardware and that
was it we had a laptop and the internet
to try to find out how to how to make it
work so this is the challenge we set
four teams every team gets an RC car kit
just a basic thing you can buy in the
stores or pick up online I think it will
set you back around 250 or maybe 200
euros
we got a fixed budget for four sensors
and other hardware on the car of 150
euros and then there's three races the
first race is just a straight line so we
start in a start zone there's a starting
light and when the light goes off the
car needs to drive then it needs to
follow the two lines for 50 meters and
then in the end there's a stopping zone
with one meter wide where the car needs
to stop automatically so this race we've
already done then the next race which is
scheduled for March is there we actually
corners we need to navigate to the track
and third race we have multiple cars on
the track that need to avoid each other
or I don't know if you're stronger than
your card and avoiding isn't necessarily
and what you need to do but you need to
navigate yourself with multiple cars on
the racetrack with corners so this is
what we have it's a fairly basic RC car
kit let me grab it real quick it has
wheels like most cars for even it has a
servo to control the wheels it has a an
engine a speed control that will make
the car drive and then a frame and a
battery to to power the whole thing so
then we need something to control it and
every hobby project gets cooler if you
throw in a cup of raspberry pies right
so we already buy tree laying around
which is actually pretty good for
particular I guess because it's small
it's light it doesn't consume too much
energy and it's fairly powerful and not
trouble running JVM on there so it needs
power so what we did is take a small
converter that will draw power from the
car battery which is 11 volts and then
convert it to a 5 volt USB connection so
we can PI we can power the PI from the
car battery then we need something to
run it on we we like Java so we run on
the Java platform which also runs on
vertex which we were both familiar with
from my work at Marburg and vertexes a
toolkit for building reactive stuff for
very general purpose non opinionated it
is event driven and it's non-blocking
and we mainly chose it because it's very
lightweight both in terms of size and in
terms of memory and resource consumption
it is polyglot so we had the idea of
maybe using different languages in the
beginning we ended up by using only Java
and the main thing first at first it has
a disability vendors so with further quu
program you could call services and
these services are all connected
together to divert ex-offenders so you
can send messages to each other and this
event this also works over the network
and even all the way to the browser so
by using vertexes with a few lines of
code we can have call running on the
Raspberry Pi on the car we can have code
running on our laptop and we have code
running in the browser and we can easily
send messages through all those those
stations and the dispute nature effort
actually helps us in terms of fast
development so we can when we're
developing we can run only the the core
control of the car on the PI and run all
the rest on a laptop and whenever we
want to move to well let's call
production or more definitely phase we
can move services from the laptop to the
car by just deploying them there they
all stay connected via DFM bus so if
you're interesting vertex are a lot of
fun work with vertex I did a talk on it
once it's on YouTube you can go out and
watch it down so then we need to we have
two pi running there we need to connect
it to the car so there's two things that
a car need to do it needs to drive so
there's an engine and it needs to steer
so there's a there's a steering servo so
these are typically controlled by a
wireless receiver so you have receiver
in the car you have a remote control
with two channels for backward left
right and then this receiver sends
signals to the servo which is like a
small motor that can go meter both ways
it's connected to the wheels so the
wheels can can turn and to the speed
controller and a speed controller feeds
power into the engine which is either no
power and still or maximum power one way
it's going maximum speed forward maximum
power the other way or anything in
between so we focus up to the
P airports of the raspberry pi TP l
stands for general purpose i/o which
stands for general purpose input output
and the GPIO pins are pins that you can
connect all sorts of stuff talk to your
two Raspberry Pi so there's two pins
with with a current on there either five
false or 3.3 volts there's a few pins
with ground and there's a lot of data
pins so typically you connect the device
to the 540 volt to the ground and to a
data data pin so then we need to we have
them connected and then we need to make
the Raspberry Pi talk to the steering
servo and to the speed controller and
this is typically done by a signal
called PWM PWM is pulse width modulation
pulse width modulation sense repeating
pulses and it varies the width so it
uses this to basic certain numbers over
over a wire and we use the utility
called servo blaster for this sort of
loss versus small Linux utility it runs
as a daemon on Linux and creates the
device the server pastor awake you can
send commands to and I can control up to
eight servos in our terms we've hooked
up an operative suit up three things one
is the steering servo one is the speed
controller which is also controlled pwm
and one is a lead which turns out to
also turn on when we send the PWM signal
to it so it was nice and comfy for us so
let's say we want to hook up something
to serve our number zero then we need to
be a GPIO port 4 so if we go back to the
diagram we would need 5 volt because the
servos 0.05 fault we need a ground
connection and data connection for so
this is what is your voice is hooked up
to and if you have this you can send
commands you can just say echo 0 is 152
def servo blaster and then servo glass
will send PDM signal so that's all you
need to basically control car serve last
resort sources upon get up for you to
grab and this is actually I think this
is very powerful piece of software
because you can you can just use this to
control whatever servos you have with
your Raspberry Pi you can create a tank
you create a webcam you can create an
automated door lock but a servo to pull
the door so for me it was a
nice piece of suffered to look at and so
then our first prototype was we had a
the Raspberry Pi serve last one there we
would have a Wi-Fi connection to the PI
where laptop login over SSH and then we
were just typing echo 0 is 252 dev
server blossom and then it would start
driving and it wouldn't stop anymore so
then we type echo something quick that
may go left and act with something else
go go right and echo something else I
would stop and we really quickly notice
that this approach didn't really scale
because we ended up running most of the
time to running after the car to go
fetch it and we have a fairly large hole
next to office and this is where we
really need to exercise a little so we
figured out that we need to work on some
safety measures first so what we're
doing is the control suffer the still
running on the laptop is sending a
heartbeat signal every 100 milliseconds
to the PI and have to PI this and
receive I don't know two or three of
these signals then we'll shut down just
as a safety measure when the Wi-Fi
connection is a bit spotty or maybe the
wife connection drops or or the laptop
shuts down so safety even in such a
small situation was fairly important for
us and we need to see so we grab the
rest provide camera you can pick them up
for somewhat 30 euros hook them up to
the board and then you can get a camera
feed and for this we used our PI cam web
interface which is a linux utility you
can run on your PI it will connect to
def video and then send out a video feed
over HTTP so you can do mjpeg streaming
from the device and it has a weapon to
face to configure video settings so you
can set stuff like white balance the
metering mode brightness saturation so
this helps in in terms of tweaking the
video image because it turns out that
since we only rely on video having a
clear video image is really important
because you're very susceptible to to
light differences we even noticed here
that the spots in the floor were
troubling for so we need to tweak right
before we start so then I would say
we're ready to drive right we have video
image and we can control it with the
keyboard and
and we're ready to get going but
eventually want to make a drive herself
so is it this is how our interface looks
like we have the camera image we have
some controls here you can just put
left-right up-down and we have the
offense going over to 30 vendors below
and then we have some other images here
that seem to do some stuff with lines
and I believe that Tim is going to share
all about this yes so we could drive the
car now by hand and the whole challenge
was to let it drive by itself so we
needed to to actually let it think for
itself on how to drive so we decided
because we had a limited budget of
course to go with the with the purely
the optics right the camera in order to
detect where the road was and how the
car should should navigate and and in
order to do that we needed to interpret
the image right so you mean you look at
an image and you see oh that's wide line
so that's the boundary and that's the
other boundary and that's that means
that the roads in between all we needed
to to let the dakar do that as well so
we needed some sort of image processing
and while we we knew about OpenCV and
it's well to our knowledge is the most
widely used open computer vision library
it's written in C++
it has Java interfaces which was
important for us as well and there are
many many resources available online on
using open CV for all different sorts of
of computer vision but also many on the
subject of Lane detection so basically
what we do in image processing pipeline
is two major steps so the first one is
it's actually to find the edges in an
image and we use that we do that using a
canny edge detection which is an
algorithm which dates back to I think
the 70s so it's it's way old but it's
still about the most widely used
algorithm to detect in well edges in an
image and then we needed to convert
those edges into lines so to interpret
where where our lines
in our image and for that we use the Q
line transform and actually we use the
probabilistic version of it and the only
reason why is because we read somewhere
that is faster so and we use do to those
two things to detect the lines and then
as you can see in the top right image is
that there's on in the top right corner
there's a horizontal line right so it
detects all lines in an image so not
only the ones that we we want but it
detects all so then we filter them and
we can do that because we know that the
image will look at the road in their
perspective so we know that the road is
doing this right it will join join to
the top so we can actually filter the
lines based on a predicted angle with
some sort of margin and then we can
determine where the lane sentries by by
doing some geometry and we can determine
what's the angle of the car and what
should we do so let's go into some of
the code and different combo sorry I'm
sorry so basically what we have is a
class that does the lane detection in
the image and because a video feed is
nothing more than a stream of images so
in order to detect the lane the first
thing we do is we determine a region of
interest because the the image will
contain a horizon and above the horizon
is well at this point it's not
interesting for us all we need to know
is to see what's on the ground right we
need to find a road on the ground so we
can drop the top half of the of the
image which is well half the image
processing which means speed so we take
the bottom half of the image to process
and then we have what we call a line
extractor and this class where it
basically takes two arguments one is the
canny edge detector and the other is the
u lines detector which runs on top of
that
it takes a configuration to set some
parameters and this can you etch
detector that we have basically as a
wrapper around a OpenCV call it's it's
nothing more than that so this this line
then that I'm that I'm currently a
highlighting is the is d call to the
opencv library to do a kind of
processing on an image and this produces
that that black and white image that we
that we showed earlier so this is
running on a native C code yellow ops
via its native C code
it took us I don't know about a day to
compile unrest reliably yeah that has
its own yet yes so and then we have the
the line detector which contains a bit
more code because actually we we go from
the domain of OpenCV which is a like
make matrix and a factors into the well
the objects that we want to use in a
java code which align but but still the
whole processing is again just a
one-line call to OpenCV so in order to
do the processing on the image that we
do to detect lines it's only to call so
obviously so that's well I think it's
pretty pretty easy to to do actually as
long as you know which which calls to
make right yeah that takes some finding
out that's what all the code you write I
guess yep it's not a typing that's
important activity exactly so and then
we have a delay detector so this takes
the input lines that we that we've
detected and actually it uses to two
classes like the lane left boundary and
lane right boundary which filter those
lines based on an angle so the expected
angle that what we do for and for the
left the left line and the right line
and the tolerance so basically that
Allah that gives us two sets of or two
lines that that define the whole well
lane that we let me drive in no wait I'm
not finished yet
so now that we have this we can actually
filter death that stuff and do some
calculations on it so now that we have
the lane we can we can actually
calculate the important stuff for us to
navigate so which is basically the
annual which is what we use it at the
moment for for navigating so we see that
the car is at an angle on the road and
then we determine what angle should we
steer in order to go straight true so
basically that's our our whole image
processing pipeline now going back to my
presentation
we we actually thought we needed an
architecture right who does have every
project needs an architecture
so this is our architecture diagram and
do these names make any sense for anyone
shout it dukes offensive fellas right so
there was our team name The Dukes of
Hazzard so we thought it would be a
great idea to call our services to the
characters in the show I can tell you
now that's not a good design choice
because every time we have to look into
what's doing what again I need to openly
read me every time to see which serves I
need to start up so right great idea not
really so the the code that I showed you
is in Daisy actually so Daisy takes the
input from the camera and does the image
processing on that and we have a
debugging surface Rosco which actually
ties into Daisy and then provides those
images to our UI this is not necessary
for driving but it's necessary for us to
see what's happening Daisy does this
analysis and and then calculates like
the angle and the distance that we that
we have on the lane and then it's
communicated to Luke because Luke always
was a smart one in the in the series
right so he is the one that actually
gets told the this is how the road looks
and and he decides what to do with
navigation which he then instructs the
steering speed to Bo who always drove
generally so that's that's the surface
that gets the import phone from Luke
that says well we need to steer like a
certain amount of degrees to the right
to the left and we need to accelerate or
decelerate and then it uses a library
that in Java which actually echoes the
commands to serve a blaster to do the
steering inputs and the the engine
inputs on the other end we have Boss
Hogg which is our UI so that's the the
whole puppet master when we do this this
ourselves and when whenever it we have
to control to start or stop the
autopilot one from from Luke Wright and
the other end we have the manual inputs
which get sent directly to Bo
in order to steer the car and it sends
the heartbeat to flash flash the dog on
a series and he's the one that that does
the heartbeat heartbeat control and that
actually well lights up the led to show
that it's connected or dense it when
it's disconnected and it whenever it
disconnects it will stop the engine so
that's our architecture and and these
two these two areas that we have the
right area is the stuff that runs on the
car and the stuff and left was runs on
the laptop so that's that's basically
our architecture for a for software for
a self-driving car thanks for the
explanation that makes a lot sense to me
now
the first time I'm hearing good so it
was designed after quite a few beers so
I can I can tell you I can't remember so
now that we have this right it must be
awesome I mean we have to take this
software and put it into actually our
boss as a Tesla so maybe we can upload
it there right to see if it works yes to
work
what could ever happen yes so well we
build a Tesla right this is exactly the
same so this is our expectation fully
self-driving automated autonomous
awesome car
our reality is more like this it drives
itself who when we're lucky but yeah
there's lots of rooms to improve that's
I think it's supposed to quite you to
look at it so here are some videos of
you know us building this thing so this
is in my kitchen and we've built a
full-fledged racetrack here so you see
the the lines here's the starting allied
and then here below is the stopping zone
so we're doing an entire race in to me
actually it has to autonomously look at
the starting light as well so right when
the light dims it should start yeah so
let's see if this works here we go
so what is this is just it's a major
success for us
yes definitely yeah it uh it uh it looks
at the starlight then it starts driving
and then we were it stops in the any
stopping sound so that's that's right
let me see if we could get some audio
there because I think we forgot to set
this up should we send this over HDMI
audio or over Jack yeah cut it because
there's one video that I really want you
to and you hear the audio in it's one of
the final ones
okay so well this is this is the first
one then let's move on to the second one
this this is a bit longer track we're
doing is is practicing whether it can
drive over long or a longer distance
so you see if making small steering
adjustments which which works fine but
what we're seeing is that when we're
driving longer distance the car tends to
work a bit because you're steering based
on the angle that the car is making with
the road so it's it's it's approaching
the the lines of the road an angle then
it steers the opposite direction and we
we kind of oversteer a bit so then we
need to compensate it again and then it
starts working good so we did some some
damping to do this but there's some room
to improve for him still looks like a
drunk driver yeah definitely but
autonomous drunk driver I said it's
better that's right so so while we were
recording this
there was a obviously in a big hole so
that there typically there are events
there and expositions and I was I think
was like a baby expectation where you
could you know buy also for your baby
and this is where we were driving so
that the video just saw was recorded
here and there's there's a small pass
through here so our car was so smart and
steering so well that it ended up going
in there going through here navigating
swiftly between those two plywood pieces
and driving onto the baby show and I
accident it didn't have any hit anything
it didn't hit what I'm thinking is that
maybe it you know so these are lines and
I don't know but I ended up running into
the baby show and all kind of amazed
people there about this little car was
you know it didn't have anything so it
behaved well but still interesting stuff
can happen so this is a bit more
advanced setup are we driving inside our
office and there's some different
lighting conditions there we've had some
small curves in the inner roads and
after a few takes it also worked all
right
it's about to stop at the most important
space in the office the bar obviously so
as I said it took us a few takes and I
think it's a it's a good that we also
show one of the situations where we kind
of miss it
so yeah this happens all the time we
were discussing what cost is maybe it's
all the reflection of the lines in the
mirror here or maybe some shade or
something it's it's fairly hard to debug
since then you need to be looking at the
the output all the time so there's
building this we got a lot more respect
for you know test landed likes about
hardware how they do it but but still we
were fairly happy with the result
so with our first race which was I think
last year we did a day of hacking in the
office and practicing and driving in the
hole under perfect lighting conditions
and then for some reason we decided
there was good at yeah genius idiot dude
race at night and what happens typically
at night it gets dark and now we
couldn't see the road anymore so we
brought some cars in some some big
lights but it was it was horrible
because you know there were all kinds of
shades on the track and if we could set
the brightness good for one portion of
the track but then we fill on motor
portion so with of those four teams one
car then didn't actually drive at all
the other was only manually controlled
and two cars actually drove
automatically so we raced with those two
cars the auto car actually made it all
the way to the end in the in the track
but it switch lanes halfway so then we
counted to this inside it did in sound
track and our car didn't make it to the
end at all but it drove maybe to 2
meters further than then your car so
that's why we won but I need to say that
we actually thought that the or car
wasn't that across so this car was
created by hice who is actually in a
room case and up guys let's give a round
of applause for the actually winning car
guys
we have a lot more racism from the first
foot and also a lot more a lot more work
but this was a fun thing to do so would
you would you drive this car if it was
driving in rubles nobody know I don't
trust my own programming in this but
that's an actual problem right because
now we have all these cars in the road
which which actually do self-driving
more or less so this is a real-world
problem and there are different
solutions for it so let's look at
self-driving in the real world well
there actually there's a categorization
of the autonomous city of a vehicle at
love zero you have nothing right yes all
do do I think many only and at level one
you have a car that can handle one task
at a time so it can do an emergency stop
when a pedestrian crosses or and it has
like the adaptive cruise control like
that sort of stuff and then you have
left two cars which can do two automated
functions so probably a car that not
only can can do the cruise control stuff
but can also keep the car in lane and
then at level three you have cars that
can actually do dynamic driving tasks
right so they can switch lanes and and
all sort of stuff without human
intervention a human still needs to pay
attention to the road it has to has to
be there to intervene but the car can do
stuff autonomously so now I think most
cars on the road nowadays are either
level 1 or level 2 cars and then you
have the cars like the Tesla's which are
actually or left to level 3 in the
under certain circumstances and then you
have level four and that's where way
Moe's at at the moment
so a couple of weeks ago they announced
that in Phoenix they will drive
driverless cars around so you can use
them as a taxi and there is no one
behind the wheel so the car can drive
itself fully autonomously there are
videos of it on the internet it's it's
really impressive and it's not like
there's a guy in the front seat dressed
as a car no it's not the chair yeah
there's just it's it's it's really
awkward to see a car coming up to an
intersection and then to see the whole
front seating empty and then it just
just crosses it's amazing for me I think
for me it already is race you see when
I'm when I'm car from Great Britain is
driving next to me alright yeah
so and then and then level fire those
are cars that can do it in in like any
situation how do I need level five cars
around no no not that I know but that's
that would be a pretty impressive feat I
mean this room for improvement for us
right yeah right so we can that's a
niche in the market that we can make you
drop into it yeah yeah
perhaps you should aim for that so um
this is this is a picture from from way
mo so how do they do it I mean we do it
with just one camera obviously that's
not enough in real-world situation so
the way mo car actually is based around
a lidar system which is a laser based
radar system we looked in to it for our
car but it's way too expensive it's like
I think it's eighty thousand dollars for
one of those units so that's not really
steep not really a bargain no it's not a
bar compared to the 30 is $30 RS roof I
can ride like we're on the good side so
I think relatively we're doing so and
it's it's actually augmented with all
other kinds of sensitive visual sensors
and they have like radar systems which
support the dead larger system in
self-driving so when you look this is
this is somewhat what allied our vision
would look like so it's it's pretty
detailed right it's 3d and actually as
you can see on the road it can see the
difference between the the pavement and
the lines so you can actually use it for
that type of detection as well and it's
it's not as limited as a camera in for
the conditions right now I would argue
that this looks exactly the same as a
camera feet with some coloring in there
right so what's what's the difference
yeah right so that's it means it's
pretty impressive and actually they're
currently mapping I think the whole
world with the system so is there like
is there's a lot of work better and when
there's like foggy weather or bad light
conditions or why shouldn't it just use
the camera I would imagine that this
would work in for example foggy
conditions yeah where visibility is
limited but well this radar system will
just look through it right yeah it's 3d
model yeah that's that's also one of the
major advantages yeah so this is this is
what Tesla is doing and then they
basically base our system around the
objects right like cameras which makes
it way cheaper to to create and it's
it's augmented with with stuff like
radar so add the the the 3d aspect is is
lost in in the video in the 2d video
aspect but they have stuff like radar to
to compensate for for that well all in
all it's it's a way cheaper system but
it's arguably less robust well what can
you imagine it looks like well something
like this so it can detect the lines it
can detect the cars around you clearly
buy buy buy buy optics and this is this
is not a picture from Tesla it's
actually a picture from the the website
of coma
AI which is created by geo hearts which
is a famous a famous iPhone I think it
was one of the first to create an iPhone
jailbreak yeah - jailbreaker right and
and actually I think it was a months ago
that he started hacking on his own car
to build his own self-driving car right
on his own and and now he's actually
building a company around it and I mean
this is really impressive so your artist
assistant work icees his phone hanging
there yeah which is basically just just
a camera and then it ties into the the
car via the OTB port and it can hook up
to the canvas protocol in the car which
well yeah well that's that that's that's
another part work I will come to that
nevertheless it's it's pretty darn
impressive when they're doing the like
the lane assist and the adaptive cruise
control - yeah right yeah - to actually
control the car so outside is fairly
cheap and it's relatively cheap so well
there are some safety measures that and
precautions that the companies take so
for example the way more cars are
geographically limited so they only
drive around drive ever seen in the
Phoenix area which is which is not just
a random decision it's because there are
fairly good road conditions and and
always fairly good weather so that that
will create the ideal circumstances to
start having these cars driving on their
own the the systems in in those cars are
redundant so they have two computers if
the main computer drops out and the auto
takes over and can bring the car to a
safe stop multiple sensors which they
can help - well to check the readouts to
see if if what if they have the correct
picture they isolate the control systems
from for example the Wi-Fi in the car I
mean it would be pretty nasty if you
could like screw up the system by by
browsing the internet maybe put on a
random are you use B stick and then yeah
right and then and then of course I mean
most of those cars still have the
fallback of human intervention right
someone who can intervene with something
it's going wrong but when something goes
wrong I mean there is a whole ethical
dilemma so this is one of the comics on
on the on the Deaf folks website
actually in which the decision is made
if AI or human programmers should
program the ethical logic in a
self-driving car and the I says well I
think the car should be preserved at any
time
well perhaps humans reprogram it because
this might not be the best outcome but I
mean it illustrates that there's a whole
world of ethical dilemmas behind this
these self-driving cars so let's go to
one of the always ethical dilemmas in
human history
cats vs. dogs right so we have a
situation in which a self-driving car is
in an unavoidable
and it can actually go it can go
straight true killing three dogs or it
can swerve killing three cats so show of
hands who would save the cats okay who
would save the dogs I'm over dog worse
oh wow
all Dorpers in the room this is a hottie
also environmentally that the dogs would
do more damage to the car then it gets
oh yeah of course but now let's get a
bit more serious because this is of
course a funny example but what if you
have a car which is full of people right
a family driving down the road and
there's a family crossing the road and
there's an unavoidable accident and the
one choice is to drive over the
pedestrians killing the working family
or the car can decide to actually take
evasive action and thereby sacrificing
the people inside now who would choose
the scenario in which the car sacrifice
itself your family is in the car yeah
your future okay yes your family right
now
okay well that's still quite a few but
that's those are the kinds of decisions
that come with driving these things in
the real world so let me ask you who
would want a self-driving car so I can I
can check my Twitter all right and now
who would want a self-driving car that
takes the decision to sacrifice the
people inside your family these are way
less hands than before right so this is
this is a real issue I mean it's bad
publicity but there there have to be
legislation in order to to give the the
the creator's a framework in which to to
build these ethical ethical decisions on
now these scenarios are actually
provided by or are created them in the
moral machine which is from from
researchers that they do research into
what what humans would do in this
situation in order to well solve the the
issue of what should be the ethical or
moral choices that self-driving cars
would have to make so go to the website
and you can actually answer all these
different types of question and it will
show you where you stack up
arrest with with regards to do the
decisions that you take and the German
government actually issued some some
rules or some laws actually and a couple
of weeks ago of which to actually well
hit this point of ethics and one is that
in in in these situations of of such a
hazardous situation and the preservation
of human life should take precedence
over all else so over property damage or
animal life the human life should take
should take precedence and the other one
is that whenever there's a choice to
make on who to kill so to say it's a
called who to preserve all right oh yeah
that's better that's a better option
right so if you have to make a choice
and who to preserve you cannot base this
choice based on personal features like
age like gender or physical mental
institution or social status so this is
basically like some sort of protection
against your all sorts of of bias if
you're reading this it makes sense but I
could make an argument against it if you
you know you need to choose between
hitting someone on the right side of the
road on the left side of the road
there's maybe an elder person who maybe
has a couple of years to live and on one
side of the road and as a young child on
your side of the road
I don't know then then I I don't know if
if he shouldn't make any distinction
based on personal features but actually
is now it's legislation yeah so you you
can't can you imagine being the
programmer having to program the lies
yeah so based on if age is more than I
would know what I would do if I was in
this situation behind the wheel myself
so yeah so it's really hard so on a more
light note back to our pet project are
we done
is this is this perfect no no there's
lots of a lot of stuff to them so first
we're now steering only on the angle at
the cars make
with the lines wrote so change steering
on your position on the road would
probably be a lot better we are not
currently able to detect and navigate
through curved lanes we would like to
make line detection algorithm a lot
better I think we could really her help
she we could automatically calibrate the
video parameters brightness contrast
lighting and the OPC parameters the
thresholds for the candidates action for
the you line detection we need we need
observability in our car so currently
we're just letting it run and see if the
questions or not and then thinking well
this was good and it wasn't and change
some code and try it again
so you know we need to be able to tap in
in what decisions that the car make and
why we're currently controlling the
servos by just making a job our system
come on doing echo zero is 152 dev
server Blosser which isn't really nice
its pragmatic I would work yeah it's
fast enough also we would like to take a
spin with with with some hey I based
approach to let the car drive itself for
example take a neural net and trained by
driving car sales but my guess that we
need to have a lot a lot of training
time to train a model and we would end
up spending I don't know will
self-driving car run office which should
be fun but and currently most of the
stuff we have is running on a laptop so
we have the PI which is only running the
heartbeat control and the core control
features and all the rest is running on
on a laptop would be I think a lot
cooler if you would run everything on
the PI and then we wouldn't have trouble
from the network latency pulling the
stream over the question is will open CV
run fast enough on the PI sorry but
that's what we're about to find out we
have next days I think in March so maybe
we have some more successful disaster
stories to share next year we have a
couple of minutes left for questions if
you would like to ask questions there's
a question over there yes
yeah
right so the question is what what do
these self-driving cars do when there
are detours right so as a human you
might you see the signs and you can
decide well then I Drive just just this
way and and and I'll avoid it well I
don't know exactly but it is the case
that the for example the way more cars
only drive in controlled environments so
they these environments are constantly
being mapped so my guess is that they
will also register those types of things
and actually put some sort of blockades
or something on its its mental map in
order for it to avoid but you can you
cannot well I think you cannot prepare
for everything right so I think there
was there was one case in which there
was a actually some some roadworks
somewhere and the car had to actually
move into the into the other lane and it
didn't get the right-of-way from a bus I
think and they they hit each other so
unexpected situations will always happen
and that's what makes this so hard and
that's also of course why why Tesla says
you always have to keep your hands on
the wheel just just to be able to
intervene in those situations and to go
for the racers you had to cover there as
this yeah right
any more questions yes
I can answer the questions about our
development process so you know how do
we work with running stuff on the pine
on a local machine I think it all starts
with beer drift and development here
definitely yeah I would say we currently
fairly lean and not adhering to any
modern development principles so we
don't have that meant that much test
since most tests we need to do in a life
where I'm to see you everything reacts
we do have some approaches that that do
work yeah yeah by recording recording
stuff right so we record every the races
that it does and we can actually do the
all computer vision and Alice's stuff
not only on the live webcam feed but
also on those videos so that way we can
get feedback on our session and in terms
of development speed we typically do is
when we develop we try to run as as
little as possible on the PI because
that takes a while to copy there to
deploy and then run as them as much as
we can on a laptop we come and just
restart the Java process there so we are
I think this combination of running the
least amount of software we can on the
PI the rest on the laptop and then doing
some finding some ways where we can
build and test off without running the
car so by recording videos and stuff I
think I think one of the things that
that works really well for us is that
because we we only use the the visual
aspect is for example with the lane
detection algorithms we just started
with a still image right no video just
one image or a couple of still images
and then tweak the algorithms to see if
it works on on detecting the rodent of
still images and then we go to video
feeds and so that that works step by
step
final question yes
one of our tours of weaponizing this
platform yes we have thoughts about all
sorts of things but not about
weaponizing yeah I would say it is it is
a cheap way of getting something in some
space so definitely we don't have any
thoughts obviously sorry how to win the
race that's that's a great question
actually well actually our competitor
might be in the room so we come this
close to any of this but if you have any
ideas feel free to go oh we have two
we've actually we heard rumors about one
of the teams wanting to put a red LED on
the back of their car for this topic
that's a great idea right yeah okay to
wrap it up everything we build is on get
up get up Lacombe / RC Dukes you can see
all the code there there's even a readme
with I don't know five lines of text in
there which might help you a bit we will
publish the slides online through our
Twitter accounts if you have any
questions feel free to reach out over
twitter twitter handles are below on
screen i really hope you enjoyed your
time and i have one more question please
take the time to rate this session i
hope you all enjoyed it lots and you
give it five stars if you didn't like it
that much please come to us and tell it
so please rate the session thanks a lot
for your time enjoy the conference and
we'll be around for the rest of the day
to chapter</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>