<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advanced Pipelines for Hypothesis-Driven Development Smart Routers... by Edson Yanaga | Coder Coacher - Coaching Coders</title><meta content="Advanced Pipelines for Hypothesis-Driven Development Smart Routers... by Edson Yanaga - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Advanced Pipelines for Hypothesis-Driven Development Smart Routers... by Edson Yanaga</b></h2><h5 class="post__date">2018-04-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uH-mPVFVVRA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon it's always a great
pleasure for me to be here at Bucharest
I know thank you very much for me here I
know it's hard to come back after lunch
I'm Brazilian I know how it works so
Romania Latin language I expect to be
the kind of the same we we got this
behavior from the Romans or not but my
name is Ezio Naga I'm a director of
developer experience from Red Hat
material handlers attea Naga just in
case you want to follow me I tweet a lot
about DevOps micro-services Java
software craftsmanship and other
subjects and today we're going to
discuss advanced pipelines not only for
that but with some pipelines that are
especially useful for hypothesis-driven
developments I also happen to be a Java
champion and Microsoft and we beam which
is an unusual combination but as I
always like to say it just proves that
the world has changed a lot in the past
years and it's an amazing that we can be
able to have such a diversity and I'm
going to start this talk with this
discussion around DevOps because if
we're talking about advanced pipelines I
must assume that if you think about
advanced pipelines all of the basics
from DevOps and pipelines you already
have it covered you already have a fully
automated software deployment pipeline
in your organization or in your team so
you already have continuous integrations
you already have tests and you can just
by committing something or pushing a
button you can release a new version of
your software into production without
major issues okay so that's the basic
discussion we must have overcome the
discussions around DevOps we are already
doing continuous delivery and if you
think about we know that we want to
deliver software every time faster more
reliably that's why we've discussed
continuous delivery in the past but in
all of the organizations that I ever
visit the number one excuse for people
not trying are not being able to deliver
software software faster into production
was that every time we deliver something
into production we have bugs
so if we have bugs we don't deliver
software production maybe we need more
time for testing then if we're doing a
release in every week then we maybe we
need two weeks between each one of their
releases but people don't realize that
the more time you have for testing the
more time you also have for coding the
more coding that you have between each
one of your releases the more bugs that
you release into production and
technically the term that we have in a
DevOps word for this thing is the bad
size so bad size is the amount of
changes that you have between each one
of your releases of software into
production and if I want to be more even
more specific we say in the divorce word
that you can have changes in three
different areas you can have changes in
behavior which is codes you can have
changes in the state which is data and
you can have changes in the environment
which is the are the dependencies that
you have in your software on which your
artifacts run so you can have changes in
these three different areas but I want
to oversimplify the concepts I want to
say that we as developers what causes
the valve bugs into production are
changes in code so the more changes in
code that you have between each one of
our releases the more bugs that you have
into including production so the
canonical way of try to solve this
problem is that if you can try to reduce
even further the amount of changes that
we have between each one of our releases
the last bugs will have into production
okay and it's all based on the feedback
loop because if you can reduce the
amount of changes we as humans we are
very good in establishing correlation
between things if we have enough context
in our minds and I'd like to define
context as if we have the right amount
of information in our brains for the
right amount of time we are very very
good in establishing correlation I did
this I got that into production but if I
have too much things in my mind like if
I change it too many things in my code I
deploy something to production
it's very hard for me to establish the
correlation because well I change it
like 20 different methods and now I get
this bug where is the cause of bug very
hard for me to establish the correlation
on the other hand if I change a line of
code today and I deploy this
for six months later is very hard for me
to establish a correlation I changed
this today I got this six months later
so if I can get the right amount of
information for the right amount of time
I can establish the correlation I
changed this code I'm getting this
behavior if I have this bug it's this
bugs cause because I changed these 15
lines of code so discussions are out
there you know DevOps and micro services
we're trying to reduce the feedback loop
time which and the third we reduced the
time between our analysis it's natural
we're also reducing the bat size so
they're there they're dependent on each
other so we're trying to reduce our bad
size
ideal sized one single commit like small
commits 15 lines of code one deployment
production easy to establish correlation
but I'm not saying that everybody needs
to deploy a version of your software
like every five seconds five or three I
don't remember anymore
like Amazon not everybody needs to be
Amazon maybe if you're working on
financial need to see if maybe if you
work in a bank releasing software every
week is a good batch size for you
so it really depends on your use case
you have to find your idea about size
but remember the smaller the batch size
the better results you get into
production but so far the goal of trying
to improve our deployment pipelines and
trying to reduce the feedback loop was
to reduce risk if we're talking about
reducing the chance of having bugs into
production we're trying to reduce the
week's risk of releasing something
broken into production and that's how to
additional pipelines work when we have
traditional pipelines we assume that
each one of our releases is better than
the other so if you have like release
1.0 or release 2.0 2.0 will be better
than the first one because if you have
it will have fewer bugs and we have more
features and so on some version 3 we
assume that is better than the previous
one so traditional pipelines is a
sequential release of versions that's
how we've been releasing software in the
past 30 40 years one version after the
other
okay and if you want to make an analogy
without that with that
like to say that we are releasing
software just like we're if we're
cooking a beef it like you have a lot of
different foods you don't know exactly
which are the foods that people are
going to be today but you have to cook
all the recipes because you have to
release and we have to feel all of them
although all of the dishes on your
buffet so maybe even if I don't know if
you're healthy here but well I'm not if
you have to cook like broccoli and
carrots or cauliflower other things that
usually people don't get don't a buffet
on the buffet
no it's a waste of time waste of
resources nobody's gonna eat or maybe
not everybody is going to eat that while
you could could you could spend more
time cooking like pasta and steak and
other things that people will consume
more so traditional deployment pipelines
are like a beef aim and we are going to
start to discuss hypothesis-driven
development and again only very mature
organizations today are being able to do
hypothesis driven development because we
solved all the problems that we have in
traditional pipelines so the analogy
we've hypothesis-driven development is
that maybe instead of cooking all of the
recipes and even the ones that we don't
know if people are going to eat into
production maybe you could just click
cook small plates on everything you can
give a small plate people can taste if
they enjoy it you can cook more or if
you do a small portion or something
people don't enjoy it you can just stop
cooking that so that's the basis of
hypothesis-driven and developments but
instead of doing that with food we're
doing that with code so we have
hypothesis driven development we might
have la virgen 1.1 and we have a certain
feature which we don't know if it should
be implemented this way or the other way
and you know we're self developers we
try to imagine how things will work into
production but the only true wage for
you to know if it's gonna work is to
release something to production and test
it so when we're talking about you
hypothesis a and B we want to test these
hypotheses into production and we don't
know for sure which branch will go on
forward to the future to become version
2.0 or 1.1
so one of these hypotheses might fail
and we're going to release that you know
it really doesn't work version B is
better and it keeps going on so if I
show you this graph it it magically
comes to our minds well if we have like
this version and this other version what
do we do work out if you're using git on
any other version control system we are
going to create what a future range
that's a natural way of developers of
trying to solve this problem and we have
future branching we can have some nice
features like if I had choose different
free tree branches maybe I can deploy
this version separately into production
and perform some kinds of a be testing
and maybe testing I know you might have
seen some demos I want to show you some
demos are very testing myself but a be
testing is not enough for you to have
two separate deployments because if
we're talking about hypothesis driven
development we want to ask us which one
of the versions performs better into
production so you need monitoring right
so you need four before thinking about
a/b testing you need monitoring and when
I'm talking about monitoring is not just
monitoring if you have no amount of
requests or memory or CPU usage you need
to monitor business metrics to know wow
if I'm selling more if I'm reducing the
costs into production these kind of
things so you need to monitor behavior
and for you to be able to produce a be
testing you you need some technologies
for you to be able to have that in
production and the first one that I'm
going to show you is a smart routine so
basically we've smart routine we have a
component in architecture and this guide
is mark brooder
it has different deployments into your
back-end and depending on some business
logic that you can add on your smart
Rooter
it will route your request from one
deployment to the other deployment how
is it different from traditional a be
testing it's not a common sense in the
DevOps word but I like to call dump ad
testing and in smart a be testing
because when I'm saying them I'm saying
that I want to route 50% of my request
to this and 50% of my request to that or
if I want to perform a connect
Adam canary I'm going to route 90
percent of my requests to this and
temperance said to the other one because
that's the most and infrastructure can
do right infrastructure can handle like
fifty percent ten percent ninety percent
but we can't add business logic
what kind of business logic is useful
maybe I'm releasing a version that will
improve the performance specifically
specifically for mobile users so why
should I forward 50 percent of the
requests of all the users maybe I could
forward the line the requests of only
the mobile review users to this version
and test it
or maybe I'm targeting of improving my
algorithm and I want to check if this
target audience improves the metrics so
maybe I want to target only females from
20 to 40 that lives in Bucharest so if I
want to target that I need some business
metrics because I should have done some
profiling before with the users and this
kind of thing can only be done with
business logic which means that you know
it can only be accomplished by codes not
by infrastructure so that's the
distinction that I made between them
routing and smart routing but let's try
to get some demos working let me see if
my resolution is correct yes
so here let first I need some
deployments to be able to test a smart
ruler so I prepared some deployments
here in my OpenShift installation I have
here blue deployments which is a very
nice application I have a green and I
have a purple I don't know if the colors
are good for colorblind people but
that's what I chose so blue green and
purple and if I want to perform them it
testing because that's based on
infrastructure openshift makes it very
easy I can just go here and create a new
route I want to say don't want to create
Bluegreen deployments and I want to say
that I want to split my traffic between
different services I want blue and green
and I want that to be 50/50 and why
50/50 because that's the
easy one for me to demo just created a
Bluegreen if I open this one Bluegreen I
get blue if I keep hitting her refresh I
always get blue because the OpenShift
rotor is sticky so I need another
browser to be able to show that it's
going to route to green and of course
didn't work because it's a demo I forget
another one on screen okay so it's
around robbing but you have to be lucky
to get like 5050 and you get the right
browser to the right color so this is
this is dumb routing so you can speed 50
15 1910 or any other statistic that you
want to have so now I'm going to show
some art routine I have here in my code
what I'm first I want to make sure that
I'm running I'm going to run Zoo which
is an open-source project provided by
Netflix I'm still running version 1 of
zoo but Netflix is already using zoo
version 2 into production but I just
realized is not that popular yet so most
people are using zoo version 1
how does zoo work zoo if you check out
the source code from the Netflix OSS
repository it's a very simple
implementation basically it's a servlet
filter that runs on top of a tomcat
instance and zoo a pause a certain
folder in your file system and it checks
for a groovy script so all of the zoo
futures are reading in groovy and every
5 seconds zoo checks if the files have
changed it if they change it it just
reloaded the future definitions so here
I have very simple zoo implementation
it's running and by default I'm just
saying that I want to route everything
to my blue deployment so if I now check
well it's running so if I try to hit
like a host it will always give me blue
okay but if I want to change that I can
implement some kind of run round-robin
logic oops here got some round Rob logic
so if I uncomment this I just created a
counter should be performing the
round-robin I just saved the file don't
have to reload anything though picks
every five seconds and you might be
thinking how does it work properly on
Netflix the distributed data inside
Netflix is distributed through a
cassandra file system cluster so every
time you commit something to a git
repository which is stored on the
cassandra file system cassandra
replicates this data across that their
clusters and each one of these zoo
system is raining from the same file
system so you commit it changes the
files you just get the same files and
reloads everything so it might take some
time but it's distributed through all
the nodes so that's how it works and now
I just change it has waited more than
five seconds we just hit here I just get
problems with chrome so for me to get
the without caching behavior and I have
to open the inspector so now I can
reload and if I do reload I get blue and
green but if I wanted to change that if
I want to add another logic here I might
want to add like if I get users from an
iPhone I want to route them to purple or
else I'll do a round robin between green
so I can add any kind of business logic
inside zoo so if I just change here it's
giving me a blue and green if I just
change my client to and I found 10 this
is new
it just gets purple okay so this is a
very simple example of how smart Reuters
can work for you it's just you can think
about that zoo is just it's just adding
a matter of some ifs and nouse depending
on some business logic of course I
wouldn't do this just like user agent
from the from the HTTP header I would
get the authenticated user or from the
geographic user and route that to a
specific deployment right it's just to
show that it's just code and you can do
anything with your information that you
have in your business logic inside
the Zulu term okay yes groovy groovy the
syntax is compatible with Java so you
won't spent much we spend much time
learning how to code here okay let me
stop my zoo and go to the next so that's
how smart rulers work compared to dumb
rulers so now we have a smart ones but
the problem with zoo is that we have to
be very careful when we have feature
branches so we're assuming you have two
different branches of code which leads
me to do two different deployments of my
application and it's not only - maybe
you're testing more than two hypotheses
into production
maybe you're testing three different
implementations from different areas of
your code into production so you might
have three different deployments each
one of them leads you to a future branch
in which our deployments will feature
branch that's just a simple example with
two different hypothesis you have trunk
which is your main version people are
committing code into the trunk all the
time then you have version a and you
have version B which leads against to
two different deployments of course you
have CI properly implemented you have CD
properly implemented and you do
continuous integration which means that
daily or every hour a week or even even
after each commit you're coding on
branch a and every time that somebody
commits to trunk you pull the changes
from trunk to your brains so you know
that your branch is always continuous
integrated right but the problem in
future branches is that every time you
create a future branch you are creating
a huge batch size because you're adding
a lot of commits that are not getting
the point to production which increases
the risk of in deploying bugs
introduction even if you're the point
that and testing these hypotheses with
smart routing or dumb brooding and the
major problem that we see that I've seen
in all of the organizations that I've
talked to if you have a version being
just deploying and committing you're
testing hypotheses then you check that
well hypothesis B works in production I
want to merge this code into trunk and
you head Lac
25 different committees on the trend on
the future be you just suddenly merge
everything to trunk what did you do you
just added the wing of 25 commits into
your batch and then when somebody tries
to merge the changes from Trent to a you
have a just a big conflict and in all of
the teams that I've visited they are
they always told me that well when you
have such a big conflict in your code
it's much easier for them to just throw
up everything that they did in the past
just copy the code that is interesting
and you just paste in the new version
because fixing the conflicts is too
costly and you might be wondering well
copy pasting code between branches might
not be a good press okay so this is the
problem with future branches if you let
your feature branches live long enough
they will Creek we will create a huge
conflict problem and most of the times
it's better just to throw up and copy
paste the code that you think it's
relevant for your new feature that's why
if you want to do future branching if
you want to use smart rulers for testing
your hypothesis your future branches
should be very short leave it short
leave the like one day two days very few
commits very few changes of code so
you'll do you don't want to have this
kind of problem when merging your codes
into your trunk another way of trying to
solve this problem of hypothesis-driven
and development that doesn't lead to the
problem with future branches is using
feature tacos okay and I have a nice
demo about feature toggles that I want
to show you right now so zoo is not
working anymore
and here just let me exit the
presentation mode now I want to have
this demo
for Jay I'm going to show a very again
very simple demo of using future toggles
into production
I'm using a future toggle framer called
FF 4j it's not the only defect to toggle
framework in the Java space you also
have to go xeam but when and when I
evaluated this different frameworks into
production so I'm not in production in
my prefer concept project one year and a
half ago FF 4j was more mature at least
in my opinion but when I did that his
valuation input in a production project
two and a half years ago I had the same
conclusion so that's why I chose that
for J for you to demo so how does work
FF you J you just need demo application
you just need an FF for J XML file but
in your configuration I'm using a
springboard application because it's FF
o J's works pretty nicely we will spring
if you get into the definition what do
you have in the FF 4 J XML you just get
a feature you just give an ID hello it's
enabled by default you get a description
which is useful after you get in the
production console I have another
feature which is not enabled by default
and have another comment so that's the
basic configuration of future togas you
just do that and if you're using spring
security you can add some you can add
some conditions here well the feature
will be enabled by default if I have
users with certain roles and etc but all
of this if that you can do here in the
XML configuration file you could be
doing code and I prefer to do this kind
of condition in code rather than their
programming XML we did this mistake in
the past so the simplest possible
implementation is that I have a hello
controller
I just inject my FF for J instance which
I created as a spring bean and I check
that if F F or J check I give the name
of the feature if it's enable return
something else return buna yeah is it
correct
okay if not I blame google translator
okay
so we were just going to run this
application with the future to go
running so what does it give to me if I
go to localhost I want to close this
inspector localhost and I say hello
it gives me hello but if I go to my FF
4j console you can see I have some
features I go to my features and it's
enabled by default if I turn it off I
get back to hello and I get buna so
you're all welcome right
buna so this is the very possibly the
simplest possible implementation of ff8
toggle but let's try something more
elaborate so I'm going to open the
recommendation controller and here I'm
changing algorithms into production what
do you do I have an interface
recommendation engine we just returns on
me a list of strings for me to show a
list of recommended foods if I go back
to my recommendation controller you can
see that I am just getting the bean and
returning the result in the controller
slash recommendations and right now the
behavior is that it's getting me some
very poor recommendations Berger saw the
hot dog not very healthy and not very
good actually so but I want to change
that so before this presentation I just
coded an improve it recommendation
engine which already implements the
recommendation engine interface and if I
want to switch this implementation
dynamically with f4j all I have to do is
just add an annotation here FF 4j
feature and I give the name of the
feature which is new recommendation
engine and then I have to add that this
new recommendation engine bin to my
spring context so I go back to my FF 4j
application see I have AB in my default
recommendation engine I can just add
improved improved
improve the combination engine return
new improve the recommendation engine
which is a very simple implementation
and I can add at beam you might be
wondering if you do that spring will
complain that you have two different
blings implementing the same interface
how its gonna inject well in this case
you have to give a hint to spring saying
that if you have two different
permutations one of them must be the
primary choice and all I have to do is
to add at primary my spring contacts so
in duct spring will always inject the
primary beam so how do we let's see how
it behaves I'm going to restart my
application and guess it's running if I
go back to recommendations it's running
returning me burgers salt and hot dog
but if I go back here to my console
refresh here you see its own because
it's by default FF 4j is using an
in-memory feature in implementation
repository but of course in production
you're going to store that into a Redis
cluster infinite span cluster or even a
database for you to have the state
maintained across your cluster and I
mean between reboots so if I just turn
it on the new recommendation engine if I
get back here to my demo you can see
that just refresh and it gives me a much
better suggestion atoms for me okay
steak wine and ice cream I really try to
find some names of foods in Romania but
I couldn't okay read properly and I
didn't want to make like a lousy mistake
here especially because it's recording
so that's how feature toggles work and
you might do this there are feature talk
on faith talk of autonomy frameworks for
visual components from 10 if you develop
another angular application you have
feature toggles frameworks for that but
if you're using back backend code I
think that the most useful use case is
the switching implementation engines so
you don't have to put your ifs on that
even this you just create a new being
just use your future toggle framework
and your switch you flip implementations
right so it sounds tempting it might be
a better approach than
using smart routing because if you're
using feature toggles you're using trunk
based developments everything goes to
trunk you don't create large batch sizes
with future benches but let's discuss
the downsides to a future Togo's you are
basically trying to a couple release
from deployment right because in
traditional pipelines every time you
release a new feature into production
you also need to have a new deployment
into production we feature tacos we have
the ability to perform like multiple
deployments into production and just
enable the release of the feature that
we want into production when we flip the
switch when we turn it on or off and the
new feature is provided to the users in
production okay and the problem with
that is the the problem with feature
toggles is that sometimes people forget
that you shouldn't have too many feature
toggles in your code so it's very common
for people well I'm just cutting any
future tacos oh the features working and
you really do forget to remove the
feature table so it's still running your
XML you still have the eve checks in
your code and it just takes forever
because nobody after like six months
nobody will remember is why are we doing
this but it's working so don't touch it
right so it's very common to have a
legacy of future tacos in your code so
that's one of the problems and now the
another big problem that I've discussed
with two different Dean's was that
sometimes you have a big team and then
everybody decides to do hypothesis
driven development so suddenly in your
future taco framework you have like 40
different feature tacos and everybody
decides to do hypothesis driven
development at the same time so what did
they do is that they have the software
run into production and then the team
was like well let's try our new feature
taco and they were monitoring the
results in production let's turn it off
and they get another results the next
day they well let's test again and they
get a different result then they turn it
off and they get another difference out
and they said what the hell is going
because and they compared the historical
measurements measures so well then the
behavior is diff
last week for example so we don't even
have a baseline and after that they just
realized that everybody was testing at
the same time so they never had like a
consistent state of the future toggles
so they could monitor the results and
after they realized that they said
everybody stopped using future toggles
and it was a like a big team more than
50 people everybody was doing their
tests and because it was a big team they
had to create Governance Committee
inside their team saying and the
Governance Committee decided which
feature toggles would be tested on that
week so this team you're allowed to test
this rich otago and this team you're
allowed to test this one because these
two feature toggles they don't conflict
with each other right so that's one of
the problems when we have too many
people doing future toggles in your
production framework and you might be
wondering if you have such a big team
and you have such conflicts with feature
toggles maybe that's a nice application
of a Microsoft architecture so on each
of the microservice it did no impact
with each other right so this is one of
the discussions if you want to do future
togo's remember to avoid these
situations that I've just described and
the third technology that I want to show
which is brand new everybody's
discussing this this things nowadays and
if you want to know more about that
right now I'm going to show a very brief
demo of Easter but tomorrow verse error
which is my another director of
developer experience that ran hat is
going to show of a whole set of feature
from issue tomorrow morning I guess so
you might want to check the schedule and
I won't discuss deeply how does East
your work or how are the features but
basically if you have like many services
in your infrastructure Easter can
regulate and can inject some behavior in
the communication between each one of
your endpoints so if you want to perform
dumb routine yeah you you can you do
that using open shift or kubernetes
but you can also do that with easter
easter even goes further because if you
have any kind of routing logic that
depends on application layer seven
headers like HTTP
Easter control any kind of TCP
connection but if you have HTTP it can
inspect your headers for example and you
can perform like a bit more smart
routing like routine based on browser
routing based on IP or these kind of
things you can do that with we have e co
2 and the implementation I'm going to
show you with Easter Easter is using
envoi which is a sidecar implementation
provided to the open source community I
lift and into M how does it work for
each instance of my application like
here a service a service B I also have
an instance of my invoice sidecar proxy
and basically what does it do it proxies
all of the incoming and outgoing
connections to my application so it can
inject some kind of behavior on that
right so you can change the routine you
can deny you can allow some kind of
traffic you can add some misbehavior you
can add some delays you can add some
faults if you want to test your your
system in the past we had chaos monkey
you can just say your own chaos monkey
here we avoid and Easter but the use
case that I want to show you right now
with issue is that sometimes when we
performing hypothesis driven development
we want to test if a new feature is
going to perform well into production
now we rhythm if I'm not worried team is
going to perform well into production
but we don't know for sure if it's going
to be able to handle the requests or we
don't know for sure if it's going to
write the right result in the right
columns and the database or something
like that for that Easter brings to us a
feature called mirroring which I did
myself in the past using complicated
routing messing with IP tables directly
it used to be very hard to do that but
with Easter Miriam became very simple so
it's a very recent feature further from
the Easter service mash and I want to
show you right now how it works so if I
get here just let me sure that I'm not
running anything else that will like
stop this guy
so I have my East you just let me change
my project so here I have three
different components running in my
back-end I have a customer service I
have a preference service I have a
recommendation service and from for the
recommendation service I have two
different instances to differ
deployments it might be where only as if
you using mirroring you are using future
branch development rack you need two
different deployments because you need
to test these two different deployments
into production even though for some use
cases you could be using future tacos
too but I'm I just stick to the simplest
possible scenario which is using future
branching and I have two different
versions of recommendation and I want to
that I want my productions requests to
go to the recommendation version one but
I also want that all of the production
requests that go to recommendation
version two ghost version one goes to
version two two two two because I want
to test the performance or if the
behavior is correct in version two right
and you might be wondering how does it
handle states because if that's a
read-only application it's okay it's
just reading values but if it's an
application that write state how does it
behave because if both instances of
different versions I write into the same
production database I might be having
issues because I have duplicate requests
okay that's the discussion we're going
to have later but right now I want to
show that if I try to heat this
application I'm going to do some curve
you can see that the default behavior
for openshift
is to do round-robin requests between
each one of these versions so I always
hit version 1 version 2 version 1
version 2 and now I want to mirror this
kind of behavior but first let me try to
get the logs at application so you might
be wondering I will be heating both
parts version 1 version 2 so I get the
the logs from the request from both
deployments but if I get here and then
apply the rule to mirror the request
from version one to version two
now if I did perform the same curve
easier we'll only route the production
request to version one version two is
fire-and-forget I get a request by the
negev never get the result back okay
so just let me check the logs to see if
the requests are really going to version
two into production so to be able to do
that he read the parts that I have I
have here recommendation v2 and I'll use
a tool called stern to check the logs I
get this pod I want to check this this
container inside that pod
because since we're using easier each
pod has two containers the application
and the sidecar and that's it that's
version the pod with version 2 you can
see that I'm heating the request to so
so every request that's going to version
1 is going to version 2 too but we just
don't see the results I just see the
results of version 1 into production
that's how mirroring works and how can
you ask us if the things are going right
through your version 2 into production
and what I am I just have to give you a
warning
everything that I'm showing right now is
there smashing mirrors is brand new so
this this is the discussion that like
the unicorns are having right now how to
do how to perform this kind of things in
production in the safest and most
reliable possible way so let me get here
so I have mirroring so next discussion
what about my data if both requests are
going to production to do two different
versions traditional approach of trying
to solve that is that every mirrored
request that goes to version 2 Easter
adds a special header into the HTTP
request so you know it's a mirror
request one of the things that you could
do is that you could add a special
filter in your application saying that
if that's a mural request I'm going to
perform everything but I'm going to row
back to transaction in the end so I'm
not going to commit anything into
production right so this is one this is
one of the possibilities but if you're
not committing anything into production
you
can't verify if the data is being
written correctly right so this is one
of the possibilities so how can I handle
do different micro services with two
different databases writing things into
production one way of handling that
first is how to handle this schema
between these two different versions
because they might have two different
schemas of your database releases this
book last year migrating to
micro-services databases and verse and
chapter 3 of this of this book
particularly shows you how to deal with
your application production if you have
two different versions with two
different schemas running how to make
them compatible so this is part of the
problem
and part of the solution to the other
part is that we're discussing right now
I'm working with some engineers trying
to create a proof-of-concept around this
that I'm going to show you right now
well not show just discuss so this is
still work in progress but as soon as we
have this thing working into our proof
of concept I want to share with the word
so just follow me on twitter you'll be
able to see the results and how is it
expected to work I have two production
services I have two different requests
production requests coming in both
services but in one it's getting to the
hot database in the production database
so the all of the records are written
everything is right and the traditional
way that I did in the past is that well
if I have a mirrored version I copied
the production request both of them but
this version is talking to a test
database right and this database how do
I do I just get a backup from the
production database and they restore
here and test in my scenario in the past
when I did that it was a big database so
restoring a backup took 8 hours so it's
not something that DBA was very happy to
do every day so you need to ask him like
and you usually you remember oh I need
to ask the backup restore from the DBA
usually ask that like 6 p.m. and he's
definitely not happy that you're you
asking but I need that for tomorrow
because I need to test my version so you
have this kind of conflict too so it
takes a long time and since it takes a
long long time for you to restore
database you want to
form lots of tests on the production the
test database so you can access the
results but when you do that the problem
is that you keep your test database
running for such an amount of time that
the production database and the test
database they differ so much that is
very hard for you to access if it's well
I don't know if this state is correct
because it's now so different that I
can't even compare anymore using my
sequel statements between each one of
the databases so that the solution that
we're trying to create is that we're
creating a virtualization layer between
my the the one on your right you know
yourselves on the right which is the
mirrored service which is getting this
new version get the mirrored request
we're creating a virtualization layer
and this virtualization layer is reading
and writing from the production database
to but all of the diff like if I want to
read things I read I merge the results
from a production database and my deep
database but when I want to write
something I write only to the diff
database right so it may it makes me a
much easier for me to compare the
results from production and diff
database because the production database
is always the hot request and the diff
database is just the the rows that I'm
recording with my new version of my
service so if I want to check let's
check just the new records I just get a
QE from my chief database and I could
compare that well it's from this
transaction ID I can easily compare the
results that so this is the proof of
concept that we're trying to do right
now so dizzy I think this for me
particular is going to solve most of the
problems when we want to compare data
with two different versions of my
production of my service when using
mirroring sorry no we're using an
existing project so it's JBoss data
routinization but the upstream project
is to eat te e ID T it is just Google T
it is a lizard yeah but if you get to
the J job
projects so yes we're using teeth as the
virtualization layer to the project and
to be very honest when I start the
discussion I didn't know if it would
work but the two engineers that I'm
working with they guaranteed for me it
works into production so I'm just
waiting for them to code that for me
okay
and what about my other services too
uh-huh well it this scenario works if my
service my mirrored service is the last
service of the chain so it's not
invoking anybody else into production
but not usually the case my production
service might be calling other endpoints
especially if I have a micro services
architecture so what do I do with my
other services you might have other are
there solutions for that if you're using
Twitter for example Twitter creates it
just mirrored the request to another
environment and it also have like other
services which are tests services so if
you get like well let's test our
notification to users it's just your the
requests go that and this service invoke
other services but these other services
are mock services so if you send a
request to notification it doesn't
really notify the users because you
don't want to have like duplicate a
notifications into your Twitter account
so the answer that some companies are
using is service virtualization which is
basically mocking services I don't like
the term service of utilization I prefer
market services but I just learned that
after reading more about it I just
learned that this term is not from now
people have been using this term service
virtualization for the past 15 years
because it came from so on so and so
they call this test services that does
nothing inter production they call that
service virtualization that's why we're
still calling them at this way and
another thing that I have to show right
now another project from Twitter is DP
di FF y DV is a service for testing the
output of Murat services so what does
Twitter DV do you get jus mirrored
requests
Eastern mirror the requests
this one processed this other one
process to both get replies but we've
issued this reply is ignored and you
just get version 1 to production we do
feel sit be between east you and the
mirror services so any using defeat
defeat intercepts both requests version
1 and version jus records the both
replies and guess who generates a deep
or the replies so if you have like a
JSON payload and this JSON payload is
change it just this little amount of
information when you get to your DV
console D if you show as well
I had choose this request same request
to the to these two different services
but variant one gave this reply present
you give this reply and they are
different on this piece of information
so that's one way for you to analyze if
your if your service return is
correcting your new version but again
Twitter just release it this software is
open source some months ago
everything that I'm showing right now to
you is brand new and that's what I
wanted to show you today all of this
information is or will be available at
developers that the head dot redhead
calm and if you want to know more or ask
me questions I'm always available
Twitter or my email
Anagha at redhead comm just sometimes
takes us take some days or weeks to
reply on email so Twitter might be
easier and thank you very much
and I'm available for questions but
before questions I have a special
request I have to show my kids and my
wife that I was here so may I take a
selfie yeah
hey they will love you okay just as I
did any questions
please oh that is not on codes it's on
dependencies dark launching okay No
yes that's how it works right now okay
yeah I didn't work with this a new
family that you're saying but the way
that I've seen people implementing with
Wichita goes that you duplicate that the
feature toggle definition everywhere and
if you get all of the implementations
reading and writing for the same hippo
repo you get the same information but
the console you can deploy that
independently it doesn't have to be in
that embedded yeah yeah so sorry I don't
have a good answer for you
thank you anything else no you're
awesome you don't have any Dobbs yeah
yeah you got it yeah thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>