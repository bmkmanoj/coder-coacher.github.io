<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Making Microservices Micro with Istio Service Mesh by Ray Tsang | Coder Coacher - Coaching Coders</title><meta content="Making Microservices Micro with Istio Service Mesh by Ray Tsang - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Making Microservices Micro with Istio Service Mesh by Ray Tsang</b></h2><h5 class="post__date">2017-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AGztKw580yQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let's get started thank you all for
being here and spending the hour or 15
minutes with me in this session I really
appreciate it
my name is Ray I'm a developer advocate
for the Google cloud platform what that
means is I like to bring some of the
latest and greatest technology and
practices that we learn from Google and
bring it to the developers over the
world and the other side of it is that I
love to learn about how you're using
technology today and if you're using
Google cloud off to learn about what
you're doing if not love to learn about
the other tools are used today so the
best way to contact me is on Twitter
Saturn isn't okay aside from technology
I love I love to travel I love to take
photographs wherever I go you can find
my photos on my Flickr as well at this
photo is a little special to me it's
it's when I was backpacking in Asia I
was in this city where I couldn't really
find a cheap place to stay because I
said backpacker you know I needed to
find a cheap place so I can spend a
night or two and this specific city in
China didn't let me do that so what
happened in is somebody a random
backpacker told me you can actually go
into the desert and hike for four hours
Tower is the Southwest direction and
there you actually find the angle laces
and you can stay there for free and I
heard free let's go and I'd do anything
twice how many people here hike in the
desert before anyway there's always one
with two people yeah there you go by
yourself yeah maybe but you walk on the
beach no everybody walk on the beach
it's not the same it's not the same
basically the sand is really soft right
so every step that you take you sink a
little bit and you have to pull yourself
out and when somebody tells you you have
to walk in one direction for four hours
it doesn't matter what's in front of you
you just go so there are all these sand
dunes you have to go up and down and you
sink you you put yourself back up very
not time in my mind I was kind of
thinking wow this feels like writing a
j2ee application and at the end was
beautiful right like for developers what
is the most exciting things
to the end and the road to the end could
be a little tough and my job is
religious to make sure that your journey
is a little easier I hope by going
through this session and what I'm going
to talk about today is not another
microcircuitry song but you probably
heard about it already how many people
here are already that implementing micro
services I'll call it vrv okay very cool
so yeah so there's no Theory here I'm
not going to tell you whether to do or
not you know all of those things you
have to decide for yourself you just
remember you do it just to solve a
problem you don't want to do it just for
doing it right so there's nothing here
I'm just gonna tell you how this new
platform can help you solve problems
when we break down a monolith into
micro-services or if you are starting
out with a micro service architecture
well first of all the first problem
you're going to see is you're going to
get more and more components that you
have to manage right rather than just
one single application code base and one
thing you need to deploy now you have to
deploy in many many different components
and they all have to work together and
you don't just run one instance of the
issue run many many instances of them
and this problem becomes a little bit
more complicated but luckily we actually
have tools that helps you to do this I
scale so with so many instances you have
to figure out how you can deploy them
onto your cluster of machines if you are
having a big project you don't want to
SSH into each individual machines and do
this manually I think about doing it and
it's not good what you need is some kind
of orchestration tool to help you to do
that and we have those tools today with
containerization with kubernetes we can
actually take care of some of these
deployment level problems so you can
deploy very easily you can impact you
can run multiple applications on the
same machines and we will take care of
restarting the apps for you and even the
networking model behind the scenes right
those are self problems so with
kubernetes right we can actually just
say well here is a application I want to
run I just give it a container image and
I can just say how many instances I want
and basically we push the container
image to like a registry the config file
we can send it to the company's master
node where you can control a bunch of
jeans behind-the-scenes they're just
aggregated resource in this case each
machine may have different resource but
Kripa Nettie's can actually figure out
which machine has the proper amount of
the resource to actually run your
application so rather than doing this
manually the scheduler with thing will
be able to orchestrate the deployment
process for you right so it will say how
do you have enough capacity no all right
let me try another machine if the
machine has is going to download the
docker container for you from the
registry and start the application right
this is a thing that we can do today and
if you want to learn more about
kubernetes I'd be happy to
you know chat afterwards as well but the
key here with kubernetes to me is that
it offers this concept of a control plan
what that means is through the control
plan through the utility or through the
API call
I can tell kubernetes I can tell my
cluster what is the desired state I want
to be what is that application
architecture that should be and behind
the scenes somebody else wakes up and
say I need to make the real you know the
physical world the same lies for you are
wanting in your demo files or in your
definitions so it actually has a
well-defined API and set off pipes that
you can just use and actually abstracts
away the underlying infrastructure for
you but most importantly it also allows
me to see all of the machines not as
individual machines but as an aggregated
resource that we can utilize and the way
we can do this is by using the control
plan so I'm just going to show you a
little demo of this and just so you can
see what's going on right so behind the
scenes I have a quite a few of these
yellow files that are really created
this is a multi-tier application with
micro services behind the scenes and if
I open up one of those things at the
pointman v1 for example if I scroll down
I can see which docker image I'm trying
to run and actually deploy everything
already onto discriminators cluster
which has four nodes and I can see
there's the front end and there's my
security point into it we can scale each
part in the vent individually if we want
to and we can also see
the ingress which is the way for us to
see this application but this is a HTTP
load balancer that we can provision
directly in cribben Eddie's and we
should be able to see the app and I use
this app before so if you seen it before
I don't worry there's something new to
it right so I'm going to say hello the
Vox and hopefully this request is going
go through and you can see the the
response here and we also store data in
the database right and you can do this
with just one command line we can deploy
this whole application architecture in a
matter of seconds onto multiple machines
however one of the problems that we
don't usually ask is how are these
services supposed to communicate with
each other okay and I do nation is in
some of my other talks especially with
the different protocols that you can use
there are actually two facets to it one
is the protocol the communication
channel you can use so whether it's TCP
or something higher level with HTTP or
HTTPS in but the other side of it with
the communication is the fact that you
have separated everything away not
rather than making these calls in memory
were in process all of these codes are
now going over network and with network
you have more latency and also
potentially is more unreliable and
because of this as soon as you move into
this kind of architecture what you're
going to see is potentially latency
problems right or ability problems how
do you make sure that you're connecting
to the instance that's actually up and
running you have to be very careful and
so to have a full micro services
architecture it's beyond just being able
to run your app it's beyond just be able
to deploy and manage them a scale but
there are a lot of the non-functional
requirements that you may actually have
to add to this entire architecture you
have to ask about how was the best way
for me to low bonus my requests to the
back end if the network is unreliable
how do you tolerate how do you deal with
those failures how do you actually add
tools and maybe logging and tracing so
that you
have insight into what's happening in
your service architecture in with the
Java world we have many of the
open-source tool that can help us solve
these issues right with Netflix OSS we
have the service registry with Eureka
your back-end can register with the
registry and now everybody can discover
what the endpoints are you can use a
client-side load balancer if you want to
in this case you know you trust the
client so the client has the control
over which server to connect to and how
they want to connect to it but that's
controlled by the client-side now what
if you don't trust the client if you
don't trust the client and you have to
control these connections on the server
side load balancer with the proxy and
with the proxy then you have other
issues like you have to make an extra
hub you may have to maintain more
infrastructure and all that so you have
to decide how you're going to load
balance your application and then we
have other tooling like histories and
other things that helps you to deal with
votes in the network and then you have
tools like Zipkin and prometheus in
Rafah now that allows you to have
insight so what happens with our
microcircuit texture is out we viewed a
lot more things outside the
micro-services right this is kind of
like those problems were we thought were
of solving a problem but now we just
have potentially more problems to solve
right every one of these boxes could be
a problem for you you got make them H a
highly available and the services
themselves now you got wrong all of
these client-side components to make it
work to make it reliable
so rather than building a micro service
potentially we could be looking item
micro service a much bigger service
because of all of these dependencies
that you add to the consumer side ok so
it is really easy to do this like in
Adina is very very easy to do it
especially if you have a single stack
that you're working with especially if
you're using spring booth which I love
very much and you can do this very
quickly with a few lines of dependencies
and you can get this entire thing up and
running in development but then you also
have to manage it afterwards I said as
well right but this is fairly easily
done in spring boot if you come to
of the spring sessions you'll probably
see how this is done however because a
lot harder and more difficult if you
actually have multiple stacks right what
if you don't always use spring boot
wonder if you found another thing that
you want to use but now you have to go
back and think about okay how do I do
all of those things again how do i
integrate all of these capabilities into
this new platform if you have different
frameworks you got deal with that as
well if it's je or spark or you know
like some other new frameworks that you
want to try now you have to go back and
deal with these issues as well it's even
worse if you're doing polyglot with
different languages in your company or
in your organization do they all have to
do the same thing now you are looking at
you know a very big problem to bring all
the services up to par especially in
legacy applications right it's something
that works in an application server and
it's been running for a long time and
how do you deal with that right how do
you migrate these applications without
causing so much trouble at the end of
the day when we talk about service to
service communication I want to blow you
down to just one thing let my service
file to your service how does a talk to
be write all of these other things
shouldn't be something that you need to
concern about in terms of how do I do
that in my program right the
communications you just be provided by
the platform same thing with it some of
these non-functional requirement
she also be provided by the platform it
should be as simple as making an HTTP
request from A to B okay to make that
service call without anything else right
just make a call and the platform should
be able to provide the resiliency that
you need for your architecture and this
is where each do the server smash enters
right and service Amash is a pretty new
term and and that's what I'm going to
you know spend most of my time talking
about it is a way for you to manage the
service communication just like
kubernetes communities was designed for
you to orchestrate containers in wrong
container size scale across multiple
machines
a service match is designed to be the
fabric that will handle your service
communication so now you have the
halfway story of deployment with sto you
have the other half about networking
service communication and resiliency
okay it was actually work out together
and open source together by Google and
IBM and lyft we use components from
these different companies as well and it
was designed to be multi-platform what
that means is you should be able to run
this service match in different
underlying infrastructure or platform so
for example if you're using kubernetes
we have support for kubernetes so you
can lay on top of cooking that easties
service mash and I'll show you what that
looks like and you don't have to deal
with some of these non-functional
requirements especially in your app
anymore okay but the same idea can also
be applied to a VM base or a bare-metal
infrastructure as well okay so what is
it what does it do in my lines is what
the service patch needs to do right
first of all it is there to take care of
the service the service communication
when you open the connection from A to B
how's that gonna be happening and how do
you handle potentially the networking
problems that you're going to see it
should also be able to provide you
insight into the performance of your
services and be able to give you insight
into how all of these service costs are
happening again we do these today but we
do this in our client-side applications
right we do this in the colors but this
is going to be provided by a service
mash it should also be apprehend Oh
failures so being able to retry your
requests automatically without your
application explicitly asking for it
right or sucker breaking as well so what
that means is a lot of these components
that we add today into your micro
Service in a java application
potentially might go away because the
platform can handle it and all these
other things that surrounds the micro
service our architecture
can potentially oh so gonna fade away so
that what you're late what you're left
with it's just the service right just
your this is logic and your code and
what we're going to be able to do in the
service match is actually take all of
these cross cuts cross-cutting concerns
and move that into your proxy okay and
so when we're running your micro service
rather than just running the service
itself we're also going to run a proxy
alongside Ave and this is known as a
sidecar panic
well that means this we're externalizing
some common functionalities so that your
application don't have to deal with it
but we will be able to perform all these
cross-cutting concerns through a common
component which is the proxy itself and
the proxy that we're using is the Envoy
proxy this is a proxy created by the
lift and it's its high performance proxy
it's apparently pretty awesome like this
job right it was battle tested within
live as well serving two million
requests per second you know your data
center is saying all that but the
important thing to me is that it also
has a low memory footprint right so
we're externalizing
some of these functionalities you don't
want to you know double the amount of
footprint that you need to to run it you
want to you know have a little bit more
manageable right so envoy is the proxy
of choice but you can also use other
proxies as well but through the proxy it
actually offers a lot of these
cross-cutting requirements and just
solves them for you automatically
all right so load balancing TOS
communication it should be to traffic
splitting health checks for injection
all that that's all provided by the park
C directly but how does the proxy how is
this different from say if you want used
to run your own server side load
balancer right that's a that's a very
valid question from the client side load
balancing side your client can choose
how they want to load balance right the
client load balancer needs to pick and
choose from a list of endpoints and say
which one to go to from a proxy
perspective if the proxies besides or
the service a load balancer decides how
you're going to do that the difference
here is that we're on we can run a proxy
per
micro-service instance what that means
is if you have multiple micros you know
a services and B services every one of
the instance will be proxy and these
proxies are configured automatically
through a control plan so you can
actually just like tripping Eddie's I
can write a Yama file to define how
myopically application architecture
should look like with E steel you can
write a policy file and that will define
what your service communication policy
should be and it will be sent to the
pilot is the Oh pilot component and from
there it can actually automatically
configure all of the proxies in your
environment to enforce these rules okay
so the way that this works behind the
scenes is like this so every service I
deploy it automatically adds a proxy for
you and when service a makes us code to
service B it's just a HTTP call okay you
say HTTP GET and that's as transparent
as you can be behind the scenes we are
using IP table rules to intercept this
connection intercept this request and
we'll forward this request to the proxy
associated to that specific instance
so this communication is local and from
there the proxy has a list of
destinations that is associated with
service B because you can actually get
it from kubernetes automatically it is
automatically synchronizing configured
and through proxy through the
destination policies you can figure out
what ways you lie low balance this call
what other policies and enforcement
should I have and then it's going to
pick and choose one of the instance two
for two and it not only intercepts the
outbound it also intercepts the inbound
so your application cannot actually call
anything unless it goes to the proxy
because we intercepts everything through
this proxy okay well that also means is
potentially your firewall rules may not
be you know in some cases may not be
necessary because this is already far
away off by the IP table rules
so once the request goes to the proxy on
the target then the checks the policies
and they enforce to the target instance
and on the way back right it goes to the
same route and goes all the way back to
the color now because
now you see opening formation flow is
through this one component or we have
many many instances sulfate right so
it's not a single bottleneck there's now
a single instance is not a single
bottleneck this is attached to your
service because everything is going
through this path we can force and apply
the cross-cutting concerns just like an
interceptor in Java right we can
intercept all of these things and say
okay if I'll need to monitor the latency
well I know when the request can mean I
know when the request god responded I
know when you've finished now I have
live in scene information I can send
this off to my my prometheus for example
I can send it to matrix door if I need
to know you know who cause what well
everything goes to proxy so now I can if
if I do passing the trace ID this the
proxy component came forward all the
data for me to Zipkin so I don't need to
run Zipkin in my own application anymore
either
it will just be down through these
components if I want to you know split
the traffic well all I need to do is to
configure it they correlate decoratively
and then the configuration can supply to
the proxy component and now the proxy
knows how much percentage of traffic to
migrate to what right it's pretty soon
point straight forward now and lastly
the most importantly about security the
communication between service instance
in the proxy could be plain text but
that's because your local there are
contained within its own environment
however if you need to go and call
another service across the network you
might want to make it secure because
maybe you're running environment where
you need extra security right you don't
want it to go over a plain text rather
than doing this in your own services you
can now rely on the proxy to establish
neutral TLS with eesti oh we can
actually install a certificate authority
that can automatically issue
certificates for your TOS that
identifies itself what that means is you
can also trust these certificates so
that you can safely say you know putting
the enforcement of a can only talk to P
but not not anybody else because we can
enforce this not only through the IP
table rules but also through the use of
certificate
so with all that said everything kind of
ties together so your application will
just become simple all those latency
information tracing information all
those they can be forwarded to the mixer
this is another component within each
deal and through the mixer we can
propagate the trace information in
latency information to the platform
services so in this case we can still
use the pen we can still use Prometheus
but if you're running on the cloud
platform this is a plug-in model so we
can plug in different adapters that
force it to different clouds so in this
case I can actually use the mixer
potentially that will forward not to my
own Zipkin instances because now I have
to manage it I can forward all the data
to Google Cloud with our star driver
trace for example that's a hosted
solution that you can store a lot more
data you don't have to manage it right
so what I also means is when you're
dealing with deployment kubernetes
abstracts everything away we're dealing
with cross-functional cutting concerns
if steel takes your you know abstracts
everything away all right so with the
rest of the time I'm just gonna show you
a little demo and I think I have about
30 minutes left so let's see how this
works now at the beginning I said this
is great if you're using a polyglot or
if you're using different form works so
for this talk
I'm not going to spring booth even
though I love it but you know I can
certainly use spring booth I can also
use something lighter weight like spot
Java or or something legacy like a
application server and I I thought about
this thing and I said what is the
smallest micro service I can write okay
to prove this point right that we can
actually help you with a lot of these
things so so I decided to use something
that nobody else ever uses and that
happened to be the sound HTTP server has
anyone you saw before yeah that's why I
thought there's like one or two people
right so I'm going to create the client
two services one go see each other
purely by just the JDK my face right so
I don't know if anyone's seen this
before but I'm God
take this down right now so I'm going to
you know create a new client a new HD
client right I'm going to assign this to
a variable here with the HTTP client and
I need
give it the new socket address I'm going
to listen on in this case port 8081
I'm going to set this thing oh yeah this
is a job and I'm sorry also nobody using
some guidance module right and now I
have the server that's just listening on
port and then what I can do is I need to
set the executors so that this can be
multi-threading so I can set the oh
sorry oh sorry not the client sorry I'm
what am i using I should be using HTTP
server in this case right so I need to
create there you go there you go and 81
in zero so that should give me the
server and again Java Java 9 modules and
to do that and I can use a variable code
server okay so I'm gonna get rid of the
client right and also uh it get rid of
this line as well right and with the
server now I have establish it I can set
the executor right so I can give it the
one of these thread pools that I can use
so I'm gonna say executor Oh which one
the kashfari pulled out some one
Sanskrit and I'm going to store it okay
and then I'm going to you just add a
little Hinderer that would do something
so so the this demo will I will have two
different servers one of this the work
surface and the other one is well what
is work work is just composed of you
know tons of meetings so the other
service is just meetings okay so in this
survey somethin's gonna have a handler
that takes in meetings so I'm going to
use some passcode meet and it's going to
give me an exchange and from here I can
take the response and what is a meeting
a meeting is really just the timing that
you spend without any doing any work
basically so so I'm going to sleep for
two hundred and fifteen minutes second
because that's what we're doing meetings
right which is like don't do anything
and nothing productive from this micro
service in this case okay
and then and I just need to respond so
I'm going to say exchange that send my
response header and oh sorry not the
response header exchange that set yeah
yeah it is respond so 200 and 300 bytes
because I didn't produce anything from
this meeting yes I'm going to get the
response body I'm going to
you closi okay and that's it not say
microservice everyone right
how how mike releases microservice thank
you i'ma show you how Mike reduce
micro-services I'm going to go ahead and
beauty okay so oh now that one this one
I'm going to do a Navin clean and
package just so this is a brand new a
very dangerous thing for me to do as
well so we'll see how this wart
by the way I sound beauty the surveys
I'm also building the docker image over
the the network here and also push the
image out so all these things are done
and configured through the palm da XML
just to show you how smooth these
services it is uh though there we go
sweet kilobytes yeah
and this actually runs this if I do a
Java our target in the meeting service
in jar issued yeah actually I think it's
roaming yeah you never know until you
try it right so here we go I'm going to
go to localhost 8080 one and uh meet ya
know what's 250 milliseconds I can kind
of feel way right so that's good not bad
it's working trust me alright so then I
can implement the worker service right
so this already implemented a few things
I'm gonna pull this up a little bit and
not literally but like the font and I'm
going to I have this handler for work so
what may I say about work it just tons
of meaningless meetings so I'm going to
a for loop right I'm gonna say eyes is
less than four and I plus plus right so
I now I'm to make a CO out now I'm now
in spring boot so I don't give the nice
rest template I'm not in spark I'm not
anything in fact I don't have any
external dependency so then I thought
maybe I can use something that also
nobody ever uses HTTP client from JDK 9
ok so I can create a new client right I
can say a new HTTP client let me move it
up here that uh new HTTP client right
anyone use this new theme already know
yeah so I thought nobody uses it right
so I can't assign this to a little
variable here and of course job on nine
need to add this module okay and then
you can actually beaut the request so
this is again very straightforward I'm
gonna studio HT request going to do a
new beuter you can create a new RI and
I'm going to use the endpoint here
and this is pretty ugly actually you
need to specify what method you want to
use so I'm going to choose user get my
fake and that's going to return me in a
pewter which I need to use later so I'm
gonna keep it here yeah so I'm going to
say what is this HTTP request pewter
pewter is equal to i1 okay and then from
the pewter I can say Butte for example
that's going to give me the request okay
and that's the request and so for me to
make this request I can just use the
HTTP client to say to the client that
send the request and a line to get a
response by the way this is all you know
pretty new to me as well but I
apparently you need to use like a
handler I can then turn everything into
a string and then what you get back is
just a string that you can consume so
let me see here there we go there's a
response string okay and then once you
have the response you can actually check
the the status code so in this case one
whoa whoa umm do I'll do there you go
what you can actually do is if the
response was successful and then I'm
going to say meeting plus plus right I
just want to count how many meetings
that have condo you know meetings yeah
plural here okay in the response code
it's not 200 now I know I didn't have
that meeting I was probably tired and I
just skip the meeting like I always do
so and that's it and in the NRA I'm
going to you know tally up how long this
took and how many meetings I was able to
attend and which hostname I was actually
on so let me give this a try I don't
know if she's gonna work there in the
right of the bat I hope he does so I'm
gonna run this my heart is pounding how
many people things just work Wow nobody
this is worse than my G RPC talk alright
so I'm gonna say hey Eddie Eddie work
know what what of course he didn't work
yeah
let me come here right this always
happens to me for some reason so I'm
going to say am i running a proxy or
something no no no you know I changed
something here earlier so I think the
problem is actually here so what
happened is I'm getting the response and
I need to write this out
bla bla bla and I closed the string and
other spirit so the first one worked
pretty well haha but that but this one
didn't
so that is too bad now luckily I do have
a backup so so let me see here I'm fly
from server Oh interesting
whatever so what's that what do somebody
see a solution here no so what I'm going
to do is to I get check out my master
voila
stashing the changes keys - yeah there
we go check out master and there we go
now that works yeah right so I need to
double check there let me check here
maybe what's running the wrong code here
we go and go to work
wait what Oh what huh internet
connection really in my off again no no
no no no no don't tell me that's the
case no no no it's here let me see you
man gone kilo cube CTO huh Chris need
this all right tell you what I'm going
to go ahead and beauty and see if this
actually works or not okay so I'm gonna
go ahead and do a million package okay
unless you just package everything yeah
we're gonna find out pretty soon and see
how each do deals with this kind of
failure okay so I'm gonna send this out
right so now I have this application in
the in the back reddit containers I'm
going to just deploy it just like any
other application so potentially I'm
going to use a for example here worth
the appointment latest right so what
this is going to do is to pour down this
container image and deploy it
it's going to use the meeting server as
the the back end here oh I think I know
why I didn't work my meeting server was
not working that's why yeah he's trying
to make a CO out ain't nothing in work
that's that's exactly why not
that happens well not when you're not
using a service smash all right
[Laughter]
not-not-not that's probably why so I'm
going to go ahead and trust that
distorts so with all these things I'm
going to do a cube CTO apply dot by the
way my talking making this case is using
Judy cane nine sorry nine slim and my
actual service is only about three
kilobytes
right so there's nothing nothing to to
do so oh I think I just deport
everything here so that's not good so
thanks you get pods and I got all my
services deployed okay
and I also have an ingress so the what I
means is I can actually get to my
service hopefully from the web so I can
do something like work now there we go
whoo that works yeah
but because each call is taking about 25
200 sorry 250 milliseconds that's why
this took a long time and then I
actually have two versions of my work
service decoy right now so if I go back
to my console and if I find work let me
do a refresh you know this one's gone -
yeah sorry it's just like bad day today
with everything and there we go so if I
go to work service you'll find even a
worse day tomorrow in my other session
so so here we have three versions of the
work service deployed okay
there's 1.0 2.0 in the latest think it's
the one that was supposed to be just row
I guess I don't need me that right now
so you know what do you what I'm going
to just delete the latest deployment
okay some gone I'll be point so I'm
going to say work the appointment works
already late okay Bri Lobby but as you
can see here um come on get rid of e I
don't have he'll check so there we go so
sometimes he goes to version two which
is when I'm working really really hard
I go to eight meetings in a day that's
why the time is longer and the second
time is something I you know just easy
day and they cannot run Robin around
right and this is something you can't
expect from kubernetes directly but what
I didn't tell you is you know this
kubernetes cluster is really running
east EO what that means is I can control
oh the traffic routing directly from the
east EO control plan and what that means
is you know if I want to route
everything to version one of my service
I should be able to do that so we'll
come on find out pretty soon because
it's not what I planned earlier but
we'll find out right so what that means
is we can add a route rule here and I
can say this wrong rule applies to that
this nation of work server well that's
the one that's responding to work and
this server I want to forward everything
to just the 1.0 application okay and
same thing with that back-end
I want to force everything to go to one
point zero just to apply this router
rule I can in this case i can use both
kubernetes or east EO coming online I
know I'll start no not that one you can
use ECL command line because then you
can work in different underlying
infrastructure but if you're in
kubernetes you can just say QC to apply
this file so I'm going to go ahead and
create this rule core out to v1 again
what's happening behind the scenes is
I'm flying this desire state to east EO
it's picked up by the pilot pilot goes
out and configures all the proxy and uh
I'm just a little afraid to show you
what this looks like but let's see okay
and there you go so now hopefully
everything is going to version one of
the service right I just configure this
directly from the east EOKA me line you
don't really have to change any
configuration your services at all if
you want to apply a retry if say a
back-end service fails and you want to
apply a retry well you can just apply
that through a retry configuration also
so in this case if I want to say I want
to retry for at most three times and if
the connection doesn't open for two
seconds and one closing you can just
simply by using this block and you apply
this and you can retry okay you can also
apply circuit breakers as well so let me
see if I have one of those so if I open
up the policy for work right circle
braking is actually quite interesting
because different people have different
understanding of where the circuit
breaker is this is this is new to me as
well when I think about circuit breaker
I think about history I think about
detecting arrows from the back in and
just drop them for a few seconds before
I retry them again right that's what we
could let's actually code them it can be
Co the outlier detection right so you
don't retry the batting senses until
sometime later so you can retry them
again but circuit breaker in the real
world behaves a little bit differently I
think about in your house what does your
circuit breaker do it's when you are
overloaded when you try to consume too
much the fuse breaks right and that's
what the circuit breaker kind of kicks
in and in this case e steel can do both
so not only can you do the outlier
detection to say how many times the
failure would mark this instance on
healthy you can also protect you from
say a lot of connections or debouncing
right so you can actually plan ahead and
how much how many connections you should
actually have you can enforce it by the
proxy as well now the other thing that's
really really awesome essentially fault
tolerance testing so in your in your
environment whether staging or test I
don't recommend this for production to
be honest you can inject faults into
your application so for example if you
don't want if I never want to go to
another meeting anymore I can't just say
100% of the meeting call it's going to
return 503 status code right and this is
cool right everything you can do it less
you can say it I just don't want award
20% of the time right do whatever you
want and I can use eto to apply a so II
still nah I all sad create F routing
meeting 503 okay so I'm gonna apply this
route again we were to pilot went to a
proxy configuration everything in supply
for you automatically if I make this
call again you can see that we are
attending no meetings yeah it's pretty
cool so again with someone's system all
of these concerns are abstracted away
from you you can also do what do you
call it
traffic splitting if you want to know
the best thing here is that while I'm
doing this as you can see this service
really has nothing behind the scenes
there is just straight-up JDK calls in
there's nothing however I can open up a
private connection here I'm going
to open up my platform level services so
in here I'm going to open up for this
one graph on out so I can see the
performance of my services in this
screen I'm going to open up prometheus
so I can query for my metrics and this
one I'm going to open up Zipkin right
this one Zipkin yeah so which one do you
want to see if right let's see
Prometheus Oh Prometheus is running on
my local port 90 90 that's being
forwarded into my East do cluster okay
so what that means is I should be able
to go localhost 1990 in here's
Prometheus and I can just go ahead and
see let me see the request count and you
can xu8 all of those they can see
metrics about your service is
automatically stored here again I didn't
do anything on the client side it's just
a JDK application
I can't even graph it if I want to but
this graph is not very interesting to
see what's more interesting to see is
actually the graph one on one so again
no extra configuration I should be able
to go to my 3,000 for my traffic into my
eesti or cluster because of the server
smash all of the information about
performance about my application these
are system level performance
matrix right this all being captured
directly with Prometheus and you can
visualize in Cremona and if if somebody
makes the call oh there we go there's a
lot of 500 arrows that's because I
turned it upwards to almost 500 percent
100 percent right so you see a lot of
these failure rates if I actually go and
remove this rule right so right now I
have zero things going through let me go
ahead and just remove this row so I can
say I host at that keep on to me now
deal EF am going to delete the 503 okay
so now everything is she coming through
yeah that's not bad
Lena I can't go to Zipkin
which is running on nine four one one
again I didn't do anything
in my micro service in this case almost
a nano service I can go and curry for
work and I should be able to find my
trace there we go I could never find
this button there it is
and there this that is the full trace
from my micro service call right and you
can see very clearly each call took
about 250 milliseconds and I did four of
them in sequence and you can also see
the internal cause that's happening so
what's happening behind the scenes is
out when this requests going through the
proxy the proxy actually has to check
with the mixer about the policies and
the rules and quote us for that matters
and that's why in every one of these
calls you also see a tiny you know
almost 1 millisecond call to the mixer
to do the check in the check passes the
request goes through if the check fails
then the service match proxy will return
a fault right so that's so pretty cool
let me show you the one last thing here
so well I deploy my guestbook
application that this is also deploying
into the sim a steel cluster so what
that means is I can do exactly the same
thing so I'm going to go ahead and apply
two versions of my guestbook okay and
let me just get my ingress now I have
two versions and I should be able to go
to one of these versions like that right
if i refresh a few times when everything
is up rounding I should be able to see
two versions and if I want to inject
failures let me see here you still rules
for example I can use cubes if you apply
in this case also to inject my e steel
rules I can say let me turn off my
hollow or service for example I'm gonna
say hello here okay I can turn off my
route to v1 there you go out everything
to be one and then I'm going to apply
another thing that kind of injects my
folks so I'm going to say guestbook
service just you know Channel off I
don't I don't want this to show anymore
okay and so if i refresh it there we go
you can see my service gone okay
now what is even better let me see if
everything is up and running I got five
minutes yeah we should also be able to
say something like raw rocky my traffic
based on not just percentages because we
can do traffic splitting we can say 80%
needs to go to v1 and let me test out
20%
because this is a l7 proxy what that
means is we can actually introspect the
headers as well so you can actually do
something special like route all of the
mobile application to a special back-end
or in this case I should say if I can
route all my applications to you know if
you're using Chrome to version two of
the back end so I'm not entirely sure if
my version - it's up and running but I'm
gonna try it out anyways so I'm gonna
apply this rule again don't modify your
application and do a refresh and it's
different right just to prove you this
is right I'm gonna open Safari and I'm
going to go to the same map and I see a
different thing okay so that is really
really easy to do if you want to give it
a try we actually have a lab outside you
can actually you know be hands-on with
this and hopefully you do see the value
potentially you know dealing with
cross-cutting concerns directly through
the mesh rather than within your own
application now there are being said you
know it's not close this out here's a
little idea of how this mutual TOS work
we can actually run a certificate
authority within the cluster and that
will actually be able to exchange the
certificate using a new protocol called
spiffy and we can give the certificate
to each other proxy so they can actually
identify themselves to establish a
mutual to your eyes okay so you remember
with the service match the key here is
that you let the the service operators
right being able to deal with
cross-cutting concerns a lot easier you
can do traffic controls you can do
traffic splitting and also with the
other resiliency czar you otherwise need
to build into your own app at the high
level I have to say it's still currently
is yeah zero point two it is better than
0.1 twice I screwed right but but it is
not exactly professional ready yet right
and they should have a new version by
0.3 and 1.0 hopefully next year right
and by that time what they want to do is
to be able to wrong sto not just in
urban areas but also in other
environments okay and you can get
started pretty easily but they just go
to the back and we have a watch a collab
area outside there's actually a sto lab
that you can take which is
cool yeah the reason I'm here today is
so that hopefully you have some interest
to keep this a try and secondly you know
participate in the community we have a
lot of community interest and
participation but I want you to give it
a try as well at the best ways to find
us our mailing list or on file issue on
github and you can find all of the
example that actually works I'm like
github and try to co-op outside and
thank you very much for your time yeah
any questions got three minutes left
yeah question in the back right so this
does not have the internal tracing of
the microservices in within the
application so for that you need to
capture potentially the trace ID and
then apply your own tracer if you really
really want to do it right and not
depends because you can also potentially
get away with a profiler sometimes so
you have to pick and choose what you
want to use yeah but in my example in my
spring application I was able to add a
HTTP span extractor so behind the scenes
that can suit you smooth I'm still using
spring cloud sleuth I can capture the
request ID and I can use the same
request ID to do internal tracing and
still forwarding it to zip and
potentially yeah question in the front
if you are not using kubernetes but
you're using VMs ah yeah yeah yeah you
sure can you can install in steal today
on many different clusters what I do
recommend is by using a criminales 1.7
plus with the features code initializer
and that will give you a very
transparent way to attach each do
proxies to your application you don't
have to do this explicitly it just
happens automatically but yes issue work
with different communities installation
including um frame yeah okay any other
questions yeah why in the back
what's the memory over for the proxy
that's a very good question I don't have
the number right now but I will
definitely find out yeah thank you no
all right well thank you very much for
being here
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>