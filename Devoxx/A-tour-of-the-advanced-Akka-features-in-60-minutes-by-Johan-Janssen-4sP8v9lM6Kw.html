<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A tour of the (advanced) Akka features in 60 minutes by Johan Janssen | Coder Coacher - Coaching Coders</title><meta content="A tour of the (advanced) Akka features in 60 minutes by Johan Janssen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A tour of the (advanced) Akka features in 60 minutes by Johan Janssen</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4sP8v9lM6Kw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now we can start welcome everybody
at least I assume there are some people
because I cannot see a lot of you with
the lot so if you have any questions
feel free to shout instead of wife
because if your way if it might be that
I can't see it
so what are we going to do in the next
hour I'm going to give you a tour of the
advanced acha features so we start with
the basic features so even if you don't
know anything about akka I hope you can
still follow along and I give a bit of a
high overview of what's possible with
akka and so if you expect like a really
deep dive into a car maybe this is not
the best place to get it
because there's a lot in akka and you
cannot deep dive into all the topics in
one hour
and the content I'm presenting today is
normally like a four day course but
you're all smart people so I expect you
to learn it and within an hour
shouldn't be a problem so what are we
going to talk about this is basically
what the agenda is for the next hour
questions are here positioned at the end
but feel free to interrupt me if you
have any questions and now try and
answer them directly I'll just start
with the first topic so why should you
even use akka mean is it another of
those new frameworks at his hip and cool
or is it even a bit useful so the most
common use case for akka is to build
highly concurrent applications with lots
of users and the advantage of akka is
that you don't have to worry about the
concurrency akka is solving that for you
so you don't have to do all kinds of
nasty things in Java to make sure
everything works concurrent it's
basically all handled by the framework
so if you have an application with like
two or three users maybe archives a bit
overkill if you have enlarged
applications with hundreds thousands of
users and you want to have fast response
times then akka is a good solution to it
so it's concurrent but it's also really
good scalable and later we will see why
because akka is using clustering and
other
concepts that make it easy for you to
add extra hardware to your application
basically and the nice thing is they
have a really nice way of handling
errors with with innaka i won't dive too
deep into that today but the error
handling is quite nice so you have like
supervisor strategies and if one of the
actors dies you can decide for yourself
what should happen should I start a new
actor should I kill everything so
there's basically like a supervisor
strategy to handle actors and it's I
think it's nicer than doing lots of
stuff with exceptions and what I like
most is and normally when we build
applications and we connect to other
systems the more most of the times we're
using rest nowadays or maybe you're
still using soap if you're in bad luck
but even rest it feels a bit strange I
mean you have to define rest endpoints
so you can connect to that application
and you have to consume the JSON and
then transform it to objects and it's
all boilerplate code you're making and
the only reason you needed is to
transfer some stuff over the wire and
with okay I will show you later that
it's really easy to get stuff over the
wire without using rest or any other
stuff and I found it easy to use of
course that's a bit a personal
subjective opinion maybe after this
session you will say man it's way too
hard to do this I don't like it but I
think it's quite doable and the nice
thing is I'm showing you examples in
Scala but you can also use Java to
program it so if you're an experienced
Java developer just use akka on Java it
works perfectly fine looks a bit nicer
in Scala because it has some nice
features for it but in Java you can do
the same small disclaimer I don't make
jokes about America or anything but the
code I show you and the examples are put
on github you will see a link later and
the code is meant to be easy to
understand and therefore I sacrifice
some good programming ideas so I do some
nasty hacks to make sure I can explain
the concepts without having to write
lots of code so for instance I'm sending
strings around instead of using case
clauses which I was
show you later so don't use the code I'm
showing you in production if you want to
really write good aqua code you can look
at the akka examples but for me and a
lot of my colleagues those examples were
a bit too hard to grasp at first the
first time when learning akka so that's
the reason I made some simpler examples
okay so enough talking
we start with local actors so a local
actor is an actor that runs in in one
JVM and so we have the actor running on
a JVM we can have thousands of actors
running on on one JVM this time we only
have one and what we do is we send a low
conference message to the actor and the
actor will then print the message okay
so that's basically what we want to have
functionally but how does it look like
technically so this is in Scala but I
think it's easy to understand for you as
well so we define a worker which extends
actor and then we have to define a
receive method so the receive method
more or less s what the actor has to do
for a certain message and in this case
it doesn't bother which matches we get
we just want to print it so this is
everything we need for an actor and when
we don't want to use the actor you need
the stuff that is put down below so we
need to create an actor system you can
give it any name basically and we can
then ask the actor system to get a
reference to one of the actors so in
this case we have a worker actor and we
can simply say ok system which is the
actor system give me that actor and we
get a reference to the actor ok now we
have an actor we want to send messages
to it it's really simple just use the
exclamation mark and you can just send
the string to it the string will enter
the receive method in this case X and it
will be print so really simple and to
show you this is not just part of the
solution I mean this is how I make it a
little bit bigger so this is the actor
in code and this is the startup so
that's all we need to do startup by the
way extends from application so that we
know it's an application but we don't
even need configuration for this it just
works out of the box so it's really
simple to use
so that's
like the basics of actors the cool thing
is we can also do remote actors so if
you have to JVMs and we want to
communicate between them we can use
actors to communicate and maybe one JVM
is running on my Raspberry Pi and the
other JVM is running on my laptop
doesn't matter I can just communicate
with those two so how does it work we
have an actor on JVM one we have an
actor on JVM two so in the first example
I said okay I want to work or actor
reference so this is for a local actor
and now if we want to have a remote
actor to access a remote actor we simply
use contacts actor selection and we
supply some stuff like the name of the
actor system IP address port and the
name of the actor so there's some basic
configuration if you do it nicely again
you would probably put this in a
configuration file instead of in code
but to make the example easier I put it
in the code and then we can use it
exactly the same way as that we use the
local actor so we're still just sending
messages to it so I don't need to define
define any rest end points of order or
our other end points to access the other
JVM I can just use it the same way as a
local JVM and that makes it for me
really easy to program without all the
boilerplate code to get this working we
do need some configuration but basically
as you can see here it's mainly
copy-paste configuration it's all like
standard stuff you need a remote actor a
ref provider some transport method
hostname and port so most of the times
you can just copy-paste it maybe change
the port or the hostname and you're good
to go
so nothing difficult there and so what
are we doing here we implemented a start
message and the start match message
contains hello conference we send that
to the coordinator actor which is
running on the first JVM the coordinator
actor will then send a worker message
with this text to the worker actor and
the worker actor will send a worker
response message to the coordinator
actor and that's basically how it works
to show you how it looks like see sort
of thing the only thing you need to do
is if you want to send messages across
the wire of course both sides of the
wire need to know which messages you are
sending and so if you want to send a
starter message that starter message
object has to be known at the sender and
the receiver part so what we did is we
basically created sort of a simple
library with case classes so these are
the messages we're sending over the wire
so this is a bit of configuration which
is not needed to send messages back and
forth so we can send a start message
a worker response message and a worker
message and now I simply have strengths
and my messages but you could put in
whatever you want so this project we
included in both the sender and the
receiver basically and if we look at the
coordinator we see the simple
configuration you saw in the slide so
here we import the shared messages
apparently IntelliJ isn't loading them
well at the moment so these are the
messages that we need at the front and
the back end mainly or sort of client
just how you want to name it so this is
basically the same code again as when
using local actors and when we have the
coordinator here we simply say ok get me
the worker actor ref to the worker actor
on this IP address and this port and
then we can send a message to it and
yeah we have the worker actor so maybe
you're not curious how the worker actor
looks like so the worker actor itself it
looks the same as any actor and we
define a receive method and we define
which type of message I want to receive
so in case I receive a worker message
with a body then this will happen quite
easily to understand I think and here we
just simply say the same ok we want
the worker actor to be active and that's
it so there is not a lot more
configuration if you want to work
remotely with actors it's mainly the
message to define the messages which
which are ascending so I really like
that model a lot more than then using
rest or soap or whatever other protocol
okay that's a good question so the
question is what would be the wire
protocol the wire protocol by default is
akka over tcp so they implemented their
own protocol to communicate with it if I
understood it correctly you could also
run it on UDP if you define that so it
basically made a low-level protocol to
do the message transport so that saves
you from doing HTTP calls for instance
when using rest so it the performance
should be better as well okay we had
this one already another thing which you
when you look at the examples it is I
need to know how scheduling works and
they have some built-in scheduling which
works really easy so here we say we want
a scheduler from the system and we want
to schedule once so that will only
happen once and it will happen after one
second and what will happen is the
schedule receive actor will get the tick
message so you simply are sending a
message to an actor and an in actor you
define that you want to receive that
message and then what body you have and
that received method will be executed
after one seconds or if we want we can
also say okay we want to schedule it not
once what we just want to schedule it
and the first one should happen after
zero seconds and then every five seconds
there will be a message talk sent to the
schedule receive actor so a really easy
way to do scheduling within akka by just
sending messages one disadvantage you
can only use it for like durations of
time and not for a fixed point in time
so if you want to schedule something at
like five o'clock you want to run a
backup or another job that you want to
run exactly at a specific point in time
that's not possible by default but there
is a nice quartz implementation for akka
which you can use to do that
if you look at clustering so I already
set you yet it's really easy to scale
and scaling is mainly possible by using
clusters so what we can do is we can run
multiple actor systems on maybe
different hardware or even the same
hardware it's just what you want and we
can just yeah and now we have tree but
we could also decide okay we have too
much loads we just add another four or
another five or whatever so then it sits
nicely distributed and how does that
work they use so-called seed notes so
the the seat notes are the entry points
for all your other notes if another note
comes up it will register itself at the
seed note and then it is known within
your application which notes are
available and so of course if your seat
nodes crash you're screwed up because
then nothing will happen anymore so you
need enough seed notes to make sure that
doesn't become a single point of failure
basically so never do a single seed note
and seat notes are quite easy to
configure basically what we do in the
configuration file which I've shown you
before where you've also had to
configure the remote actor support we
can also just say okay I have a cluster
with seed nodes and here I just give
them the actor system name and IP
address and the different ports so this
way you can easily set up the seed notes
for your cluster what will happen then
is if we have two seed notes when the
first one pops up so the one on port two
five five one it was say okay I cannot
find my body on two five five two it
isn't working
and if we then bring up the second one
then both will say okay there is another
member and everything is up and running
so we're good to go all the seed notes
or life and yeah we can do whatever we
want now basically and then we can bring
live a coordinate or not and so the
worker node is doing all the work and
from the coordinator we're just
dispatching the work basically what we
can do then is from the worker node we
can send a register worker node or
register worker message sorry to the
coordinator node
the coordinator knows which workers are
available within the cluster so now the
coordinator knows we have basically
these two actor systems running so that
that's still quite a bit of
configuration you have to register
yourself and make sure everything works
well so it feels a bit too difficult too
low level maybe for the ones who like
difficulty and low level stuff there may
be really happy with this but there is
an easier way to use clustering as well
and that's by using routing and with
routing basically does this it's doing
load balancing across your actors so
here we we define the load balancer and
here we again have our actor systems
with the actors running on different
JVMs again we configured it quite easily
within the configuration file so the
router is defined here and we say it is
a round-robin pool so we will send a
request to each node one by one and you
can also use other routers or writer
configurations so there is some
configuration available which will send
messages based on the load the nodes are
having so Evernote is already quite busy
then they won't get any new messages so
that's also a configuration that you can
make an easy part is you just do this in
the configuration file and it all works
if it can be changed
online the number of instances was the
question you need to restore the app for
it I believe I don't think the
configuration is picked up life so if
you want to change this configuration
you'd probably have to reboot the
coordinator actor so the rest of the
cluster can remain online with the actor
system which is using this configuration
will need to be restarted to pick it up
at least I don't know that that it will
pick it up life of course you could
programmatically make sure that you list
that you read the configuration file
every hour or something like that and
then reading the values again but I
don't know if you
if you do it life if it will work as
well so I think you have to reboot it
but can try it out so we say we have the
cluster so some some default
configuration here and we can get going
so if we now again have the coordinator
actor and we will send a message in this
case just an empty string I don't really
care what message is this I just want to
demonstrate the cluster capabilities so
we send an empty string to the empty
string actor on the first JVM or JVM -
in this case the empty string actor will
send an empty message back and what I do
on a coordinator actor is I simply keep
a hash map of the host names and
encounters so I can see how many
messages are processed by which note so
that's easy if I have an example and I
will show it in a minute with my
Raspberry Pi cluster so after we've sent
the first message to JVM - we do round
robin so now if we send a message it
will be sent to JVM tree same goes for
JVM for and of course we get the
messages back and we fill our hash map
with the number of course we're having
so to demonstrate it I could have used
of course a few applications on my
computer and just turn them on and then
distribute the messages but I thought
that was really cool and since raspberry
PI's are cool I brought a couple of
raspberry points not nicely in a nicely
enclosure so I had some colleagues that
called it a piece of crap but ok it
works so this is a collection of
raspberry PI's the bit foster wants -
raspberry pi twos and a couple of
raspberry pi zeroes so the raspberry pi
2 stores two of them there the seat
nodes there the Quaker so they can
handle it easily and we have three of
their bit slower raspberry pi zeros that
can handle the load as well so what I
now do is I simply so the stuff I just
showed you function functional wise I
will now execute it so the messages will
be sent to the different notes of course
if the demo is working
so we see here how many messages are
processed per IP address so this is
shout every few seconds I think we're
almost done so you see here that the
loads evenly distributed we use
round-robin so every node has handled
the same amount of messages or one has
handled one more but okay if you have
not the same amount as messages as the
amount of nodes then you will get some
differences in it but this is how easily
you can send messages in a cluster so to
do this you need a bit of more code to
keep track of the IP address and then
that's basically some yeah some go to
fill a hash map so I won't show that
code I will show you the code that's
just sending the messages across because
that's the most important part and
that's less code so it's easier to
understand for all of you so let's see
which one this one so this is the the
the router part so the backend part
where we have multiple nodes of so this
is running on my raspberry point we have
the application configuration so the
stuff now we have a cluster actor ref
provider instead of a remote actor a ref
provider remote part is basically the
same and we have some seed nodes we have
the scholar configuration here I
retrieve some port numbers to make sure
it is running on the correct port but
for the rest it's just getting a
reference to an actor and we have a
worker ref which is basically the same
as we've seen before if we get a message
we will simply print it so there's not
much difference from using local actors
or remote actors or using clustering
it's mainly just a bit of configuration
that is being changed and if we look at
the part that is calling this this
application it's basically most of the
configuration is the same the only
difference is here we define that we
have a router and that we want to do
routing
because in the calling part we have a
router the stuff that's running on the
Raspberry Pi of course it doesn't need
any router capabilities again we say
what the seed notes are and that's it
start up again simply retrieving a
reference to an actor and we can get
going so here is a little bit part of it
scheduling and so what you see here is I
scheduled that after five seconds every
second there will be a sent message sent
to self and self means the current actor
so we're now in coordinator actor so the
coordinator actor will receive the sent
message and here we have defined that if
we receive the sent message I will want
to send the router the message test
message and a simple counter so that I
can see how many messages are being
processed so this is basically an
everything you need to build a cluster
with writing capabilities and the
ability to just add extra nodes so you
can just live add extra notes and those
nodes can just register to the seat
nodes and you can directly use them
without having to restart your entire
application or all the applications
running on the different nodes so I
think that's that's a really powerful
capability and it works really nicely
and by the way not working for arc or
anything so I don't have any commercial
benefit telling you how great it is okay
so we have a cluster running but maybe
we want to have some stuff running only
once a day for instance what I said
before
we have a database backup and we want to
run that only once we don't want all our
notes to do a database backup and
because that then we do the same stuff
over and over again but we want to make
sure that that database backup is always
running even if one of the nodes fails I
still want to have my database backup
because if my server burns down I lost
data so what we can do is we can say we
have a complete cluster and the
is running somewhere on the cluster and
that seems like a bit of magic but the
thing is what what happens is there is
one actor which is the single term and
that will always be the singleton during
the lifetime and as soon as that actor
dies the actor systems will then start
negotiating a new singleton actor and
that new singleton actor will be created
on all this note living in the cluster
and what I say here you can use it
friends for scheduling cashing backups
or anything so how does it look like if
we again have the same example with the
cluster
now this JVM 2 actor system is chosen as
the actor system very singleton actor is
living so when we again start sending
messages from the actor in JVM one it
will be sent to this one because that's
the singleton actor we again keep track
of how many messages we receive and when
we send a second message it is again
sent to the singleton actor so with
clustering we had two routing that every
time another note was chosen with a
single turn it will always be sent to do
the same note so we keep on continuing
until that single to note is crashing
then the other nodes will start
communicating with each other and will
pick a new one and in this case the one
on JVM for was the longest-running note
and will then be chosen as the new
singleton actor note and we receive the
data from there and we then we can
continue using that actor system for the
rest of its lifetime so now that's the
singleton and we can just keep on
continuing and to show you that it
really works cause I mean I can talk
about it but maybe you don't believe me
so what we basically have is the same
code as I've shown you before we're
sending messages to to the router or to
to the our corrector systems but now
we're sending it to the singleton
instance if we now start I have to look
because I will pull out one of the
cables but I have to be careful to pick
the right one
so we start the test run and now if
everything works correctly only one
notes you to reply to the messages we
are sending and so we see note 1 or 81
it is responding so now I just simply
pull out the power of node 1 so points
respond anymore
the actress system we see some warnings
oh it's unreachable there will be some
negotiating so it takes a little bit of
time and after a while we see that note
2 is being picked up as the new
singleton note so it's just continuing
with its work so it's a nice way to make
sure that something is it's really
happening I mean I could have chosen to
run an actor system on one note and just
let that do all the singleton activities
but if that now dies then all those
activities stop working and now I have
failover options because it is just
running on the entire all the notes that
are being active at the moment
it depends on how you implement it by
default new loser of you but something i
sorry I didn't repeat the question I
believe so the question was what happens
to the messages sent when an actor dies
and the new actor singleton has to be
decided you lose a few messages but you
can solve that for instance with using
persistence or something like that
and make it a really resilient so okay
we can do clustering we can enable
multiple nodes so if you have a high
volume of loads we just put on lots of
extra raspberry pies or maybe actual
servers so that the load can be
distributed but sometimes it's difficult
to distribute the load or you want to
make sure that certain requests are
handled by a certain machine maybe if
you now we're talking on microservices
and database / micro service and if the
database is the bottleneck mean we can
add extra nodes but it won't help the
database won't get any faster but we
could decide that every micro service
which we implement in our craft course
has its own database and maybe even for
the same functionality so say we have
functionality to transfer an amount of
money from one bank to another bank and
we have one database and mean that's not
scalable at a certain point of time
because at one database is the
bottleneck we could also decide that we
have multiple micro services that each
serve a particular request so only for
users that have a lost name starting
with a B or C so we defined the stuff
we're processing in smaller units so we
create a micro service that handles all
first names with a B and C a Marc
service that handles the request with de
F etc so they're all handling their own
stuff they all have their own database
so database is no longer a bottleneck
that's in short what you can do with
which
so basically we're dividing the actors
over a cluster and partitions that's
basically what we do and we call those
groups charts and we can program at
ourselves so we can decide for ourselves
how we do the petitioning in shorts and
so for instance I could have chosen that
we have an even shorter on JVM too and
it will get all the even messages and we
have odd JVM on tree which will get all
odd messages so that's a simple way to
do sharding if you look at the code we
see that it's a you need a build
configuration for that let's see
so here is the configuration basically
for our shorts so do at the beginning
doesn't really matter that's mainly to
do some port configuration but here we
basically we define what should happen
in which case and we define a short
resolver so so for this we need a bit of
code because logically you want to
define your own shorts and you cannot
just hard code it or configure it easily
because you main may want to do it on
first name or on company or whatever and
you can define it yourself it with a bit
of coding but this is a bit more work
than than just using a cluster cluster
it has many defaults which are working
quite nicely and if you want to use
shorts you need a bit more configuration
for it
okay so yeah we have all those actors
really cool we keep on sending messages
across but I mean what happens if an
actor crashes like we for instance had
with the Singleton actor or what happens
if we want to store data somewhere I
mean most applications store some data
somewhere and there's also support for
that within acha with our core
persistence so basically we can store
actor information or you can recover
after a crash and it is possible to take
snapshots I will talk about that in a
moment with an example that's easier to
understand so if we start with an
example without persistence so what will
happen if we don't implement persistence
when we have a COBOL message and we send
that to an actor an actor is keeping a
list of the messages he is receiving
after that we send a Java message to the
actor so now the actor has two messages
Java and COBOL we have a crash and a
restart we get a new actor and we send
Scala to it only Scala is in the actor
so we lost all the previous messages and
I mean probably nobody would care if
Kobo would get lost but there are still
some Java programs and here I assume so
we want to fix that so how do we do that
within persistence we say that the stuff
that's coming in within the actor is a
command so now we have a Cobo command
coming into the position actor and we
have a journal and in a moment we will
see what the journal is doing so the
position actor is sending an event so no
longer the command that we just seen
with an event so it can contain other
stuff than the command that came in an
event will be stored in a journal the
journal will give an acknowledge to the
position actor and after that the
position actor will also have the
information in it so this is a simple
way to just store data in a journal we
do that with every Java so we have to
both the Cobo and a Java event in it if
now we again have no crash at the exact
same time with the two events in it the
following will happen all the stuff from
the journal will be replayed by the
actor so the actor will just process
those events again
we again have COBOL and Java in our
actor and then when we add Scala with
COBOL Java and Scala so basically what
we want
except for COBOL then if you have lots
of events and you have to replay all of
them there is a bit of a performance
impact and it's lots of small events and
it will be handled quite slow if you
have a lot of them and what you can do
then is make snapshots so what happens
is we can simply store a set of elements
from the journal so for instance the
state until event C++ so those two
events from the journal we simply store
them in a snapshot store then we add
Java and if we don't have a crash in a
restart we can simply first replay the
stuff from snapshot store and afterwards
we can replay the stuff from the journal
we could have optimized this of course
and remove COBOL and C++ from the
journal because it's already in the
snapshot store but for an example that's
I think white okay so Koblin C++ or reap
a replay it from the snapshot store and
Java is replayed from the journal and
then we again have the same solution so
you can choose to use snapshots mainly
for performance reasons but you don't
have to you can do everything with a
journal and of course we won't have
Scala in it as well
okay so actors a remote actors it all
works really well there's only one
disadvantage with rest you can simply
communicate with other systems maybe
even with a c-sharp application or
another language application with the
actor system it's it's really tight you
cannot just call an actor from another
language so we do then we still have the
need for some HTTP stuff and so what we
can do is we can create an actor with an
HTTP instance to connect to the evil
outside world and then the rest of our
system is just running with actors so as
soon as you want to have an endpoint for
instance because you have a JavaScript
front-end or another party that requires
you to define a rest interface you can
still do that and communicate with them
but cool isn't of course to not do that
and
from everything with actors but not
always possible so finite state machines
lots of applications they have like a
process where you go to registration and
maybe you can go back one page and you
can change some information and then you
can go forward again so it's basically
some states and some events to change
between those states and of course you
can program all those changes from state
and events into a new state with all
kinds of if statements and stuff like
that but that's not it's not really nice
and it is hard to test all those
different transitions between the states
because you ideally want to test all the
transitions so with finite state
machines we have state and events and in
this example I made it like this so we
have a few states we have a new project
with in progress project and we have a
crappy project so what happens here if
we receive a no progress event we will
stay in the same state if we receive a
progress event and our counter we keep
track of a counter is - then we also
stay in a new project size if we have
progress with an iteration so progress
in iteration is a message then we go to
the in progress project and so basically
we get a few iterations until we had to
the second iteration then we will stay
here so here we get the message work
harder and we get the message good job
wrong direction so project is failing
you should use akka because then your
project won't fail anymore now you are
improving a little bit but still in the
wrong direction you still should use
akka of course but I mean I feel two
failed attempts you just just get
another job and and let's see how that
looks
I just realized I didn't show you the
code for doing persistence so maybe
we'll start with death and so forth if
you want to use persistence you have to
configure like a journal as some kind of
database or something to store the
events of course so I choose to use
leveldb but you can use all kinds of
databases to store the events in so
that's something you have to configure
if if you don't come from your this
persistence won't work let's start with
the actor so what we have here is we
have a few commands but that's not the
most interesting part here we keep a
list of the states so this was the list
for COBOL
akka and Java wherein if I first start
with the receive command so if we
receive a new command so the command
Java or Scala or whatever it will be
persisted and we do an update state and
update state is mainly adding something
to the list so we get an extra item to
our list so we keep on continuing
persisting stuff and adding stuff to our
list until there is an exception and
what then happens is the receive recover
method will be called automatically and
receive recover here we say okay we have
an event and we want to replay that and
it's again just updating the same state
it's just filling the list again so it
is a bit of code like this basically and
of course the update state but I mean
you need that anyway if you want to add
something to a list but to build in
persistence you need like these four
lines of code and and and a little bit
here so in a few lines of code you can
persist anything and I mean I basically
persist the data I'm getting in but I
could also opt to just process the
subset of the data if I'm transferring
stuff over the wire
I'm only may be interested in the
customer IDs if I do a bank transfer I'm
not interested in somebody's home
or something like that I mean that data
shouldn't be persisted we just process
the data that we need you can choose
whatever you want to persist and if we
then look at the the finite state
machine so no configuration in here it's
quite simple how four possessed I didn't
show this startup once I promised so
this is what we do we sent the command
COBOL to the persistent actor that will
be persisted and put into the actor than
Java then we throw the exception
so without persisting then the list will
be empty but because we have implemented
positions and the replay events the list
will just the new actor will just get
the information from the journal and and
this is the example where I don't
possess stuff and it will just be thrown
away so it's quite basic stuff to get
working with with persistence if we look
to the finite state machine so we saw
that we had a few statuses we define it
as a trade and then we create objects
for the different statuses and we can
then say if we are in a new project
status when in the new project status
because we start with the new project
status and counter is zero we can say ok
if we now receive an event with progress
and two we say ok get another job but if
progress is it doesn't matter but not
two then we go to in progress project so
this way we can easily say when to
transfer to another state and we can
even supply information with it so the
counter is supplied with it and will be
updated during the runs the nice thing
of the exists is that it's also easy
testable so you can easily test how the
transactions are working between the
states or the transition sorry not the
transactions so it is a lot easier to
test finite state machines than writing
all kinds of if statements to do all the
transitions yourself
and we see here that there is an own
transition as well so if we go from a
new project to an in progress project we
will also print this line so we can
change states and if we are changing we
can print stuff or do actions when we
are in a state we can print stuff so you
can basically do anything around States
and yeah these these things
so on to do a conclusion of this really
fast introduction to lots of features
from akka and you can use use it with
Scala Java doesn't really matter what
you want and I like it a bit better with
Scala and you need less code and it
feels a bit more natural it's easier to
define what to do on which message so
pattern matching works a lot nicer but
you can do it in Java we've done
projects with that as well and you could
even do it in the net if you want to I
think it's quite easy to use but you
have to keep in mind some features are a
bit more experimental than other so be
sure to check out what the state says
before you're using these things in
production so it works quite stable but
they tend to change some stuff now and
then for instance akka HTTP was fairly
new and they changed quite some things
on that during the road so we'll be
careful with that if you want to check
out the examples there in this github
account if you have any questions you
can tweet me as well you can also ask
them now because we have plenty of time
left any questions yeah
okay so the question is what's the
compatibility between donut akka and JVM
akka
there's no compatibility is the easy
answer it uses all java serialization or
other serialization you can configure
that but it's quite tightly coupled to
your programming language so you cannot
easily communicate between actors on
different languages thank you all for
showing up and have a good day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>