<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Quickstart Hibernate OGM to tame an Infinispan distributed key/value store by Sanne Grinovero | Coder Coacher - Coaching Coders</title><meta content="Quickstart Hibernate OGM to tame an Infinispan distributed key/value store by Sanne Grinovero - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Quickstart Hibernate OGM to tame an Infinispan distributed key/value store by Sanne Grinovero</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8D8BfAaLsw0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">furgus inflated do it make sure welcome
everyone
not many people that a promise is going
to be quick and interesting so you can
run to lunch still so we're going to
talk about hybrid or GM in particular
about new developments we had to
integrate OGM with memory data grid and
I am parked on the infinite pond team so
two words about myself I've been
contributing to hibernate since almost
10 years now has been doing many things
I like Russian on performance and
scalability so I was also very
interested in the infinite plant project
which started eight years ago and I was
contributing back then already and so
now it seems like I was the best person
to integrate actually hibernate with
infinite pan as the data store not just
as a caching technology so I think I
hope you all know already about
hibernate and sits just at 50 minutes
we're just going to hope you do and so
typically you know hibernate is like the
Gateway or like the API the the
middleware between your applications to
your relational databases now
technically in your java api there is
really nothing to do with java with
sorry with sequel and you already see
that like with all the complexities that
you're facing with hibernate it really
is about the fact that the java objects
and a sequel word are really really
different so the conceptual change of
slipping from a relational database to
just any kind of database over there is
actually from a point of view of api or
hibernate user doesn't actually change
much like if you look at like the JPA
specification okay there is like a
create a native query but it's just
saying it's native it's not saying this
has to be like valid sequel or anything
like that like so if you look at all the
annotations on the specifications there
are some things which hint that there
might be tables behind this thing
and actually most mystical stores call
things like or tables or caches or
groups or documents or things which
actually map conceptually quite well now
what we also noticed is like in some
logical categories like graph databases
graph databases actually match your Java
objects quite better than relational
database because what you have in memory
is objects which are related to other
objects and you're trying to map this to
some kind of different store this
mapping is hard but when it comes to
like a graph database if it's the same
stuff so that Maps clicking well so what
are we talking here about is it like an
or m4 no sequel well we call it a GM
because we started as an object grid
mapper we were focusing on in finished
planning embedded mode that was like the
first experiment we did about five years
ago now running a finished part in
bedded mode is pretty much having a big
hash map which has high availability and
failover across different nodes what's
new about the recent development is you
are not only using in finish planning
embedded mode which is essentially
storing your data in the same heap user
application but separating concerns
which is now something that people like
in a microservices type to have database
back to a separate thing and so what
were what I'm presenting today is
totally new in the latest versions of
our GM which was released a couple of
months ago so getting back a bit on the
hybrid family you might know it as
hibernate or Ram but it's actually a bit
of a portfolio of different projects
interacting with data we know hibernate
or M which is like the flagship project
you know it quite well there is a
hibernate search which is a really cool
extension to allow you to do like better
full-text
queries on top of your model we
integrate with Allison and with elastic
search as well we have plans to
integrate other search engines when
hibernate validator
which is not so much about persistence
but it's very related to your data like
making sure that the stocks you are
storing is Malak data and it is of
course the reference specification for
the bean validation expander now
heydrich OGM is the new project we're
talking
here and just to make it really quick
what it is about I'm going to show you
right away some running code now using
an idea this resolution is not going to
be very easy but essentially this what
I'm showing here is actually a unit
tests and integration tests from the
hybrid regime source code project itself
so if you can want to check it out from
github into you can import a project in
your favorite IDE he'll have the same
thing that I'm about to run now now what
we have in this class this is an
integration test using our Killian
arquillian means we can we have like the
shrink-wrap component which allows me to
define deployment and we are defined
deploying a couple of beans and a
configuration file for hot rods which is
the client to connect an finished pan
and we are defining a persistence XML so
this is the DSL but it's generating
essentially the same XML format which is
to the deployment for a persistent XML
on the server what I like about having a
DSL is that since it's programmatic we
can you know invoke methods on different
tests and make changes dynamically
without having actual source skills like
hard-coded configurations so what you
can see here is this first property
we're setting this is a hybrid search
configuration because since we're using
a key value stored business search
engine so as an alternative to search
engine we want to use hybrid search to
be able to find data after it's stored
I'm setting this in memory just for
pickle data cast of course and then we
set the data store provider for OGM we
want to use the in finish memory mode
and then we have to this is not visible
sorry try to expand a bit so that it is
other property for GM which is going to
set which client configuration so how to
connect the data grid this is the
replacement of data source if you see
here there is no data source configured
in this configuration file and then well
we have one additional this is a
technical detail to make sure that the
OGM libraries are actually exposed to
their application when running on
work life so technically what's
happening here is you're running the JPA
application we're running it on white
fly and there is absolutely nothing new
in terms of like mind-blowing setup or
the dub setting the two properties here
which are I want to use OGM that's here
in the provider it actually is the same
thing as hybrid or M just with some
additional extension points which enable
the you know simple capabilities and
then of course there is no data source
and we replace this with here now if you
look at the parent plus this is an
actual enterprise javabean which will
get deployed and does some data
operations on the database now the good
the interesting thing is that this beam
is extended by various different
configurations so that OGM can test at
this same set of operations will work on
a relational database and on other data
stores like we have support for MongoDB
and I forget like neo4j that there are
several other alternatives so what's
nice here is a run it our integration
tests which set up is quite extensive so
here is running a website server it has
been packaging our just being built test
its in deployed and then it's also
running here is also starting an
infinite span server instances in a
separate idiom and here we are saying ok
the cache manager is now running then
it's deploying our application which is
using this magic card it's creating a
protocol schema which we are going to
see now and the protocol encoders which
are needed to encode your data in a
specific format for the hot sort client
and it's going to use this to actually
run a test rig and that's all it has to
show because we don't think it has much
time so now I'm going to go quickly back
to slides to explain what's actually
going on behind the scenes here but
really if you want to replicate this you
know it's just a maven project to import
it you will run it it will automatically
set up
whitefly set up the data grid then run a
shovel in all the dependencies and run
the configuration so
I think giving you a good starting point
to try something else so what is this
all doing well first off you should
never see the lies an object within your
key value store so even if it's a key
value thing if you are civilizing
objects as they are and then you make
any change then you are not going to be
able to read your data back so you need
to use this protocol encoders which are
like the standard format used in in hot
rods which is the wire protocol to use
to talk to a finished panel and this
protocol stuff actually looks a bit
scary because oh it's not that scary but
it's new thing that you have to learn
and you have to generate this is like an
example mapping you have to create these
objects and sorry these text files which
represent your schema and you have to
deploy them so it's pretty much like a
schema in a relational world the
different is fundamental that this is
not representing how your data is stored
on the server this is representing the
wire format of your messages so this is
about what you're sending back and forth
to the server which means like here in
this important identity we have to feels
like description both these are optional
even if maybe they are required from
your objects the thing is if you don't
want to do like a select statement and
just fetch IDs from the server you
wouldn't be able to just such an ID
without the description and the
WorldSkills if the eyes are mandatory so
to be able to run all the queries you
pretty much want to ask these components
like optional and we need to be able to
include all the types the Java types
into potable so this is all stuff that
high metal GM is taking care of
automatically then of course we have the
client you need in installation and
management you don't have to learn how
to bootstrap the hot rod client and how
to do pooling of connections and
especially which component of your
framework is going to make sure that
this is started or stopped at and all
that because well the good thing is like
since this is the real hybrid or am any
framework that you're using which is
able to booster fiber next it just has
to add the additional dependencies and
it will know how to start this you just
have to add the additional properties
and the
mmm extension so your framework already
knows how to manage the connections to
the server and the data grid and all
that well compared to using hot rod
directly what so directly would
essentially give you an API which is put
together you can use some batching but
it gets quite complex and you cannot map
any relations like exception handling is
totally different and so I think there
this helps a bit it doesn't do sequence
generation so if you need IDs to be
generated that's going to be really
tough piece of code that you have to
write because it is just a map and it
can support some atomic operations but
the atomic operations you need to learn
about the specific semantics and the
specific semantics actually vary
depending on the configuration you're
using so there are some combinations
which are just not valid that you're
just going to generate duplicate IDs and
your data is not going to be very well
so I suggest to not use this feature and
you know just use application of science
IDs which are the most efficient in this
case but if you want to migrate or just
ease of use and get started and have the
application to use auto-generated IDs
ugm knows how to do that and then
relation if you have foreign keys
everybody has foreign keys I think we're
a bit spoiled in the relational world
because they just work we have integrity
checks we we know when something is
going wrong if the database will take
care of us not doings and mistakes all
the safety bills that we are spoiled
with they are gone when you're using a
like a no sequel store which doesn't
have referential integrity checks so you
have to write your code to make sure
like if you're not using OPM to make
sure that all the different relations
are always going consistent and well
twitter that's just really boring and we
all have something better to do so it's
good to have a framework which like
forum
knows since many years how to do it it's
because it does it on the database you
have to write things in the right order
and we do the same on here
so to wrap it up here I've been using in
Finnish pan a lot it's very flexible
because it can be cured like crazy to
get really high performance out of it
the downside of all these tuning options
and flags and advanced api's which are
in there is that you can really hurt
yourself like do something totally wrong
because there is a little
misunderstanding of what an API is
effect actor is going to be in a
concurrent environment or in large-scale
environment so what I think I'm giving
with OGM is really like hard coding my
experience in there like if you need to
store these things in the specific way
letting tastic girl feel like this is
how it should be done and we work with
the infinite banking to make sure that
we are actually doing the right thing we
have some more things planned which are
not there yet
so at this point it generated schemas
which we are creating they do not
support embedded objects like the
protobuf actually is more like a
document store so we can embed nested
collections in there and as you have
like embeddable collections we could
actually embed them in like the parent
objects and this this is like a nice
mapping 12 in some cases another thing
is like while we can generate the
protobufs encoders and the schemas we
cannot actually generate we cannot
connect to the server and define the
caches that need to be created to run
our application so you would have to
create those in advance but we're
working on now we can finish Pentium 2
as new metals that we can call like with
the privilege its operation to actually
create the caches for you and
transactions is coming as well
transaction is a hit which exists in log
very long time in a finish permit only
if you run it in embedded mode here
we're talking about connecting to
infinite span over this hot rod protocol
in which case you don't have
transactions yet that should be comment
there are already working on that
finally something that is missing on the
OGM component for this specific
integration is we do not have the
translation of queries LEDs we have it
for some other backends like if you're
using MongoDB or near 4j
we can actually translate your data QL
or operations into the native query
language and crateria operations are not
supported on any system yet but they
will come when hibernates or m6 arrives
because we are actually writing the
world strategy of generating queries
within the engine the main reason is
actually to get my crazy performance of
it immunizations doable on the
relational database world but a GM is
going to benefit to get the chance of
actually converting criteria ng dql to
native queries that's all I had and
we're a bit short any question was I
going too fast too many complex concepts
so the API is going to be exactly the
same because it's standard specification
right but what we do internally yes it's
a major rewrite it's a massive amount of
work what's actually happening is about
today behind the scenes it's like
generating snippets of strings and then
these get appended and sent to the
database in hope that the database would
know how to optimize that what we're
doing now is actually have a semantic
query parser and we're building a
semantic tree which is expressing the
intent of the operation which means the
different dialects for different
relational database will be able to have
something more like a compiler strategy
so that we can actually generate
entirely different style of operations
to push the performance to the maximum
yeah yeah
yes that's a very good question so he is
asking if I can summarize it if we will
be able to express all the complex and
advanced at the relational features that
the criteria API are exposing which are
very much relational in nature and map
those on all the nodes equal stores
probably know we have we have several
ideas to explore one of them is to
include teeth which is an open source
project behind the tables data
digitalization T is pretty much able to
transform any kind of source in a
relational engine and be able to run
signal operations on it like with my
customers using it through you know
connector spreadsheets through CVS files
from other files which are FTP and
people can query it is using sequel and
it has a really clever optimization
engine in there so that might be a way
of course if your if you need really
relational kind of analytics you
wouldn't use the key value story right
so that's a bit of the thing and I think
the Holy Grail is going to be like
having a hybrid storage so that you
would be able to have your model
partially muppets on like a key value
store and partially map it on the
different system so that you can pick
like this section of the data is that is
best served by let's say MongoDB for
example and you mix these different
things as as a matter of configuration
really yeah yeah because if you have any
more questions I'll be around and I must
get the reddit booth but they walking
around put everybody thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>