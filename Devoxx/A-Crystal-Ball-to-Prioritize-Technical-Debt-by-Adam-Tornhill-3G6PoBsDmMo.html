<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Crystal Ball to Prioritize Technical Debt by Adam Tornhill | Coder Coacher - Coaching Coders</title><meta content="A Crystal Ball to Prioritize Technical Debt by Adam Tornhill - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Crystal Ball to Prioritize Technical Debt by Adam Tornhill</b></h2><h5 class="post__date">2018-03-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3G6PoBsDmMo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so good morning everyone can you hear me
fine perfect really nice to see you so
welcome to this talk on a crystal ball a
crystal ball that will help us to not
only identify but also to prioritize
technical depth so let us jump right in
and see what this is all about and my
sterling pointer is martin fowler's
well-known definition of technical depth
and I want us to focus on the key aspect
here and the key aspect of technical
depth is that just like its financial
counterpart technical depth incurs
interest payments and this is something
I found that we in the software industry
seems to sometimes misunderstand and
sometimes misuse and as a consequence
technical depth the wire concept is not
as useful or helpful as it could be let
me show you an example on that so what's
going to happen now is that I'm going to
do a small test or rather you are going
to do a small test you weren't prepared
for that that early in the morning were
you but here we go what's going to
happen now is that I'm going to put up a
piece of code here and your task is to
judge the quality of that piece of code
are you ready you do look ready here we
go have a look at this beauty what do
you think about that how many think that
this is great
fabulous code not so many how many would
let it through a code review wow it's
really just me of course this is not
good code this is not the kind of code
we would like to see and we would of
course never ever write code like this
ourselves never but is it a problem is
the technical depth without more context
we just cannot tell because it's not
technical depth unless we pay interest
rate on it an interest rate interesting
enough is a function of time so that
means in order to decide
this is technical left or not we would
need a time dimension into our code
where can we get such a thing in a few
minutes I'm going to show you one
possible way but before we go there I
would like to share a little story with
you
now as part of my day job I go to
different organizations and I analyze
the code and try to come up with some
recommendations on how they can reduce
their technical depth and last year I
visited one organization that prior to
my arrival had used the tool capable of
quantifying technical depth so they had
taken this tool and thrown it at their
15-year old codebase and this tool
reported that on your 15 year old
codebase you have accumulated 4,000
years of technical depth 4,000 years
right just to put that into perspective
4,000 years ago that was here when Moses
parted the Red Sea so 4000 years of
technical left I mean it may well be
accurate but it's not particularly
helpful I mean where do you start if you
want to pay it off is all that it depth
equally important besides I think it's a
mistake to try to quantify technical
depth from code alone and the reason I
think that is because most technical
depth isn't even technical and again
this is something I find over and over
again as I work with different
organizations that we developers we tend
to mistake organizational problems for
technical issues and the consequence is
that we start to treat the symptoms
instead of the true disease so let me
give you some quick examples and when
that can happen perhaps you have
experienced this yourself you know you
start out on a new assignment or a new
job and the first day you'll get there
someone's takes care of you show you
around and they talk a bit about your
system you're supposed to build and they
tell you that I watch out for this part
of the code over here it's really really
nasty you don't want to go that right
it's really hard to understand you
recognize that
or maybe my pertly maybe I've seen my
personal favorite this is one I really
love come across it several times
let's see if you have heard this one
yeah we spend a lot of time merging our
different feature branches we need to
buy better merge tools as you will see
tooling might not be the problem there
might be a social side to that and we're
going to cover that layer today but I
would like to point out that I think the
main reason that we keep making this
misattribution is because the
organization that builds the system is
invisible in the code itself and this is
really really unfortunate because there
is a very strong link between technical
depth and organization behind the code
base and I'm pretty sure that we will
never be able to successfully address
technical depth unless we take a
holistic view of the concept and that
holistic view has to include a social
and organizational side so let me try to
put all this together so far I pointed
out a number of issues with technical
depth and what I did now is that I put
together a wish list and a kind of ideal
information that I think we will need in
order to successfully address technical
depth so let's have a look at that the
first thing we like to know is given all
our code where's the code with the
highest interest rate the second thing
we would like to know is how does it
look from an architectural perspective
do we work with or against our
architecture which is actually quite
common and finally and perhaps most
important how does it look from an
organizational perspective or any team
productivity bottlenecks you know those
parts of the code where five different
teams continuously have to coordinate
and synchronize their work now I hope
you all agree with me that this is
information that's useful to us that can
help us do a better job however I would
like to point out that none of this
information is available in code itself
more importantly we like a time
dimension and we like social data so how
can we get the kind of data where's our
crystal ball it turns out you all
already have one we just not used to
think about it that way I'm talking
about this our version control later our
version control later is an
informational goldmine and I find it
fascinating that version control later
it's something that we have used
traditionally as more or less a
complicated backup system and
occasionally as a coordination tool and
then almost a society effect we have
built up all this wonderful behavioral
data that's just waiting for us to
inspect mine and get information so this
is just a simple example from gift and
you see that we get a time dimension
with version control we know exactly
which part is software that were changed
at which point in time and even more
importantly version control data is
social data so that means we know
exactly which developer that worked with
which parts of the code over time so
let's embrace version control data as
our crystal ball and let's see where it
takes us and let's start by trying to
uncover the code with the highest
interest rate and the technique I use
for this is something I call hotspots
now I'm going to walk you through this
visualization in a minute this is a
hotspot analysis of a well-known mature
Java code base Tomcat how many of you
have worked with Tomcat Wow
almost everyone how many have looked at
the code so 1015 people may be cool so
let's see what we see here
so this visualization have a look at
those large blue circles the ones that
link on screen right now each one of
those represents a folder in that code
base so this is a hierarchical
association that follows the folder
structure of your code it's also an
interactive Association which is
important once you get to larger systems
so that means you can zoom in on any
level of detail you're interested in and
when you do that you will see that each
file is visualized as a circle and you
will see that the circles have different
size that's because the size of the
circle is used to express something
called a code complexity that is how
hard is this code for a human to
understand now how do you
measure a finger code complexity well we
have a bunch of different ways of doing
that you might have heard about things
like yeah cyclomatic complexity
cognitive complexity nested-if function
complexity and so on and what they all
have in common is that they are pretty
bad at actually predicting complexity so
what I tend to recommend is to use the
simplest thing that could possibly work
and that is the number of lines of code
yes it's a lousy complexity metric but
it will give you an indication and it's
simple and language neutral besides
that's not the interesting dimension the
interesting thing when it comes to
complexity is to know if this complexity
actually affects us is this a part of
the code where we need to work and this
is data that we can pull out of a
version control system so we can look at
how often you actually work in each part
of the code we calculate the change
frequency of the code and use that as a
proxy for interest rate on any technical
depth now when we combine these two
dimensions were able to identify
complicated code that you have to work
with often and those are our hotspots so
let's return to Tomcat if we as you see
here on the hotspot analysis there are
relative spots make up relatively few
parts of the code there are not that
many of them right now what does a
hotspot actually tell us first of all a
hotspot doesn't say it's a problem
necessarily it just tells you that this
code is a little bit extra important to
you so the hotspots are the part of the
code where it's really really really
important that code is easy to
understand easy to evolve and easy to
maintain because that's where you spend
most of your time in practice more often
than not the opposite is true and that
tends to make hotspots excellent
refactoring candidates and there's a
fascinating reason why that works so how
many of you have read any work by George
oh well yeah cool so those of you who
have read at George Orwell you might
remember that he once said that
code is equal but some code is more
equal than others now what do I mean
about this well have a look at the
following roughs each one of those
graphs show exactly the same thing here
on the x-axis you have each file in the
system and those files are sorted
according to this change frequency that
is how many commits have we done to that
file and the number of commits is what
you see in the y-axis now have a look at
those free examples on top there they
show a free-radical a different code
bases developed in different programming
languages targeting different domains
different life time spans different
developers different organizations
everything is different yet do you see
any similarities in the patterns that's
right they all show exactly the same
distribution they show a power-law
distribution and this is something I've
found in every single code base that
I've analyzed this seems to be the way
that software evolves and this is
important because it gives us a tool to
prioritize because what this means is
that most of our code will be here in
the longtail that's code that's rarely
if ever touched and most of our work
will be done in a relatively small part
of the code base so that's the part
where we will prioritize improvements
and be pretty sure that we get a real
return on that investment and hotspots
point you to precisely those parts that
matter so hotspots are a really really
good starting point but sometimes they
are not enough and I would like to show
you an example on when hotspots don't
work now I'm going to switch code base
I'm going to switch code base to a code
base that I think a lot of you actually
have running on your laptops right now
the dotnet core runtime from Microsoft
the.net core runtime is a fascinating
piece of software so when I did this hot
spot analysis I think it's like six
seven months ago but it looks pretty
familiar too
most of the hotspots were here they were
in a cluster inside a JIT package ah
that's the just-in-time compilation
support interesting but even more
interesting is this satellite that we
see here
this satellite hot spot this is a file
called GC dot CPP hmm
that's the dotnet garbage collector
interesting now GC dot CPP might look
quite innocent here on screen but that's
just because the scale of dotnet core
dotnet core is a big code base so what
you see here on screen is almost four
million lines of code and GC dot CPP is
a pretty big file how big I don't really
have any ID
so let's look it up on github here's
what it looks like all right so it's so
big that github fails to wish air lysis
we using a syntax markup so we need to
look at the raw file and when we do that
we find out that GC dot CPP consists of
firday 7,000 lines of C++ firday 7,000
lines of C++ now let me tell you I used
to be a C++ developer I did C++ for more
than 10 years and I know what you all
think those are 10 years I'll never get
back
but that's not like my main point right
my main point is that I have a lot of
respect for further seven thousand lines
of CSS but it's quite scary stuff right
that's the stuff nightmares are made of
and besides how useful would it be to
know that GC dot CPP is a hot spot let's
say I get to your organization and I
analyze your codebase and say hey look I
found your worst maintenance problems
you just rewrite this file with first
seven lines of C++ and all your problems
will go away
would that be helpful no not really how
do you react on that information the
answer is you don't you need much more
detailed information so what I do when I
come across those large hotspots is that
I use the following technique
I take that locked file and then I parse
it into the different functions and then
I look at the commits in which functions
do they hit over time so that let me
calculate hot spots on a function level
let me show you an example from GC dot
cpp here it is so these are the hotspot
level functions inside GC dot cpp and
you see that the number one final number
one hot spot on a function level is
something called grow brick card-tables
whatever that is we see that it's a
pretty big function 332 lines of code
it's quite a lot for single function
isn't it but it's much less than 47,000
lines of code which was the size of a
total file and it's definitely less than
4 million lines of code which was the
size of a total system so more
importantly we are now at a level where
we can act upon the information and do a
focused refactoring based on how we
actually work with the code now I'm
going to come back to the hotspots but
before that I would like to give you a
book recommendation this is a book
called the Challenger launch decision
written by Dale Morgan and it's the best
book and no on how organizations fail
now Diane Morgan is fascinating because
she Sam she's not a software developer
she's not a programmer she's a
sociologist and she studied the
Challenger launch accident so how many
of you remember the Challenger accident
while so like half of you right so let's
cover this briefly this is the space
shuttle Challenger on its final launch
back in 1986 and this is the actual
Space Shuttle the white large object
that you see here in front of you that's
something called a solid rocket booster
now those solid rocket boosters those
are huge huge rockets in fact they are
so big that they're delivered in three
separate segments that are then
assembled before launch now if you look
at that solid rocket booster you see a
puff of gray smoke here you see it it's
not a good thing
not supposed to be there so what
actually happened here was that one of
those solid rocket booster joints failed
to seal and as a consequence hot rocket
gases were able to escape an impact and
compromised the structure of the whole
space shuttle system and once it get
into the air it just disintegrated now
what Diane Warren in her book was that
already back in the 1970s during the
early design of the space shuttle system
the early designs tests they showed that
those solid rocket booster joints their
actual performance deviates from the
predicted performance that's not a good
thing if you want to fly rockets what do
you do well if you're no sites easy you
just form a committee so they did and
they discussed the problem and decided
to pass it off as an acceptable risk
years later in the early 90s during the
first in flight tests again the first
test showed that the actual performance
of those solid rocket booster joints
deviated from the predicted performance
again it was discussed and passed off as
an acceptable risk and it went on and on
like that for years before underwear we
eve of the launch there were some
worried serious concerns raised by some
engineers due to the unusually cold
temperatures in Florida at that time and
again the problem was discussed and
passed off as an acceptable risk and the
consequence was a tragic loss of human
lives this is what diane wagons the
normalization of Debian's that each time
we accept a deviation those deviations
become a new normal we get a new point
of reference and what I find so
fascinating about that is that the
normalization of deviance has nothing at
all to do with spaceships it's all about
people people like us who develop
software and we have plenty of
normalization of deviance when in the
software industry too so think back to
this file with further 7,000 lines of
C++ how do you get there well let's say
that you inherit a file with 5,000 lines
of code
at first you might not be that
happy about it but if you spend enough
time with it soon you start to feel
familiar with the code and I mean
besides you have five thousand lines of
codes what difference that's 100 extra
lines of code ooh so soon you have six
thousand lines of code then you have
seven thousand lines of code and so on
and we need a way to detect stop and
fight the normalization of Debian's
here's one technique I've been using for
that this is something I call complexity
trends and they're pretty simple to
calculate all I do is I go to am a
version control system for each hotspot
and then I pull out all historic
revisions of that code and then I
measure the code complexity using any
metric you want it could be cyclomatic
complexity whatever and plot the trend
over time so that's the red line here
the blue line is just our count of the
lines of code as a reference now what
offense are fascinating about complexity
trends is that all systems tell stories
we just need to learn to read them so
let's have a look at this example this
is actual a piece of code drive where I
worked myself to so what happened here
was sometime in 2016 we did a
refactoring you can actually detect that
small improvement right to some slight
decrease in complexity but we probably
failed to address the true root cause so
pretty soon the complexity keeps
creeping back in again and here early
2017 there's a steep increase in
complexity which is a warning sign it's
a sign that we might have to take a step
back and investigate what's actually
going on here the normalization of
deviance is one of the reasons why
whistleblowers are so important to an
organization and I have found that
complexity trends are excellent
whistleblowers in code now to sum up my
hot spots hot spots helped us identify
the code with the highest interest rate
and every Sun hot spots work is because
all code isn't equal now let's continue
by talking a little bit about how you
can use the same thing
nice $2.00 a tear architectural patterns
and as you all know you cannot really
talk about architecture without
mentioning art now how many of you
recognize this painting no one that's
really really good because it doesn't
exist this is something called a liquid
crystal light projection done by the
artist Gustav Metzger and what's so
fascinating about this crystal light
projection is that it changes it morphs
all the time right
so this artwork looks completely
different today than it did yesterday
and what I find fascinating is the way
it changes because the way it changes is
that it necessitates the destruction of
an existing form for the creation of a
new form and what I like about that is
because that's exactly the way software
is supposed to evolve and it's also
reason I like hot spots because they
make it clear that a code base is never
done successful code will evolve it will
change and that's actually a good thing
it means we have users right however the
reason I say code is Auto stress
directive is because changes and new
features tend to become increasingly
more difficult to implement over time
and some systems they just reach a
tipping point and beyond that point they
become virtually impossible to maintain
so how can we detect that how can we
detect those parts of the code well we
have hot spots right so hot spots might
work on our function or a file level but
in a large system with million lines of
code or maybe distributed distributed
system like micro service system we need
a higher level view so one concept I've
been using is the following instead of
focusing on individual files what I do
now is to take a group of files maybe
even a whole folder of files and then a
map that to a logical name a logical
component and what I do then is that I
just aggregate all version control
activity on any file within that logical
component i aggregate it and sum it up
and that let us calculate hotspots
an architectural level and most
importantly you can use any grouping you
want the important thing is just that
your logical components carry a meaning
from our architectural perspective so
they say should have some architectural
significance now using this data we can
start to ask the right questions let me
show you an example from our
service-oriented architecture now this
kind of data can help us answer one of
the big big big questions we have around
microservices and this is a really big
question because this is a question that
you know if you look at internet flame
wars have been fought about it
friendships have been ended and that
question is how big is micro service
supposed to be 100 lines 1,000 lines
mm well we all know it's a kind of
pointless and misdirected reason about
micro service I'm size in terms of lines
of code what we're after is business
capabilities we want each service to
implement a single business capability
so let's see how we can supervise that
so what I do now is that I take all
files that belong to a single service
aggregate the contributions to all of
those and calculate hotspots on a
service level and here's an example from
our real word micro service system and
we see that the number one hotspot is
something called a recommendation
service now we can also calculate
complexity trends based on those
boundaries and when we do that we see
that this is some piece of code that
seems to have evolved rapidly and then
stabilized at a very high complexity
level where we keep changes all the time
and it's around 5,000 lines of code now
using this data we can start to ask the
right questions we can ask questions
like does this service with 5,000 lines
of code that changes at a rapid rate
does it really implement a single
business capability or is it maybe a
service that has two or three or four
different responsibilities and would be
better off when split into multiple
different services
but we can do much much more once we
embrace version control later and I want
to show you one more thing and in order
to do that I want to introduce a concept
called temporary coupling now temporary
coupling is different from the way we
typically talk about coupling because
temporary coupling is invisible in the
code itself it's something can only
detect from the evolution of the code
here's how it works let's say we have a
simple system here just three different
subsystems and the first time I do a
change to the system I modified a fuel
injector and a Diagnostics module
together the next time I modify
something else the third time I'm back
to modify the fuel injector and the
Diagnostics module now if this is a
trend that continues there has to be
some kind of relationship between a fuel
injector and the Diagnostics module
right because they keep changing
together over time they are coupled in
time they have a temporal coupling so
let's see how we can use temporal
coupling to evaluate our architectural
patterns I'd like to start by discussing
a layered architecture a layered
architecture are quite popular and what
I find fascinating is that when I get to
a client and ask them what kind of
architecture you have and they say oh we
saw a Model View controller and they
might even draw something like that
however then I look at the code and
that's never ever what it looks like
because we all know we need a services
layer - of course right so we can stuff
some business logic in there and then of
course we need a repository layer and
the reason we need a repository layer is
actually I don't know I've never seen
any use for it so let's call it a best
practice and then below that we might
have an object relational mapper who
don't have to access the sequel directly
and then maybe we have some sequel at
the end and in reality we might have
even more layers right we might have
things like view helpers and whatnot so
it's not uncommon that you see 10 11
different layers now when I do an
architectural analysis what I do here is
I aggregate all contributions to all
files within each layer consider each
layer logical component and then I
calculate temporal coupling on that
level now what do you think the temporal
coupling looks like in a layered
architecture usually something like this
in fact I've found that somewhere
between further to 70% of all commits
than to read through the entire
architectural stack and this is pretty
fascinating because what's the main
motivation behind the layered
architecture one thing I always heard
was that it's a separation of concerns
and it is but it's a separation along
technical concerns each one of those
represents a technical building block
however the work that we do tends to be
feature oriented tends to be an user
driven and that is at conflict with the
technical architecture and the
consequence is that few changes are
local most of our changes ripple across
the architecture now a layered
architecture like this might work really
well for a small team I've seen it work
well I think the main problems I've seen
starts once the organizational size is a
little bit bigger let's say you have
maybe just 1012 people working on that
on architecture like that what happens
now is that you run into a bunch of
different coordination problems because
suddenly all developers need to work in
all parts of the code all the time and
this is something we're going to come
back to in a few minutes but I like to
point out and I think that this failure
to separate around them and use
requirements and features is one of the
main motivations and one of the main
reasons when microservices have become
so incredibly popular over the past
years so let's have a quick look at
micro services so as we all know this is
what micro services always look like in
PowerPoint
in reality they tend to be much more
complex right so we might have shared
building blocks we might have service
time
lights client api's cross-cutting
concerns like monitoring and diagnostics
and so on so all that extra complexity
puts it at risk for one of the cardinal
sins of micro-services and one of the
cardinal sins of micro-services is tight
coupling the moment we start to couple
different services to each other we lose
most of the advantages on microservice
architecture and are left with an excess
mass of complexity so if we haven't
fundamental architecture a principle
like that
why don't we measure and supervise it so
temporar coupling works really well for
that purpose so all you have to do is
again aggregate all contributions that
belong to each service and calculate
like logic you could calculate temporal
coupling between different services in
particular you want to watch out for
panels like this when multiple services
tend to be changed together over time
this a few is tempera coupling at this
you might be able to get an early
warning on early warning that can help
you prevent what I call the
microservices shotgun surgery pattern
now the microservices shotgun surgery
pattern that's basically when you know
you want to tweak a single business
capability and you end up modifying five
different services and there are several
reasons why that happens the most common
reasons I am seeing out in the wild is
that first of all different services
might share code that itself isn't
stable from an evolutionary perspective
so changes to that shared code ripples
to other parts services may also be
leaky abstractions so that means that
other services come to depend upon
implementation details and they get
coupled in time finally I've seen that
this is a more common problem when the
same team is responsible for multiple of
related services now before I move on I
would like to show you what kind of
tools I used to do this analysis in case
you want to try it on your own code this
is still a young and evolving field when
I started out with this analysis was
like maybe almost 10 years ago there
weren't any tools
available that can do the kind of
analysis I wanted to do so I put
together an open-source tool suite
called code matte it's still available
my github account I still maintain it
and it might be a good starting point
what I'm working on right now is our
product called code scene codes in is
free to use for open source projects so
if you like these techniques please have
a look at it there are also several good
tools from the academic space so one of
my personal favorites is something
called evolution radar which is really
really strong on temporal coupling and
then finally in case you want to build
your own tools I recommend that you have
a look at the moose platform so the
moose platform is basically a framework
a platform for building software
analyzers and moose platform is also a
great excuse to learn to program in
Smalltalk wonderful language really now
what I want to show you now was the
taught spots scaled to an architectural
level and we have also introduced the
concept of tank mark coupling that may
help us evaluate a supervisor
architectural patterns now I want to
cover the final segment in this
presentation where I want us all to
explore the social side of our code base
let me start by asking you how many of
you in your day job develop software as
part of a team so that's like as close
to 100% as it gets cool most of us do
that right we have to do that because we
keep on taking on larger and larger more
more complex problems and we cannot do
it alone so we need to get together in
order to get things done however what we
rarely talk about are the costs of
teamwork because there is always going
to be a cost and this cost is something
that social psychologists refer to as a
process loss now process loss is a
concept from social psychology the
social psychologists have taken from the
field of mechanics and the idea here is
that just like a machine cannot operate
at 100% efficiency all the time due to
things like friction and heat loss
neither can our team there's always
going to be a cost and that cost is
called process loss so we see an example
here where we have a bunch of individual
contributors and together they have a
potential productivity that's never ever
what you get out of a team the real
productivity is always smaller and part
of the potential is simply lost now what
kind of process loss is it well it
depends on the task but if you take
something like software where we have
complex inter dependencies between
different parts of the work you would
see that most process loss is typically
communication coordination and
motivational and another common reason
for process loss is a concept called
diffusion of responsibility so before I
talk about diffusion of responsibility I
need to warn you that I'm going to talk
about a really controversial topic here
it's that kind of topic you don't even
mention it right you're not supposed to
talk about it at conferences but I need
to go there so sit tight because I'm
going to talk about code ownership yeah
I'm going to do that so I just want to
point out when I talk about code
ownership I don't mean ownership in the
sense that hey this is my code stay away
no I mean ownership in the sense that
someone takes a personal responsibility
for the quality and the future of a
piece of code the reason I think that is
important is because of this principle
diffusion of responsibility which is
another ID from social psychology and
the diffusion of responsibility is
something that you can see in the real
word in case you're unfortunate enough
to witness an accident or an emergency
because it turns out the larger and a
group of bystanders the less likely that
an individual will offer help so this is
actually quite scary
and there are several reasons for the
diffusion of responsibility one of the
main reasons is because we in a large
group we don't feel a sense of personal
responsibility and we just assume that
someone else will help instead and I'm
pretty sure that this should be a
driving principle behind
- in good software I'm pretty sure you
have a sense of personal responsibility
for everyone involved and I don't think
there's any way around it now if we have
an important principle like the
diffusion for responsibility how can we
measure it oh it's easy
remember we're in version control
Wonderland subversion control system
knows exactly which developer that
worked on which part of the code so we
just aggregate individual contributions
into their teams and from there we can
measure the overlap between different
teams in the codebase so this is the
same kind of visualization that we used
for the hot spots only now the color
carries a different meaning so the color
signals the amount of potential
coordination between different teams so
the more separate teams that work in
each part of the code the more diffused
their contributions the more red that
part of the software now once you
identify parts of the code that looks
like this with a high amount of
diffusion of responsibility between
different teams you need to react to
that finding and this the bad news here
is that it's usually pretty hard in
practice there are typically two things
I've seen work the first thing I do when
identify Co like this instead I look at
it from a technical perspective and the
reason I do that is because you will
find out that code typically changes for
a reason
and the reason that part of the code
attracts contributions from multiple
different teams is typically because it
has good reasons to do so it has too
many responsibilities so simply
identifying those different
responsibilities and start to split the
code according to those responsibilities
will increase the cohesion of your
solution and provide natural boundaries
for the different teams and help you
minimize the organizational coordination
needs in your code base a second quite
common case that I found is that
sometimes organizations need to
introduce another team to take on a
shared responsibility
sometimes you might find that there's a
team missing now using social data like
this we can take it a step further and
actually start to measure things like
Conway's law how well aligned
are we as an organization with the code
we build so it's the same visualization
style but now each color represents the
contributions of each team so this makes
it possible to see things like this
which is actually quite unique
right from the perspective of Conway's
law if you look at this you see that
each team pretty much our own module
where they can work in complete
isolation with the minimum of overhead
this is wonderful isn't it it's also a
lie because I have to make a confession
here all data you have seen so far are
from real word systems except this one I
had to make it up because I'm here to
find the organization that's that well
aligned with the code and I'm not even
sure you want to be that so I want to
show you one more realistic example from
a real world system because this is a
common pattern so this is a story about
the company that decided they wanted to
introduce feature teams so what they did
was they took their existing
organization and sliced it into twelve
separate feature teams they worked in
sprints so at the start of each sprint
each team were given a number of tasks
and then let loose on a codebase
and what you see here is the
contributions of the different teams
over just a single month now do you see
any patterns there you have to look
really really deep and I mean there's
might be one or two components that are
almost but not really in the hands of a
single team what you have here in
general is true collective cows you have
12 teams that work in the same parts of
the code all the time for different
reasons because they work in different
stories not only is this going to be
incredibly expensive to coordinate it's
also a missed opportunity because what
will happen here is that you will miss
synergies between different
features that is an opportunity to
simplify both the solution and the
problem domain so please align your
architecture and your organization your
code is going to thank you for it now
I'm almost done and I hope you enjoyed
this journey for the field of evolving
code and behavioral code analysis so
ultimately it's all about writing better
software software that's able to evolve
and withstand the pressure of new
features novel you suggest and change
circumstances a Verizon code of that
quality is never going to be easy
so I'm pretty sure that we need all the
support we can get and I hope this
introduction to behavioral code analysis
using a crystal ball has inspired you to
investigate the field in more depth and
to help you get started I put together a
number of references here I have a brand
new book and this came out just the
other week where I go into all these
analysis in much more detail then also
blog about it
so check out and peer comm where present
a bunch of different case studies from
real word systems and finally in case
you want to play around with code scene
it's located at codes in i/o and now
before I leave a few minutes for
questions I would like to take this
opportunity and say thanks a lot for
showing up this morning thanks a lot for
listening to me and may the code be with
you thanks
Thanks
so so if the tooling is for yes it does
it does so that's quite fascinating
right because version control data
itself is language neutral so basically
this analysis works on any kind of
content that you have in version control
the only thing that is language specific
that's when you want to start to measure
things like code complexity as long as
you go with simple metrics like
calculate the lines of code you can get
really really far without having any
language specific tooling at all it's
also fascinating to note that since its
language neutral you might find it
really really interesting patterns so
one of my favorite examples is do have
any dotnet developers here any dot net
developer one - Wow oh all right so I
used to be done that dotnet developer to
sort or free of us right yeah so anyway
a the rest of you might be familiar with
Microsoft's ruslan system
it's a compiler platform when implement
two compilers themself Visual Basic
compiler and a c-sharp compiler now if
you do a temporal coupling analysis of
ruslan you will find that you have
temporal coupling between the visual
basic parts and the c-sharp parts
because they're pretty much mirror each
other's design so I find it really
really fascinating because you cannot
see that in the code itself but you can
see it in the virtual control data that
when you do a change here we also have a
change over here and that makes it
really really useful as a way to explore
and learn the system so it's something I
think will grow in importance now that
our systems become more and more
disconnected with more and more complex
into relationships like microservices so
one more question yes please
so basically the question is once you
have a hot spot how do you know the
reason of that hot spot assist you to
changes in requirements something
external or is it because the code
quality isn't good so you need to do a
lot of bug fixes and basically you
cannot decide from rush control data
alone so that's why I always tell that
version control data it doesn't really
replace anything it doesn't make any
decisions for you but it gives you a
decision basis by point your attention
to parts of a code that are needed the
most what I have been working on over
the past years is to integrate other
data sources to help make that
distinction so one thing I've been doing
is to integrate with things like JIRA
for example so we can pull out
information about the date different
tickets and find out or right you can
connect that to the commits in case you
have reference to JIRA ticket in the
commit and then you can also questions
like that all right so this jetpack it
changes the course of changed hardware
requirements for example so it might
give you additional information so I
think we have time for one more quick
question know that you want to have your
coffee break we're in VN after all yes
please
yeah so this is a question actually get
plenty of times and then my auras always
that yeah if you take a big file first
of all we can basically game any metric
we want and if we take a big file and we
slice it at random in different parts
are we going to get a better design no
it's going to be worse but one of the
most common reasons that code grows into
hot spots is because it has too many
responsibilities that's why it keep
attracting changes so what you do is you
identify those different
responsibilities let's say you have this
hot spot in your three different areas
if you break apart those
responsibilities you get better cohesion
you might still have the same complexity
in the code but I'm going to argue that
it's going to be easier to work with
just by separating those different parts
because now the names of your different
classes will provide an additional entry
point once you read and explore the code
so I think that separating along their
true behaviors is going to help you
separating at random it's going to make
it worse alright so I'll be hanging
around for the rest of the day and I'll
be really happy to discuss this and
phylogeny Shoutmon deutsche bahn vielen
dank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>