<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Graal: High-Performance Polyglot Runtime by Thomas Wuerthinger and Aleksandar Prokopec | Coder Coacher - Coaching Coders</title><meta content="Graal: High-Performance Polyglot Runtime by Thomas Wuerthinger and Aleksandar Prokopec - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Graal: High-Performance Polyglot Runtime by Thomas Wuerthinger and Aleksandar Prokopec</b></h2><h5 class="post__date">2018-03-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8AYESZIaacg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so welcome everybody
so I talked about the chromium this is
Alexander Brokovich he's a researcher at
Oracle labs here in Zurich and I'm
Thomas fitting I'm also researcher here
and we'll do this presentation together
I'll be responsible for the demos and
Alex will do the talking and before our
legs talks we need a little bit of a
safe harbor statement here as usual this
is just research that represent here and
we are making no commitments but we
still hope that at some point this
research will make it into interesting
products in the future all right so over
to you Alex thanks a lot to us so
basically thanks thanks for coming
so this talk will be about a new runtime
called grow VM this is essentially a
language runtime polyglot language
runtime and the goal of this lecture is
basically to illustrate to you how and
why is groving different than other
runtimes and we're going to do this with
free highlights that we want to point
out here first of all the growl VM is
polyglot second of all it's embeddable
and third it's very efficient so this
lecture will be I said basically this
presentation will be structured through
these three key points okay so first of
all polyglot what do we mean by this
essentially every once in a while people
have an idea why don't we have one
language which unites all language why
don't we have one language that rules
them all so every once in a while on
Stack Overflow a question pops out such
as this one what can there be an
ultimate programming language and the
result of that is usually as follows the
question gets closed as non-constructive
right and of course there are good
reasons for this so first of all should
we go to the next slide the so the first
of all the world is polyglot right so
that means we don't have just one
language we have many language and there
are good reasons for this different
languages are tailored towards different
parts of the software stack and are
tailored for different usages so for
example what we have
here on the right is the TOB programming
index from 2017 which uses its own
metrics which you can you know elaborate
and discuss if they're correct but
essentially there are different there
are different ratios on how much people
use different languages so for example
in Tel you obey you have to figure one
so in trouble you have like basically
what it says that people use Java most
of all and then after that you have C
and C++ and then followed by JavaScript
assembly PHP and so on so but the point
is like really there in this ecosystem
that we were using they're a bunch of
different languages that need to work
together okay so what is there's a big
other language which yeah of course and
there is a big ratio of other languages
which are not categorized like this main
ones right the the fat tail okay so
essentially there is a challenge here
and the challenge is to make all these
languages somehow work together to
basically make the the ecosystem
productive when you're using multiple
languages together we call this
challenge the polyglot challenge and is
essentially the problems in this
polyglot challenge are as follows so
first of all only languages which have
high industry attention achieve high
performance and the reason for that is
that if you really want to have a high
performance implementation of a language
you need to invest a lot of money and a
lot of time into it so a typical example
of this is JavaScript which started off
as an interpreter language in the
browser but it took a really long while
until the whole world started using that
and there were good use cases for
implementing something like v8 to get a
really high high performance
implementation but there are counter
examples such as Python which is widely
used by a lot of people which still
doesn't have a particularly high
performance implementation okay so so
that's one of the challenges we would
ideally like to have all these different
languages running high performance mode
okay so then the second problem is if
you have multiple languages which need
to interact with each other is that each
language executes in its own little box
essentially in its own little runtime
and sometimes when this length
need to interact each other for example
one a language wants to use some
functionality of another language
essentially it needs to pay a high
serialization cost it needs to marshal
the data converted it to some textual or
binary form then send it through some
interface and on the others under the
other side the other language needs to
deserialize it and then respond to the
request in the same manner and this
marshalling can be costly ok and the
third problem that we want to highlight
is that languages different languages
they have different tools and tools are
of various sorts for example configuring
your project setting up your build
system or debugging and profiling and of
course every if every one of these
languages has different tools of
different quality to then then you have
a problem essentially what you would
like to have is the same set of tools of
the same quality for all these different
languages it ok so here's how growl vm
essentially addresses this problem so
what I'm going to show here is the
software stack which comprises the growl
vm so what we have at the bottom of this
stack is the Java hotspot virtual
machine essentially this is a high
performance virtual machine a lot of
time has been invested into this but if
you use just your virtual machine as is
then essentially the only thing you can
do is run Java and languages the target
the JVM so then one layer above that we
have this JVM CI compiler interface
which is essentially an interface that
allows one to implement a custom
optimizing compiler for the JVM so you
reuse you know use like dynamic class
loading you use garbage collection from
the JVM but then you can plug in your
own compiler and in our case this
compiler is growl this is the compiler
that we developed and this alone this
compiler alone allows us to run Java and
Scala in high performance mode on top of
the JVM and we have additional
optimizations compared to the standard
hotpot Seto compiler which make these
languages actually faster we have
benchmarks to support this way too heavy
benchmarking okay so now that addresses
the problem of running all the languages
which compile down to JVM bytecode
but if you want to run other languages
such as the scripting languages like
Ruby are in JavaScript you need
something else
and basically the growl vm runtime has
this layer on top called the truffle
framework which allows one to define
their own language implementations and
automatically get a high-performance
implementation for them in our case the
truffle framework comes packaged with
high performance implementations of Ruby
are in JavaScript which already made in
art by our teams and of course we also
have no js' and then in addition to that
we have another layer called Seulong
which essentially enables you to on top
of this system run any kind of code
that's compiled down to LLVM bit code so
that primarily targets C C and C++ but
also all the other languages which
compile down to Alvin bit code okay and
in addition to that we currently have a
research prototype which we're working
on which is targeted to become a fully
fully usable product which is an
implementation of Python on top of this
framework okay so one very important
very important part of this software
stack is truffle itself and basically
the way to think about truffle is as
follows so when you look at your
application essentially it uses a
certain software stack and at the bottom
of the software stack is an operating
system okay an operating system is
typically written in an unmanaged
language such as C or C++ and it's
written by somebody who is an operating
system expert then at the next level you
have a traditional virtual machine which
essentially takes a high-level
representation of your program such as
bytecode and then compiles it down to
something efficient and this is written
by a virtual machine expert typically
it's written in a man in an unmanaged
language such as C such as C or C++ but
it can also be written in managed
language language sometimes so this is
this is this first two levels are sort
of the traditional virtual machine API
and what truffle adds on top
is something called a guest language
implementation so essentially the idea
in truffle is that anybody can come and
provide the definition of a language and
that person is then a language developer
and this definition of the language is
not given in C or C++ but is given in a
high-level language such as Java and
then on the top you have the traditional
application developer who uses the stock
the stack below it already developed
languages and can write his or her own
application on top of this stack
okay so let's focus on this third level
essentially what does it mean that you
can define your own language so the so
first of all a disclaimer is that you
don't need to do this to use growl VM
it's only if you have at your company a
language there is the legacy or is
developed in-house then in that case you
can provide an end you can provide an
definition of it and you can plug this
definition to the truffle framework you
automatically get a high performance
implementation however if you're using
one of the standard languages which we
have already worked on then you get it
the implementation out-of-the-box but in
case you're in a position of this
language developer then essentially to
define your own language you need to
provide two components the first
component is a parser a parser is
essentially something that converts your
textual representation of the program
into an abstract syntax tree and the
second thing you need to provide is an
interpreter so given an abstract syntax
tree you have to say how do you execute
this program you have to give it some
semantics so let me show you an example
on this live so let's say you have a
program which is as follows so it says
if X is smaller than 0 return minus X
and otherwise return X so this is an OPS
function essentially so the abstract
syntax tree which must be produced by
the parser looks as the thing on the
right essentially it's a tree which has
an eighth-note at the top then on the
left it has the subtree which is the
condition and then it has the true
branch and a false branch and
essentially the interpreter would take
this up abstract syntax tree and then if
it sees an if it needs to call the left
subtree which will produce return a
boolean and
and depending on whether the boolean is
true or false it calls either the first
there is the second or the right
sub-tree
essentially it's an interpreter it's
just a method which traverses the
abstract syntax tree and this is a
minimal definition of what a language is
it's the semantics of the language now
this is very easy to do usually and it's
much less work than implementing the
compiler which produces high-performance
assembly ok and this is all that a
language developer needs to do in this
framework ok so once the language
developer does this then essentially
this abstract syntax tree representation
is taken by the truffle system
optionally it can perform based on
profiling information additional
rewrites to optimize this abstract
syntax tree and then it feeds it into a
framework into an engine called a
partial evaluator which essentially from
this abstract syntax tree and the
definition of the interpreter produces a
high-performance compiled code it
automatically ok so this part on the
right side of this this slide is
completely Americas handled by the
framework ok and so I imagine that most
people using rel VM will not be actually
defining their own languages but in case
they do there is a template on github
called simple language which you can
take a look at and you can extend it or
you can use it as an idea to produce
your own language definition ok so it's
so much about about polyglot aspects of
this runtime the other thing we want to
talk about is there is some in barrel
and what do we mean by this essentially
we have built so basically what you can
do with grow VM is that you can embed it
in two different runtimes so you can
take grow VM as a binary and you can put
it into a runtime such as a database or
some other or some other program and
that means that you can from this other
runtime directly execute code in other
languages so for example what we've done
with the oracle database we allow we
basically integrated the girl vm runtime
into the database so that users can
write their SQL query
and directly from the SQL query executes
some call some JavaScript function for
example and then essentially the
advantage for doing so in doing so is
that you don't need to query the
database to get the data and then
implement separate functionality on
another business logic server you can
push your business logic all the way
straight into the database and if
there's a rich ecosystem that you want
to reuse such as NPM libraries then you
can directly run them in the in the in
the database and we also have this thing
done for MySQL for we have a research
prototype for the nginx HTTP server
where we use growl VM to provide users
with the ability to specify a custom
routing rules using javascript we also
allow analytical queries in other
languages on Apache spark so that's kind
of the idea of how embed abililty what
availability provides you so in co2 next
slide so the real value added by this
embed ability is that if you have a
bunch of languages then you
automatically can use them all together
and what you get when you use them
together is interoperability so
different languages you can call each
other's functions directly you get this
same pooling essentially if using a
debugger you can debug this is one
application if so you can see the stack
which is composed of calls to different
languages for example and you get the
high performance optimizations which are
shared between the languages and on the
other hand you can embed this in two
different products okay so how does this
embedding actually work it turns out
that growl is somewhat of a hybrid
between a static and dynamic runtime and
what do we mean by this well essentially
what it what we talked about so far is
that growl runs on hotspot and then on
top of hotspot it executes Java bytecode
or this abstract syntax trees for other
languages so that's one mode of running
growl there's another mode so we have a
project called substrate VM or for short
SVM which essentially allows you to take
your java application and then
pilots together with this substrate
virtual machine and produce one image of
the entire application and this image is
essentially a binary program binary
which has the virtual machine package
together with your Java program ok so
it's so this is this gray area on the
right but it additionally allows you is
to still dynamically execute code from
dynamically from these other languages
right ok so go to next slide so the
first thing that we want to highlight
here is that it's also very efficient so
here just some slides so we actually run
a lot of different benchmarks we have
like probably several hundred benchmarks
altogether used in in our development
process so here we're showing only some
of them here and we're showing geometric
means across benchmark suites for
different languages so this this slide
is I believe a little bit outdated
we actually constantly do improvements
so I think right now these numbers are a
bit better than the ones you're showing
on the slides essentially so you can see
basically the red bar is showing the
geometric mean across all benchmarks for
the growl vm and the gray bar is showing
the geometric mean across all benchmarks
for the best
specialized competition so in the case
of Java this will be hot spot in the
case of JavaScript that's v8 and and so
on in case of our it's probably gonna
are and so on so in case of Java we
mostly use benchmarks which are
traditional Java benchmarks traditional
workloads such as The Da Capo benchmark
suite if somebody heard about this so
here we're actually slightly better on
these graphs then then the standard
hotspot implementation but one thing
that's not taken into account in these
graphs is some more modern workloads
such as Java eight streams on which we
actually achieve up to 2x better
performance on Scala the workloads which
are comprised of more functional
patterns and lambdas and pattern
matching in this kind of constructs
actually achieve up to 20% better
perform
and then on Ruby and are you see this
effect of what I was of what I mentioned
at the beginning which is to say that
there are no high-performance
implementations contributed by the
industry because this basically these
languages didn't get enough traction and
and this benchmarks we were on geometric
average we were we were like four to
four and a half times faster on the very
right you see JavaScript here we're on
this on this slide show performance
which is ninety percent of that of v8
which but we're getting closer and we're
closing the gap constantly right so this
other slide actually shows you about
some of the advantages of this zero cost
inter up between the languages so
essentially if one language calls into
another directly rather than marshalling
and immersing the data then it has two
advantages first of all it can take
pieces of the code from the target
language in which the function is
defined and then optimize this call this
code in the calling context of the
language that is doing the call so we
can opt into optimizations across
languages this is one advantage the
other advantage is that all this
language is running within the same
process space basically they have the
same shared memory it means you don't
need to unmarshal this data but you can
directly access it and what you see on
this slide is essentially a benchmark in
which your the the program is querying
the database and then the database sends
it back the network packets as responses
now normally you would have to unmarshal
these network packets like convert them
into some higher form such as you know
javascript objects or JavaScript arrays
and then do querying in JavaScript based
on that but what essentially this
Interop provides you is a way to create
sort of a proxy around these network
packets and then query them directly
without on marshaling them and the
performance benefits of doing so are
shown here essentially if you use raw
nodejs then you have the red line and if
you use grudges to execute the same
workload then depending on the number of
matching rows you get from the database
you get starting
from ten rows a tool X speed up or if
you're doing 10,000 rows and up to seven
seven X speed up by doing this direct
memory access okay so that's kind of the
main part of this talk sold I'll give it
to Thomas to talk about the demos thanks
Alex
alright so that was enough slides let's
see some code and a couple of live demos
and I will we will fire them from least
these three ski to most risky so let's
start with the with the least risky
first which is I want to show you a
little bit what you can do with the
polyglot aspect with the political
aspect of things and what I have
prepared for this is I have downloaded
the gravy and binaries they are freely
available on the Oracle technology
Network and I have installed them on my
local computer and for this I have
created a directory and if you are like
looking into this directory into the
binary directory of this installation it
looks a little bit like a Java
installation it has all of the binaries
to the usual JDK download house and
there is a few more however because you
can see here a node binary you can see
an NPM binary you can see an LLVM
interpreter binary you can see a ruby
binary and you can also see in our
binary summer so our script and and and
JavaScript so that's those are all tools
that are provided in addition so here's
our and our script those are tools that
are provided in addition to Java so many
install krabi I mean really can think
about you installing a polyglot language
runtime that runs all of these languages
at the same time and there's one of the
one of the things that's there is like
no chess it's a version 8.9 and I can
use no chess for running a simple hello
world which I've here it's just a hello
world from garage yes and
I can I can start that up it's and I can
run here that room no chance application
which will tell me hello world from
crotches okay so that's that's running
but it's not super exciting because well
why would I not run the normal no chess
and so one of the first capabilities you
get with the growl based version of no
chess is the ability to use Java data
structures so in JavaScript for example
it's harder to do a big integer you have
to use a third party library for this
they're currently discussing some
changes in the standard but still let's
say I want to use the big integer
implementation from Java which is very
efficient and statically typed then in
our version of know chess we can just
import a Java type here which is big
integer and then I can use it as if it
would be like a JavaScript object I can
start this different version of the
server I need just one flag which means
- - JVM which will start no chess and
the TVM simultaneously and so after this
server is up I can get my access to the
know chess again and I get now my big
integer on the screen and I can use or
any of my previous Java libraries and
still run right - no chess so this is
one one aspect of polyglot but polyglot
aspects don't stop there I can mix other
languages here as well so I can start to
use are now in my no chess application
and are is very good at doing statistics
and and graphics with statistics so what
I do here in our is I create a little
SVG graphic that creates me a cloud of
points that I was randomly generating
and I can start this type of application
now with - - JVM - - polyglot so this
enables the JVM based interaction with
nodejs
and it enables other languages including
Python Ruby
are to be accessible you wanna change
the oil or I need to change the file
thank you I need to run seven three so
now I'm creating a request here so this
request will take a little while the
first one because it needs to initialize
three language context at the same time
it needs to internationalist know chess
Java and are but after some time I get
now my are brought my as vgr blood into
my noches application and the subsequent
requests are faster you see the point
the points change based on random so so
this is a very convenient way and
straightforward way to combine these
three languages I just have this one
file and here for it in JavaScript I've
written Java and written R and first of
all if you would run this in separate
files or separate applications one issue
obviously is performance which is you
need to serialize this rule as anything
you send across these languages in our
system the data is not C realized is
utilized it can directly there are R can
directly access the JavaScript data
structure and the other way around but
there's a second advantage just from a
usability point of view you don't need
to program the civilization and
dissertation you get a very convenient
interface here to access your Java from
JavaScript or are from JavaScript so
that is on this polyglot aspects and as
it was mentioned chorale also has this
embedding aspects and let me go to the
embedding demo so the first thing I want
to demo here is that you can use groznyi
UM's
ahead of time compilation to a head of
time compiled Java code to make it start
up very fast and use less footprint than
it would if it would run on the JVM so
for this I have a little Java program
which is here list the deer it uses some
stream API to walk the files and list
the directory that's just there and I
can I can just compile that and I can
run this list directory Java program and
it lists my directories ok that's that's
the type of program but the problem of
course is in Java if you do this type of
utility then and you run it then well it
takes like two hundred milliseconds
still sort of ok but not the same as you
would just type LS for example right
which is the C version of this of this
utility and we engrave eme providers
common that's called native image so
what I can do in chromium I can see the
native image and then I say list here so
it's it's similar as with the Java
comment sorry I need to compile with
mr. cork Java version because it sinks
yes okay
so it's similar with like the Java the
Java comment but it is taking now the
main class of your Java program and
analyzing the whole world what is
reachable from this main class and
creating a binary that includes
pre-compiled
everything that was reachable and after
some time it then compiles everything
and that's all the out of time
compilation and what the output of this
is is this list dear executable which is
now just a normal C executable a native
executable and I can run this one and it
has the same functionality like the list
here and if I'm now timing this I am
down to about yeah 13 milliseconds here
compared to if I'm timing just this this
is like 20 milliseconds so that's a 20 X
speed up in user time it's even less 50
X p.m. so you can use this utility to
add up time compiles in Java code there
are some limitations as to the type of
Java code that supported meaning you
need to specify all of the classes in at
large we don't we don't support the
dynamic class loading but we can also
compile some more complex programs
because I mean as a Java krob program I
kind of used to this but if I'm doing
just this this Java C and I'm let me
just I'm doing this time Java C and then
I'm doing the list here at Java then
it's taking me almost a second to
compile this file and this file is not a
big file it's just 15 20 lines of code
so what we did is that we created a
utility that that is able to create a
boot image from Java C so what I can do
is I can
do the same approach are used for my
java command-line utility I applied to
the Java C tool which is written in Java
and this sooner it takes a little bit
longer because it's a little bit more to
work with
because Java season more complex
application but it again does kind of
did the whole world analysis on Java C
and compiles it down and writes it to
disk creates an image and has now ahead
of time compiled all of Java C now I
have a new utility here which is my Java
C here which is pre-compiled 15
megabytes and what I what I have to use
a slightly different compiled command on
now and I will explain this in a moment
because Java C usually wants to run on a
JVM and it uses the current boot class
path from the TVM for looking up classes
we need to because we had of time
compile it and run it not running in
achieve and we need to specify the put
class pass so but if I'm using now this
to my compiled my list here is like
let's let's just that's that's
unbelievable right let's just make sure
it does something let's remove this guy
yeah so the class is not here right and
yes they're amazing so um and if you if
you compare this one which the time yeah
that's like 40 milliseconds use a time
35 milliseconds use a time and if I
compare this with just a normal Java C
is X 300 400 milliseconds so it's 10x
10x Peter we think we can do better in
the future we are currently working on
things to improve the performance
further because at the moment we do the
add of time compilation result any
profiling she'd pass but what you're
currently working on is to allow you to
profile your application then use that
profiling to create the better version
of the head of time compiled image and
then yet advantage you get in this mode
of crawl is actually that you can fix
your profile the
you have a reliable profile on on what
you what you will what you will get when
you run this application as opposed to
the profile being kind of checked on the
fly and so we use this out of time
compilation like originally we developed
it just to be embeddable in these native
applications like the database like my
sequel or Oracle database but it turns
out it might also be useful in other
contexts and yeah as I said there is
some at the moment we don't support all
of Java with these things so if you try
it on a large application it might at
the moment not work correctly but we are
interested to hear your use cases and
why you would like to like make use of
such a technology and are willing to
work with you to to resolve any issues
if there are any yeah this is this
native image comment which comes with
the grab em download you can and you can
give it a class pass you give you the
main class and it's it's like it's like
Java yo T ok so now let's go to the
risky parts of the live demo D well I
mean just just one quick note before we
move on here it's I can in this ahead of
time compiled image everything is
pre-compiled but I can still run
crowd-based languages so I can still run
some JavaScript for example I can still
customize my application with JavaScript
Ruby R because you can still include a
compiler also in that image and this is
the type of image we use for embedding
so for embedding we have something we
have a prototype that that's embed grab
into the Oracle database so we also have
worked to embed it into my sequel if you
prefer my single but yeah here is the
embedding in the Oracle database and
here is a docker image that you can
download for free that will run the
Oracle database you only need about 12
gigabytes of
of disk space because the download is
large for complex technology and I
pre-loaded that so we don't need to wait
for that now and you can then run this
as a docker image you will get the
version of the Oracle database and I'm
here locked into the docker image I'm
locked into this docker image and what I
can do now is I can run an OGS model
inside my Oracle database so one of the
noches models I want to show you here is
validator validator is a node.js model
for validating emails and other other
properties like mobile phone numbers and
it has a very complex logic to validate
emails it's just it's not like one
regular expression it's like 20 lines of
code that validates emails of all sorts
and the way it works is value in
importance and then you ask it is
something an email and it says yes or no
right so what I did before is I
installed this NPM model and the other
thing I can do here is I can deploy this
as NPM volley module so we have a tool
here that's what we call DDGS and and
then I can deploy this validator into
the Oracle database and it tells me some
of the functions it created inside the
Oracle database here this is Peter
sequel I'm not family with PL sequel but
it's it's it's it's kind of the typed
versions of the JavaScript that we have
created but the most important thing is
that you have our is email function here
summer which is here yes created and is
email function inside my ugly debase and
this is email function will run this no
GS model so I can now log into this with
Scott tiger all right
and what I have prepared here is a
little superheroes table
yes who is five for superheroes in it
with emails and phones and now I can
just use my OGS model in the query so I
can say select email and then I want to
validate whether something is an actual
email address or over this somebody was
cheating here and I can do validator
that is email of email from superheroes
now I get the email addresses and here
tells me yes this was a valid one this
is not a valid email address this is
also not a valid email address and this
is a valid one so instead of kind of
coming up with your own regular
expression for email or not and whatever
you you just you just reduce the noches
model and and be done with it and I have
a second example here because there's no
chase models for everything this this
validator by the way has about a million
downloads last week so it is fairly
popular there's another node.js model
which has even more downloads which is
cost fast Levenstein
it is an OGS module for checking the
distance between two two words I don't
know why everybody's using it maybe to
be annoying when you get a new password
kind of looks like your old one and so
here this fast Levenstein this has a
gate function which calculates the
Levenstein distance between two strings
which means well this is - I need to
change two characters it also supports
Chinese obviously and yeah and so I did
the same thing as mr. validator so I
downloaded that and I just deployed it
into the Oracle database and now I have
this gate function available to me which
will calculate me the levenshtein
distance so I can now select and now I
want to name and I want xi the
Levenstein distance between
duper man and the name from my
superheroes table here yeah okay now is
it a Dubai mine is closed to Superman
it's reasonably loose to Batman
spider-man definitely not Flash Gordon
so yeah so again I used a standard
Noches model I III deployed I installed
it I installed the types for it because
the types are important to have because
sequel the database is a typed
environment and then I deployed this
model with a simple comment into the
Oracle database and now I can call out
to this type of functionality and you
can also deploy your own your own code
there of course there's pros and cons to
putting logic inside database versus
outside and but I think like one of the
things that we provide you here is you
actually don't need to make a commitment
up front while you put your code because
we provide you an environment in which
you can run your no cheers models
outside the database or inside the
database and it's exactly the same
environment so you can if you feel like
well I want to use this utility also
inside I can do it but I can use the
exact same code it'll be the exact same
engine and the research that we're
currently doing in this area is to allow
some amount of auto deployment into the
database meaning I have a client
application that runs some a query but
then I want to ship a function into the
database so this is currently not not
supported but this is kind of the
research direction we are going in here
such that you and the whole goal here is
kind of to avoid also Network
round-trips Network round trips and the
word copying data and to avoid copying
data out of an environment or it's
secure and nicely stored and managed and
this is what Croghan gives you here is
an oracle database example we are
working on a my sequel integration as
well so will be my sequel plugin
released very soon on this
and we have some prototypes for
integration to other data processing
engines like spark or nginx as you have
it all right yes so that was the demo
part and now we get to the final slides
right thanks okay so to conclude so we
want to tell you a little bit about our
community that we're kind of working
actively to build essentially we have
currently open JDK mailing list for
growl but we will soon switch to new
mailing lists which will be free as
follows so we'll have growl vm - dev for
people who are actively contributing to
grow vm which is open source so we have
growling users for people asking
questions or asking for new features and
there will be mailing list called growl
vm announced for announcements so
basically growl is divided so there are
two versions of growl one of them is
open-source and is available on github
so you can take a look opening issues is
very welcome as well as submitting pull
requests if you want to help us we also
have an enterprise version of growl
which is essentially just an extension
of the open-source growl but it has some
additional features and optimizations
it's it's actually available on the open
OTN network from oracle at this link and
there's a month 1 release every month so
it's free to download and use but if
using it in production for any
commercial purposes then you have to
have a license but you can evaluate it
as much as you like but as for the open
source version like if you have
contributions for us there will be
they'll be great or just feature
requests that's already already means a
lot to us
we also have this link here for database
integration binaries and the
documentation at the bottom and so to
conclude basically this talked with one
thing that we would like to get from you
here at this event and you can approach
us now in the question
or either offline whatever works for you
but essentially what we want to learn
from you is what kind of languages are
you using at your company what kind of
combination of languages would you like
to see what are the use cases for embed
ability that you see or any other
features that you that you'd like to see
when it comes to interrupt or any idea
other ideas that you might have for us
so your feedback is very welcome so
thanks a lot for coming here and for
listening to us we'll be happy to take
questions thank you
I have a question about the whole code
feature when you run different languages
of different libraries in different
languages listen yeah so so the question
is how how do you deploy your code in
such multilingual environment and I mean
a lot of the languages that you're
supporting here is like Ruby or
JavaScript
those are languages which people
typically deploy the source code and
this is what we do here this is also
what we do when we deployed JavaScript
source code into the Oracle database for
Java or similar we we support running it
on bytecode and for static languages
like C C++ the deployment model is that
you are deploying LLVM bit code so
you're deploying a platform independent
bit code and this bit code isn't run by
our engine so the answer basically
depends on the type of language dynamic
language is source code in JVM based
languages bytecode and LLVM based
languages bit code sort of our goal is
to mimic the normal thing that
developers do not in their workflow and
we try to be as close as possible to
wherever the developers usually would be
so question is how is the polyglot IDE
integration so I mean we're using here
multiple languages in one file for the
demo I mean frankly honestly if you do
your own polyglot application you would
usually avoid using a lot of mixture in
one file you would rather do it over
over several files
so so you would have an hour file and
that loads a ruby file and and and the
clue code would be rather small we don't
think that the it makes so much sense to
combine them in one file except for the
demo here we we do support major IDs we
do support also major debugging
protocols but I didn't join the demo
this time is the debugging in the Chrome
browser we can integrate with chrome dev
tools and that's a shout-out to the
chrome dev tools team it's awesome that
they made it language agnostic meaning
we can actually debug our Ruby in the
chrome dev tools which the chrome dev
tools developers probably don't know
about but but it's awesome so so and and
other other ideas like I mean I used to
visual studio code for the for the for
the demoing and IntelliJ and and but
also like NetBeans or eclipse they all
have at least I support all languages
within one environment and not the
servicing on file but within one
environment but one of the things we can
do in the chrome dev tools for example
is to debug across languages
it's a debug like from long language to
the other and so so that is that is
something that's nice because we can
have a stack trace that is multilingual
that works in the chrome dev tools and
also works in a netbeans plugin that we
created also one note about the support
in the same file actually IntelliJ
Enterprise Edition has very strong
support for this out of the box so if
you write like a string which is
actually a ruby string you can click on
symbols and it takes you to the
definition point it's quite smart
already yeah I guess IDs will catch up
once this gets more mystery
thank you it's always very exciting to
see what's what you're doing with ground
and I have a obligatory question since
you mentioned Scala it was wondering if
you tried to build a brick of polyamide
john scalzi yes the question is if we
did create a precompiled image of Scala
see yes we did I think actually be
successful in doing that at the moment
also we cannot support all features we
also get some interest and we will work
with there's this startup there's a
faster Scala compiler ether compilers
we are also in contact with them so they
can use this technology but at the
moment there are some features called
see that also require complex reflection
so it's it's not out-of-the-box
application but I'm very much assuming
that we were able to do that within a
reasonable time frame I think I think
you will see Java C ahead of time to
publish this stuff right and we we can
compile Scala we can also compile code
line if you're not a small demo where we
are compiling this language it's out of
time covered as well which is kind of
interesting because there is a project
that's called Scala native there's a
project that's called Cortland native so
yeah so we have Crowell native which is
Java Cortland and Scala everything at
the same time and we think actually that
we should join forces with Sicily
together to support this native
compilation across languages the
languages again in their own yes
absolutely absolutely so we have an avid
pivot demo also historical images
whether you're running a simple web
server with Java and we can show that we
can start this simple web server that's
written in Java in in ten milliseconds
or less than that even
and no be absolutely working that
direction we are also doing work with
the FN project from Oracle or crisis FEM
project very deployed function as a
service also based on Java where we
apply that so I mean of course it will
take it some time until we resolve all
of the limitations of the subsidy M
approach but that's how we are actually
yeah looking forward to hear from you
also on what what limitations we need to
prioritize next and and what would be
what would make most difference you and
it's not just this startup it's not just
the charts are up it's better the other
thing that's better is the memory
footprint because you're using less
metadata and less profiling data when we
run these applications and this is also
more relevant when you deploy several
containers yeah absolutely
that will happen I'm very optimistic and
I'm I'm looking forward to getting input
and feedback from you in terms of
example applications because we're like
a research lab you know vvv we make up
stuff but we don't yeah you know you're
not like real world people so to speak
and so that's sort of looking for real
grow people to like tell us what's
relevant in the real world what will
what directions we should go what what
will make a difference for you all right
we said thank you very much for
attention and yeah looking forward to</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>