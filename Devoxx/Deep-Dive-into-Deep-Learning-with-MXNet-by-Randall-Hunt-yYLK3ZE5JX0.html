<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deep Dive into Deep Learning with MXNet by Randall Hunt | Coder Coacher - Coaching Coders</title><meta content="Deep Dive into Deep Learning with MXNet by Randall Hunt - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deep Dive into Deep Learning with MXNet by Randall Hunt</b></h2><h5 class="post__date">2017-11-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yYLK3ZE5JX0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning I am NOT guy earnest I am
Randall Hunt guy earnest was not able to
come to Belgium and I found that out
about 24 hours ago so I am now giving
this talk I know Amex net and I use it
in my day job but I am certainly not the
foremost expert on it so if you have
another talk that you would like to go
to right now I will not be offended if
you get up and run away your one and
only chance okay before we dive into
things I'll just tell you a little bit
about me my name is Randall I live in
Los Angeles where it's warm and nice
unlike here where it's very cold but the
food is worse in LA so you know things
balance out I used to work for a company
called SpaceX in LA and then before that
I worked at Amazon and then before that
I worked at MongoDB and before that I
worked at NASA so the next logical step
for me after Amazon is obviously Blue
Origin since I could keep flipping
between startups or companies and and
space companies I'm a software engineer
I have this title of like Technical
Evangelist which means I just sort of
like chill and travel and I get to work
on code on my own pace it's a great job
I strongly encourage you to pursue that
as a role if it's something that
interests you because it's it is very
chill today we're gonna kind of talk
about who you know if I were to pull the
audience how many people feel like they
have a really good understanding of deep
learning great how many of you will feel
like they know what MX net is how many
people have used in X net so for the
purposes of any video that was 100
percent of the audience everybody's
really jazzed they're standing up there
like already clapping everything's going
great so my goal today is to give you an
overview and a framework for how to
think about deep learning problems and
we have 178 minutes don't worry I'm not
going to take all of that time I'm
hoping we'll get done a little bit
faster than that so first of all what do
you need to
know about deep learning the first thing
for those of you who have your laptops
open and charging and all that stuff is
I would say go ahead and go to this URL
and launch the deep learning AMI this is
important to do now before we get into
the rest of it because it takes a little
cumin 'its to get started so I'll leave
this on screen for a little bit it is
really cold here in Los Angeles it's
like 75 degrees Fahrenheit fahrenheits a
temperature scale based on the human
body supposedly whereas Celsius is based
on something intelligent like water but
being from the United States you know we
don't do intelligent things very often
that's why we have to have artificial
intelligence okay everybody got that URL
doesn't work you're right it doesn't
work oh I should probably get on the
Wi-Fi let me see what the
so it works for me but I'll just
demonstrate what you're supposed to do
so you'll go to the AWS console how many
people are familiar with AWS Amazon Web
Services again for the purposes of any
video that was 100% of the audience
everybody's just really really happy
this is called one and a half factors of
authentication and set a two-factor
authentication it's 1.5 I can tell you
how that magic trick works it's the
subject of my rejected Python talk but
what I want to do is I want to go to a
region here a region is kind of a set of
data centers in a particular part of a
world and a particular geography and I
want to go to EC 2 which gives me
instances oh well that ruined all of my
jokes didn't it here let's try this
again
that working I have way too many tabs
open let me get off of the page that has
all of our secret stuff okay so again
going to the AWS console this is called
1.5 factors of authentication and then
we're going to go into EC to EC to is a
Elastic Compute cloud it's I don't name
things it's not my fault I'm sorry
essentially you can launch a virtual
private server with various networking
options and all this other stuff but
what we're interested in doing right now
is launching the deep learning AMI
so if I go over to this launch instance
button and then I click this deep
learning ami a bun to blah blah blah and
then I'll scroll down and I'll go to a
GPU compute instance and you'll see I
have a lot of options if anybody wants
to email me for the next 24 hours or so
if you shoot me an email at this email I
will send you a credit code for a
hundred or so dollars to cover any costs
that you incur from this workshop after
24 hours that deal is gone so take it
down shoot me the email if you want the
credit code and I'll happily shoot you
one because these can get expensive so
you'll see we have a couple different
instance types here we have the p3 16x
large which has 64 CPUs 488 gigs of ram
25 gigabit per second networking and
then it also has a Nvidia Volta GPUs
which you know it's not that powerful
right like it's not powerful at all we
don't need that machine that's a joke
it's insanely powerful
all right everybody's laughing a lot you
should be laughing on the livestream
okay so we're not really gonna launch
one of those p3 16x larges just because
we don't need it we can go with like a
p2 8x large and even then we don't
really need that we could go all the way
down to this P 2x large I'll configure
my instance settings
had some storage I'll add a full
terabyte of data just in case we start
doing some crazy stuff and then we'll
configure a security group my security
group is just open to everyone because
that's how I roll
don't do this in real life it's a
terrible practice all right
and rather than launching this I have
already launched one so I'm just gonna
go and look at the one that I already
have here we go oh and it is a p3 man my
boss is gonna be angry about that
so what I want to do is I want to set up
an SSH tunnel and the instructions for
how to do this are down here in that
blog post that I showed you earlier this
SSH tunnel you know I'm sure many of you
have seen this command before basically
all you're saying is I want you to take
port 88888 on my machine and send it to
port and send port 88888 from the
machine that I'm connecting to to that
same port so I'll start that tunnel
and everything should be good and then
if I go I'm just gonna make sure I'm not
running something else already okay see
the the issue is I do have a bunch of
other models that I'm training on this
machine so it could get a little hairy
here oh well so I'm gonna start a
Jupiter notebook right here in my home
directory and I to do that I'm just
gonna run Jupiter notebook and it's
gonna pop up a little token that I can
click on and then boom lo and behold I
am in my notebook everything is good
everything is running so do that follow
the instructions here in parallel and
then it'll take a little while for
everything to spin up and while that's
happening I'm gonna keep talking and
hopefully no one falls asleep
I know it's nine thirty forty all right
so does everybody have the URL I need
everybody to shout yes it's not working
deep - learning - a my blog
so if I go HTTP bit ly / deep - learning
- am i - blog so
so this is the URL right let's see what
happens
Oh No
well that's not inspiring is it yeah I'm
wondering why when I click on it it
works
weird yeah I'm sure that's what it is I
just don't know how to use PowerPoint oh
I just want to point out I did not make
these slides the person who is supposed
to be giving this talk is stuck in
Seattle that's my excuse okay hopefully
we've started making some progress here
okay sorry about that everybody this is
gonna be a long day everybody made a
little bit of progress awesome because a
resounding yes again for the livestream
that's never gonna get old so let's talk
about a max net MX net is one of many
machine learning frameworks but I think
it kind of stands out from the rest of
the machine learning frameworks in that
it is a couple of different paradigms
all mixed into ones so the idea behind
MX net is that you separate your
computation from your kind of the the
description of your graph so it's this
idea of I have a graph or a set of
things that I want to execute I have you
know this idea I want to add variable a
variable B and multiply it by variable C
and then to the dot matrix products with
this matrix and I don't actually have to
have any of those values in order to
define that graph and then I can take
that same structured execution and I can
say run this on a GPU run this on 100
GPUs run this on a heterogeneous cluster
of millions of machines and it works the
exact same the code is is roughly the
same regardless of where I'm running it
or how I'm running it so it's pretty
powerful in that regime but you may not
really have the contextual knowledge for
what that means until you kind of
understand what deep learning is so
deep learning at its core is this idea
that we can take a bunch of labeled data
and train a network similar to a you
know human visual cortex is one type
like the the convolutional neural
network is one type of network that you
could train so it's this idea that you
can take a network of or you can take a
set of labeled data send it through a
network and iterate that the weights and
biases that go into each of the neurons
in that network in order to build a new
kind of network each time where the
output is more and more like the labeled
data that you're looking for so if you
guys have seen any computer vision API
is like recognition I'll show you this
really fast and then there are other
kinds of networks that aren't
convolutional neural networks there are
all other kinds of models that you can
train Palestine's can stuff like that so
this is an image skateboard sport people
these are the labels that were detected
in that image we can look at another
image and it's like City downtown
metropolis I can do facial analysis
looks like a face appears to be female
age range it's really funny when I
upload my my headshot the real question
is how well do you guys think I am
ooh Wi-Fi this is my official headshot
by the way don't know how that happened
very unfortunate but we can call it a
recognition and it looks like a face
appears to be male age range 35 to 53 I
should maybe look into some skin cream
or something
smiling appears to be happy not wearing
glasses these are all powered by deep
learning so these are the kinds of
things that you can do with deep
learning and I'll tell you about some
like truly magical stuff that you can do
later on
and you guys can try and break my
Network but for now we'll get back into
it and that's that's just an API that
you can call by the way has anybody used
AWS recognition or Amazon recognition
well essentially it's it's an API and
you say hey I have an image I want you
to tell me things about that image and
then you get back to like JSON data that
tells you what that image is now these
were first proposed back in like 1957
there's like the perceptron
and there was this idea that you could
take electromechanical inputs and encode
data in it and build this network and
then in like the 1970s there was this
algorithm called back propagation that
people use to adjust the network over
time and calculate what the cost was
between your your desired output and the
actual output and if this has been
around this long then why is it that
only now it's getting popular is the
question that I commonly get and this
kind of brings us into the idea of the
the curse of dimensionality where you
have a ton of data like imagine that
that image that I just uploaded you have
all the RGB values so let's say it's
let's look and see what it is
so let's see this is two thousand by
three thousand pixels so two thousand
times three thousand times let's say
three that's eighteen million
values that you have and then imagine
that we were streaming a video at that
same level then we'd have twenty-seven
frames per second or 18 million pixels
per second and then of those 18 million
inputs we now need to kind of coerce
down into a set of neurons in that
second layer and those hidden layers and
then we have to figure out okay how do I
take this dimension of time and
eventually it just gets very complex to
perform the operations well it doesn't
become complex to perform the operations
it becomes very computationally
intensive to perform the number of
operations that we need to do in order
to make this network work so what you
see here is kind of a 3d visualization
of this idea but it's important to
understand that most of these networks
are operating in far more than three
dimensions they can be operating in
thousands upon thousands millions upon
millions of dimensions and when you're
calculating all the different vectors
and different functions that go into you
making the network activate on certain
inputs and outputs it is a complex set
of computations that happen over and
over and over again and a common thing
that happens is people will I'm gonna
warn you about this now because we'll
get into a little bit later the 3d
visualizations that I'm showing you are
like really cool patterns for thinking
about things but they're not accurate
because probability distributions across
multiple complex dimensions like say
thousands of dimensions do not map well
to 3d space and I'll explain that more
later but but your intuition works ok
for 3d space after 3d dimension after
three dimensions
you know rely on the math more than your
intuition so deep learning is kind of
coming around again now because we
finally have some advances
in both algorithms also in the data that
we have available so in since the year
1991 we have produced more data every
second of every day than all of humanity
produced from the year from the
beginning of recorded history until you
know 1985 so most of that is admittedly
pictures of cats on the internet or
tweets or Facebook posts but you still
understand we're producing a ton of data
now and there's the advantage of a lot
of that data is labeled and we can use
that and we can do kind of cool stuff
then with GPUs and various other forms
of acceleration like FPGA is stuff like
that in cloud computing we kind of bring
all of this deep learning stuff that
used to be very expensive to do over to
everybody so a student in his or her
dorm room now has the same capabilities
of a fortune 500 company or a fortune
100 company or a fortune 10 company you
know 10 years ago and that's true I mean
that's a that's a true statement you
don't have an HR department though all
right in AWS kind of sits at the center
of this this is the required AWS plug
that I'm supposed to put in I do work
for them they're pretty cool so oh and
there's so this is an example of deep
learning in the real world these are
Kiva robotics that run our warehouses
and they each have a model that they run
so given a set of inputs given the need
to look for this item i as an individual
robot will go out and i'm
anthropomorphizing this a little bit
which will get freakier later I will go
out I will find the Shelf that I need to
find and then I will also communicate
with all of my neighbors and the network
as a whole in order to orchestrate this
kind of NamUs and then we have these
kind of drones which can even file their
own flight plans with the FAA they can
go and they can say hey I am delivering
a package this is my flight plan so on
so forth and this is all powered by deep
learning and then we have the Amazon go
store which
I walk in scan my phone pick up whatever
I want and walk out and this takes
sensor fusion and what it does is it it
allows us to basically using RFID and
computer vision and a ton of other
different kinds of sensors we can
determine what each person is getting
and we can kind of eventually
consistently swipe their credit card for
let me on their way out it's like your
AWS bill okay
these jokes are coming in too quick
something that's particularly
interesting to me my brother got a heart
transplant earlier this year and the
fact that deep learning and machine
learning are two things that are
enabling advances in the medical field
the very very interesting to me so
there's another example this is our
terrace and what they do is they are
able to create this four dimensional
flow of blood through hearts or even
through the whole cardiovascular system
and they can rely on these these models
that they've trained in the cloud as
well as these solutions running in the
cloud and then just sort of render it on
a very thin client in the doctor's
office pretty powerful and there's
another example where deep learning is
now beating human doctors so there's if
you take a scan of your retina there are
indications of whether or not you will
get diabetes within that scan and human
doctors kind of suck at identifying that
because they're human and humans I think
we'll find out by the end of this that
humans are just really bad at everything
but the deep learning thing can identify
100% of the time whether or not you're
likely to develop diabetes based on
these criteria and it's very very
interesting that they were able to build
that with just a fairly small training
set then there's this common example
does anybody have a Tesla okay I live in
Los Angeles and I worked for SpaceX so I
obviously have a Tesla and we do this
kind of self-driving thing and it's
pretty
crazy that this is you know these are
sensors that are going and saying hey
these are humans don't run over them so
on and so forth and especially in these
complex scenarios like this you see you
know the car is stopping because there's
a human walking it's kind of organized
chaos and this is all again powered by
deep learning so a lot of these
different things are modeled after
neural now these neural networks they're
modeled after literally neural networks
in your mind so there's this idea that
you have these these neurons and these
synapses and each neuron gets triggered
when it is over a certain threshold I'm
not a biologist or a neuroscientist so
I'm not going to pretend like I know
what this is but what I can tell you is
mathematically how it works now the next
series of animations that I'm going to
show you are not mine they're actually
by somebody named grant whose last name
I don't remember I'm sorry but I'll put
it in the notes later but grant runs a
YouTube channel called three blue one
Brown very very useful interesting stuff
so let's imagine I'm gonna start over so
let's imagine we have handwritten digits
and we're trying to identify handwritten
digits so we have these 28 by 28 pixels
so 784 different neurons in our first
layer and then we're going and we're
trying to build a network that will
correctly identify the handwritten
digits so maybe your intuition tells you
okay well this top part this little
loopy bit of the two that'll activate
you know the loopy bit that I am looking
for and then the one maybe that all
identify the the long slanty bit that
I'm looking for and we can in that first
layer we can break up the image into
different pieces and we can say this is
how this should work and that's what
your intuition will tell you the network
will learn however it wants to learn so
the way that our minds work is not
necessarily at all how the network will
work now frequently they do work that
way but I could pass in a completely
random like QR code style image into
this and
would very confidently tell me that it
was a five so it's interesting stuff
maybe it is a five so this is the idea
of kind of bringing that first layer of
784 inputs down to just 16 and what
we're doing is we're taking all 784 of
those neurons and we're fully connecting
them to all 16 of our next set of
neurons in this first hidden layer and
we it ends up giving us like 13,000 and
some 13,000 and two different kind of
parameters that were juggling around so
the weights are the kind of edges in
this in this graph and when we're
training what we're doing is we're
finding the right weights and biases and
occasionally the right activation
function for these neurons does this
make sense or am I just like way out of
left field here everybody following did
you know that if you speak out loud
you'll stay awake longer is everybody
following oh that was great
100% of the audience answered
everybody's really jazz they're just
clapping I'm sure you guys on the live
stream are clapping - okay so the way
that this works I can demonstrate this
is a slide but this is a lot easier to
understand on the slide so you have this
idea of you're kind of going through and
you're trying to match each one of these
edges now you don't really go through
like this it's much easier to just have
the edge do the math and see whether or
not it matches so you don't actually
have to scan each time and you can move
the whole kind of kernel around but at
its core this is kind of what's
happening is it's it's going and it's
building up this map and it can do all
of this information parallel and then
this is a convolutional neural network
yes and this idea again of where it's
going and scanning each time yes that
happens but it also happens all at once
it's like not it's not like it's doing
each one of these operations
see really all of these operations are
happening simultaneously so this kind of
brings you to the math section I studied
physics and I worked briefly as a
physicist at NASA before we blew up a
bunch of rockets and as fired so I'm not
going to talk about math because
apparently I don't know anything about
it
but essentially you have a set of inputs
a set of weights and you sum those up
and you have some sort of function like
the typical function that people used to
use was a sigmoid function and that
sigmoid function basically took a series
of values from like a range and it would
bring them into a smaller range and then
you determine with some bias whether or
not that individual neuron is going to
activate so a lot of people think of
neurons is just holding a number but
they're actually holding a function and
that function is the result of all of
the different weights and parameters
going in the bias and the activation so
talking about activation functions like
I said before a lot of people use
sigmoid then there are other ones I
almost always use Ray Lu I don't
remember what it stands for it's
something like rectified linear unit or
who the hell knows and the only reason I
use that is because it works and it's
really fast and I don't know much more
about it now we can write code to
simulate all of this ourselves like we
don't actually have to use a framework
to do any of this work like we could we
could define it in Python in fact
there's a really great book that does
just that but that's a lot of code and I
don't really want to cover it so instead
I thought now that most of your deep
learning
EMIs are spun up we would start looking
at this kind of in this together
okay so has everybody seen by the way I
guarantee you almost every tutorial you
go to on deep learning is gonna start
with this but we're gonna go through it
fairly quickly and then we're gonna move
on to some fun stuff it's just this
amnesty de set is like super common it's
what everybody uses to demonstrate how
this stuff works so I have installed you
know all of this these prerequisites and
stuff that it's talking about here these
are already installed on the
deep-learning ami that you've spun up so
what you can do is and MX that already
includes kind of the the in this data
set
so we will just go ahead and run this
which will download them this data set
and like pull it in to stuff for me oh
and one one point I forgot is in this
process of training the network you
could run all of the samples at once all
of your training data at once and and
calculate all the weights and biases
from that set at one time but it would
also take forever so what people do is
they break things down into batches and
they calculate the weights on those
batches hopefully that batch is a
representative sample one of the things
that people do to make sure those
batches are representative is they kind
of shuffle their data set we don't
really need to do that because it's
already kind of set up although I guess
we do do it here so what I'm doing is
I'm creating a batch size I'm creating a
training iterator and that training
iterator is going to use an indie array
which is our training data with our kind
of training labels and then we're going
to say shuffle all of this and we have a
validation set and you typically save
maybe 20% of your data and you know you
can play with those values you typically
save around 20% of your data for for
validating that your network learned
correctly which is you take 20% of the
data that's labeled and you make sure
you never pass it in to the network
while you're training it so that it
doesn't know it it's not just memorizing
it's actually learning how to identify
stuff so I'll run this now I'm going to
create a symbol and I'm gonna cover what
all of this is in a little bit I'm just
kind of demonstrate how this works so
I'll take the the this is this is not a
compliment or network by the way this is
a multi-layer perceptron so we'll create
a fully connected layer one with yes 128
nodes or neurons we have an activation
function of rectified linear unit we
have a fully connected layer 2 with an
activation function again a Tralee so
we'll create that and then what I'll do
is I'll just sort of point out what all
of this stuff so we take our data we
flatten it we pass it into this fully
connected layer and then we pass it into
this activation function to the next
layer we have another activation
function and then we have our output and
the output is just reading the labels 0
through 10 or 0 through 9 and then
softmax is another function that we use
to kind of bring things bring these
these series of values down into a value
that maps and again I will talk about
all of this in a little bit this is a
really useful function when you're
building networks so that one line has
saved me a tremendous amount of time
when it comes to like visualizing and
understanding my networks if you're
working with thousands upon thousands of
layers you can kind of dive deeper into
the plot network API and you can say hey
I don't care about any of this I just
really want to know like what my input
and my output looks like
so more complex networks you can't
really visualize just because they have
thousands upon thousands of layers and
then we can train it so I will start
training it and you can see it's going
raining training training training
don't do it do and I'll talk a little
bit about what this training does in a
second and you can see we kind of arrive
at like 97% accuracy and we can test
that on
data set and looks like it's true we
could also do this using a convolutional
neural network which is more complex to
explain but again we're just doing this
kind of symbolic math and we're creating
these different activation functions
telling us when the the neurons that we
have in this whole square are gonna
activate and again we're just plotting
it back out to this final layer so this
is more complex I'm not gonna go super
into it but same idea I can train it and
I can train it on a GPU this time it
will actually go slower on the GPU than
it will on the CPU just because there's
not enough data to really make full use
of the GPU and it takes time to send the
data from the machine to the GPU and you
can see we arrive at like 0.998 accuracy
and then we can test that yeah all good
so the convolutional neural network
works a little bit better but it might
also have other constraints and stuff so
that's the basic in this example that
everybody always shows when they are
talking about deep learning and now that
we've knocked that out of the way we can
talk a little bit more about how these
things learn so what you're doing when
you are training one of these networks
is you have a cost function and the cost
function tells you how different your
output from this first set of like
randomly initialized weights and biases
in your network is how different that is
from what you wanted it to be so let's
say I pass in the number 5 into my
network and I get out you know 0
activated 3 activated 4 activated 9
activated so I can take all of those
different things that activate it and I
can say ok these are off by this amount
this value and I want to take that
number and I want to kind of iterate
back through the network and make sure
that I'm adjusting thing so that that
cost function is constantly going
smaller
now the global Maxima or the global
minima like the the place where the
network has like the most perfectly
trained is a really hard thing to find
finding global minima in complex
functions again this is where your
intuition doesn't work so well because
what you're seeing here is a
representation of a two dimensional
function right and even if I moved into
the three dimensions again your
intuition is not doing a great job of
describing what it's actually like
because these are things that are
operating in thousands of dimensions
sometimes but what you're trying to do
is you're basically trying to calculate
the slope and figure out am I going down
or am I going up and you always want to
be trending towards one of these local
minima so there are different kind of
optimizers and ways of getting to that
local minima you know the the most
straightforward way if you had all of
your stuff available to you if you had
that whole set of like 13,000 and two
different or 10,000 different
handwritten digits as your sample would
be okay I want to make the optimal step
each time but because we're batching
things and because we're doing different
kinds of optimizations we actually end
up kind of drunkenly walking around down
to this gradient but we we descend a lot
faster in real time which is
advantageous you know that's kind of
like this this stoick yeah I don't know
how to pronounce that word gradient
descent and then we have other kinds of
finding the local minima kind of things
and you can understand that as these
things trend towards these local minima
you start to have networks that
recognize different features
now with convolutional neural networks
you more frequently kind of start to
find these higher these features within
each of the hidden layers so maybe this
first hidden layer is recognizing all of
these different random edges maybe this
second hidden layer is starting to
recognize like whole pieces these whole
little kernels and the third hidden
layer is recognizing actual faces
or a hierarchy of information where it's
cars elephants chairs stuff like that
and this is a really useful cheat sheet
for MX net essentially you can take all
of the stuff that we've been talking
about you know creating fully connected
networks creating convolutions pooling
your data together
LS TNS long term short term memory or
even embedding all of these different
networks are typically just one call one
symbol in MX net and it allows you to do
some pretty complex stuff with very
simple code so y MX net it's very
portable so you can run it on iOS like
if you've looked at core ml that that's
you know you can run MX net with that
it's very high performance it scales
linearly across hundreds of GPUs it's I
don't know that it's the most open but
it's certainly open it's you know an
Apache project it's programmable with a
couple of different interfaces so
there's also the gluon interface which
somebody asked about earlier and I'll
dive into that a little bit later but
that's more of like an imperative idea
where you can just sort of go through
and declare everything in real time and
have it execute it's got a very diverse
community of both industry and academia
so if you look at the top contributors
for MX net it's kind of all over the
place you know Tesla AWS Stanford Apple
all kinds of people and it's kind of the
fourth deep learning framework in terms
of popularity Cafe is kind of where or
calf I don't know how to pronounce that
actually is where like the old school
deep learning people tend to hang out
there the people who are like the
Masters of this so if somebody says they
know calf for cafe really well they're
probably really good at this and they
probably know all the other frameworks
really well too so look for those people
and try and learn from them
tensorflow is is newer it's super useful
and tensorflow has also built in to the
deep learning ami so
I'm talking about Amex in that today you
can use tensorflow very easily on AWS
and I think a dress is probably where
most tensorflow workloads are deployed
so you can scale to multiple GPUs with
MX net pretty easily so if you look at
what the ideal kind of line would be as
you add more GPUs you can see with these
different networks inception ResNet and
Alexan alex net I always call it Alexa
net because I work for Amazon and Alexa
is just a thing that I say it too often
but it's Alex net I've made that mistake
probably a hundred times and I was
determined not to make it today but I
already made it so you can take all that
info and you can kind of use that to
determine whether or not adding a GPU is
useful based on the different types of
networks that these are I know that that
slide is just broken I'm sorry so it's
pretty darn efficient and with that said
let's like talk about how it all works
so the core piece that you're working
with typically is an indie array it's an
in dimensional array and it's basically
just I have some data it has anybody
used numpy so it's very similar to an
umpire ray it's like I have this data
it's in this shape and it's this type
and then the next thing that we have is
the symbol and this is a symbolic
expression for how a set of computation
should unfold so if I wanted to take one
in D array and another indie array and I
wanted to multiply them together or do
the dot matrix product whatever that
would be one kind of symbol then we have
modules and modules are both
intermediate high level interfaces for
different kinds of training and
interfaces then we have loading data and
binding data so that's feed-forward is
the common API call for that kind of
stuff where you you have a bunch of data
in these Indy arrays and you finally
want to feed it into these MA
that you've created or into these
symbols that you've created so you feed
forward send that in DRA through your
network and you get this output and then
we have kind of this mixed programming
approach where we define the network
symbolically and the data separately and
those are the end of my slides
thankfully and we can get into some
crazy stuff so again I was not the
original speaker for this I found about
24 hours ago I was doing this so I have
hundreds of different examples that I
could go into I just finished doing a
deep learning series on twitch TV that
you guys can watch and we have a bunch
of different episodes one of the things
that we created was whether or not an
images is me so we can do that we can
talk about sentiment analysis we can do
this one really fun one that I liked
which is predict places or I have a
whole set of labs that you guys can
download summer for distributed
computing some are for sentiment
analysis some are for building out like
giant distributed clusters it's really
up to you guys where we go from here or
we can kind of in the video and do some
Q&amp;amp;A styles top Q&amp;amp;A style stuff what is
of the interest to the audience
everybody just immediately started
talking and jumping up and down and just
chaos so I'm sorry for those on the live
stream that you guys have to hear all
this chaos right now predict places okay
okay so so I'm gonna download all this
data this will take a hot second
basically this is from a paper I wish I
knew the name of the paper but I don't
but it is a set of images that are
labeled with their geographical
coordinates
and down this will this will take a
second so while that do we have any
questions so far I'm from New York but I
live in Los Angeles so I speak English
quickly and I'm really hard to
understand because I don't enunciate
because in Los Angeles you don't really
want to communicate with other people so
if you guys are having trouble following
me
that's why desperately need to move back
to New York any questions yes
I mean it can run anywhere it doesn't
have to run on AWS but we definitely
spend a significant amount of time
making sure that MX net and tensorflow
and all of these other frameworks run
really really well on AWS so yes in Mex
not is optimized to run on AWS but so
are all of the other deep learning
frameworks and as far as what that means
it means you know down to like
instruction set we're looking at how we
can improve the speed of what's
happening does that answer your question
do we have specific hardware that can
accelerate more no not really
so I mean we have FPGA style instances
so if you wanted to hmm it can also run
on lambda which is the talk that was
actually accepted here that didn't
involve somebody canceling 24 hours in
advance which is a talk that I'm
prepared to give so you guys should come
to my lab to talk just throwing that out
there
so yeah so I can it can run pretty much
any way so what we're gonna do now is
we're going to create we're gonna load
in this existing module that we have
this pre train model and we're gonna
load it from I think that should
probably be it twelve yeah that should
be at 12 but we don't use it I I just
hard-coded 12 in because I don't know
how to write Python and when we load in
an existing module what we're doing is
we're just saying bind all this data and
you know this is the shape of the data
and we're not going to be training so
we're not going to be using this model
to go back through and like fine tuning
it we're really just going to be running
predictions with it and then this is
just creating a set of truths values
using a grid file so oops
so if we look at this grid text it's
really just a set of labels then we
define the distance function this is not
a hard thing to do and then these are
just things that these are helpful
functions that allow me to go through
grab an image process it and get it into
the network and and all that stuff not
very difficult so the first thing we
might want to do is I have this image in
my data set so I want to grab it and
then I want to see where it is that
didn't look promising so I need to
restore the way no no I I the tunnel is
still there I believe so tunnel running
on one port me running on other port
control connection doing all that stuff
for me yeah the trick so this is the
image here this is from Hoover Dam I
think yeah that looks right
and you can see the first prediction
puts us squarely at the Hoover Dam so
not bad I was thinking we could take an
image that I took yesterday
unfortunately that will involve me
hiding my screen because I don't know
what other images are I was in Amsterdam
yesterday
and ate a lot of really good food oh no
none of my images have been uploaded yet
so let me I'll just grab some from
Facebook those are all definitely safe
you guys are welcome to follow me on
Facebook who that might be a good one to
use so lots of trains to get here so I
need to find one
not food picture that might work
obviously I had a really good trip so
far I think I think we'll use this one
so we'll say save image as
I'm gonna crop it into a dimension here
tools I that's not right
how do i crop something you can tell I
don't do a lot of like image work
okay that's what I'm going to use so
sure
and then we want to SCP from downloads
what did I call this Amsterdam that PNG
amps whoops yeah well everything is
messed up this SCP I wish there were a
way to just drag and drop this I wonder
if that would work is I terms smart
enough to do that
nope okay so
SCP downloads Amsterdam PNG I mean I can
make the file name totally random if you
want why isn't this working this is the
fun part
this is what all of my twitch streams
look like by the way
tada oh well it worked
I I don't know why I did it again cuz I
know that it works anyway okay so we'll
make this a random name like yeah 1 2 3
dot PNG that way I'll be able to type it
and I actually just realized that what
I'm trying to do is not gonna work and
the reason for that is I have completely
forgotten what dimensions and stuff I'm
supposed to put this image into so if
you guys want to bear with me for a
little bit I will figure it out yeah so
this is this is a good break time if
anybody wants to get a break images
there used to be this half code like
JPEG info
we can always just how to get image
dimensions from yeah ten minutes go for
it oh you're really planning on coming
back wow I'm surprised you can also just
leave I would not be offended how to get
image dimensions from COI and yeah I'm
just trying to get the the dimensions
that I need to put the image into Oh
file d66 five hundred by three seven
five so then I can be like can route
nope I think I need to image magic for
that
because the network has been trained on
a certain set of inputs of like
apparently 500 by 375 pixels so I need
to pass in that set of inputs to the
network for it to properly evaluate
things so I'll just I'll resize here
tools it just oops I'm just sighs 500
and then we need to take off 116 no
sorry you take off 41 pixels from the
bottom so
does that look like 41 pixels
damnit I have no idea how to use these
things
really delicate work here
I think the image size we had would have
been fine oh well okay so I'm gonna move
oh and I probably should have shaved
save it as a JPEG
so I went cheap haying and I'm just
gonna leave it at whatever size it was
so long as it's 500 and we'll call this
one open Amsterdam 1 and then we'll say
I just sighs perfect
I think this will work I think this will
work even though it's not the right size
SCP mr. dam 1.jpg should probably take
off that other G and then move Amsterdam
one dot jpg two images one two three dot
jpg and then we'll take all of this
again and we will say use one two three
jpg and let's see what it does
I might need to reload those images
somewhere so let's go look at our
predict and evaluate method and see what
I did there
it's the right one I might need to
recalculate all these ground truth Ian
I really wish I hadn't saved the
notebook before I deleted the part of
this that worked okay I'm gonna look up
the answer I don't remember
I can take any questions while I'm doing
this just start talking how is it
supposed to work is it supposed to say
that this image that I had is in
Amsterdam even though we haven't given
it any information about where in the
world I am like if I showed it a picture
of Tokyo it would tell me that I was in
Tokyo and it does work but again 24
hours of preparation less because
Amsterdam
so it doesn't give you the name of the
city it gives you the geographical
coordinates and yes so even for things
that are not in that now I'm not saying
it'll be a hundred percent accurate but
it is pretty magical to watch that work
so this is built on top of a paper from
Berkeley multimedia Berkeley and it's
built on top of the media eval sorry
placing benchmark and then it uses the
the AWS multimedia Commons data set to
geographically categorize the YF cc100
in images so it has a pretty large
training set and you can look at this if
you just go to github.com slash
multimedia - Berkeley you can see this
this running I'm just trying to figure
out where the stuff to launch this is
most of the local minima are roughly
equivalent now I mean that's a gross
statement but finding any local minima
is normally better than you know you
would do otherwise so most people don't
worry about like getting over the humps
between different local minima There is
obviously a global minimum somewhere but
the the general idea is if you're what
network is well-designed most of the
local minima should be you know roughly
equivalent now you can try different
things so you can there was this really
cool paper that was published recently
where they adjusted the hyper parameters
of a training network with different
kinds of shuffling different kinds of
like folds so you would take 10% of your
data and validated on 90% of your data
and then you would do cross training so
you would have one part of your model
trained on like 50 percent of your data
and another part chained on 20 percent
of your data and you would just kind of
iterate and that is like one of the
techniques that people are pursuing to
try and find other local minimum but
typically if you find any local minimum
you're good to go so there is some
impact but it's not it's not significant
so I think I've got this working
think I've got this working
would you see me buddy remember what we
called it was it one two three jpg oh
yeah that was totally on purpose no I
wish I'd had it plugged in okay so
moment of truth and I'm sorry that I had
to put all that away but I had to look
at my email to find links and stuff and
we have this conference coming up called
80s reinvent and there's all kinds of
secret stuff so we got to figure out
where these different things are so
we'll plot it
so not super accurate but still it is
that's an image that I took from my
camera roll like relatively little
modification we could try another one I
could so I could kind of dive deep
they're a bunch of different tools
actually for kind of diving into the
network and you know what layers it's
going to but I don't have the expertise
or the the preparedness to dive into
that today so instead we're just going
to try another image of a landscape from
my camera roll and hope that that one
works
I think this is San Francisco so we'll
try that one
and then I'll rename this SF dot jpg and
then we'll do a WS yeah we're gonna try
without doing that I don't think that'll
work very well but we'll we'll try it
I'm hoping that this code will properly
kind of resize things I've already lost
where I was sorry
so it'll USS yeah SCP SS not cheap it
move as if don't you nurse I
move SF jpg into images right that's
where we were keeping everything will
change this to SF oh and it's also
upside down I'm pretty sure this is San
Francisco and not oh yeah you're right
wait if number one is in the right place
no okay you're wonder where number one
is
so it's got the landmark of like the
Empire State Building and that's where
it thinks it is I'm pretty sure this is
San Francisco let me look at you that's
definitely San Francisco okay so I
normally have ya latitude and longitude
coordinates kept in my images so I
promise we'll find one that works okay
okay this is Paris obviously okay this
this has to work so I'm gonna call this
one yes or do you like the the network
is trained on tons of pictures of sky
and maybe this guy looks different in
different places like we have the human
intuition for how these networks should
be able to determine where something is
and when you actually dive into the
network it's completely like you you
cannot understand like how its deriving
some of these locations so a CP
this is a very long talk how are there
109 minutes left how to design a network
yeah so what I typically do is I find a
paper an academic paper that's already
done something similar to what I want to
do and then I copy their network and
then I make a bunch of different
modifications maybe I changed the number
of layers or maybe I have a different
activation function based on like the
output of one layer and sometimes I'll
change you know the first thing that you
start tinkering with are like the batch
size in the learning rate after the
batch size in the learning rate you have
to actually kind of get into the network
itself and they're there other
parameters that you tune but I I've
never really had much success training a
network without some sort of idea of
what somebody else has done like you can
totally go and do that if you know a lot
about machine learning but that's not me
so I just steal from academic papers and
tune those different networks to do what
I want like we have to get on to our we
have to get on to our network at Amazon
a little token like a hardware token
that we have to read and I built a
network that would read that hardware
token take out the numbers from it and
type them into my computer for me and
that's the extent of like success that
I've had building my own network again
just want to point out I was not the
person who was supposed to give this
talk 24 hours ago and after this works
because we're determined to make it work
I even named it works
we are gonna kind of close things down
works
yeah all right cool sorry so I mean you
can do things whenever they're like big
landmarks like that I I'm happy to take
like any challenges for this network
because it's pretty well trained and it
can do some pretty magical stuff like
this is from my camera load this isn't
like some picture from the internet this
is literally just a picture that I took
last year at on October 2nd okay that's
really all that I wanted to show off
there a couple kind of calls to action
that I have for you
so these are the sort of calls to action
all of these different pages and
websites will teach you things I will
put these in the the notes for the talk
later I strongly encourage you guys to
go check out other talks that didn't
have their speaker replaced 24 hours ago
but if you want to talk about things can
we in the video and then we can do
talking things mister audio person can
we in the video and everything in
perfect great alright thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>