<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>JDK 9: the performance bits or why you would really want to upgrade to Java 9 by Dmitry Vyazelenko | Coder Coacher - Coaching Coders</title><meta content="JDK 9: the performance bits or why you would really want to upgrade to Java 9 by Dmitry Vyazelenko - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>JDK 9: the performance bits or why you would really want to upgrade to Java 9 by Dmitry Vyazelenko</b></h2><h5 class="post__date">2018-03-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/s31xjuWcD54" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I have the last was last load of the
day which means I'm standing between you
and the beer so I make have to make sure
that I'm here on time so if need be I'll
cut some corners you cannot see anything
yet
my original talk title is Ric really big
it doesn't even fit on the screen and
something about JDK 9 and upgrade etc we
actually the new title is called
performance after eight because I'm
going to tell you about performance in
Java after release eight because I think
for most of us here in the audience just
a quick poll who is running Java 8 in
production like 90% of you Java 7 okay
couple of hands who is brave enough to
have Java 9 in production okay sort of
one hand but nobody using this used it
ok there is a reason for that so that's
the talk will will answer some questions
why why it is that way and I'll tell you
what's going on now in Java
after least 9 Who am I I am one of the
dis organizers for two unconferences one
is jaikrit on the island of crete
another one is J Alba which is gonna
happen in Scotland we start in May this
year this will be awesome
I work for canoe one of the sponsors of
this event and so that's more on the
agenda of the talk is I'm gonna talk
about release cadence of Java and then
couple of interesting jabs in JDK 9 and
new api's and then we conclude with some
parting thoughts what it all means we
okay John release cadence I don't know
how many of you seen something like that
and that is a new reality prior to Java
9 we lived in the world where every new
release of Java would cook for some
years usually two to three some leaders
work much longer but then basically we
have this huge hourlies and then we'll
move on well starting with jdk 10 Java
will release every six months
and so you see Java 9 was released just
September last year it's gonna be
end-of-life in two weeks then we have
Java 10 for six months it's going to be
also end-of-life and then from there on
we'll have a long-term support release
Java 11 so ok what's the difference and
what what do I mean by end of life and
of course the code will still be there
this release will not have updates
anymore so in the older versions of Java
and every new major released like when
Java 8 was released at end-of-life Java
7 which was kind of okay because it was
already time to move on to something new
now with Java 10 release which is six
months of the jo9 release what do I do
with Java 9 well this is a problem so
essentially if you're not a paying
customer you have to kind of think
herself do I use a new features of new
release or do I stay for long term
support releases which will Oracle will
support for three years so like Java 11
which comes September this year will be
support for 3 years until 2021 and at
which point the Java 17 will be released
so you can just jump from Java 11 to
Java 17 which is pretty scared and
you're missing like five releases in
between or you go to another vendor and
down there I have a link for the blog
post by Simon Ritter from Azul where
they explain how they gonna handle the
situation and for instance Azul was
there Zulu
open JDK built will offer one-year
support for the intermediate releases so
Java 9 will be supported until Java 10
essentially is over by the Oracle
release and so on and much longer
supports for for the long-term support
racism okay so this is a new new model
so new releases come in every six months
I think for for us Java developers it's
a big news and big shift but if you look
at the other community it's like go and
they also released bunch of times a year
and everybody jump into new release
without any problem so we'll have to
adjust to that alright so let's start in
digging into the performance or what we
mean by performance I am what kind of
speed benefits and and other cool
exciting things we have in JDK 9 and of
course I couldn't miss a big elephant
room which is modules so what do I mean
by modules are nuts I'm not talking
about like defining modules and working
with modules I want to take on the
premise of how the modules thing who
started so it started with project
jigsaw as an attempt to modular arise
and take apart the JDK itself and then
one of the premises was because you can
like break apart big monolith JDK you
can have a smaller footprint and they
put Java on the smaller devices etcetera
etcetera etcetera and of course as as
having a smaller thing smaller footprint
and we've got the premise of faster
startups because Java startup JVM
startup sucks so this this thing
supposed to to help us and he just list
of all the jobs and GPA jarvan has been
proposals which went into JDK 9 operated
two modules there's a whole zoo of
different things
starting from modularize in the jdk
itself down to cool things like j linker
so you have a linker now in Java
welcome C++ was a long time off and we
can ahead of time compile live intro
okay so let me just look at one
dimension on jdk 9 so i decided to
compare because jdk 9 saw modular and so
small what is the footprint of the gdk9
releases and here's a table to showing
you JDK 8 and Gerry 8 compared to JDK 9
and Giri 9 and as you see on essentially
both dimensions was download size and
the install size
it sucks it's actually bigger than the G
decade so even though we have modules
well we have to pay cost for it okay so
well this is not the most most most
exciting thing let's let's move on
so meter on my friend hello world app
you've seen that and let's just run it
and time what what it takes the the
start essentially the execution time of
the program so you're starting an app
both in JDK 8 and JDK 9 and as you see
I'm using a pair of I'm doing like 50
repetitions and doing something
scientific and all of a sudden I see ok
Java 9 sucks
just by using old class pass and jar
options I'm losing I mean come on that's
but but and so to myself well I know the
answer the answer is obviously modules
right so I build myself a module and I
run with the modules and like oh okay
well what does it all mean
all right so I have some other options
besides that one of the one of the
premise was exactly did J linker what J
link allows you to do it allows you to
build out out of your app and native
applications so to speak so it packages
the the bits of Giri the modules of Giri
that you use in the modules of your app
and your dependencies into one package
so I decided okay let's build that thing
which is called hello app in this case M
which is by the way has a awesome
footprint just building they had this
hello world app it's forty five Meg's on
the disk unlike almost 600 megabytes for
the jdk itself so I have really nice
thing and it can just use Java
- module and they don't have to specify
class bus because it's built into that
image so jaelyn could build me an image
okay I'm building that and I'm down to
essentially class pass option so yeah I
can build I can still use modules and be
on par was the class pass option with
JDK 9 but I'm not close to the JDK 8
start all right let's use heavy
machinery I know one of the things was
ahead of time compilation come on we go
native right even even the web
technologies talked nation mention
native everybody goes native so we go
native so what you see by these two
commands highlighted here I built two
things I ahead of time compile my module
which is called hello a so in this case
and I had compiled hello s all in the
Java based module so if I run just was
mine man it sucks even more than then
without ahead of time compilation if I
run it with Java basis a disaster and
reason why because the Java base as far
as I understand when you specify the IOT
library it memory maps the files so it
reads goes through them compiling Java
based takes a long time several minutes
taking its rose megabytes of exceptions
but that's okay
you know everybody say it's okay it's
supposed to be like that you know there
are some issues with ahead of time
compilation and it produces a binary
which is like 300 megabytes or something
like that it's really ridiculous okay so
um in this case there is one more
feature I haven't tried and it's called
class data sharing who heard of this
feature okay some people like to see
three hands three hands in the room this
is available since Java five so what you
can do with this feature and I show you
the final result you see this let me see
if I can point to that now whatever this
each their own option so I'm using the
class data sharing option and run in
Cherokee nine and all of a sudden we
managed to beat JDK 8 like almost we on
par with dedicated and class pass option
right but I'm this is not fair
comparison because I'm enabling class
that is sharing on JDK 9 but this is
features in Java 5 so let's enable it in
JDK 8 game over so this time say ok one
day we will have better faster systems
startup times the Java it's just not
today which which brings us to the to
the next topics and I'm here well and I
will come up briefly first to Jeff's not
going to cover them in depth because
they're - they just important to mention
first one is the Java level compiler
interface this is the thing that enables
the holy grail who've been to the growl
vm talk today I see a couple of hands
this thing enables to run growl on the
JVM so essentially this allows to to
hook into the DVM and replace the
hotspot see - compiler with the compiler
written by Java in this case is draw
just a couple of things to mention this
incubating feature enabled in JDK 9 in
JDK 10 there is Japs three-one-seven
which is essentially enabling the growl
compiler this is just enabling the the
entry point to the compiler where you
have to build
pilot yourself and plug it in in JDK 10
you can just enable with two common line
flags you enable the growl compiler you
can actually test your application
against growl which will be embedded
with the JDK installation which is
awesome and second thing the growl is
used to ahead of RAM compile so a
compilation is actually based on growl
and the sort of thing and Twitter is
using it as we speak in production and
there is a guy called Chris Challenger
from the VM team at Twitter he has a
talk where he explains why they switch
their custom OpenJDK build to use growl
and how they benefit was there Scala
code base using that another sort of a
big elephant in the room and the thing
the offender in terms of performance
measurements is a g1 compiler for better
for worse guys at Oracle decided they
don't want to support all the GC
combinations out there and they decided
that we should all switch to one and
only true GC which is in this case a g1
and they made a default collector so
what are the problems was dead well the
pros is default changed if you were
serious about garbage collection you
monitored it and tuned it most likely
you define your algorithm and you'd
specify GC - recently so it will not
affect you if you run in on default here
with Dragons if you want to use g1 and
you're serious about that and want to
switch and try g1 you need the JDK 10
because JDK 10 brings a first-time
parallel
. GC 2 G 1 prior to JDK 10 full who GC
like GC of the full heap who stopped the
world is single threaded
there was JDK 10 at least the worst
pauses will be much much smaller and
here be dragons here's a blog post link
what the difference will make by needs
and Walker the guy who created JC Tools
where he recently investigated the
problem why his lock free data
structures run in supercool and JDK 8
suck on JDK 9 and it boils down back
basically to the default GC switching on
gdk9 to peril
GC fixes the problem and the culprit
there is that GC for its own bookkeeping
insult some instructions to the code
like card marking at that thing all of a
sudden puts a lock so we have a lock
free data structure which has locks in
it inserted by the by the runtime
awesome isn't it so that's why we've
seen on the previous slides as well and
if all my measurements I always use it
parallel GC on the JDK 9 so I am
comparing apples and apples I'm running
the same garbage collector in both cases
and by the way JD can I also duplicate
CMS collector so moving forward around
JDK 10 essentially you have like two
parallel G C and G one and there are
other some exciting garbage collection
technologies coming one is 0 DC z is z
GC it's called by oracle for huge heaps
and another one is Shannon doll from Red
Hat but nobody gives us timeline when
they will arrive so keep an eye on the
space so let's all move on to really
exciting things one of the biggest
changes in the JDK 9 released in terms
of performance was compact strings so
what compact strings are is helped me
show you examples compact strings let me
rewind what you see on the screen is in
little program which has a string value
lorem ipsum blah blah blah you can
Google and Wikipedia find the full text
for it it redacted this long thing and I
am printing the class layout in a graph
and then the footprint of an instance
and I run this program both on gdk9 and
JDK 8 so if you're under the JDK 8 we
see what our string class is so a string
class has essentially two fields well
it's an object header followed by a
value which is character array and the
hash code I hash for the hash code and
it's 24 bytes so empty string just by by
sheer class overhead is 24 bytes so if
you put one character in string it
cannot be less than 24 bytes in fact
will be much more but this is 24 bytes
and down there below you see the
footprint of this of my test text that I
put there and it's 9
thirty six bytes okay so what we see in
JDK 8 is that every character or every
every element of the string every
character of the string is a character
in java terms this is two bytes which is
two bytes because Java uses utf-16
encoding okay what guys at Oracle did
they analyzed bunch of heap dumps and
realized that up to 25 to 30 percent of
all the hips are taken by strings and
most of those strings are ASCII or
lighting one encoded which means they
essentially cared is one byte but we are
paying for two bytes for the thing so
they said okay what can we do about it
so they came up with the idea to replace
our character array value which is
highlighted here with a byte array and
we see something other thing here which
is a new field called coder that you can
decide what it is is it light in one
encoding or is it utf-16 instance like a
string instance size still 24 bytes
nothing changed but look at the
footprint size difference so we had 1936
by its before 488 so in total is almost
twice 2x but if you compare the two
areas like character array and the byte
array content wise you will realize that
is exactly 2 to X reduction in the in
the memory footprint all right so we if
we switch to JDK 9 we get by default
compact strings and if our compact
strings are of 50 if the strings that
we're using is latin-1 encoded using
less heap so we can utilize it better we
put less garbage collection pressure
everything is OK but what it means in
terms of like you know performance in
terms of basic operations because string
is not just a storage of characters we
do something with we iterate over
characters we do substring on it we to
lowercase it to look to make a case
insensitive map lookups etcetera
etcetera etcetera so I decided to create
a couple of benchmarks one is called the
basic one just in this case matters for
operations like walking the character
array using to lowercase
and doing substring at the beginning and
the end I'll just explain why was my
test data and here the results so what I
am doing I am essentially
having two strings which character-wise
have the same length so 16 characters
one string is letting one encoded
another string is utf-16 and as you see
I mean iteration time is a bit better in
JDK 9 but I would say it's essentially
didn't change and this one one of the
biggest concerns of the performance team
at Oracle that you cannot regress the
string so if you make changes to
something fundamental a string in the
JDK you better be sure that performance
was 10 par and then you see something
like stop stirring head having the same
model as the same speed allocates the
same amount of bytes everything is
awesome
you see substring tail has an
interesting story here for a while when
the string is a utf-16 encoded so in JDK
8 it's certain milliseconds or not
sorcery milliseconds nanoseconds further
for this operation and in JDK 9 it's
18.8 under seconds and actual JDK 9 in
this case allocates even more bytes so
what happens here is that you have a
string which is utf-16 encoded but if
you split it in two sizes into pieces it
could be that the piece that you take
out could be compressed now to let in 1
so what they do there opportunistically
every time you like take a piece out of
a bigger utf-16 string trying to
compress it so in this case they
allocate a storage array self bytes
going going compressing it and upon
second character realizing that this
character is not letting one encoded so
we have to throw away array and start
again by allocating bigger byte array
and and put it in putting stuff
unencoded there so that's why we see
some smaller regression in here so I
think it's a reasonable price to pay
especially if you look into into other
potential gains like for example to
lower case an example if you see light
in one encoded string in JDK 8 and
latin-1 called the string in JDK 9
it's like 1.8 X and performance
improvement and more than two like two
and two and a half times
footprint improvement or honest
so essentially the smallest ring smaller
storage less bytes you allocate let less
pressure you put on the allocate and
garbage collector you get performance
benefits all right but that's not all
string does right string does some some
other funky operations like you search
string with index off you you have the
searching starts with ends with and you
have things like equals and compare to
quite heavily used so let's look at
those operations this is quite packed
screen so no worries it's just like the
full combination of now I have two
values so I have the same the same
strings and just full complete
combination between parameters so legend
100 city f-16 let in one which is like
mod etc so you have like four four
values per operation and so far the
story it's more or less the same okay I
highlighted a couple of things here down
there at the equals you see that JDK
nine is much faster and for two
particular cases and the cases are when
the strings have different encoding
because if strings has different
encoding there byte coder is different
there is no reason to compare can't
content so the JDK nine has an
implementation optimization saying if
color is different screw this equals
false because they cannot be equal by by
definition if they are if encoding is
the same of course you have to perform
the full encoding thing any similar
stuff of course exists for things like
index off because if I am if I'm having
a lot in one string and I'm searching
something that is utf-16 encoding I know
for sure this this string cannot contain
that so again seven point seven
nanoseconds for the second role and
therefore JDK 8 and 2.4 4 gdk9 because
it it's no op there is nothing nothing
for me to do okay there is one or like
there are always pros and cons of doing
something right the same goes here
here's a thing called string max size so
what we see here is that this little
tiny program that runs nice on JDK 8
provided you have enough heap well you
need eight gig there is seems fine and
JDK 90 see this bizarre error out of
memory error utf-16 string size well
essentially what it tells us is that the
byte array storage that we have in a
string cannot hold more than one point
something billion entries
whereas the character this is basically
the byte array right and there's the
character array before was able to hold
central twice twice more characters in
this case and the problem only appears
if you have utf-16 encoding because we'd
have sixteen for every entry in your
area you need two slots so before it was
one slot no problem now you also need
your basically double your storage
capacity so and this is the price to pay
so the guys at work will say well if
your problem is strings with billions of
characters you probably have some other
problems and so and finally thing enough
if I run it if I don't put this funny
characters there and they keep it light
in one encoded it works because the
compression algorithms kicks in and it
figures out that it can compress the
whole character array directly to one
one two one two by terrain then there is
no exception
another interesting feature added to JDK
9 also related to strings is called in
defy string concatenation quick show
hands who knows what this code at the
bottom compiles to on pretty much any
release of Java start in Java Java 5 may
get shut out well what does string
builder yes so the how everybody used to
think about it whenever you have the the
string concatenation pieces which you
don't explicitly manage shattuck
language 1 this is a syntactic sugar
essentially that the Java C provides you
to generate a string builder behind the
scenes in in and do it like this so
let's have this example and look at Java
PD's assembly in JDK 8 it's huge role of
text but what you have to follow you
have to follow the comments on their own
there on the right hand side from you
and yes you see basically we allocating
a string builder we add in
left square bracket to it then we call
current and Milius and essentially
essentially this all whole dance with
the stringbuilder stuff okay what does
the problem is that the problem is
simple because this is a sugar that is
spit out by the java sea once your
program is compiled it will stay the
same for as long as your jar or your
classifier lives and this means it
precludes JVM from optimizing string
concatenation it's essentially like it's
there there is nothing to do
so what it guys again performance team
at Oracle decided to do they decide to
change it and they decided to use a
frank funky technique called in Wong
dynamic so GSR 292 back in Java 7 was
added for essentially for the in
implementing dynamic languages and since
then this horse is used for lots of
different things including lambdas
itself so how it looks in JDK 9 so all
of a sudden our method compiled to
essentially six instructions or seven
byte codes essentially calls in this
case we just acquire current I'm
Millie's and we the important bit is
this one highlighted instruction in work
dynamical and this invoke dynamic Oh
strangely now has just three parameters
which is J capital J stays stays for
long then comes our Java long string and
then an integer so it's a three argument
method call very strange it returns a
string and then afterwards we put the
string into the print line which is
essentially systematical and down at the
bottom I'm showing you what the the
invokedynamic
I don't know how many of you have heard
about it more dynamic it's essentially a
two-stage process when you invoke the
nimac bytecode by the way normally the
java sea is not emitting that bytecode
is JDK 9 fo for string concatenation
there is no way to do it from Java you
have to write like through through
awesome or by body whatever you can we
can put this instruction but essentially
to two-stage process and while normal
invokes like walks passion walk static
etc in Java Java
knows what you
it knows the target was involved I Namek
the target is I know unknown so the
process is two-stage first there is a
bootstrap method call so you call
somebody to tell you what what are you
calling to establish that that thing and
that's like a linking step and
afterwards all subsequent calls from the
air from their own a call directly that
that method so here down bottom we see
the bootstrap method definition which in
this case points to something
interesting called java.lang it walks
through income cat factory macon cut
with constants and highlight it in blue
down there
it gives this stranger argument this
argument is a string it's called a
recipe for for building the concat
concatenation with constants as the name
implies and as you see by the shape this
is our string from the example we have
bracket we have bracket spaces
parenthesis and this you 0 0 1 is a
placeholder for the parameters so first
parameter is our long which is current
time Milly's the first argument to our
method second one is a message and the
third one is account so it's exactly
mimics the the thing so what did in
essence what it does essentially it
built the recipe it realized that there
are constants in this recipe so it
compiles down it generates a method
handle which accepts three parameters
because everything else our constants
are built behind the scenes and plug
plugged in into this into the story ok
so they did this funny thing very very
cool doesn't matter
well let's look at if it works click ok
let's look at the benchmark I'm
essentially logging the same and the
same message is shown in the previous
slide run it with jmh and then you see
these numbers so concatenate in with JD
cane 8 compared to gdk9 so essentially
we have like 3x in performance and we
are more than 3x in in footprint and if
you look closely this 80 byte operations
a second and you you look closer at the
data it's essentially the exact size of
the string that we are quick
catenate in the the there is not a
single bite wasted down from the second
roll down I'm I'm running on the gdk9
with different options one is I thought
okay maybe it's combat strings you know
who knows that the combination of the
two of course is the best
let's run without compact strings just
with with optimized con cut and we still
essentially have the same performance of
course we lose some bytes in the process
which which is expected because strings
is now strings are now bigger but who
cares and the rest of the experiment is
essentially inside the string
concatenated is for doing actual
concatenation there is one default for
the second role not shown here and there
are five explicit ones shown here
essentially they split into two
categories one is white code generation
which is all all strategies prefixed
with BC underscore and then method
handle base and this first five
essentially all of them essentially
delegate at the end to the stringbuilder
and the different combinations of size
and size exact is how how they precise
the storage so they just say okay if I
know all the arguments and I put all the
sizes together and I can create a string
bill that was the proper size it doesn't
have to resize internally so it's just a
game of how the thing but okay but what
it makes what makes the default so fast
well the default is called mah inline
sized exact what it means is that
instead of using a string builder API
they allocate in a byte array and right
into the byte array directly and the
coolest thing of all if you look and how
it is done because it's a method handled
base there is no code generation it's
essentially kind of like generating code
on the fly during the first bootstrap
call the method handle will be created
method handle is creating kind of like a
substrate like a node of trees like I
are if you if you like abstract syntax
tree if you familiar with parlors to
build that recipe and gives you the
method handle and from now on you call
in that and essentially generated code
on the fly and that was like before
looking at the
example ID I was not aware that you can
use essential metal handles for
cogeneration without coaching the rating
and without resorting to the bytecode
management which is super cool and of
course there is always a carrot and the
carrot is this if you think it the
concatenation is so awesome I'm gonna
stop using string builders I'm gonna use
just default con cut yes as long as you
don't use loops as long as you have
loops like that where the warning
suggests result plus equals is actually
mandating that the new string will be
allocated this is in GLS so you cannot
avoid allocation of new strings it will
be allocated and discarded allocated and
discarded so if you don't believe me
let's run the benchmark and let's see
the times if you and JDK 8 you see a
huge difference it's like 5 x in
performance in JDK 9 everything is
better because JDK 9 is smarter was the
storage and the cult intonations and
allocations you still you still pay like
almost 2x for it but look look at the
memory even if you on gdk9 you're paying
5 weeks more in the garbage generated
and of course that means pressure to
garbage collect means more pauses means
slow down alright those were our strings
what else we have in store we have lots
of stuff enjoy taking I'm one of the
interesting ones our convenience factory
message for collections I think most of
you heard about them they look something
like this now you can create a list or
rather not just a list but immutable is
by calling list off from 0 to 10
arguments and then comes another
overload with like war arcs array so
it's unlimited the same goes for set and
for map up to 210 key value pairs you
have an off method and if you have more
than 10 then you have to use of entries
okay new collections what a big deal
syntactic sugar you know before you say
arrays as list that's it well it a
immutable so you have to put like
immutable collection around it or
whatever okay well not just that these
collections are first and foremost of
optimized also for storage
so unlike a generic collections these
collections problem is that they like
keep overhead to minimum and provide the
super cool new functionality like being
immutable so let's just have a quick
look this is a slide with a was a list
what you see here in different
incarnations of the list interspersed
with lists of some basic comparing one
to one what it means to create an empty
list with the new functionality all
functionality one element two elements
10 elements and as you see in first two
rows are not interesting because least
often empty lists the constants nothing
to see here
list of one and the singleton list from
collections the same and you see I'm
storing a 16-bit 16 byte object which is
in this case in integer and the overhead
is like 60% so ok I'm not winning
anything let's create an error list and
all of a sudden error list is like 64
bytes because L is inside itself
contains an array which must be
allocated and there is an object which
has a header 12 bytes plus 4 bytes
lengths so it's at least 16 bytes on top
of it plus you put a value inside it
means another 4 bytes which is already
20 and object alignment rules tell us
that it must be at least 24 so here here
you see how we go from from 40 to 60 4
we got 24 bytes of overhead linked list
even worse it creates the linked list
node with the pointers to it 72 bytes
and you see the overhead is just
increasing and it's basically the same
the same story goes if we continue
adding more elements to our list and at
10 elements okay one thing to note here
the list and set have specialized cases
for empty one and two elements that's
why I'm sure when empty one two and then
more than that
so as you see for instance list of two
is 56 bytes only 43 percent of overhead
and really at least link this suck big
time so we just add thing but once we go
over to over three like starting from
three elements on list off and new error
list is essentially the same they say
have the same overhead because it's
implemented in the same way the list of
more than three elements onerous has an
error inside okay this is kind of okay
we we gain something on part was all
released much nicer syntax let's move on
let's take a set it a set is like real
deal thing here again empty ones not
interesting set of one element
collection singleton has a have a
scoured here well let create a hash set
within one entry in it boom two hundred
eight bytes so it's like ninety percent
overhead slick don't they we don't even
bother Ling her set even more three set
better story there just for those who
who don't remember all the hair sets
three sets Lincoln sets etc in Java
implemented on top of hashmaps
so a hash set is essentially containing
a field of hash map historian areas in
the map so you're essentially paying for
the cost of the map and the trend
continues the more the more data you put
basically the dome overhead you see and
especially especially bad with lead hash
map there are maps just shown here for
completeness I'm not gonna spend too
much time on it but just look at the
last four rows what I did on top of just
adding like sequential elements from one
to ten to the map I decided to create a
hash map collision when a hash map
collision is when all your entries have
the same hash code which essentially
provoked animalic behaviors in the hash
map and prior to Java 8 and hash map
would degrade to a linked list data
structure inside it with Java 8 onwards
it builds a binary tree so what i'm
doing here essentially i'm creating the
collisions and seeing what what is there
was the overhead of what becomes of our
collection if the collision same present
and you see my data size is quite
substantial like half a k and the map of
entries essentially has has fixed
overhead this is quite easy because ma
Ventris is just an airy
well the hash map link hash map and the
tree map all have much more overhead
these these things like hash map has now
inside a table
like an area of buckets plus a tree to
us it and it's just ridiculous the
overheads so as we see the the first
thing is the collections did they
deliver on promise and bring the the
memory down so let's let's look at the
some numbers so this is just some pics
from from from the benchmarks I did list
contains contains in the list depends
what the what kind of list is a list of
air a list link list quite simple one in
two element special cases in list of win
across the board very easy and go into
the N elements list of an ArrayList
essentially behind behave the same same
four hundred elements because they are
the same there is an error inside and
linked list is you see walking linked
list essentially it's a pointer chasing
it's a cache misses and it's just the
performance drains down the drain
essentially if you are takes take
something out of the stock don't usually
linked list at all in your code there is
no reason for it there are some special
cases which might call of them if you if
you like add at the beginning and do
frequent removals but even the normal
code never never do the similar stuff
for said it says list off but it's
actually set off because everything else
is have set and link here set here quite
interesting for special cases of one and
two elements it's very fast like 2x
faster than everything else and then and
then it gets funky because then we don't
have the performance advantage anymore
even though we have this specialized
storage we have an array inside that
thing it doesn't work this way and this
is quite easy to explain that the reason
is they decided to put a feature into
the set off and map of implementations
which is called randomized traversal
order I don't know if you've been bitten
by the bugs before that like iteration
order of the hashmap is never specified
so if you have three map is one thing
because it's sorted but the hash map is
like random and there was a change
between Java 7 Joey I think broke lots
of programs and they decided to avoid
this thing in the future by saying ok
sets and maps update
through the factory methods will
randomize the order once per VM start so
once you start a VM and the order would
be randomly chosen and then it uses some
some funky while loop by essentially
jump into different places or like for
instance the two element thing once you
call the iteration you have one and two
element second time you can't get
another iterate and they get two and one
so they flip flip as you as they see fit
the order so you cannot rely on the
order of the thing and it seems like
they these things they have have exactly
the negative performance impact on those
okay let's let me move on I have about
ten minutes I'm near the end of the
thing so stack walking I don't know if
you know about that but back in old Java
days sometimes you need to inspect the
stack or like know who is the color of
the method is so there was a way to use
reflection some misc reflection dot get
color which is propriety API which is no
longer possible in Java nine an
essential that classes is deprecated
still and if you can get it to work but
nonetheless in JDK nine and you have a
new API to do the job but let's look
first what would you do in Java eight in
Java 8 and the way to get a stack trace
is essentially you create an exception
asking for straight trace or go into
thread dot get stack trace which
essentially creates exception for you if
it's for single thread or if you have s
all stack traces of the application then
you can say thread get all stack traces
so that's the old way to do it and the
new way is to use new API called stack
Walker you obtain an instance of it drag
several methods to get it risen without
parameters I'm using a special one here
to be able to use get get color feature
otherwise it's not available but
nonetheless is essentially you see for
getting color it's a single method to
get color for walking the stack you have
a single method walk which receives a
stream of thing called stack frame which
is a new interface and you are walking
that stream which means you are not in
control of the stream
whoever gave you the
stream can close it upon you so it's a
pretty clever design they could have
just said call a method and get a stream
and do whatever you like with the stream
but then you are the client the caller
is responsible for the stream and with
inverting that and saying the stream
will be parameter to your function you
have to give a lambda or a function in
order to process the stream then control
of the stream so in other words they can
close the stream for example because
stream is hold on holding to the
currents currents Reds stack stack
information so if they would give you a
stream by the time you leave in the the
call this the the thread stack trace
changed so it mutated so it just doesn't
work so by having you basically they
giving you just this one little window
when they give you the stream thing they
in control and saying okay this is now a
stable view of the stack you doing the
call by the time call finished the stack
is gone loved it this view of the stack
is gone so you are you you cannot harm
them and then they can give you some
cool things so I'm here I'm just doing
like a count of this of the stream and
just walk the whole thing and for the
for the get in top 10 frames I'm just
limiting the stream to top 10 and
collecting to this nothing special here
standard Java 8 ok so let's see what I
mean that doesn't matter so if you look
the exceptions what you see the pattern
is quite simple they'll the the deeper
is your stack size like in one case is
10 frames and other case hundred frames
more time you pay in the time now is not
in nanoseconds is in microseconds so
doesn't matter which operation I'm doing
it cost the same because every time you
have to get the full stack trace you
have to get the array with the stack
trace they all materialized you take you
get that and then you move on from there
and if you use a new API caller class
essentially constant time operation it
doesn't depend on the stack depth I'm
essentially stack depth is quite funny
because for stack depths I have to walk
the whole stack and call a count at the
end and when walking the stack the stack
is lazy so the stacked frames that this
API is giving you have to be created on
the fly so as you see as the size
increases from 10 200 so does the time
so it's more than 4 times slower
because the the deeper the stack and
getting the top ten frames essentially
constant because it's always top ten
frames and it's just the price for this
ten frames to get alright one more topic
my agenda this is a not a jab this is
what the new API is in the in the JDK
everything found with at since nine
there is lots of stuff and a couple of
things highlighted here have to do with
performance first one is full fuse
multiply add there is an instruction in
the modern CPUs to do that and it's more
for correctness tanta for performance
actually did the benchmark and I didn't
see performance benefit but you get
better
rounding results but two other groups
are quite interesting one is different
check index help helper api's come on
just checking you know if index less
than great and then whatever some simple
stuff but what is important
those things are heavily in light and in
trees defied and actually almost all JDK
is now using those instead of putting in
explicit checks or writing them on eaves
or whatever by using this essentially an
entry methods and the objects the
hotspot knows aha this is special thing
I know how to optimize that so it has a
specific special code it recognize the
code shape by seeing the call into this
methods and there they used and another
thing this bunch of stuff added to erase
you see like new compare methods compare
and signed equals methods was lots of
funny like you can have an equals on the
portion of the array and the last two
ones as they actually are the building
blocks for the rest it's called array
mismatch so given two areas you can find
an index at which arrays diverge if the
Rays are equal there is no such index or
you find the first index the divergence
of the array so let's have a quick look
how that work might look like naive
approach and the one that we use in
library so native approach is basically
you're walking both areas simultaneously
obviously to the to the lengths of the
smallest array so you stop at that and
if the length was the same and you
didn't find anything it's like okay
there is no such index otherwise you
return the index all right so doesn't
matter let's run it
oh yes it does it does big time so it's
like the the bigger area once once you
cross in the threshold of like hundred
or thousand elements essentially see
more than 10x performance tend towards
15x performance difference and the
reason is being the area's mismatch is
operating on the strides of eight bytes
so if I'm working here byte by byte they
can get the chunk of memory and analyze
that by the way this feature is used
heavily already in patchy Lusine
together with object check index they
also using the multi release jar of JDK
nine to being to being able to benefit
from the feature so once you start using
your soul early scenes instances on a
JDK nine you can you should get even
more benefit by not just strings but
also these things okay let's quickly
recap Java changed release model
releases every six months release is not
created equal some releases a long term
supports homilies is not so we have to
think what it means and how do you sell
the upgrade to your boss before it was
easy
it's the biggest new thing all the
versions end of life we get new security
patches etc I think it's it's hard at
jedikiah has has lots of stuff I didn't
cover lots of different things there is
lot of changes to concurrency like on
spin weight hints like optimized locking
etcetera etcetera just tons of stuff
encryption also improvements to
encryption JDK 10 is bringing more stuff
the growl growl is coming closer so we
can experiment then with delicate and
using growl instead of situ and see if
our Java apps or our polyglot apps
groovy apps whatever and will benefit
from that and and some improvements to
g1 and some other stuff bunch of
references and questions if you might of
course there's beer in like one minute
so if anybody has a question or remark
or comment okay no questions it seems
like beer o'clock ah there is one there
is one question okay it's it's really
you know I cannot see half of the
audience because of the lights so sorry
for that thank you very very much for
your presentation I would probably say
no I have kind of anticipated this
question the question is the startup
time doesn't matter I mean if you launch
in something like your springboard app
or your JBoss and it takes three minutes
to kick that off difference in between
20 or 50 milliseconds even hundred fifty
milliseconds will make no difference
you've not seated this is more for stuff
like you know you know micro-services or
restarting something or something
smaller
they put using Java and different for
different deeds like maybe doing some
little scripting in Java and writing
apps and invoking Java to do that that's
where it matters but it was more an
exercise to see the deliver on promise
you know modular Java should like have
better footprint has better startup and
it didn't at least in my in my test
actually I found the blog post by some
some other guy who did almost the same
steps and he went even further to like
selectively ahead of time compile you
can compile module directly or you can
give it a list of methods that you need
so he went all the way there like
dumping all the methods that his hello
world or whatever his app was doing
needed and compiled on the debt and even
managed to get like some millisecond
improvements but it's I mean it's
ridiculous the amount of pain you have
to go together I think what you get
already you get like linker so you can
build your application in the like a
releasable package which you don't need
to install java and you have all the
modules together there I think that's
already super beneficial and if if it
takes 20 milliseconds longer to start
and dedicate who cares
inge a decade you didn't have that you
had to build your docker container and
put jdk there or whatever now we can use
essentially using Java tools
already have your application in a
runnable state in the real estate and
they actually can create an exit every
when you build the j-link you can
provide an exit so you have an
executable to run
no no I'm using the compressed oops I'm
running on was default this is I'm not
sure I think I'd input
unfortunately I'm printing the VM
details but it's essential default
modern 64-bit VM plus with JDK nine nine
doesn't have 32-bit VM he said goodbye
that's another thing if you are having
some sort to be platforms and you
planning to upgrade to a new JDK since
gdk9 there is no city two-bit releases
by Oracle there might be like arm ports
a little bit but like Windows Linux and
it's gone
so there is no such a two-bit Java has
moved on it it uses compressed ups so
the default mode if you if you if your
heap size is up to is below 32 gigabytes
VM is able to compress the the pointers
from 8 bytes to 4 bytes and so that
that's where you get the benefit from
and that's of course in fact alignments
and all the sizes yes ok so no times we
had very different experience with j9
it's actually when you start complex
application for example for us is jetty
it's actually four or five times faster
starting in Jurek a 9/10 jka and this is
due to way improve it class loading when
cherokee nine starts up there's all the
metadata about classes where they are
how to load them into memory etc rather
Jerry k-8 yet to crack open the jars
scan off the jar may be that the cluster
you need to load is the last one in the
list of entries in that jar so it takes
way more time so overcomes application I
think it's Jake announced way faster I
was actually the first time that I tried
to start
Jerry with Jerry canine I was actually
surprised because it was like I was used
to wait up to 30 seconds to start up and
then whichever canine was like two
seconds and he started in a second
there's something wrong checked
everything and everything was starting
just fine so it's it's probably true for
the other world but the more classes you
load probably the way that's ready and
make the testers thanks for the remark
testing is a very important so it's even
more encouraging so encouraging people
to upgrade but I guess all of us are
waiting for LTS 11 release I don't think
it's a I think it's a safe bet to assume
that you can start playing with like 10
but it's gonna be gone in six months or
there's another way you start upgrading
every six months you just say okay now
with Java I'm gonna break my Java
release every six months and if you in
control of it if you ship your app with
j-link or whatever docker images you can
do that alright thank you very much for
coming and the beer time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>