<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TCP? UDP? Que? – Fundamentals that were abstracted away from us by Hadi Hariri | Coder Coacher - Coaching Coders</title><meta content="TCP? UDP? Que? – Fundamentals that were abstracted away from us by Hadi Hariri - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>TCP? UDP? Que? – Fundamentals that were abstracted away from us by Hadi Hariri</b></h2><h5 class="post__date">2015-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cTKQAe4DN6g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good midday thanks hello you guys who
know you have to show a little bit more
enthusiasm my talks actually I should be
the one cheering because I was really
really nervous that nobody would show up
to this talk because you know that the
title is like tcp/udp k okay in spanish
means like what and it's it's not a
really it's not like a topic that is of
much interest to people so since you've
all shown up I'm thankful and I want to
say thank you before the next slide
which I'll tell you what this talk is
about and then you can all leave so
getting to that what is this talk about
there's I I will promise you that in
this talk there will be no mention of
new JavaScript frameworks
there will be no no there will be no
talk about micro-services no rest all of
those will come in my talk tomorrow well
it was just the the silver bullet
syndrome this talk is actually getting
back to a little bit of basics it's kind
of like going back to school it's the
perfect talk that you can walk out and
say oh I didn't learn anything new I
knew it all kind of like thumbs up your
brain very smart but it's kind of going
back to explaining a little bit tcp/udp
what is the purpose of this talk well
first of all for you to understand a
little bit more about tcp/udp most
likely you will probably not end up
using anything specifically from this
talk unless you're writing your own
protocols but I find that it is
interesting to realize a little bit how
things work under the covers and then
understand why some things are moving in
certain directions and I'll loop that
back in with some of the aspects of HTTP
and in particular HTTP - how many of you
is using HTTP - or have heard of it so
you'll understand a little bit why
also the reason for HTTP two so I've
given you a disclaimer my only favor
from you is now you don't walk out and
you stay right you can sleep work
through whatever just don't walk out if
you do walk out still vote green okay
I'm serious right the network the is so
of the Aussie layers you're all familiar
with this physical Link Network
transport session presentation
application and the vast majority of our
life we've spent here right unless
you're doing any kind of like socket
programming or implementing protocols a
lot of the time that you're focusing on
it is spent on the application layer
mostly if you're doing HTTP programming
you're on the application layer writes
all of the web frameworks HTTP requests
responds all of that lives here but if
we go back down to this and we focus on
several of these we can see that each of
these actually has a different function
on top of that application layer so the
application layer you are all familiar
with HTTP SMTP pop all of the IMAP all
of these protocols are implemented there
TCP UDP that's the level below it and
that's kind of like the thing that is
moving all of those packets back and
forth all the segments then we have the
the the network layer which is the I I P
therefore TCP IP the link which routes
the datagrams and there's a
misconception sometimes UDP is user data
great Datagram but Datagram is actually
what's on the link level and then the
physical levels that move the bits so
our focus today is mainly on the
transport level we're going to kind of
will look a little bit about HTTP but
we're going to try and focus a little
bit more on the transport level and when
you start with communications basically
it's very simple I have a server on one
side I have a client on the other side I
have an IP everyone's familiar with IP
and the client talks to the server
server talks to the client an IP address
you're all familiar with it's composed
of four billion addresses and as of a
few weeks ago we officially ran out
right so there are no more public IP
addresses that's even despite that the
breakdown of our ipv4 address
which really don't have to know anything
about except this part over here the
32-bit sorcerer destination and this
data which we'll get to is that
fantastic take a screenshot of it now
the next step is where we're going which
is IP version 6 which I kind of tried to
fit in in the same way with the binaries
because you can't express it like that
we're going to have hexadecimal and then
there's notations for example if I want
to script
skip the zeroes if there's a lot of lock
blocks of zeroes I can just put colon
colon and so that's what we're gonna get
used to thank God for DNS s we don't
have to worry about that
the Datagram itself has also been a
little bit simplified so now we've got
128-bit and technically now every grain
of salt on the planet could have an IP
address so there is no limits to where
we can take the Internet of Things right
anything you can think of in your house
can now have IP address which is
fantastic because now we can get hacked
from every side now going back to this
communication of course there isn't a
one-to-one always like here I have a
client and then I have a 192 ending two
for two and then I have a two for five
but sometimes I actually have this two
for two two for two on the same machine
typical machines we have it web servers
SMTP servers pop servers all of those
and how is that kind of working so this
comes down to processes and sockets I
have processes on each point working
with each other and then the saw each
process is listening on a socket so on
the client side I have this process
called what they call multiplexing which
basically what it takes is all of the
different processes and all of the
different sockets gather that
information puts it on the wire sends it
to the other end and the other end does
what's called the modem multiplexing
which they deciphers that and allocates
the exact packets to specific different
end points to specific different
services and those services are pretty
much uniquely identified by a port which
is what the socket is constituted all
right so if we drill down to that data
block that I showed you in the IP
datagram what we have here is that data
is the gray part and inside that we have
a source port we have a desk
nation port we have options and then we
have the actual message so basically a
TCP UDP package is identified by a
source IP address a destination IP
address a source port and destination
port etc and that gray part as I said
drools back down to that data aspect on
the lower level of the IP for now you
already know that this kind of a pre
assigned port number so you have the 0
to 1023 which are basically reserved by
operating systems and well-known
services or 80 runs HTTP 443 is SSL etc
then we have another block of ports
which you can actually use for your
applications and you can register with
the Ayana
so if you go to the IANA list there's
actually application servers that lasts
and all of these different ones have
allocated ports and then there's a block
which is used for the client and server
for dynamic port allocation right and
that's the forty nine thousand one
hundred fifty two to the sixty five
thousand hopefully we won't run out of
ports and TCP and UDP can actually work
on the the same port number okay
and talking about TCP UDP those are the
main two protocols that we actually have
on the IP stack and the difference of
them is pretty much in this chart right
so you have from one side you have the
heavyweight TCP which provides you with
connection orientation provide you with
reliability ordering data flow
handshaking and we'll see what all of
these are in a minute transfer mode
basically means streams it doesn't
really have boundaries between messages
and then we have the UDP which does
nothing right UDP pretty much on top of
IP adds very little it just sends
individual packets and surprisingly it's
used quite frequently so TNS is using
UDP DHCP is using either BT FTP which is
an revile unreliable FTP protocol is
using UDP and it's actively used but you
know a lot of focus has been on on TCP
TCP transmission control protocol RFC
973 it's connection oriented that means
there's a virtual circuit it basically
from an end to end point there is a
connection that's going on it's reliable
in that it makes sure that when a packet
is
it arrives at the destination it
provides flow control it's full duplex
that means communication goes on both
ends messages are streams as I said so
there's no real boundaries but it's also
heavyweight and to give you an example
this is a Wireshark how many of you use
Wireshark okay so this is Wireshark and
this is a simple echo server all I do is
send a hello and I get a hello back look
at all the packets that are going
through right I have a bunch of packets
at the top then I have a few packets
that is actually the hello and then I
have a bunch of packets at the bottom
and all of that for a simple hello but
all of that is required because of the
way TCP is built but all of that also
impacts our applications and we'll see
why so to start with we have the
handshake right TCP has a handshake to
basically synchronize the client with
the server to make sure that moving
forward anything we do goes well right
it's reliable ordered etc I don't know
in Belgium you don't have it in in
Holland you have the three kisses kind
of thing right in Spain we have two
kisses and in Holland they have the
three kisses kind of the same thing so
here when I want to speak to someone I
first do send the sync that's the client
that's the server I send the sync then
it I receive an acknowledge the
acknowledge comes back and then it goes
back so the client sends is saying
they're sorry the server sends sync
acknowledge goes back and forth and I do
that three-way handshake so if we look
at this big interchange you can see that
there at the top all I'm doing first is
this three-way handshake and what that's
providing is a sequence number you you
can see now the sequence number is
actually random so it can be any number
it can start at 56,000 294 right the
important thing is that from that point
on it starts to increment by the number
of bytes that are being sent in the
payload and by the three-way handshake
initialization what Wireshark does by
default is basically set that to zero
but you can actually switch that option
off in Wireshark and say just show me
the real number so every time I open the
TCP connection what it's going to do is
do a three-way handshake and once it
does a three-way handshake then it's
stopped
to actually send information sometimes
it also does this thing called the TCP
window update which we'll get to in a
moment and then it starts to send this
information back and forth with this
sink ACK sink ack sink act which we'll
see as well and that just goes on and on
until it gets to the end and then it
tears it down and it kind of does a
three-way handshake for tearing down the
connection as well kind of like saying I
know that from this point on there's no
more data coming in okay so if we take a
look at a segment in detail you can say
this is each of those packets you can
see that there's basically a packet set
of a set of flags which are saying
what's going through so I have a
different set of flags and I have the
acknowledgement flag I have the sync
flag I have the push flag reset flag etc
and this is communicating what packets
correspond to a once coming back and
forth and what what what makes TCP
reliable how does it actually implement
reliability so this is a one-way imagine
that this is was a single direction
we'll see how it does it is in full
duplex if you were to do it like a naive
implementation of reliability what you
could do is you can send the sequence of
packets so here I say I set my sequence
number to one and I send two bytes the
server now acknowledges and says okay
I've received three bytes so it sends
back the sequence number plus the number
of bytes it's received so sequence
number was one received two bytes sends
back three now the client now sends the
sequence number that it has plus new
bytes so in this case eight and the
server would send back acknowledgement
11 right and this is a single way
reliability implementation in TCP
basically every time I send the packet I
gonna make acknowledge the bytes I've
received and send that back
now since TCP is full duplex it's trying
to do this in both directions and the
way it does it is pretty much similar
but it like piggy backs off of the data
that is sending back and you can see
like the sequence and acknowledgments
are inverting their role so here I have
the same client server and then I have a
sequence one
acknowledgment 10 for instance I sent
two bytes so now the acknowledgement
comes back as three the sequence comes
back as ten right and then I send four
bytes so now the sequence comes back as
seven because four plus the previous
three seven the acknowledgement comes
back at twelve so this way it's allowing
to do full duplex bi-directional
reliable communication and to not make
the overhead higher off for each data
send back and acknowledge what it does
is use piggybacking so basically on the
data load is sending back the
acknowledgement so if you see that for
instance again in the diagram you can
see that there is the push while the
push I'll get to the axe sink going back
and forth in both directions and what is
this push because this psh appears quite
often so this is actually a screenshot
of telnet right this is a telnet
application I've done a sniffing and
what you can see here is that every time
I basically type a character it's
sending it through and it's sending this
push flag and what the push flag is
basically saying is push that up to the
higher level right so as a telnet
application when I want to type
something I want to make sure that the
receiving end is basically seeing that
and it's not seeing it in chunks of data
so what it does is basically push that
value up to the upper level in this case
the application level that takes care of
it so that's what the push exactly
stands for but you can see that in
certain cases that's not recommendable
because sometimes I don't want to
constantly send back exactly what I have
I want to let the buffer fill up and
then send back for instance if I'm
sending back a stream of data a file or
whatever I don't want to continuously
have that push so you can also you know
the TCP is capable of doing that as well
in this sequence you see that I'm
streaming a file so you can see that
there's a lot of acknowledgments and
then there's only a single push when a
certain amount of buffer has been filled
up okay now that's in terms of
reliability but there are other aspects
that that come in to come in to problems
with the network
one of them is flow control and
congestion so if I have if I have one
server here and I have one client here
and these two machines are talking I can
basically say okay I have I can send you
a hundred bytes and this hundred bytes
goes from the clients of the server
great the server can do the processing
it's fantastic and then I say ok 100
bytes you can cope with let's try and
send 500 bytes okay 500 bytes I can cope
with at some point what happens though
is that the server can maybe not cope
with the processing and when that
happens it starts to drop bytes because
it says I can't cope with this so the
buffer fills up and it starts to drop
bytes if that happens since TCP is a
reliable protocol what it has to do is
again send the same bytes in order to
prevent that there's a thing called flow
control which basically allows you to
adjust exact amount of bytes you want to
send over without losing bytes and
without congesting the other end and
that's when I have the situation of two
machines point to point if you look at
the internet between the internet we
have like you know if I want to talk to
a server that's way over there in the US
for instance I have routers switches not
all bunch of things in between and each
of these have their own implementations
of IP each of them have their own buffer
implementations all of these are going
to affect the flow of information going
back and forth so that's where the
natural algorithm that you've heard of
comes in which is basically allowing you
to control the flow of information and
what's that done that's done by
basically saying Windows Update so I set
a window update and I say that's
basically the buffer size that's the
amount of information I consent if I see
that things are going well then I start
to increment that window and increase
the size and that's what is called in
tcp slow-start so slow start starts with
a single window a small window and
gradually it starts to increment the
size of the window okay now of course
that is great but at the same times it
has problems because we know that every
time I start a TCP connection if I want
to stream a lot of data
for example it's gonna still start slow
but it's okay if I'm streaming a file
it's fine because eventually you'll get
to that optimum point and then you'll
start to stream that file nicely but
take a look at for example typical
protocol on which we use HD TCP which is
HTTP HTTP has lot of small requests for
files and each of these think about it
so far what is it doing it's doing a
handshake it's establishing connection
it's doing the three-way handshake it's
sending a whole bunch of acknowledgments
for reliability is setting a window
update and it's finishing so look at the
overhead the TCP is adding to http right
in addition TCP gives us one other thing
which is fantastic but also contributes
negatively to http which is head-of-line
blocking which basically means if I want
to make sure that the upper application
level doesn't have to worry about
packets coming in out of sync out of
order I gotta take care of that and that
effectively means that if one packet is
lost I can't continue I gotta wait until
that packet is sent again and then
continue right and that negatively
impacts HTTP so you're all familiar with
the concept of bandwidth and latency
right yes bandwidth is how wide my
street is latency is where I have to go
right so you know if I mean if I'm in I
gotta run 12 kilometer walk drive tall I
never run 12 kilometers right so latency
is limited by what speed of sound no
that was a trick question
no it's limited by speed of light and
until someone breaks that latency is
basically limited by speed of light so
that means that the fastest I can go in
an optimum vacuum is how fast light can
go over a fiber optics line right now we
don't have that vacuum and when we're
going from one point to another point
there could be thousands of factors in
between what does that translate in in
that if I'm four
in here in Belgium and I want to ping
somewhere in the US it can take up to
200 milliseconds right now before I
continue I'm on a moment of silence and
I want that to sink in it will take 200
milliseconds to travel 8,000 kilometers
okay sunken okay great
apparently that's an issue right that's
why people are complaining that you know
if I go to a website and it takes more
than one second for me to get my
products I won't use that website and
I'll go to the competitor right do you
do that does that happen to you in Spain
I don't do that because I have no choice
right it's it's slow and there's only
one person that sells so but
realistically we have reached our point
where for us 200 milliseconds is too
slow well okay but the issue with that
isn't the bandwidth the issue is the
latency if you take a look at the HTTP
protocol what that is doing is every
time an typical website is creating
multiple requests to multiple different
resources each of those requests are
traveling on TCP each of those TCP
connections is opening up a new
connection it's doing the three-way
handshake it's implementing reliability
flow control all of these things it's
closing the connection right all of that
adds issues it adds latency because I
have hundreds of different connections
going out here's a chart which basically
shows you bandwidth versus latency on
page load times on HTTP you can see that
at some point it doesn't matter how much
bandwidth I have it's not going to
impact the speed and load time all right
if you take a typical look at at HP HTTP
connection you can see that the
breakdown is queueing DNS lookup request
sent and here you can see that the
content downloaded is 0.84 milliseconds
that excuse me and the overall time is
355 milliseconds now again this is at
the HTTP level right take a typical web
page and you get the water flow down a
waterfall diagram how many of you use
this site it's called web page 10
which is fantastic he goes and it shows
you all of the waterfall of loading of
the application of the webpage and then
the cached version etc and you can see
this waterfall effect and all of this is
consequence of TCP its consequence of
head-of-line blocking its consequence of
three-way handshake its consequence of
the implementation of reliability all of
these are contributing to the slow
response times and what HTTP 2 provides
and what speedy provided which is what
HTTP 2 is built on is ways to overcome
this by creating a multiplex stream
which basically means now I have a
single connections which means I no
longer have to open up multiple
connections etc so to summarize HTTP 2
is about performance but it's about
performance trying to overcome the
limitations of TCP not HTTP 1 point X
protocol because semantically HTTP 2 is
basically the same as HTTP 1 there is no
difference in the semantics it still get
post put etc well there's a server push
but in terms of verbs headers bodies all
of those are the same the focus of HTTP
2 has been about trying to improve the
performance because of the underlying
issues of TCP because TCP was never
built for HTTP ok so now you know why
HTTP 2 and by the way who is using HTTP
2 nobody who's using Twitter so you're
using HTTP 2 a lot of sites are actually
using HTTP 2 under the covers obviously
the difference between speedy which is
now being deprecated and HTTP 2 is HTTP
2 opens up a whole new world for us
because at the same time that it fixes
these issues it provides flow control
window well flow control and the server
window regulation priorities all of
these it brings it up a level and gives
us an API in order to play with it
effectively meaning in three years we'll
probably
talks at conferences saying how to not
shoot yourself in the foot with http/2
because we're very good at that okay so
that's what TCP is those are some of the
issues that TCP have and working with
TCP how many of you actually make socket
connections like socket work directly
with sockets okay for those of you that
don't I'll show you very quick a couple
of quick samples it's very very simple
so here I have you can see my screen I
can see it there let me take my mouse
over so here I have it's very simple
right so I create a server socket here
what I'm doing is basically creating
actually I start with something very
simple over here a discard server and
basically discard server is the simplest
implementation of a protocol I send it
something that it ignores me kind of
like my children and serve a socket I
set the port
I set the the number of connections it's
going to accept all the number of
connections it's going to queue and I'll
tell you that in a second the address
binding if I want to bind it to a
specific port because when I pee because
remember you can have multiple sockets
open on the same port but on different
IPS on the same physical machine and
then what I do is I basically say now
accept connections when someone when a
telnet ping connects to that it's going
to return a socket connection and then
I'm going to just process that socket
connection and here what I'm doing is
just reading the input checking to see
if it's not a blank line if it is read
if it isn't or read the line and do
nothing pretty much ok if we go back
here what happens is that basically if
you run this this is going to accept a
single connection as soon as the telnet
closes it's going to die
very very very pointless in useless and
that's not how you do it in production
so here is a single run symbols single
server so what this is doing is
basically an echo now I send it a
message and it just sends the message
back but again the product the problem
here is that if you run this it's going
to accept the single connection and it's
going to process that client so again
this is not what you do
normally what you do when you set up a
TCP server is
provide a threaded model so basically
every socket has its own thread which is
in this case over here which is exactly
the same as the previous example the
only difference is that I'm launching
this process client in its own thread so
now I allocate a net a thread to a
specific client and it goes off and
handles that connection
right and that is absolutely fantastic
and it's great and the accept header
here tells me how many connections I can
q basically so the accept header the
accept call is cuing x number of
connections which is defined on the
server socket here so what that means is
that if 300 clients try and connect it's
not going to let them if 10 connect it's
going to let them the 11th one is going
to drop until one of the clients
disappear so it allows you to queue up
connections now that has also its issues
right if we go back here you have this
thing that a lot of people have been
talking about which is threading versus
event loops now how many of you are
familiar with nodejs right so in a
typical threaded model which I've just
shown you basically get a request and
then what happens is that you get a
bunch of threads and each thread is
basically handling that request okay so
the thread is coming in I'm allocating
that client to that thread I go off and
I do my stuff this is a typical threaded
model in an event loop model what I have
is something a little bit different what
I have here is an event loop that
requests are coming in so it's a single
loop it's a single threaded model in a
sense it's just looping over getting new
requests and then it's delegating
long-running requests to what it's
called worker threads there's a there's
a the worker threads go off and do the
work and then when the when the work is
done it it does a callback this is
typical nodejs and there's a common
misconception in that this is single
threaded it's not it's not magic the
difference is that is delegating that
threading work outside of your scope
so it's handling all the niño the older
i/o in our in an honest inquiry cetera
right no
kind of implements that charts that show
you comparisons which always favor the
person producing the chart show you that
like Ingenix versus Apache that uses the
threaded model right so the number of
requests per second versus the
concurrent connections that you can get
and then if you do performance
comparisons in terms of memory it also
shows you that well this is actually
much more effective because you're
letting the underlying framework library
whatever you're using handle the actual
threading model for you if you're in
Java don't worry you don't have to go to
to no js' to take advantage of this
there's another technology in Java
called nettie which basically does the
same thing right the difference is that
of course when you use something like
neti the programming model is somewhat
different so here I have a sim single
TCP server setting neti up is the best
thing to do is just like collapse that
and then that's you set up once but
basically I'm running events so it's
more like an event model
I just read write do whatever
connect/disconnect so pretty much when
you're doing net C programming in Java
you're going to be implementing
different event handlers okay but that
provides that takes care of the NI over
under the covers and all the threading
so that's a little bit in terms of TCP
and of course protocols that you can
that are built on top of TCP so you have
HTTP 1.1 which is very simple it's a
text protocol request response HTTP 2 is
by the way binary it's not text and if
you're wondering how binary protocol
works on top of text protocol it's
called TLS right so it's basically
creating a point-to-point and it's using
TLS to provide this compatibility in a
sense it can work with non TLS but by
default basically everyone's going to be
using TLS so that's the typical example
of HTTP IMAP very simple
it's all based on text ice the server
says okay I'm app server version 1.1 you
send the text login use a pass it
responds you pass that response you send
more information you parse our response
and most of the protocols nowadays that
we're using pop IMAP SMTP all of those
are text based protocols now you can
obviously roll your own and in fact I've
in my past life when I was young I
implemented a bunch of these protocols
and I also rolled my own protocols and
it was fantastic because you just
created this text protocol that only you
and whoever was talking to you needed to
know and you rolled your own you don't
necessarily have to build on top of HTTP
if you want a very simple protocol you
can just do a text-based protocol and
get rid of the overhead of HTTP however
I would recommend nowadays that if you
really treat HTTP as what it is which is
an application protocol it's worth
probably building on top of that whether
or not you do rest so first of all make
sure obviously your protocol doesn't
exist define it unambiguously between
the two parties and text is very simple
but at the same time it's very hard
because text protocols aren't easiest to
parse or efficient to pass as binary
protocols right you can have a lot of
bad characters in there then you have
the base encoding that if you want to
send binary you've got a base64 encoded
etc so it's not the easiest thing in the
world either so what are the benefits of
TCP it provides you a reliable
connection it has low overhead over high
level protocols and it provides you with
a persistent connection so when to use
it and I put a little star in terms of
reliability is crucial right because you
don't need TCP for reliability you can
actually create reliable protocols using
UDP but TCP reliability isn't simple and
the algorithms implemented aren't simple
so don't reinvent the wheel you know in
essence if UDP which we'll see in a
minute if you want to go full-blown and
start to create your own reliable
protocol on UDP really consider what
value you're adding over what's already
available on TCP but you have to take
into account all of the overhead that
TCP is adding and of course have this
concept of a connection do I need a
persistent connection do I need a long
live in connection because HTTP is a
typical example where the protocol
wasn't effectively well built on top of
TCP and in fact it was only until HTTP
1.0 when we had persistent connections
did we gain some performance because up
2-0 0.9 HTTP every request opened and
closed the TCP connection so I was in
1.0 and then it was back 40 and sorry
1.1 and back four there was one point
out UDP the Forgotten kid user Datagram
protocol again RFC go look it up read it
fantastic read bedtime reading
connectionless so if you don't want
connection that's your that's your thing
there's no reliability there's no
ordering there's no congestion control
but it's lightweight so it takes
everything away and it says here you
don't get anything but I'm really fast
if you take a look at a message here is
basically that same echo server right I
send a hello I get back hello two
packets okay two packets the cert the
packets however contain something
important which is the actual end point
the client end point server end point
are all self contained in that packet so
what that means is that when I send a
packet from a client to the server the
server receives our packet but there's
no connection
therefore how does it know where to go
how does it know if it needs to respond
how to respond that information is
contained in the actual packet right so
it has the source IP and the source port
and it knows how to send information
back but it's part of a different data
gram packet the difference of course
here is that if that data packet is lost
well it's gone I don't know anything
about it so if you take a look at
some code here we can see that this is a
simple time server you can easily
identify what's happening here so I
create a Datagram socket which is the
equivalent of a UDP packet and I
basically assign it a buffer etc and
then I read some data here and then from
that data from that packet that's coming
in I actually get the address and the
port and that is what I use to if I want
to respond to that request right so
under the covers you need to now get
access to the port and IP because you no
longer have this connection that's been
open and you can just send back and
forth packets each one is its own
independent request response kind of
thing now before I explain one broadcast
everyone's familiar with networks and
subnets right so I've got a network
which is the first three blocks and then
I've got the host and then I have the
subnets versus the network and then you
can get the subnet mask by bitwise in
that and that gives you the network with
the host and what this basically means
is that if I have two blocks of machines
if I have a bunch of machines on this
side on the network 192 168 three-point
X and then I have one and two 165 point
X these are on two different networks
and in between I have a router or a
router and what the roots are does is
route packets between different networks
so there's one problem right now is that
first of all most routers implement NAT
right network address translations which
basically allows a single company for
instance not to have you know all of us
don't necessarily need to have a public
IP address given that the public IP
addresses are limited we had not which
kind of resolved it now that works fine
with TCP with UDP though there's a
problem because there is no virtual
circuit so how the hell do I know when
to open a connection when to close a
connection when is it done and there's
techniques and algorithms that kind of
implement that and
basically to boil it down all routers
contain a UDP address translation which
basically is a temporary table that
map's incoming and outgoing UDP packets
and holds on to them for a while so that
it knows how to route it to a proper
machine inside the network
now sometimes UDP what's very good for
is the ability to broadcast so with TCP
what I'm doing is I'm creating a
point-to-point connection UDP is very
useful for when I want to do a broadcast
for example I want to broadcast messages
to all the hosts within a single network
and that's what UDP is very good for it
which is called broadcasting now the
problem is that broadcasting won't work
across routers right so you can't really
get that to work across browsers the
broadcast address is basically a bitwise
or of a big compliment of subnet mask
and IP which basically means that I send
it to the if that's my rock if that's my
network that's my net the net mask the
broadcast address is dot 255 and that
effectively means that anyone on that
network can potentially receive that UDP
packet and we see when you can use these
things multi casting that's somewhat
different to broadcasting in that I can
have nodes having to subscribe to a
specific point and then that point kind
of broadcasting things out so this can
cross network borders and it's very good
for low bandwidth high demand basically
video streaming so basically what it
does you stream to a single machine and
that multicast it out to multiple
machines something again you can use UDP
for now what are the benefits of UDP
lower overhead I have eight bytes versus
20 bytes basically no connection makes
it much faster I don't have the 3-way
handshake to set up I don't have the
3-way handshake to teardown not having
reliability makes it faster I don't have
to acknowledge your package however I
lose the reliability right which
effectively means that if I want to use
UDP I have to provide you reliability at
the application level which means that
if I want our
reliable system I need to implement it
myself
so I gain the fastness but I lose
reliability now having said that UDP is
commonly used in fact for instance in
the stock market a lot of financial
companies use UDP to broadcast the stock
prices etc why because maybe a lost of
one packet doesn't really matter because
it's and the next one is going to come
one millisecond after so you really have
to equate the balance of if it's okay
for me to lose a packet what you cannot
what you shouldn't really do is say you
know what I'm gonna reinvent TCP on top
of UDP because most likely you'll end up
with a smaller a slower protocol than
you would if you just use TCP out of the
box when to use it when speed over
reliability is required and again a
little star because it can be somewhat
reliable if you're streaming video and
you lose five packets no one's going to
notice it's not going to notice so video
and audio streaming self-contained kind
of protocols that are like simple
packages coming back and forth and
discovery services very typical
application use of this is for example
licensing servers most Licensing Service
Center UDP packages to find out you know
what applications are on the network or
on the network which ones are you know
what applications are instantiated what
are being used etc when you don't know
who to contact if you want to contact
the server but you don't know the IP
address you can use bruhh broadcasting
to kind of make that discoverable on the
actual network
so what else when you're doing this kind
of thing there's a whole bunch of tools
which are very very useful Wireshark
and if you're on OS X now in 1.99 it's
no longer required to have x11
and quartz you can just launch it up and
it works and it's got somewhat of a
nicer interface so Wireshark is
fantastic it's also very beneficial if
you're doing any kind of if you start to
look at HTTP to wash our work Wireshark
works well with that it already has
support for HTTP two and it basically
the same way as when you're trying to
use white shark with TLS you just
pointed to an SSL key lock there's blog
posts and instructions on how to send
this up on the Wireshark but you can use
that for HTTP to other protocol
tools obviously there's telnet for any
kind of text protocol is a very good
client when you want to basically test
your server implementations because it's
the chicken-and-egg problem right which
one do i implement first the server
protocol or the client protocol server
and then test with the telnet and then
do the client NC which is kind of like
telnet for UDP netstat and route which
allows you to examine connections and
routing information postman fiddler if
you're using IntelliJ or any of our
tools you've got basically got a test
restful web service which allows you to
also do any kind of testing for HTTP
protocols and Nagios for monitoring etc
so to summarize basically abstractions
are good and it's really great that
pretty much we don't have to deal with
any of this really most of the work that
we're doing is basically at the
application level where most of our web
applications right now whether we're
doing actual web user interfaces or
we're doing a endpoints they're all
built on HTTP however I find that it
really does provide value to understand
what is going on under the covers and
when does it make sense to optimize when
does it make sense to tweak things okay
in fact if you look at as web developers
if you are web developers you've done a
whole bunch of optimizations in your
life right you've done domain sharding
to open up multiple connections to try
and get page load times faster you've
done script concatenations you've done
what is another thing spriting how many
are familiar with spriting right which
is basically before you had a single
image now you have one big image that
contains all of your images and then you
spend a good six days trying to use CSS
to tweak it and place the exact images
all of these da are done not because of
the shortcomings of HTTP as much as the
shortcomings of the underlying protocol
which is TCP all right and why because
of all of these things that are going on
under the covers fortunately with HTTP
- a lot of these issues are resolved
unfortunately for you all of the
optimizations that you have done you're
going to basically have to undo okay but
it's good it keeps us in business right
so really you know it's more this
session was more about just
understanding a little bit what's under
the covers and of course if you're doing
any kind of TCP programming or socket
programming know that you've got
extensive API is available on the JVM
and nettie especially is very good and I
said I want to mention
micro services but you can use this for
micro services too okay
so thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>