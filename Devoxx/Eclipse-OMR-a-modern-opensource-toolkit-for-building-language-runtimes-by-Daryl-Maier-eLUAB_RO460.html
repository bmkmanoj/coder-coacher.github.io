<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Eclipse OMR: a modern, open-source toolkit for building language runtimes by Daryl Maier | Coder Coacher - Coaching Coders</title><meta content="Eclipse OMR: a modern, open-source toolkit for building language runtimes by Daryl Maier - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Eclipse OMR: a modern, open-source toolkit for building language runtimes by Daryl Maier</b></h2><h5 class="post__date">2017-04-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eLUAB_RO460" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay welcome everyone this is a clip
Solimar a modern open-source toolkit for
building language runtimes my name is
Darrell Mayer I'm from the IBM runtimes
group at IBM Canada I've been doing
compiler development for about 20 years
now and my career at IBM some fairly
propellerhead stuff I think been working
on HPC the last 15 years I've been
working on dynamic compiler for Java so
as part of the j9 java virtual machine
recently we spent about 3 years taking a
lot of that technology and open sourcing
it and these days I'm working on you
know trying to get that technology used
outside of Java and into other language
environments so I'll be talking a bit
about that today first of all the
standard because I work for IBM I have
to have some disclaimers that they can
disavow anything that I say so today
what I'd like to do is to take you
through the eclipse of our project what
it's about what's like but it's what its
goals are you know what its origins are
and you know where it's where it's
really going I like to show you what's
been contributed so far and some of the
technologies that are already out there
that are that are consuming it and what
are the some of the future directions of
where this is going and perhaps most
importantly where and how you guys can
get involved so I'm gonna cut right to
the chase and just say that the Eclipse
Ammar project was created about a year
ago in March it just had its first
birthday and what eclipse Omar really is
is an open-source project that provides
language agnostic parts that you can use
to integrate into into language runtime
so you can use these things to
supplement your runtime so for example
it would probably provide technology
like GC technology or compiler
technology or threading technology that
sort of thing
we have a logo we have a color scheme so
you know you know it's got to be an
official project
the code is all available on github we
try to make it as consumable as possible
in different environments so it's got to
do a license so EPL v1 and Apache 2.0
and you know what contributions are very
much encouraged and like many as many
people as possible to get involved with
that if you're interested
so before anyone asks and perhaps the
most common question we get is what alum
are actually stands for it actually
doesn't stand for anything because it's
not an acronym when we started this work
about five years ago the intention was
to call up the open managed runtime but
as it turns out as this technology is
actually as we got into this project it
turned out that it's actually not a
managed runtime it's actually different
than that it's really just a collection
of components that you integrate but
over that time the you know the acronym
kind of persisted throughout the
codebase and in people's vocabulary and
it's really hard to change that and
coming up with another name is very very
difficult
so it's stuck and then the other most
common question we get is what does this
have to do with the Eclipse IDE and the
answer is nothing because it's really
just a project of the Eclipse Foundation
and it has no association at all with
the Eclipse IDE so a bit of background
on on where this where this came from
and and why it's why it's come to be so
when we talk about language runtimes you
know we really want to understand sort
of what what the different parts are
that make up a typical language runtime
and if we focus on something like Java
for example in a typical Java execution
environment it really looks something
like this with all the you know from
from a very high level if you look at
all the pieces from a developer point of
view you typically start with a Java
source and it gets compiled down with
Java C into some sort of bytecode
representation and then that bytecode
representation is executed on a bytecode
interpreter that follows the the java vm
specification
part of doing that it you know the new
Java does have a memory model it does
make requirements about the lifetime of
objects and manage memory and that sort
of thing so Java typically has some sort
of garbage collection technology built
into it as well
Java is also a write once run anywhere
technology so in order to handle that
you have to have for you would usually
expect to find some sort of a
abstraction layer that sits between your
your virtual machine and then the
underlying operating system or the
underlying hardware that it's that it's
running on and then you know most modern
JVMs these days do require some kind of
compilation technology to translate byte
codes directly into some sort of native
instructions in an optimal way and then
execute that you pretty much have to
have that in order to get any sort of
decent performance these days out of
Java and also things don't always go
right so you tend to have tend to
require some kind of diagnostic and
tooling hooks into your into your into
your runtime to be able to help you
debug your application or in the worst
case if there's something wrong with
your VM you need some technology there
to help you out so if you look at Ruby
now instead of Java and you're doing
this from a very high level as well
you're going to start to see start a lot
of the same kind of components here so
you mean even though things are
implemented a lot differently the the
components look more or less the same so
you do start with a ruby source it gets
translated down to some sort of Ruby
instructions that get executed in some
kind of a bytecode loop within Ruby you
know it does have the notion of you know
managed memory and an object lifetimes
and that sort of thing so you do need
some kind of garbage collection
technology to take care of that for you
it does run on multiple platforms as
well so you need some way of abstracting
what your VM is doing from running on
the different targets that you they you
care about and again you you may have
some some you would expect to find some
some diagnostic
capabilities built on top of it as well
jets are not necessarily a requirement
for Ruby you know there's certainly some
schools of thought that think that comp
compiled code is where you're going to
get a lot of performance we're actually
one of those schools or IBM is one of
those schools but you know what you
would find in some Ruby implementations
these days is not a JIT compiler so it's
a bit optional so that was Ruby a lot of
similar things with Java and you can do
the same kind of argument with with
JavaScript as well you're going to see a
lot of the same kind of components if
you look at look at something like that
so so even though there are a lot of
similarities between these different
language environments what you tend to
find is that because each of these
language environments has been developed
completely independent of one another
they're going to have very different
implementations for all those different
components so what that really means is
that you know if you're going to make a
significant contribution to the compiler
technology in under that underpins Java
and you're adding some cool RDMA support
or you're adding some Sindhi support or
GPU support something like that that
effort that you took to put it into Java
is not going to carry over into any of
these other languages or language
environments you're going to have to go
through the effort of re-implementing
this for Python or Lua or Ruby or
something like that you're going to have
to walk around all those different
languages and do the same thing which
isn't a great way of proceeding so the
point being that you know any investment
that you make in one of these runtimes
isn't necessarily going to carry over to
any of the other ones and this is
particularly important as we start to
move things on to the cloud so a lot of
these languages underpin the cloud and
this is particularly important there and
the reason is that cloud platforms are
really built on runtimes
so a lot of the applications that are
running the clouds that are making the
cloud you know what it really is are
built on on different language
environments so all the things that make
a cloud a cloud the resiliency the
security the efficiency the elasticity
you know consistency all those things
are there because of the applications
that are that have been implemented
there and what that means is that the
way that clouds can actually grow is by
their underlying languages so you know
the more kind of features you can get
into those languages that build the
cloud you know the better off you're
going to be and the way that the clouds
can actually advance so having a lot of
different language environments that
each grow at different rates is really
going to hurt the development of of the
cloud so it's something that you know
would be great to be addressed and
that's where the Eclipse omr project
kind of came into being so you know the
the the mission of the Eclipse omar
project is really to build an open
reusable language runtime foundation for
the cloud and it's got a number of you
know tenets toward that yeah you know
the first is really to really embrace
really address those issues of you know
having different components across all
these things but by really having you
know sort of a common place where you
can go and invest in in this kind of
technology and you know you do all your
work in one place and it can sort of
naturally be consumed by all these
different environments so it's really
sort of a place where you can go and
innovate and then they can be picked up
by by by different components so it's
going to help accelerate cloud platform
development the other thing is that it's
going to be done in full cooperation
with the language communities that are
out there so a lot of languages that we
talk about they've been around for a
while and they have some fairly well
established communities built around
them they have their own processes their
have their own way of working they have
their own you know extensions things
like that that they built into their
environments and the intention of this
is not to be very disruptive in all
those environments really it's really to
work with those communities in order to
get this kind of technology integrated
and the other thing is that there are a
lot of different like where you find a
lot of innovation in and
which runtimes comes from a variety of
different places these are like
corporate developers these are you know
researchers and universities and
colleges they're students there's guys
in basements that are working on hobby
projects that all have great ideas that
they want to want to contribute but what
they tend to do is to sort of focus on
one of their pet languages and and put
the technology in there so what this
would enable them to do is to really you
know contribute at a very common place
and that that you know and get that
investment you know deployed more
broadly so I mean that's you know a
great idea
but it would require a fair bit of you
know capital to get going on that right
you you really need to have all these
different runtime pieces in place in
order to really start to make this
happen so where would all those pieces
come from are we starting from scratch
or what are we gonna do
well when IBM thought about this a few
years ago you know what we had at that
time was a very mature very stable very
high-performing runtime system for Java
and we decided to start there and see if
we could look at that and understand if
whether or not there's parts of that
that we can actually make specific to
Java but there's also parts that we can
make language agnostic as well so we
weren't quite sure how much we could do
in other direction but we but we did
take a look at it so again standing back
and looking at the the high level of the
runtime system you know you tend to see
all these different components similar
to what we saw before but when we did
start going through each of these things
we did figure out there's there's
actually quite a bit of the code that
you can actually isolate into a language
agnostic bit and then push all the Java
bits down into their own kind of glue
layer so what we decided to do was to go
around to all these different parts that
make up a runtime system and then start
to do that separation and the language
agnostic bits really did become the
basis of what was contributed to the
Eclipse om our project to start with so
now as part of this project it does have
a number of you know sort of goals so
the first is that it doesn't have any of
the components in this in this toolkit
does not have any language semantics so
it doesn't favor one implementation or
one language environment or another so
for example it doesn't favor Java it
doesn't force you know if you're writing
something in Lua it doesn't force you to
have to obey you know Java language
semantics in order to implement
something for Lua so the intention is to
make this as clean as possible it's also
not a language runtime which is what
I've said before it's it's very much a
toolkit that for a particular language
or for a particular environment for your
particular needs you go around and you
sort of pick and choose the parts that
you want if you don't want if you just
want the garbage collection technology
you can just go out and take that and
assemble that into your runtime if you
don't care about JIT technology for
example and the other thing is that it
should actually be fairly easy to
integrate this technology into any
language runtime and you know this could
be a new toy language that you're
working on it could be you know
something that's been out there for 30
years or so that's really the goal there
and the other thing is about it doesn't
actually influence the language
semantics right so I talked abut I
talked earlier about the the working
with the communities the intention here
is not to cause a lot of these language
communities to change their code to
adapt to this technology it should
really be the other way around this
technology should be flexible enough to
sort of bend to the needs of those
particular environments so that's what
we did so we did actually go about and
you know take all those different
components we isolated the the language
agnostic bits of it we can truly created
an eclipse om our project push it out
the door like I said it's been out there
for about a month for about a year now
the rate of contributions has actually
been fairly healthy it's it's doing
quite well I would say that on average
we're getting about five to ten commits
a day and it's so it's it's really only
sort of taking off from from here
that's great to see so just looking a
little bit under the covers
into what is what has been contributed
so far so it's a fairly diverse set of
of technologies that you can use to
integrate into different runtimes so I
talked before about the platform
abstraction layer so we do have
technology for isolating you know for
for building that abstraction between
your runtime and the underlying
operating system or architecture so
that's like the port layer the thread
layer some VM technologies as well
there's a you know world-class garbage
collection technology that's been out
there
same thing for compiler technology as
well there's something called JIT
builder which is a simplified interface
to the two to two enabling the compiler
technology in a particular runtime there
are components to help you get
information out of your runtime and into
a need to some sort of a format where
you can actually attach tools and things
like that - it's for for doing
diagnostic work and there's a sort of a
unit testing framework that's being
developed as well that allows you to
test the different parts of the code
that you actually want to contribute so
so far to date there's probably around
800 thousand lines of code I would say
that that is growing fairly steadily
every so often because there's more and
more technology being being contributed
to this all the time I do want to drill
into a little bit deeper into a couple
of the technologies that we do have in
the box so these are some of the ones
that that different language communities
are particularly interested in so the
first is some of the garbage collection
technology that we have so I said before
that the origin a lot of this was the j9
java virtual machine and you know the
the GC technology that was developed
there has been developed you know from
for many many years it you know it had
really matured out in the field and it
really does support it is really well it
is a world-class garbage collection
techno
so it does all the things that you would
expect a GC to do these days so it's
very parallel it's very scalable Java
had some very specific requirements of
being able to run on very small devices
like watches up to very large servers
very large clusters things like that so
it had to scale very well so it does
that it understands multiple cores it
understands threads it understands Numa
topologies things like that so it does
all those all those things and it's fast
too so with that as a starting point you
know the one of the most basic things
that you can do is this sort of hook up
a mark Street garbage collection you
know technology and there's been a few
projects that have done this already and
I would say that for the most part it's
been it usually requires less than 100
lines of code to make that connection so
it's a pretty good consume ability story
to begin with and then depending on what
your needs are you can start adding more
and more advanced GC technology to that
as well so you can add compaction for
example if you want to reduce
fragmentation in your heap you can add a
nursery if you want to add some
generational capabilities and if you
want your GC to run in parallel with
your with your application you can or
concurrently with your application you
can add you know there's support there
for concurrent GC as well so a lot of
really good things there to to get your
GC going just to give you because it is
one of the central pieces of a lot of
this technology just to make sure that
everybody understands what Marc suite GC
is and what it can do so what this
really means is that periodically the
application threat the threads in your
application or the thread if your if
your VM doesn't support threads will
have to stop and then you try to find
out what objects are live by starting
with these route sets which are
typically like global variables or
statics or the thread stacks and from
there you try to figure out what what
objects do you happen to see and when
you see an object which means it's
reachable you mark it as you mark it as
live and then once that's done you have
this sweep phase that basically goes
through and finds anything that hasn't
been marked and mr.
sweeps it away and then reclaims that
memory so and then the threads restart
and you can carry on so fairly really
simple idea there and then hooking this
up to a runtime is actually fairly
simple I don't really want to show code
but I just want to sort of talk about
concepts you do require some kind of
initialization you do need to be able to
describe what your objects look like and
and how they're laid out you need to be
able to provide some kind of
functionality for allocating these
objects and getting them initialized
when you create them you need to be able
to poke the GC to tell it that you need
to do a collection and then you know
configuring your heap and and then
tearing it down is also important as
well so like I said this is all part of
the less than hundred lines that you may
need to get this integrated so a good
consuming story
another thing that's that's in the box
is the compiler technology so this is
another popular you know bit of another
popular component that's that's often
integrated into different environments
so like the GC technology its history
has like the this compiler technology
has been developed a croffer for many
many years the interesting about
interesting thing about this though is
that it did come from
it was developed initially as a dynamic
JIT right so it didn't actually start as
a static compiler it did start so a lot
of the things that it had to solve early
on were intended to be solved in a
dynamic environment which is which is
really good for for runtimes these days
but having said that though over the
years it has proven its flexibility
buying it by being able to run but by
being able to produce static comp
compilers and binary tree binary
translators and stuff like that so it is
a fairly flexible piece of technology it
is a cleanroom implementation so it was
developed completely from scratch
without any IP from anywhere else you
know written in C++ and like I said
owing to its embedded heritage its
design goals were to you know have
really fast startup time
really fast compile-time it's very
strict on memory management a lot of
things are very tightly controlled but
on the other hand it can actually be
very flexible right so if you happen to
be if you happen to be running on a very
small device you can configure it to use
very little scratch memory and therefore
you may be hurting some of you some of
the performance you might be getting out
of it but if you're running in a very
large system you have a lot of scratch
memory you can widen that and perhaps
get more performance out of it it does
have the kinds of optimizations that you
would expect any modern optimizer to
have so a lot of high-level
optimizations you know classical stuff
loop optimizations dataflow speculative
controls low that kind of thing it
generates code and does deep platform
exploitation for a variety of different
platforms so it does this sort of
traditional x86 it does 32-bit arm but
you know unlike some other systems it
does handle power and system Z as well
so it's got a fairly wide base there it
does do dynamic recompilation so with
with with profile directed feedback so
this is really where a lot of the
performance out of this dynamic compiler
comes from is from that which has been
built in from from the start and you
know it does speculative optimizations
as well so a lot of fairly advanced
things that are that are in the box
that's good just looking at the block
diagram of the different components here
and how things flow together you know we
you the the main thing that has to be
contributed by a runtime a host runtime
you know you really have to somehow get
your representation of a method into a
form that the compiler can actually
consume so what you typically do there
is produce what's called an isle
generator you need to get the you know
let's say your byte code representation
or your instruction representation into
the il representation of the compiler so
there's a couple of ways of doing that
you can write a native ayala generator
you can write a JIT builder I'm gonna
talk about that in just a sec but once
you get this code into once you get this
il into the optimizer it behaves just
like an optimizer you know you can throw
many different stress
Gee's optimization strategies of the
code I usually have a slide where I list
all I think there's 90 or more
optimizations that we have the intention
being to just overwhelm you with
information but I didn't I don't have
that here but you know there are many
many optimizations that you can choose
and add to any strategy that you like it
does tiered compilation it's been doing
that for you know almost 20 years now
and he was one of the things that we did
from the start and of course code
generation it does that all the while
that this is operating it's in sort of
constant communication with the the
language environment itself to ask
questions about things like what is the
offset of this field and this object or
talking with a runtime profiler as well
if that capability is hooked up to get
that kind of information and fed into
the optimization process so there's a
couple of ways there are a couple of
straightforward ways of actually hooking
up this compiler technology to to your
runtime the first and perhaps the most
brute-force way of doing it is to
actually write your own native il
generator so what you basically are
responsible for is producing the il in
omar directly from whatever byte codes
your method happens to have you're
likely going this path you're likely
going to you know have the deepest
exploitation of this technology possible
and you're also probably gonna get the
best performance by doing it this way as
well so that's one of the advantages the
of course the the real challenge here is
that it can be fairly overwhelming to go
this route especially if it's sort of
your first time doing this and and
because the the il itself can be complex
in some in some areas and it's got some
nuances that need to be sort of
understood and your unfortunately you
know you're you're assuming all the
ownership of the complexity of this
you're not really you're taking it all
on yourself but you know there's some
pretty rich rewards you can get from
that so knowing that this is sort of a
you know a steeper learning path within
about a year or so we decided to come up
with
a simpler way of taking this compiler
technology and integrating it with a
runtime and that's where JIT builders
come in it's sort of a an isle generator
with training wheels and really it's
really trying to simplify the process of
taking the compiler technology and
plugging it into a runtime I've got a
couple of links on here to some some
blogs that we're developing around this
technology trying to introduce it
there's some docker images there if you
want to go and start playing around with
it as well so there's some some cool
stuff there but the way that it works
it's it's it's really just a simple API
a simple API that you use to describe
what it is that you're compiling so in a
particular runtime you have to describe
your method what its signature is what
its what like what parameters it takes
what types are you're using how do you
actually interpret your byte codes and
what does it actually mean to interpret
those you know how do you do your
compilation that sort of thing so it's a
it's a fairly straightforward interface
for describing that and then what the
end result of that is is it produces the
il that you were that that can be
consumed by the by the compiler so the
the downside of doing this is that you
are because it's a much more general
framework you are sacrificing a bit of
performance in order to achieve that and
and the technology is very much a work
in progress you know we've been taking a
lot of this technology and using it to
integrate it into multiple different
language runtime is like Lua and Ruby
and some other VMs as well and every
time we do that we learn something new
or something different that we need to
add to this kind of technology so that's
where that's going so that was a bit
about what's in the box so in terms of
who's actually using this technology
right now I would say that perhaps the
the best ambassador of this of this
technology right now are the IBM SDKs
for Java so these are commercial
products and you know I've talked a lot
about the the IBM SDK so far and it's
really been the origin of a lot of this
technology but after we had gone through
the effort of
actually separating the language
agnostic parts from the java parts we
were able to ship java 8 in 2014 with
the language agnostic you know
technology built into it and you know it
really exercised a lot of the extension
mechanisms and the way than the kind the
consuming mechanisms in that so the the
real point of that being was that you
know we really it really showed that the
the thing that we had did was actually
fairly the quality was there the
performance was there and you know it
was it was versatile enough to be to be
used in that way so it really worked out
well so one of the next things that you
know we're looking at is it's something
called open j9 and we've already
announced that that IBM will open source
the j9 java virtual machine later on
this year so that's coming the work to
do that is actually proceeding in
parallel with the IBM's SDK for Java 9
so you know there's gonna be two of
those things arriving later on this year
why open source open j9 well there's a
few reasons for that
you know first is the fact that you know
a lot of times when you know we work
with partners or customers or
researchers or whomever and you know
they've got some great idea and they
want to get that implemented in the
technology it's actually difficult
working with them in some cases because
they because it is closed source they
can't actually do the work themselves so
you know it's a more complicated
arrangement getting some of the stuff
and it really inhibits some of the
innovation so getting it out in the open
is important for that also I mean I I
mean I personally was very much on the
front line of a lot of the Java
benchmarking Wars of you know the late
2000s and I can tell you that those Wars
really drove a lot of the innovation
into the into the java virtual machines
and so for example in you know the the
advancements that we made in some of the
GC technology and some of the compiler
technology in order to you know drive
some of those benchmarks was was really
good and I think that a lot of that's
going to apply here as well you know if
we kept this open source and in another
area that
what we tend to see is that you know
when investments are made or
contributions are made in a particular
platform so for example if I'm
implementing some GPU support on a Power
Architecture oftentimes that kind of
contribution would also apply on x86 or
arm or something like that and you don't
often get that sort of cross platform it
does not actually percolate across
platform and by having the code out in
the open you know someone can actually
take that code and actually port it to
x86 reporter to arm or wherever it
happens to be and so it's really you
know encouraging that so there will be
an open source project created for open
j9 it really is the most robust well it
is a very robust extension of the
Eclipse OMR technology it is kind of
going back to its java route so it is
really pulling on it in a lot of
different directions which is really
good for stressing it out the intention
is that this will be the upstream repo
for a lot of Java VM projects so for
example the IBM SDK for Java the
intention is to have it as a very open
like run it as an open community
encourage lots of contributions to that
it's not public yet but the expectation
is that this is going to be open around
the the IBM Java 9 release later on this
year there's a URL there that you can
you can go to if you're interested in
tracking the progress of that and
getting information about this project
as it as it comes along
so ruby is another area that is
consuming this technology this was
actually one of our first proof points
of the of this technology outside of
Java
it was developed very early on with some
of the refactoring that we were doing
what we were able to show was that we
can take the the the GC technology and
we've got that integrated into Ruby 2.2
we've done the we took the compiler
technology we also had it in 2.2 but
it's also in in Ruby 2.4 and these proof
of concepts have actually really shown
quite a bit of potential in terms of you
know the quality of the code
the performance that they're able to
achieve and the other thing is and we're
talking about you know working with
these communities you know it runs the
things that they care about so for
example this code will actually run
rails and it does it quite well so that
wasn't that was really good to see so
we're kind of encouraged by this and you
know what we're what we're thinking that
the next step for this technology could
be is to actually help achieve the Ruby
three by three target so if you're not
familiar with what that is so that's
basically said that by Ruby three the
performance of Ruby three should be at
least three times the performance of the
previous generation and we think that a
lot of the technology that we have here
is is well positioned to help achieve
that three times performance gain we've
been doing a lot of prototyping a lot of
study of the code and the kinds of
things that we're looking at that that
are likely going to be needed in order
to achieve that are you know just better
communication between the runtime system
and and some of the technologies like
the VM GGC that sort of thing
so for example things like when classes
get when classes die when classes get
overridden things like that are extended
in some way you've changed things in the
environment that the compiler or GC
would need to know about there's not
really a lot of that communication yet
that it needs to happen and then you
know profiling types specialization of
your code and doing a lot of inline
optimizations they're the kind of things
that can really get give you a lot of
performance in some of these
environments so we're working on that we
do want help this is open as well so we
do have a repo there if you're
interested I encourage you to go look at
that look at look at the issues in that
in that repo and search for the Help
Wanted tag and you know you know by all
means get involved lua is another area
that we've kind of moved into as well
this actually started as a as a bit of a
pet project we just kind of wanted to
see how easy it would be to hook up the
compiler technology into Lua using JIT
builder and as it turned out it was
actually relatively straightforward so
you know in terms of the changes
VM you know we'd only needed about 50
lines of code to pack REO Lua and we
probably had to provide about 2,000
lines of code for the actual compiler
itself so and and just by doing that you
know we were able to achieve some fairly
respectable performance improvements on
on a few tests and but you know we're
you know we were you know we were very
encouraged by that and what that really
caused us to do as well is to start
looking at other ways that we can can
really improve performance and so we've
done some experimentation with more
advanced compiler techniques similar to
what we were what we were doing with
Ruby like with the type type
specialization and the inlining and and
that sort of thing and you know the
kinds of performance that we're getting
there now is kind of approaching you
know Lua jet performance in some cases
so we're very encouraged by that and we
really want to accelerate that kind of
work and and to get that integrated
because we think that there's quite a
bit of potential here there is a repo
for this again we want help for that as
well so by all means help out there's
also a talk I've got listed here that
one of my colleagues gave at at FOSDEM a
few weeks ago so he goes into more
detail as some the work that we've done
with with Louis so far
ssam do want to go on on this but you
know it's I have to mention song because
you know a lot of these different sort
of language frameworks that have come
out all seem to have an implementation
on song we've done that as well is one
of our early early proof points you know
it didn't take much effort like probably
you you know a week maybe two weeks and
you know you get fairly decent
performance out of the the benchmark so
they have there so it is certainly
possible to integrate with that too and
the last thing I want to mention is
something called base 9 which I don't
think most people have heard about yet
so what this is is an it's sort of an
educational VM that we're developing
that will be used to demonstrate how to
integrate some of this technology with a
typical language VM so it's really a
training aid for
for teaching how you can take all these
different components and integrate it
it's fairly simple
at the moment it's got a very small byte
code sets you know it's stacked based it
has a limited set of types at this point
but you know it certainly is it is is
extendable you know we've done some
tutorials there's some educational
training on how to integrate the
compiler technology with with this
performance-wise it behaves you know
phenomenally so like there's an example
there about getting you know 760
performance some number 60 times
performance improvement by over the
interpreter on some basic fib work you
know it certainly is possible to
integrate GCC technology here we need to
add like an object model we need to add
some array allocations we need to add
some other things like that but then you
know we'll have something in place where
we can demonstrate GC hookup as well and
then on with tooling as well
so there is a repo there as well you can
go oh I check out okay so looking
forward where this is going so this is
by no mirror we're near the the you know
it's just the beginning of this
technology
IBM itself is still very actively
contributing to the technology not
everything that we wanted to open-source
did get open sourced we're still working
on a lot of lot of cool stuff
like for example in terms of the garbage
collection technology we're working on
releasing our region based garbage
collection technology for you know for
doing that kind of allocation compiler
technology there's still a lot more
dynamic compiler technology that we need
to sort of separate from Java and then
push out the door so things like like
more speculative optimizations and the
runtime assumptions and class hierarchy
work and and things like that so there
should be more of that coming over the
next over the next a little while and
just to sort of show the the you know
how cool the quality of this code IBM is
actually pulling this in every hour
every all did all the commits that are
happening every hour and you know
consuming it in internal builds of some
of these language products
like any new project of you know we need
to work on the onboarding experience so
we need more documentation we you know
we need more designs that kind of thing
to facilitate some of the communication
that's been happening we do want to
create a like a discourse instance for
the project so that you know developers
can can discuss in sort of a Q&amp;amp;A type
type way so we're gonna get that going
as well and you know we need to work on
the testability aspects of it as well
right so so right now what uses Travis
CI for doing testing which is great if
you just want to test on x86 but this
the the technologies that this covers
you know it covers arm it covers power
covers zi you can't really find those
externally very very easily so there are
places where you can but it's not really
reachable at this point buy it from
Travis CI so we really need to work on
extending the testing that actually
happens on on PRS to get that to get
those technologies rolled in we are
working with various language
communities we're working with Ruby
we're working with Lua that kind of
thing so we need to start you know
showing that this technology actually
does have some some legs and is really
going to benefit them and then research
communities so colleges and universities
we've got a number of projects ongoing
already with with some universities
around this technology and you know that
should only continue perhaps most
importantly how you can get involved if
you just want to go grab you know fork
the repo and start playing around with
it that's that's terrific if you want to
go the step further and actually start
contributing to the code you do need to
get an account when eclipse.org and you
need to sign the eclipse ECA because it
is an eclipse project and then you know
read through the contribution guidelines
and you know you should be all set and
you should be all set for your first
contribution the Eclipse Foundation is
also has also been chosen as a as a
mentoring organization for the google
Summer of Code so if you're you know a
student and you're interested you know
you can certainly we have a number of
suggestions of projects that
that could be worked on I've got the
condensed link there so you can go check
out some of those and if you're
interested you can start writing up a
proposal for one of those we do have a
number of mentors in place already for
that you know the the the window is now
open for actually making your your
proposal submission so you know if
you're interested go ahead and do that
and if you wanted to see a little bit
more about this technology in action my
colleague Buuren VAR doll has a has a
talk tomorrow and tools in action
session where he's gonna sort of be
demonstrating how you can take some of
the tooling interfaces of eclipse or
more and plug it into a plugin into an
existing runtime to help solve some of
the debug ability issues with that so
tomorrow afternoon check that out
finally you know just some contact
information you know I'm certainly
willing to take any questions that you
have
you know now or later you know we've got
the the two project co-leads are listed
there mark and mark and Charlie so by
all means reach out to any of us if you
have any questions about this or want to
get involved or whatever and then
finally and hopefully not the reason
that you're here the the booth
information from IBM for the for the
scavenger hunt so so that's it any
questions about the technology
well I mean so the question was the
differences between this technology and
an LLVM so you know from the the roots
of that so we're looking at the compiler
technology or LLVM well this technology
is more than just compiler technology
right it's it's it encompasses a number
of different pieces for runtime but just
focusing specifically in the compiler
technology
it was developed from scratch really to
be work to be to be used in just-in-time
compilers so it really does solve a lot
of those problems up front and and and
it sort of gets it for free LLVM as I
understand it and I and I'm not deeply
familiar with LVM but LVM you know does
have a more of a static compiler route
so you know it may take longer to
compile things it may be heavier on foot
and memory footprint things like that
whereas a lot of the stuff that we've
done here really solves that out of the
out of the gate so you know you know
it's it's you know they solve problems
differently but you know we think that
this is more suitable for language
environments like dynamic language
environments
any questions okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>