<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Intelligence at Google Scale by Guillaume Laforge | Coder Coacher - Coaching Coders</title><meta content="Machine Intelligence at Google Scale by Guillaume Laforge - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Intelligence at Google Scale by Guillaume Laforge</b></h2><h5 class="post__date">2017-06-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kl6aJEzByV0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right hello every ma well I'm
probably still bit jet-lagged I was
going to hello everyone welcome to this
session I will be speaking about machine
learning especially what Google and
Google cloud in particular provides in
terms of machine learning with a big
focus on the on the available machine
learning API in particular and I'll say
a few words as well about the the
tensorflow
open source project and the the cloud
machine learning engine platform so what
we use so me this morning and during the
the keynote and gilma falls I'm a
developer advocate for Google cloud and
I work in the Google Paris office and
friends back in I forget in which year
that was that you remember in the 90s I
think when Kasparov the chess player
played again deep blue an IBM program
and computer the computer managed to
beat the best chess player in the world
for the first time what was interesting
was that compared to what we're doing
now here with the alphago when we when
the the engineers were actually design
this program they instructed the the
computer to actually learn about the
rules to teach it the rules of the game
of chess by saying okay these are the
legal moves that are allowed here's how
pcs move etc so it was really brute
force search through a tree of possible
moves
and through legal moves that had been
taught to be to the actual program so it
was really humiliating giving the rules
to a program but today with alphago
which a few month ago beat lee sedol in
korea and the chinese champion i forgot
his name just a last week or the week
before a different approach was used
deep learning using neural networks was
used to have a neural network actually
learn the game of go by just looking at
positions and the various positions
throughout the game but without actually
teaching teaching the exact rules of the
game so instead of doing teaching rules
and brute-force search etc instead we
give tons of games of go of existing
games and the the neural networks just
like the human brain within with our
neurons actually learns how to play the
game so it's a totally different
approach and so this is the team called
deep mine within Google that created
this special neural network to to play
the game of God in the also in the 70s
80s 80s in particular there was
something we call the AI winter the
artificial intelligence intelligence
winter in the sense that there have been
lots of research in the field of
artificial intelligence but
unfortunately didn't really yield the
results researchers expected so we kept
on researching but much less credits
were put into that type of research but
today we see a kind of resurgence of
artificial intelligence and in
particular machine learning thanks to
neural networks
for two reasons why we're seeing this
renewal first of all there's way more
data which is available today labeled
datasets so for example all the games of
go all the games of chess etc and also
I'm in all our websites applications are
collecting tons and tons of the useful
data and from that data you can use
machine learning techniques to derive
interesting things and interesting
knowledge so this is the first thing for
example for image recognition we have
tons of pictures within which we know
what elements are in that picture etc
that's a first aspect more datasets with
a labeled data so we know that okay this
picture contains a cat for example and
the other aspect is now with the very
powerful machines that we have would see
very hot cpus and gpus as well as for
example a Google created its own special
machine learning CPU code TPU tens for
tensor tensor processing unit and also
think about all those servers that can
be put together in the cloud to work in
parallel across even bigger models of
machine learning and neural networks so
if you combine this more label data set
more compute power to train your models
on bigger hardware in a distributed way
we managed to escape this AI winter and
see machine learning being used in more
and more places and speaking of that I'm
going to take one little example where
machine learning is actually applied so
I'm using Google photos for for my
pictures before let's say I wanted to
look for pictures of dogs my dog for
example five
but where if I wanted to search for the
pictures of my dog I would have had to
flick through tons and tons of pages of
pictures to find okay where's my dog
voice my god where's my dog
the other approach would be you know you
manually each time you add a new picture
in your library you add labels saying
okay in that picture there's a dog it's
this picture was taken during my
vacations in that Singapore or wherever
else and then potentially you could have
searched through those labels but here
what's interesting is that thanks to
machine learning were able to say okay I
want to search for dog and automatically
it will find in my pictures the pictures
containing the dog and even more
interesting you can do that combining
different machine learning ap is under
under the hood so for example that the
speech recognition API so you could say
using in the search query you can use
the voice input and you say Doug and
it's going to use machine learning
models for voice and speech recognition
to actually from the voice from the
audio file actually get the word that is
said in this case dog and then with
natural language processing you can
actually make sense of the text that was
meant to recognize the virus entities or
elements inside that sentence and then
use the vision API to actually analyze
what's inside pictures and at Google
many other applications and services and
tools actually take advantage of machine
learning for example which one am I am I
going to mention again like the the
inbox Google inbox these days I think
it's 20%
the the replies I don't know if you know
about this feature in Google inbox
photos we use it there's a some kind of
buttons at the end of an email that you
received to give a canned response and
it figures out the the response to say
by reading your email and looking at
what's inside and for example if someone
says ok let's meet at that place on that
particular day you've got various
options like ok thanks let's do that or
whatever and 20% of the replies that are
made with Google inbox today on mobile
devices are don't prove this mechanism
and it's using machine learning to
actually figure out the kind of canned
responses to give to a particular email
and all those yeah all those products
and many more are actually using machine
learning models this is a little graph
of machine learning usage inside the
Google represent area source code at
Google we actually have a one huge
source code repository which contains
all the code base of all the products at
Google so you can search the source code
of Gmail the source code of any other
Google Calendar or anything or any other
product and this is a search through all
that code base since 2012 until fairly
recently until last year and it's the
disturb shows this graph shows the
number of directories that actually
contain those machine learning model
description files and as you can see
there's a pretty much an exponential
increase in terms of usage of the
machine learning techniques in inside
Google products and services sundar
pichai the CEO of Google
said on a few occasions already that
we're actually moving from being a
mobile first company to being an AI
first and artificial oops not official
intelligence is it it's here it's a
software update keeping up so mobile is
still obviously very important but we're
trying to add artificial intelligence
machine learning wherever possible where
wherever we can add value to our users
to our tools and our services so it's
really a strong desire to to improve our
apps and services with machine learning
at Google and in particular Google cloud
in the Google cloud platform so I'm
going to try to present a little bit the
spectrum of what's available so on the
there are ready-made api's for vision
speech recognition and etc which are
available and I'm going to show you the
the little logos there so this is well
Apr that you can use directly either
with REST API that you can call or with
an SDK in various languages so for
example SDKs for Java and on the other
hand on the other end of the spectrum we
have the open-source framework
tensorflow which you can use to actually
train and create your own models ai
models and in the middle there's a cloud
machine learning engine which is a cloud
environment where you can actually train
your neural networks your models and
also do predictions or inferences to
let's say you give a new picture and to
get the result okay what's inside that
picture so you can do both the training
so you give all the labeled pictures
okay this one contains a tab this one
contains a dot and then you can also
later on once the model is trained
you can make the the prediction so we
are going to look at all the Opie's with
a big focus on the api's so before
diving in let's do a little experiment
together since no networks actually
learn from examples let's say you have a
picture okay is there a cat or dog
inside that picture so to show you a
little bit about the structure and what
we call that deep learning because there
are various levels of different layers
of neurons so there's a base layer the
input layer actually there are pretty
much as many neurons as pixels in your
in your picture then as the other
neurons in the upper layers are
activated they start to actually
recognize let's say they do you know the
Downs the the the shapes of things or
particular aspects and as you go further
and upper in the in the layers
perhaps it's going to recognize okay
here here there's a year and here
there's the tail or whatever and then at
the very top there's the output layer
which is okay it's a gap or it's a dog
and it's deep because of the number of
layers which are available and with the
computing resources that we have today
we are actually able to to create very
large and complex neural networks so if
we try to do this with the usual
approach of devising rules so humans
defining rules to say okay I want to
recognize cats and dogs so let's apply
this to something like fruits how to
recognize or it's over you have a an
apple you have an orange so how do you
recognize an apple from an orange what's
the difference which kind of rule you
would give color okay but let's say
you've got a grayscale picture ah yeah
so how you still recognize the fruits
right so the shade the texture okay
for example the like the coat the the
other the colors well not necessarily
put the pole but you know the the red
and green on on the Apple okay so you
could try to look at all these things
but for example if you take a mango you
also see the same kind of mixing of red
and green right so it's not so easy to
define rules especially when you know
there are new sorts of fruits new sorts
of things so it's not that easy
even for us humans to and you also have
to do the actual shape recognition
somehow viable pixels looking at an
array regardless of how many pixels you
have because you might have different
sizes etcetera so it's not really
straight forward another example okay
and you know fruits perhaps the fruits
always are kind of round well except
that another or whatever but so it's
kind of RAD so something like a Doug and
I'm up I mean it's much easier to
differentiate the two right yeah you
agree with me so far let's look at this
dog a common door that's the name of
that kind of dog that dog breed and and
them up well for some well the first one
is it's probably obvious all those the
the one on the this one as well it
pretty much looks like a mob so that
that's that's okay but you know like
this one or perhaps this one it's much
harder to figure out right so there
again you know defining rules for that
that's pretty pretty complicated so this
is an example with pictures but how to
do that with all the things with video
with audio with text etc and that's
where we have pre trained models pre
trains
API models which are bundled in the form
of API that you can use with the rest
interface or via SMS key gain and
different languages so we'll have a look
at those various API is so the vision
API there are many features which are
supported label detection so you can see
okay that's a cheetah and that picture
face detection find the faces in the
pictures text detection so it's going to
recognize what's written on the sign
explicit content so I didn't put a
picture of explicit contents as you can
get landmark detection to see okay this
is the Eiffel Tower logo detection etc
let's look at this picture from some of
my colleagues so this is parts of the
JSON payload which is returned by the
API so for example you can see that for
for the face okay that that person sarah
has no head where the joy likelihood she
is smiling so it's very likely that
she's happy and you also see the the
bounding boxes where the the place
actually appears in the picture so
there's a virus in this lots of
information available landmark detection
do you know what Monument this is Eiffel
Tower wrong this is actually the Paris
Hotel and Casino in Las Vegas that's you
know the small shape Eiffel Tower and
interestingly the API managed to
recognize that it's not the real Eiffel
Tower but that's the one in Las Vegas so
again you've got the the bounding boxes
to say okay where was the actual thing
but you also have information like
latitude and longitude where is it
situated in the world and this M ID
stuff that's the knowledge graph the
Google knowledge graph it's kind of all
the concepts in the world that Google
knows about on Google search uses etc so
with that knowledge graph you can also
get additional information for example
finding
related related links on with Wikipedia
or things like that and the the just
when was that last month or two month
ago or normal last month there were some
new features which were added to this
API so crop hints to suggest if you can
crop the picture to a different
dimension webinar tations I'm going to
show you what this is about
giving you details of what has been
found on the web related to that picture
and it's the the OCR capability for
recognizing the text in pictures as also
be been improved the webinar tations
let's let's look at this car that's the
Ford Anglia a car that you can see in
the Harry Potter movie and interestingly
this particular car was actually taken
from the Ford Anglia which is at the art
Science Museum in here in in Singapore
and the you also have the information
about the the knowledge graph ID again
and words coming from that's coming from
the Harry Potter series of books the web
annotations also tell you ok where's
this picture coming from is there where
Google knows that this picture was found
on Wikipedia on the Wikipedia page it
gives you also some older URL of images
that for example they took the same
image but cropped it and reintegrated it
in their website or you can also find
other websites with equivalent images as
well let me do a quick demo so if you go
to increase leave it so you go to the
cloud google.com page then you can click
on products and you'll see this although
all the products available on the
Google cloud platform and in particular
this section about the machine learning
and the API and we support so let's
click on the vision API here what's nice
is that for all the api's there's a
tryout box allowed so is the Wi-Fi
working I hope so because otherwise all
my demos will just not work that's going
to be ok it's coming so it gives you oh
it's in French right that's interesting
I'm French and it probably used my local
but it doesn't matter so if you where is
it or the tryouts there should be a
tryout section the tops that's because
I'm in French what's the clue that hmm
now it's do you think you think it's
because it's low loading no no seriously
should I look at the source of the page
to simple things like wow a lot of stuff
but I should be looking at that
no it builds lowering or it's coming up
at strange perhaps I should force in the
oh let me just reload just to be sure
it's not that because yesterday I just
did it and like it was just fine I'll
class I can force my browser to be in
English perhaps it's because I'm in
French somehow or no with the
Preferences plans as well
sorry or incognito that's a good idea
yeah that's a good idea thank you and
Google that it might have my am product
so let's see if it's happier that way
okay
national envision now it's still in
English I think I have to change the
Preferences of my browser I guess too
bad so how do you set language anyone
knows I've done settings perhaps
language language and input settings and
I'm going to put English first let's try
that done okay you have it in English
Angus and is it showing up in the
English version of the page other
triumphs yeah okay it's there okay good
to know
town the Wi-Fi is not super fast come on
come on come on come on
don't use the Wi-Fi please
that is it's in English and yeah it's
there now okay so for example perhaps
you've seen this somewhere so there's
this tryout section so you can drag and
drop pictures so it found the label so
it's skyline etc urban area taken at
night you can see it's probably taken
from sentosa singapore etc so well there
are some things I'm not sure you know
Hotel boss there's a hotel boss I guess
I don't know which weird though is this
one it seems like it may need to
recognize something in the in the light
patterns on the so this is strange but
well what else you can see the dominant
colors etc also it's able to tell you if
it's some you know adult content or
something like that
you can see also the the Jaisal the
details and I'm going to take another
example with this one so it's a poof
image in the sense that there were some
text added to real image you can see the
the virus bounding boxes for the face or
recognition like you know joy sorrow
anger perhaps anger should be I I don't
know
so for example if you look at the text
yeah it managed to recognize curved
faces etc
and it's spoofed the sense that there's
been some text added to the original
picture all right okay
slides coming up and if we come back
just to the other pictures of dogs and
mobs so for example for this dog it
really recognized its dog this one it's
a broom a tool but for these two
pictures if you use the the vision API
for this one it recognized some fur but
it didn't figure out that it was a dog
and this one at the bottom it said it's
some kind of textile but it didn't
really recognize so it's not that far
away of that wrong but it didn't
recognize as a tool as a broom as a mop
all right next the natural language API
you can extract entity the various
elements the sentiment whether a phrase
a sentence is a positive or negative and
see also the structure of your sentences
so for example in this sentence which
speaks to that which talks about JK
Rowling the Harry Potter author it
recognized those different entities and
John Jo Rowling JK Rowling Robert
Galbraith are actually one single person
Robert Galbraith is the the pen name of
JK Rowling for some of her books and it
really recognized that that's just the
same person and it points at the this
Wikipedia page which is referencing the
knowledge graph which knows that Jake
Arad British it recognized it some
location pointing at the United Kingdom
and here our reporter is recognized
Harry Potter as the person of the of the
book the sentiment analysis so you can
okay look at the score magnitude the
score
or it's you can range from minus one to
plus one whether it's negative towards
positive magnitude it's how strong this
feeling is being expressed and here you
can also see the the syntax how the
sentence is made like the determinant
the noon the verbs et cetera and also
additional information for example for
the verb what mood was used whether it's
singular which person was used etc and
if we do the similar test here I think I
can write NL it goes straight to the
page and here again there should be if
it's loading up and it's in English so
it's ok it's just loading alright so for
example something I wanted to do just
like in my example the food was great it
is slightly different sentence but the
service was awful in this sentence you
actually have two different sentiments
for you right hopeful and analyze so the
the two entities that are recognized
with to let's say concepts there's food
and there's sawdust right and you can
have the the sentiment not just for the
whole sentence but as well for the
various entities and here the food was
great so it's positive 0.9 it's close to
1 and the service was awful sounds yeah
perhaps didn't you see there are 2 else
now how you spell awful no there's no
eat right don't how to spell awful I'm
sorry I'm awful at staring
yeah and it's uh yeah because it didn't
recognize my wrong spelling I'm sorry
and minus 0.7 that's something quite
negative and the other syntax that's the
the nice graph that you saw the various
elements of that sentence
next we're going to have a look at the
speech API so the speech recognition
works across 80 different languages so
it's pretty pretty good let's have a
look at a little demo so what I'm going
to do is I'm going to show it in action
directly now let me explain first what
I'm going to do is I'm going to record
my voice I'm going to send that audio
file to the speech API this speech API
is going to give me the text then I'm
going to use the natural language
processing API to see the various parts
of my sentence and then there's Alice's
one because I use that well today's conf
Singapore to be correct and I actually
created a special custom search engine
using using a Google custom search to
actually search the the program which is
a go to the schedule to search the
program so my little tool is it is going
to so if I click let's save this talk
which is here excuse me I'm going to say
something like okay is there a
presentation about machine learning and
I wanted to return a result pointing at
this particular page so let me show that
in action so I've got a little script
that I'm going to show you so I did that
just with common line tools basically
and using curve to call the rest API for
the speech recognition and the speech
recognition and the natural language
processing and also a same thing for the
the custom search so I'm using socks for
recording my voice then I'm going to
send that to Google Cloud storage to
stall the fire and I'm going to instruct
the speech API to do the recognition on
that file that is stored on Google Cloud
storage
then I've prepared some so I say that in
a file then I'm going to use a little
tool called JQ which allows you to
squirt navigate through some JSON
content where the return the response
from the API call then I'm going to do
another call to call the natural
language processing etc and finding the
right information so let me try that so
let me record is there a presentation
about machine learning so I'm uploading
to cloud storage so it takes a few
seconds hey I need to update the g-cloud
command this is the request that I sent
then this is the response let let me
scroll back a little bit because it goes
too fast afterwards this is the the
response of the speech API said okay is
there presentation about machine
learning it really recognize the what I
actually said then I call the natural
language processing API which then so
it's a bit more verbose this one but
you'll see I mean over like all the
words that machine learning then I went
through the the J'son that you see there
and I retrieved it I retreated all the
over all the words and I was just
interested in the the part of after the
about keyword basically so I looked at
just that part of the sentence because I
have the structure of the sentence and
then I retrieve the topic so I'm
interested in machine learning and then
I'm using the custom search Google
custom search tool to actually search
for sessions about machine learning and
indeed so there's work so the
returning just the the so I should
output the URL instead of I'm actually
outputting the title of the page and if
you look at the website here indeed the
title of the page that's human affairs
what's de Singapore so it really found
the right page next time I should change
that too to output the URL so pretty
quickly you can combine different api's
together ready-made machine learning
api's and create something useful okay
the translation API so this one is
actually one of the oldest API that we
have and so before it wasn't part of the
Google cloud platform but now it's also
available that for example in Airbnb
when you travel 60% of all air B&amp;amp;B
bookings actually connect people who are
from well who are actually using
different languages and that's pretty
handy because even if you go to a place
where you don't really master the
language you can still interact with
with your with your host and yeah I can
do a little test for the translations I
think I can just jump slate to head here
and okay so I'm not I'm just going to
use the example there so I don't I'm not
a robot for sure at least I don't think
so or I'm not self aware so well I don't
speak Chinese so I'm not really able to
assess whether the translation is good
or not but at least well you know the
how it works
yep so that might be it just trust the
transition and yeah perhaps I can show
you I didn't really show you so I I
should be some shell script but for
example here's the Java SDK so if you
want to integrate the Translate API in
your application it's fairly
straightforward and yeah you just
retrieve the the translation service and
you call the translate method and you
pass the text as well as the source
language and target language and called
get translated text to return the the
translation so it's fairly easy to use
and what's interesting about the this
translation API is that so before a few
months back we had an existing
translation so this that actually used
statistical models with humans who
actually define the rules for various
languages to understand the structure of
text etc and to figure out how to best
do do translation but that was that was
initially with rules that were defined
by human beings and we totally scrapped
that totally with a new neural machine
learning translation system and which is
based on deep learning techniques using
some so this little animation shows the
search form of I think that's an LS TM
neural network long short-term memory
here so another big big expert in the
virus structures of neural networks but
it's able to look at the virus
words and parts of a sentence
progressively and make up the the
translation by really mapping elements
from one word in a certain language to
another word and see how things are
related together let's say an adjective
which is tied to name etc and this very
quickly compared to the many years that
had been spent in improving the the
statistical model that was used before
in in in a matter of six months they had
completely redone the the translation
and with much improved translations for
example here in this text again from
Harry Potter let's say the via the
Spanish existing translation then the
first generation translation in the
middle which was using the the
statistical model versus the neural
machine translation and for example
things like the company from mr. Dursley
manufactured drills instead of making
drills or instead of necklace which is
not quite correct
it's without a neck etc or almost twice
longer than usual is not totally correct
almost twice as long is more correct etc
so it's pretty mature I've tried that on
French and for well my own needs and
that really found the quality of the
quality of the translation to be a
really much much improved and before
often you could figure out that it was
machine front translated with the
statistical model whereas with a neural
model it's much much better and
sometimes it's very difficult to figure
out that it's it's not translated by a
human being the video intelligence API
so you can think of it as just like the
the vision API but instead of steal
pictures that's moving pictures let's
directly have a look at a real demo and
the vision API is no good learn a bit
where's the video intelligence API so
I'm going to select some of the sample
videos which are available and still not
robot I tell you which one I'm going to
use let's say you know perhaps this one
with the general so this is the the
scientist that worked with AIDS in
Africa so this video so it's going to be
uploaded and passed to the video
intelligence API so it's actually the
one because the the video is quite big
but what's interesting is that it's able
to figure out what other the various
shots the various sections of the video
and for each section it's able to figure
out okay what's inside so it's some
nature animal trees and it's going to
change the labels as we as we let's see
yeah pretty much the same or perhaps I
should have chosen a different video
with more changing scenes I know that
sir yeah that's here that you see that
the different levels changing so you see
the various shots and you also see that
the labels are changing because it
figure out that it figures out what's
inside that particular shot so there
should be an ape here that appears etc
so let's see what the next one shows up
again a penny more wide large etc and
yeah
what other information is there any
other labels and here the well the
requests there the response that you you
get with all the details so what's nice
with that is that you are able to also
search for videos so let's say you have
a in your website you let users upload
videos you can have people search
through the videos or there's a snake
there so if I search for snakes I'm able
to find videos containing snakes etc
alright
so there's also things like label
detection so this one figures out that
there's a portrait and you can see also
in which segment with the offset this
appears in the individual so all these
are pre-trained models which are
available as api's that you can use
again from a REST API or from a new
decade but all those models are actually
using a framework that we actually open
sourced called the tencel so so
tensorflow that's actually the
second-generation
deep learning library that we created we
had another one internally there was no
consult but this one weapon source it so
it's available in you can use it from
Python or C++ that's the two main API
soror languages they take but there's
also experimental support so the the API
might might change a little bit because
they are currently labeled as
experimental but you can also use it
from Java as well which also means that
you can use pre trained models and
things like mobile applications as well
so with this framework you can describe
your machine learning model so you can
define the features that you want to map
recognize you can define the kind of
neural network that you want to use
recurrent neural network convolutional
neural network etc and you're able to
select those algorithms and then you can
use this framework to also over here
regression models of also I didn't
mention you can then use this framework
to train your model so you give it tons
and tons of data and it's going to
figure out by itself what it has to
learn depending on the features that if
you've selected so this is available on
tensorflow dot-org there's lots of the
documentation about it if you want to
learn a little bit
or that and so when you use tensor flow
you can use that on your own machine or
on the server but as part of the Google
cloud platform there's also true service
that you can use called the cloud
machine learning engine which is
basically tensile flow in the cloud so
you can send your model into this
service on the cloud and you also pass
the data and you let it run through the
over data and learn from from the data
so this is the training part where
you're training your model and then you
can also run the predictions once once
the model is trained afterward you can
reuse it to say okay tell me what's
inside that picture if it's a kind of
vision API that you've implemented here
I have a little command line which was
an example of how you can submit the job
of running training on an attached core
system so you can you can use the UI you
can use that to to submit stuff so this
is a veil over all so what it's what I
forget to mention is that the advantage
of running that in the cloud is that you
can use as many servers as you want so
you can define how fast and how much
you're ready to spend and how fast you
want the the training to happen because
running on lots and lots of data running
the the training it can you it can take
you know hours that perhaps or perhaps
days or weeks to train for very complex
data sets and huge data sets but if you
do that in the cloud you can say ok I
want to use GPUs I want to use 100
servers and then instead of doing that
in a week you might have the results in
just a few hours so depending on how
much you're ready to spend on how fast
you want to get the results you can
decide
how the distributed training should be
taking place in the cloud all right so
all these pre trained models in the form
of api's are available online you can
use those little demos to play with them
there's a lots of documentation samples
available there's all the decays in
various languages and in particular in
Java to call those a applies we have the
tensile flow open source project which
can also be used via Java as well sent
to the experimental API and then the
machine running engine is so if you want
to do the training and predictions and
inferences within the path so that
thanks a lot for your attention and I
think we can take a few questions if you
have any questions
no question
what one thank you
so the to to give like tents of local
for free our cloud computing so what's
the question is is it free or how much
is how much is it or what I'm not sure I
got the question or is it just a remark
so say it louder
so there's a freak here for like the
virus aap is but then for example I
think like for the pad machine learning
engine since it's using computing
resources etc I don't think there's
anything in the fridge here at that
level yeah yeah in the phone yeah
situation alright so how to identify
which model to actually use I think for
that it's not really helping because you
have to know learn somewhere which the
kind of stuff which is used so for
example I think for things like image
recognition vision analysis etc and
things like commercial convolutional
neural networks are usually more
applicable but for things like
translation or things that need to
remember what we've seen before
things like LST M long what I never
forget you never remember the long short
term it is the memory networks for
example are better because they are able
to remember what was said before for
examples I didn't run this demo but
there's a one of my colleagues they did
that of analyzing the the check Spears
place and to go through the full set of
place and it rained the model you're
using an ethical new STM network to
actually understand the style you know
of Shakespeare and after tons of
training using a random generative
approach reusing the model he was able
to generate Shakespeare plays and it was
really looking like Shakespeare plays
even creating names for the characters
of the play etc so there are different
models for different areas but it's not
really helping figuring out which model
is best so you usually have to know that
on the other hand there's would I forget
he'll be this picture scope this feature
is called that's the hyper tuning or
something like I forget the name of the
feature which also helps you which also
helped you figure out the how to tune
some of the features that you're using
in
put and we also announced during Google
i/o or a few weeks ago a new feature
called Auto ml which helps letting let's
say that the computer learn about what
you want it to learn basically now not
dive into that but we are getting there
but I think it's still an active area of
research how to make it even more you
know transparence an automatic etc but
so far is using terms of flow you'd have
to normally be a little bit more about
neural networks to to figure out with 20
years yeah
there were another question there
yeah you can do that on your local
machine
so also something speaking of that for
example the the vision API we also open
sourced the model for the vision API so
it's called inception v3 the version 3
of the inception model so there are it's
available I think somewhere on github I
forget what it is you can actually take
that model run it for yourself or even
more interesting because you might have
so it works well and virus kind of
pictures but for example perhaps you for
your own use case you'd want it to
recognize the various types of nuts and
bolts or whatever okay and you can
actually take that model and retrain it
on your own data sets of pictures and
views so you add the labels etc of
course and you're able to further tune
an existing model for your particular
need which is a pretty useful and
interesting chaining using video video
so you mean Vision Plus video yeah I
don't know exactly how the like the
video has been implemented whether it's
using some part of the existing vision
API etc so if you were wanting to do the
same thing with the the video for your
own needs I don't know if we I don't
think we've open-sourced that one so you
could perhaps extract the various frames
once in a while and do that analysis but
it's yeah it's more more work obviously
right with them we have do I have time
for one more question
one we're there one more yeah
boy
so I'm going to make you repeat because
I didn't feel that well okay what we do
with the data basically yeah so on
premise yeah yeah so the the tensile
project you can use it and run it on
your machine on your GPU etc so it's
totally possible and then the model you
can reuse it and deploy it on a mobile
phone or web app or whatever wherever
you want to make it on your server etc
so yeah on premise you don't have to use
a cloud machine learning engine to
actually do the training it's just that
it helps getting training and prediction
to faster than running that on your
machine because it can take days or
weeks to to train a complicate on a
complicated data set also yeah when
you're using the cloud machine learning
engine the the data that you that you
you send I mean in something if you look
at the terms and services of the service
we definitely don't use or keep your
pictures it's a trap well you have to
upload them somewhere for example on
cloud storage so afterwards so the data
belongs to you right doesn't belong to
Google we are not going to find a
question I often get is whether the
pictures I've uploaded will they be on
the Google search no of course not don't
worry about that but then if you use
Google Cloud storage you would have to
delete afterwards the data but that's
going to be your responsibility okay
well thanks a lot for your attention and
enjoy the rest of the show</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>