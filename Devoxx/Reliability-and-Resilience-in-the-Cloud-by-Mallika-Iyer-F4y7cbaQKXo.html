<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Reliability and Resilience in the Cloud by Mallika Iyer | Coder Coacher - Coaching Coders</title><meta content="Reliability and Resilience in the Cloud by Mallika Iyer - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Reliability and Resilience in the Cloud by Mallika Iyer</b></h2><h5 class="post__date">2017-11-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/F4y7cbaQKXo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good evening everyone thank you for
being here
my name is Malika I work for Google I
actually started working on this project
when I was working at Pavlo as a cloud
architect so this sorta just carries
over because I love people join go to
you two months ago so there are a lot of
there is a lot of Cloud Foundry that
you'll see there is a lot of Google
genomics that you will see and some
bigquery so actually had an interesting
situation with my laptop because it
wasn't connecting to the projector here
and so the code that I'll show you
there's not a lot of code and luckily
I'm not doing a live coding demo
otherwise I would have not been able to
do that anyway so
No
all right um okay so the challenges that
come with not using my own machine all
right so for the next 30 minutes or so I
will share with you what I've learned I
worked with a lot of customers while at
pivotal in my past life and while at
Google and I just want to share over the
next 30 minutes my experience working
with large scale organizations who are
doing one of various things right they
have started on what is you know you
must have heard this buzzword a lot
cloud native cloud native so they're
either in the process of starting their
journey embracing the cloud moving their
app architectures to the cloud moving
their data stores over to the cloud or
they're somewhere along the
transformative process so over the next
couple minutes I'll talk about you know
what what I started out with as a
baseline architecture how I evolved over
it to run applications that are built
for very large very unpredictable user
load so I'm talking about petabytes and
and beyond that running all of that at
cloud scale and the overall goal is it
has to be resilient it has to be
reliable so while architecting for
failure and just wanted to clarify a
couple of things because cloud native
it's such an overloaded word so when I
say cloud native from an application
stand for standpoint I'm talking about
cloud native applications that conform
to a framework or a contract and it's
designed to behave in a predictable way
to maximize h.a to maximize resilience
and its container driven highly
automated does auto scaling can self
heal itself and so on and cloud native
data is a little bit different right so
when I talk about that what I really
mean is that I want to store it I want
to structure it in a way that it is flex
so if I want to be able to scale it at a
moment's notice I'm able to do that I'm
not stuck in infrastructure land what
I'm trying to size for capacity so
primarily I'm this is what I'm gonna
focus on so some of the challenges that
I keep coming across when I talk to
customers or going through this is the
first thing that I have seen is you know
from a data standpoint either they are
maintaining their own data farm server
farms they have a mishmash of data
present some in silos some in the cloud
a little bit in the cloud and everybody
has a slightly unique challenge so the
other problem when you have this kind of
a situation is how do you scale how do
you scale really really fast at a
moment's notice for unpredictable
workloads the third problem is when
you're architecting in this kind of
scenario there is also the application
delivery to think about and I want an
architecture that lends itself to
continuous delivery if I want to push
code out multiple times a day took a
push push features out multiple times a
month I want to be able to do that
seamlessly and lastly I want you know
resilient infrastructure for my
application I want to be able to do the
same thing for my data basically my goal
is I don't want to I want a future proof
my infrastructure I don't want to work
for my infrastructure I want it to work
for me and I want to just focus on the
actual code the actual need of my
business and the thing that's actually
going to provide value to my customers
because everything on the infrastructure
side they're not going to see it it's
all behind but it could really really
affect how your application is used by
customers and your and your audience
right so the challenge is to create
best-of-breed resilient a future-proof
application architecture as well as a
data analytics architecture that's
impervious to scale so when I started so
this was an experiment that I
ducted based on all the things that I
keep hearing when I talk to people who
are in various parts of this journey
right so for the purposes of for this
experiment I needed a very very large
data set and there are not that many out
there I mean you would think about you
know you talk about or you hear big data
a lot but there is not that much big day
out there so the first challenge was I
wanted a very large data set I'm
thinking of literally petabytes of data
even beyond that and something that
grows at cloud scale while not having to
deal with being in the business of you
know being
maintaining my own infrastructure I
don't want to do that I want it to be
completely serverless I want it to be
able to scale I wanted to be able to
handle advanced query analytics and I'll
tell you why in a moment and you know
most importantly against herbalist I
just want to start using the technology
I don't want to set anything up and
natively I wanted something that had a
che that had global availability and so
on basically the building blocks of what
is what does resilience and reliability
in the cloud mean so the so as we've
tried to you know I started looking
online I was trying to look at good data
sets that I can use for the purposes of
my experiment and I just got the idea
for the data source very randomly so I I
have three dogs and you know and they
play with each other constantly two of
them are German Shepherds or Alsatians
one of them is a rescue she's a mix and
it was interesting to me that you know
my rescue dog she was actually behaving
or almost mirroring the behaviors of my
two Shepherds and if any of you out here
are dogs have dogs you would know that
the behavior of a dog is is very
specific to the breed of the dog
themselves
I just wondered I mean it wouldn't it be
great if I can find out her history find
out if she somehow has some sort of
German Shepherd genes in her and somehow
correlated to other DNA and basically
just like that I started looking into
genomes and I found some very very
interesting things so I use one of the
publicly available genome datasets and
the interesting thing about genomic data
is that if you think about a single
human being one human genome literally
has from a storage perspective from how
much data you need to analyze it's about
a hundred gigabytes of data so
interesting thing is 99.9% of that is
the same there is only a point one
percent that makes me different from
somebody else but the challenge is that
in order to find that variance in order
to find the 0.1% I have to actually
analyze everything so you can see how
this can become you know an interesting
problem really really fast because if
you just think about I was thinking
about the population of Antwerp and and
that itself would literally be
translated translate into 52,000
terabytes of data or you know 52
petabytes of information roughly so as I
got my data source my next challenge was
I wanted to be able to store this in a
meaningful way so what does that
actually mean in my in my case I wanted
to be able to store massive data sets
every time I add you know one person's
genome that's literally a hundred
gigabytes so I wanted to be able to do
extremely fast query processing so this
can differ based on your use case right
but if I am storing you know 50
petabytes of data I don't want to start
the query and come back after weeks in
order to get the information I want it
to be fast I want it to be within
seconds or minutes and of course in
order to do all this I don't want to be
in the business of figuring out storage
I don't want to manage my storage it has
to come fully managed for me so I'm
looking at a service service model by
default and
again resiliency and reliability means
it has to be globally available it has
to be highly available and in order to
do any sort of meaningful query analysis
complex query analysis variance analysis
and such it has to support complex query
patterns so basically I ended up finding
Google genomics and remember I sort of
ended up in this google land while I was
still at pivotal so that this whole
field completely fascinated me mainly
because it hit all the checkmarks for my
experiment because I wanted to be able
to store process and explore the data
without writing the tooling and genomics
API exposes a lot of endpoints that
allow me to do this and just let me
focus on the code I don't have to worry
about the tooling and behind the scenes
it actually uses bigquery in real time
the query is a Google Google cloud data
product it uses it to do the data
processing and data analysis and this
was amazing because I started digging
into bigquery a little bit more and I
found out that it was perfect because it
was literally built to process trillions
of lines of logs and and we're talking
about interactive speed so one of the
examples that if you just google it
you'll find this that basically there is
an example that queries over a hundred
billion rows that is roughly around ten
terabytes of data it's basically a lot
of Wikipedia data and it comes back with
the analysis in under thirty seconds
which which is kind of amazing
so I zeroed in on this this part for my
data and then obviously everything was
serviced I didn't have to spin up
anything I just created an account and
started using it so my next challenge
was I mean if I were thinking in a real
life kind of a situation I would need to
have application infrastructure as well
so my next challenge was I wanted to be
able to have an application
infrastructure that was letting me
deploy code several times a month or you
know as often as it needed
and basically have an intelligent
infrastructure that let me autoscale so
I could set thresholds and I could scale
it up or it could do that automatically
based on whatever I have defined from
you know how I want to what is the point
at which I want to scale my application
up so another thing that I wanted it to
be able to do is it has to be obviously
ideal for micro services it had to be
ready to work in container land so
that'll be container ready I don't want
to be constrained by programming
languages either because what I learned
while doing this work with Google
genomics is that I can use Python I can
use or I can use some other language as
well so I don't want it to be
constrained by programming languages and
in a real-world scenario you're going to
see or I'm sure you have probably
experiences in some way or the other
there are groups within your
organization some of them but a lot of
them might write Java code there might
be folks who are only focusing on
writing services and go there is
basically a mishmash in every
organization so I wanted it to be
future-proof from that point of view as
well and the most important thing I
wanted to be able to connect to any data
source from anywhere to anywhere so it
could be on Prem it could be in the
cloud it could be on Google Cloud so it
doesn't matter I wanted to be able to
connect to that so this was actually and
obviously it has to be serviced because
that was I didn't I don't want to be
managing all of this so again these are
all the application challenges that you
will see while you're running anything
or architecting to do anything in the
cloud and this was a fairly easy answer
for me because I was already working
extensively with pivotal Cloud Foundry
so just just for those who may not be
familiar with what Cloud Foundry is it's
a platform as a service it is open
source and it supports multiple clouds
and paraquad foundry it's an Enterprise
version of that so basically I mean
getting back to the actual you know
weeds of it it's basically a technology
that lets me forget about application
infrastructure lets me forget about what
I need to do to do auto scaling lets me
forget about you know how
do i how do I have containers interact
with each other basically how do I have
micro-services interact with each other
it's a great choice what a microscope is
based architecture paradigm so I said so
basically now my architecture would look
something like this right so from a very
expanded point of view I have in a
real-world use case and I'll show you
exactly what my use case was in just a
second so in a real-world use case you
might have users who are you know doing
web mobile application IOT you might get
data from IT you might
all of these might be using one or more
protocols so from the left to the right
hand side you can see that all the
requests are going beyond API gateway
and you might be using HTTP mqp TCP
something else and then there are
clusters of micro services that I have
within my application that are handling
each one of these requests so the
interesting thing is so my stack is now
running on Google cloud platform because
it was great it was easy to use and
everything is running on payroll Cloud
Foundry so my biggest challenge here was
you know I don't want to do direct
connections to databases because I might
want to it's just not a clean way to do
it I don't want to expose my IP
addresses I don't want to expose my
connections so I don't want to do a
direct connection to any of my databases
so in my case it looked something like
like this only the genomics part was
what I was using right so in order to
not do that there is a very interesting
concept within the Cloud Foundry world
it's called a service Pro currently it
can't be expanded out if you're using
kubernetes or you know any other
platform also basically what the service
broker lets you do is it's a component
that is implementing what's called a
service broker APs this is where you
know you might you will implement five
endpoints which do a number of things
like advertising a catalogue of the
service offerings so for example within
genomics
if I wanted to
but I is just what is available which
teams can use it I might say okay this
team is allowed to do this this and this
this is the functionality that's
available and this is the amount of data
that they can store so this differs
based on what you're doing if it's some
sort if you if it's a my sequel
situation you might have define a limit
on number of concurrent connections you
might define a limit on how much data
you can use so you can you can expose
all of this just by building a service
broker and then you act on those
requests you the service broker lets you
do provisioning of a database of an
instance and obviously the the the
opposite part of that also deep
provisioning and then it also lets you
bind or talk to an application instance
and unbind and sort of gracefully cut
off that connection from an application
instance in the same way so I don't have
to use any API keys I don't have to use
IP addresses I don't have to use that so
it's it just used bindings so I wrote my
service broker in spring boot for a
couple of reasons
mainly because I'm a Java developer and
spring takes a very opinionated way of
writing code in the spring boot in the
for the spring platform so if I am
bootstrapping multiple applications and
multiple services for production it's a
great tool to use and within the Cloud
Foundry ecosystem within favor doe Cloud
Foundry it actually has great support
for spring boots so that was kind of a
no-brainer almost so now diving into
each method itself this is basically
where you will define the exact behavior
in code so with respect to what does it
mean when you are having your broker
implement the catalog method so for
example I might want let's take a simple
example with my sequel I might want a
plan that says X number of concurrent
connections are available this is the
amount of data that's available I might
have multiple plans based on the teams
that I'm building it for so the next one
is it could be create instance in my
case I was creating a data
but instant creation basically literally
spins up an entire data service for you
on top of parallel Cloud Foundry as well
so I'm not doing that in my case I'm
only creating a database because I am
reaching out to Google genomics which is
running on GCP and I am creating an in
database for my experiment the binding
and the unbinding that is the create
finding and the delete binding methods
here that's where I implemented or this
is where you would go and implement the
actual brokering of the connections
injecting the via the connection details
into your application instance
gracefully removing that as well and
delete instance versus delete database
it follows that is basically the
opposite of the create and stems and
create database so this is what my
current architecture look like so
shrinking it down just for the purposes
of my experiment I have everything
written using the service broker and
I'll talk about the open service broker
API in a second but basically I am no
longer trying to reach out to my data
source directly and I'm not doing
connections that way so the open service
broker API is really really cool because
what it lets me do is let's say tomorrow
I want to be able to so if you look
further below if I want to be able to
move out everything from the Google and
from the from pivotal Cloud Foundry over
to Google container engine which is
basically which is basically completely
serverless
it runs on Google cloud platform so I
can do that basically without rewriting
any code because what I would be doing
is simply exposing the endpoints so are
simply implementing the endpoints in the
open source API open source open service
broker API
like you know get catalog which is which
is the catalog method that I I told you
about earlier so what I would end up
doing is without any code rewrites
without any change I can basically
completely port all my microservices
all of my service brokers over to an
alternative architecture paradigm like
this one over here so this is really a
completely serverless architecture if
you think about where your data sources
are running so if you are using
everything running on the cloud then now
you are free from actually having to
manage anything on from because even if
you are spending some time orchestrating
it architecting it to run seamlessly on
Prem it is still time that is going away
from actually spending all of that
energy and all of that effort on your
code so on the right hand side you'll
see a couple of common common offerings
or common areas so I specifically here
have pointed out Google genomics because
that's what I used for my experiment but
you might use a variety of in any
architecture there are no sequel
databases that are enterprise data
warehouses analytical data warehouses
key value stores so there are
alternatives if you have not actually
explored these within the Google
ecosystem for example I could use cloud
pub/sub for messaging I could use
bigquery for doing analytical data
warehouses and there are a number of
products better available using the
cloud launcher as well so it's really
cool because I don't have to manage
anything I just focus on actually
writing the code for my application so
lastly so just to sum up everything that
I talked about I started out trying to
figure out is there an elegant way to be
to the solution to the problem of I want
to go to cloud native application
architecture or I want and also I want
to be able to move all of my data to the
cloud as well so it's not an easy
problem to solve because there are
technical limitations in each
organizations there are cultural
limitations that you have to kind of
bridge as well but basically if you
think about the problem statement itself
if you want to build a highly available
globally available resilient
architecture for data as well as
applications that is a really hard
problem to solve but one thing that I
have found is if you pick the right tool
it really helps a lot because in my case
just for the scope of my experiment I
picked a really really large data set it
was petabytes of data it could
potentially be exabytes of data
depending on how much information I push
into bigquery so if I had selected the
wrong tool I would have just spent a lot
of time trying to optimize it trying to
figure out how to make it run
efficiently and so on and this was great
because it just works the other thing is
you know going back to the application
infrastructure side if you're if you're
building containerized applications
there are multiple options out there in
my experience I have found I work with
PCF I worked with Google container
engine they're both great options and GC
is truly serverless because it runs on
GC P and you just you just forget about
it
and parallel foundry is great because
you can run it anywhere you want if you
really really need to run it on Prem you
can and lastly again I would not have
been able to actually do this experiment
end-to-end in and prove it out in a
successful way without without bigquery
without something that was able to give
me that sort of interactive speed that I
needed from an another
data warehouse that was completely cloud
native because it's it's challenging if
I go to any other alternative that needs
set up I didn't want to do that so Vic
where is an excellent choice over there
and since this was you know my
experiment sort of hinged on genome data
I wanted to share a little bit of a
trivia with you that I found out I found
out that the number of so dogs have
about you're going back to my original
inspiration for for this for this
experiment dogs actually have about
nineteen thousand or so protein coded
genomes not that not that different from
human beings we have roughly around
twenty thousand or so and that kind of
blew my mind away so if anyone's
actually interested in exploring this
further whether from so from a genomic
perspective they're actually found out
there are a couple of dog genome
projects that that a bunch of
organizations are doing that that
predict or give you the the probability
of you know the an autoimmune disorder
that might happen in your dog or you
know blindness or deafness or any other
kind of disease and on the flip side
going back to the tech stack there is a
lot more information about bigquery
obviously on the Google web site on the
Google cloud web site so if you and and
there's a lot of information about
Google genomics there as well it is
really cool the API is phenomenal and if
you are interested I highly recommend
that you play with it and that's that's
one of my dolls up there questions
so when I the reason why I picked the
stack that I picked was so from a
language standpoint as prick springboard
for a couple of reasons it's mainly
because spring would lend itself really
well to developing micro services on
federal cloud foundry I was to begin
with I started out with Cloud Foundry
because I was most comfortable in that
area and it was it just it just lent
itself phenomenally to deploying
application apps basically microservice
paradigm following apps and I sort of
and while I was actually exploring what
can hold a lot of data at cloud scale I
I wasn't working at with bigquery at the
time I sort of explored when towards
that area after rejecting a number of
options because several options and I
will not name the products of course but
several options actually had me you know
I needed you know I account I needed a
license I needed to set up almost a
small server farm it was just not
feasible for me one of the great things
about bigquery is that I do
I can use it as I as my data expands or
as my data shrink so it scales up or it
scales down so that was perfect for me
because at the time I wasn't sure how
far I wanted to take the scope of my
experiment did I really want to push
petabytes of data into it did I want to
go beyond that so it lends itself really
well for that and Google cloud platform
it was just really easy to use I started
I worked with a number of other cloud
platform I asked providers as well and
in my experience over the past couple of
years this has been amazingly easy to
use so if you want to you know dig a
little deeper into that I'm happy to
talk to you offline and you know we can
go into it if you're interested all
right my times up so thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>