<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Watson and the Cognitive Developer by Sandhya Kapoor and Mehjabin Kapasi | Coder Coacher - Coaching Coders</title><meta content="Watson and the Cognitive Developer by Sandhya Kapoor and Mehjabin Kapasi - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Watson and the Cognitive Developer by Sandhya Kapoor and Mehjabin Kapasi</b></h2><h5 class="post__date">2017-04-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jL-rtsEz2ok" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm Sanjay Kapoor and I am here with
my friend mahajabeen capaci so here we
are today to talk about the cognitive
developer especially using Enterprise
Java applications how do we make our
applications smarter because we all
understand and know and see it around us
that we are in a cognitive error you
look at how applications are adding
voice recognition or visual recognition
or even making them conversational with
the numerous chat BOTS we have around us
and even going further enriching the
unstructured data that we have tons and
tons around us with concepts keywords
entities and then gaining insights into
that data is where we are headed and so
no wonder we call it the cognitive error
and that's why we wanted to share with
you today our experiences in taking
enterprise java application and making
it cognitive and it's a live application
so we would like to share data with you
as to how it is performing what are the
glitches what we are improving upon so
please feel free to ask questions as we
go along let's make it an interactive
session all right so there is a project
we named it Esaki and I won't let the
cat out of the bag
let mahajabeen explain why it's called
Esaki so do you want to first ok go
through the agenda and I get it alright
so here we go here's the application and
go ahead Mary so hello everyone and the
you are on the right side that you're
seeing this is the live application so
you can you know definitely try it
if you want now or later we definitely
look for feedback so we'll talk about
that a little bit so a sake I'm sure
he's wondering why this name is it
another IBM acronym what is it about so
we're we were looking for we're still
working on an official cool name for
this project but it's AK he's named
after the first Nobel Prize winner at
IBM felt like a lofty goal to point
towards that so that's what we're doing
so I know over the past few days we've I
at least I've been to talks that talked
a lot about prototyping mindset design
thinking that we just heard in the
keynote today so we've definitely taken
that to heart and we're building this
complete application Design Thinking is
a big part of it which is to keep the
user at the center of that experience
and then build the application around it
so we we have this exercise where we map
out who is the user what is the current
situation and how do we want to so what
is there the goal that we want to
achieve and help make their situation
better which is the to be scenario so
the as a situation today the application
is something that helps candidates who
are searching for jobs how can we
minimize some of their pain points
they're trying to they're trying to find
out information about the company
they're looking in many different places
to get that information finding out
whether is this a come is this company a
good fit for me am i a good fit for this
company what type of roles I should be
applying for all of those type of
questions are in current job seekers
Minds right so how do we help minimize
some of the pain points and help make
that experience better so our goal is
that with a sake we can we can do that
we can allow a sake to allow the
candidate to chat with Watson and ask
questions if they were looking for a job
at IBM how can they understand whether
they're a good fit for the company how
do we help minimize that gap and also
whether the company is a good fit is it
a good culture fit or not okay go to the
next slide so what we came up with was a
cognitive adviser it engages the
applicant
in conversation where they can learn for
these questions about the company about
a company's culture all of those type of
things in that one experience have that
available to them at the same time what
it'll do is it'll also look at their
information either through resume or
through answering some questions that
then analyzes and finds them best fit
jobs that they can then apply to and
Sandy will actually talk to you about
how we go about doing that in the
backend okay so as you can see here
these are the watson api's that are we
are using in this application so the
first one is alchemy language and that
is extracting the custom entities and
keywords from the conversation that all
of you are typing in as well as the
resumes that you may upload so please as
we were mentioned even earlier don't be
shy to pull this up on your laptops or
mobile devices and just chat with it
because it's meant for all the
experimentation as well as it learns
what you are typing in how we are
performing I'll share all of that
because we are saving it in our database
as the interactions so going back to
alchemy once it has extracted all of
that information it also combines with
it custom dictionaries because alchemy
as such is a general-purpose natural
language processing API it doesn't know
about the various schools in the world
doesn't know about the different kinds
of degrees that exist today and so on so
we built custom dictionaries to input
all of that information to a tool called
what's a knowledge studio and then the
custom model that was built from Watson
knowledge studio was fed as a model ID
to alchemy language API and then it was
smarter and could extract when a regular
as resume is uploaded as to where one
has studied what degree one has number
of degrees
what certification you have what is the
kind of work experience all of that is
factored in into really aligning you
with the job positions that are
available in a specific company so the
next piece of the application is
conversation and that's an important
piece because we are in a era of
chatbots
so we have to have a chat bot that can
chat with each one of us conversation
enables you to do that and we not only
process the sentences that you're typing
in and you could be typing in just like
I am speaking to you and we also keep
the context as we go back and forth in
the conversation with you and in
addition to make the application smarter
we use annotations so when your input
comes in we do certain processing on it
before giving it to conversation API and
when conversation API gives us what
dialogue to return to you we do some
post-processing on it using annotations
so that's how the application is working
and let's dive into it deeper so it
would be amiss if I did not at least
mention what we have been talking about
and that is Watson so Watson is our
cognitive computing platform and it
interacts with us like a human it
generates hypotheses based on evidence
and it learns as we go along so there
are no deterministic algorithms being
used it's all probabilistic algorithms
in play in Watson so that's essentially
what is happening in a nutshell and how
do we make Watson available to the
developers we have it on our cloud so if
you were to go to bluemix.net you would
see in the Watson category on the cloud
all of these REST API is available to
you and what we are using in our
application is this conversation a
and document conversion for converting
the PDF or docx format in which you
upload your resume into text that then
alchemy API which is what I call alchemy
language uses so we are using one two
three out of this catalog in our
application and we have made available
to their developers on github the Java
SDK for making easy to use these api's
so you also have a swift SDK Python node
unity and dotnet besides the Java SDK so
that's how we are making that available
to you and here's the architecture of
our application just as all of you are
accessing accessing the app accessing
this application here through browser or
your mobile phones it is running on the
cloud in an application server so that's
on the cloud and it calls out to
conversation with the input texts that
come in conversation in turn calls into
alchemy language which has been enhanced
with the custom language models the doc
the resume that you upload goes through
document conversion and since the resume
up for parsing to alchemy language and
the alchemy language is acting like a
resume parser so we have work experience
in your in our resumes the time interval
where we were for each job at a company
it is parsing all of that using alchemy
API all our interactions that are
happening are stored in Cloudant the
enhanced candidate object so the object
for a user like me who is using this app
is called candidate object so all of the
metadata that is the enrichment is
stored as a candidate object in Cloudant
and also there is a jobs object which is
coming from any job database that you
may use we are using this particular
jobs database from there we get the jobs
and we enhance them also by enhance I
mean add the enrichments that is extract
out the concepts of the jobs of the
requirements that each job position has
annotate I mean by annotation I mean
keep all of those concepts and keywords
as an enriched document and Cloudant so
Cloudant has two objects one is the
candidates object and the other is the
jobs object so that's the overall flow
for the application any questions so as
I was describing here are the two
objects the candidate has school degree
major work experience skills location
email address and lot more
similarly jobs has the primary job
category to which it belongs what is the
location or locations for that job what
are the requirements the skills that are
associated with that job work experience
that you would prefer to have for that
job and lots more so we look at these
objects in Cloudant so here i was
talking about annotations so i just
wanted to show you the code we have and
i can also jump into my eclipse ide this
may be easier for our eyes so what
happens is as you use the application
you will see that it will map what you
are asking to an intent called find jobs
and when the application sees that your
intent mapped is find jobs it will use
this annotation to say okay let me call
this method and do further refining on
it so I will go into the database I will
get the enhanced documents and search by
your interest and here the CTX is the
context object that is going back and
forth between you and the conversation
API so this object has
all the history in it and we'll show you
in the browser as we use the application
life and this primary job category is
another object PJ CS that is keeping the
job category so using both information
in the context the primary job category
and your input text we will return to
you the best jobs possible so I just
wanted to find out or point out how
annotations are being used by the
application once conversation says that
your intent is to find jobs we are smart
enough to intercept in the application
and do more work on it so we can give
you really the best possible positions
matching your requirements your interest
or your resume okay if you have uploaded
your resume and it's in your context
then we will do a better match still so
if this first if was the condition when
you did not upload your resume you were
just typing I'm interested in finding a
job in AI then we went by your interest
and AI was part of this context and it
was also part of the primary job
category but if you had uploaded your
resume we have parsed it and then we
will do a skills match based on your
resume so that's what is happening here
and there are many more intense like
find internships which are also
circumvented using that annotation so
this is just to illustrate how the
context this is the context object that
is the primary object that is used to
store information that you are entering
and give it to the conversation API back
and forth so this context object keeps
everything about the user that is me in
it so that's what I just wanted to point
out is the main link to keep information
that you are entering inside the contact
context object as well as get the
enhanced information from the database
and put it in the context object so that
this context object is really key in our
enhanced cognitive application so and
the reality is that you are talking to a
chat bot after all I mean you are not
talking to a human who has had years of
experience and can process things in the
brain on the fly
because we have so much experience built
into our brains you are talking to a
cognitive platform so some of the things
that you type I mean you may just be
being funny and you may type certain
things that the chat pod doesn't
understand so they will all go into
off-topic intent and the off-topic
intent will try to be very nice to you
and may have these messages in it I'm
afraid I don't know I'm sorry please
forgive me and so on and we can even
pick them up at random so that is that
is reality right so we I also want to
point out that we are calculating scores
in matching the jobs and job categories
and we use TF di F the inverse frequency
for matching how many times your skills
are there in the job position we are
mapping to so this is just to tell you
that we do the concept and keyword
extraction of your skills we do the
concept and keyword extraction from the
job posting and then we see how many
times this skill happens in this job
posting your work experience does it map
the work experience that is minimum
required in the job posting and based on
this complex scoring we get the job
score and the job category score so we
point out two things one is the major
category of jobs that are applicable to
you and then what jobs within that
category would be most applicable most
create for you yes yes very very
excellent point and that's where we are
headed as we are doing speech-to-text as
another API that we will pull in from
our catalog and you would be able to do
voice and that's not difficult actually
we have done it in fact I had a project
with devoxx community last year and as a
community project we had used speech to
text to talk to a conversation yes no we
can have text to speech to talk back to
and that also was part of that project
as well yes there is
so there's speech to text in the catalog
that I pointed out and there's text to
speech right and then you can apply
transformations on the speech to text
you can also train speech to text and
text to speech with domain-specific
language so just as we have custom
language models for alchemy API we also
have custom language models for our
speech to text so that it is familiar
whether it's FinTech world we are
talking about or insurance world or
anything else right so good question
thanks for asking yes well it's been
folded into natural language
understanding so what we are trying to
do is have a better cohesive service
available to developers so we make it
better and folded it into a natural
language understanding and LU and that's
in the catalog yeah the same
capabilities yeah same and plus more a
better yeah that's the intent so
anything else
yeah yeah definitely
so I mean it is okay these are the set
of majors that are available today and
then they enter their interest they
could just be typing in their interest
or they could be entering some document
which talks about the projects they have
done so far and there could be a mapping
right there very easy to do that and
today when it comes back with the
results it comes back in a UI not in a
text form so at least it is very easy to
visualize we will just see that yeah any
other okay so here is the enriched
candidate object so as you can see it is
of course when it was created at but the
main thing to look at is the user ID so
this is the user ID that has been
assigned to each person who is using the
app and this is what ties in from the
context context carries the user ID and
that will tie into the candidate object
and so they enriched candidate object
lives in Cloudant and context is what is
going back and forth between the
application and between the user and
conversation API okay so and then of
course when the candidate object was set
up all of this extracted data the city
the phone country school name degree
major years that that person has worked
his all of that was filled in that so
that is how the enriched candidate
object looks like in the database and
here is the enriched jobs object and you
can see that this is one particular job
has the title of financial analyst
description what are the required
experience which country which state
city
and so on so preferred education so all
of these are entities custom entities
that have been extracted out using
alchemy API yeah and you can customize
this to any domain using what's a
knowledge studio that we will demo okay
so this is just to show you how we call
on to the alchemy API and we would have
the anything that we are doing with
respect to this get concept and keywords
that is just going out to alchemy API
and tacking what it extracted onto the
candidate object so this is how we are
using the alchemy API just just to
illustrate that okay so I will before I
show you the demo I just wanted to share
to give you a feel of this is a instance
of what's a knowledge studio and these
are the custom entities that we added it
does not know what job titles can be
what degrees can be what a email address
can be so all of these were custom
entities that we added so that we could
build a custom model and then we also
added certain custom dictionaries of
different kinds of majors schools
degrees and job titles so that we could
then build a this dictionary and the
custom entities and then the documents
that were uploaded here we trained we
trained the model and by training I mean
we developed a algorithm now a real-live
algorithm is now developed which we call
a custom model which is pushed to
alchemy API using the model ID and we
will deploy that later on so that's how
you can work in any domain in any
industry using this scenario
so if this application is quite complex
somebody could be talking about a
company I want to know about your
company I want to know about the culture
of your company want to know the salary
range in your company on and on you
could be talking about a company and
then you would say yeah ok fine the
information you have given me sounds
like I might be interested in your
company can I try to find jobs in data
science what kind of jobs do you have
and so we would like to know about that
candidate before we can suggest jobs so
we will say to them well do you want to
upload your resume no I'm not really
interested in uploading my resume at
this point I can tell you a little bit
about myself ok then we ask them
questions what what is your highest
level of education where do you have
work experience so tying the simple
conversations about the company along
with asking them questions we could not
design in a single conversation
workspace so we came up with two
conversation workspaces the main works
conversation workspace is related to the
company and the other side conversations
are building your resume with questions
we ask you all right or if you upload
your resume then that is great we will
parse it so that's what I just wanted to
give you a feel for the complexity that
can happen when you design enterprise
cognitive applications all right so here
is a just a screen shot but we are going
to see that in in the workspace I think
I'll just skip these other than to point
out that these are what we call intense
right so there's intent for IBM stock
prize or there's intent for IBM culture
and so on but we will see this in in a
minute the main thing to show here is
that when we are training our
conversation API we have something
while intense entities and dialogue and
this is a very simple easy to use user
interface so the the objective here is
that we want to make cognitive api's
machine learning API is very easy to use
and have them robust enough that they
don't break on you so and we did this
java application development as an
example and it is live and being used in
the world just to share and show that
these are production ready so we define
different kinds of intense so that we
can parse out when somebody is saying I
want to know about your stock price
today has it been going fluctuating a
lot then that stock price word will map
to the intent IBM stock price so that's
how the machine learning works and we
train that a little bit which will show
you this is how we train it so if the
intent is find jobs then we will enter
some phrases can you recommend a job do
you have jobs for people got anything in
I mean somebody may be really being very
not in a mood to chat so that person
just says do you have you got anything
in so at the reason we you see these
phrases is just to train conversation
that hey when somebody types anything
like this so it this is parsing out
these words anything that is related to
job in it you should understand I'm
talking about jobs and when it sees
something like this or even a
resemblance to this recommend a job it
will map my question to this intent so I
mean this is what is happening is that
when you are typing in natural language
sentences it is parsing them out using
NLP algorithms and building a knowledge
graph so that is what is learning
so that
all the concepts that it and keywords it
has parsed out it has built a graph of
it and when some new keyword comes in it
references those knowledge graphs and it
is always learning so like a child we
also learnt word by word what our
parents taught us and we formed a
knowledge graph in our brain that's
exactly the knowledge graph that is
being formed in Watson okay so this is
how we've it's with just some five to
six five is a minimum number of
sentences or phrases you should give but
you can give as many as you like you are
training and making Watson learn yeah so
we we have very good question we have as
I said off topic right so if we cannot
really map to any intent so it will
follow a sequence and it also goes
sideways when an intent is map then it
goes sideways as well but it follows a
sequence if nothing is mapped then it
goes to anything else or true or
off-topic
I can I can add a little bit more there
to show the so this this pilot what
we're doing right now is it's actually
live an ibm.com US career site and we've
been getting tons of data right people
are already trying this and there are
many places where we're getting it wrong
or we're mapping it to the wrong intent
and so we've been looking at this in a
tight feedback loop going back looking
at the off topic like sandy mentioned
and also just looking at these
interactions and saying okay we just
completely got it wrong
these are some other types of questions
that we should go back and train so we
do go back and add more yes
absolutely yes exactly
yes yes I mean exactly so I mean that
adds another layer of complexity because
you have audio there so the tone the
dialect so we do have many languages for
which we have the capability to
recognize and speech-to-text API plus
also train for dialect so there is
training involved there too so yeah I'll
let you answer plus I'll add something
yeah so I it's not completely to the
point that it's super automated that as
you enter the conversation workspace is
getting trained it's a little bit more
complex than that at this stage so there
is a manual process involved where these
questions have to be taken in and we
kind of address it pretty much in a
weekly basis where we take these we map
these and questions that are we're not
getting them right into buckets of
topics and say oh you know what we need
to provide an additional answer here
because so many more questions are
coming in so on a weekly basis we're
training this and it keeps getting
better and better but we I think we're
getting to the point where we can start
automating a good bit of this as well
right so what is the training aspect so
any interactions and we will see in
Cloudant database where we are storing
all the interactions that are hitting
the application and also all the
feedback as well that people are giving
so that is being looked at daily plus we
have a testing framework a j-unit
framework that is also retraining and
testing retraining and testing so it's a
continuous activity I think we have one
more question yes
I can address that sure though we're a
very small team we're about eight people
total we have a team of five engineers
and two designers and myself I'm the
product manager for this application we
started in September of last year is
when we really started taking this idea
and started flushing it out we demoed
this at our IBM conference in November
end of October last year and we Pyatt
started with the pilot on IBM comm just
three weeks ago so it's been a very Lean
Startup methodology to take this further
and keep getting user feedback this is
the same team that's continuing to
enhance it and make it better and as far
as the impact to the hiring process we
don't have enough data and the timelines
we still need to work through it's only
been three weeks but you know we'll
probably start looking at that that data
is starting to come in of how the how
many people are applying and how they
are getting matched getting that and for
input from recruiters on how this is
helping as well
our first goal with this application
with this pilot was to get this out
there have people trying it both on the
conversation side and then there is a
matching side right to get feedback on
are we doing a good job with the
matching or not what do users thing what
can we show at the back end that yes the
matching is working correctly so we're
taking and we're tweaking our algorithms
as we go but I'm sure that within
another two or three months we'll have a
lot more data to share on this any
others okay so and this just to show you
an example on the screen but we need to
look at the live conversation workspace
is the dialogue nodes so these dialogue
nodes they need to be expanded to show
what they contain and I will show them
the point here is that the answers from
the conversation are contained in a
dialogue node so we have the UI as as I
was showing earlier we have this
you i with the intense entities and
dialogue so it is very easy to build
so the that interface we have given to
break the barrier for you to use any
cognitive API right so intense is what
you're trying to do entities is further
qualification on it so suppose I want to
locate where all your company is it's
sent where all the company lives in the
state of California so then with the
entity I can give the different
locations for it
San Francisco San Jose so on so entities
are used to further qualify the location
intent so that's just an example here it
is to show that we have the UI for you
to use conversation so let's dive in
right this is a convert example of a
conversation verse Asian dialogue would
look like so you would come in with
certain mapping from an intent you would
jump in to whatever needs to be done but
I will skip this because I want to show
life and I think I'm going through the
slides because if I switch to browser I
will have to end this slideshow so I
want to go through this and then show
this to you life I think we I will let
you now demo right and then I can show
live workspace
sorry conversation workspace is that is
the tooling that we are giving you for
designing your chat bot so in that
tooling as you saw intense entities
dialogue those are the three tabs in
that tool with intense you can define
find jobs
IBM culture Google pay salaries those
could be your intense that we have
defined so that if you were to enter a
text I want to know I want to compare
the salary range at Google with IBM I'm
putting myself in a hole but just as an
example then it will take out that your
intent is to find out about salaries
right it will map it to an intent called
salary and then you can have an entity
on that intent Google IBM so then once
you are going through salary Google
salary : Google so intent a salary
entity is Google it will take you to a
dialogue that will have the expanded
form the salaries at Google range from
XK to YK so that is the dialogue node so
all of this isn't a UI a tool that you
can build very easily so if you have
made pad available and that's what we
are using so this is the live
application and they so I'm just
starting to show I know I want you'd see
more of the details of their behind the
scenes type of things I'm gonna quickly
go through this so say I'm I type in I
want to know about IBM and brought the
debug console here so I can point out
what just tie it all in together and
this is the IBM conversation this there
were two conversation spaces that sandy
talked about this is the IBM
conversation because asking questions
about IBM and you can see the intended
map to here is IBM General right and
then the answer comes up about details
here you can give feedback here and let
us know just the answer meet your
requirements there's always tweaking of
the content that we can do and make it
better
you major I mean you can expand that
response to show what came from the
dialogue node
so in the output text yeah so this is
exactly what is coming out what you see
on the screen here is exactly what came
out from the conversation dialogue node
right there right sorry it's very easy
heart not not visible yeah I'm sorry but
maybe you can do ctrl + - a command + no
doesn't help better that's better that's
better yeah yeah so I mean all I was
pointing out is to tell you how this is
working is that the response that came
out from conversation is IBM is more
than just mainframes it's a worldwide
company is exactly what you see here so
this response came from the conversation
dialogue node which we had put it in the
tool I'm just making up a question here
that you might typically want from to
ask about so again this is just calling
calling that back this is the intent the
IBM employee review intent write it that
it map to because we had trained it on
employee review it picked that together
and said okay this is what the this is
what the answer's no yeah
it is I mean it's it's it's still an
ongoing process I'm not saying we have
answers through all the questions a lot
of the data is already on IBM comm that
you would be able to find so the only
thing is you have to go dig deeper and
find it we allow and we bring it in here
we want to get even more creative with
this where we can probably bring in
videos and multimedia and things like
that that would make it much more
engaging as an application but yes
absolutely well I mean yes sorry so I
mean these questions are very high-level
generic questions and we can go to or
bang the door or beg one person or a
group of people and get the answers so
that's it's not so hard it used it's not
it's not that difficult
thank thankfully thankfully yeah type -
sure why not let's let's see yeah and
that's why we want we wanted you to play
with the application is and this is
great
has IBM what happened what was it oh it
just it just give you a typical check a
basic coming no and it's as you know as
you know it's a it's something that
we're training on right Annie if it
turns out if you if you click on the
latest dialog what did it map to to IBM
history so it mapped to IBM history so I
mean it's somewhat semi intelligent in
the sense we haven't trained it for this
that question didn't occur to us so
sorry
yeah it's not sure but this is the best
intended could find for the for that
sentences IBM history and if it turns
out sorry
we may go down that road because as you
said it is a hard one to answer we can't
answer everything in the world right
obviously about I mean there's tons of
information what we could potentially do
one of the areas is to start linking
them to webs to other sites that or
either they can go to that site or bring
in a blur above that so that they have
some kind of news feed so to speak that
comes in right mm-hmm
could be so because it didn't maybe it
less why don't you type it and then we
will see what it mapped to right near
near San Jose
so actually because because of this
developer console who can't see it but
it's it's this way this is how it shows
their children yeah you you didn't type
in a comma CA sorry it hasn't learned
near San Jose near California
no no near oh sorry in Calif in take out
the in near San Jose California
it's a comma California yeah that's okay
yeah maybe it didn't it didn't pick up
the IBM location yeah so it just took a
random requirement into that because
they banned out San Jose as the bigger
part because yeah because it's a
randomized drop option right so here
it's saying I don't know how to respond
which one oh sorry so location like San
Jose it just okay IBM location it mapped
to that intent IBM location yeah yes it
doesn't know the state of British yeah
that's why not hard not hard it on
not a we know it just takes we'll take a
hardly a half a day to get the state do
you put in a dictionary of state
abbreviations and then the dictionaries
that I was talking about then that's not
useful yeah so that's why those
dictionaries can be easily uploaded
through Watson knowledge studio and
baked into the custom model and I think
it's a little bit on priority right
that's that's the most important thing
that you want to work on and you need to
ensure that we have some certain
questions that we need to absolutely get
answered we could go down the path right
now it's pretty open other time other
chatbots also have this capability of
just suggesting a certain set of
questions and answers maybe we go down
that path right big depending on what
are the different areas and types of
questions at beginning asked you asked
about the previous question about sexual
harassment cases if a lot of people are
asking of that question then we know
that that's a priority that we need to
fix right so we're never gonna get all
the answers yeah sure
exactly yeah that's what we're doing
right sure yep understanding
abbreviations mm-hmm yeah you can do
that right with the dictionaries you can
do that yeah yes uh yeah I mean these
are independent questions so there's
like nothing of the except some learning
that it has done internally nothing is
carried over yeah yeah comma see a
previous question right yes right yeah
you can so I can just go to the
conversation workspace right and so here
is the so this is the conversation
workspace for the IBM conversation we
are looking at so and here in in built
into the workspace which is our tool we
have a way to test out so our question
was what was the question how many IBM
locations are there is there and okay
near San Jose not yet no no not yet it
doesn't it it can't detect your location
at this point not yet but it is one of
the things we're looking at so it mapped
it to off topic intent so the reasoning
is well it's it no we would not be able
to show that because it is
other than going into the code here and
setting looking at the data being passed
we would not that's how we would debug
it sorry
yeah yeah and I think this is a very
good test case for us to definitely try
it so I mean we do have over here yes
yes I mean we do we do
so the interactions that are coming in
here this is one of the databases and
the interactions are coming in here it's
like this is the user who is who has
done this interaction his name and so
what the user what state we are in is
that it's like he have asked him to
upload his resume so but there is lot
more interactions the question was could
we look at the interaction that we just
did yeah I know I know I know and
because I mean this is one of the
Cloudant database it's not the one where
exactly this instance is going to yeah
so many reasons actually we can't share
that database so that's why we can't get
to it yeah yeah you would like to
that is very true and it is behaving
that way because when I don't type in CA
it goes to IBM locations and so that is
so yeah so the the the I mean this can
be just this a simple Java debugging as
well I mean it is not just it is nothing
besides debugging a Java app but it's
like okay what what method calls were
made I mean it is going through
conversation API for sure right
so here I think we have hurt ourselves
in the sense that if you did not have
our app doing the pre-processing so if
the app takes in the user input and
extracts the entities out of them so the
app has extracted San Jose and
California and location those words and
then we are feeding it to conversation
so our app is coming in the middle to do
that pre-processing if you did not have
that if you were just using the
conversation tooling you would have the
accurate answer so it is not
conversation that is messing up here
it's the app that is at fault and that
we can sorry we happen okay so in this
well you do I mean it's not that you
don't know that's not that you don't so
we are out of time
sure it's a good it's definitely a good
question to explore and I would love to
do that I think we're completely we're
at 12 now could we touch up on those in
the slides we could just quickly touch
upon the upload resume and you know you
can upload it you can do the demo okay
yeah you can do the demo I'll be out of
time yeah it's true oh you're completely
out of time well you can quickly upload
right you can find the jobs at least
there were the jobs would come back
right to that just upload a resume and
the jobs would at least some some things
that's okay that's what it was for and
that's an important point is the uh-huh
it is
because of the logging part you're
saying
so but if we knew why and which which
definitely we do it's just a matter of
pointing out how you see that but if we
knew why then we are on a clear path
right yeah so it's just knowing that why
that's that's the reasoning right that's
the key part so we can we had machines
to the maker
okay so I'll just end with we're looking
for feedback on the application so it's
looking at the matching and the what I
showed quickly was how we take a resume
and questions and answers and you know
recommend jobs that best match your
skills so there we have two places you
can do you can give us suggestions on
things we can do better
I definitely got one I need to work on
if there are others you want to pass
this on and how people try it give us
feedback would be wonderful thank you
for the time it'll come to me but I'll
give it to Watson
[Laughter]</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>