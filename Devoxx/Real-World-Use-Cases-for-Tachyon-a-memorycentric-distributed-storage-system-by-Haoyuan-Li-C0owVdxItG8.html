<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Real World Use Cases for Tachyon, a memory-centric distributed storage system by Haoyuan Li | Coder Coacher - Coaching Coders</title><meta content="Real World Use Cases for Tachyon, a memory-centric distributed storage system by Haoyuan Li - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Real World Use Cases for Tachyon, a memory-centric distributed storage system by Haoyuan Li</b></h2><h5 class="post__date">2015-11-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/C0owVdxItG8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yeah that's right that's fine okay cool
so thanks to be here actually I'm not
going to give this talk right so as you
can imagine so I only is their online
from SF so yeah hello so I will leave in
the ground between coats and okay go on
dude alright thanks Andy so uh hey guys
sorry I couldn't be here you either
issues so I'm going to give the hot
remote like to introduce Tae Kyung as
well as its use cases so here's a slide
so that the presentation is a to
introduce Tae Kyung which is an open
source memory centric distributed
storage system and I'm Holly from tech
MX's people also call me a twat so so
Who am I so I'm a co-creative attack
young and now i'm the CEO this company
called tachyon axis which is the company
behind keep pushing takia forward as
well so I was a PhD candidate from UC
Berkeley amp lab where I you know I
created tackle great idea as my PhD
thesis so lady by the company at the
beginning so tech and axis is a forum to
buy the team by the tekken creators and
type taking on top contributors and
we've got a series a funding from
andreessen horowitz and we are committed
to do the technical open source push the
tekken open source project and add a
button that's our company website and by
the way we're hiring as well so here's
alternative talk so at the beginning i'm
going to introduction to takia and then
i'm going to introduce some techniques
cases and the new technical features
were released in technion giro point 8
and emailed and talked about how to get
involved with this open source project
so let's start with an introduction so
here's a history of the Tachyon so we
started
hi quiana back at UC Berkeley and plop
from the summer 2012 which is like three
years ago it's the same lab produced
apache spark and party missiles and
taking up with open source on the second
year April under Apache 2.0 license and
the latest release is a version 0.8
actually 0.8 point to which is like
yesterday or today your time zone and it
has been deployed at more than 100
companies so here's a so the project's
growing pretty fast just to give you a
sense so here's a community growth of
the project so in terms of number of
contributors at the beginning for v 0.1
we had one contributors and then we have
three contributors in 0.2 then we had a
15 in 0.3 and then 40 30 in 0.4 0.5
around 50 ah 0.6 more than 70 and then
more than 100 and 0.8 we have more than
170 so so so now we have more than 170
contributors from more than 50
organizations and it's one of the most
fun is that one of the fastest growing
big data open source projects and I want
to use this opportunity to thanks to our
contributors as well as users and this
is a figure also generated on the taking
website if whoever contribute to the
Tachyon product it would be a bubble
showing here and the more you contribute
the bigger the bubble will be and on
bottom that's a part of the company
which are using and contributing to the
second project and there are some
recently reported usage like taking
fedora distribution is a default of
cheap storage for spark and IBM said
what the work they have done with
tachyon and the pivot on the emc said we
believe taken is a future played a
critical role for the did lake
architecture
yeah yeah I can hear you oh that's weird
okay can you see now oh yeah all right
okay so let me see if okay let me try
this way I entire screen so let me see
kya here can you see the difference now
okay great alright so a probable also
you guys from the very beginning but
anyway so here's a community growth and
it's a it's a lot of companies and the
contributors and it's one of the
fastest-growing project in a big data
equals ecosystem and here's the
contributors and the users you see that
the bubbles I mentioned earlier and here
are the companies which are contributing
and using takia and and this is our some
reporter usage in federal distribution
of TV storage for spar company using it
EMC IBM they or endorse the system and
doing work around the system so then the
question is was taken so it's open it's
an open source memory centric
distributed storage system so so here's
a from the stack perspective we're
taking on sitting in sac is this between
below tachyon this all kinds of a
distributed storage traditional storage
like HDFS like Amazon s3 opens that
OpenStack Swift SAP this and that and on
top of that you have all types of a
computation engine like spark MapReduce
like flink like Impala and and then the
question is why why use takia so here's
a trend so from the performance
perspective tacking is memory eccentric
and memory is fast run through to
increase exponentially every year and on
the other side this throughput increased
solely then you can see that memory look
energy is very important it's a key to
achieve met to achieve very low latency
interactive queries that's a performance
perspective then let's take a look at
the price price trend so during the past
like several decades drm costs decrease
exponentially so every 18 months the drm
costs decreased around fifty percent and
you can see that at early 2000 Wall
Street they started embrace technique
memory technology aggressively and then
in late 2010 elate 2000 you have company
like Google by do start to embrace
memory technology aggressively and now
it's the rest of the world it's like us
so this trend has been realized by many
say for example you have a spark you
have Hana in-memory database you have a
clutter Impala but the issue is still
not solved so what's still missing a
solution for the storage layer so so ty
can feel the gap take an enable reliable
data sharing and memory speed within and
across computation frameworks their jobs
so how does taken work and so from a
high level here are two features that we
provide at the beginning so one feature
is a memory centric storage architecture
and the other feature is lineage in the
storage layer and there are many more
features nowadays but I'm going to talk
about talk about those briefly in there
in the later slides so here's the
architecture takia it has a single
master with which keep striking the
location of data as well as monitoring
the status of every single worker node
and also has a workflow manager which
manages the lineage information on every
single worker node we run a technical
work a demon which manages a local space
as was responsive the remote i/o
requests and beyond the taking
work a demon we also run around this
which store the real the real amurri
data' and then we have the tech inclined
and also we have the locality you access
this run this directly without going
through the orchid demon to guarantee
the memory performance so that's a
worker side and of course the worker
also periodically reports to the master
about his status using a heartbeat and
then after the the architecture we also
have the lineage in takia which
basically describes the relationship
among different files or data inside
that idea it is particular example you
can see see for example you have a fuss
at a and you have a spark job r is a and
generate be and then you have another
spot job rician Jenner d and later on
you have a MapReduce job r is B and D
and January and tech can remember this
information reliably and this means that
when this application like spark jobs
MapReduce job when they try to rise too
when it tries to try to write to tachyon
the only right they only need to write a
single copy the data inside the tycon
space Hegins memory and then if added
data got failed technical will be able
to relaunch the necessary computation to
a gather data back that's how the
lineage works in takia so say in E if i
SAT ii failed taking us to use B and D
and mark these job to recompute it and
get it back so that's that's a basic
very high level overview of the attack
young a project and then let's talk
about some use cases so let's first use
spark as example how tackling works with
spark so spark is a fast and general
engine for large skillet processing so
it's great it has been deployed in many
companies but there are still issues
cannot be resolved using spark say for
example the first issue so in many
companies you have this complex did I
did an Alexa pipeline and
way you do it is you have many jobs
inside of it so one jobs output would be
consumed by another job and the system
use like Amazon's three like you Apache
HDFS to do this data sharing so you need
particular example on the left side the
spark job one writes the data into the
storage and loaded by the spot job too
so even though a single spot job
computation could be fast for the whole
pipeline is still very slow because in
the insuring process is so that's the
first issue and then the issue is
further more complicated say in your
cluster you may have more applications
like more than spark you have MapReduce
applications how to share the data
efficiently among these different
computation frameworks is a isn't more
is it a is another issue as well so we
Tae Kyung basically the way we address
the issue is that basically we just use
tachyon in the middle and these
applications just interact with Tae
Kyung to get a memory speed so you can
have them very fast memory speed it's
sharing so the problem it will be
resolved that's the first first issue
and the second issue is memory in many a
memory computation engine nowadays like
spark they share we use the same process
for the storage engine and execution
engine so then you have the issue that
if the storage engine crosses you also
if the if execution engine crushes you
also lose the data in your search engine
so you either recompute it or the load
of data again from outside storage which
could be time consuming in this case the
solution is also put attacking in the
middle and put the data in tag here in
this case if execution engine crosses is
still fine you have the data in taking
that next time you can load it from
tacking edit memory speed and the third
issue is can see there a simple example
like you have two different applications
like to spar jobs want to process the
same data
so how do you do this nowadays you have
to load the data into different JVMs
into the different applications then you
have the America duplication issue and
and also these applications run on top
of GBM you have a serious dubbed
collection issue we have a lot of data
which can scrub the performance how do
we solve this issue so still we have the
data we set in tight on space and these
different applications you can all load
packings memory at attacking space at
the memory speed and there therefore
there is no environmental data
duplication and also these applications
to load the data from Tigers memory as
the off the heat storage you have much
less garbage collection issue as well
great and here is a production use case
say it's a public use case by two which
is a dominant which is a dominant search
engine in China say they use spa SQL on
top of takia and under takia they use by
dual file system and you use tachyon to
manage two layers both memory layer and
HDD layer in the compute cluster and
then leaves taken to manage more than
100 100 notes now it's like around two
hundred and more than two more than one
PB our space storage space and when they
use taking out they have money they have
30 times performance improvement so one
query like example they gave normally is
that there's one query so which it took
like 1200 seconds to do the two process
which is like 20 minutes and that's was
using MapReduce without easy takia and
then they switch to spar and there the
time reduced to 300 x 300 seconds so
which is four times faster and then they
take it into the picture and it further
reduce the time to be like 10 seconds so
which is another 30 times
foster so in total is like 100 times
faster so that's the use case production
use case by baidu and then there's
another use case this is a the company
the sauce company they are using impala
in top attack young and undertook young
they managed they use as 3 as a
persistent storage and the you stankin
to manage post memory and SSD and they
got 15 times performance improvement and
so that's the second use case and the
third one is the oil company and they
also use spark on top of takia but under
tachyon they use cluster file system and
the use taken to manage memory only and
this enable taken to manage data in a
traditional to analyze data in a
traditional storage system and the
fourth one this is another test company
and they run spark on top attack young
and then underneath they run I three
storage and for the use taken to manage
SSD only but they also have elastic
deployment for tech as well and that's
some use cases in Tokyo so the the next
section talk about the new features in
takia which will beat you up develop so
we just announced the Tachyon 0.8
release in october a 20 second and this
is our wrist we have a much longer
release note describing the features but
now i'm going to briefly talk about
several them and also we have
maintenance release 0.81 and 0.8 point2
and recently as well you can check them
out so first of all it's a fast growing
ecosystem so now you can use different
frameworks on top of tachyon and also
enable were closed on different storage
so what does this really mean so to the
under layer to the underlayer storage
layer so the benefit of using takn is
first of all it enables new work clothes
you can do on top of different storage
secondly it boost the performance
if you can say that's the benefit to the
lower layer and to the upper layer for
these different types of frameworks or
the users by using takia if you program
against takia firstly you can enable you
to access data or store data in many
different type of storage so you just
want ur face you can access them all so
that's the first benefit the second
benefit is that by using tachyon you can
also like it get the significant
performance improvement like the
examples I mentioned earlier like fight
you then improve performance by 30 times
and on top of that you can also share
the data among different frameworks
efficiently if you have the environment
that's going to be more than more than
one jobs or 101 frameworks it now or in
the future and also just one point I
forgot to mention and for the under
layer you can access different storage
systems at the same time at the same
time in a unified namespace which I'm
going to talk about in with detail in a
later slides that's the benefit of using
the system every using tachyons system
so second feature is that we have a
tiered storage concept as you can see
you have memory in the normal like
storage hierarchy your memory SSD HDD to
the bottom you have a better you have a
larger capacity by you is slower and to
the upper you have the faster access but
you have a less capacity and it's more
expensive and now i can manage is more
than 0 so we can manage the SSD HDD all
the same time so you can have like a
much larger space say like invite you
example they have pb's of space managed
by Takya this is tiered storage concept
and of course you have the pot you can
have the policy to manage these
different layers for example how to
evict eight a from upper layer to lower
layer and how to a local its advocates
face in the same layer or or two they
promote data to the our player
it's all policy-based and you can
configure the storage tiers in different
modes as well you can say I want to use
memory only manage I don't use taken to
manage memory or lay or use taken to
manage SSD only or memory plus SSD or
different type of tears configuration
and also this is the policy i mentioned
and you can evict the data to a lower
layer promote to the hard data to the
upper layer and this is pretty important
because the different companies they
open have some data more important than
other data you want to keep those data
in the IP layer as well so let's say
that's the tier storage and another
important feature is the transparent
naming so this feature means that so you
can see taking out these I have taken
namespace and I'm detecting out you have
the Unga storage say HDFS or Amazon s3
and you have to configure to configure
taken with the paired with a or more
than one persistent storage and
previously attacking and store the data
in a persistent storage using some like
a naming convention only understood by
taking out so now we'll change it say
you put the data in taking us a
particular example particular example
you create a folder called data in Tokyo
and you create a file called the reports
or in you cutie file called cells inside
of the data folder and correspondingly
in the under storage you were saying you
similarly you have the folder called
data and you have another folder called
reports and the file called reports on
the data folder and you have a file
called the sails under the data folder
as well so this is very important
because now beyond using tachyon and
using different ways to access data
through Takya on top of it you can also
access those data using other system
like some some other applications access
the youngest or directed a just in case
some api's and
us are not supported by tackling yet but
if you want to get the performance of
course we can propose other AP is you
can access those data as well so that's
the transparent naming and be honest
this is the unified namespace which is a
very important feature and critical in
many environments as well so you can
mount different multiple on the storage
system in tachyon space namespace arm at
the same time it's on the fly on the fly
and we can share the data access across
different storage systems and its
particular example as you can see like
you can mount the taken root namespace
in the HDFS like using HDFS and then you
want you say okay for the folder data
folder I want to mount it like I want a
month as3 a storage on to the data
folder and and you can access and you're
from application perspective perspective
on top of takia they only see the tekken
namespace they don't need to worry where
the data really is so the virtualized
this namespace in a unified way and we
have some additional features as well
say for example are you can say
previously in takia you can only do
local tachyon names but no local taken
right but of course you can always write
to the persist under storage all the
time but now we also support remote
right say for example when you have the
local space is full and you haven't
evicted data out yet so what the system
can do it will write to remote taking a
storage like like transparently to the
upper application so and then another
thing is we improve the deployment of
takia so previously you can only do a
standalone taking a deployment and now
you can use one command to do mesos
deployment taking on top of mesos or
yarn deployment to run takia to launch
take it out on top we are too
be easy to be managed like in different
cluster or production environments and
also we have the initial like security
report a support and in next release
this will be enhanced as well so this is
some security feature wagons have and as
I mentioned you have this one command
like deployment and also we use vagrant
222 better like support deployment as
well say you can't apply tachyon mean I
ms3 in in virtual machines are using one
command and this is very good for
developers as well because you can do
that you can deploy tank young in your
laptop be using one command and create a
cross training environment like several
to virtualize it like several machines
so this is very important to developers
as well so also we have matrix can be
reported for taking coins taking workers
and taking a master and this means that
you can use your favorite like closer
monitoring tool to monitor how attacking
and perform or how healthy the technical
system is your cluster ok so that's
basically the features are new features
we have in in tachyon in the most recent
release and next section welcome talk
about is how to get involved with the
Tachyon system so so you can see we have
a pretty big like ecosystem and we
welcome like users and collaborators and
say if your users you can if you have
any question you can go to our user
forum to ask questions and you of course
you can email us as well and also from
the collaborating perspective there are
different ways you can have like if you
are a free work developer you can
integrate your frame work better with
title in that case you have better
performance and also and also access
different storage easier as well and
below tacky out you can build a more
efficient connectors between different
traditional storage with taking as well
to make your storage being accessed by
more different workloads and of course
if you want to develop a consistent
myself it's very welcome as well so we
have a lot of JIRA tickets in our
current system and you will have new
contributor tickets like beginner
intermediate and the best so we have
four different levels and in the end we
have this slice we have these links if
you want to know more about tachyon so
you can try tachyon I you know you can
try taking on going our to our website
you can do about taking on this out
github you can if you come to the bay
area we have meet up websites our last
meet up have more than 300 people send
up and this is our company website and
that's my email um that's that's pretty
much it and I'm happy to take questions
I know I there is it I had there is one
don't go don't go hello I wonder aloud
and I wonder how you deal with kerberos
authentication dacl in with the hdfs
system and tachyon how do I deal with
how how do you how do you keep the
access do you have issues or is it occur
correctly working so I'm sorry so how do
I deal with when you most when you want
your gfs with ha how do you keep the SEL
within the Tachyon the users search mode
and so on the the right define in your
system's HDFS to tachyon yeah ok
oh icicic okay okay so how if you mount
a volume how do you keep the ACLS so
yeah so that's a great question so for
now when you mount a ND storage on the
storage so a detecting layer at the
titan layer we cannot keep the ACL but
in a folded in the following release
like in Japan I as you can as you can
see imagine earlier we have the initial
security report support for 0.8 but 40.9
we're going to have a much better story
there but now if you mount on the
storage base plate the data will be able
to be accessed by anyone okay the second
Christian how do you deal with Kota how
do I deal with what Kota Kota yeah
edition so yeah that's a great question
as well how do we deal with Kota so for
the under storage under storage has
their own Kota limitation so that's
that's their story but forum title in
perspective the short answer is now we
don't have a cota system so basically
anyone will be right into takia they are
treated as a the users one single kota
which is a like a capacity of the sort
attacking system but like we we also
have the Kota on the management on our
road map thanks for the question that's
a great one anybody else doesn't look
like um yeah actually by the way I shall
I think it there is no other questions
so I guess we're down okay wait wait
wait wait still one
hello a spasm distant and tachyon is
memory like Cashin memory for file IP
eyes and how do you deal with cash in
the lead asian memory invalidation how
do we deal with memories vegetation
memory allocation no invalidation based
on radio caching system actually is
persistent behind so I didn't hear the
last word how do we deal with a giant
meaning haha I can hear you clear click
Andy when you are here scratching a
validation oh I see I see so first of
all first of all technically is not a
caching system it's a it's a source
layer and we provide a file system API
so it's a me if you like you can choose
to use tie Qiao as a caching system but
we provide functionalities much more
than catching and regarding the
invalidation so the semantics were
facing now is the youngest storage we're
seeing is right only semantics say for
example basically if you mount the space
will be managed by takia right so in
that case we do not expect like far
update those type of operations and this
is true this assumption is valid say for
example for systems like Gloucester for
a for system like HDFS or Amazon s3 or
OpenStack Swift so that's that's our
this our assumption and and if you
really change modify the files and for
now we cannot do much about it but we
may have been mechanism to detect that
later on that's a great one
anyone else yeah hello in an underlayer
system how do you deal with alert if you
lose one or if it's getting too slow no
the underlayer I'm the high European
fashion um I'm going so how do you deal
with latency with the right in the back
end underlying system i see yes so this
is a great question as well so we would
do it right there are three different
majorly majorly three different ways in
takia so one way is if you don't care
about the persistency you say I only
want writing to take on space if it's
gone it's gone that's a one-way the
second way is that if you want to say I
don't care about the performance i can
say i can choose i righted it into
tachyon in the meantime I also write
data like synchronously like take him to
write data into under storage in that
case you have a slower performance like
not very slow but the same as the same
performance as using under storage
directly for right but in that case you
also have the persistency as well as a
second right second type of right and
third type of right is that you you use
the lineage feature or asynchronous
right feature in takia say basically you
use the API and you say I right into
tachyon and take down with asynchronous
lay flush the data into the under
storage and the what you want to call
the lineage API to guarantee the fault
tolerance that's a third way so
basically there are different ways and
depends on the environment and the
requirement I guess the question is that
if you're in streaming and ruin my night
and you can't you don't have really
can online hedge capability you cannot
really hask back to data that you had
right so if you lose the connection with
let's say HDFS behind and you don't have
this capacity to get back the data from
the sources oh icic i think the mark
pump is lost yeah let's see it's lost
yeah I see so for now we don't have a
solution solution there but like the
assumption now we have is say say if the
one month point is lost so all the
storage in a month point will not be
accessible but a player but the
assumption we had was because it's a
persistent source persistent storage
layer so normally the data should be
still there in the inner under storage
because that their whole job but if in
any way like data is a the networks is
done so we cannot access data Tom freely
in that perspective
cool I may have one question when you
read data so you can cash directly data
from spark to tack on right yes yeah and
you can save it is there an easy way to
read the data back from another spark
context right now yes so they are
majorly three different okay you can say
two different ways for spark to interact
with die again so one way is you use
like thi ki down to encourage the rdd in
a spark format like in smart internal
format so in that perspective you can
say like smart rdd cash or persist and
you can say i'll keep and then the data
will be put in tachyon directly and but
that's a temporary storage in that
perspective and that data cannot be
accessed by another storage spot
contacts at at the moment that's one way
and the second way is you can use spark
to interact with tachyon and seat ikea
as the file system and interact a key as
a file system you still will get a
performance gap benefit and in the
meantime it's much easier for other
applications to access the same data
because it's just a file from the
outside perspective yeah you can use for
up to read the file load the file save a
file and other stores the other
applications save a file a lot of file
whatever they want yeah so the idea is
to have a data source API implemented in
spark for instance here we can access it
and we may also store it as parque so we
keep the ski mother I see yeah yeah so
that source API is another one so we're
also investigating that part as well
that's a good one yeah okay
we're done okay looks like cool vintage
white all right thank you guys yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>