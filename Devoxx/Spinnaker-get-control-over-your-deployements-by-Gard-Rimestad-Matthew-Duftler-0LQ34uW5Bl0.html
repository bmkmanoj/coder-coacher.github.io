<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Spinnaker   get control over your deployements by Gard Rimestad &amp; Matthew Duftler | Coder Coacher - Coaching Coders</title><meta content="Spinnaker   get control over your deployements by Gard Rimestad &amp; Matthew Duftler - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Spinnaker   get control over your deployements by Gard Rimestad &amp; Matthew Duftler</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0LQ34uW5Bl0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and good morning this is Matt from
Google and I'm gutted from shipstead my
manager told told us to introduce us
with companies so I'm doing that for him
and we are here to talk about spinnaker
and how spinnaker can help you deliver
your applications to your rental
environment in a very nice way and has
anyone here heard about spinnaker before
going here wow that's a lot of hands has
anyone tested it very good feel free to
ask us questions while we present and
we'll do our best to respond to them so
I'm jumping straight into a pipeline
screenshot this is a actual pipeline
that we're running in our company and
this is kind of a typical simple
pipeline in spinnaker all the circles
you see here are stages in the pipeline
and the fields you see listed down here
on the left side is is tasks within a
stage a typical pipeline has a trigger
most of the pipeline's we use have a CI
trigger that means that the pipeline is
started based on a finished build a
successful build in the CI system
currently Jenkins and Travis is
supported in spinnaker and the CI build
produces a dead build artifact or rpm
artifact which is then picked up from
the CI system with the concrete version
of the Debian artifact or the RPM
artifact that is being uploaded in from
the CI build and then the bakery in
spinnaker uses that concrete version and
installs that to your image or
container that you want to run in your
real-time environment
so once the bake has finished the
deployable artifact is is the image
reference to either your container or
your image for your rental environment
then we deploy this image to the dev
environment and this this is done in
several way you can select various
strategies Matt will come back to how
what kind of strategies we had for this
but in this case we are using with the
red/black strategy which is actually the
same thing as Bluegreen just different
colors when the deployment is done and
the dev environment is healthy we go
over to the verification stage to verify
that the deployed artifact is ready to
run in production in this pipeline we
have a manual judgment stage that means
that the developer or the tester or
whoever it needs to test it before it
can go to the production needs to sign
off on or in spinnaker to say that this
is ready for production
this can be automated by using
integration tests or Foreman test or a
combination of all of that spinnaker has
integrations to various authorization
providers authentication providers and
and your name is put into the judgment
stage so you can always see who approved
this for production which is nice when
you have a production issue then after
the verification stage is successful we
start deploying to production a
production deployment is just the same
thing as as dev development the
deployment the test environment
appointment but it's targeting a
different cluster or account or whatever
you use to defer production and the next
stage we have here is a data dog
and that's something custom to our
organization but we are using a generic
stage in spinnaker which is the web book
stage so there's actually a generic rest
call to do whatever endpoint you want it
to target and we have a service that
takes up the deployment events and
stores them in dated or guess events for
that application this makes it possible
for us to like when we were looking at
data door graphs we see when the
application was deployed and we can
correlate like incidents and changes in
graphs to actual deployments it's
convenient and makes it very flexible so
let's backtrack this a little bit so
what does spinnaker mean spinnaker is a
sail you put on the racing yacht to make
the yacht
go faster you're still having the same
exact yacht but you just add the sail to
it to make it go faster when running
before the wind and this is kind of the
mindset within spinnaker as well so
spinnaker increases your velocity when
you're working with the cloud and it
does that by by embracing the features
in your runtime environment so spinnaker
doesn't run the smoke tests or do stuff
like that it relies on the providers way
of handling infrastructure and just
gives you a common way of handling
deployment strategies and cluster
management on top of the provided api's
so one example of this is a kubernetes
so kubernetes has its own way of
declaring what the cluster is what how
to present the health or represent
health and load bouncers so this is a
kubernetes replica set which is which is
called a server group in spinnaker this
is
set of pubs and the health provider of
pubs is like Burnett's has a interface
to see if a pub is healthy usually use
lightness probes or redness probes to
kind of see that it's healthy and
spinnaker just uses the kubernetes api
and fetch this information from
kubernetes itself and this is what you
see on the right side here provider up
this is that the pod itself is healthy
on the top right corner you have this
load balancer icon and one hundred
percent healthy and this is service
object in kubernetes is translated to
low bouncer in spinnaker as Bailey uses
the status of your service object to
resolve if the instance is receiving
load or not so as you can see we're
building on top of the kubernetes
features in order to control deployments
and health status of your cluster so
this this next example is a from ABS
it's a ELB a old scaling group which has
a TLB attached to it or the boat scaling
group is attached to an EOB so on the
right side you see that the health is
being set by it it's the application
being healthy in the low bouncer because
the low bouncers in ABS has a health
check so the feature of checking that an
instance is up is within abs and spirit
just leverages this so this the same
kind of strategies can be applied to the
ABS clusters which are which are
controlled by like deployment strategies
just using the health provider from the
EOB
instead of the the service objecting
cabinet so it's the same experience the
third kind of health check or state this
thing in spinnaker is the service
registries like Eureka
like consume spinnaker integrates
against those as well so you can have
Eureka as your health provider and it
does the same thing but Eureka is not
tied to the cloud provider itself it's a
separate provider for representing the
health and controlling the the load of
your application if it should be
consuming a queue or being load or
whatever so spinnaker does the exact
same thing here and and uses the API of
eureka or console to resolve the health
status so spinnaker doesn't run the
smoke test itself it relies on the
underlying infrastructure to do that for
for spinnaker on the behalf of spirit
now Matt will take you through a little
bit more details about that how this
works
all right thanks card I've lost my voice
a bit I'm not gonna yell and hopefully
can hear me okay so guard mentioned
deployment strategy so let's take a look
at a few common deployment strategies
we'll go into a fair bit of detail kind
of the pros and cons of each the goal
here is not to say that these are the
only deployment strategies or to
recommend using one over the other just
to give a sort of overview that it's
flexible you can create custom
strategies you can use built-in
strategies and to make the point of how
these strategies leverage the underlying
cloud providers native capabilities so a
pretty typical approach guard mentioned
this red-black deployment strategy the
idea here is you have one version of
your software running in production
typically running in a server group
containing some some instances some
similar servers or VMs or containers you
want to roll out a new version you would
provision a second server group same
size as the original server group of
running the new version of the software
you wait for the underlying health
providers so this would be load
balancers discovery services the
platform
whatever's reporting health to report
that the newly provisioned
infrastructure is healthy once it's
healthy you cut over all the traffic
from the old server group to the new
server group at that point once
everything's healthy once all the
traffic has been cut over you can stop
sending requests to the old server group
it had end up in a disabled State which
roughly means not taking traffic from
discovery services so internal callers
load balancers external callers and if
there are scaling policies and other
things that are configured those are
typically disabled as well the goal of
this is to get the new version running
do it once the underlying systems report
that it's healthy but leave all the old
infrastructure around so you can quickly
roll back if something goes wrong you
don't want to have to reprovision
everything in case of an issue so that's
a typical red-black there's a more
advanced version of this called a
rolling red-black which is quite similar
the primary difference is instead of
cutting over all the traffic 100% you do
it in in finer grained increments so
maybe a percentage based approach our
time based approach so say first 5
percent 10 percent 25 percent and so on
you would often get these additional
increments with some sort of
verification or functional test so roll
over some of the traffic beside besides
the underlying providers reporting
healthy you can run tests against the
new infrastructure once you're satisfied
turn the knob further and it keeps going
and all this can happen in an automated
fashion a benefit of doing the rolling
red black said since you no longer have
to provision a full-size server group
with the new version of the software all
at once to cut over everything 100% you
can be smarter and how you provision the
new infrastructure so maybe do it
several instances at a time maybe you
start to destroy old instances but leave
a certain number around that the main
goal is to do it gradually gain
confidence as you continue to cut
traffic over and maybe consider things
like capacity management door costs a
third type and this is really the you
know the more advanced end of the
spectrum would be a canary based
deployment strategy quite similar to the
rolling red black the primary difference
is that instead of a functional or
verification test at each increment or
gating each act increment you would run
an automated canary analysis at each
increment and what this does typically
is consider underlying metrics so
typical deployment your infrastructure
and your applications are recording
metrics to some sort of backing dilemma
restore Prometheus data dog stackdriver
Atlas there are many of these and an
automated canary analysis tool which is
in the works here and should be
open-source shortly I'd hope can
consider these metrics you can configure
how you want them considered so you can
give more weight to one or the other but
an automated fashion can say this does
or does not meet our requirements taking
into account underlying things like CPU
utilization memory utilization latency
error rates response codes all those
kinds of things as well as business
metrics whatever custom metrics you
define it's quite generic and it lets
you at each step say here's what a human
would look at if they had to do it
manually but we've got another point
where we can automate this so let's use
that to gate the increments as we do a
progressive rollout alright next so
guard mentioned pipelines mentioned
stages let's look in a little more
detail
the thing to keep in mind the pipeline
is the top-level construct that's
available in spinnaker to build your
automation it's composed of first-class
stages that's what you see here it's
what you saw in guards earlier slide
this is a pretty simple example even
though it's made up just for the slides
so if something kicks off a pipeline
there are many ways to trigger this it
can be a cron job it can be a CI job
completing another pipeline completing
you can programmatically kick it off
manually kick it off a bunch of these
things right once a pipeline kicks off
you can have potentially multiple
branches in this case there's one main
branch and then several branches that
that join back together but the first
stage there is a find image a lot of
pipelines that you see in spinnaker make
it very clear that the thing that you're
testing and promoting is the image it's
not a jar file or a war file or source
code it's an image it's a baked artifact
so a VM image a container image some
sort of deployable asset that won't
change throughout the testing and
promotion so in this case we're
resolving an image we decide to deploy
to a new environment with a red-black
deployment strategy which will dig into
in more detail do some tests do some
kind of weighting scale down the old
production but don't destroy it yet wait
for some other additional approvals wait
some longer period of time
then when we have a lot of confidence we
can eventually destroy the old
infrastructure since we're likely at
this point not going to have to rollback
one of the key strengths of Spinnaker's
at these stages look largely the same
from the pipeline construction point of
view regardless of what provider you're
targeting so if you're targeting AWS so
kubernetes or OpenStack cloud foundry
Azure GCE app engine whatever oracle
bare-metal cloud lots of integrations
whatever underlying cloud you're
targeting these stages look mostly the
same the the common concepts look the
same across the clouds when you get into
the fine-grained details it starts to
look different but the idea is it's it's
a common experience once you know how to
do it for one it works for all the
others and you can mix and match so you
often see pipelines that do a bunch of
tests and then slowly fan out and start
to push out the newly verified code to
different clouds or you know different
clusters that kind of thing so looking
at one stage so the notion of deploying
seems fairly straightforward these
stages look like atomic things but but
in reality they are composed of finer
grained steps so in the case of this
deploy would the red/black strategy
configured it breaks down to a bunch of
steps there's a deployment step there's
a shrink cluster step disable scale down
and we'll look at what each of these
means but picking just one of those
disable cluster even that decomposes
further into a bunch of individual tasks
so the first one is determined health
providers this can be do i of eureka or
console configured by just looking at
the underlying platform health drive
load balancers configured disabled
cluster it essentially restricts the
number of active server groups in that
cluster to whatever you configured in a
red-black configuration and then there
are various monitoring steps and what
that's doing is it's essentially saying
make sure the underlying cloud provider
has done all the work it can at this
point so I can't get any other further
information from that in-flight
operation it doesn't say that it
completed successfully it doesn't say
anything about the resulting state it
just says I did all the work I can next
we say update the cache what makes all
this responsive is that they're various
agents running in the background to
build graphs of the resources that
you're managing with spinnaker so
there's some tactical updates of that
case
in the background then there's a thing
that says now wait until the desired
state is achieved so the earlier step
just said do all the work you can then
it said start to update everything so I
can I can have a responsive interface
and the final step says okay now wait
until it achieves that desired state if
the desired state was to disable some
set of infrastructure the wait
is saying wait until all of the health
providers say yep it's disabled it's not
taking traffic it's not being served up
as an endpoint for internal discovery
services it's not auto-scaling
whatever the desired configuration is
this this is what verifies that it was
achieved and the last step is again to
update now that everything's been
completed if you look at disable cluster
this actually decomposes further those
are actual cloud platform operations so
forwarding rules target pools remove
instance each of these amount to several
platform operations so you can see
looking at the top-level pipeline where
there's a step that looks our stage that
looks atomic which is just deploy do a
red-black it ends up as many many
low-level tasks against the platform and
what we tried to achieve with this is
that it's not that you don't have to be
familiar with the underlying platform
but you don't have to be hopefully an
expert in every single nuance of every
one of these low-level operations if you
look at the API is that the underlying
cloud platforms provide each API is
simple enough but when you get to the
point of wanting to cobble them together
and do something more complex
it does get difficult and then
reapplying that same work to a different
platform is is almost a an exercise that
starts from scratch so we try to give
like a common experience without
requiring a like a pure abstraction it's
just a common experience the underlying
details are different all right so I'm
assuming I'm still on the network I'll
reload sure okay so we want to show you
what it looks like running will do a
live demo one thing I wanted to point
out before we get into it the demo that
we're doing here was configured and
constructed and even really the script
of what we're going to do is all taken
from one of their code labs or tutorials
that we have on the site so the
spinnaker dot IO site has a whole bunch
of tutorial
focused on a bunch of different
platforms this particular one takes a
user from scratch through provisioning a
full spinnaker installation on a VM
including a local Jenkins instance local
git repo with a simple hello world
application and then configure pipelines
kick it off experiment with the results
in all that so I'm really following
without deviation a publicly available
tutorial on how to get started and try
all this out as we get into it I just
want to kick off the Jenkins job the job
completes very quickly it packages up a
simple Java app and publishes a dead
package to a local and genetics backed
Deb repo ethica tactically we're using
but it's all on that same VM so I'm just
gonna run this because it takes a couple
minutes once the pipeline kicks off to
provision the new server group so let's
do a quick tour of the UI there's some
terminology that'll that'll need to
sound kind of familiar as we get further
into it so the UI after you play with it
for a few minutes you realize there are
really two sides to it there's the cloud
management side which is this clusters
view the load balancers view security
groups it's it shows you a rendering of
the infrastructure you have under
management and lets you perform a bunch
of ad hoc operations
these can be clone operations destroy
resize delete whatever terminate you can
isolate things for troubleshooting
create new things but their ad hoc
operations that happens in an
interactive way it's as you work with
the user interface those things happen
for you one thing to keep in mind is
that everything you see from the user
interface whether it's rendering things
that pipelines are doing in the
background or things that happen in
response to us interacting with the user
interface this all happens via an api
gateway so 100% of what we're doing can
be done the same way with the api is the
UI is not doing any magic so this is a
clusters view there are two clusters
here the top one is um it's just code
lab - prod is the name of the cluster
the bottom one is code lab - test -
arbitrary names but the way to think
about this is a cluster there's a
logical grouping of server groups a
server group is a logical grouping of
instances above clusters you have an
application this whole application is
called
code lab the terminology is overloaded
it's probably not great terminology but
but that's what we have so don't read
too much into the terms cluster or
application just what an instances
depends on what platform you're
targeting in this case I think I only
have GCE configured so sorry it's just
the Google cloud configure the instances
in this case happened to be virtual
machines if you're using kubernetes they
would be pods the server groups again a
platform dependence so if you're on
Amazon it's an auto scaling group if
you're deploying the kubernetes it would
be a replica set for GCE it's a managed
instance group it just depends on the
underlying infrastructure so poking
around here this cluster has two server
groups this cluster has two server
groups you see there are different
version numbers here so if we click on
one of the server groups in the code lab
test a bunch of details it's the kind of
stuff you'd expect what network are the
instances in the server group attached
to some location information you can
kick off some individual operations in
the context of this server group and so
on there are a bunch of
context-sensitive operations under pull
down menu even things like clone where I
want another one of the same but maybe I
want a different image all this stuff is
pretty good for tactical work
troubleshooting experimenting testing
that kind of thing okay and these server
group wizards or modal's look very very
similar from provider to provider so in
the same environment if you have
multiple providers configured which
which many large customers do they look
about the same but the details start to
differ and the details should look
familiar to somebody deploying
infrastructure out to their platform so
those are server groups if we click on
one of these little green Chiclets
probably not a great name either you'll
see some instant specific details on the
right and then some instance specific
options and again these are things for
abandoning instances terminating them
rebooting them isolating them for
troubleshooting maybe you don't want a
particular instance to take traffic
because it's acting up but you don't
want it destroyed so it allows you to do
those kinds of things on some platforms
you can even shell directly into the
instance so it's it's really good for
you know acting as a single like
operational pain where you can tie
additional systems into the UI
so quickly before we get to the
pipelines there are a couple of other
bits that we have to look at so the
pipeline's make sense think of the
server groups and clusters as more
ephemeral things are always destroying
server groups and instances in creating
new ones things like load balancers and
security groups are a little more
durable so load balancers we know what
those are security groups are more like
firewall rules ingress rules egress
rules port ranges it's all of the things
that you know allow you to poke holes in
and out of your infrastructure so
security groups hopefully are not
creating and destroying tons of those
load balancers put them in the same boat
it's more durable infrastructure but to
do anything meaningful you will have
some set of these things existing in
your environment for the purposes of the
demo we have some security groups which
are kind of irrelevant but the load
balancers are quite relevant so we've to
load balancers we have a test one and a
prod one the names in this case are
arbitrary it's just so we can see what's
being attached don't read too much into
the names but you can see as you dig in
here each load balancer has a server
group listed under it the bottom one has
one the top one is two again it can show
the instances so you can always drill
down to the details but where it gets
very interesting is under the pipeline
view so let's go over there
I think the terminology should all be
familiar now we'll look at the overall
setup we'll look at the configuration
we'll look at what's what's kicked off
so far and I think we have we're really
good on time so I don't think we need to
go too fast so this is a fairly typical
workflow for a set of continuous
delivery pipelines we have three
pipelines configured here and it turns
out there's an execution of one under
each but we'll come back to that so
we've three pipelines configure the top
one is a bacon deploy to test and we'll
look at the configuration in a second
but the idea here is that we went we
poked the job on the Jenkins server it
built some simple Java hello world app
it published it to a local dev repo and
then this pipeline kicked off and the
way that works is that Jenkins has a
simple web-based integration or polling
integration with spinnaker and spinnaker
notices that that job that this pipeline
is configured to care about completed
successfully it kicks off the pipeline
their important detail there is that the
pipeline one was kicked off was primed
with information from that Jenkins job
so it knows what artifact
were produced that knows the build
number the address of the job there's a
bit of building for provenance that that
extends throughout the pipeline so you
can always get back to from this server
group it was this build it was this
pipeline it SAS artifact that's all
linked throughout the UI so that first
pipeline kicks off it takes that dead
package which is in a repo somewhere in
this case locally and then it wants to
produce a machine image the idea what
the baked stage is that that machine
image is the immutable thing that we're
testing throughout all this we adopt
this principle from you know blend for
structure you test things you don't
change them if you wanted if you get in
a spot where feels I can need to change
something the right approach is really
to tear it down fix it and rebuild it
capture that test that thing don't
change it again as you gain increasing
confidence in your test pass then you
start to promote it through the
additional environments so that they can
deploy the test takes a dip package
bakes a machine image deploys it into a
test environment that's it's only
responsibilities this is a VM oriented
demo if this were a container oriented
demo the only difference would be
instead of a bake stage you would likely
use another hosted service to produce
the container image and then the
pipeline just triggers off of that
container image so instead of noticing
that a dead package showed up and the
pipeline being responsible for baking it
into a machine image you notice that a
container image showed up and you go
right into the deploy that's the only
distinction okay following that there's
a validation pipeline which is triggered
off of the earlier pipeline completing
and we'll look at that in a second and
once that's done there's a promotion
pipeline so let's look at the
configuration of each of these and then
we'll we'll respond to that manual
judgment so this is the bake and deploy
to test pipeline it's a fairly
straightforward pipeline it's just one
sequential set of stages there are no
branches in this one but if we look at
the configuration we say we want to
trigger off of a Jenkins job completing
there are a bunch of different types of
triggers as we mentioned in this case
it's Jenkins it's interacting with
Jenkins it gives you a pulldown list to
select from the jobs and so on we say we
want this hello build job as that the
artifact would care about when that job
completes produces an artifact the
pipeline is primed with it and we can
use it downstream so
downstream we have a bake stage this
looks fairly similar from platform to
platform says well there's some package
and it does a bit of decorating of this
package to try to find the correct
version that was produced by the
upstream CI job so what this means is
that if you have a bunch of Jenkins or
Travis jobs that are producing different
artifacts when you run a pipeline from
one of those jobs it'll install the
correct version of the package so it
doesn't just take the latest or try to
install the package with that name with
no version it looks in the contextual
information primed into the pipeline
from the Jenkins shop to find the exact
version so you can always go to an
earlier version or a later version based
operating systems you can configure base
images so all this is dynamically put
together from the back end if you have
different base images that you're
curating for your environment they can
be they can be chosen here but this is
this particular stage is a good example
of how stages look basically the same
from provider to provider but the the
fine-grained details start to differ a
little bit so in this case there are
slightly different options for a GCE
oriented baked versus an AWS oriented
bake but most of the time you can stick
to the the paved road and the common
attributes and things work fine so we
have a bake and assuming that complete
successfully we have a deploy we looked
a moment ago I clicked on the clone
operation for a given server group and
we saw a server group wizard or when I
click on edit for deploy I see the exact
same server group wizard and this is a
key feature of spinnaker and that the
building blocks the stages that you have
to put together your automation are the
same exact building blocks you can
interact with from the api's or with the
cloud management side of the user
interface so ad-hoc and you know
background automated tests are the same
tasks there's no difference
the single only distinction in the UI is
that in the other one there was an image
field a pull down that said these are
the images we've queried from the back
end when you do it in a pipeline there's
no image field here it's getting it from
the context of the pipeline the image
that you want to provision on to that
new infrastructure is what was primed
into the context of the pipeline from
the Jenkins job that triggered the
pipeline you can override it there are
expressions and all kinds of things but
this is a typical approach is that use
what's in context
okay so we have a deploy oh that's one
other thing here so for strategy we
chose none we didn't choose a deployment
strategy we will in the other pipeline
for this one we'll leave it at none it
makes a pipeline simpler it's easier to
see what happened in the end so we have
deploy and then we have destroy there
are a lot of stages that look almost
exactly like destroy there's destroyed
disable enable resize that all have this
similar notion of targeting coordinates
so if you see here it says choose an
account so an account matches to like a
set of credentials and a back-end
provider so it could be an AWS account
Google account could be multiples of
each of these the targeting coordinates
are the account the region the cluster
so where do you want to look for this
thing you want to take some action on
and then the actual coordinate so do I
want to look at the newest one the
oldest one the second and the most
recent one largest one it's those kinds
of things so the idea is you don't want
to give a name for a server group it's
going to change you'd have to change
your captured pipeline config from run
to run so you just say well in this case
I'm deploying the new version of my
software into a test environment I don't
care about the old version so just
destroy the previous server group and
that's what I'll do when this pipeline
runs all the way through we get a new
server group with a new version it
destroys the old one we don't need to
keep it around we're not going to roll
back to it that's it for this pipeline
so this pipeline ran there was a bake it
was triggered off with a Jenkins job
which is linked this build link here is
the Jenkins job that we kicked off then
we have the bake stage which produces a
machine image and there's the various
details of it it says what package was
installed all the configuration you can
even get to the underlying bake logs the
bakery delegates to Packer and the
typical approach but this is it's pretty
extensible you can do different things
but it's it links directly to the logs
there's an image produced which is then
available in the pipeline context and
that's what we deploy and here's where
we're actually provisioning something
new and it says it provisioned this new
code lab test version 5 server group so
if we look at the cloud management view
of the clusters tab there is in test a
new server group and you can see from
the time this happened while we're in
here but the other server group has got
it destroyed it and we can see that from
the output off the pipeline I know I'm
jumping around so it destroyed version 4
of the server group I hope that's
illegible you guys can see that yeah all
right so we destroyed 4 so that's gone
we don't need to roll back to it but if
we look at this next pipeline in the
configuration instead of choosing a
Jenkins job we said we want to trigger
from a pipeline so we've pipeline we
chose which pipeline sorry that's the
application we chose which pipeline we
wanted to trigger off of its bacon to
ply to test we only want this to trigger
when it's successful and in this case
that pipeline completed ok and this is
you know it's an example right it just
says do some verification in this case
it prompts you user validate that test
cluster because we don't want to
continue on unless we're happy with what
was provisioned so this is waiting for
us to do something there are a bunch of
different notification styles it can
email slack SMS there's a Twilio there's
a bunch of different integrations but in
this case we'll just say yep continue
it'll take a few seconds to notice and
what's going to happen after that
there's a third pipeline and this is
really the end of the the workflow again
triggered from a pipeline in this case
triggered from the validation pipeline
again only if it's successful now this
is a little bit different so we're not
going to bake a new image we said
throughout we want the image to be
immutable we're not going to change it
so we want to refer to that existing
image the one we already tested in the
test cluster and promote it into the
prod cluster so the way we do that is
instead of looking at the Jenkins job
and finding a dead package in producing
a machine image we use that same set of
targeting coordinates to say well look
in the test cluster and find the newest
server group and resolve the image from
that so that's what find image from
cluster does and at this point in the
pipeline context instead of an image
that resulted from a bake we have an
image that resulted from this find image
job and then again we have a deploy it
looks quite similar there are two
differences we're deploying to the prod
cluster instead of the test cluster and
we configured a deployment strategy in
this case red black and there's an
additional detail here which we didn't
touch on yet there's an option where you
can say maximum
number of server groups to leave and the
the reason we have this is that well if
you start from scratch and you have zero
server groups and you do a red-black
deployment you're just going to end up
with one server group that's active and
if you do another red-black to the same
cluster you're still going to end up
with one server group that's active and
you're gonna have one that's disabled or
inactive and then if you do it again
you're gonna end up with one that's
active and two that are that are
inactive so this just bounds it to say
leave at most two server groups no
matter their status whether they're
enabled or disabled so we say just leave
two and it this way it'll start to tear
down the very old server groups so we
clicked that manual judgment now the
final pipelines running so it shows the
fine image status it resolved the same
image that was produced by the earlier
bake but it resolved it from the running
cluster and then it starts to run the
deploy and if we look here you end up
its deploying into prod version five so
we go look there and it's deploying this
one and it'll take a while so it's going
to deploy that one it's gonna provision
the server group we set everything to
one instance because it's simpler and
faster so we'll have that one instance
it's going to wait for it to be healthy
now it's green which means it determined
it's healthy it's going to start to
disable the old server groups and then
it's going to wait for them to show us
being not healthy by the underlying
health providers then it'll start to
destroy those and then it'll wait for
them to be destroyed so that pipeline
isn't going to complete until all of
that work happens and in the end it's
probably fifteen or twenty underlying
steps and probably forty to fifty
straight up API calls against the
underlying cloud platform not counting
the queries for health that are being
done in the background by caching ages
so it's a lot of work to get things to
that point and the the idea with the
deployment strategies is make it
repeatable and give a disciplined way to
compose your deployment strategy so you
don't have to figure all this out from
scratch each time two things worth
mentioning about the deployment
strategies first we showed a list of
some choices there but there's a nice
thing here which doesn't get used that
much probably because we don't show it
that much but there's an option here
somewhere for custom so I don't have any
custom strategies to find here but what
a custom strategy is you come to the
same pipeline editor and instead of
creating a pipeline
strategy so you can cobble together a
wire together whatever steps make sense
for your style deployment strategy save
it with a name and then other users in
your application can choose that as
their deployment strategy because you
can very easily wire together a
red-black using top level stages or
something slightly different maybe
you've already with a verification step
so custom strategies allow you to do
that the other thing worth mentioning is
manage pipeline templates which guard
may touch on a bit if not when we get to
the end if we have a couple minutes
we'll touch on it but it allows you to
share underlying pipeline configurations
among groups have like a curated library
of templates so that when you settle on
a configuration that you like and that
you think other groups should use you
can share it they don't have to start
from scratch and you can parameterize it
and make it extensible and all of that
and all of that is in service of the
idea of like a disciplined repeatable
approach to composing these stages into
pipelines so less step before I turn it
back over to guard it's still running
but just to give you an idea each of
these stages decomposes into many steps
each of these is a quite a collection of
steps and it's going to keep going it
probably may be another minute before it
completes but I think I can turn it back
over to guard while that runs in the
background yep
okay so now you've been looking at the
mats great demonstration and you're
probably wondering how can I test this
how can I test this how can I test this
and you can actually test it quite
easily at least in Google ABS a shirin
kubernetes there are QuickStart guides
on spinnaker dot dot IO which gets you
started very quickly to start it if you
decide to move on and use spinnaker for
your for your organization and you want
to have a like stable good setup you
should use the new cool cool tool called
halyard which is which is a
configuration service for spinnaker so
halyard is a service that you run on the
machine and you have a CLI to in
with this service and what it does is
that when you configure a cloud brighter
like you Burnett's provider you have a
lot of fields like the of an
authorization against the kubernetes
cluster the endpoints you reach what the
doc registries to use and so on and so
forth
there's a lot of configuration and it's
different for every cloud provider
because it's cloud provider specific
information but Allard validates the the
configuration your supply and actually
tests the configuration against the
cloud providers to see that it's valid
and gives you feedback if you've if you
are missing fields or it can speak to
your cluster or whatever reason it can't
it doesn't work it will give you a error
message and try to guide you in the
right direction of solving this so it
really helps you do this and at the same
time it helps you maintain your spinner
grab installation so it if you're
upgrading spinnaker and new
configuration Flags are appearing it
will help you migrate to the newest
version and in spinnaker there are like
10 services and halyard makes it easy to
use endorsed version releases of this
bunch of services so makes it convenient
for users to keep a cluster running make
it stable and also upgraded to the
latest version stable endorsed versions
so if you're gonna use spinnaker in the
organization for real after testing it
definitely check out halyard for all
kinds of questions and stuff like that
we are on slack and and spinnaker dot IO
has a lot of documentation now and it
should be possible to look at on
spinnaker with IO
and see how to solve your problem so
when you set up spinnaker installation
and you want to
to maintain it it's probably good to
have some kind of monitoring so there's
being put in a lot of effort into making
spinnaker easy to operate and one key
part of this is getting metrics from the
spinnaker cluster and spinnaker has the
spinnaker monitoring part with which is
a kind of sidecar that you run along the
services which provides metrics that are
consumable by Prometheus is able to push
to date the dog and I'm not sure if it's
push or pull to stackdriver but it
supports tack drivers as well so so
although the metrics and systems the
major metric systems are supported and
in those repositories on github
there is pre-made dashboards for staff
driver data dog Prometheus that you can
just upload to your account and see see
a lot of details about your spinnaker
installation and the cool part which
surprised me a lot was how I learned a
lot from it because spinnaker provides
multi-dimensional metrics and you're
actually able to look up all all your
spinnaker services and look at metrics
and then filter it by application so you
can see applications that your users
have and what kind of impact they have
on your spinnaker installation so you
can see the kind of footprint of every
application that is managed by spinnaker
which is really cool
so um a little bit about how to get
started with spinnaker
the first place to look is spinnaker dot
IO where all the documentation is and if
you have if you want you can look at the
spinnaker repositories on github you're
all developers so I think looking at the
source is a great way of learning stuff
and we have a slack channel our slack
space it's black group at least if you
go to join the spinnaker Lodi oh you can
join us on slack there is currently 3300
users on that slack grip so it's really
active and channels for halyard channels
for kubernetes channels for all kinds of
stuff so if you need help it's possible
to get it on ons like um Stack Overflow
there's a tag spinnaker which is being
being read regularly from developers and
everyone to to respond to questions on
Stack Overflow spinnaker was open
sourced in November 2015 there is 1900
forks of the repositories four and a
half thousand stars and there is 251
users that has contributed with pr's
different users one of these users were
Ben - so I think it will it's not a real
user so it's 250 contributors yeah we
have made a video that shows this
activity from when spinnaker started
until now which is so here you see the
activity in spinnaker like free open
sourcing it and now it's open sourced
and you see how how the project grows
and the amount of users that are
contributing so it's quite cool to see
the activity now we're in 26th
and it goes fast so yeah there's a lot
of activity in this project new
repositories and services are coming and
new club providers and yeah there's a
lot of traction in the project and it
just keeps on getting better in our
complaint we started back in 20
in November 2015 and in the beginning
like the first year we did a lot of pull
requests and stuff to fix kind of edges
that we met in spinnaker right now we're
not facing a lot of edges anymore we are
becoming more and more of consumers of
spinnaker which is great because it
shows that spinnaker is getting mature
and and really solves all our problems
what's happened here did I close the
presentation I think just go up to view
again yeah yeah so this is the roadmap
so this is basically showing that a lot
of stuff is happening in spinnaker there
are there are some highlighted items
here which is like in 2016 the
kubernetes provider was created and
kubernetes works kind of different from
the the Avs Cloud GCE and all the
regular clouds because kubernetes has
its own kind of concepts there was a
little bit of feedback on this so so the
the terminology and the way we interact
with the kubernetes cluster didn't
really fit that well with kubernetes so
in a response to that
it got prioritized to create the
kubernetes provider version 2 which is
not based on on the same kind of
concepts as before now it's template
oriented so you upload the kubernetes
manifests to kubernetes instead of
having all kinds of abstractions on top
of that I see that we have two minutes
left so
there are a lot of things to say so I'll
try to be quick pipe glances coal
doesn't not mentioned is is getting
mature more and more mature now you can
handle your pipelines let's code share
templates inherit from templates and
it's a really neat and you can create
templates or pipelines in the UI and
dump them to pipelines this code so you
don't need to do it all from code in the
beginning and you can experiment and
then download the template from
spinnaker which makes it a lot easier to
iterate on the pipeline's I think I'll
just skip this there is there is a lot
of stickers here we got that from
someone right in front of the talk so
you can pick up spinnaker stickers and
we'll be around after the talk in the
areas around here and you can just grab
us and talk with us if you have anything
you want to talk about yeah thanks
thanks a lot for having us</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>