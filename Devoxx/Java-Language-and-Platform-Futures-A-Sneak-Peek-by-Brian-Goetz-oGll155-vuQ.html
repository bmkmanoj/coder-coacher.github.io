<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Java Language and Platform Futures: A Sneak Peek by Brian Goetz | Coder Coacher - Coaching Coders</title><meta content="Java Language and Platform Futures: A Sneak Peek by Brian Goetz - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Java Language and Platform Futures: A Sneak Peek by Brian Goetz</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oGll155-vuQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay welcome everybody thanks for making
it out on for the first session of the
morning
this talk is Java language and platform
futures so I'm going to be talking about
some of the things that I've been
working on recently and you know we're
we're taking the Java platform you know
five years ago or so people expressed
concerns of whether the Java platform
had a future at all that whether Java
had reached the end of its line I think
we've confounded those expectations but
the the good news is in addition to all
the great work we've been doing recently
the long term story for where Java is
going is probably as good as it's ever
been so I'm gonna talk about some of the
things we've got in the pipeline the the
flipside of doing a sneak-peak talk like
this is but cause it's a work in
progress everything I say might be wrong
but that's okay right so you've seen
this slide a lot right ordinarily we
speed that past this and make some
comment about the lawyers made me put
this up but today I want to focus on
this slide right
this is speculative this is for
informational purposes only this is not
a commitment everything I say might be
wrong okay I want to make that very
clear in particular the one thing I want
everyone to not assume is that any of
this will be scheduled for any
particular version of Java I don't want
to wake up tomorrow morning and see
Twitter posts about Oh Brian get says
XYZ is coming in Java 10 none of this
stuff is scheduled for any particular
version right so there's a bit of
audience responsibility that not to post
incorrect or misinformation you know
this is just a snapshot of where we
think we might be going so with that we
all on board everyone agree sign the
paper okay good let's get started
all right so as everyone has undoubtedly
heard Java turned 20 last year and over
those last 20 years Java has been
declared dead almost more times than I
can count and we've managed to continue
to confound those expectations because
we've managed to evolve to stay relevant
to the problems that people want to
solve and
hardware people want to run their
programs on so don't know where Java is
gonna be in 20 years but what I do know
is we're going to continue to evolve the
platform so that it stays relevant and
vibrant so fortunately we have some
principles that guide us along that
evolution so you've seen these slides
before probably 10 years ago Graham
Hamilton outlined some core design
principles for the java language and we
still look to these principles today as
we think about how to evolve the
platform and you could summarize them as
readability simplicity and transparency
and in some sense they're all the same
thing it should be easy to look at code
and know exactly what's going on to not
have to reason through what's going on
here what's going on there because if
you can't you know if you can't read
code you can't maintain it and then you
know it but it becomes fragile and
eventually it has to be thrown away
successful code lasts a long time and
over that time it's read over and over
and over again so the code that's easy
to read is also cheap to maintain and
has a long lifetime code that's hard to
read means we're likely to introduce
bugs when we go to maintain it and then
people are gonna say let's throw this
junk out and rewrite it so this focus on
reading code is an indicator that Java
was aimed at building successful
long-lived code not just banging after
supposable code so evolution was also
always in Javas DNA I haven't made it
clear that we were planning for the long
term that we're gonna evolve but - so
cautiously so you know rather than try
to guess the future or follow fashion
our approach is a more conservative one
where we focus on the real-world
problems that developers are facing
today and we look to solutions that have
been proven you know in other
environments rather than just jumping on
the latest fashion so the goal is not to
add as many features as possible but to
add as few as needed to tend to meet the
actual needs of developers while staying
true to those principles of readability
simplicity and transparency so we don't
want usually to be the first language to
add a given feature we kind of like to
wait until we have evidence that it's
actually an improvement and have a good
understanding of how it fits in with the
other features in the language and you
know if our goal is to
Nabal writing successful long live code
sometimes it's better to let other
languages do the experimenting and then
adopt selected features after they've
been proven you know to carry their
weight since language features live
forever we have to choose them carefully
and so to give you an example a few
years ago job one james gosling told a
story about why they didn't have
generics in java 1.0 and it wasn't cuz
parametric polymorphism wasn't
understood at the time or wasn't seen as
important it was because they hadn't
found the java way to do it and
sometimes it's better to do nothing now
and preserve the chance to do it right
later rather than risk doing the wrong
thing now and so it did ultimately take
ten years to add generics which was a
long time but I think the generics that
we got were a lot better than what we
would have gotten in 1995 which might
have been C++ templates or might have
been patterns from beta and we would boo
be living with those mistakes so before
I talk about what's going next let's
look a little bit in the past of some
evolutions to the platform we've already
done now so we're big rebooting data
abstraction through generics in Java
five rebooting behavioral abstraction
with lambdas in Java eight rebooting
application configuration and
encapsulation with modularity in Java
nine so these were big changes but for
each of them the story was the same we
know we identify what we saw as a major
pain point you know so for generics this
was the inability to capture enough type
information in the code which led to
less safe and less reliable code and the
cure was better abstraction in in namely
parametric polymorphism and the result
was more type safe maintainable code now
when we had a generics did everyone have
to rewrite their code no of course not
we did it in a way that offered
migration compatibility so a library
could be genera fied and then clients or
subclasses of that library could choose
to genera fine now later or never and
this is an important aspect of our
formula that new features should be
enablers but not necessarily forced to
use them so it's also important to
realize that the mechanism and the goal
are different things language features
are a mechanism right there cool there
thing but the goal is making it easier
to build and maintain reliable programs
language features aren't an end unto
themselves and like while the big stuff
gets most of the attention there are
dozens of small improvements in every
release and these smaller features have
similar goals they have a you know they
address a pain point we've observed a
pain point where identify a solution and
you know and implement it and that's
true for the big things like lambda and
it's true for small things like try with
resources so you know whether whether a
feature is big or small the goal is the
same make it easier to build and
maintain reliable programs so let's
start with some smaller features that
we've got in the pipeline I showed a few
of these and they in the keynote I'll go
into a little bit more depth you know to
today and these are those that are aimed
at improving everyday developer
productivity it's like I said it's
really easy to focus on the big stuff
like lambdas and it's obvious why those
are there they're big and they're
interesting and as a language designer
they're big and they're interesting so
of course we focus on those things it
takes more of our attention but the
little stuff matters too now again usual
disclaimer this is a statement of
direction not a commitment to deliver
anything and certainly not an any
specific release when I say minor or
smaller I don't necessarily mean small
some of these features are still pretty
significant they're just not in the
reinvent the platform category that you
know generics or lambda lambda is worth
and I'm going to throw up
show off three feature sets that we're
working on expanding the scope of type
inference reducing common boilerplate
and pattern matching so let's look at
each of these quickly okay so let's
start with type inference type inference
is when the compiler can figure out the
type of a variable from in from
information in that in the program from
context rather than making you type it
with your fingers now most of the time
we like this because it eliminates
redundancy while maintaining our
commitment to strong static typing now
it's important to remember that type
inference is not dynamic typing when we
infer type there's still a strong static
type we just
make you write it down in the program so
is type inference good or bad
well sometimes it's good sometimes it's
bad how do we decide whether it's good
or bad does it make the program more
readable and maintainable often type
inference removes noise from the code
that's just obvious and that makes the
code more readable
sometimes it removes essential
information from the code makes it less
readable so that means that as
programmers we have to use judgment
sorry
no free lunch so you know we generally
like to use type inference in
implementation contexts we generally
willing to accept more redundancy in API
is because api's or contracts between
you know between bodies of code that
might even be in different maintance
domains so all of the techniques that
we've used type inference for in the
past and that we're going to in the
future focus more heavily on the
implementation of code rather than the
api's so okay so let's look at where we
use type inference today in in Java 5 we
introduce type inference for generic
method type arguments so if you're
calling a generic method like empty list
which is generic in the type of the
element of the list you could specify it
explicitly like this how many people
here actually don't know this syntax so
now for 12 years we've had this feature
in the language and a lot of people have
managed to avoid learning it because you
almost never need to use it that's
really cool that's really successful
right so you know you can write this
like this and this is how we all do it
and this is better right the extra
explicit type witnesses don't add a lot
of value we know what it's in it what
it's a list of we asked for a list of
string why do we have to say string
twice right so this is a perfect example
of where type inference offers a lot of
value and in the event that the
inference produces the wrong type or is
unable to produce a type you always have
the option of using the explicit witness
but most of the time you don't have to
so that's an example of type inference
working the way it should
a similar thing we did in Java 7 we
extend
bandit not just to generic method
arguments but generic constructor
arguments so originally if he wanted to
construct an ArrayList of string
you said list of string new ArrayList of
string why do I have to say string twice
what else might it be so in Java 7
we added type inference for our
constructor invocation z' we call this
the diamond feature but it's really just
another form of type inference and again
this code is just as readable if not
more readable because it's it's
eliminated something that that's really
just redundant and in Java 8 you know
when we added lambdas and and you know
you can explicitly you name the types of
lambda parameters and sometimes that's
the right thing to do most of the time
you can leave them out and the compiler
will figure it out for you now you you
may have to use explicit type arguments
for lambdas more often than you did with
generic methods because there are times
when maybe there's a method overloading
and the compiler can't figure out which
one which one of the overloads that you
meant so people might fall back to the
explicit form more often for lambdas
than they did with with generic methods
but the general concept is the same if
it's obvious let the program or a minute
if it's not obvious give the programmer
a chance to make it explicit so given
that these past uses of type inference
is that pretty much been winners it
seems reasonable to consider new context
for type inference as long as it doesn't
conflict with our bigger goals
simplicity readability transparency so
like I said earlier we like using type
inference to smooth out implementation
details but not so much in api's and the
reason is that API is should not only be
clear and unambiguous but they also
should be stable
you don't want small changes your
implementation to turn into a change in
the signature of one of your methods
which then might turn into a binary and
compatibility so explicitness really
helps to maintain stability for api's on
the other hand and the implementation
we're willing to you know we're willing
to be more more loose because it only
affects the implementation so another
place we can use type inference
to smooth out implementations is the
types of local variables and they're
pretty much a pure implementation detail
right the you know the local variables
occur only in the body of methods and
you know the method has a contract and
this is just how how the method does its
thing so if we if we do if we use type
inference for the for the local
variables we can replace the explicit
type declarations with something more
implicit where we're still saying I'm
declaring a variable but I'm not going
to tell you the type you're the
compilers going to figure out the type
by looking at the type of the thing on
the right hand side now at first glance
sometimes people freak out here because
of the the loss of type information but
you know tell me which is more important
the type of a local variable or its name
if you want to be able to read a program
and tell what's going on which of those
gives you more information my claim is
that it's the name and you know in the
in the top version the names are sort of
scattered all over in the middle of the
code whereas in the bottom version the
names line up nice and cleanly near the
left margin so we're putting the most
important thing first now this feature
isn't new with job of course people have
been asking us for this for years
because they like it in C sharp or Scala
so this isn't this isn't new people who
have used this in other languages swear
they'll never go back so you know we
think this fits into our profile for
we're expanding the scope of type
inference makes sense you know it's been
successful in other contexts in Java
this particular context has been
successful in other languages so we sort
of feel like this is a feature that's
ready to ready to be promoted okay so
let's talk about boilerplate Java has a
bad reputation for being boilerplate
intensive and it's a deserved reputation
now taming boilerplate is actually a
never-ending journey because every bit
of boilerplate that you remove just
makes the other boilerplate more obvious
right it's kind of like you know you you
get a new pair you know you replace your
shoelaces and all of us
you realize how shabby your shoes look
right so you get new shoes and while you
use you see where this goes so you know
we've done some features for eliminating
boilerplate in the past try with
resources one of lambdas and streams
Alima eliminate a lot of a lot of
boilerplate but there's still a lot left
and you know so you know we're gonna
look at what the biggest sources are and
attack them from you know from the top
so you know I think one of the biggest
sources of boilerplate are what I call
the state driven methods for domain
objects the methods like equals hash
code to strengthen structure the ones
that have to do with initializing an
inspecting the object state and these
can usually be generated formulaic lis
in fact I des will do this for us right
you say generate constructor generate
getters generate equals and hashcode in
the IDE just does it and that's great
because that's you know error-prone work
that you don't have to do yourself but
that only helps with writing code that
doesn't help with reading code and it's
also easy to just cut corners and leave
these methods out how many people here
have been bitten by methods with bad
equals or bad to string right now you
know that the person writing that class
knew that they were supposed to provide
an equals in a two string and they got
lazy and they got lazy not because you
know it was so hard to do because they
could have asked the IDE
I think the think the fact that this
visually clutters our code deters us
from doing the right thing so if we can
eliminate this clutter maybe more people
will do the right thing so you know a
lot of classes are just you know pure
pure data objects they're just dumb
holders for data they don't have any
non-trivial behavior they don't have any
invariance or preconditions you know
they just they just hold the data so you
know classic example is the only class I
ever write point XY and you know you'd
like to yet this is what being an
architect is this is all the coding you
get to do so you know you'd like for
this to be the end of it because it's
all of the useful semantic contact of
this class all right it's it's called
point it hasn't it has it has index it
hasn't why what else do I need to tell
you why
I need to tell you a lot which is
unfortunate because there's not a lot of
information in all that extra
boilerplate code that the IDE generated
for me so it would be nice to be able to
say this class is just a dumb data
holder this is the whole thing int X int
Y and just give me a constructor you
know and give me equals and give me hash
code and and and all of that and of
course you know maybe I don't want the
default equals so that's fine I just
included in the body of the code and the
compiler says oh you already have an
equals method I won't give you one so
this seems like a nice idea
of course the Devils in the details
right you know the all of the all of the
hard parts of doing this are how do we
deal with you know allowing the user to
you know tweak the definition of equals
right let's say you have one of your
fields as an array should you compare
equality by are they the same array by
identity or they sit the same array
contents well for you know for either
those choices I can find cases where one
or the other is the right thing and the
other is the wrong thing so people are
going to need to be able to do both we
need to provide mechanism to allow
people to fine-tune these things that's
where all the hard work and this feature
is right it's easy to say wouldn't it be
great if I didn't have to write these
things and in the easy cases are easy
and then the you know the hard cases are
where all the complexity is but it's not
just about boilerplate one of the things
that makes this an attractive feature is
it's not just eliminating code it's
raising a level of abstraction it's
saying declaratively I am a domain
object and therefore domain objects
behave in this way I behave in this way
and this allows the compiler to sort of
infer more about what's going on and
this connects with other features and
stay tuned well we'll get there like I
said you know there's a lot of details
to work out how do I add validation to
the constructor without rewriting the
whole constructor how do I tweak
equality comparison without rewriting
the whole the whole thing there's a
hundred would F so you know what if I
want the fields to be private what you
know where do I put annotations where do
I put Java doc etc but you know so you
know when you kind of pull on that
string a little bit what you see is
there's a deeper problem here
which is is there actually a compact way
to declare the state driven methods and
if there is then these data classes are
really just macros for classes that use
a state driven mechanism for generating
these methods so stay tuned for more
detail as the project evolves okay so
let me talk about the last of the
smaller features that were I'm going to
talk about today and that is
improvements to to switch or another way
to look at this is pattern matching if
you were familiar with pattern matching
from other languages how many people
here have seen pattern matching in in
Scala or in functional languages all
right so a lot of you have seen this a
lot of you like it right a lot of people
say when are we gonna get case glasses
so let's look at the switch statement
that we've got right now it's sort of it
you can think of it as a generalization
of the conditional operator but it's
very very limited it's limited that it
can only have statements in the body of
in a case arm rather than expressions
it's limited in the set of types you can
switch over you can only switch over in
sand strings and enums and a few other
well-chosen types it's limited in the
set of conditions you can test with case
you can only test for comparison for
exact equality against the constants and
once you hit the limit of what switch
can do what do we reach for we reach for
visitor right how many people here use
visitor how many people who like visitor
right okay don't have to say any more
than that
so you know people ask us for features
all the time we have a database of like
thousands of our fe is one of the most
common our fe as we get is can i have
types which please in actuality yet
people don't want types which they think
they do because it's better than what
we've got now but what they really want
is pattern matching pattern matching
subsumes the constant matching that
we've got today it subsumes type
matching and it subsumes a lot more
including a lot of the use cases for
visitor so let's take a look at how we
might have all switched to i incorporate
some of these features so as an example
can people read this in the back of the
room I don't know why I asked cuz I
can't make it any bigger you can't but I
guess it's polite to ask so
here's a switch statement that is
actually almost came from real code I
cleaned it up a little bit but but this
this came from some actual code that I
wrote where I was writing I was
extending the azzam class file library
to add some experimental bytecode
features and one of the one of the
things you end up having to do in Azzam
if you've ever used it is whenever it
talks about a class file constant it
hands you back an object and then you
have to do this big if it's an integer
if it's a string if it's a long etc for
the enumerated list of class file
constants so if you write code like this
first of all it's kind of big but it's
also error-prone and I'll get into that
it's basically a more general mechanism
than we really need what we want is
piecewise assignment we want to be able
to test a bunch of things and then
assign a variable exactly once in each
arm but that's not we're doing we're
using a general if else--if else--if
which ends up being bigger and and
riskier than we like so first the first
thing I don't like about is it's less
readable right I you you know you have
to read through the whole thing to
realize that you know each of these each
of these if blocks is doing basically
the same thing it's also slower it's
guaranteed to be O of n whereas a switch
in you know in the best case is o of 1
an annoyance that everybody complains
about is after you do an instance of the
first thing you have to do is cast it to
that same thing I just did an instance
of what do you mean I have to cast it
right not only is that annoying but it's
an opportunity to make an error right
whereas if there were refused to
operator that did both you wouldn't you
you wouldn't have that opportunity to
make the error in each of these arms I'm
assigning to a local variable what if I
forget well the compiler catch me well
maybe the definite assignment analysis
will but not the way I wrote it where I
assign a default value at the top so I
could easily make a mistake in one of
these and if it's a rare case I won't
even notice and finally that's just an
awful lot of code to do something simple
right so we've all written code like
this we've all kind of wished it was
simpler
so this is an example of the kind of
boilerplate that people complain about
with Java okay so how could we improve
this well you know the case label today
means is the switch target exactly equal
to this constant so what if we extended
that to include a type test right so
here's an example syntax case integer X
what does that mean is the thing an
integer if so cast it to integer and
then assign the result of that cast to X
so I can so X is in scope in the body of
the switch so what would the example I
just showed you look like under those
rules well it's better right
it's the code is already getting smaller
the type test which and this this is
accurately a pattern what that means is
it combines a predicate of testing the
target to see if it matches and if it
does match it's able to bind pieces to
destructor the target and bind pieces of
it to some local variables which can
then be used right so this is an
improvement I fused the instance of in
the cast and it's also more clear that
I'm doing the same kind of test in each
arm right the the conditions in all of
those else--if else--if else--if
all happen to have the same structure in
the first example but here because I'm
using a more targeted language mechanism
they're forced to have the same
structure and that's less error-prone so
when I say case integer I that variable
I is then in scope in the for that case
arm so I can just freely use it you know
in the spring dot format so you know
this is getting better right we've
limited some boilerplate potentially
switch could be o of 1 instead of o of n
you know time complexity we can actually
do better here so what we really want is
some kind of piecewise definite
assignment so can we bend the switch
statement to do that and I think we can
by allowing switch to switch not only
over statements but over expressions so
I've picked the syntax here don't get
caught up in the syntax but I used the
arrow instead of a colon to indicate
that the result of a case arm is an
expression and then
whole switched statement evaluates to
that expression so I switched on the
constant if it's an integer then the
switch evaluates to this string dot
format if it's a byte then the piece
which evaluates to that string dot
format etc so the code has gotten a lot
more compact it's gotten a lot more
direct and it's gotten a lot less
error-prone
and it's the error-prone part that I
care about I know you care about the the
boilerplate part I really care about you
know can we make it easy to write clear
error-free code but you know it is an
awful lot less code and I think it's a
lot more readable because it's not
obfuscated by all the details of the
instance of test and the casting and and
and having to assign something to a
local variable in the middle of the arm
and etc alright so those examples showed
off a lot you know we showed off
expression switch versus statement
switch switching on an arbitrary type
not just the you know nine or so blessed
types that switch works on and using
type test patterns as case labels
instead of just constant case labels but
actually there's sort of a rich vein of
stuff that we can mine here to make this
even better now probably these won't all
come at once they'll come out over time
but but you know this this is a feature
that really has legs okay so let's talk
about how you know how this might get
you know fancier so we talked before
about data classes how Dave the classes
commit that I am a you know I am a
domain object they they make somewhat of
a commitment to their their state being
the representation being couple to their
constructor signature which means that
you can reverse the operation of
construction right construction takes
the fields creates and objects the
office of that is taken object and bring
it back to the fields for an arbitrary
java class you can't do that but for
domain objects you can so we can exploit
that by wrapping up by using you know to
give us what we call these constructor
patterns where we can say is this thing
equivalent to what I would have gotten
if I called the point constructor with
X&amp;amp;Y and if so cast it to a point extract
detects my fields and bind them to local
variables and this is something that the
compiler can automatically do with data
classes if you've seen cases in Scala
you you know you're asking what took you
so long so you know let's uh you know do
an example of this now this is a
slightly more complicated example the
example is is sort of a typical I'm
representing the expression as a tree so
I have a abstract type called node and
there are subtypes of that node constant
node plus node negation node
you know multiplication node etc and I
want to write you know a method to
evaluate an expression so I can express
that very clearly with switch and with
patterns with these constructor patterns
where I can ask are you a plus node are
you a multiplication node if you are get
the left and right pieces and bind them
to some local variables so walking
through the code I've been handed a note
I want to evaluate and I switch off it
and I say is it a constant node if so
bind it's constant to I and just
evaluate to I because that's what a
constant is is it a plus node okay
extract the left and right you know sub
nodes bind those to some local variables
recursively call eval on each of those
add them together and that's the
evaluation of this plus node right how
much code would this be to do with
visitors too much right is the visitor
code more clear or less clear than this
well once you learn to read the you know
that this stuff it's it's a little bit
new so it looks a little scary but once
you learn to read it it's much more
clear because everything's right here
you don't have this multiple layers of
indirection that visitors give us and so
the key here is this constructor pattern
which fuses the instance of check the
cast extraction of the relevant fields
and binding them to local variables but
because this matches the shape of the
constructor for a domain object it makes
intuitive sense
are you a constant node with this
parameter constant so we can actually
take this farther I don't want to die of
too deeply into this but you can
actually take this
are there because patterns actually nest
pretty nicely and so you can ask more
complicated questions like are you a
plus node whose left subtree matches the
pattern constant node with zero and you
know using this mechanism most uses a
visitor pattern can be eliminated and
reduced in complexity in size like I
said probably these features will be you
know will not all come at once
we'll start with type test labels and
probably get fancier from there okay so
now let's look at some some bigger stuff
so everything I'm going to talk about
now actually I've talked about before
actually here if you saw the version of
this talk from two years ago you're
probably gonna be wondering see haven't
they made any progress since then this
looks awfully similar to what he was
talking about two years ago this is the
nature of big evolutionary projects so
to put this in perspective
I have literally spent thousands of
hours thinking about project Valhalla
which is let me talk about next value
types and generic specialization and
what I'd say is I've just about got the
problem loaded into my head this is not
small stuff so you know the diagrams I'm
gonna show you now are gonna look a lot
like what I showed you two years ago
what we've been doing for the last two
years is understanding what are the
consequences of of putting this into the
language in the VM okay so what's
project Valhalla project Valhalla is
about rebooting the layout of data in
memory okay why is that important that
doesn't sound particularly interesting
the reason it's important is because
hardware changes in the last you know 20
to 30 years hardware has changed
dramatically so just you know give you
an example thirty years ago if you like
looked up what's the cost of an
arithmetic operation and your processor
data book and he looked up what's the
cost of a memory fetch you'd find out
that they were about the same thing
roughly four cycles each at that time
since then the relative cost of these
two operations has has expanded by
several orders of magnitude a cache miss
now costs you on the order of three
hundred clock cycles typical in
processors like the one in this
laptop here can issue for instruction
arithmetic operations per cycle which
means that a cache miss potentially cost
you a thousand instruction issues Lots
so two things that cost the same thirty
years ago one costs maybe a thousand
times as much as the other now so
there's a good chance that the decisions
we made about laying out data in memory
twenty eight twenty five years ago are
probably not optimal for today's
hardware and the big cost is in
directions pointer fetches and the
reason we have to do so many of those is
object identity so with the exception of
the primitive types in Java everything
is an object objects have identity
identity serves things like polymorphism
and mutability and locking which are
useful things to do but not all classes
need that in particular the point XY
class that I showed before doesn't need
that it's just a point it's not you know
it doesn't need to be mutable it doesn't
need to be polymorphic it doesn't need
to lock it just wants to carry some data
from one layer of an API to another but
if we have a model that says everything
is an object and all objects have
identity everybody ends up paying for
identity whether they use it or not so
how do we pay for it we pay for it
by having a layout in memory that's not
necessarily something we want so again
the only class I know how to write final
class point final index final and why
how is this gonna get laid out in memory
well I have an array of points and so
that's an object's they have object
headers and the elements of an array are
references to a point so each of those
points is an object with an object
header and you know it there's no
mutability or probably morphism here but
we ended up with this layout because
well maybe there will be right and the
costs you know so if you look at like
the the memory density that we get out
of this it's kind of lousy right we have
two words of payload x and y and we have
two words at header as overhead and a
word of pointer as overhead so that's
like 150 percent overhead for
representing an array of points like
this at the same time you know these
points are all actual allocation in the
heap that means more allocation more
garbage collection
and then the real cost is the loss of
locality if I want to walk through this
array of points I'm gonna be doing a
dependent load to get to each of these
points and that means I'm risking taking
a cache miss every time every time I go
so this you know harmless seeming idea
everything is an object objects have
identity leads us to a memory layout
like this which as Hardware evolves 2025
years later turns out to be highly
suboptimal now sometimes you don't care
your data sets are small that you know
cut your program isn't compute bound but
if you're doing data intensive work
analytics big data this hurts a lot both
hurts in terms of how much data you can
load into memory and it hurts in terms
of what it cost a crunch on that data
now when you know people hear about this
sometimes developers do things like this
let me shred those XY points into two
arrays so I get better locality right
and you know sometimes you actually like
need to do this because you have real
performance requirements sometimes it's
just some bizarre obsessive-compulsive
disorder that programmers seem to be
prone to but you know it happens a lot
that developers will crap up their code
for performance reasons even though they
don't have any reasonable performance
requirements or metrics in place but
they know that the other way is slow so
they end up writing bad code and you
know doing this means your codes less
readable if it's less it's more err
opponents less maintainable and you know
we sort of feel like the stems from this
bad choice that people have been given
which is you can either have abstraction
or performance pick one and in general
developers pick wrong every time so if
we don't put themselves in the position
if we don't put them in the position
where they have to make this choice
maybe though they won't shoot themselves
in the foot the problem is we can't
figure out that no one will ever lock on
an object so we have to lay things out
pessimistically unless we get some help
from the programmer who says look I
really don't need polymorphism I don't
need mutability I don't need locking I
just want some data please so the layout
that we want is most of the time is this
just give me the data lay it out in
memory
I want an array of structs please so
what kind of code do we want to write in
order to get this layout and what I
claim people want to do or should want
to do is to say something about the
class this class is just data it's a
value it should be treated like a value
it should be compared by its state not
by its not by its pointer identity and
that is what enables the VM to lay
things out like this where values can be
inlined into arrays that can be inlined
to other values or objects so you know
this is the motivation for project
Valhalla which is that as Master Yoda
tells us identity leads to pointers
pointers leads to indirection and in
direction of course leads to suffering
so okay so value types core feature of
al-hawa value types these are just pure
data aggregates just the data no
identity we compare there equality by
two points or equal if they have the
same X and the same why we don't allow
representational polymorphism they you
can't extend them they're not mutable
they're not nullable now these are
restrictions that not every class will
be able to take but a lot of them can
write we write classes that fit into
this category every day and by giving up
on identity and these other things that
identity enables like immutability it
allows us to get the layout we want
values can be routinely flattened in
memory we can squeeze out all those
object headers they all go away and we
end up with things that behave like
classes in that they can use
encapsulation and methods and
constructors and all of those
abstraction tools that classes are good
for with the runtime behavior of
primitives so they're better than
primitives because they can have methods
they can have fields they can have
constructors they can implement
interfaces they can use encapsulation
their fields can be private they can use
generics so all these great tools for
abstracting over data that we get from
classes you can use of values and they
have this nice memory behavior
I like primitives so for a lot of
classes like our point class or like
most of our domain objects it's kind of
the best of both worlds right now
there's a lot of devil in the details
here but a quick way to answer kind of
any question about value types is
imagine how would it work with int what
would int do right what happens when you
assign an INT to objects it boxes right
what happens when you assign a value to
an object boxes so there's kind of like
two ways to look at this you could look
at this as faster objects that have some
restrictions or you can look at it as
better primitives right so you could you
know either either view this works but
our sort of mantra for this is codes
like a class works like an INT right
best of both worlds don't put people in
a situation where they have to choose
between abstraction and performance okay
so who would use these well everybody
application writers that deal with large
data sets would use value classes so
that they could reduce the memory
footprint of their data set and reduce
the number of interactions get a flatter
data set that they can work on with
better locality library writers will use
this all the time both in their
implementations like we can make hash
map faster by just having the internals
use values for the math entry is rather
than objects for the map entries so we
rewrite hash map every Java program gets
faster no no API changed that's great
there are also a lot of useful
abstractions you can expose those values
so things like alternate numerix big
decimal or unsigned int STL style
cursors algebraic data types like
optional it's possible to implement
these with value types so that they're
expressive and powerful and type safe
and all of that but much faster if
you're a compiler writer you're gonna
love this so you know people who
Gentiles for JavaScript and Ruby are you
know on the JVM are constantly fighting
with the fact that the numerix in Ruby
are not the numerix that they have in
so they can't translate Ruby in students
they have to translate them to objects
and they're much slower so compiler
writers can write language runtimes
using value types that don't pay that
object penalty and end up with faster
code it's obvious substrate for
implementing features like tuples or
multiple value return or wrapping native
resources so compiler writers will like
this too so my argument is this is good
for everybody even though it's it seems
like a low-level feature it's actually
something that will find benefit at all
the layers so okay so how could this be
so complicated how can you be working on
this for two years and we haven't seen
any results well this is the string it
seems simple enough it has all is value
types come from all the same motivations
why we have primitives but it's deeply
intrusive into everything at the VM
level we have new byte codes new type
signatures at the language level it
interacts with everything so if I am you
know if I'm gonna have value types well
I'm gonna want to have generics that's
over value types I'd like to have an
ArrayList of int and have it be backed
by an int array not turn that into an
array of boxed integers because
otherwise I'm back to the same memory
layout that I showed a picture of before
so we have to figure out how generics
interact with values had a wild card
interact with specialized generics
what's our top type is everything an
object well maybe maybe not so you know
we don't want to just nail these things
on the side we want to integrate them in
so that they fit in you know sensibly
and compatibly and that's where all the
work is right all the things that it's
connected to that makes it look not
nailed on to the side so like I said
with generics generics are expressive
enough right if you want to express list
of int you can just say new ArrayList of
integer no problem it works it does
exactly what you mean but it's slow
right every integer in in that list is
like you know the picture with the
points the array of points I had earlier
and you end up with all of the same
overheads the memory usage of the object
header is the indirection to get to the
date of
loss of locality extra allocation extra
GC so for all the same reasons that we
wanted value types we want specialize
generics over value types and you know
if we couldn't make these play nicely
together it would be pretty lame also
who use a stream okay who finds the hand
specializations like in stream and long
stream annoying and kind of like ugly
yeah that's what I thought when I was
writing them too I don't want to do that
ever again
oh I let it slip that I write could be
given points sorry
that was horrible right it was necessary
because you know they were there there
would have been no easy way to add up a
list of integers without it other than
reducing over boxed you know about since
but it was something we had to do but
not something we wanted to do it was
more code more footprint more buds
serious design constraints on stream and
there are features we didn't get because
of that and less abstraction the you
know the the commonality between stream
of integer and in stream is a lot less
than you'd like it to be right so that
was a big big compromise that we had to
do in that library and in other
libraries that people write everyday you
know you've anybody used the goldman
sachs collections now eclipse
collections library you know they they
had to they took a template based
approach where they generate
mechanically specialized versions of all
the collections over all the primitives
you know 81 math implementations it's
horrible right but people they need the
effect of that they just don't want the
code footprint of it okay so how does
this look well if you're specializing
over a broader set of types that include
references and values actually the set
of operations you can do is restricted
because there are some things that
aren't supported by both refs and values
like synchronization right in a if you
have generics today you can synchronize
on a tea because tea is always object
but what if T could be int then you
wouldn't be allowed to do that right so
the compiler has to know are you these
the old generics where it's just
references or these the new generics
which is references
primitives and values and maybe even
void so you have to label the type
variables such to say this is genera
fiying over a broader set that's what
this any modifier does and then
thereafter it looks mostly like regular
generic code so I talked about the
string you know it's I you know when we
added generics it was important that the
existing classes could be compatibly
genera fide without forcing a flag day
where everybody had to recompile their
code and genera phi their code all at
once we've got the same constraint here
when we convert collections from old
generics to new generics whatever that's
actually called that any fication
needs to be binary and source compatible
we need to be able to any file our
libraries without forcing everybody who
uses lists or has subclass lists to
immediately any phi their implementation
and like i said this is where most of
the work is is ensuring this kind of
compatibility and there's an awful lot
of work fixing up our libraries so that
we can merge in stream into being just
stream event okay so what's valhalla
about well you could say it's a bad
performance make object graphs denser
and flatter so we have fewer object
headers less indirection less allocation
and GC and so how do we do that with
value types we extend generics to work
over values and we NFI our libraries
okay great good story you can also say
Valhalla is about better abstraction
about clocking the seam between
references and primitives so that you
can make generics more powerful genera
fie over everything genera phi over
references primitives values and even
void so like how many people here have
noticed that there's nine versions of
arrays dot sort in the the JDK now
that's not fun for the person who have
to write it not fun for the person who
had to test it and annoying for the
people who have to use it right so win
all-around right we'd like to be able to
write at once test at once have it work
once and again you know the the goal is
stop making people choose between
performance and abstraction because if
they don't have to choose then you won't
be ten
to hand unroll your array of objects
into twin arrays you won't be tempted to
write specializations like in stream and
generics will just you know be the
primary tool of choice for abstraction
so that's where we want to get to big
project okay let me talk briefly about
the other big project we're working on
we did a demo of this at the keynote
project Panama project Panama is about
rebooting the interface between Java
code and native code and data so calling
native code
accessing data out of the native heap so
today we do that with j'ni which is
unpleasant error-prone slow and insecure
so let's do the opposite of that let's
make it easy secure and fast who thinks
that's a good idea
yeah right so we want to make it easy
safe and fast to access code out of
native heap going through Java
interfaces to call out to native code to
get rid of all that j'ni and replace it
with stuff that's been generated by
tools which can then be more easily
optimized because the VM can see all the
way through it and this makes it
possible to use a native library as
easily as using a Java library so what
do we have to do well right now with J&amp;amp;I
we have this like long workflow where
you look at the target API and figure
out how you're going to model it in Java
you implement the some wrappers then you
have to implement some C headers and
then you have to implement some C
implementations and you get out of that
you get a shared library that you can
then eventually call so let's get rid of
all the steps that involve manual stuff
and replace it with tools where you
point a tool at your header file it
extracts the calling sequences and the
struct layouts and it generates a jar
that has interfaces in it and you just
program against that as if it were a
Java library sounds good right so I did
demo at the keynote and I'm not gonna do
the full demo here but basically what we
did here was they took the opencv
library which is a C++ library for image
processing we wrote a simple program and
C to call it to look at an image and
detect if there was a picture of a cat
in it and then we wrote the same program
using j'ni and then
the Panama tools so the C code was about
you know page of code pretty
straightforward read the image in pass
it to the library library hands you back
a list of rectangles you draw the
rectangles on the image and then you
draw the new image the same thing in
Java is almost the same maybe 20% bigger
but pretty much exactly the same code
and you know the library returns things
like you know pointers destructs that
comes back as a generic abstraction of
pointer to some interface type that
represents the struct it may look like
it's slower because you're calling you
know you're making doing these
interactions through interfaces but in
fact at runtime the VM generates binder
code to do it to access the native it
all gets compiled down to direct memory
access it's way faster than j'ni and
it's safer to give you the idea here's
like you know half of the Java code that
J&amp;amp;I stubs and that's not good
well the coats coats horrible right lot
lots and luck wouldn't even fit on this
screen if it were actually on this
screen demo fail who didn't even do a
demo and it failed all right so you know
and we when we run it you know it just
works right you know it finds the cat's
draws the picture yeah everybody loves
cats
so project Panama is actually fairly far
along the the demo that I showed at the
keynote is actually real it actually
works and there's a open JDK mailing
list Panama Deb if anybody's interested
in getting involved but it's really
really cool stuff and with that we have
about seven minutes left for questions
you can send your questions to Twitter
at this hashtag and I think there's a
microphone and people are already
queuing up with the microphone aren't
they or they just like trying to leave
well if anybody's near the microphone
wants to ask a question go ahead no they
really just want to leave you can leave
just
just do so quietly so other people who
want to ask questions can ask questions
where's the microphone it is up in that
corner right if you're standing near the
microphone and you're in the way of
people who want to ask questions it will
be nice to step out of the way oh we
haven't got a handheld microphone all
right fall back to old technology who
has a question raise your hand do you
envision something like a partial
perimeter parameterization for lambdas
which you see in functional languages do
you mean like partial type inference
were it infers the types for some of the
variables but not not all of them or do
you mean partially evaluating the not a
high priority there are other things
that are way higher priorities there's
nothing intrinsically wrong with it as a
feature but from a return on complexity
we think there are other features that
are more valuable to to focus on that by
the way that's the answer to like every
why didn't you do X question well
actually know some of them are like it's
because X is dumb but plenty of them the
answer is not X is dumb but there's
infinitely many things to do there's
finitely many of us so we have to
prioritize the answer is almost always
there were other things that we thought
were more important okay more questions
yes for the Scala people which I call
myself a little bit umm where do you
draw the line with regards to stopping
certain features like with the better
marriage matching you can go quite far
and put a lot of stuff in yeah so you
know a lot of the features you know that
you saw today you might have thought oh
they're just dealing features from Scala
aren't they and there's some degree of
that we kind of view other languages
that are have a little bit more of an
experiments all bent to them has great
laboratories for figuring out what works
and what doesn't there's lots of things
in Scala that work there's lots of
things that don't seem worth the
complexity and so we kind of cherry-pick
the things that
are easy enough to transplant into Java
so pattern matching is something that
transplants very cleanly without
dragging 47 other features with it and
it's also something that I think
object-oriented programmers are pretty
much ready to accept right you know it
doesn't require a big paradigm shift
about how you think about your program
it's something that fits fairly nicely
into object-oriented program so that was
an easy one
to scoop up it's also one of the most
commonly requested things that people
say they wish they had from Scala and
Java so it wins both on the not
connected to 47 other things and the
it's something that people really want
and as the example showed you know it
really does squash down some real-world
code into pretty readable stuff and do
you see like simple better matching
something you can evolve later to more
complicated absolutely right if we just
did I mean people been asking for types
which for years so if we just did that
we'd make a lot of people happy right if
we went one step further and just did
constructed patterns and no nested
patterns that would make more people
happy you know so there's many
opportunities to go to go deeper it's a
pretty pretty rich vein okay so in Java
all of this will make each other more
fun of course great job so but one thing
I see from Scala a lot of frameworks
right now in Java depend heavily on
reflection in Scala well something the
big shift is happening libraries more
and more and get rid of a reflection
they use okay or full macros but it
seems to be I would say less error-prone
are you thinking about moving in this
direction in the future in Java you know
in theory that sounds wonderful
it took Scala a long time to get there
to where mere rocket scientists could
write correct macros and you know the
closure community has you know similarly
you know it's taken a while to figure
out how the macro of facility should
work it seems like it's a big stretch
for Java good
add one little comment yes please one
one thing we're definitely looking at is
is ways to support frameworks with
alternative reflection techniques core
reflection has kind of had its run
I think there's there could be a lot of
mileage in method handles and variable
handles going forward where reflection
is based more on a capability mechanism
rather than the rights-based mechanism
that we've got in inquiry reflection but
that's well and and similarly you know
one of the challenges about reflection
is that it's really reflection over
class files and that was you really
didn't notice that when in the early
days of Java when their class files and
source classes were so close to each
other but you know then when you add
things like generics and bridge methods
and generic methods it's much harder to
use core reflection to figure out what
source code did this come from and what
that suggests is we need a higher level
reflection mechanism that actually
reflects over the language level type
system not the class files high with the
type inference it seems like you want to
prevent the developer from writing in
readable code but she should that not be
the responsibility of the developer and
moreover also of the team of the
developers to to keep the code more
readable and therefore you could maybe
introduce type inference at more places
so I recognize it's impossible to
prevent people from writing unreadable
code so you know that that's kind of a
fantasy to think we could do that but
more seriously this is a trade-off right
this is a trade-off between programmer
convenience for writing code and the
stability of the Java ecosystem and so
you know things like using var in the
return position of a method is probably
what you're thinking about no we're
never going to do that right because
that makes libraries unstable that leads
to dynamic failures that are hard to
predict because people will make tiny
changes in the body of a method which
ripple into
change in the method signature which
means class is compiled against older
versions of that library that
dynamically linked to the new library
will will fail to link at runtime and
that makes Java less reliable and we
don't want to do that right so it's not
so much about protecting people from
writing unreadable code it's about
protecting the ecosystem from unstable
code I think times up so thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>