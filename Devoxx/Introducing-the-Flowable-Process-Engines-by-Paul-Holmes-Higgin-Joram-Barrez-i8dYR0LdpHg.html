<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Introducing the Flowable Process Engines by Paul Holmes Higgin &amp; Joram Barrez | Coder Coacher - Coaching Coders</title><meta content="Introducing the Flowable Process Engines by Paul Holmes Higgin &amp; Joram Barrez - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Introducing the Flowable Process Engines by Paul Holmes Higgin &amp; Joram Barrez</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/i8dYR0LdpHg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">just give people a moment to sit down
well thanks very much everyone for
coming to our talk appreciate that my
name is Paul Holmes Higgin and my
beautiful assistant today is your
embarrass and we're going to be talking
to you about flowable I'm going to do
the easy fluffy bit of a very
lightweight introduction to Fleur ball
just if you not sure what it is and what
we do and why and then I'm going to hand
over to Yoram to do the the tricky stuff
of talking about how we've plugged in
machine learning into interflow ball so
first of all what is Flo ball well it's
an open-source set of libraries for
business process management implemented
in Java and you may have heard of
activity it's a fork of activity and
Fleur ball is built by the team of the
built activity and the thing that we're
known enough for is our BPMN engine
that's been developed over many many
years and then just a month ago we
released a new engine a CMM n engine
this is a custom engine for CMM n it
really is focused on making sure that we
we scale the execution when when you're
trying to do case management and earlier
in the year we also released a decision
management dmn engine as well and the
thing that we're very focused on the
thing that makes global special is it's
very focused on making things super fast
super scalable super easy to use
and even if it's written in Java if you
not a Java person it's got a very rich
REST API we do have people that use
things I don't net clients to be talking
to to us as a back-end as well and
pretty much anything you can do with the
Java API you can do with the REST API if
you like boxes here some boxes with some
words in them what global does so I'll
go through showing you the apps at the
top the all of this is open sourcing you
literally just download a zip file from
the project website and there's some
Wars and there deploy those in your
favorite container and you're away I'll
quickly show you
the app said they were all talking to
flowable through a REST API and in the
core engine there are there really four
engines and you can use them
independently so if you just interested
in the BPM execution you can just use
the BPI main engine and it will only use
the BPM parts of the engine it won't
sort of deploy a whole bunch of other
stuff that you're not going to use this
is like waste if you just want to use a
case management on its own you can you
can work that way if you start working
with them together then they start
sharing services between them so things
like the task service you could create
tasks in cm MN or create starting BPMN
and they're all going to go into same
users task inbox if that's the way you
want to work or sat on top of a range of
different architectures Knuth in terms
of what type of database you flavor you
like what JVM flavor you like and and
things like this and there's all sorts
of I mean it's a very small box on the
right hand side about being able to
customize and extend that there's any
number of different ways you can
customize extend and exploit and use the
flowable engines so why would you want
to use flowable
why pick us well we're interested in the
engines we're all about the engines were
constantly pushing the BPM technology
forward with the engines some of the
innovations we've done recently around
dynamic process execution being able to
take things and manipulate them
dynamically when they're already running
so trying to deal with some of the
modern use cases that people want allows
us we're providing the technology that
allows you to do that always interested
in performance scale reliability
everything else these are fundamental
things to us so from the point of view
of a tool to use yep we're always
pushing the boundaries but keeping it
safe and sound at the same time we are
very developer oriented the api's that
we have are things that our developer
will find very natural to use very easy
to get up and going with however with
things like some of the visual tools it
is also something that a business user
can just pick up and play and actually
be running something with without doing
any development or having to involve a
developer at all not trying to do
developers out of a job just trying to
stop developers time being wasted by
people saying how do I do this how do I
do this how do they des can I do this
they can actually get up and do some
things themselves
the other reason why flowba might be
interesting to you is we're opinionated
about the engines and how they scale how
they perform what bpmn means what cm MN
means and how they should be interpreted
extremely opinionated about that that's
what makes us special we're not at all
opinionated about what you want to do
with it where you want to put it how you
want to embed it how you want to use it
you can embed it in your own application
you can stick it in a whole bunch of
different contexts and environments on a
whole bunch of different platforms and
things like that and that gives you a
lot of flexibility to use the same
concepts use the same approaches to
modeling the business but how you deploy
it to two different infrastructures
everything else it is very much up to
you so that's the that's the words of
the intro so always it's nice to see
stuff happening for real so what I'm
going to do now is quickly switch to a
messy screen is this going to catch up I
don't know how to switch the screens
here is there some magic going on well
it is a Mac with a Dutch bar so I don't
think you touched it right enough so let
me just see yeah see it's little
something you have to put is a Dutch bar
and then you go oh thank you my
beautiful assistant Yoram thank you very
much so what I've got here running is is
literally just the war files that don't
download from the project website
running in Tomcat and a delicious just
deployed them there's nothing else there
it's all running within any memory
database what I'm going to do is just
give you a quick you know flow through
sort of the process design and deploying
it running it so you can see stuff
happening and that's going to be the
basis for what your arm is going to take
and do some augmentation with later what
I'm going to do just to make things a
bit easier for myself and less tedious
for you is import an existing
application because otherwise things
could go horribly wrong so what I've
done I've imported an app an app is just
a container for a bunch of BPMN XML
the process model any forms models any
decision tables and things like that so
it's just really a container for that
this particular app has only got one
process in it what you can do you can
have multiple processes in the manage
them as a as a package and deploy and
control who has access to them things
like that so there's one process in here
and this process is quite a simple one a
few steps and then a branch and and
depending on what we decide to do going
different routes on it and there's all
various things you can do for editing
within this so I'm going to go into the
visual editor now and it's just Visio
style drag-and-drop this is all
web-based and it's got all the lovely
BPMN things that you can get excited
about if you get excited about BPMN here
all sorts of fun stuff so you can draw
out the process diagram as you wish
things being able to plug in and
integrate into the other elements like
the form so here's the start of the
process I can have a form associated
with that so that you know to start a
process I can fill in some information
here I'm just going to ask for someone's
name and that's going to kick off you
know that the starting of the process
and you know the first step after that
is a user task they're going to use the
task is something which is going to be
assigned to someone to work on and and
changing who it's assigned to I can do
things where I can give it to someone
explicitly or I can give it to a role in
this case I can say for the demo I just
want to come back to the person who
start the process it's going to be
assigned to the process initiator and
again I can have a form associated with
this this is going to be anymore a rich
form and an author the working with the
controls here I can drag and drop to
create the forms on here certain
controls here in terms of you know what
type what type of label I want to have
placeholders more advanced things in
terms of min length sort of patterns
matching as to what's acceptable things
like this it's all of that's in there
for working with create in the forms
quick and easy then after the next up
I've got after that is a decision so
what's something I've collecting up some
data and now I'm passing it to a
decision type of decision table is
something like a set of rules it's a way
of evaluating the data I've collected so
far maybe deducing some some data which
I'm going to use later on and
I'm doing on this particular step is
I've got a decision table and each row
in this spreadsheet like thing you can
think of as a real as a rule and so that
the left hand side is that the
conditions I'm testing the right hand
side is things I'm using including or or
setting so in this case I'm going to be
evaluating the age and the status of the
person that I've collected data from so
far and then I'm going to be deducing
some credit guidance so in this case for
the first rule again filling in
information here I'm saying if someone
is less than 25 years old whatever their
status then I want to set the string the
guidance to be they're young so they
need we need to do some some further
checks on it and you can have a whole
number you can have a whole range of
complex conditions and a whole number of
different conclusions to come from that
so this is a very simple example here to
show you it working and after that we go
to another user step where we've we've
sort of clicked at some formation we're
going to assign it to someone to look at
and we're going to put the the the
information that we've just collected
and just reduced you can see at the
bottom we've got the guidance text here
so again this would be passed out to the
person who's doing their the review the
other important thing at this point is
making a decision where we're saying
there are certain outcomes that can come
from this particular step and we're
saying that there's three possible
outcomes reject consider accept so I'll
put those here to find those here and
then what I can do is in the process
where I've got this exclusive branch I
can have conditions that test on those
particular outcomes so depending on what
they choose as the outcome from that
then it will take down you know one of
these other branches so if I reject it
is going to go and just do a simple
information form of rejection or if we
may consider it goes to an advanced step
here so you get the idea of a simple
flow through here so here I've defined
my process I've I've got decision tables
I've got a bunch of forms I've got my
app all defined what I can do now is
literally I can just deploy this and
start using it life so if I publish this
now this is now deployed into the
runtime system and I can start working
with that now the runtime there's a
runtime app called the tasks application
it's got a generic inbox there but what
I can do because I've just deployed this
new app I've now got a separate app for
the set of processes associated with
that app in this case it's just one when
this thing's with global where you can
do you can create ad hoc tasks and
things like this good remember to say
about contributing to the project you
know you can create a doc task but you
can also do actually start a process if
I start the process now is going to kick
off that process that was defined there
from over the first step which get the
full name of the person so I've
initiated the process and now what it's
done it started the process as a person
who started I can always see where the
process is and what's been filled in so
far so we can see that we've filled in
the start form and now we've gone to the
active task of capturing the the
application details now that task will
be sitting in someone's inbox it's
sitting in my inbox because I said it to
assign it to me and here's that form
that I said for that was for the first
step so I'm going to say that the
request is for 10,000 things it's Jane
she's living rented she's 23 she's
British with the name like Jane Smith
and her income is 50
British pounds which are worth so much
these days after that step if your
member was going to a decision table and
then after the decision table that was
going to the review stage if you
remember the decision table if somebody
was below 25 then automatically they
were going to get the advice that they
were young so they need additional
guidance so you can see that additional
guidance put here the decision table has
been run we've now got the choice of
whether we were going to reject consider
or accept this so if I go down the
reject route we just go to the inform
rejection so if this could mean so
sending out an email or sending a system
request into a system or something like
that and there I've completed the
process the process is done yes remember
to say about computing yes all of this
stuff is open source and we're always
open and willing to to people to add
additional things here if you see
something here that it isn't great then
you can you know contributing that it in
yourself so that tasks that that process
is run I can always look back processes
and see exactly what was going on went
on in the past I can see my completed
process I can see it
what was filled in I can see what was
captured initially and review everything
and find out who made what decision
where at what time so that really is the
flying intro to flow but just give you
an idea of that that's the that the
standard out-of-the-box download and
play what we want to move onto now is
how do we take that and that's regular
beeping around stuff and start
augmenting that with some machine
learning and this is way we want to get
into truly adaptive and dynamic BPM
people talk about dynamic BPM it just
means you can do stuff ad hoc what we
want to talk about is trying to move
this things forward to where the
visitors want to go today if you have a
conversation with the business an
organization is what they want to do is
try and get the machines doing what
we've all heard this AI is is going to
take care of the world what what people
are talking about to us is more about
trying to move some of the mundane tasks
away from the people so that people can
to be more valuable tasks and try and
get the machines to do more things but
at the same time what's really important
to be to people particularly in things
like finance things like this is not for
that to be a black box what you don't
want is the machine learning to be black
box and magically it's given the the
answer and you don't really know how
it's come to that conclusion so what is
really important is still finding a way
to exploit machine learning but use it
in a way that is still audible and still
understandable by people to be able to
review that and at this point this is
where it gets very complicated and
difficult and also where it gets into a
live complicated demo and I step out of
here and hand over to my attractive
assistant Yoram who's going to take all
the risk and all the harm and all the
danger associated with doing a live demo
so over to you on thank you very much
Paul so good morning everybody here in a
room and hello to people on the
livestream so what we're gonna do now is
take this process that Paulus built and
we're gonna with you know the team of
the conference we're gonna apply some
machine learning to its but before we do
that let's take a little step back is if
you do any online research about
Business Process Management or you talk
to any BPM vendor out there you always
get something that looks like this it's
called BPM life cycle it's as old or
probably all the rest the street so what
it's about well it's about this
continuous refactoring of your model the
idea is that at the top you start
modeling your models discovering it
talking with the people you're gonna
build it you're gonna add some
developers you're gonna code some logic
you're gonna run
to give it to your end-users you're
gonna let them fill in forms or whatever
they do these days but important is that
the flowable process engine is
constantly monitoring constantly keeping
history data in various data stores what
are people doing how long did it take
them why are we going a certain branch
up or down the data that's involved and
the typical idea is that in its last
step the optimization step is that
you're gonna look at this data and
you're gonna try to find bottlenecks
you're gonna try to fight our contention
is going on where people are waiting for
each other and you're gonna try to solve
that and then the whole circle starts
again that's why is it's a continuous
lifecycle and it's in this last
optimization step that machine learning
can help us so we've got this enormous
amount of data I mean Paul just showed
you one form and how it's filled then
you gotta imagine that this is being
done on a big corporation or even in for
a full country you've got an enormous
amount of data what we're gonna do in
this demo is we're gonna build
prediction models based on this data I'm
not gonna use it for two things the
first thing is let's say the easiest
thing is we have this prediction model
based on all our data we're gonna use it
to make suggestions at run time in the
user interfaces to our users so we're
gonna help them with some some you know
advice while they're Finnigan or we can
validate you know when they click a
certain bottner fill something in and
the prediction model says hey this might
you know not be alright then we can
actually help them getting the right day
time that's you know that's the the
obvious part the second part at the top
there is the more complex part is when
you have your prediction model and you
have your
PPP event model you can actually use
those two to see or to calculate
mathematically how can i automatically
improve this process right this cycle
how can i automatically do this how can
i make a more efficient version of this
process so that's what we're gonna do to
try to keep that in mind that is this is
our end goal of the demo so why is this
a good idea well typically when you do
machine learning you've got a quite a
bit of a problem because you've got all
these data sources coming in from
various places and you've got to
correlate it somehow you've got to make
sense of it somehow you got to find how
the data is used how it moves around why
certain data point there and with flow
but with a process engineer in a quite
luxurious position because you have a
bird's-eye view of what's going on in
your
process in your company right because
that's why you do a business process you
see how people are doing stuff you see
which services are invoked how they're
orchestrated so you can make sense of
the data then you'll see in the demo in
the code that we use a lot of this model
this in this metadata of the model to
make sense of the mathematics behind the
machine learning so the code that will
show the architecture behind the code
let's say looks like this now bear with
me this might look a bit complex and
lots of boxes but I'll go to each of
these steps separately also to note for
for demonstration purposes all only be
running one node of each but all of the
services have been designed to be as
scaleable independently from each other
so you know keep that in mind that but
if I do that on my off-the-shelf laptop
it'll probably just melt down the floor
here so they're not gonna do that and
it's already speaking off with all these
servers running on my machine so just
from a high-level point of view what's
going on well we start a story on the
left-hand side we are gonna have a
process service that's gonna take the
example from Paul and it's going to run
it a lot of times it's going to generate
a lot of data we're gonna send this data
into RabbitMQ using a feature called
asynchronous history and I'll get back
to that in a minute
from that RabbitMQ we've got a spring
booked listener service which takes
messages from the queue it's going to
fold into elasticsearch on the right
hand side we've got the decision
analysis service it's gonna priyada Clee
check the process that finishes in the
system is going to calculate lots of
metadata and it's going to kick off a
spark job and a spark job that we've
written to use the ml loop the machine
learning library from spark and it's
going to be basically going to infer a
decision tree based on all the data that
we've gathered in a process and then
eventually because you know it was the
end of the night we were storing it in a
relational database because there was
easy and JDBC
it's quite easy to do so and then we're
gonna use that GD BC relation database
data to enhance DUI now one of the
things I think Paul already mentioned it
is that global never chooses we always
give you the interfaces the abstractions
the the convenience classes to do
something but we never make a choice for
technology for you so for example here
we've chosen rabbitmq but it can be
replaced by any other cue implementation
that you fancy you'll see that in the in
the
there's just one interface with a few
lines you swapped out with your
imputation same for lastic search if you
like any other big data jason store you
can swap it out same for spark if you
like tensorflow you're like sky kid or
you're a Python guy and you'd like to do
something else
that's fine you know no problem so our
last note about this so Paul talked
about you know there's various ways on
how you can use the process engine and
and the embedded way is one of the
popular race meaning that basically you
take the jars or one jar and
dependencies you add it to your project
and there you go you got you get an
instance from the process engine you've
got the services and you talked to three
of these process services in a very
natural way for Java developers and in
each of these services you'll see that
we have in some way or another embedded
now do you I might be confusing
basically this UI is both the REST API
and the UI layer on itself that's why
it's also embedded there all the code
that will show now is can be found on
github on the flow below examples
repository which is real there it's just
been pushed just before the talk so good
and let's go so the first part of this
story was the process of service quite
such a simple service from complexity
point of view we have the process engine
as a regular spring bean and what I'm
going to do is we're going to use it to
start a random number of instances to
generate data and then we're going to
send all the historical data into
rabbitmq and we use a feature called
asynchronous history which is a quite
recent feature global and basically when
it comes down to is we saw that when you
do when you when you do go from process
in the process from Step A to B to C
typically you have a lot of history
right because it's not only ABC there's
a lot of stuff going on who's known what
the timings you know side effects and
stuff like that we saw in our benchmarks
that a lot of the time was spent on
processing this history in the same
database transaction as the runtime data
so what we've done now with asynchronous
history is we gather all this stuff into
a big JSON blob basically and we store
that one and process it later for the
user the perceived performance is of
course better because the user clicks on
the button and there is a UI returns
quicker however as a developer you know
that we're actually exchanging you know
time now then we'll do it
actually using a bit of more resources
and processes later so it's not magic
right but the perceived performance for
the user is a lot better and the last
point is that from a transactional point
of view it is transaction incorrect if
anything later on crashes the master
data will still be in the flowable
database tables they will be safe and
sound that it will be you know we
guarantee from an engine point of view
that your data is your events that
you're actually sending out your history
events are actually saving sound so
let's switch now for a minute
it's a bit of code here we go
as you might see I'm using Eclipse here
for a very easy reason that Eclipse has
support for having multiple independent
maven modules in your in your same view
that saves me from some clicking I'm not
gonna start an IDE or I use IntelliJ I
use NetBeans I use Eclipse whatever what
day of the month it is just so you know
and they don't get any tweets about
saying hey use this or that so the first
is the process service that's a regular
spring boot application now in this
spring boot application we don't use the
flowable spring boot starters and in the
next service i'll show you how to use
that one but basically what I wanted to
show here is how you boot up the process
engine in spring in a very easy way so
what we have here and I'm gonna go into
too much detail here there's a data
source there's a transaction manager as
you expect from spring and this is where
the flow book code kicks in so here we
have a process engine configuration what
we do is we simply pass at the data
source transaction manager a few
settings we're also going to use the
decision management tables as a poll
showed you we're gonna use form so we
need to add a few configurators and this
is basically these four lines the stuff
that we need to get our asynchronous
history working in a message queue mode
you see we set a few flags and the only
thing you have to add is this job manage
and that comes back to our philosophy of
not choosing for you but giving you the
hook points so if we look at the
implementation of that you'll see this
is a rabbitmq based one which extends a
clause that we provide for your
convenience clause and the only thing
you have to implement is the actual
sending of the JSON let's say to the
cube alright so if you would swap this
to Kafka or over ActiveMQ or whatever
you would swap this one line with
something else
and for the rest here in the spring
application we've got some some RabbitMQ
set up that we going on but that's it
the next part was the process service
and this is just to show you a bit how
the API works it was a Java developer
that's a very natural API so we're gonna
call the execute methods later on in the
demo and for example what we do here is
we get the process engine which is just
an instance it's a it's a Java Bean it's
an instance we get to repository service
the repository services where you deploy
your processes and that's what's
happening here right so on this line 68
we're actually gonna get some zip file
that's on our class path and we're going
to deploy it into the system and then
from that point on we can actually start
new instances from it in the next bit of
code what we're doing here is we're
querying for tasks and you know just
very simple get the task service your
task list and you can do a various
amount of stuff here you know you can
you can order by various things you can
query on assignee for example you can
combine all these things in a very
powerful way anyway for demo purposes we
kept it simple what we're doing in the
next couple of lines is generating
random data and so while I'll always be
speaking there will be a lot of data
being generated you'll see that in a
minute and at the end we basically
complete the task alright so let me
switch one minute to the next slides the
next service you know in the middle of
our architecture we've now got the
process data basically starting process
instances and we're sending those to
have a time queue right there now in
rabbitmq and now we want to get them off
rabbitmq and we want to send them into
elasticsearch now this is another
Springwood application where we use the
global spin boot starter it's quite
simple when you see there is nothing
more than taking stuff from the queue
and sending it to elasticsearch so let
me show you how that works so this is
the listener application so you see
another spring boot application we're
setting up a few things for RabbitMQ you
know a queue in exchange a container to
listen for the messages and the actual
stuff that that takes the messages and
process them is this one here is the
asynchronous history job message we see
that's the one we give into a listen
adapter from spring booty mpq library
and what we do the only thing you have
to do is you have to give it a message
handler as you can see you're on line 89
the matches handler again the philosophy
that we always follow is we give you an
interface or a hook point or a
convenience class again this is an
interface the async history job message
handler so you're responsible now for
for handling the job we give you all the
hook points and all the you know the
helpers to basically process this in an
easy way so what we're doing here is we
are getting the data the Chasen so we're
opening simply with jackson in this demo
i'm only interested in the variables
right so I'm only going to filter on
those and I'm going to send those into
elasticsearch so that's what happening
here I'm filtering them if we found it
we actually just send it to
elasticsearch in a very you know non
performant way let's say you know we
were doing some for demo purposes we're
gonna wait until elasticsearch just yeah
it's good go ahead otherwise stuff can
you know I have to take care about all
of a synchronous timings and and queue
overflows and stuff like that so that's
to solve that now while you didn't see
in the listener application here we've
got a data source and some elasticsearch
things but that's it there is no process
engine beam being created as was in the
previous application so the magic to
that is the global spring boot starter
which is defined here on line 30
basically by having this jar on your
class spot it will automatically
initiate the process engine based on the
convenient on the conventions that's
been good follow so it will if you have
spring food on your class spot boot up a
data source transaction manager and the
global starter would simply take those
and create a spring boots process engine
for you so you don't need to define
anything but as you can see in the
application you can actually already
where is it here it is you can actually
already inject these things so spring
boots create these for us in the
background so what we're gonna do now is
we're gonna start while I'm talking
gonna start generating all of this data
so let me swap here so what I've done is
I've created a very simple listener just
to rest endpoints just just says you
know start any number of instances yes
this is not you know pure rest but
anyway it works for this demo purposes
so I'm gonna trigger it and I'm gonna
execute start the loan example from Paul
so
is just triggering here we go and now
while I'm talking
stuff is being generated now you can see
that well let me first show this one I'm
also using spring boot admin application
this is just you know I think it's a
pretty cool thing when you have a couple
of spin boot applications to show all
your service up and running and you can
get notifications of it you know
something goes up something goes down it
uses the actual actuators behind the
scenes to give you lots of information
about various bits in your system you
know pretty graphs that people always
like to see anyway remember that if you
would stand be standing here you would
hear my machine sound like a small
vacuum cleaner because now there is a
lot of data being generated in the
background so you can see that the
yellow line this is the RabbitMQ i've
been a few by the way so i can see the
yellow line those are the the history
that's being pumped into RabbitMQ the
green line that's the one that's elastic
you know being the ones taking it from
the cue I'm putting it into
elasticsearch so while I'm talking
there's a lot of stuff going in the
background and you'll see that while I'm
talking again stuff will be calculated
for us by the machine learning but how
does this work well we go it's really
making lots of noises now so it's even
slow to open up PowerPoint so all we see
here is this is the decision service now
how does it work basically this service
will periodically inspect the data in
your process definitions will gather
metadata and kick off a spark job spark
on itself basically for people that
don't know how spark works basically you
define a topology of nodes in a cluster
and the sparked framework will make sure
that your work load is distributed in an
efficient way over this topology so the
reason why we're using elastic search
here is because they have a nice
integration with spark spark you just
are Dedes which stands for resilient
distributed datasets basically means
that when you spread the work over your
cluster your spark cluster they won't
take any more data than necessary so
they will be very efficient they will
not load everything in memory they will
basically fetch whatever they need when
they actually need it so it's a very
efficient way you'll see it in the code
too
a very abstract high-level way to make
sure that you don't overload your
servers so how does it actually work you
know if we go looking in the codes let
me first explain a bit how it works well
first of all we're gonna open up the
BPMN model and we're gonna look for
patterns we're gonna look for human
decisions followed by a decision
followed by a sequence flow that have an
outer check for a certain outcome in a
form in this particular example from
Paul we've got two of those right we've
got the loan review there is a form and
you can click on accept to reject and
consider I think and then we'll go later
on and advanced review those are the two
that will match our criteria when we
found one of these patterns that match
we actually trace back from this pattern
back to the start and we actually try to
gather while we're passing from from
this matching thing to d2 the start
we're gonna gather all the metadata
about what are the forms that you can
have all those variables you can have
for the service you're gonna touch
what are these services producing what
are they gonna use this input and we're
going to gather all of these things
because you will see that the machine
learning all buttons they're very
mathematical they don't know about you
know form variables they don't know
about services but we gotta give them
some some meaning so that's why we're
gathering all of these things so we can
make actually sense of the output of our
machine learning algorithm so let me
show you how that looks so these service
that actually does that so you can see
there is at the three the three faders
look for the pattern so let's have a
look at finding these patterns again the
idea that I want to convey here is more
to show you how this works in flowable
basically you've got an API that gives
you access to the BPM and mole which is
a Java representation of your process of
the visual thing you have and as a job
developer you can much easily work with
this then you know compared to XML or or
any other format so basically what we're
doing here is we're opening up our PP
man model we're getting all the user
tasks and never gonna have a small
lambda that basically filters all of
these out that have a form R followed by
a branching like an exclusive gateway
and that check for a form outcome and
that's the one we actually want to
enhance with our machine learning data
and then the second step you know the
tracing back of the of the metadata
that's happening
a lot of co2 you're not gonna go into
detail but basically again you see that
this will use the API is from flowable
to open up you can see that the concepts
here you know we talked about process
definitions past instances and for forms
for the form engine it's exactly the
same we've got form definitions form
instances etc so once you know one API
they apply to all of the engines that we
basically have so here we're gonna query
for the form definitions and we're gonna
get the formal and you will see that you
know there's a bit of code here it
actually will open those form
definitions will gather variables but
it's you know the code is on github this
is you know pretty boring code but if
you open it up gathering in a big hash
map making sure it's all you know unique
unique that we don't have to placate you
know that we have all the values that
can be so if you have a drop-down for
example we enhance it with all the
values in a drop-down and stuff like
that and then once we have this data um
what we done do let me put it on a big
screen again once you we have this data
we can now start giving it into into
spark so we we have all this metadata
human thoughts form from service how
it's used we've got the the combined
with EEPROM and model and we're now
gonna give it into spark so what's it
gonna do it's basically going to infer a
decision tree and I'll show you right
away how we do that in code it's going
to infer something that looks like the
stuff on the left-hand side it's a very
mathematical representation but if we
interpret this we see here if feature
four is in a certain vector feature four
four we know that that this is
nationality that's what we map into
spark and it goes into a few ifs there
but basically if you would interpret
this it would say if your nationality is
Dutch or Spanish remember the form that
Paul was filling in you could select the
nationality that's actually what it's
doing so let me show you now how this
looks like in codes
a little bit of bit of setup going on
here but here this is basically the the
core of the whole machine learning
algorithm applied to the data we have
again you know we did all of data
gathering so far so now we're going to
to make it to change it into a format
that basically the machine learning
algorithm from SPARC needs the first
line here on line 190 this is where
we're going to stream it in an efficient
way from elasticsearch you know remedy
RTD the Brazilian distributed data set
this is where we actually will fetch
data from a certain elastic search index
and what we get back is a thing called
Java RDD with a hash map basically a
hash map representing the Jason from
elastic search the first thing we're
gonna do here is we're going to group
them by buckets so we have a lot of data
but we got a group it by process
instance so that's what we're doing here
we're gonna basically divide it into
buckets and you can see the rent result
is going to be an RDD the bucket is
going the pickup key is going to be the
process instance and now we've got a
collection of hashmaps a collection of
jason's or from elastic search against
Park we'll make sure that this is done
in a very memory efficient way it's not
going to keep all of this stuff on one
node the memory is going to distribute
this over your cluster the next step is
quite simple we're going to filter it
basically it could be that we're still
in the middle of a process instance and
we actually don't care about those that
haven't stopped yet we really want the
data for those that have completed their
their adventure let's say so that's what
we're doing here actually gonna check
whether or not we're already finished
it's a very simple lambda to do that and
the last one is a bit bigger so then in
the end so we've got now you know this
this already with a collection of hash
maps and now we're gonna map it into
something that spark understands so if I
make this a bit bigger so SPARC needs
something called a labelled point it's a
mathematical representation that takes
two parameters the first ones being the
label value it's basically the outcome
so what you're actually giving into
SPARC is to say okay these these values
this vector that's need a name of its in
the machine learning algorithm is this
vector containing a big number of points
map to a certain variable value right
these vector values map into a certain
outcome variable could be that you know
this for
all these variables suppose that you're
in the loan review step all these forms
you collected beforehand all this data
let's to this state at this point so
that's actually what we're giving into
the machine learning algorithm and this
you know we gather serious in a thousand
hundred thousand million kinds of data
points to actually get to a certain
confidence here and then in the end once
we have this we're gonna do is we're
gonna give this into the algorithm
there's a bit of setup here you know go
and read the spark documentation if you
want to know more but basically we're
gonna train a model decision tree model
to do our predictions so that next time
when we have this set of variables into
a certain point in the process instance
we give it and it can predict the
potential outcome of the future of the
process instance again we can now save
this and in how's this and then in the
end what we do is we're gonna flatten
the decision tree that's being generated
and regarding to store them in our
relation database to help our UI now
while I was talking hopefully hopefully
the decision the algorithm has been
kicking in and has been generating
states has been generating for sure some
stuff here okay
good that's good because yesterday we
were that we were practicing our demo
and machine learning you never know
right of course I'm the data that I have
is a bit you know I know my data so I'm
I know that what he can go to but
yesterday we were demoing and it it kind
of led into a situation that was okay
you're right but this was not the point
I was trying to make but luckily almost
so basically what's what what we see
here all the data so I remember in the
backgrounds have been generating these
process instances basically what Paul
was doing manually filling in these
forms you know I'm I was doing that
programmatically all the time while I
was talking so the decision Alex or a
decision tree algorithm from spark has
now inferred a few simple rules it says
you know if you're in Belgium of course
you're going to be accepted everybody
trusts the Belgium now if you're not a
Belgian and you're lower than 30 you're
going to be rejected and if you're not
the Belgium and you're more than 30
you're gonna be considered and the next
also you know for all the patterns that
were matched in our in our demo data
let's say is going to
decision trees it also is a bit you know
doesn't like people over fifty sorry for
people over 50 just by random accidents
so this is you know this is what's
happening behind the scenes we've got
now that this data so how can we we've
store this data remember in our relation
database if you remember the
architecture and if we go step back you
know the DB I'm life cycle we had two
goals first one was and halls in the
user interface right so we cut now the
rules and now we can use those rules to
enhance our user interface so let me
show you how that looks
whoops so we're now in the same task
environment that Paul was I'm gonna I'm
going to swap begin to the running ones
I'm going to start a new process and the
same thing that fold it John Doe I'm
going just the first toss was capturing
the data so now we're actually filling
in data this data will be done compared
to the prediction model that we've built
in the background so I'm gonna say I
need I don't know 50 thousand was it I
think we're gonna be thirty thirty
two-years-old
gonna be Belgium and then one through
three of something I'm gonna complete it
remember the next step was a loan
reviewer so this is not the person
asking the loan but actually the guy you
know the bank talking about alone I what
you see here is the stuff that was not
on Paul's demo is that basically we've
got this little guy here saying hey
based on your inputs that you that we've
gathered so far the machine learning
predicts accept as outcome because of
all the variables that you filled in now
of course it is a very simple example
you gotta imagine that in reality you
can use it's for far more advanced use
case for example suppose that I would
now click reject well the machine
learning has deduced from all the data
we've gathered that actually the chances
of it being reject for this kind of case
is very low historically and you know we
always have been doing different things
so you could use that to enhance you
know validation of your you eyes of your
forms and make sure that the data is
consistent or even while you're filling
in the forms you could be filling in the
forms and even say
oh listen up you might have a second
think about it because you know this is
not how I be doing things this is one
way you know you can start thinking
about enhancing your UI so the data
you've gathered which is a very powerful
way you know to do this second thing is
that remember your BPM life cycle the
second thing we wanted to do is actually
use this data because our machine
learning algorithm if we go back here
has said that well it's actually 100
percent sure so it's quite sure you see
that if I scroll up you'll see that it's
actually like it starts with 70% you
know being sure about something and it
90% and in the end because of course I'm
you know I'm generating the data in a
way that I can control in reality you
know you will have to have to you have
to set a certain threshold for
confidence now the machine relevant says
yeah I'm absolutely convinced that you
know this is the way that we're doing
business and could be right it could be
that you have a process and you know
we've seen this many times you have a
process that somebody is doing every day
a lot of tasks but they're always doing
the same thing or following the same
thinking right so what we can do then is
actually optimize or model and you've
gotta imagine that you don't have a UI
that you give in to your modeling people
and you actually say hey you know the
machine has learned that actually we
could optimize this you know this is not
automatic step right I'm now gonna do it
automatically but in reality you know
you gotta be very careful with these
things because it can offend many people
if you if you're trying to do that so
imagine that there is this nice UI which
for demo purposes and time constraints I
did not have the time to build anymore
and that basically swaps swaps the user
tasks with adeimantus so we've got these
rules right so where's my beautiful
slide about that so you've got these
rules basically right and you can now
flatten these rules into this the amount
table into this decision table Billy's
Excel kind of like table that Paul
already showed you right so what we're
gonna do now is we're gonna swap out
runtime these these human tasks with a
decision table so that's what I'm gonna
do now here you know it says magic
happened again imagine a beautiful UI
for this so if we now go into the same
thing as before so I'm gonna kill this
previous one and I start a process if I
use the exact same
parameters as before I'm gonna say
50,000 h32
Belgian and one-two-three income there
is no love you anymore remember before
it went into the loan review step but
now we swapped it with a demon model
doing the automatic decision for us so
if we go into showing you the diagram
you can actually see that instead of
having a human task before with a form
and a person has to click on the accept
reject or consider it's actually now
swapped with an automated step that
calculates that for you
right so this is a bit of the fun stuff
you could do and you know we've always
started researching into these areas and
there's a lot with BPM and process
engines there's a lot of stuff we can do
because we sit on top and a huge amount
of data and we have a structure about
our data it's a very luxurious position
so the last thing I want to say is is of
course people that have a mathematics
background or in statistics or whatever
there is this of course the xkcd comic
that let's not assume alas not thing
that because we found a pattern in our
data that we found a correlation that
there is actually causation right
you cannot trust machines blindly you
can you always have to have a human
interpreting these results and of course
I made some you know easy steps here but
in reality you got a look at the data
and understand why the machine is
generating a certain thing right but you
know this comic if you hover it it
always have a nice you know even
sometimes more funnier title text you
basically correlation does doesn't imply
causation necessarily but it does point
you into a certain direction right even
though it might not be the cause of it
it does give you the the food of thought
to do something and I think that is all
I wanted to say about that Paul so
there's two URLs if you want to learn
more about us flow below org and if you
want to see all the code key TOCOM slash
global for all the stuff that we have so
that's all I have to talk about today
thank you very much
we got a couple of minutes left for
questions not many I think but uh but if
there's no questions I assume that
everything was crystal clear you can all
square oh sorry
so test that is my you know colleague
from foe sorry that helped me building
this demo yes that's the stuff that you
actually did for me so the last step
remember that I was swapping this this
human toss with addition table and
that's actually work that TAS has done
in this day in this particular demo in
Vitesse at the same time it's an only
swap at run time also the model has been
regenerated so if you go into the
decision tables there is actually a new
model that people can actually
introspect and see and of course there
can be some optimizations here because
we got a few columns that don't add much
into this but you know the general idea
is that we have accept reject consider
for a certain age right so there is
indeed a model being graded you can give
to your business people to actually see
yeah is a machine making sense or not so
very good point as I'm very sorry for
missing that I did see a question
further back I think reserved a question
further back
so the question is have we tried this
with some real-life clients the truthful
answer the open-source answer is no
however that what's driving us is we
have a lot of customers who are in the
financial sector and there is a lot of
interest in trying to improve as I
saying trying to move some of the men
deign activities out so some of this is
is being driven you know by the
requirement that the desire to explore
particular types of decision-making and
how they can be augmented and and and
use so not used in anger yet but
certainly being pushed to find ways of
using this technology so the question
was so that that indeed within all of
the chat BOTS popping up is that that
will be a way you know that people will
start to gather data and for all the
stuff that we showed chat BOTS is just a
little source of information right now
we had web forms but for let's say the
whole back-end stuff the the chat bot is
nothing more than a very simple form
let's say now of course when you have
chat balls and you've got this
prediction models you can actually
really cool stuff by making the chat
bolts actually quite smart in its
responses so that's definitely you know
stuff that we've thinking about and
breathing in my neck line okay so yeah
absolutely stuff that we are currently
experimenting with
there's some very interesting things
were doing in that area yes can't talk
about it I'm afraid that's not open
source any other questions
already want to get a few seconds left
yeah well thanks very much everyone
thank you very much have a good devoxx
or rest of the books thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>