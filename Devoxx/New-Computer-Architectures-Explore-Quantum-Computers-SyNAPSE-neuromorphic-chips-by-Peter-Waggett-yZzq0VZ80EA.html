<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>New Computer Architectures : Explore Quantum Computers &amp; SyNAPSE neuromorphic chips by Peter Waggett | Coder Coacher - Coaching Coders</title><meta content="New Computer Architectures : Explore Quantum Computers &amp; SyNAPSE neuromorphic chips by Peter Waggett - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>New Computer Architectures : Explore Quantum Computers &amp; SyNAPSE neuromorphic chips by Peter Waggett</b></h2><h5 class="post__date">2017-04-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yZzq0VZ80EA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Oh Kailyn I make it half past so I
kickoff factors I know that there's a
lot of other parallel sessions going on
so what I'm gonna try and do today is go
through some of the stuff we're doing in
terms of developing new architectures
and how we hope to make them available
people to get the hands-on and play with
particularly two areas I'm looking at
one which is neuromorphic processing and
the other is quantum computing so I'll
just give me a bit of background on me
name's Peter wagget my PhD is rocket
science which for me is great because if
somebody says this isn't rocket science
I can say well it can't help you
but having failed to become an astronaut
I looked around for the next most
exciting career I could find and I've
either got limited imagination or has
been something in this IT research that
kept me going for about 20 years and
currently I'm director of emerging
technology at IBM's Hosie labs which is
just outside Winchester so the first
question I need to get asked is why do
you need an emerging technology group
and that's usually by people from
business who have done the MBAs and I've
seen this nice curve about how a product
gets out there in the marketplace now
gets adopted it's a very smooth curve
you get some kind of visionary comes up
with an idea it's shown to the business
people they adopt it and then eventually
gets replaced by something else so over
time sales go up sales go down something
else comes in to replace it but what
happened I guess around about the late
80s it was a guy working in California
called Jeff Moore who pointed out
actually for a lot of IT and a lot of
high technology there was a gap between
effectively the people that understood
the technology and the people that
understood the business and what was
happening was that a lot of technologies
were getting stalled and not really been
picked up and adopted so the aim of the
group that are running in her sleigh is
to play in that chasm it's try and act
as a bridge between the business people
the technologists and draw them together
such that we can get an adoption of
Technology and part of its just due to
the fact that you know people speak a
different language you know the
technologists can't explain the business
benefit and the business people don't
understand
technology and what it can do for them
so the team that I've got is
deliberately multidisciplinary it's set
up so that we can actually bridge that
gap I've got some people who are
complete propeller heads who I wouldn't
put in front of most clients and I've
got some people that you wouldn't
actually realize could code at all but
it seems to work because we've been
doing it for about 20 years now so a big
part of what we try to do is actually
try and also understand what are the
trends what are the things that really
are emerging and how can we try and pull
those together and so we do a lot of
work both internally and externally
around forecasting so we're heavily
involved in a series of internal
forecasts I mean the one that people
probably have heard of is the global
technology outlook and I'll describe
that bit that later on but that's really
our internal forecast that enables us to
do a route map for all the products and
the development we're doing we've got to
think all the global innovation outlook
which is trying to capture some of the
things that happen in society and
understand how you can actually take
advantage of the fact that you know
society's picking up technologies
quicker than a lot of the businesses
doing five and five is just five
technologies are going to make an impact
in the five year time frame and the
final one that is the Grand Challenges
which was the sort of thing that we did
where we set the research groups the
task of in a beating Kasparov at chess
or you know playing people are with
jeopardy and winning that sort of game
so those are the things that drive our
research groups forward but you know
we're also very aware that you know we
need to be talking to the outside world
as well so I do a lot of work with
analysts with like-minded research
groups academia and also on client
projects but I said the key thing that
we've driven a lot of stuff from is what
we call this global technology outlook
what happens every year is that the call
goes out to the R&amp;amp;D community give us
your bright ideas give us your thoughts
what's going to be disruptive technology
over the next 10 years those ideas get
taken on board by a committee that
committee produces the report we then do
a gap analysis and that's what direct
where we spend our R&amp;amp;D spend every year
the committee gets taken apart and a new
committee gets put in place so stops are
becoming stale and it becomes quite a
competitive thing to try and produce the
sort of like best GTO I may be biased
but the one I was involved in about
three years ago was the best GTO but I
say I might be biased on that one thing
that's come out of it though and one
thing that is really becoming quite
apparent is that the GTO in the past was
almost a case of articulating what's
going to happen with Moore's law you
know in terms of what the impact is
going to be so we've been calling it so
like automating the world to really
trying to get things passed and faster
in terms of what we've got out there but
over the last few years what we've found
is that there's been a trend which is
towards actually trying to understand
the world and to do that what we need is
a whole set of technologies that you
know machine learning object recognition
video speech analytics all those sort of
things that I've listed up there that
typically are not very well served by a
classical von Neumann type of
architecture they get very overloaded
very quickly and aren't really able to
satisfy some of those requests so one of
the areas they've been looking at is you
know what's happening next in terms of
computing and you know we've been
looking at some of the different things
we think and the time scales that we've
got on these things here I said what I'm
gonna try and do is just go through what
we think of a sort of like three to ten
years out the corner of computing and
the nearest synaptic processing side of
things we paid a huge amount of money
for this logo which are smarter planet
logo so I thought I better put it up
there at least we get some money out of
return from it but really all we're
trying to say is that you know we've got
a vision that there's a smarter planet
out there it's instrumented
interconnected it intelligence driven it
and it's interactive and I think that
interactive thing is the thing that
stand to come out more in terms of the
weave seeing a blurring of distinction
between wash machine generated much
human generated content and why do I say
that you were struggling with a poem and
architectures well you know Klee
everyone's familiar with them they're
very simple in concept I wouldn't like
to claim that I could design some of the
the more revolutionary things are going
on with them now but you know you've got
an eye oh you've got a CPU got memory
and it's all based around classical ones
and zeros in terms of what they do with
these things here and I mean summary is
that it can check many different
possibilities in rapid succession and
the whole interests being driven about
getting that succession quicker hiring
out the clock speeds trying to
understand how we can shorten
interconnects to get better transmission
speeds through the systems here but
everything in sequence and that's I
think where we're struggling and it's
the sort of thing that you know we need
to look at with a different eye on
because regardless of how quickly
Moore's Law is driving us you know it's
only state of different ways but it's
only doubling every 18 months and but
some of the applications were looking at
that really isn't good enough it is
driving the industry in terms of the von
Lohmann classical systems but it's
really now struggling and the two areas
that it's struggling with are really
heat or energy I mean how much is
technically get these things driven at
the speeds that they're working out but
also the quantum effects as we're
standing gets smaller and smaller you
know what we're finding is that we've
got quantum tunneling that's causing
problems in terms of the error rate and
things are coming through for those sort
of systems so in both of those areas
there are real problems in terms of
trying to improve performance at quicker
than you know what we're working at now
so the two systems that we've been
looking at the one on the left is what's
known as a synaptic chip and the one the
right is the quantum computer are
tackling each of those problems in
different ways so on the Left were
tackling the heat and the energy problem
on the right we're tackling the quantum
were refracting brace in the quantum
uncertainty and actually using that to
probe process things so the nearest
synaptic chip I'm probably the oldest
one here so don't think anybody ever
remember transputer arrays oh - all
right so I'm not here perhaps I'm not
the old as well but you know what they
were was the saw like effectively a
small processing element you build up
into an array and they every element was
interconnected such that you could do
processing that's much more
similar to the way the brain works the
neat thing about what we've done with
the TrueNorth chip is we've actually
taken that transputer array and put it
onto a chip so you've got a million
neurons effectively with 256 million
interconnections between them and what
that means is that you have to get your
head around the fact that you're
processing in a completely different way
much more like the way that the brain
works but the energy required for this
thing is very small so running flat out
it's going about 73 milli watts which
given you know difficult to give you a
sort of like a direct comparison but you
know certainly at those sort of levels
you'd be talking about having say a
mobile phone powered by one of these
things that would last some months
between recharging so it's a really
quite a revolutionary way in terms of
tackling the heat and the energy but
it's doing something very different yep
it's getting down to that sort of level
it's becoming a sort of like more of a
biological level of energy set up and it
but it requires a completely different
way of trying to tackle these things but
you know if you think about it you know
one interesting model is that you know
if you're trying to cross the road we
don't sit there and analyze every single
bit around you to understand when it's
safe to go across the time could take
you to do that would probably mean you
get run over halfway while they were
trying to sort out what the information
is coming in you're looking for changes
and it you have to with this sort of
system the ability to pick up changes
rather than doing a background search
through all the day to the town there so
it's a very different way of working the
quantum computing again very different
and what come we'll go through some of
that stuff there but you know really
what we're looking at for a certain
class of problems like cryptography drug
design all these different things that
require incredibly intricate pattern
matching type of capabilities
there is a huge promise with a quantum
computer to actually do those things
very quickly so starting with the
neuromorphic chip code on the side is
60% of valuable sensory data has lost
its value within milliseconds you know
if you're trying to think about if
you're trying to drive in driverless
cars if you're trying to do things that
require interaction with the real world
you have to be working pretty much in
real time if you're not then you've got
that very little value coming out of it
similarly you know when we're all
looking at say information that's on you
know sensory like data you find that
it's very difficult to understand what
value it is that you know if you're
picking it up and not doing anything for
quite a while so given this sort of
capability built into the chip the sort
of activity looking at is the you know
the ability to have built-in onboard
processing for cameras cars phones all
these different things here such that
that the actual sensor itself can do the
processing and only give out the
metadata so rather than having the issue
of trying to gather all the data send it
somewhere to be process
somebody to and do the analytics on it
and then do some kind of action on it
actually having this whole feedback loop
built into the device itself and with
these sort of capabilities say
particular one the bottom in the center
there this idea of having sort of like a
floating drone that can go out there do
temperature measurements and do
real-time analytics on it
would enable you to do much better
forecasting but also doing a lot of work
around climate change and things like
that and that's really why you know we
try and do with these things here so
it's really understanding what benefits
we can get from trying to tackle math to
give you an example the sort of thing
that we're doing this is a famous test
that is set up for law the machine
learning type of setups and this one is
being collected and processed by this
neurosynaptic chip I'll just run it
through first you can see there that
there's some things in there that like
the car which has been plugged up is
blue that are stationary but we've got
this chiptune such that can pick up any
sort of like cards in there whether it's
moving with the station and put on them
there we've trained on three categories
of objects people which come up in the
green bicycles which come up in the
purple and cars which come up in the
blue but interestingly when you look at
this thing through just run again we see
coming in on the right there's something
which is flicking a room between purple
and green it's somebody on skateboard we
never told you what a skateboard is it's
struggling in its real world construct
to actually understand how to classify
that thing so it makes its best guess at
the time that it's going as to what it's
on there and what we've been looking at
is how we can then start putting
learning loops around that such as
anything that comes out as being an
uncertainty is reclassified then put
back into the system such that you get a
new category and try and work those
things through so that's what we're
aiming to do with this setup here
and we've done one system which is for
us parochial in in the UK managing the
English Channel it's one of the busiest
waterways in the world it's got a huge
problem in terms of illegal dumping of
oil so a lot of the ships that go around
but basically clean out their tanks and
dump a lot of oil into the English
Channel similarly you know we need to
understand what ships are going around
they're both from a safety point of view
but also security so there's a sense
that they've been looking at which is
called The Sentinel sensor it's set up
by the European Space Agency flying at
the moment and it what's called a
synthetic aperture radar how it works is
that it's side-looking as it flies past
something it's get a huge swath of data
and generates that in terabytes of data
that then get has a process in terms of
the system traditional systems have to
basically wait for the day to be
captured once that takes being captured
the process into an image then you do
image detection on that data with the
synaptic chip we've just owned
demonstrator which is put up in place of
the idea is that that's going to fly on
the next versions of the satellites such
that once the data is collected its
processed onboard and you only send down
the actual points of interest that
enables you to get away from all of this
sort of issues of data overload but also
latency in terms of the imagery that are
coming through so that's the sort of
application that we're looking at to try
and do work with on this synaptic chip
and the first feasibility turns have
been done have been done affected with
offline days to actually prove that if
we did have a thing in place that it
would actually be able to get the setup
and the sort of data that we're getting
is looking very good so basically from
one of those chips were able to pick out
and categorize a whole range of
different ships and different
capabilities of things that we've got on
this sort of system so in that instance
there is no way that you would be
able to carry a computer big enough to
do that processing onboard a satellite
and you know basically it would still
not be able to process in time to enable
it to get this real-time capability so
what things have been looking at just
play this clip as well
hello mr. yakamoto welcome back to the
gap how those assorted tank types work
out for you mister anybody know what the
film is Minority Report we were asked by
a retailer to recreate that system for
them and one of the things we needed to
do was to get the real-time processing
at the level that we needed because we
were using the same way they had their
iris recognition we were able to do that
with a synaptic chip in real time so
effectively we proved that we could
replicate that system using a simple
processing algorithm around that new
chip there were several issues with it I
mean you see in the film the two things
that happened in the film that don't
happen in real life you don't get the
flash of light to tell you you're being
looked at and you can't swap eyeballs
that was the other thing that we found
was different from the film but
everything else we could do and the only
issue we had it was and the thing is
slowing us up now is that the legal
departments got involved and basically
said not until you've sorted out all the
privacy issues can you go ahead and do
this whole thing and the other one we're
looking at this one is slightly
different in that we were asked
challenged by the BBC to do a system
that would allow us to use a gaming
headset to drive a London cab around
Piccadilly Circus again the legal
department got involved in that point
they said you can't do some Piccadilly
Circus so they let us loose on Santa
podrace way but but I say we build this
with a program called bang goes the
theory and basically just thinking
enable you to drive this cab now one of
the things we're looking at is we
clearly it's it's not autonomous car
such because we're actually just driving
it remotely but we're trying to look at
using some of these chips and some of
these architectures to actually put in
safety features so I'll show you what we
did
will our brains be up to the challenge
go
yes I've done it the first-ever
brain-controlled taxi so it was a bit of
fun and I by cutting it there I didn't
show the bit where it veered off to the
right and took out the barrier but it's
it's an indication that with these sort
of applications that we're trying to
look at we will need to look at a
different set of processing capabilities
so the other one is going to look at at
this point I'll give an apology if
anybody was coming here expecting
equations I had a short amount of time
so I decided not to put the equations
you know if you want to see the
equations see me afterwards quantum
computing based on quantum mechanics
couple of things that really drive that
there's a couple of things that known as
the uncertainty principle and really
what that's saying is that you prepared
variables you can't have an absolute
knowledge of both of those paired
variables so if you have things like
position and speed you our position and
velocity you can't measure both of those
absolutely because the problem is when
you try to measure one you destroy your
information about the other one
and the fact that you know you've got
this wave equations they've got a wave
particle duality meaning that some
things that you expected to act as in a
particles don't do that when you get
them smaller so for example if I run
into that wall I can keep running into
that wall and I'll just bounce off it
because I'm above a certain size where
there's not going to be any ability for
me to slip through the empty gaps within
that wall to get through it but when you
start to get down to the atomic level
and what you find is that you can fire
say electrons or something like that and
every now and then just go straight
through so you've got to worry about all
those sort of things as you're trying to
do it it's a different way of thinking
again and as different approach is
needed but it's got huge potential the
part of the promise is that rather than
checking things in sequence we're going
to be able to check a huge number of
possibilities in parallel
and the reason we're doing that we're
based on qubits rather than classical
bits the easiest way I found to sort
like get my head around it is that you
know classical bits have a 1 a 0 so if
you imagine the earth what you'd be
saying is that with a standard bit you'd
measuring the North Pole of the South
Pole with a qubit you can measure
anything around the surface of the earth
and have a different band values
associated with it so you can have a
different information stored to say in
London so you've got in San Francisco or
San Jose or somewhere like that and you
can interrogate those sort of things
there the interesting thing as well is
that some of those bits are in multiple
state at one time so the only thing that
determines the value is once you do the
measurement and again part of the
quantum mechanical sort of like folklore
around this thing is that it's the
classic thing of Schrodinger's cat which
is that you don't know whether to live
or dead until you actually open the box
and it you've got those sort of issues
and coming through on that they're so
qubits are incredibly fast except when
you do the measurements so what you have
to be aware of is that there are certain
things that classical computers are very
good at that qubits are probably going
to be slower at it's only once you
started getting to some of the
applications that make sense for a qubit
do you actually start to get those
advantages and coming through so it's
theoretically awesome amount of
increasing performance so say for
example you know R all been a lot of
worry in the press about crypto
decryption and things like that and you
know by making the RSA keys bigger and
bigger your actuation point where
classical computing can't crack them
typically for some of the things we've
been looking at say 1024 key strengths
and things like that you would need
probably about 30 cubits - I do the
processing to decode that in pretty much
near real-time so you've got this huge
capably coming in
and the key thing is that the
performance of a cubit system doubles
for every cubit you put onto it so you
don't have to you know basically to
double the performance you just put one
more cubed so that means that you know
once you're starting to get you through
way through these systems up until say
into the 30s 40s 50s
you've got more processing power than
being deployed anywhere else in the
world at the time so you know it's
really phenomenal capability coming
through now that's the theory the issue
you've God is that typically these
things are very difficult to set up and
they're very difficult to maintain the
largest numbers of qubits that are
really being talked about at the moment
is is five and they are not approaching
the theoretical limit of five cubits
because of errors and uncertainties that
come into the systems but and so the
simplest calculations have been done
with them a fairly trivial you know it's
basic multiplication and things like
that so you know we're starting on a
journey with this but there is a huge
potential coming in so the closer we can
get to the theoretical performance and
the more cubits we can put into it then
the better you know we're going to be a
fire firing the performance coming
through from it but I say things such as
you know the Traveling Salesman type
problem crypto decryption all of those
sort of applications are going to be
able to be handled in very short order
by these sort of systems one thing to
said was that you know you know ibm's
i've been doing these GTOs for quite a
while and just something that you know
we've been coming out quite consistently
is that we need to look at quantum
computing so last month we launched what
was our quantum program which is God
they can try and get things going in
terms of the quantum experience and get
people in the developer community
involved in this sort of activity so
Master six we launched this program it's
effectively now an open program
we're and I'll give you the website we
can go into we can sign up a new start
get access to one of these systems
you're able to go in play with a five
cubits system and play with simulators
around those sort of systems such you
can understand how to put together your
processing around a quantum computer the
intention and where we look working
towards is clear to start producing
these things in tens of qubits but I
think what's been really important and
this this is quite interesting
demonstration what we're trying to do is
that we're embracing the fact that you
know we know at the moment the qubit
systems that we've got in place now are
not perfect they do have errors coming
in the ideal qubit system would be
completely isolated from any
interactions with the outside world I
any vibration or thing that comes into
it would be a problem because that will
affect the capabilities of the systems
and it will introduce errors so one
things to be looking at is how we can
actually approve approach a more perfect
qubit I lower error rates but at the
same time increase the number of qubits
that we're putting together to actually
do this sort of processing so there's a
concept that we put in place which we
call in the quantum volume which is
basically an indication of just how
close we get into the theoretical
capability of individual qubits and then
understanding how many qubits we can
actually key together because one of the
things that I think is apparent and one
concern are quite high on this thing
here is that you've got a high error
rate on these qubits actually increasing
them doesn't help you because your
errors are counterbalancing the increase
in performance you getting from the
individual additional qubits so we're
going to make a push to try and get the
error rates down and then start to look
at putting more capability around them
and they say the call for the
development community I think has been
really quite interesting because this is
a big unknown you know we don't know we
understand at the moment clearly you
know the easy problems per classical
computing frankly it's not worth us
using a quantum computer for the hard
problems it is and there's also some
that we're able to look at that we don't
even think we've been able to address in
terms of the classical architecture and
putting things in place so for us I
think this is going to be a fairly big
step and it's certainly something that I
think we're going to be seeing a lot of
work on but we do realize and one of the
things we're looking at is just how we
actually get this developer community
getting in place and trying to
understand this thing so the one website
that I've got on here which is essays
worth looking at is the one I've listed
down the bottom so it's IBM research
research at ibm.com slash IBM - Q - Q X
and that's quantum experience but
there's a whole set of things in there
so there's tutorials the simulations
there's graphical programming SDK
becoming soon for the api's and access
to a fully operational five qubit system
over the web so people can come in and
actually run stuff on that to date in
terms of launching the thing we've had
40,000 users 275 thousand programs been
running the thing there's been fifteen
scientific provocations go and gone
already good you know given that we've
been you know as sort of like an alpha
beater and now launch date is pretty
good and we've got 10 departments
looking to use this as part of that
teaching program so that I think is a is
the important takeaways probably that
website if you're interested in this
sort of area is I'll log on to that
under it gives you understanding of what
the quantum computers around it gives
you understanding of what the
capabilities are but it also gives you
access into this system that we put in
place now it's a one thing I've always
been aware of is in fact
back to one of the classical articles
are written by Niels Bohr who was one of
the founders of quantum physics and he
said that prediction is difficult
especially about the future so what I'm
giving you is a lot of predictions take
them with a pinch of salt but if you're
not convinced by anything I've said I've
got this nice graphic here which is the
classical computers in the 1940s and the
quantum computers of the 2010s
I think there's pretty good similarity
there so 6070 years then we should be
reaching the point where quantum
computing takes over completely so I'll
stop at that point and open up if there
any questions or any comments yep oops
yeah
so the problems you get are saying is
that until you actually measure
something the quantum computer is very
fast so what you don't want to do is do
your standard problems that require a
huge amount of measurements so it's not
going to do things like make you know
video stream quicker or media streams
quicker it's not going to do anything
like you know do more you know intricate
calculations
unless you've backed them up correctly
but you know say 4,000 24 crypto
decryption you know you're talking about
30 cubits to do it in a matter of
minutes whereas if you looked at a
classical architecture then you're
talking about you know a gigahertz
processor would probably about three
thousand years or something I think was
the number on that one there so anything
that scales at a level such that it
becomes you know difficult to understand
how you could get it there is the sort
thing we try and do scheduling problems
you know scheduling again it's you know
one of those things that becomes very
complex very quickly and again that's
the sort of thing that would be very
appropriate to try and do it image
matching pattern right matching anything
like that that's got a I guess a form
that you're looking at rather than it's
you know a series of measurements you're
making those are sort of things that it
will be best used for but I say unless
you're going to get something like about
30 odd you know
qubits working efficiently that's once
the things start to become a real
practical proposition yeah yeah
yeah yes so the idea is that I mean I
guess going back to the probably and
again this is not a direction to thought
more than thing else is that you know
typically have deployed things like you
know FPGAs and different things like
that sort of like they've been hosted on
a system that handles all of the stuff
that you know the system is not
particularly good at and it just has
that as a if you like a plug in effects
we try and do now you know given the
constraints around classic quantum
computing in the bone which is that you
know to minimize the vibrations and to
minimize the errors you know you have
the thing very cold and things like that
it's probably gonna be something you're
gonna be able to throw stuff across the
web but I think and that's the
architecture they're looking at with
this developer community so you know say
for example on the crypto thing you'd
have the ability to package up they you
know you're the thing you're trying to
decrypt fire in the system the answer
would come back and then you would care
and doing the rest of the processing
around the edge so I think that that's
probably a good model to think about how
it would work out I don't think you'll
have standalone ones it's only for a
long time for quite a while sorry
well it's a shameful thing we were
looking at there I mean anything that
requires say shedding programs any kind
of drug discovery type of things we're
looking at you're trying to pick up
patterns in data and patterns in
structures all of those things would be
very appropriate for a quantum computer
it's really those sort of complex tasks
for traditional computers those are
things we can try and throw this thing
yeah I think this is something that
there'll be several groups working I
know there's some very strong groups
around particular countries so
Australia's got a very strong group to
work in this space or some of the UK
some in Switzerland you know I think at
the academic level I mean my hope would
be is that it'll be the standard
academic model that you know they'll
publish and share and that way we'll
drive the knowledge forward so there's
no monopoly on good ideas and good
thoughts you know I think everything we
do to pull that knowledge I think would
be worthwhile
yep
it depends on the the the particular
architecture using pure cubits you know
some of them are set up with MRI type
imaging systems that are being used to
actually do the positioning but also do
the measuring the systems on there so
you know MRIs are fairly intensive users
of well energy and also helium which is
another major issue you've got it's a
different way of a different problem
because in a lot of it is to do with the
cooling and everything else he needs to
you know most data centers will run it
you know ambient conditions whereas
these things are going to work it
effectively close to zero so short
answer is no in terms the practicalities
are a bit haven't done but you know on
the counter bounce you know if we're
talking about thirty cubits I mean it is
only thirty bits you know so whereas you
know we're seeing the stuff that's put
in place now which you know 20,000 cores
or something like that you know for
something that's putting it out there
instinctively if that can be replaced by
a much more number of qubits then you
would think that there will be some kind
of benefits are coming off it but you
know we're not at the stage of actually
planning these things out yeah yeah
yes
well I think this is where this is
possibly one the more exciting areas and
reason say those that I think where
we're moving with these sort of systems
and actually even with the neuromorphic
systems you're moving into a more
probabilistic based domain where I think
we'll be trying to develop programming
that accepts a degree of error and so
you know you really what you're looking
for is detecting the catastrophic
problems that mean you really have got
an issue I'm going to go back with it
but I think we're going to be getting
answers that are going to be more you
know the answer is probably this rather
than it's definitely that or whatever so
I think that the there is a there is a
sort of like a theory that you might
actually end up having a more
probabilistic type of programming model
that comes into these things but you
know if you go if you go these things
here the the actual you can you can you
can minimize the errors by minimizing
the advantages you get out of the qubits
and that's what's behind this idea about
the quantum volume if say for example
you know we took the model of the earth
and he gridded up into ten kilometer
grids and he had an arrow that was a
couple of kilometers then that may not
be too big a problem in that it'll you
know affect me net out to be at the same
point that you're trying to work the
data prom but if you had a you know 10
100 meter error then the whole thing
would be impossible to use so you might
have to go to say a one kilometer grid
so that you there are different
approaches that you can try and do these
things I think it's safe to say the news
you've got the real answer yet
so you know it's an interesting area to
look into
yeah
well yeah because the problem you've got
with some of these things is that you
know safeties have to quantum
mechanically isolate the whole system
from everything else in their vibration
and their level you talking about an
atom being affected by vibration
occasionally will be a problem so I
think we'll have to have more tolerant
and and more correction built into the
software than the actual hardware
elements the system yep
yeah I mean basically what you know what
you try and do is that you're you are
applying energy to a system to put a an
element of it out of kilter such that
you've gotten got the capability of
getting a you know a reading back on
that one that then enables you to do it
so you know you're having to manipulate
at the atomic level certainly to try and
get some kind of capabilities on there
and you know that's compared to but then
you know the problem we got with a lot
of the hardware Devon at the moment is
that you know we're getting down to
levels in terms of the gates that we're
trying to construct with the material
substrates that you know are reaching
those sort of like atomic levels or such
that the quantum effects mean that you
know electrons can tunnel through and
things like that and cause problems so
we're going to hit those problems anyway
even if we just stick with the classical
architectures think there's one over
there
yep
I mean I think this I think that's huge
promise I think you know it's going to
be a case of understanding how we can
realize this rather than you know
claiming up front that we would know all
the applications and ways we could put
this stuff together yeah yeah all right
say I think this huge promise and I say
certainly I you know I think that it
it'd be good to sound like em if you're
interested get into that website and see
what you can pick up from it
that one's a bit more interesting there
is some if you go to Maine IBM site you
can pick that thing up we don't have the
capability to have simulators or have
that thing set up this limited
production run at the moment there's
only a hundred in the world we've got
three of them and the rest them being
handed out to academics it's not at this
stage a you know a fully you know
privatized version but it's just a
different architecture that we think
it's got some real promise buts in the
quantum one has been opened up so that
one is were able to get into
I can imagine they they are but if they
were I couldn't tell you but now I mean
with the group that we're working with
this European Space Agency and that's
all on purely civil applications of the
imaging side of things but you know the
capability could be used in a number of
different ways yep
I think if you I think it's more it's
the bandwidth on the academics now if
you put more money in that don't they'll
flock to it but um it takes a long time
to get your head around and get you you
know the the thought on this thing yeah
I think there's a there are a few
departments that are very strong but I
think there's a lot of I think that's
going to limit is it's going to be
academics and the people working in this
space rather than this stage the money
necessarily well no I mean what they're
looking at is effectively you know
single atoms so and some systems have
been using well so there are only think
using silicon a lot as their substrate
but others are using particular atoms
where you know you're picking up the
effectively you're manipulating the spin
on it on the outer electron and things
like that
so any doing that you know usually with
something like you know MRI type systems
and a atomic probe that will try and
direct them so it's heavyweight systems
in terms of the designs have put in
place for
yeah okay okay could do I mean it's like
one of those things that you know my
background asleep however it was radio
astronomy and you know we used to keep
building bigger and bigger dishes but
then everybody found that you know
single dipoles dotted across the field
and clever maths could enable you to
synthesize an array that was bigger than
the biggest dish you could put out there
so you know I think that again that
that's an interesting areas that you
could almost have an interferometric
type of approach to some of these things
and that again might be an interesting
way of doing it and cut down you know
some of the costs and capabilities on
systems
yeah yeah yeah yeah that's right yeah I
do think there's been some issues I
think it lack of helium it's gonna be a
problem at some point because it's
really being exercised by the existing
MRI machines we've got out there and I
think that there's a definite shortage
of helium which it just seems a bizarre
thing to have to worry about but yeah
it's to get a community of developers
out there that are able and willing to
pick this stuff up and work with it so
again it's down to the skills and
education and putting the thing in place
okay back to the right</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>