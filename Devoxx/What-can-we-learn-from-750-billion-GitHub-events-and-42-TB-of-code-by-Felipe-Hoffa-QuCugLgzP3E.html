<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What can we learn from 750 billion GitHub events and 42 TB of code by Felipe Hoffa | Coder Coacher - Coaching Coders</title><meta content="What can we learn from 750 billion GitHub events and 42 TB of code by Felipe Hoffa - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What can we learn from 750 billion GitHub events and 42 TB of code by Felipe Hoffa</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QuCugLgzP3E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Birgit make it do it makes it excellent
hello everyone thank you for coming
super happy to be here I didn't sleep
much yesterday but that yet lack fault
I'm Felipe Hoffa I'm a developer
advocate for Google I work in San
Francisco I traveled all the way here to
present this to you so hopefully you
will enjoy it if you have any questions
interrupt me most of what I'm doing here
is interactive so if you want to do the
same query for any other project or you
have questions feel free to ask and if
we have to move on we move on but it's
good to be as interactive as possible
any questions excellent let's get
started so this talks about analyzing
github analyzing 750 billion events 46
terabytes of code and we are going to do
it interactively here thanks to having
github data or bigquery and having the
query who knows bigquery by the way
we're going to see a few hands we will
change the answer during the stop so
what do you see here just to get started
what is this mmm it have yes tensorflow
yes code so there's a lot of things that
we can see here not it's not only code
it's called that has a license it's
called that kind of depth and import it
was written a certain date there's a lot
of things that we can start analyzing
just by looking at looking at code as it
what data and we also have more data
here we have metadata like the project
the number of stars how big the file is
how many people have contributed and I
call this data and it's very big there
because it's big data we are going to
collect a lot of that
and so who wants to analyze github I
gave you because you chose the stock but
this is important for project
maintainers who have their own popular
project on github here something good so
these are things that you may want to
know how popular your project is who is
paying attention to it how did they get
to your project when you want to apply
changes if you want to change the API if
you want to apply a breaking change
should you do it how would you do it how
do you measure the impact of it and you
also want to know if your project is
Kelsey if your organisation closing your
issues on time if the community
participating we are going to answer
those questions same if you're a project
user you want to know the same things
you want to know what's the best way to
request features how to place a feature
how to back your request with data you
want to know what other projects to
follow then especially before you become
a producer when you're choosing a
project you want the same answers you
want to know if if you have to choose
which project which one is more popular
with one if healthier etcetera etcetera
and if you that love data you this is a
lot of data to analyze and that's how I
started here we're going to use three
main data sets get have archives this
one has eight point seven billion events
since 2011 and updates hourly DX torrent
is another data set that is capturing so
the travel card is capturing all of the
github events hourly and the edge
torrent that's a streamline job but it
goes further it goes round the graph
annotates all of these events and also
gives you real-time updates second by
second and then the last repository we
are going to use is a copy or follows
github
open source code that we also have on
bigquery that will be sent around 46
terabytes of Scott and we're going to
get closer to this data set now but to
start back in 2012 howdy
we'll get all of this data in a user
replace this is ilya grigorik from my
from google tool and he was downloading
he started downloading all of github
events and he was wondering how to share
them how to use them and back in the
first the same time 2012 we were
launching the carissa product at Google
cloud and he figured out that that was a
good place because first you start with
Thailand pipes like this this is the
JSON file with all of the events for a
certain date at a certain hour and it's
not that big of a file but then the more
hours to go by the more days ago by the
more data you start gathering so for
example one of this file for one hour at
the in 2016 is about PI mega writes
compress takes nothing to download it
has around 18,000 lines of events but
the problem is if you want to do this
for seven years
then you have 2.39 terabytes of
compressed data and you have 1.1 billion
events so you cannot go and you have
downloaded files you need something
different and this is where the query
can be query for those that don't know
it it's a Google cloud product it's
always on it's a service there's nothing
you need to configure it's really really
fast you will see it now we will analyze
all these things with sequel scales
there's it works with any of your
favorite tools tableau our pipes or
lucre etc etc etc and something that is
willing interesting here is that you can
share that if I load data to the query
it's private until I decide to share it
with someone with another organization
or with everyone I can share data loaded
to the query with everyone and then
everyone gets a free monthly terabytes
no cleric are needed you just need to
figure out how to create the account on
digital data project and the
every month you can do a terabyte of
queries and yes you can do now
everything that I'm going to do so let's
start by looking at the space what do I
mean by this github stars a way to
measure how popular a project is is to
look at their stars it's a very easy
number to measure but we can go much
deeper than that so let me show you what
happens this is the bigquery web you
line makes things if you don't want to
connect it to anything else and I have
github archive here let me put in search
for 2016 Ghita archive so this is my
2016 summary of all events from last
year I could be looking at yesterday but
let me start with a full year we have
events of a certain type and the payload
is a JSON string with a lot of
information that's how we collect non
structural data because some types of
schema changes a repo and actor proper
perm and these crafts this table for
2015 has 256 gigabytes of data 320
billion events that happened on github
and if you want to see the data here we
have a preview so that we have a fork
which is public a lot of metadata there
you would do deeper and we have a lot of
X and let me query stable just to look
at how many stars were given in 2016
where price equals what event what event
are the events that represent a stock
has been given and in 2015 people gave
26 million stars and you can see that
analyzing all of these roles was pretty
fast and easy and then what we want to
do is
do something more interesting start
asking questions like what were the top
projects in 2016 and for that I just
need the rapper name and I can group by
the second column order by the first one
in descending order limit let's get the
top 20 projects for 2015
again it's incredible fast I think and
these were the top projects you might be
familiar with them free code camp for
people who for learning to call the
Google interview niversity
second free programming books you jes
tensorflow
and so on something interesting here I
don't know can you read this or should I
make it bigger better something
interesting is how many more stars free
code camp has than any other project
like we're talking about an order of
magnitude different and part of this is
because this is a really popular project
to learn coding and the first step is to
start this project so they get a lot of
stuff now as I will show you an the
official list of events and let me see
one of my projects for example this one
every time I start this project and
generating a new starring event so if
I'm counting things like this
this project has seven stars but just by
Counting I'm getting a lot more shake
stars so when you are working with the
stars in love veggies you really want to
do something different like count the
distinct actor I see and with this real
count and if we order by the real count
here we get the real number of staff by
unique users that were given in 2015
again we can change it to any time and
again it's fast and easy to go and be
changing these things oh yeah we can see
the some projects they go from a hundred
to thousand stars 235 and and we can
start getting rid of fake stuff in fact
I was looking yesterday at this and I
won't run the query now this year there
is one person that has given thousand of
stars to the same project and I don't
know why or how but they have doing this
and so it's really important to be
duplicate if you want a real camp so
this slides with them interactively one
not all staff are equal and like every
star that someone is giving you your
project it has a story behind every star
comes from salmon so just to count the
number of stars my project has more
stars than your project is not enough
maybe you're interested in stars by
people that are new to github or maybe
you're interested on starter come from
people that told a lot or from people
that are interested in big data or
people that are interested in other
things new programmers or programmers
this country there are so many
dimensions we can look at things so for
example as we were looking this is free
code camber substantial flow free code
can receive an order of magnitude more
stars more than tensorflow
but again we can do more interesting
queries like the one that I have here
where I want to see count only people
that have written more than 20 comments
on github for me that means that's an
experienced user that some of the
someone that is doing a more someone
that is have 60s so when we start asking
questions like this we start getting a
different number of top projects and
they don't know where this one is slow
but here you are so for example just to
see some dimensions of recode cut versus
tensorflow
the age of user I don't know the real
life but I know how long they've these
accounts can exist on github the age of
tensorflow starters is double the age of
three code camp and they people that
drive star in terms of flow have start
80 projects instead of twelve and how
many issues they've written and how many
Papa Papa pop stuff how many pushes I
then have many repositories a push to
all the measures that might be
interesting when you want to know who is
starring who is the handle project so if
you go and measure only people that have
written more than 20 comments free code
camp goes down from a hundred seventy
thousand stars to only three thousand
and the expense of flow goes down to but
not that much and maybe this ranking is
more important to me in fact the top
project for 2016 the ranking changes a
lot here where the top project by
experienced users is young which was on
number 10 at first sight and then terms
of flow is not even at the top ten
projects by this measure still apps but
not that high and then you can start
asking questions like off from on the
Talmud project what else are they
interested in and and you can see all
the history so for example with this
query and looking at people that started
the flow I'm looking at all of the other
projects very start and I'm removing
people that also start free code camp
just to get a different view and this
query shows me related projects people
that start my project
what else they start and it's kind of
monkey like yes if showing me on top
other so yes people start tensorflow two
to two thousand stars but they we are
getting that they're also still models
and these people are cafe Ikeda
the googling tip University so yes this
is working I don't know if you want me
to run this query for any other Java
project related to it or we can move on
yes sorry yes
let's fight oh yes so what I did here is
for this ranking
I removed people that have start too
many things like yeah where people that
had that gave more than thirty thousand
start with 2016 I'm not interested in
them for this purposes same if they
start only one thing then be fed me
nothing because there's no related
project to look at thank you
and then stars where you start getting
stuff stuff you don't get them every day
at the same rate usually it happens like
this a you get a really big peak of
stars one day or different different
days and if you want to know where
people are coming from it's usually
happiness when your project is
publishing hacker news do you get a lot
of people interested that they leave
then and the notations I have here is
when this project was on the hacker news
front page and even more interesting I
didn't write these annotations manually
because in Vic we have a lot more public
data set and with a simple query or not
so simple I can join across projects I
can join across hacking music and the
negative events and I can look at yes
things are happening on social media I
also have a lot of Reddit and I can
annotate how things how the social media
sites are impacting my project
that's the query if you want to go
deeper a prayer house prayers have a lot
of issues a bit on filing issues
engagement the best price are closing
issues and the fracking for example d15
2016 the github repositories with the
most comments on issues kubernetes co
native had so many more comments that
this other project and unite node spark
and you may know OpenShift
and then several demos also have also
has a lot of comments but i who knows
that project is relatively unknown
compared to anything else there so again
we have to measure things in a different
way instead of measuring just a number
of comments we can measure the number of
distinct users writing these comments so
the number of authors and then
kubernetes again this month had 499
people writing comments and terms of
flow also reserved and docking had way
more people commenting almost a hundred
but here not ranking only by the author
writing code by the number of a sort i'm
also dividing the number of comments by
the number of authors to know how many
comments is each person writing because
this term tells me a lot about
engagement they for example in fourth
awesome I had 643 users commenting but
each one left only one point six
comments so they are not really there
they can they say something they live on
kubernetes on the other hand each author
left 18 comments during this month that
really shows you people are engaged at a
very different rate and you can measure
that you can see and you can go deeper
you don't only have to go to number
analysis as I've been doing so far for
example you can do text analysis - you
can take all of the comments of people
writing and asking two questions like
what are the first three words of people
use it turns out people on github really
starts asking questions opening issues
say things like it would be nice or if
it possible to I am trying to it would
be great and again when thing you can
measure is how many Oscars I'll start in
the comments like this and you can see
which ones are the most popular ways to
start a comment but it's also
interesting to see in the second column
is how many of these issues are closed
so if you want your issue to be closed
it's much better to say things like if
it possible to and I'm trying to 80% for
and trying to then it would be nice
it will be nice gates only 50% closed
question so there's a ways to ask things
there ways to establish the things you
want to get the results you want even
when you're just requesting something so
that the humans penguin is funny too
I'll it I'll give you that one a strong
work but we can do it on the question of
size and countries on the edge story as
I was telling you we are also lucky we
also get a lot of metadata we know what
users have written their profile page so
if you have a github account and you
establish where you live that
information you will find it on the edge
story and now you can start wearing it
and you can get things like oh the u.s.
is a country with most colors followed
by India China the UK first place has
Exeter to deter that and again rankings
are way more interesting when you start
looking at more dimensions so for
example this is a chart of the number of
pushes during this month and you can see
yep of course the US has doing more
pushes to github but we doing this math
but what you really want to know is per
capita okay you can do a join with a
table that has the population of each
country and here I have
this child represent the number of
unique ideas pushing so a new use of
pushing active users divided by the
population and the ranking move
different now you can see the difference
north europe has a way higher
interaction participation just by
measuring per capita the ranking is here
you can find the united kingdom that's
like 11 something like that and you can
start seeing things like colder places
are attracting somehow more authors or
developers and the next question is can
we prove it so yes i have all web or
world whether they buy they loaded into
the query I can do a joint I did this
last night the I couldn't sleep here you
can see the temperature colder places
that way hotter places with this way and
more developers per capita on top
Iceland and also Canada and Finland and
it really shows you yes colder places
have more developers here on the bottom
we have a lot of Africa and we have some
that escaped the Train like russia
mongolia and north korea they are below
would expected and then over the
citations new zealand and australia like
it really helps to be an island but
whether have something to do with
programming i even know if it's
causation but yes you can really find
some correlation there then you start
mixing stars in star mix looking at the
country of each star and then you can
start asking what are the most
interesting price for each country i
wrote this blog post recently and it was
interesting was up in italy the top
project for italians is the
constitutional reform
you can send push a pull request another
day we like I said them but yeah it's
really interesting to go deeper look at
this ranking and look at how projects
low country by country oh there that's
really the Deaf is a really interesting
project that corrects every time you
type the wrong comment you say it fixes
what you wrote on but the Irish really
like this that one
oh maybe even know that I will ask you
later what that we've yeah so Romania
the top right is made in Romania that
one is not a third word but sorry for
the first and so let's go to a second
part of this talk is where is the cold
because it's really interesting to go
beyond all these events metadata and
let's try to look at code how did we
move all the code from github we took
everything that has an open-source
license so if your breaks a decide have
an open-source license we will be
reflected there but we made a copy we
publish a this June last year I have
been really interesting to go inside
this table have when I took this
screenshot let me not those creatures
let me grow life
so this one is github repos here the
table with the contents have unique file
contents of text files and the one
megabyte so we don't have everything
just things that are text and but the
one megabyte make sense and this table
today was updated may 12
representin 230 million files now I told
you only that earlier that we had way
more code and that's because each unique
file we are only representing it once so
again we can write a query to know the
real size of all of these we can
multiply the size by the number of
copies this basically looks at each
unique style we have in this table we
also know how many copies of these files
we have and in three seconds now taking
a little longer what's happening here
get this it's not the answer I want or I
didn't run the query sorry
some of the size for kotti yeah this is
a total number of bytes of code we are
representing here which is a lot but in
terabytes I don't want to do the math
yes we have 50 terabytes of code
represented here and we can start
writing queries over this content so the
proto-tool well in case you want to run
your own queries if we only have text
files under one megabyte one copy of
each unique file if you want to get the
name of each file each files have many
names because it has many copies so you
have to join with this with this other
table now some people start by
duplicating this and doing a join of all
files with all contents and just getting
a huge table of 50 terabytes of code
that's not really what you want but what
you want to do first is do an extraction
for example if you want to analyze the
error code take a random query then who
joins with the file path and only select
all of the data files all of it all of
the r54 a years ago today extract file
first and then
regular analysis and I left their sample
contents table that has 10% of the
contents we fold the top projects and
one sample path for each file and that
is a much that's a much smaller table to
make you're free to write last and
what's important to it they we only have
open source projects now how do I know
that something is open-source it's not
enough to have a license and you go here
to any project or github
github will tell you what's your license
and yep
my license is Apache too that's fine I
can copy this file and this is because
my life is was recognized by their API
but sometimes there are projects like
let's say spark the basics is oh this is
fixed for a long time Apache projects
were not given have their license
identifiers so go and check that you
have a license that the github robot can
check and glad that they fixed up next
slide um a lot of people here know Java
so let's do something fun with Jana and
what are the important that are growing
more during time and this were my
results but it's more interesting to
know added to see the query so let me
copy it here things I can do with the
query here I'm looking at all of the
content the Java files from 2013 and
doing a split of each of these files by
just to look at the line by line and
then for each line I want to know if it
starts with imports and if we want to
know the torque import for 2013 then we
just need to run this these are the 300
top imports
how much data analysis here
first yes so people in 2030 we're doing
importing you to list I affection I
released it don't make sense but then if
I do I joined those 2013 with 2016 and I
want to see and what did I do wrong oh I
need if I want to see what libraries had
the most growth proportionally run a
query like this when I'm looking at the
ratio of how many and what percentage of
import each one represented and I can
see that people started doing a lot more
inject in 2015 or using the immutable
list from Google or Android build and
perfuses no lab the new level like
sanitation etcetera today we can see how
the language is maturing with how people
are changing the way to pop open and let
me come back here any questions yep
everybody's happy and let's go back to
requesting features when you are
requesting a feature is not only
important to start it in a nice way and
you can also back your request with date
and you can back you have data how
people are using certain project this is
from the goal length repository someone
was asking that they wanted to add a
time until time duration function
because it looks prettier than the
current alternative it's a reasonable
request
but they help do you back a request like
this with date my teammate ranch desk
who knows about this data set I started
looking at how many projects are you
using this pattern would benefit from a
better API and you have skipped over
2,000 repositories without country by
Forks would be
from this kitchen yes I look this really
shows that by open source with your code
by living it on github and you are
voting with code you are able to vote
with code on what if important please
because now the project owners can see
how the prayers are being used code wise
and the goal and community implemented
this as they saw that it was very
fitting a lot of project now someone
else asked to to have TLS config
involved to be consistent between
packages then process also ran a
different query and he determined that
685 repositories would break if we made
this consistent so so far they have not
changed this it's harder to choose here
but at least now you know if you're
breaking people or not and so far been
doing a lot of regular expressions text
analysis and because sequel is a little
limited or not with the query you can
even write JavaScript UDF inside your
sequel queries that means you can
analyze things however you want just it
is a language to complete language so
for example at when I may also able to
import Java JavaScript libraries that
other people have written in this case
with J skin that is a static code
analyzer I am able to import it into the
query and run static code analysis over
code so this is my sequel query that I
use this fabric will query where I asked
the query to import my copy of the a
hint
I go through all my JavaScript files and
in the middle of this query have some
JavaScript code that runs JSC's and gets
the top warning for my yellow script
files I was analyzing yes you can even
go there like you can go and analyze
that there are missing semicolons use
the
function for mystery the name of the
variables are not important anymore if I
can just know that things are variables
or not and I would love to roll people
into this project and write code
analyzer for any language as long as we
do it in JavaScript they will work and
this is one of my most popular questions
the articles have written their tabs or
spaces any preference here are you tough
people
taps people spaces people so make sense
both yes good yes yes for every file I
use a different pattern so how do we
determine numerically with data which
one is really more popular these were my
rules I'm using the copies of this file
from bigquery and I won't look at all of
the files I will only look at the top
400,000 repositories and this white
stuff matters any private have more
stars might have more votes in my
rankings I will only look at five with
modern pear lines one vote for each
unique file if as some money 50 balls
spaces and tabs in the same file and the
solute will count with which one we have
more off and I'm doing this for the top
languages by the number of files from
github and first I extract all of my
files abstracting the joint with the
name of the files I'm starting the fire
end with this M with the patient's and
then I can run my beautiful query that
applies the rules that I was showing if
I'm going to do it lies because it's
called
so yes I'm doing a split of line by line
I'm looking if the line start with a
space or a tab and then I'm some timing
the number of tabs the number of spaces
and looking at what we have more and
these are my results of course I want to
move them to Google sheets to visualize
them
that was fast
and let me do a copy of this so tabs
there's two spaces and this example
suppose it isn't one
I don't know why was it yes so I want to
have taps to be negative instead of
positive so we can show them in a more
beautiful way and now I can just type
these insert a new chart I don't have
little spaces starting standard how
beautiful does this look and now we have
our answer of language by language and
this is how long it took me to write
this article Java has different shells
has a lot more spaces and tabs while
languages I see it's 50/50 and if you
really really like that you can go right
go because they only do touch data shows
same thing a ruby is really good with
spaces if you never want to see a tab
why I don't know but here is a date
determined and yes this is we will the
the visualization in real time and
things can get a really more interesting
this was another project man by Googlers
where we use the query and get have to
find a patch thousand of open-source
projects on their ultimate gadget that
was a really nasty bug and with these
tools we were able to find that there
was a team at Google that was able to
find all of the repositories that have
this problem and send them patches and
that was really really cool so just to
go finishing who was to analyze github
even github uses bigquery to analyze
themselves it is a video I did with
Alice on one of their data analysts I
guess I could touch to them and
hopefully everyone wants to analyze it
hopefully you will try the query later
there's a lot more other people have
done a lot more please you write
anything you do anything please sting me
I cannot eat or sleep people are doing a
lot in many languages a lot of profiles
keeping the track of the health with
these tools and if you have any
questions feel free to contact me on
Twitter and reddit and Stack Overflow
and if you have feedback for me please
give me feedback I love feedback this
URL thank you very much let me take a
picture free snipe edit any questions or
yes please credentials Oh security you
can search for credentials and if you as
I believe in human nature if you search
for credentials you can also send pull
requests to the people that left the
clevage of there and you can automate
the process to help a lot of people yeah
it's all there yes any more questions
thank you I think we're going but I'm
here and feel free to contact me thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>