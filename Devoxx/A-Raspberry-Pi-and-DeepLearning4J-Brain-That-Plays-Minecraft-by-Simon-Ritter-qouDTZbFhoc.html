<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Raspberry Pi and DeepLearning4J Brain That Plays Minecraft by Simon Ritter | Coder Coacher - Coaching Coders</title><meta content="A Raspberry Pi and DeepLearning4J Brain That Plays Minecraft by Simon Ritter - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Raspberry Pi and DeepLearning4J Brain That Plays Minecraft by Simon Ritter</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qouDTZbFhoc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">right good afternoon and welcome right
so what I'm gonna talk about something
is this rather long title building a
brain with Raspberry Pi and Zulu
embedded JVM and really the idea behind
this presentation was that well one
thing I needed a presentation that would
appeal to the audience of devoxx because
I wanted to get to talking demyx again
but it was more about that I wanted to
look at how I could use Java in some
slightly more unusual ways I've been
working with Java for a long time I've
been talking about Java for a long time
and certainly in my earlier career I
have had the opportunity to do some
weird and wonderful things with Java so
I kind of thought right I want to
continue with doing that so I came up
with the idea of building my own brain
well not my own brain but my own brain
that I could use right so introduction
where did we kind of come from in terms
of getting to the project that I've been
working on I have to say that I've been
working on this project for about I
guess about six months now so it is
still a work in progress I will show you
demonstration at the end but I liked the
line that the the previous presenter
used so I'm gonna use the same one take
a deep breath and then lower your
expectations like say I stole that from
the previous presenter anyway
inspiration inspiration came initially
from this book which is called on
intelligence and this is a book which
was published in 2004 so it's like 13
years old now so it's actually quite old
in terms of technology is written by
Jeff Hawkins anybody heard of Jeff
Hawkins one or two people anybody heard
of the Palm Pilot a few more people
obviously you know slightly younger
audience the Palm Pilot was very popular
back in the early 2000s as the
sort of de facto personal digital
assistant and one of the things so Jeff
was the co-founder of the Palm Pilot
company one of the sort of interesting
things about the Palm Pilot was it had a
stylus and you could use handwriting
recognition and the way that it did it
was rather than trying to do handwriting
recognition based on any input that
people could could have it tried to
simplify that in a way that made it
easier for the device which let's face
it was fairly low power if you think of
today's standards making the handwriting
recognition easier from the point of
view of the machine so he came up with
what's called graffiti and graffiti was
a way of having a single stroke for each
character and doing in a specific way so
it was easier for the device to actually
interpret so he wrote this book after
he'd founded Palm Pilot where he looked
at the way that the human brain works
and how that could be taken as a model
for building artificial intelligence
remember this is 13 years ago so this is
long before machine learning and deep
learning became very popular as they
have in the last few years so that was
kind of my inspiration was I read that
book when it first came out and I
thought this is really interesting idea
I'd like to do something with that
clearly it took me a while to get to it
now I will talk a little bit about some
some things to do with the brain so
we'll talk a little bit about neurology
but I'm not gonna spend too long on this
because obviously we need to get into
the technical side of things but just as
a bit of background this is a picture of
your brain and the important thing about
your brain from the point of view of the
intelligence is what's called the
neocortex and the neocortex is really
sort of the outer wrapper of your brain
and you can see that obviously you got
all these kind of like valleys and dips
in the actual brain structure and the
neocortex is wrapped around that and we
can see what that moon looks like if we
take a stack of my business cards so if
you take a stack of business cards
but six of them together what you've got
is a fairly accurate representation of
the neocortex of your brain the
neocortex consists of six layers of
cells talking about neurons six layers
of neurons and they're about the
thickness of a business card so it's a
layer of six layers of cells wrapped
around the outside of your brain and
that's what makes up your you basically
so Jeff did some analysis on this he he
looked at the the actual mechanics of
how these things worked and he came up
with a way of modeling the way that your
brain works with the idea that that
could be min used to simulate things
through a computer and come up with an
intelligent system what he actually came
up with was what he called the
hierarchical temporal memory and this
was the idea of a model of how the brain
worked but it's it's interesting because
it takes a slightly different approach
to the way that the neural networks that
we use today work because neural
networks today obviously you put lots of
data in you train them they can form
connections those connections can have
certain weightings associated with them
that change as the the different
connections get used more frequently
what Jeff did was to take the same
approach but to also say well we'll add
time to that if the inputs don't get
used for a certain amount of time then
the waiting decays so rather than
leaving a static and only adding to it
when new things come through there if it
isn't used for a while then the waiting
associated with a prediction starts to
decay and it's only as it gets
reinforced that it will then be built up
again so it was an interesting sort of
approach to to looking at how learning
could actually work by including time as
well as all the data input okay so that
was kind of the background to where I
was coming from now let's let's talk a
bit about machine learning still about
the basics machine learning and this
particular cartoon has been around for a
long time I remember the seeing this
when I first started doing computer
programming
and if you can't see the exact thing
there what you've got is got events and
one of them is pointing at a little bit
of the the flow diagram which says then
a miracle occurs
and Klee he's saying you know we need a
bit more detail there but that to me is
kind of like machine learning you know
you got all this data and you put it in
and then a miracle occurs and at the end
you get out something which is a sort of
decision about what's going on and it
does seem to have this sort of magical
quality about it in how it actually
works so let's look at some of the sort
of ideas behind this learning for
computers so we now have rather than
talking about artificial intelligence
which is a sort of an old we're talking
about things we now talk about the
machine learning marketing's got
involved we've rebranded it and it's now
much more sexy machine learning so the
idea here is it's about giving computers
the ability to learn without being
explicitly programmed what we want the
computer do is to take input and then
learn from that input such that the the
algorithm or the processing changes
based on that input not based on the
algorithm that has been hard-coded into
that it's what the information gives us
that changes how the machine works now
if we look at this or the simplest form
of this machine learning what we're
talking about is having a system which
needs to be trained so we have to
provide a set of training data that can
be used by the the program in order to
learn how to interpret data that we want
to give it at a later time and therefore
get results from it now the way that
that works is that we have what's called
a labeled data so labeled data has
information that allows us to classify
that data and the way you can look at
this is if we look at the kind of
simplest example simplest example is
where we've got a set of data that is
two-dimensional so we have an X and we
have a Y in terms of real machine
learning type problems often you have
lots and lots of different diamond
there are lots of different factors that
affect the data so different different
pieces of data that we're dealing with
but if we look at this example here
we've got two axes its x and y and the
idea is that you've got a set of points
on that which are our training data so
we know that if we give an x value for
that particular point we can then get
the y value of that point and the idea
is that we can come up with a function
such that if we give it a new x point or
a new y point we can get it to predict
the corresponding X or my point right
and if we look at that as a you know a
typical human we will see that what
we've done here is to take that data and
draw a line through it such that we have
a very simple straight line function
that allows us to have what would look
like a fairly accurate prediction of the
results now you can see that there's one
point at the top there which is quite a
long way from there but overall the the
error between the line and the results
that we've got is fairly low now what
you can do in terms of your training
data is ideally the bigger the set of
training data you've got the more likely
our to be I was training in such a way
that you get better results at the end
but there's also other things you can do
in terms of how that training data is
used so on just throwing all the
training data at the problem and saying
okay we'll draw a line based on that
what you do is you say ok let's take
three-quarters of our training data use
that to generate function and then we'll
use these other quarter of the data to
test the function so we'll make sure the
the data works with our training data
and then you can also reorder things so
you can have a sort of sliding window of
testing data so you can you can
iteratively go through and test
different sections of your training data
and use different sets of data to to
actually learn but the idea is that in
this case we've come up with a simple XY
straight line function you can obviously
become more sophisticated you know
mathematic says that we could actually
have a polynomial function that we can
map to that so we could actually make
line fit better through our training
data and reduce the overall error
function between what we've got and the
results we have the problem with app is
that you can end up doing what's called
overfitting because with the small set
of data like this we've got maybe a
dozen data points we've actually come up
with a polynomial that would allow us to
draw a line that went through all 12 of
our training points problem with that is
that's not a good thing so even though
it actually gives us perfect results for
every one of our training points it's
not a good fit in terms of predicting
the future because again if we look at
that we'll see that yes that line goes
through all of the twelve points of data
but you will certainly see that if we
have an x point which is near to the
exact the y axis and we try and predict
that we're going to get a very very
large value even though that doesn't
seem like a logical thing from the
training data that we've got so when it
comes to machine learning we need to
avoid overfitting based on our training
data and this is one of the the things
that becomes difficult in terms of
judging at what point do you stop trying
to fit your data so the next thing is is
deep learning so we talked about machine
learning where we have training data
that is labeled we know what the values
are we know what the results are deep
learning is about taking a little bit
further so it works with the idea of
neural networks a little bit more about
neural network nodes in a moment but the
idea of the neural network node is that
it takes a set of weighted inputs
applies a function to it and then
generates an output and then you can
link these things together and you can
do that in layers so this maps to the
idea that we have in terms neocortex
having six layers you can organize those
as layers you can have nonlinear
processing so you don't need to have the
same number of nodes in each layer you
can have different connections things
like that and the idea of this is to
have input and then have different
abstractions of the problem as you go
through the layer
what I mean by that is you could take
something like a picture photograph and
you can divide that up into obviously
pixels so your input is going to be an
array of pixels different colors you
provide that to you input layer the
input layer then has to do something to
that and provide an abstraction of the
input data and that could be something
like doing edge detection so you you
have an abstraction which goes from
being a simple set of pixels into a set
of edges and then you pass that to the
next layer the next layer says okay
that's those set of edges can then be
mapped into starting to recognize an
object and classify that as something in
the photograph and then you push that to
the next layer and so on until at the
end of that you get the output which is
a classification in terms of what is in
that picture whether it's a cat whether
it's a dog whether it's person so you
get that abstraction from a set of
pixels all the way through into a
classification of what's in the picture
this deep learning idea is a good
analogy in terms of the hierarchical
temporal memory model because it works
in the same basic way and then you can
apply the the temporal aspect of it to
that key thing here is that you use
unsupervised learning
so it's data which doesn't necessarily
have let won't have labels it's actually
very easy to get unlabeled data it's a
lot harder to get label data because if
you think of you know if you want to
take all the photographs from Instagram
most of them don't have information
about what's actually in that picture so
what you really need for recognizing
images is labeled data so that you've
got an idea of classification with deep
learning it's more about trying to find
patterns in data without necessarily
having a classification so you're
looking for where there might be a
pattern which you wouldn't recognize
straight away cancer is or cancer
analysis is a very good example of this
because you know you may not have an
ideal sort of thing about what the
cancer is but the algorithm can spot
patterns and if you then say okay well
this person developed can
so you've got these patterns that can be
picked up on and suddenly you've got
information that isn't available or
isn't immediately obvious when you look
at the data overall but by doing pattern
recognition and on finding patterns
through this weave unsupervised learning
unlabeled data it allows you to have the
system learn about how to predict
whether a person will develop cancer or
not your network elements so I said the
idea of a node it's the own idea of a
node is that we have something which
represents a neuron and the neuron has a
number of inputs so we link it to other
neurons in our system those neurons will
provide input to a neuron that value
will then be passed through a weighting
function the weighting function
basically says how important is this
input if something has been used many
times it becomes more important if it's
being used less times it's less
important so the weighting function will
adjust the input value based on how
important the connection is from that
other neuron all those things are then
passed into a function function could be
a very simple one like just adding them
up it could be taking the average it
could be doing something much more
complicated and then that produces a
result that's then passed on for the
next neuron that it's connected to or
it's passed on as a result that we can
then gather together by putting these
things into layers we can make
connections between the different
neurons so we start at the bottom we've
got our input layer this is where we
might pass the pixels from our
photograph we then pass those two hidden
layers and we make connections between
the neurons in the input layer and the
neurons in the hidden layer that doesn't
abstraction the problem decides where
the edges are maybe or what the type of
object is and passes that on to the next
layer and the next layer is the output
layer and eventually we'll get a result
from that now in terms of the way this
is organized the connections in this
particular case are always one-way so we
go from the input to the output
there's no connections going back
you can have neural networks where you
have what's called backpropagation but
in this case we're only doing forward
propagation of the results the other
thing is that you don't have connections
between the neurons in the same layer so
you only connect between neurons in
different layers right so talked a
little bit about deep learning and the
idea that what we're doing is using
unsupervised learning the other thing
about that is that we typically have
more than two layers in our neural
network for this and as I say not
necessary we not necessarily have
training data although not necessary
have labeled training data the other
thing which is kind of an extension of
that is reinforcement learning deep
reinforcement learning and the idea here
is that there is no training data so you
don't have a set of data to start off
with to allow you to then predict what's
going to happen in the future this is
much more like we are as humans so when
you born nobody provides you with a nice
set of training data which says write
load all this into your brain and
suddenly you're fully working fully
developed human being you have to learn
you know you have to go to school you
have to repeat things you have to make
mistakes you have to learn from what
hopefully learn from those mistakes so
reinforcement learning is the idea of
doing that with your neural network so
you learn by experience you have trial
and error you try something it works
great you have reinforcements say next
time we'll do that if it doesn't work
next time you don't do that and so it's
a way of making decisions based on that
linked to that is what's called a Markov
decision process now a Markov decision
process when get into too much detail
about this but essentially it's a
mathematical model of how you can decide
what to do next and the outcome of what
to do next is partly random but also
partly controlled by what's happened in
the past so the reinforcement idea but
there is a certain brand of element in
there to enable things to to change so
if you do get stuck in a situation it
will change things so that they won't
necessarily get stuck there
what you have in a Markov decision
process is a a five tuple a five value
set so what you've got is a state now
the state is where you are at that
particular time and you then have an
action associated with that state and
that's the idea that by doing something
you're going to move to a new state
there's a probability associated with
that so that it says if you take this
action the probability that you will get
to this state is so much or the problems
you get to a different state is this
much then there's a reward rewards the
idea of what is the gain if you like in
moving to a new state and this is the
idea of thinking about learn by
experience you need to understand you
know is something going to work or is
something yet a file the only way you
know whether it works or fails is based
on a reward
so working means something is good
failing is something is bad so there has
to be some feedback in terms of whether
it was good or whether it is bad
and then you've also got a discount
factor involved there which is a way of
sort of factoring in an importance based
on future and present rewards and again
this is sort of interesting to sort of
model with with humans you know my son
really doesn't get the concept of
delayed gratification at the moment he
wants everything right now so he doesn't
understand that he has to save up his
pocket money to get something in the
future so it's that kind of thing so you
can have a discount factor which can say
okay well it's actually better to wait
longer for a bigger reward than it is to
have a small reward right now that kind
of thing if we draw the Markov decision
process has a sort of flow diagram we
get something like this so the the green
circles are the different states that we
have we then have a set of actions
associated with that and those actions
have probabilities so if you look at s0
and you take action zero there's a 50-50
probability that it's neither going to
come back to state zero or it's going to
go to state two and if you look at other
ones you know
a one there's a hundred percent
probability that taking action one will
move you to state two then you've got
these little squiggly lines which are
the sort of exits so there are the
rewards you get as you leave from making
particular decisions now again coming
back to sort of how I came up with my
project there was an interesting thing
that was done fairly recently and this
was deepmind company based in London got
acquired by Google and what deepmind did
was they they looked at how to use
what's called a deep queue network and
what this does is allow something to
learn and do it in a deep learning way
which means that you don't have training
data that's classified what they did was
they basically got their artificial
intelligence machine learning system to
play Atari games the great thing about
Atari games in this case are they're
nice low resolution so you've got two
dimensional data it's not sort of three
dimensional game it's two dimensional
fairly low resolution zone smallest
number of pixels and what they gave the
the system was the video frames so they
gave the video frames they also gave a
little bit more information in terms of
okay they would from a reward
perspective they would give the system
the score that it got so I didn't have
to read the score off the screen it
could actually be given the score as the
rewards and clearly it gave the system
the way to control the game in terms of
the different you know keystrokes or
whatever to move the paddle so in this
case you've got breakout and the great
thing about this was that the system
actually learnt how to play the game
without having any knowledge of the game
so the no pre-configured knowledge of
the game it simply started doing things
in at random started to see which things
worked in which things didn't based on
how high the score was and it learnt
from that so that it did the right
things over time and it started to learn
okay if I move the paddle to where the
ball is going I get a higher score if I
don't move the paddle to where the board
is going I lose I'd get a lower score
and that to me was a really interesting
sort of approach so I thought right
what can I
do based on that so the next thing I
thought right
I need some some hardware from my
project and for this I thought I was
going to use embedded hardware the sort
of Raspberry Pi because what I wanted to
do as well was to kind of include a
number of different things in the
project hence the use of the Raspberry
Pi so who's got a raspberry Polly ah yes
great so you're all fairly familiar with
the idea of the Raspberry Pi Rose before
fantastically successful embedded
development board cheap powerful great
connectivity the original boards were
$25 I guess you could still get the $25
Raspberry Pi model B I guess it is but
they also came out more recently with
the Raspberry Pi zero and that's five
dollars so it's just incredible to think
that this is a fully configured computer
for five dollars and it's not even that
sort of low powered even by today's
standard this was launched like sort of
five years ago and again fantastically
successful they actually there are two
companies that sell these in the UK one
is RS used to be called Radio spares
originally but now it's called RS and
the other is Farnell and both of those
websites were actually brought to their
knees on the day when these were
released because they couldn't cope with
the number of orders and they reckon
that even since the last year they've
sold over 10 million of these boards
which is an incredible feat if you look
at the actual sort of configuration of
the Raspberry Pi boards it's all ARM
based
the older ones are arm v6 new ones are
arm v7 even arm v8 on some the newer
model B's PI 0 still are v6 but does
clock at 1 gigahertz some of the speeds
are very you can actually change those
if you want the newer model B actually
has a quad core processor the other ones
have a single core processor and you get
somewhere between half a gigabyte and
one gigabyte of memory so it's not you
know a totally non powered machine isn't
it's quite a lot of processing power
there so I thought let's see what we can
actually do with that processing power
in terms of building
machine learning system so this was my
original kind of concept in terms of the
architecture I felt right let's use one
Raspberry Pi for each layer in the
neocortex to model our brain we'll have
a set of neurons in there we'll create a
neural network between the different
Raspberry Pi boards and then we'll
communicate between the boards over a
network have my laptop connected to the
network and then get it to do something
so this was my my monk one roz B PI
cluster what I did was I basically took
a bunch of the Raspberry Pi boards that
I had and I'm kind of bolted them into a
stack found a nice little power supply
that had some short USB leads stuck one
on the top to be the sort of like main
controller that the whole cluster I in
the picture that you can see I actually
added an SSD because I thought I'd need
some more storage and this is kind of
what I ain't came up with I then decided
okay let's see if I can make this a
little bit smaller and I came up with
what I've got here which is my Raspberry
Pi cluster mark - and this makes use of
the PI zeroes rather than the Raspberry
Pi model a or model B again in this
particular picture I've got a hard drive
underneath the Raspberry Pi cluster
which I don't use at the moment because
it turns out I didn't actually need that
much storage so I didn't need the extra
disks I didn't bother including it now
what misuse is is a nice little board in
the breadboard there that you can see
which is called a cluster hat all the
board's you stick on top of Raspberry Pi
apparently called hats and this is the
cluster hat the way that this works is
that the Raspberry Pi zeros and actually
plug into the cluster board through the
USB connector so you don't have to it
does networking it does the connections
everything through the USB rather than
having to have either using Wireless or
using you know physical network
connections so it makes the wiring a lot
simpler as well and like I said
basically you've got four USB ports
there you can plug four PI zeros in and
then there's you use GPIO pins as well
to connect and control various things so
it makes actually setting things up
simple so next thing was okay I want to
write this application whatever it's
gonna be I want to use Java we use Java
for an embedded application right so why
would we use Java well first thing is
write once run anywhere or as some
people refer to it right once test
everywhere write once anywhere right
months run anywhere is great because it
means that you can develop your code on
the laptop then all you have to do is
remove the jar file to the device and no
cross compilation no toolchain no
complicated things in there it's just
compile your java code into byte codes
move it on to the new platform off you
go so it made life simple in that point
of view next thing was lots of libraries
lots of frameworks available so you
don't have to write everything from
scratch there's all sorts of nice
libraries we'll talk about a couple of
those in a minute but lots of things
that you can use to to help you build
your application more quickly for the
point of view of the raspberry pi simple
interfacing again it's libraries for
this there's PI for J there's D i/o
which allow you to control things like
the GPIO pins I squared C you arts stuff
like that I haven't actually used those
in my demo yet I've got some sort of
ideas for doing things like that but I
hadn't quite got to that point in the
project the other great thing about Java
is simple concurrency because in
something like this what you want is
lots of threads doing lots of different
things for you different neurons and
having all that coordinated and creating
new threads is actually very very easy
in Java as we know you know if you look
at Java C 5 there was a concurrency
utilities you've got the things like
semaphore you've got things like
readwrite locks atomic operations things
like that jar se7 we got the fork/join
framework take a big task decompose it
in smaller tasks have the framework deal
with all of that for you
job right we got the parallel stream so
there's lots of things in Java that make
doing things concurrently a lot easier
and then if you do need to kind of delve
down into lower-level code you've got
J&amp;amp;I available so you can interface with
native libraries if you want to use
things like OpenCV there's a java
wrapper for that and that's using the
like J&amp;amp;I my one marketing slide I do
work for is also will mention that we
have a version of Java which runs on arm
correct so that's what I'm using for
this what we do is we basically take
open JDK we compile it into in this case
an arm binary we support v6 v7 v8 soft
and hard float 64-bit is actually
released now I should change that it's
not close to release it is released and
we're doing some interesting things
around c1 and c2 JIT compilers to
improve that you can download that for
free from our website if you want
support for it we will quite happily
sell that to you nice thing about this
is there's no field of use restriction
it's an open JDK binary so it's released
under GPL v2 with class path exception
so there's no issue of licensing with
this like I say
download it for free from our website
right let's switch back to machine
learning talk about machine learning in
Java so what I did was I looked around
and I found that there's this nice
library that's been created specifically
for deep learning in Java and it's
called deep learning for Java so what
this is all about is creating neural
networks being able to set them up being
able to train them being able to deploy
them into whichever development
environment you've got and really the
kind of key part of this is what's
called nd 4j and this is n dimensional
arrays for Java a lot of what you do
with machine learning and deep learning
is matrix manipulation matrix
multiplication because when we looked at
the graph we had two dimensions so that
was two values for each piece of data
but as I said often you have many values
many dimensions for the data that you're
using so you create a vector of those
values and then what you need to be able
to do is in order to do the the neural
network is you need to do matrix
multiplication matrix manipulation so nd
4j gives you that to a core piece which
does a lot of the mathematics underneath
in a in a much more easy way the other
thing they've got is a thing called data
Veck and this is about transforming the
data into those
so you've got the data that comes in
that say we're taking um our image again
so we've got our RGB values for our
pixels datavac we'll help you transform
that into a set of vectors which you can
then use nd for J to manipulate in your
your neural network arbiter is a way of
evaluating how your model is working and
then apply more tuning to it based on
how well it's working high parameters
are the values that get created not that
so they're not your your data though the
values that get created from your data
so things like the weighting that you
have on your different nodes and your
neural network and so on in terms of
classes that you get for D alpha J
there's the obvious things that you've
got a neural net configuration that
comes with an optimization algorithm
there's then a multi-layer configuration
because you need several layers in your
your neural network this will allow for
back propagate back propagation so if
you do won't have feedback from lower
layers in your neural network then you
can do that through back propagation and
then there's this this wonderful tbp tt
forward link from backward electus and I
actually had to put that there because
it's truncated back propagation through
time so it's really how you tune the way
that things work in terms of the neural
network and then obviously you have a
layer you could have dense layers you
can have output layers and you can have
input and output between those layers so
it gives you a basic set of classes that
you can use to construct your neural
network you can use the neurons have
them organized in whatever way makes
sense for your application then there's
this thing called RL for J so this is
reinforcement learning for Java and this
was what I particularly wanted to use
because the application as we'll see is
it's going to use this so this deals
with both low dimensional state and high
dimensional state and the idea here is
low dimensional is state like data and
if you've got something in your
application where you've got a small
number of values associated with it like
a position so you've got next Y maybe a
Zed position in your application that's
low dimensional high dimensional is
where you've got lots
lots of values say a video frame which
has you know potentially thousands of
pixels in each frame then that's high
dimensional information we talked about
the Markov decision process of his
libraries or classes in the RL for J
which allows you to model that also the
DQ network can be modeled through that
and then you've got various policies
that you can apply to how to decide what
to do next
if you're in your Markov decision
process you're in particular state and
you need to decide what to do next then
there's various policies that are
associated with that I won't go through
them but there's apps act critic there's
a Boltzmann probability distribution
there's DQ n policy and then there's
epsilon greedy partially random so
different ways that you can approach
making a decision right minecraft and
Project namo who's played minecraft
right most people great so minecraft is
an immensely popular construction game I
know that because there's literally
millions of people that play this game
and lots of them are children my son
who's 11 is one of them
he loves minecraft he loves building
things in Minecraft the thing that
really kind of weirds me out though is
he also is very much like the average 11
year old child if you've got children
you're going to know what I'm gonna say
which is he likes to watch other people
playing video games on YouTube I just I
really don't figure out why there's so
much attraction for watching somebody
else play a game when you could play it
yourself
but anyway so minecraft very very
popular there's different modes in terms
of how you can do it so you can do in
creative mode where you don't ever die
you can do it survival mode where you
can die it and you can do it hardcore
mode where you die more easily the first
PC version was written in Java it is
probably well certainly the most
successful ever desktop application
written in Java I think and so you know
it's very popular 121 million copies
sold worldwide
Mojang who were the company who first
created Minecraft not the the programmer
who released on
all off was acquired by Microsoft back
in 2014 right so here's a couple
pictures of Minecraft I don't really
need to show that because you'll know
what minecraft is project malmÃ¶ project
Malmo is interesting because this was a
project that came out of Microsoft labs
what they did was they looked at
minecraft they said actually this could
be a really good thing to use to test
machine learning algorithms because it's
three-dimensional but it's a relatively
low-resolution three-dimensions isn't it
I mean it's you know nice chunky
graphics nice big blocks which means
that you're not having to deal with too
much in terms of interpreting the data
you know it's not like trying to play
you know tour of duty or something like
that where you've got very very high
resolution very very high frame rates
with this it's a kind of lesser amount
of data so that kind of thing could be
interesting so what they did was they
actually created their own mod for
Minecraft which would allow you to take
your machine learning algorithm and kind
of plug it into Minecraft so it could
play the game and then it could figure
out what was going on and it could get
information about the game didn't need
it you didn't need to do things like
screen scraping you didn't need to do
things like keyboard simulation or
anything like that they provided all the
api's for that so we look at a very
simple piece of code using Malmo what
you do is you create yourself an agent
host and then you need a client so it's
got a client pool a Mac next to the the
game the nice thing here is that you can
actually connect to a game on a
different machine so you basically go
across network give an IP address and
you can play the game which is good
because I obviously wanted my my ROS be
PI brain to play the game so that's
connected to my laptop and and can play
the game on my laptop you then have a
mission specification and the mission
and specification is where you can set
up what it is you want the machine
learning algorithm to actually achieve
in the game so there's various things
you can set up about that one is you can
say how long you want the game to run
for you can set up the video resolution
things like that and then you can also
record all the information about what
actually happens during the playing of
the game this is obviously very good
because if you want to analyze how your
machine learning algorithm worked in
terms of the game you've got all the
details about what happened whilst the
game was being played it what you can
save is things like what commands we
used you can save the video you can save
the rewards because you get rewards as
you play through the game in terms of
what actually happened and also
observations and then what you knew is
you simply say ok start your mission
when you interact with the game from the
point of view of the machine learning
side of things
you've got the mission specification you
can do things like setting the this
allows you to set up the world that
you're going to play in so you can set
the motor creative if you want you can
also do things like adding blocks into
the game so you can set up a specific
arrangement of things in order to have
an environment that you want to work
through we'll see that when we show the
demo and then you've got the agent post
which is how you control things you say
start mission you can peek at the world
state the world state gives you
information about what blocks are
immediately around you so you get
information about that and then you've
got send command which allows you to
actually say right I want to move in
this direction I want to turn in this
direction
you know maybe use a particular block or
whatever you want to do in the game is
controlled through send command so it's
just putting it all together what I did
was come up with a slightly more
detailed architecture so I used rows B
PI 3 as the the main board which had the
connection to the laptop and this runs
the the demo controller and it runs the
Malmo library so then I had to recompile
a Malmo library forearm that wasn't
actually pleasantly simple didn't have
any real issues with out there a couple
of minor things I have to tweak I think
in the build script but overall very
simple to move the the Malmo library
from a PC to the Raspberry Pi that way
it can then can communicate with the the
laptop in order to play the game then we
use the PI zeros as the four layers in
our neocortex obviously there should be
six but you know the PI hat very
says has four so I thought we'll use for
the way that works is that one of them
is the input obviously that's running
the reinforcement learning Java that
then passes the information from the
input down through into filter one down
into filter two into the output and then
what you get back is what to do next so
it's the decision that's been made about
what is the next thing to do
use the Markov decision process and say
ok we've processed the information we
got from our current state of the game
we've made a decision about what to do
next have the game do that and then
repeat by taking the information back
and going on so I need a demo scenario
so I thought to myself right what do I
want my machine learning algorithm to do
in Minecraft so I thought right we'll
have the machine learning algorithm
build a house
great yeah turns out that's really hard
so yeah I don't think we'll do that
because it really is hard so then I felt
right demo revision one okay let's keep
things simple let's have the agent build
a wall uh-huh yeah turns out that's
really hard as well so simpler but not
as much so building house right so then
I came up with demo revision two which
is have the agent walk around without
dying so that seemed like a simpler
thing to do it's still not like totally
simple but it is much easier in terms of
the coding that you need to do so the
idea was that you would create a world
in which the agent could move around and
you would put certain obstacles in its
way that could potentially kill it and
the idea is then it can move around the
world and if it bumps into something
that kills it it learns that that's not
a good thing to do so the next time that
he goes through it should then avoid the
things that kill it and gradually it
will be able to move through the world
staying alive okay
applying machine learning to Minecraft
basically as I said we're using the
alpha j RL for j that uses vectors so
the the tricky bit is taking your
problem space which is playing minecraft
and translating that into the machine
learning side of things which is a
number of numeric values that you want
in your vector which and then going to
form the inputs to your nodes and you're
on your
network and have them processed so to
start with I've kept it very simple and
I'm just using the state information
that the game gives me about what blocks
are in front of me and around me in
order to make decisions the long term
goal is to go more down the sort of DQ
Network idea of taking video frames and
having those video frames interpreted to
get information directly from those and
figure out what's going on start with
random moves so it has to do something
it was interesting I was talking to
somebody about this I was talking to
somebody about this when I did this
presentation at the weekend and somebody
said well you know wouldn't the system
just learn that if it didn't move it
wouldn't die and I said yeah well it
could do I mean that would be a
legitimate way to stay alive is not move
but obviously in order for it to learn
to start off with we give it a random
way of moving around so it does move and
it bumps into things and then it should
hopefully learn from that right so
conclusions future directions
conclusions right so embedded hardware
can be used for AI machine learning deep
learning
I mean I've found that the processing
power on these boards for what I'm doing
alignment is is quite adequate you can
certainly run a neural network on these
boards we're not talking about millions
of neurons but we aren't talking about
you know hundreds of neurons it's not a
problem cheek field multi-core
potentially as you know might move up
into using more of the bigger Osby pi
boards for more cause java is very much
the ideal language for this easy to
learn the threading model is easy lots
of useful libraries like I say like the
deal for J things like that and I
definitely think that minecraft is it is
a fun tool for testing this kind of
thing things I'm thinking about in the
future obviously more work on my
minecraft player making into a better
player trying to figure out and get it
do more things than just move around
without donning I'm also interested in
experimenting with what's called J CUDA
J CUDA is where you can use GPUs to at
processing power and I've actually got
there's an Envy
development board that you can get
called the Jetson tk1 and it's
essentially a graphics card processor
where it gives you access to all the
GPUs so that you can use those to work
as your neurons because the neurons
remember I'm not really doing
fantastically complex processing so GPU
is actually very well-suited to that
kind of thing and it could be
interesting to explore using that and
then machine vision I've also you know
thinking about where the opencv could be
an interesting thing for taking the
video frames and then doing
interpretation on that and figuring out
what's going on in the game place to go
for more information
obviously Raspberry Pi dot org cluster
hat comm is the place where I got my
cluster board from deep learning for J
dot org minecraft.net and project Malmo
there's a you know if you search on
Project Malmo you'll find it Zulu Zulu
org is where we publish our binaries for
the embedded JVM as I say it's free
download it and with that what we're
going to do is we are going to switch to
the demo right so as I say this is a
work in progress so um right so
basically what I've done is I've got it
set up so yeah you can see that you've
got the minecraft screen there what I'm
going to do is I'm going to run the
application which then gets the runs on
my laptop uses the the Raspberry Pi
brain to to do things and then hopefully
it won't start playing the game so what
we should see it starts moving so so
what we're doing is moving to up see it
died actually that's yes so what it's
doing is it's moving through the
environment and I've given it a
completely flat environment and then
what I've done is put lava blocks
randomly on the flat environment and so
if we go
and if I run it again like I say is
still then we'll build the terrain and
then it should start moving there we can
move around it's it's kind of use as I
say is using a lot of randomness and
sometimes it just calling walks off in
the opposite direction like it seems to
be doing better this time
it won't run forever yeah fight is yeah
I've got four seconds left all we're
getting is like an ex-wife yes okay so
there you go it survived so like you say
that that's it
hopefully that's been interesting I am
planning to put this code up on github
when I've tidied it up and actually got
you know a bit more of the stuff going
but I will put the code up on github so
with that thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>