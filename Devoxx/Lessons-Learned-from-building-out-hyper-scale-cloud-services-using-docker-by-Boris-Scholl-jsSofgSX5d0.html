<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lessons Learned from building out hyper scale cloud services using docker by Boris Scholl | Coder Coacher - Coaching Coders</title><meta content="Lessons Learned from building out hyper scale cloud services using docker by Boris Scholl - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lessons Learned from building out hyper scale cloud services using docker by Boris Scholl</b></h2><h5 class="post__date">2017-04-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jsSofgSX5d0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I guess we get started fight welcome
everyone can you music so the question
is about lessons learned from building
out hyperscale cloud services using
docker so we made to be probably know
that normal is getting into the cloud
business quite a bit now and we're
building out some internal services as
well as external services and this talk
is about like an internal service that
we may externalise but we have some
lessons learned there we use a lot of
modern technology that's what is talking
about so my name is partial I run the
microservices development organization
in Oracle I'm a recent hire as so many
of us you probably also heard that
Oracle is like building out a new team
there so I came from Microsoft month ago
and that Microsoft I was working on
service fabric and container service so
I spend in a micro services world for a
long time Saudi agenda it's a pretty
small growden and we can be very open
and have like discussions I think that's
perfect so the way I thought about it is
I give you some characters so that you
know what you're getting out of that
talk and if you don't like it you
probable inside and hold on I'll give
you a service use case because i'm
talking about best practices so it's
good for you to understand the service
use case the architecture and everything
right i want to talk about the platform
architecture as well as our design goals
what it basically takes to build out
such a cloud service and you can
directly translate those type of
learnings into when you guys are
building out platform services on AWS
oracle or edger then i'll talk about a
def helps slow because it's fairly
important when you work with containers
how we think about DevOps because we
made some discoveries there then I'll
hope I can give you a demo I just tried
it but it's very slow so then you get a
picture and then I'll talk about all the
lessons learned sounds okay cool all
right so objectives I already mentioned
that I just glanced over it the
difference to the prom this talk to
other talks is you get an insight into a
real architecture that's not a sample
demoed it's not a sample that we build
that's really
service that's been used internally at
Oracle so what you get out of that is
it's you probably get into a nicole you
get inside into an actual real world
architecture as well as you get some
ideas of where we struggled with in that
game so I hope that sounds good so the
service we had to build as I mentioned
we had to build a service that's been
consumed by all the service right so
think about we build out a database
service or think about we build out a
computer because those are distributed
systems we needed a consensus service
for leader election for configuration
management at all so that's really the
use case it's the service that i'm
talking about as a backbone for other
internal services that we built and it
offers leader election service registry
configuration management how many of you
have heard about it today xcd basically
the brain of cuban it is that's what
we're using you so and then what we may
want to do at some point we may because
configuration management and that type
of stuff is fairly important in a cloud
world we may externalise that service
that's not been decided yet so right now
to the internal service but we may make
it available to customers as well so the
service design goals for us are
obviously had to be hyperscale right and
motorist enterprise-scale because
eventually we want to have a lot of
compliments on your cloud and they want
to use our services we have many
internal service as many instances so
that thing really needs to scale right
and it cannot it has to be absolutely
highly available because if that service
goes down think about if your brain goes
down your body doesn't function it all
right if that service goes down a lot of
our internal services go down so it had
to be resilient because you cannot avoid
failures as you know and distributed
systems they've willow kurds just going
to happen right so it had to be really
resilient and then from a that's
probably the most interesting part from
a architectural perspective because it's
an internal service we wanted to run it
as multi-tenant right we wanted to not
have a service per box we wanted to run
it in an economically efficient
way it has to be multi-tenant we wanted
to optimize hardware utilization and
optimize costs because after all we are
still oracle right so we want to have
very efficient services and um we want
to leave it a natural delivery of
individual services so you see that
service architecture talk about our many
individual components and we needed to
be able to if like let's say the
database team comes to us and say hey
you need to update this we wanted to be
able to ship it right away so that led
us to service design principles and how
many of you have heard about
microservices surprised with so we
basically follow that pattern right and
what is really about is why we chose a
microservices architecture is we had to
optimize for time to market right it's
less about decoupling which is also
importantly but we needed to be able to
really those things and those
components independently right away so
um each service is delivered by an
independent development team which is
also a characteristic of a micro service
um we've tried to automate everything
because you all heard about
microservices you probably also learned
that you should automatically def up
slow and we automated pretty much
everything all the way until we need to
put it in production that's a manual
process i'll talk about why and why we
did that but pretty much like automation
of everything is was was one of the key
things ease arm so the service itself
consists of nine separate services
meaning not service instances just
services great like developed services
and they're delivered by five
geographically separated development
teams so it's a true like micro servers
architecture with different teams on
different specs what's really important
there and there was another design
principle and that's that's fairly
important in a micro services world for
every micro servers ever continued no we
had to adhere or we had to apply
governor because if you think about you
have all those different teams building
out the services everybody is doing like
tracing logging on their own terms
you're going to have cael's right so we
decided okay we need to have governance
in place and governance starts the sauce
with unit testing there has to be a
certain coding standards code reviews on
all commits and then a common log format
it's very important in a micro services
world and you basically agree on a
common log format so every service has
to be deployable and testable that means
because we also own Java and there is
this discussion should we just ship at
all war we decided no it has to be a
docker container right that means every
team has to put the stuff in a docker
container so and if it's not on ataka
continuously part of the pipeline and
then the last thing is it had to be
built for operations because operations
is very important in a distributed
system so we basically are build our
custom UI dashboard for the that shows
our entire on citv pipeline that also
shows our entire tracing so from a
technology stack we've chosen following
things to you so we needed a reliable
infrastructure all we need so we build
it on our bare metal cloud services in
oracle that's the new thing as an
Orchestrator on top of the lid we're
currently using NATO's marathon the
reason was because obviously we started
building out that a while ago so we
decided to go with measles marathon
we're going to switch it over to our own
container as a service or manage
container service offering and the
reason is because right now our dev team
parts of our desk you need to operate it
and we just want to handle the
operational see the cluster it does is
one handed over to turn on the team
right and then we're using engine eggs
obviously for for gateway stars then
technologies designed i call it designed
for operations the Dockers obviously
given that was very early on that we
went with docker four tet for
diagnostics we use the elastic stack
elasticsearch logstash Cubano we also
use grass on offshore
UI and for time series data way through
community knows so to have like that
time sequence database on the Java side
are we are using jax-rs way to be jersey
grizzly Nettie and coherence how many of
you have heard about coherence okay look
some the detail so and then for the cic
d pipeline using cheng can see on as you
can see it's a very open popular who is
that step so from an architectural point
of view this is how it looks like so we
have a on the right hand side we have a
call you operator so the operator is a
guy who basically sets up a new cluster
and you had to be cluster right think
about I said configuration management
leader election that's exedy so if we
need a new cluster bomb from the
operator or there's a new version we
basically go through the operator and
says hey upgrade from a CD version 2 2
version 3 yeah so that goes for a load
balancer that's what we call the
operator LOL israel a thousand eggs then
we have a bunch of management api's and
then we have the thing is called service
orchestrator it's a little bit confusing
don't get like it's not an orchestration
of containers like what marathon loss
it's really I'll talk about more what
that component does it's much more like
our own water expression was in Asia and
then it basically have the sed gateways
and then it's backed up by coherence so
think about we provide XV ap eyes and
the data is stored in coherence which is
basically a memory data grid so it's
highly available highly where are the
other inventions we wanted to have a
multi-tenant available the way we
basically build what is the magic
multi-tenancy there is we're cave of
having the data in the same cluster it
is more about the network separation RM
so we have on the left hand side those
are like a tenant network we have no
service which we call it a terrible
silence which are engine X and they were
basically think about it as being a
wormhole from our service
Network right service private network on
the right hand side into the tenant
network right so that they can basically
make a regret into the server that's
what was it platform components arm
again I already mentioned it as an
accident for control plane and load
balancer and the tenant loss of control
they store operator one on and as I
mentioned a tenant load balancers
basically the one more thing the
management API is there that i showed it
or basically just the endpoints what
management api's do for the console the
web console as well so to see a CLI that
you can use against it and then the HUD
service itself is really to mentioned a
virtual concept because it can go and
install at city as it right and it's
basically storing the data itself but we
we took basically a to be like the head
of that to be the api's and everything
and put another backend underneath it
right and that's what we call an entity
cluster so deity gateway are in the
coherence world front end nodes the
storage enabled notes or the back end
nodes and the data is basically
persisted to our VMs so I talked about
that weird saying that orchestrator
right not marathon why did we have to do
this because when I joined a team we
were starting did a little bit of rocket
engine like why do we need another
orchestrator so it's basically a bridge
think about the building out a service
with a bunch of components that depend
on each other wait so and we need to be
highly available as I mentioned this
poor we cannot just take down components
we need to make sure we can take them
down or we need to make sure that
they're basically being spun up in a
certain order right it's more like hey
our entire application are those nine
services that i mentioned before right
and they have a certain order they need
to be started right a lot of
orchestrators do that nowadays but we
also needed to have a certain order than
the updated either to make sure we get a
response from like we're here and say
hey your data is save your data to
replicate and then the other cool part
is it supports target environment
profile because think about the icd
right we say you have our definition of
our micro services application in those
nine services and we say okay I want to
spin up that environment on a laptop I
want to spin it off in the cloud I want
to spin it off in like our production in
one what I'd also has to do or what it
also does is you know if you have
different environments they have
different resources right so you if you
have just a test environment you don't
want have like five nodes we're really
just want to have to so what the
orchestrator also does is it provides
environment profiles where we actually
just a cluster site for EDD based on the
environment ignoring it also just the
JDM resource usage right because if i
deployed on a laptop a laptop has less
memory typically than our bare metal
machines right then we just use the
orchestrator deplore the application and
say it runs in a bath and why amendment
is it just puts on with each other de
chava settings and things like that so
that's why we need that awkward thing in
the middle there the lateral manifest is
basically what I already touched on is
the collection of components through all
of our vaca which is lifted in there
according to the registry along with the
versions and that basically gives us the
final state of the application and the
platform installer is that thing that
actually installs it into the
environment so that's at a high level
the architecture does it make sense or
is that super confusing kind of sort of
all right so from a runtime architecture
the way it looks like very simple you
have 10 and think about a client it can
be a service program right it needs to
put some data into the at CD store it
runs in a tenant network and then it
goes
low balance of service which is engine X
as I mentioned before and then it's
basically our gets routed to an exedy
gateway and that route to a back-end
that is available obviously for high
availability or across availability
domain so it's one availability to
remain goes down you still be able to
access your data and you still have the
reelection there so that's that's it on
the runtime side arm so what's the
architectural will you give you a little
bit of testing strategy what we're doing
before we get into the best practices so
testing strategy as you know you know
microservices world each service is
owned by the service team and they're
typically responsible for the entire
pipeline right there are like in power
to make an update and put it into
production so we have that too so we
have service level tests they're all by
each service team that includes the unit
test component tests and integration
tests and Iran let's say a developer in
in Prague basically updates the code
checks it in runs of part of the
individual build in the CIC d-pad one
then we have what's called platform
level test that doesn't mean there is a
team that pushes a button right it's
still it's still up to the individual
team what the platform level tests do
they're basically like looking at the
bigger picture they are owned by a
central test team that doesn't mean it's
not automated right it's just a
different team that says okay those are
the tests that make sense for us to
deliver that's what we need to have in
order to ensure that our components are
actually safe and they include enter
interests like functional acceptance
tests minimal acceptance tests it's
basically like tests against EDD api's
upgrade tests right and things like that
longevity tests as soon as we have a
bill candidate for one service we
basically run along all probably like a
day off of tests against it and see if
something happens like memory leaks and
upgrade test so if we upgrade one
component to make sure the entire
application still works and then we have
of course performance as reference test
I too and then we do something very
special which is chaps and testing I
don't know you guys are familiar with
chaps on testing so it's because we're
revealing with a distributed system we
need to make sure that the data is
always consistent so if you write to a
node and then actually coherence
replicated to another node as you've
seen in architectural diagram and
something happened there needs to be
testin placed at eight on a cluster
level your data is consistent always
right as well as for the end user and
there is a test and mythology it's
called Jepsen testing and that's part of
our pipeline it's actually quite
interesting if you guys build
distributed systems was like distributed
data the factoria test you want to look
at and that's part of our automation
floating on so from a CI CD pipelines
the way it works is the first step is
what we call our verification so we use
localhost installation localhost cousin
Tina quantum laptop we can deliver some
machining can be our cloud just busy and
we do that with the last published
manifest that means it has think about
the manifest I talked about it has all
the components in their young you want
and we just deploy beautiful we deploy
the entire stack for testing there with
all the components then we're on a
functional acceptance test in 10 minute
parallel chunks so we because one thing
and I'll talk about that in the lessons
learned is if you have a lot of teams
that commit a lot of stuff write your
end-to-end testing actually becomes
fairly long so we need to find a way
that our developers get a response back
in a timely manner and said eight my
components a successful I can involve or
we've discovered it so we broke down the
tests in parallel testing so we
basically all the tested
about or broken up into chunks reached
10 minutes and then we run them in
parallel and different levels so and
then be around the upgrade acceptance
test again from one component to another
like think about you have engine X
gateway version 12 version 1.1 so the
next one is on the brief stage is a
production live environment with the
last published platform manifest again
but this is like not on my local machine
is really productions priest in the
glory of lat immune systems that as I
mentioned with a new component so
everything is going to be worked out and
deployed from you then we're on all the
acceptance tests and the operators and
see if that's okay so after that we go
into staging and as you can see that's a
very traditional like testing pipeline
but it's very agile because it's all
automated there is no human interaction
at that point I should point it out
that's all all so and then here we are
making environment and that's a
production lab environment which is
mirrors and then we operated a new
version we run a bunch of tests and if
that pass were successful to take the
manifest that we just created now we
have an updated component in there and
that's going to be our new manager and
then if another team basically starts
over that that's the long ago and then
we have the production candidate so the
relaxing edited and as I mentioned
before we try to automate everything and
we actually couldn't we couldn't do
continuous deployment and the reasons we
run in stress test we're only captain
says we get so much either we haven't
found a good way to only the
interpretation of that data right so we
still need a human person who looks at
that and says yes that actually works we
don't have any problem okay so that's
the you that's what we haven't been able
to other way and that's mainly because
again there's a lot of data coming in
from
from stress testing and judgmental and
so we review the probe occupied at night
with all the apps and we say yeah like
based on what we've seen it looks okay
but then we still have a person that
actually looks at it and says yes that's
actually something to put in corruption
that being said we are actually working
on trying to automate it but we haven't
found a good way it so there is a team
right now is actually trying to do it
because eventually we want to get into
the continual promoted in component or
service all of that that step is
actually holding us back another
interesting aspect here probably from
entering once we have that production
candidate declared it and someone says
it's okay we have another we have a
production release class line where it
basically goes through again but it's a
smaller but so this is this is it I
think from a architectural perspective
you get an idea how we build it you get
an idea how we do the devops right so
let's try if I can actually show it to
you oh cool it looks works so this is
just a marathon you I I mean you guys
are familiar with NATO's marathon okay
so at the marathon you I it's basically
like the orchestrator that takes the
containers and schedules them in the
cluster that's the thing that I
mentioned it will be replacing
eventually but from an end-user
perspective it looks more like this so
this is the on this is the the website
to create a new etsy store for your
service as you can see that's why I said
we haven't decided whether to make it
publicly available um more like an
internal you I but it's okay i don't
have a store yet and what I can do in
here I can create a new store and give
it a name called a demo store I can
choose the version i have my my network
think about that's a network of my
that's my network of my tenants I want
to create that distance right and then
I can have some automatic backups and
stuff like that it's for the data and
then I just create a store and so now
it's creating it if I switch over to
marathon it's going to create a new
application in Marathon as you can see
here it says 10 and 1 and intended one
that's actually thinking think back to
the architecture diagram now you have
those at td1 td2 that's actually the
application okay and the cluster itself
wrong here in the service we CN and
let's see if I can make that bigger so
in the service museum you see all those
components that I mentioned before the
orchestrator and diagnostic stuff that's
the part on the right hand side of the
architectural diamond on so if i go back
here to oblique applications go to
tenant this is my v CN 1 and then I
basically have my attorney store now a
service team could go in there grab the
end points for that particular to do
write the data to use it for legal
action and so on then we have the other
UI is so that was the UI for tenant to
create it the other UI we have is for an
operator and the operator actually just
shows you how many clusters we have
running right now currently have one st
gloucester running so that means what an
operator could go in there and say we
need a new cluster and go in here and
and create a new cluster managed to
gloucester will upgrade it to a new
version let's say there's a new a 2d
version which is actually true like from
ftv to version two to equity version
free they can just go in there upgraded
and your application would be impacted
ok cool so as you can see it's a it's a
fairly complex architecture it's not a
lot of services if you will like their
Microsoft applications of thousands of
services right well it's a fairly
sophisticated architecture given the
nature of the use case of the service
so what are the lessons learned here on
let me switch back here and go alright
we go to the lessons learned so the
first one as I mentioned before it's a
left-hander you learn but it's also best
practice for any diseases we assume that
your services tail right there is that's
not something that may not happen that's
going on so what do you need to do here
in your code you're actually two are
going to implement like certain things
and Eric there things are we are using
obviously retries right so once the
service endpoint cannot be reached are
we are not saying it's down which just
retry it what's important there is that
those operations need to be idempotent
so to give you an idea let's say you
make a make a call to a service right
which puts a message in a few wait so
and that's they failed and use
implemented retry and you put a new
message in there with the same value
right so you have that message twice in
your queue right what you need to do is
you need to make make it item code n
that mean to give it like an ID right
where you check hey that's the same
process that's very important there then
we're using circuit breakers which is um
basically on at some point we give up
retrying we just know that things going
to fail and we need to snap out of it at
all and that's why we use our circuit
breakers and there in our case they're
combined with a regional power and then
we also using arm bulkheads which is
basically trying to avoid that
exceptional threads and things like that
the cool thing here is except the
retries like the broadcast and the
circuit breakers are actually available
for java developers in an api called his
parents like that so if you go to
history or netflix or results there's a
historic library which you can just put
in there and it's really great it comes
with a dashboard
so the other thing is our lessons
learned and that's true now think about
in microservices world a lot of people
say hey dot gradient and I have so many
services right and they talk to each
other what are a lot of people
completely underestimated there's a lot
of Kenny mess going on right so and that
action can become your bottleneck so
what do you need to do there is you need
to have certain you need to think about
what kind of protocols you want to write
so and in like a micro services world
you need to think about this is an
external service or its as an intern
instance because for an internal serves
you can different these different
protocols that are probably better for
performing so in our case we are using
like for the DD its South we using HTTP
to right now because that's what's
required for it to be we free but
internally then are we using TCP UDP as
well because it's just faster and for
the coherence connection they have their
own pro recorded the other aspect is
like because you're in a micro services
world like in ours you exchanging data
and the data needs to be serialized in
DC and that can actually become the
bottom it may not happen ok but if you
have an occasion grows and think about
you bill to service to be hyper again
right then it can actually become a
bottle all right then you need to figure
out what's a good way of serialization
GC realization wait the thing is we have
i mentioned we're using chedi for a type
of stuff that does it for us but there's
also a long thing you can do is can
actually maybe you don't need to
serialize it again right maybe you can
just pass it on and just off mine the
data and things like that so that's
another lesson learned that's that's
really something that's very
underestimated in the space of microsoft
then darker in java apps what a lot of
people know is that Dockers
hey I just want you to use that amount
of memory I just want you to use that
amount of CPU problem is your change
another little people know and so on we
also figured it out we own each other
right and so it doesn't honor the doctor
the most happily there is where we
figured out the darker Damon killed the
container and X crossing occurs when
it's crossing the constraint so what
we've done is we actually are specified
might be proposal and also nominated so
they to me every time you start of a
daughter for dinner with the jvm in
there you tell it the changes and tell
you can use that model so the other
thing is now you're dealing with the
docker container rate but you also have
like in our case makers marathon you
have a deployment kingson file you also
need to make sure that that deployment
chasin file somehow aware of what's
going on right so it's a tricky part the
good news is on on the memory part
that's addressed in Java nine so the
memory thing is going to be addressed
with going away you don't need to worry
about it you still have to worry about
that in the in the cpu case and it's
pretty much the same the same so the
other problem is if you if you're not
doing that as i mentioned before
orchestrator shut the garnishes insert
your application so the way we're doing
this is on on the left hand side we make
we have a
and we going to launch a startup script
in there right start of it every time
you're welcome then there's a marathon
cases on a fool like American tape of us
so think about it like Dhaka FA's you
guys know right so in an American
Kingston file you could always as your
description of anomaly Jason 5 that says
hey who's that container said those
environment variables right use that
much CPU use that much memory in that
type of stuff think about it as a
description of your application I can
actually show you 10 because going back
here going back to marathon let's grab
going back to applications go to the
service vcn and don't you that pic let's
take the storage one going here so if i
look at the configuration this is
basically the dead chasing fun right so
you define it you declare the chase and
fog you submit it to marathon and
marathon grabs it and I'm basically
schedule into your container on the
cluster that's how it looks like it says
container e-type talker then it says
ready to get the docker image from right
which networking to use the container
port service ports and so on and so
forth so this is this the idea of the
table so what we had to do here is
obviously going back this one you are
marathon location father I was to show
you you had to be fine environmentally
weighted we're saying ok the mask ok no
cpu or you can use this wrong and here
are the max container memory quota is
give chase change in that and then what
the environment that's when I mentioned
we to sync it with our with the
orchestrator as well
when your bleep self marathon itself how
much memory will adjust or give it to
that container late and I'm on the
amount so that's container memory on
that marathon will give to the container
right and that's what we set it to the
chava vm inside the country and we have
a factor of 20 and that's how we figured
it out there's actually not a formula
how I cannot give you a formal and say
as you do this age travel nine is gone
nueces there's really no formula we
figure it for all that works best if we
have a factor of two wheeler alright so
then once the container store the other
image-sharing component and then yes as
we basically executed start of sh off
script which is in command instruction
and sacrifice and that looks exactly
like that are actually confidence from
our sources say hey you know what get to
get the memory quota get the cpu grown
environment so key takeaway here is java
nine memory you don't need to worry
about it anymore it KVN will honor it if
you do things with the cpu and things
like that you still need to do right and
we're currently looking at java 10
because it's it's not super easy to
implement that to be honest alright so
the other thing is armed lessons learned
marathon or some other orchestrators
good good real I sure that certain
certain component often wrong so what we
have to do is we had
health check your altar we actually ping
to service and say hey hey are you there
are you there are you there so we
couldn't rely on basically are the
status of marathon and that's in general
a good practice there it's very
interesting because I've been as I
mentioned before I've been dealing with
that stuff for quite a while especially
on a service container service never
really thought about too much if I'm
completely on it until I came to work
order we have the requirement that
service has to be awesome so very
interesting so that's all that I put
that in the slide on engine eggs so
dynamic reconfiguration I want to be the
Lord short version talking to it hey so
when we need to reconfigure internet is
think about I have the tenant low level
that I had in my architecture virus now
I set up a new trouble right I've been
at the DJ raise a problem how would be
my 10th 11th normal so one who is
actually are our orchestrator takes care
of it and says hey I have a new cluster
that's a cluster endpoints but we need
to update the engine eggs configuration
things wrong so also no need to do know
very good i have a woman's life on earth
but we didn't know that change was
applied he was very unreliable telling
us yes and genetic processes running
what had the new configuration or not so
we do the same thing we do basically we
recycle the engine hex process and then
opinion and say are you back home um
most of the fabled engine I logging
because again we have our own stuff and
then increase the worker processes to
match the load because they're de quite
on some lose so the way it works is on
and this is a nightie animated slide
simplified diagram overlap show you the
orchestrator is there that's the thing
again that creates a new cluster and
things like that so contain I want to
add a new cluster and operator at a new
cluster new cluster gets added to the
bare metal cloud service then the
cluster starts operating and then what
happening then is it basically reports
back to the orchestrator says hey I have
a new cluster have new entity gateways
for you then the the orchestrator takes
the new endpoints and issues and puts it
together and actually been cleared to
engine X so our engine next image is not
just an engine X image it is also it has
a child or component in there that
offers an endpoint ready orchestrate a
complaint of information right and
that's very yellow thing you should have
probably said thing so the traffic
component receives the new are the new
router engine X adds it to the engine X
configuration recycles the whole thing
will ping you'd say hey are you back up
and once it's back up it can actually
use a new tenant can use the new
gloucester so i hope that's like kind of
illustrates why we had to do this you
create and remove cluster so from you
can inside you need to do the dynamic
configuration containers um it's
actually I think mean wallets it's
common sense to emitter to version your
container images because necessarily
mean that the latest update right it's
basically latest on version thing so you
should always on do the container image
versioning use small base images it's
also one thing that's not something
that's obvious right away because a lot
of examples are built on let's say big
images like and 12 and there's nothing
wrong with it but if you need to start
in
ah what am I sure that your container
image size is pretty small because if
you're in an Orchestrator let's say
you're getting out and says hey I need
to launch a lot of instances on no three
that image is not a North Korea needs to
pull it out if you have a large image
size it takes a while to pull it down
nothing to do with the container
lunchtime that's super fast the pole is
what's taking time and that's taking
time Tory service so think about keeping
the decisis no one what we've also done
is arm for engine eggs are we actually
use one base image for multiple purposes
and I don't know that whether or not i
just added air because you may run into
that situation so internet 2014 qe2
right now right so we had to add code to
support HTTP two so we updated it but
our operator wrote that in the world
owner dinner but we really should do
right now we have moved it over Tristan
HTTP the tenable silencer don't need to
because on like a TV version 3 which it
should be too right so what we're doing
is we're actually just clapping a slag
in and say we have one image for both
use cases and we just pass a flagon and
say okay is it a tenant load balancer
roses and operate a little Dunham's and
based on that we enable it or not so
finally the CIA CD lessons learned
formation we know everything we know the
whole again try to be sensible but we
cannot right now this is like a
technical thing it's more like a if you
deal with various development teams
which you do in a micro services world
let the development teams choose what
they want to use so we we have a whole
mix because as you probably know Oracle
is acquiring bunch companies right
that's what
or does and we have a bunch of companies
and a bunch of why I complete the
technology we have to prey on the weak
side you know what you guys really
comfortable so in that case we are
supporting both you even greater project
that also helps to you from an
organizational perspective to get your
desk ray more involved in the theology
because before they don't really care
and especially to force them to certain
in that case you can ignore our
development they are very more involved
they are very more opinions and how this
whole thing's of your then with
restricting the testing pipeline the
global components i mention it before
our deployment component or unit of
deployment is a talker container period
we have teams that just produce a jar
they are required to put those things in
a docker container kind of like common
sense right because our entire pipeline
amenities with Aranda and then the other
thing is their project to be responsible
for managing advances with other project
so we basically push that climbing down
today it's working fairly well on then
every every dev team member should be
able to stand up an environment an
isolated environment in a very easy way
and that's why we created remember the
orchestrator things that I talked about
with environmental cause it's very easy
for a developer now to reproduce
something in our case because they just
basically say okay I have deployment
profile development and it spins it up
on a virtual machine and then they
contested and it basically have the
entire environment running there
the other part is the agile testing
pyramid of you have integration on trend
test so what's taking the longest it's
your interests intense rate if you think
about and if you go from the entire time
I normal eyes so we actually emphasize
more on the unit testing more on the
immigration because you right at the
beginning right and that's why we call
it like that the pyramid because our
testing is we do less enter and testing
we do more emphasized on on your new
testing and things like that are
paralyzed testing were possible to cut
down the time that's what we've done
before our tests were running for quite
some time and then we cut it down into
10 minutes chunks as I mentioned before
by spinning off those tests in parallel
it's good because developers get the
feedback right away then the upgrades
have you seen in my slides we test
upgrades pretty much like from the
beginning right as soon as we as a team
hasn't produced a new version service we
test the upgrade of the service of the
entire application so we do that very
early in the cycle and that's been
proven to very to be very time efficient
because think about guys what we really
want to be able to do is we want to be
able to react to new environments
quickly we'll be able to push it out and
so times of the essence we don't want to
go all the way and then just like after
three hours of testing and potentially
longevity test figure out the upgrades
so we do that very early and then we are
intermittent failures and end-to-end
testing be addressed right away do those
as well then develop a focused dashboard
on to essentially identify Pena's and
pipeline and blockages so as I mentioned
our CI 2d flow our CI TV system changes
and then we have our own dashboard on
trouble they'll actually shows which
component is a 12 stage which components
using what manager so every developer
can go there
and see if his check in is actually
going through the stages or and they can
also see which other components or part
of that testing were trailing arm very
important then on the diagnostics piece
as I mentioned before a front-loaded
adachi because diagnostics is key the
distributed system Diagnostics is key
even interesting and we are we're using
a common log format i said i mentioned
this before it's very important even
like think about date kind comments
right won t even puts it in a certain
format another team puts it in a certain
format you want to order it and things
like that so it really its diagnostic is
really key and again as i mentioned
before we're not just using elastic for
logging we also use in community so
we're using you may argue that we read
in too many systems for diagnostics
northerly to operate the system but it's
really pretty valuable to us to have
like a time series data between
communities to do like that the time
serious thing as well as the longing
thing then more to our situations in
finding about jimenez was a good choice
because we actually always know now what
makes our application right all the
components in our application what was
the latest version and so on and so
forth so for our pace that was good on
then mixing and matching between
component versions i was also good and
then the only thing and that's probably
not applicable to you guys and because
it's a lot of effort one thing that we
wish now we should have done it we
should have abstract from container
management maybe cuz now as I've seen
everything is amazing marathon now we're
going to move it over to another
orchestrator right so we need to change
all that it's doable but I mean for us
really now we need to dedicate a bunch
of resources on to moving it over to the
new platform
and we could have just avoided that by
making a really horrible so summary I
hope it was kind of like useful and so
we're using micro servers approach hats
with time to market we're really able to
should not take the component in a very
timely manner if you're probably like
normally launch there's a nice blog post
out there actually talks about it
because you're entering a distributed
system world it's a complex talk I just
need to be rare would be dealing with
tools and technology of choice requires
governance because if you follow like
the microservices recommendations every
team can use what they want and things
like that if you don't have governance
and place you're creating anarchy that's
just a fact starts with Diagnostics it
goes over data and so on and so forth so
if you have multiple teams building out
an application like that governance in
place the IP pipeline automation or key
but again can leave those two supporting
our team and they're more on that topic
I actually started blogging out from
microservices topics I mean it's been
beaten to death but a lot of that stuff
is actually influenced from what we've
built here on the Oregon law on so with
that I think I'm right on time I hope
that was somewhat useful
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>