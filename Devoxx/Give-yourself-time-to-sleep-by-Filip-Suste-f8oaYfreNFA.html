<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Give yourself time to sleep by Filip Suste | Coder Coacher - Coaching Coders</title><meta content="Give yourself time to sleep by Filip Suste - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Give yourself time to sleep by Filip Suste</b></h2><h5 class="post__date">2017-08-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/f8oaYfreNFA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I think we can start now so welcome
everyone to give yourself time to sleep
painless system marketing talk first off
you're going to hear a lot today don't
let that intimidate you there's a lot of
components a lot of properties and
information you're taking in the
painless part is when you set it up
it runs on its own so what do you want
to get out of your monitoring system is
not not being on your computer checking
that your servers and services are up
all the time a bit about me so I'm
Philip Schuester I'm in the UPS engineer
at infinim we are independent design and
development agency based in Zagreb
Croatia we have clients from all over
the world a lot of projects that we
handle and with agency type of work
comes a specific set of problems so
there's not a lot of servers but that's
a lot of projects that need to be run
and a lot of external services that I
need to communicate with and that my
developers need to communicate with and
I need to check if everything is okay
between them so talking about monitoring
who uses some kind of monitoring
can you see hands okay shame on you
don't so when you started when we
started when you started we had obtained
robot that's basically a service that
sends an HTTP pink and if it receives
200 that's okay it says everything is
fine and then we needed to need to
monitor a bit more services so we need
to check if everything is okay with the
database if everything is okay with the
Redis
if some other api's are okay if they
haven't changed their schema because you
know external API appears does that
so sometimes we had we had drafted up a
list of available monitoring tools then
and Prometheus was not really stable and
the community was a bit low but we went
through the list so we wanted our own
hostage monitoring tool so we just like
eliminated those on the right and we
went through each one every one of them
check their pros and cons we found that
nagisa new single was were a bit out of
date a single okay but Nagas was out of
date they had a higher learning curve
for a less rewarding experience compared
to some others and while monitors to
basic zabbix was too complicated so
basically we came to San Soo
first of all let's let's see a bit of
spoiler so this is our monitoring setup
it seems a lot but it's really easy
small components that do the right thing
so what is sensu since there's a
monitoring framework that uses four
components so there's a sensor server
there are sensor clients there is a
sensor API and a dashboard you can see
the results through so basically this is
the architecture from behind so it uses
the server and uses rabbitmq as a
default transport you can change that of
course to communicate with the clients
to publish and subscribe through to the
checks then it uses Redis for storage
not permanent
course but storage so and API to
communicate with external services and
dashboards so these are the four
components that sense users so talking
about sensor server it's basically the
brains behind the operation you
configure it with basic Ruby and JSON
files it's really easy not much to it so
we just run this down way okay so I'm
gonna have to point like this to you so
the checks is the keyword for all the
checks that you want to have the CPU
status is the name of the check the type
can be either standard or metric the
difference between the two being the
metric will fire off an event for some
other type of handlers the command
basically a script or a binary needs to
be executed and you given two flags
that's warning and critical so the check
will know and give you one zero or two
depending on how the check went the
interval is basically how many seconds
between two checks are needed the
subscribers are a list of clients that
listen for those types of checks the
handlers are which which handlers are
needed to to tell you if something
something went bad and the occurrences
is basically the number of checks that
need to be failure for sensitive
reported to you so it's basically
warning a 90% critical at 95% and
that's it the sensory API is basically
the glue for communication with external
services that Nash boards so you can
either run a check by pinging sensu
playa checks API or get all your clients
and results through the API through
Achieva it has also aggregates API
events stashes API and so on it's got
really really good documentation and I'm
not kidding about this if you want to
check it out the bar code is here this
is the this is basically the real power
of sensu so it has easily programmable
checks that you can do almost anything
with and through its API is restful JSON
interface okay so you Chiva is basically
the sense dashboard that's open source
you can have a sense of enterprise
dashboard if you pay for it we don't we
think of it as good enough
it's basically django api a django app
that uses the sense of api so this is an
example of the achieve a dashboard god
that's huge
okay so these are the clients here I've
covered the piece but you could see
their IPs
those are the events that are occurring
the checks that are failing or something
else that's happening for for those
clients the versions the data center and
when when did that happen
so Achieva prides itself to be unified
client and you can see all the checks
together or one check specifically I'll
show you that a bit later
it's really powerful and simple so if it
can you can do basically everything you
need so if you need to silence a check
if you need to aggregate the results and
make a summary of those Jax checks it's
really simple to do so so this is the
rate check of one of our servers
basically it's one check that you can
see how its configured its history
through Redis and when it was last
issued and so on the sense client is
basically a piece of software that
subscribes to the RabbitMQ checks
through through what you defined it as a
subscriber - it can be standalone also
so if you have a server or in a bank or
somewhere where nothing could get can
get in - you can still report that and
monitor that with sensu it has a simple
confer configuration with advanced
features so as I said standalone pub/sub
and it's basically used for
communication between servers and
clients you can have one or many of
those sensor clients so basically it's
like a namespace for for a bunch of
checks okay so if I wanted to test an
API external API that's a black box to
me and they need to check the results
against my adjacent Seema to see if the
API changes or not you can do that
namespace it with and create the client
that's basically for that and it will
appear as I don't know Maya's map API
and signal you
exactly what check didn't pass or did
pass so these are all handled to
RabbitMQ or whatever else transport you
got so again the architecture before we
go any further as you can see so the
sensor clients are communicating to the
RabbitMQ that sends the server published
its checks to since server then gets the
results and stores them into Redis and
you can use Achieva through its sensory
API to get those results out of the
Redis so next thing we need is a bit of
graphing so alerts all are all fine but
when you get an alert that your disk is
up it's already too late so you need to
monitor that accordingly and make sure
that doesn't happen before you hit the
roof so we chose graphite because well
it it goes really really well with sensu
so you just get the sense to relay and
that's basically like three lines of
code to pipe all your metrics into into
carbon carbon is uh
is a thing from graphite that fetches
those results and stores them into
whisper whispers the database and
Griffin eyes the view layer or the app
that which through which you will see
the graphs so this is graphite slogan
agree with it completely
so let's go to the process again you get
your checks done with sensu you then
rely on to carbon in to carbon through
centrally relay so that's the picture
again here then on carbon
you got your carbon cache your
aggregation and relays so carbon cache
is a peyten
writing script that basically aggregates
results from sensor relay and then
writes them into the whisper database
aggregation and relay are another two
carbon scripts I didn't mention them
because we don't use them basically
those are if you want if you have a
bunch a bunch a ton of checks that you
need to save really really fast so we
haven't hit the roof like it's about ten
percent usage currently with 30 of 30
servers and 2,000 checks per minute so
it's really powerful
so you configured it just the way I like
it so we're talking here about data
retention so carbon when he gets the
checks from the sensor relay he creates
data points data points we rich retreat
which he writes to the whisper database
and you can create a lot of data
retention points that suit your needs so
you can have 10 second data points for a
day a minutes a minute worth of data
points for seven days and then 10
minutes worth of data points for a year
it's all sort in the whisper database
since its since you have all these data
retention pairs that are fixed it has a
fixed size so don't let that worry you
if you're like looking why isn't
anything coming into my whisper database
it's everything it's the same size the
files are just updated but they don't
seem any bigger and basically the
whisper database is really easy to
configure it has a really small set of
eight attributes you can just leave it
as is when you install it default lis it
also has a lots of tools to get you
started so like whisper create dump
fetch info resize update or set a
gradation method then there's the data
aggregation is in whisper is a bit
unique so when you're dealing with
metrics you have to have some
aggregation or your data points and
since the update came like a month and a
half ago since you didn't have
configuration files I deleted them
accidentally because everything was
running okay by default whisper database
again replenished the all the default
configuration files and ran in the fault
mode which meant half of the half of the
data points in a date period needed to
be valid or none know for it to give you
a result when you create it so that
caused me they a week and a half of lost
metrics so I didn't see anything on
gravano but it was actually there I was
just not crying it's that good
so--but about Griffin oh it's it
unfortunately relies on graphite web
that's the API it uses to query the
whisper database it has really beautiful
metric metrics and graphing so this is
what it looks like it's again easy to
set up it took me like 10 minutes to get
this running you can see you can have
multiple multiple metrics on one table
or I don't know what what ever you want
basically you can do with it it has
support for templating so if you get a
bunch of metrics from a bunch of servers
you don't need to make a lot of
dashboard so you make one dashboard and
configure it templates like here so you
don't need to repeat yourself even even
if in dev ops it has multi-user support
if you want to give your clients access
to your graph owner for us that was
particularly useful because as I said we
have a lot of clients and they want to
see some metrics that if we say well we
created the metric system for them and
we're monitoring their servers they want
to see it and this is the way to do it
since Rivanna 4.0 it has alerts so
basically what I said was you want to
know when your disk will run out these
alerts will get you there so they'll
send you an email when you set the
threshold and when you see like up in
graph so so the graph is going going up
rapidly Griffin will alert you about
that
- it has a kiosk and playlist mode since
Griffin a 4.0 so you can even stick it
up on a wall and let everyone in the
firm see how great your servers are
doing and to round it up to round the
whole thing up we need centralized
logging so okay here has centralized
logging who has tried that out okay I
see a few hands this is really really
great great so basically when when we
saw the opportunity from one of our
other clients we said we have to have
that and we had four three three to four
demands from it so we needed to have
everything in one place we needed to be
able to search through through those
logs and make charts because hey
everyone loves charts and we really want
an easy-to-use front-end because no one
likes to go through pearl red X's or
whatnot
so when we put the tones on the tables
so again we didn't go with a paid
solution a hosted solution we go to self
hosted solution and between elk and gray
log we chose Greylock since elk was elk
is the industry standard I know but we
really got more from gray log especially
for the interface part so all of our all
of our developers could query the logs
easily and get some useful information
out of them without us being there for
them so what is Greylock
in Elk logstash pipes directly to its
its contents to elasticsearch and
Greylock did think some things
differently so log sources are piped to
the gray log server and then you can you
can get them through pipelines and
different inputs and merge the data or
edit the data before it gets saved into
elasticsearch and that's a really nifty
feature and then it could you can view
it or pipe it again into another system
so this is what looks like this is not
really a bunch of messages per second as
you can see right there but it's really
really useful this is a stream view of
one of our apps
Greylock has Gulf which is gray log
extended log format which is really easy
to use to to read and basically all the
older languages adopted it to format
their logs into it so you're not gonna
have a problem with formatting your logs
the way Greylock is used to you can
refine you can define multiple inputs
for your data you can extract them with
extractors so getting those fields out
of the logs is really important because
of quick values something I will get you
a bit later you can then store them into
indexes indexes is a bit
quirky at the moment but they're working
it out so you can have maximum of one
index per Greylock server that means no
different retention periods for now for
different kinds of logs logs can be then
grouped in streams and this is again
really useful for for agencies work
because this is what it looks like you
can you can set up users and groups to
view only streams so you get that
isolation between your clients so they
don't see everything on your
infrastructure it has simple and
advanced search so as much as developers
don't really like redexes we DevOps do
so we we can still query it query our
logs through Advanced Search or we can
set up easily dashboards this is
something like it used to so when the
developer comes to me and asked me how
much how how much percent how much is
the percentage of users going to the
German API of my app I just sit with
them show them this and they're like
well I can see that like in an instant
now that's great
so you parse parse the language out with
an extractor you click on the language
and you get those quick values for the
period you're looking for it has
notifications and alarms so if you can't
do something through sensu or gravano
which i think is a bit or
over-reaction you can do that through
Greylock so if anything comes through
your logs and needs your attention you
can get a mail or get to slack wire web
hook as I said it has granular user and
group management so isolating the
streams or inputs setting up groups of
people that can view different streams
is really really easy okay
so let's review we have our sensor
clients that pipe the data and the
checks we need to into rabbitmq we then
have our since sensor server that stores
that into Redis we use the sensor API to
show our checks on Achieva and on the
carbon side on the graphing side we use
sensor relay to get our that data from
the sensor server to carbon save it into
whisper and then create through Gravano
and from for the Greylock bit so we pipe
and edit our data into the graylek
server which then saves it to
elasticsearch and then we can pair it
and manipulate it to the Greylock web
interface or pipe it again to another
system so the point of my talk was not
to show my shiny set up but to say is
say anything that lets you sleep at
night
is good monitoring so you want from your
monitoring to get an alert when
something goes down and when it comes
back up again
you need to be able to react to it fast
you need to highlight the problem and
get a result quickly that's it for me
please read rate me on shadow and feel
free to pin me or Twitter or catch me
outside are there any questions so the
question is how long did it take me to
set is set it all up so first time I'm
not gonna lie it took me three days the
second time I was doing this last last
Saturday for another for another setup
like this it took me four hours when I
when he kind of grabs grasp the which
components reacted which ones
communicate and how it's really not that
hard to do
so you're talking about sensu ravana or
a narwhal so sense who has a great way
of aggregating those pings
so it won't bring you unless unless
something changed which is great which
is probably the way all monitoring
alerts should be and you can also set
with I didn't mention here you can also
set up remediation so if I don't go to
my achiever panel and say okay I fixed
it sensor will try to remediate the
problem by running a script I made that
will just like reboot nginx or something
and see if that fixed if that didn't fix
the problem send me another ping anyone
else yes
we have sensor client yes
gray looks gray look is gray look
doesn't have a client you just pipe your
logs to your application
so we Center a rails shop we use log
sorry
Symantec logger I think Symantec lager
which transforms so rails logs that
would usually end up in passenger logs
and just sends them to our gulf endpoint
and for the sensor yes you do need to
have a sense of client on the server you
it's not that not that hard to install
it and it's definitely not hard to
configure it so you just if you don't
have any checks on or that that are
custom you just install it on the server
subsided up the client so it would
subscribe to the topics like CPU web
servers and database and when the sensor
server pushes those kinds of checks it
can immediately react and send the
results back
yes oh so the application when it
receives our crest it goes exactly into
rails logger and then rails loggers and
is over ridden by semantic logger which
just shoot it shoots it out on a gulf
output or it the gulf endpoint of our
gray log server okay is that it
okay thank you for being here and I'll
see you outside for drinks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>