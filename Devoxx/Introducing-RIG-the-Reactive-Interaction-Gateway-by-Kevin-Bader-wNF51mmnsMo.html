<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Introducing RIG – the Reactive Interaction Gateway by Kevin Bader | Coder Coacher - Coaching Coders</title><meta content="Introducing RIG – the Reactive Interaction Gateway by Kevin Bader - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Introducing RIG – the Reactive Interaction Gateway by Kevin Bader</b></h2><h5 class="post__date">2017-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wNF51mmnsMo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so welcome to a talk we have a
we're happy that you here even though
this is the last slot so a lot of people
already left or in your own rooms and we
will present the reactive interaction
gateway but before we do that we want to
introduce ourselves this is me I'm Kevin
bada
I'm with extension technologies based in
Vienna and and yeah I'm Dominic
varnished
I took the picture so I'm not in the
picture one of the team events on the
Danube I came up with the entire idea of
the Rick so if you think the idea is
plain stupid blame me if the
implementation is bad blame him so what
is the idea behind it it's pretty simple
the business pitch as a user while on
the site I want to do specific things
and I want to see specific things happen
I want to see that my online banking for
example pops up new transactions or new
messages or stuff like that
automatically if I'm on a hotel booking
site and I'm looking at a specific hotel
and I'm leaving the window open and I go
to the toilet and I come back again then
I want to stay to be up-to-date I don't
want to click on a room that is actually
no longer available or I want to choose
a flight or a seat on a flight that is
actually available so in the end it is
about having real-time inter information
available so that you can do real-time
interaction and this is particularly
complicated once you go into
state-of-the-art microservice
architectures and with that I leave you
with Kevin essentially but can of course
help them with all the questions that
you have about why this idea is good or
not good so now that the business side
is easy to describe I want to talk a
little bit more about the technical
sides and motivation for it so what is
directive interaction gateway
so let's start with a very simple
example of a client-server system we
have just two devices of one user
she's Ellis and we have one backends and
we have sync in this example we have
synchronous request reply through an API
gateway pretty straightforward if we
want to have notifications or
asynchronous events pushed from the
backend to LS we can do this by using
something like WebSockets or service and
events we can just make a channel
directly from the back-end to Alice
basically somebody gateway so this is
this looks easy enough but what about if
we add more services to it so instead of
having one back-end let's consider
having multiple services on the back
hand side
this might be multiple different
services but also maybe one service that
just scared out so if we do if we have
this and we want to get the
notifications we can do the same thing
as we did before we make a connection to
this service and then this service or
two connections basically for each
device one and then this service can
push down notifications again but if we
interested also in events of another
service we can do the same thing again
and it already starts to look pretty
crappy so we don't really want this kind
of architecture because it's just not
scalable at all so what could we do
about this we could add a service that
holds all those connections for us that
service is here you see that all the
connections go to that service and this
service holds all are connected to the
front ends so we have to copy that one
thing that's still covered here is that
all services are coupled to this service
that consumes the event from the
back-end services so we can add yet
another thing some event broker in our
case within the Jose Kafka that is used
to decouple those back-end services from
that service and this service and
basically is a Kafka group consumer and
now it easy to show what Drake is it's
exactly the combination like Ric is an
API gateway and also a consumer to Kafka
and pushes down events to front ends and
holds all the connections for you
services so now that you know what Drake
is I want to talk a little bit more
about how it works internally and its
features regarding scaling out Rick is
pretty easy to scale out despite having
holding all those connections and being
stateful rather than stateless you still
can just deploy it many times and we
will synchronize automatically between
all the instances among a cluster
routing messages you can have you can
have a lot of users and each user either
is not not online at all or has one or
more devices and those devices are
connected to any node usually you would
have a load balancer in front of you
Rick nodes and so you can really know
which devices are connected where so to
show this I have in this example two
users now Alice and Bob I both have two
devices connected to different instances
in the red cluster and then if you have
a back-end that generates a message for
LS it sends this message to a kafka
topic and then this message is consumed
in this case by Rick three they are
group consumers so they split the
petitions are assigned evenly among the
cluster so this is just basically at
random where this message ends up now
Rick three knows where the where Alice
devices are so Rick three can distribute
the message to the other nodes where
Alice devices are really connected and
those nodes then pushed pushed down the
message there is another scenario where
you have privileged user we can say that
Bob is privileged and is able to see all
the messages including those targeted at
Alice then finally we have request
authorization Rick checks the valid the
validity of tokens we're using JW T's
and to check the validity for proxy
requests so in a usual API gateway thing
and also for long-running connections
also we have also have a feature for
black listing tokens for immediate
logout so what you can do is you can if
for instance you think that something
malicious is going on and you want to to
disconnect all the devices of a certain
user you can use an API of you can one
of you can use one of Rick's api's to
blacklist the token of that user and our
connections will be immediately torn
down
this is special because usually with WTS
you have just timeouts which tell you
the validity of a token but you cannot
end the validity of a token before the
timeout unless you have something like a
blacklist and this blacklist is also
distributed in memory among the cluster
so you register shared ability to be
blacklisted at OneNote and this
information will get distributed
eventually consistent among the cluster
so to summarize rick is a stateful
component so that you micro services
don't have to be stateful it holds all
the connections to the front ends and
exposes internal events in a scalable
way and on top of that it does request
validation and managers this token
blacklist I just mentioned so now that
we know what the features are of Rick
and let's talk a little bit about how
implemented this stuff we didn't go for
Java but instead went for elective
Phoenix which runs on top of the Erlang
virtual machine the reason for this
actually there are quite a few reasons
why we did that the first one is that
the Alang vm gives soft real-time
guarantees this means that soft
real-time and this means in this case
means that the average latency of any
request and doesn't change that much you
always get the result in the same time
in regardless of how many connections
you currently have and this is possibly
because the actor model is implemented
in Erlang VM in a ways such that all
actors are really really very much
isolated from each other to the point
where you
have a separate garbage collector for
each actor those actors processes are
not really are not real or less
processes they're not even real threats
but are even more lightweight
abstraction which takes very little
memory and can be created and destroyed
basically instantaneously so this is
perfect for handling a lot of concurrent
connections you never run into a cheats
and GC pause or anything like that then
we have this distribution thing where we
have location transparent communication
the message routing I've mentioned
earlier in Allen it's just the same
thing as if you would route the message
to the connection on the same host you
don't really doesn't make a difference
from from an implementation perspective
along VM is also very mature of VM it's
used in production since 1992 so it can
be considered better tested and it is
optimized for it for the actor model so
with Scala and akka we have the same and
we have a similar model but JVM is just
not that optimized for it then last but
not least we have reliability the reason
is that transient failures happen all
the time and Erlang has supervisors that
help with this and I would like to
demonstrate this really quickly so here
you see a shell where I start the server
and sure where I start the server a
second time and you see a lot of errors
here because I haven't started Kafka yet
I will do that
so Kafka is going up now and if
everything works all right we should see
them reconnect so while I'm waiting for
the reconnect I know you see it
they recognize the Kafka is up now and
petition zero I only have one petition
in this example got assigned to the
first rigged instance and then I connect
the remote child to
instance and then I can start an
observer which is just a fancy going to
see into the internet process you can
see that I don't know anything can make
it larger I hope you can see that here
you see all the applications that run in
there they're pretty much isolated from
each other one of the applications is
called Rick and there you see the
supervisor structure that I've just
mentioned for instance you see a
structure a part which is concerned with
Kafka group consumer part and brought
this the library that we're using and
now I can try killing one of those
processes can just kill the main Kafka
client here if I do that you see in the
top left corner that it exited because
there wasn't and because there was a
failure it tells you the last message
and the state the process was in when it
died and you see also that the petition
got reassigned to the other client but
now it has restarted everything and you
see that here Rick brought client is up
again the supervisor has has catched the
arrow has catched the fault and
restarted everything in the same state
just like he would restart just like if
the application would have been
restarted but only that part that
actually died and then you see it up
again and it again gotten cut the
assignment is now currently with the
other one so this is what the does it is
what the supervisors are for and this
makes the system very resilient to
failure to faults because there are a
lot of transient faults in the
distributed system like network
connections might fail or stuff like
this stuff that you cannot really
foresee so it's good to have a system
that's and that's built on the
assumption that everything can fail all
the time so this was a long another
question is I said Alexia what is the
leaky and what is the difference and X
is basically a dynamic fun
and language on top of the lnb m and
binary content and also directly
compatible with it
so for instance you see here at the
bottom ets create my ideas table this is
an early method is called from Alexia so
you can directly call Linux can directly
call an encode from it the advantage of
a leak zero is that Berlin is quite is
famous for being hard to read in how to
write for instance you see here an
example at the bottom where you try to
replace something in a string and then
make it upper case you have to use
intermediate variable for it in Erlang
and you cannot reassign those variables
anymore so it's quite strange to write
stuff in earning and Aleks it just makes
it a very pleasant experience it is kind
of Ruby ish and it has simple Center
syntactic sugar that just nice to write
like the pipe operator it has no monent
and this is by design it tries to be a
very simple functional language and very
explicit in what it's doing and you
still have neater programming and can
write your domain-specific languages in
it you have data polymorphism module
polymorphism and it also comes with with
a very capable built tour and then so
this is Alexia which runs which
basically are a better way to write our
own programs let's say it and it's
saying like that then you have the
Phoenix framework which we heavily rely
on it's a it's a web framework with
written in elixir and it has two modules
that that we use heavily and rely on
heavily one of them is the is the pub
sub module which is usually when you
send messages in earning you always send
from one actor to another and you if you
want to do that in a publish/subscribe
manner like not sending one to one but
to many then you can just you can use
this module so this is all that it does
everything in earning is
is around the idea that it that you're
doing one thing and one thing well so
the modules are also very isolated and
following this idea then you had a
module that we're using his presence and
this one is interesting because it's an
in-memory key value store it's
eventually consistent over the cluster
and it's using see oddities conflict
conflict free data structures under the
hood and we use that for pretty much
everything that we store in there so for
the connection state for finding out
which devices are connected where and
for the backlist
and for the API configuration everything
so we don't have any state on disk
everything is in memory and everything
is eventually consistent and latency
optimized so to summarize this as such
as that in memory only this also means
that we have no external dependencies so
when you deploy Ric you can't just
deploy Ric you don't have to to deploy
Redis as well or any of the other stuff
and also if you want to scale out Ric
you just have to scale the Ric instances
you don't have to worry about scaling
the data base underneath it and I also
want to point out that I think I noticed
a Java conference but I still think that
elixir is awesome to build software in
especially I mean it's probably not for
every kind of project but for a project
like this it's just perfect we managed
to implement all the features that we
wanted to have for our 1.0 release in
less than 600 lines and single lines of
code and this is because much of the
heavy lifting is done by the underlying
virtual machine and Erlang and OTP
that's the Erlang framework and Phoenix
and all that kinds of stuff so let me
end this talk by talking about the
roadmap I was very very quick so where
we want to go from here we still don't
have a logo we have open source under
Apache to just this morning and we're
still in the process of
and production hardening I want to do
security tests on it we're also working
on a new joint session API this is the
feature I've mentioned earlier with you
can with having privileged users that
can listen to the messages of other
users we want to have an API for that
such that your micro services can
actually decide ok dis user we checked
his privileges and he's allowed to do
that one use case for this could be a
support user imagine you have a product
where you have a lot of customers that
where something goes wrong in the UI and
they call your help desks and you want
to know what they're doing wrong and
then you help desk user might just be
able to de-spawn the same UI state and
also listen to the same events so he
sees the actual keystrokes that the user
is doing this is something that's
possible with this we're going for HTTP
to support we don't have it quite yet at
the moment as I said we have service and
event and I didn't say that we have
service and events and web sockets with
a long polling fallback so these are the
transports that we've currently
implemented and at the moment we are
only supporting Kafka as the message
broker but thinking about other message
broker supporting our message brokers as
well also login mechanisms and this is
the most important part your idea if you
think that this project is interesting
and I know that loads of people I've
spoken to here at the conference have
told me that they were implementing
something similar for at least one of
their clients because this is a very
common issue and still it hasn't been so
far it hasn't there is no generic open
source open source solution that you can
just take and deploy with your micro
services and have this feature if you're
interested in it if you have ideas and
if you also if you just want to take a
look at the elixir source code and see
what it's like please just check out the
github repository as I said it's online
since today
there is also more description and
description on how to configure it and
stuff like this so having said that I
want to thank you for your attention and
we have a lots of time for questions
and also have a lot of architecture
diagrams in help endings if you're
interested thank you any questions so
the question was did you consider using
go yeah in the final in the finest list
we had go and in the Lexia essentially
because go has the has this very very
lightweight function model and a lot of
the applications that target a similar
model are written and go also like
databases and stuff like so if you look
at a pretty fancy thing like cockroach
TB and so on it's all done in go we had
a very very thin majority in the final
voting for Alexia by the way the very
first version of it was written in no
js' which naturally didn't like scale
out then they they they used the socket
IO and then they added then then we
added Redis to it but that didn't really
that really didn't work work out so well
we also had a small trial run once with
Java but not yet with an actor/model
yeah that's essentially the text story
but in the end my micro service paradigm
and especially containerization and
Tucker to the rescue I mean in the end
you will just have a docker container
and you just put it up and you don't
tell kubernetes who which essentially
won the war for who has the best
container scheduling mechanism that you
want more instances and it will connect
so that is our aim and we will tune the
application appropriately if we need to
change anything to to get that goal it's
also one thing I would like to stress if
if you consider using it you're not you
don't have to touch any Alex or Ellen
kind of stuff it's configured using
standard Jason and it just spin up as I
said a docker container and that's it
you don't even have to care and what
it's written if you just want to deploy
it yeah it is like completely neutral
and in that regard all you have to do is
you have to send Jason messages to Kafka
so essentially you send adjacent to
Kafka and within that Jason you
essentially have the outside object and
then the inside object and in the
outside object you say which customer is
it like the name like for example Kevin
or whatever your system uses as an
identifier and then the inner object
essentially is the payload like I did a
transaction I did whatever now the rig
is not concerned with what your Jason
actually says it just needs to find out
which user is it then it will look up
which user it is and it will push it out
and especially if you use server-sent
events you can subscribe with pure web
technologies no dependency to Phoenix
and liquor whatsoever it is super clean
from from the from the surface area that
you have and we also plan to in general
do extensions in a way that you don't
have to write any plug-in that you throw
into it we think that does not really
fit the modern micro service connotation
we take a little bit of inspiration
there from kubernetes in that we just
provide an API that allows you to do
something like for example this
subscription that a support user just
simply goes there you call the API and
you say subscribe me the support to
whatever Kevin is getting and then you
can essentially see what is going on we
have that stuff running but not yet with
that nice API there is also one thing
that that made it easier for us to
choose elixir of a go which was the
distribution primitives and also the the
way we envisioned Tower
it would work like we wanted to have one
tool that does one thing well and runs
all the time for instance if you have
forgot to mention derp before the one of
the problems when you have your
WebSocket connection so as the C
connections directly to your back-end
services is also how do you upgrade
those services without impacting the
user and you will upgrade those services
all the time because they contain
business logic but in this case when we
have when you have Rick holding the
connections you don't have to upgrade
Rick that much because it doesn't really
change it does one thing and it does
that all the time and there is no
business logic that you want to upgrade
why would you change it so a new
connections don't go down you don't
affect the user by upgrading your
back-end services yeah you can kind you
can kind of upgrade your back-end
without destroying the running sessions
and without caring about them so we
wanted to have software that is also
very I've mentioned the 600 single lines
of code we wanted to have software
that's that's really very stable and
small and not very complicated nothing
that could fail and if it fails we have
to supervisors so the the language and
also the runtime system gives us a lot
of primitives that are useful in that
regard for instance if you have another
node coming up it will just connect to
all the other nodes and everything will
just work out and we don't even have
implemented that ourselves it's just the
Erlang runtime that works this way when
Ericsson designed the language and the
runtime back in the in the late 80s
there it was designed for having
telephone switches and they were
designed to run 24/7 all the time and if
you have a new switch you just plugged
you just plug the cable in and it should
just work and this is exactly what we
wanted to achieve here without having to
code it ourselves because this way we
can do mistakes very lengthy answer to
answer goal versus elixir yeah other
questions no probably everyone is
already tired
are there any features that you you
would love to see in such a system or do
you think that this system isn't usable
at all everyone's asleep
who has implemented some kind of event
pushing in their applications at least
one client one of you well how did it do
it
rather than Q sayin X with Lua oh nice
one and then lower kept the connectional
oh okay aha so Lua did the JWT token
validation so a similar job like here
and then ran within and nginx as plug in
and caught it from RabbitMQ that's a
nice one I mean I I don't know how
exactly done to scale that one out but
yeah well cool important message of
course etc also in Belgium is of course
hiring and we're not only doing boring
stuff we're also doing pretty cool stuff
or at least we believe that it is cool
stuff but yeah thank you thanks very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>