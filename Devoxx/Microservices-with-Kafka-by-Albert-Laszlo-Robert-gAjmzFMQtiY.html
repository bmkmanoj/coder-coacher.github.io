<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microservices with Kafka by Albert Laszlo Robert | Coder Coacher - Coaching Coders</title><meta content="Microservices with Kafka by Albert Laszlo Robert - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Microservices with Kafka by Albert Laszlo Robert</b></h2><h5 class="post__date">2017-06-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gAjmzFMQtiY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello can you hear us yes it's okay in
the back - okay good I think we should
start because it's five o'clock hello
and the welcome I'm pleased to see that
you last this long I know it's the last
time slot and looks like the force is
with you so I'm happy and welcome to our
presentation - micro services with Kaka
I'm done is Robert and we are here to
tell you our story about this amazing
message broker it's not we will talk it
will not talk about actually some sort
of tutorial about micro services or
about Kafka but what was our decision in
choosing Kafka and also what we added to
Kafka to make it count and make it
actually useful for our use cases within
ing of course I will start with a short
intro is Robert he's a more than 10
years experience software engineer he
worked in multinational companies like
IBM ing 1 &amp;amp; 1
he likes to design complex application
but he enjoys even more to do the coding
to implement it and also he's a proud
family guy he has Trickett and very
proud of it
I'm then I'm also software enthusiastic
I like a lot traveling and my bike as
you can see also I enjoy I have two kids
and I am a proud family man what we have
in common is that we both love love Java
we both love software development and
we both love Kaka and we work for I&amp;amp;G
software development center in Romania I
don't know how many of you know Romania
the IT hub in Eastern Europe actually
not only missing Europe and we have most
of multinational big software companies
there and just to give you an idea of
how important programming and software
development is in Romania I can tell you
that with 100,000 people we are
producing like almost 5 percent of our
GDP with a population of 18 million so
just to have having an idea on the side
as compared to agriculture which is a
very popular segment in Romania with
almost 2 million people we are producing
like 4.4 out of GDP ok and that's it
about Khomeini ah when we started this
journey with a project like one year and
a half we have in mind a lot of not
fancy let's call it common sense things
for example performance or for torrents
or scalability or self-healing these
were some buzz words and like a
must-have for our application that's why
when we started it let's see the journey
we analyze different architecture
possibilities and for the purpose of
this presentation I'll give you only two
options that we had and we have yes I'm
sure you all know this character she's a
very beautiful ready for some for some
brave knights the important thing is
that she's the princess and the princess
princesses
our verily our unique actually there are
in high demand there are priceless right
and it's a one-of-a-kind and also they
are high maintenance so if we make a
short analogy the princess will be
something like a monolithic application
yes of course monolithic applications
have their own advantages I don't
believe there is a tool or architecture
that will serve or will deliver
everything so definitely we should use
proper tool proper architecture to prop
to do the proper job I think this is
bottom line so I'm not here to criticize
the monolithic color applications but
yes they have their advantages I mean
they have a you have the same stack it's
easy to work with everything is somehow
connected this of course can be also
cited a disadvantage however even though
monolithic application have these
advantages and not to mention that we
are working in a bank and as you know
banks have even ing also still have a
lot of monolithic applications I mean
they are changing but banks are not
moving that fast as big software
companies as you know and another option
is that another option that we had
actually was a this guy this guy what's
his story
besides being funny it's using me thank
you by the way and he is doing one thing
and one thing only if I recall it's
getting shrek out of his nerves also is
cheap so it doesn't need a lot of cost
to maintain it and also I can replace it
with somebody else so it's quite common
which is good which is what I want so
again if I turn to my analogy I can
compare this magnificent donkey with a
micro-service of course I'm not saying
that microservice is the best solution
out there and that yes if we have a
micro service then we are okay even
though it everybody is using these days
micro services I think they still have
their limitations and yeah
there are use kits with you wouldn't use
them but for what we had to do like
highly scalable application loose
coupling availability I mean this kind
of feature was very good so having this
donkey in place I can take an example
right since we are working in a bank
I'll take a banking example and I will
ask you to think of a solution which is
a use case let's say I want to transfer
some money from my account to Roberto
better from Roberts account to my
account it's safer then and of course in
a bank I will need some sort of
components to do that we have this
account manager component which
basically does things like I don't know
balance inquiry some validation of the
accounts and so on we have the core
banking which is like any bank you need
to have the those actual accounts are
they'll live within core banking and we
have some very transfer component for
example which in our case can have this
logic of transferring money from one one
part to another as you can see these
three are somehow connected they work
they work together and their power comes
from their number so use isolated they
don't do much but when I combine
everything then I have the real power
however there is also a yeah I wouldn't
call it down oxide it's something that
maybe some people miss when using
micro-services is communication I mean
because these guys I mean they need to
communicate doesn't matter how would
that account manager is how fast it can
cope with whatever if to perform an
operation he needs to talk with those
other two guys then of course
communication comes in two loops and it
becomes very important to have a very
very fast communication in ing we have I
know tens maybe hundreds of of
micro-services I mean worldwide as a
group but if you think this is much I
can give you some example for example
you take halo halo is a you ball like
company which offers a simple platform
where channel drivers and customers meet
and here they can talk to each other
halo uses around I can even come from
here like 450 micro services and as you
imagine they need to talk to each other
and yeah to talk to each other you have
like look like a mess what's there so
this means is they I want to highlight
the communication that we have between
micro services so it's quite quite
important also we have for example
Netflix or or Twitter which have more
than 500 micro services but if we look
our thinking how much they do
communicate to each other
well Twitter for example has like 500
milli
messages per dick while Netflix 700
billion so just two short increase while
LinkedIn 1.4 trillion which is yeah what
can I say
definitely they talk a lot and these all
these three what they have in common
it's cover so I'm sure they use Kafka
because caca has it's fully packed with
features and you can cut back and do
almost anything so I can show you a
short comparison between kappa and other
message brokers in terms of features for
example multiple protocol support as you
can see we compare Kafka we tested MQ
and RabbitMQ Kafka doesn't have support
for multiple protocols what about
support for GMS well active enqueue
RabbitMQ is they have it Kafka doesn't
again so ii read both then the part of
author authentication authorization
again it's missing transactions no
filtering no then if you can see why I
would use Kafka well I can tell you I
think it's not persistent even though it
have it it's something else which we
call we like to call performance that is
the key asset that Casca has performance
and how much performance well on the
left side you can see a use case when we
are trying to produce like 10 million
messages and of course we are trying to
produce it using Kaka active enqueue and
rabbitmq you see there that for Kafka we
have two measures so we are
but we are creating a batch of messages
of 50 messages and a batch of one why we
do this because to show you even with
one message what is the difference
between Kafka and his competitors in
terms of performance so as you can see
with one message a batch of one message
Kafka can do like Colonel 5000 there are
15,000 messages and having a batch of 1
is quite inefficient because each time
you have a new message you will send it
to the broker each time you have it so
Casca what to do is to optimize this
this prepare prepares a batch right of
messages and send it as a whole to the
server in this way with 50,000 50 with
50 messages we have like more than 450
messages sent then on the right side you
will see the same use case so 10 million
messages being consumed by these brokers
so again Kafka
I think it's quite high compared 25 22
thousand messages consumed compared with
the other brokers so definitely the key
thing that Kafka has it is performance
and that was the main reason for which
we have chosen Kafka however you saw
that okay it has performance but it
lacks features so no features okay Kafka
it's an open source solution you can get
it use it however it doesn't give you
added value because you will always have
a boss a company or whatever they I want
that that and that I want that and that
and that and whatever so you always need
to add something to it I mean it's not
just get it from the open source use it
oh yeah this is my perfect especially if
we are working
in our back so definitely we have to
work on a lot on the feature side and we
saw that this is possible that that's
the great thing about open source is
that it's open for extension so I can
extend it to the degree that I it will
be useful for my need and I will let
Robert later on I'll continue with the
use cases that we have to give you a
hint of what we actually added to cut up
to make it useful for us alright
actually what done what didn't mentioned
is that this is these comparisons from
2011 and actually in 2014 the guys from
confident guys that are developing kafka
they showed the use case where they
tuned up to more than two million
messages per second so it's quite
performed first bill we have performance
but not too many features so first of
all what were our knee in terms of
yes sorry
our laptop didn't work here so this is
another laptop sir well first of all we
we started with the use cases that we
needed to fulfill first of these use
cases was that we had to make to
communicate to micro services in
unidirectional wave meaning sending
message and receiving the messenger
force then the other use case was that
we needed also that to the communication
to be directional and of course we also
have the situation where we needed
something like fire-and-forget in
extending events and one more one or
more services could respond to that even
and what this is nice
these are some pretty simple use cases
and you may wonder okay then why we
didn't use red because for fulfilling
these requirements you could use rest
simply so let's have a simple example we
have service a which sends the message
to service B service B do does some
processing and it will save to a
database
well if we are looking at this then we
will notice quite sorry we will notice
quite soon that sorry forgot
no you will notice that sorry first of
all that this communication is
synchronous and the aleutian didn't
sorry we didn't find the cost point
Muslim oh look we have sorry so as I
thought the first problem was that we
have a process it's a synchronous
communication well this will arrive to
two issues with this first it means that
service' a now requires that service be
to be up and running so this means that
it's uptime is dependent on service B
the other issue that we see with this is
that service a cannot respond on till
after service be responsive so this
means that it's performance is dependent
on service B and this could raise some
other questions things like how often
does service B is down for maintenance
how many time is down for failures
what is its peak performance does it
actually respond or it just pretends to
response just to to be able to make the
look that it's performance is it higher
does it depends on any services on its
own which means that the coupling goes
even further than that and what we can
tell is that service like this is only
as good as its weakest service
having Kafka on the other hand or Kafka
has has the heavy topics as some of you
may know it's like a queue in GMS but
actually has hazards recarpet in please
a Kafka topic is persistent by default
meaning that a message that arrives to
Kafka is persisted almost instantly so
this means that service a has to only
make sure that his message will arrive
to Kafka and then eventually service B
will take that message and it will
process it and save it to a database so
first of all service a doesn't even have
to know that service B actually exists
and this will decouple it then the other
thing that we need to consider is
scalability well most likely when you
start to get a lot of load what is the
first thing that you do you start at
more big services well if you are using
rest this means that you have to add a
load balancer you actually have to
reconfigure your application so that
we'll be able to talk now to the load
balancer the load balancer on the other
hand needs to be able to monitor your
services and so on which could be
complicated actually if you were this
morning at just long-sought currently it
looks to be a bit more simpler if you
are using cloud native Java but usually
if you are not on on the spring side
then it's quite complicated to do it and
even with spring you still have to do
some configurations or have
and not talking about when you have
another service that you want to couple
again that needs the same message in
that case you will need to reconfigure
again so that it will send a message
also to the G service with cock on the
other hand well the traffic our topic by
default is able to to to fulfill a
request from multiple consumers you just
can plug in your consumer on a topic and
it will just consume that message
without any need of configuration from
the a services point of view yes you
have to do some configuration on the
kafka itself so that it will allow you
to communicate with to accept more
consumers but beside that from the
application point of view you have to do
nothing and in case you have you need
someone else to consume to set that same
message will you just hook it up and if
we consume without any change for
services so this means that this shows
us that actually it's a great advantage
out of using Kafka compared to rest and
even more this will allow us to do
actually another use case is to log the
messages via Kafka and then goes
and elk that elasticsearch locks - Jabar
and actually what why we need the death
was first because what we having a lot
of micro services they are logging a lot
of information on all these of course
from regulatory perspectives needs to be
stored and needs to be collected so this
means that they had a lot of
infrastructure just for monitoring these
log files individually collect them
together and then of course made them
available by elasticsearch for further
analyzes and the other cool thing that
allowed us is was the near real-time
monitoring because what which systems
know the best if one other system is
done those that are actually using it
and once you are not able to communicate
with your other system you can send some
specific error messages that could be
filtered on khakha site and instantly or
almost instantly could be visualized by
operation guys who actually can
intervene and do something with it so
this is why it was pretty important to
have log in via Kafka done okay so we
have use cases that we need to fulfill
but how actually we are doing so first
of all we started by making a producer
as you can see we try to do two we try
to do this implementation quite
minimalistic way in the sense that most
of our users wanted to just use cough
kotti don't really care what was inside
there they just had to hook now to Kafka
instead of traditional jammers that they
used before so for making this simple
for them we created the producer Factory
that will produce some producers with a
custom payload and then on that producer
the only thing that they needed was to
have a send method where you can
actually put your payload and send your
message and it's pretty simple and
should work actually it's architecture
it's a bit more in that it's a bit more
complicated but not that complicated as
you see you have the central point is
the producer Factory
which of course in the background uses
the native copper producer API and which
will create you a producer that has the
send message for custom tailors of
course you have some additional metadata
informations like how to secure your
communication with Kafka or how to tune
up your your settings for Kafka if you
need it after that we created
of course the consumer it's not enough
just to write some messages you should
be able to read it so our idea was
pretty similar with the producer part to
have it as simple as possible so we have
a consumer factory week from which we
create a consumer and that consumer you
are able to register a receiver handler
and that on your receiver handler you
can actually consume that message with
your custom payload that is actually
pretty important here you can see the
payload of the message itself is a
message with a payload this is a custom
message that we created which is pretty
similar with the message from Sprint
messages meaning that you can add some
headers and a payload it's architecture
again is very similar with the producer
it has a consumer factory with a nattie
with the native after consumer API in
the background
and from which you are creating the
consumers and you can hook your register
handler okay so this as we had those
already the producer and the consumer we
were able actually to implement the
login part which of course uses the
producer part on the left side actually
you see the most traditional logging way
from log back it's logging through with
a cough cough pen with a file appender
you are logging to a file and then on
those servers we had the so-called
locked up order which was monitoring
these files and land line by line it was
sending them to the else back when we
implemented the Kafka way was we
implemented the Kafka offender that of
course used our producer and through
this producer it sends the messages to
Kafka and from Kafka on a stock so this
is cool so we actually had one feature
implemented that we didn't have before
but still having a simple consumer and
producer it's still not enough for the
daily job and actually not fulfils yet
not fulfill more of the need that our
users have so one of the features that
we actually developed was the serialized
what actually this means was that in our
producers we embedded a way to allow to
our customers to add multiple
transformation unit multiple
serialization units in our code what the
transformation means for instance in
your messages you could insert variant
information like the timestamp when this
message was created the server from
which this message was sent
and I don't know the user ID and things
like that that you might need for your
logic the serialization part was was
allowing us to for instance to serialize
our data as a JSON or in some cases
actually we needed even more we needed
to have this data encrypted because it
it content it had some very sensitive
data and we didn't want anyone to be
able to read that information and we
could change we can change this
information so this is a feature already
that we didn't have before just by using
vanilla Kafka so this already happened
the next feature that we implemented was
the filtering actually the filtering
could be done in two ways on the
consumer part you can actually have we
actually have a filtering receiver
handler as you saw in the example with
the code there I had only a a receiver
Handler and actually we can check if
actually we want to process that
information or that message will not and
we had the other possibilities like you
are seeing here actually having another
micro service that is working as a
filter we needed this because some of
our topics that we are using in Kafka or
highly monitor eyes and they don't want
that any kind of application just
connect to them and consume messages
from there and they want to be able to
control the access to these messages so
this is why it was done like this and
actually what it does it reads the the
the message based on some meta data it
will filter it or not and if is accepted
then it's sent to another topic
another cool feature that we had was
this transformer which actually is
pretty similar with the one that I
presented a few slides ago but this
again is done at micro service level
with the same reasoning because not
everyone is allowed to use every topic
as a consumer
another feature similar to this is a
feature that we call forward and
dispatch were we actually forwarding the
message or replicated for others to be
used of course under control another
very cool feature that kafka offered us
is that as some of you may know Kafka
actually it's more hyper Bopper because
it is able to retain the messages for a
fixed period book for a given period of
time and we call this functionality
ripley actually what it does is well as
developers as you may know we are
developing also some box how many of you
are actually developing the box as well
they're just your vague developer stand
by I assume the rest of you work at
Google or another one right bull I am
also developing both from time to time
so what actually this feature does is
that allows you put a given amount of
time to actually realize that actually
you bit about and you process that
message in a wrong way
so this permits you to re-read those
messages to check if those messages were
processed correctly or not and if not
gives you the opportunity to reprocess
it again
of course for those kind of systems were
it was pretty important that your
message to be processed only once it's
not working but most of our system of
most of our requirements are not needing
it and okay so we already had some cool
features but you may ask okay but this
of course will impact your performance
indeed it print it impacts your
performance but what we did we actually
micro benchmark what we did and actually
in these numbers that you see here you
see the time from when the user had that
producer dot m and on to the point when
we are actually sending it to Kafka the
message actually we wanted to see the
overhead that we have how much impact is
it's done so based and actually the
lighter orange is for messages of 500
bytes and the darker is for messages of
1,000 bucks every saw most of our
messages are around 500 bytes and with
500 bytes we are still able to process
more than 2.7 million messages per
second with one single producing so we
were now confident that we can do quite
a good job with this and for most of our
specification this was way more than
then needed and we went even more and we
tried to see if we could turn it a bit
more and here for of course smaller
messages it these are messages of 100
bytes and with messages that small we
could we were able to actually send more
than 9 point 1 million messages per
second so for corner cases that indeed
the performance requires even more than
you have to drop off some of your
data that it's not needed but you can
tune it up and on logging part well our
logging it's a bit low compared to the
earth what I showed before it's only two
hundred and twenty four thousand
messages per second but this is because
in our case we require a lot a lot of
information these messages are mostly
around two thousand bytes and besides
that we lose almost ten microseconds
because our messages are allowed to
contain JSON messages and in case they
are Jason messages so actually we have
to check if they are JSON messages we
have to treat them a bit differently and
we do it this for each and every message
so we have there an impact but for our
systems this was enough for what they
needed so as we saw we have a very
powerful very performant Kafka but with
not too many features so what we did we
try to add some of these features on top
of it and with it we try to make front
him a Kafka plus plus that could have
almost the same performance as the plain
Kafka but with some of the features or
more of the features that we wish with
what we had in other traditional systems
that we used before and actually this is
our message that if you invest some time
you can make your Kafka to be as
feature-rich as your other systems but
having a performance way about the
others and we were so good at this and
so successful that actually talked with
actually proved to our management and
say to other countries within the group
that Kafka can be extendable and this is
actually the the challenge that we open
for you so you can extend Kafka as you
can see it's possible so you can do it
we convinced our management to go global
with Kaka so we have an ING copies
becoming the number one let's call it
event bus so the basket will change
event and we have doing development
right now of three countries they are
doing development one of them is Romania
the other which are the Netherlands and
the third one is the Germany and we are
now committed to have a single community
to have logging in place which so far I
don't know if it has been done before at
this date this integration with TL k
here k it's an epic solution and it
should be quite popular at least in ng
areas and logging in a bank it's like
something sacred so we don't mess with
logging because it's user logging
transactions so how much money move from
one account to another so you wouldn't
would want to alter rate that so it's
important and they are all done with the
car and actually we already started the
process of actually making all of our
code to be open-source your mom or a
bank and well it takes a while so this
code that you see it's still copyrighted
but maybe in some day we'll be open so
that was the reason for which we didn't
give the gate github link if you are one
so yes the message is use micro service
with Kafka and code
of the croup and I think that it thank
you very much for your time if you have
questions feel free to yeah if you have
question we still have them in it so
yeah
whoever okay Mike yes we need them by
the way because I forgot to ask you how
many of you use caffeine production not
that much
how many intends to use it doctor it's a
presentation other guru is over okay
okay good
yeah we need a motorist we don't have a
mic so yeah yeah oh I will get Justin
with the question out we got
okay
you are my services architecture
how do you do
yeah
okay so Doakes there were two questions
one is related to compatibility between
Kafka and our development right
yes our future upgrade and the second
one is how do we handle the
reconciliation in a bank
not many people if you are not working a
bank maybe you not to know exactly what
it is reconciliation it's a financial
term right that which somehow matches
our interest with our output or back
inputs and output and make sure that
they level up and I'll answer for the
first question actually our library how
we developed it is it was developed so
that we can plug in different versions
of the native Kafka library and this is
how we target to be able to migrate for
future improvement means that the code
that you are writing today will work
even if you are in currently you are
connecting to 0.9 or maybe in year 2
0.10 or even now if you are using 0.10
and your code should be compatible
because all the incompatibilities we are
trying to solve it in the background for
you but from 0 9 0 10 we didn't really
had issues only with the consuming part
but all those are solved in the
background and actually the code that
used 0 9 and now they migrated 0 10 they
don't have any change to do you do
sensor into your first question ok and
the second one a reconciliation well for
reconciliation we I mean we didn't face
so far this use case we didn't implement
it shouldn't be something that
we cannot handle it so what is the
learning folders I have shouldn't be
something that we cannot handle it the
cup guys I mean what we did was with the
idea that it needs to cop it almost any
situation that you will face
so regardless what you throw at it
should be able to handle it that's why
as you saw in the code if you looked we
give a message we don't care what it is
just give a message whatever that
message base so I can put anything there
I can do like a message we have the body
hands and headers I can do whatever I
want I can send JSON XML brought about
whatever you want I can put it there and
send it and use it of course that was a
the main reason behind it because of
course if we are talking about Bank it's
always we have challenges why that but
we want that but we have something else
and so on so on but mostly we are
standardizing what kind of messages we
are selling trying to trying to first
other question yes just shouted loud in
the background
which one why do we use cough call what
not
I'm not I'm not familiar with indicate
to you all this in ing like almost three
years ago was bought beside that
actually I don't know about not so yeah
I don't saw a comparison between it so
maybe at the next conference we will be
able to tell you
by the way how we implemented our
producer and consumer was also having
the possibility to actually change to
any other technology that we might
encounter in the future so currently
it's embedded with Kafka but actually we
already made some proof of concept that
we can actually hook in the background a
simple JMS so I suppose that in future
we might also try out not as well and
still the consumers and producers of our
clients API they will not have to change
almost anything so basically with after
you have in cough cough cough car broker
you have the performance while the
producer and consumers you have the
features these how it works so you can
extend with the broker you don't do
anything with it but with the producer
and consumer that is where the power of
feature is while the broker and the
protocol between them that is the key to
the speed yes there
hello
so somebody's fire-and-forget
license plate okay so it's fire is
capped ice fire and forget how we ensure
the delivery of the message but how what
did you mean by fire and forget from
cough carpenters
ah that we have that use case our
producer actually can send in
synchronous and asynchronous a the
synchronous way actually means from our
point of view is that we got we get an
acknowledgement from Kafka that the
message was replicated and persisted and
only after that we are considering our
message to be to be sent and
or for fortunately for this we've had
some very good improvised that actually
solve this problem basically you have a
cluster you have a cluster you can
distribute it over data center for
example I can have one node in one data
center two node in anot another data
center they are all in a virtual cluster
and this is how you solve the high
availability so if one not goes down
actually in Kafka you have a leader
which is one node which takes the lead
and here we see the let's say calls and
then if the leader goes down then there
is another broker which can take up the
leader or row so this is how by having
in different data centers also you
ensure even jewelry general redundant if
you and they are trying to have it in at
least two data centers yeah at the same
and you wouldn't and I wouldn't
recommend you to use because we have
this I mean there were people coming to
us and say I want to use Kappa in
synchronous wait no Kafka is not that I
you shouldn't do that
because to using synchronous way you
will lose a lot of time so that was the
idea I mean I will fire-and-forget I
don't agree with you and if you enough
to have a situation like that then you
probably don't need to million messages
per second so it's usually do some
typing using the bottom image that it's
very good for that
it's not ensuring you delivery
what insuring you that if the messages
were persisted on the system which Kafka
realized that if you consumed it or not
that's another question
for example the Robert mentioned earlier
the rest comparison so we the rest rest
has a big disadvantage compared to Kafka
for example which is exactly this
message persistent so with the rest I
can make a rest call and if I am in a
use case where each Resco counts so I'm
I want to make sure that the call is
somehow safe somehow right with the rest
I have no guarantee if something goes
down you know break the connection I
lost it I had to do it again with Kafka
you send it that it you make you are
sure that when that system when
targeting it up then the message will be
reversed so and even if Kafka will be
down because actually we we were able to
put it down but if it is even if it's
down when it will start up again the
mess your message was persisted and it
will be able to use it yeah was put down
by a configuration mistake not way
because cops are doing the same and it
wasn't in production but yes any other
question yeah
but in the benchmark that I showed I
mentioned we actually we didn't tested
the sending of the messages itself that
was done by the guys from conference and
they proved with three servers that they
can do more than two million messages
per second what we wanted to see by
these benchmarks was that the overhead
that we put on the native library it's
still able to deliver that many messages
so we didn't send effectively the
messages with replication and so on we
wanted to see that our library is able
to cop to cope with that many messages
I don't think there is a recipe for this
so the question was about the
replication of the message but it's not
something I think it's contextual based
so you shouldn't take if we go to
LinkedIn as then what is your
replication factor they say 1000 okay
let's use it but no it will not work it
so I think the only way to actually find
the exact number of the optimal number
for you is that you actually use it this
is how you see how it goes using new
rhetoric on the end to help refer as
well some companies may have also some
virtualization in the background which
of course has some other issues that may
arise from this others are using pure
hardware some are using two data centers
that are located far far away from each
other others they have quite close data
centers that depends from from case to
case
you okay super bonus point so - Pokemon
yes
the sounds are like
after it appeared like mostly about when
we started our development and we didn't
look back yes a different type of what
consumers actually for how we were used
we used it we had a specialized consumer
for that that was able to read process
the message again and verify if actually
we were reading from the from the
original topic and for those messages
that we found that have mistakes to say
so those were put on a separate topic
from which it was then really reprocess
so as long as you didn't put any message
on this replay topic then nothing
happened but as soon as you started to
put messages there then it started to
consume it as before and also you can
have use cases when the replay will work
differently our so that's why it may
sometimes you can put some logic on
consumer that will act with serve that
scenario while on others we will not
have thank you for your prize thank you
enjoy the drink thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>