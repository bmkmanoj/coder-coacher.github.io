<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Chaos Engineering Primer by Sergiu Bodiu | Coder Coacher - Coaching Coders</title><meta content="Chaos Engineering Primer by Sergiu Bodiu - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Chaos Engineering Primer by Sergiu Bodiu</b></h2><h5 class="post__date">2017-06-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/u1h-NKH3X0k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I would like to thank you all for coming
to my session it's really a pleasure for
me to come to the first box at base and
present from resilient to anti fragile
the Chaos engineering primer my name is
Sergio Bordeaux you can follow me on
Twitter I'm a solution architect I also
Corgan eyes the Singapore spring user
group and devil today's conference
my background is mainly in software
engineering and I don't call myself an
architect it's more like a combination
of all of the above and I'll try to
explain you know what I understand as an
architect it's more like the definition
of padua which gives a nice block
well-rounded architect so you're
experienced developer your system
focused you need to be entrepreneurial
and you need to think in technology in
terms of a strategic direction which
means you need to communicate the future
version of it pretty well and of course
you need to lead some of the changes in
your organization so I think that's my
definition of good it doesn't mean that
I'm all of the above still growing so
one of the topics which I'm very keen
interested is risk management and I
think I've seen many organizations where
they go through multiple levels and they
try to build resilient organizations and
they are asking themselves like what's
next so once you build the resilient
level well what would be the next level
how can we perfect our risk management
framework our compliance or security or
anything like it in this area so I think
if you image imagine a very stable IT
system that doesn't need any operator
and suddenly it crashes you know after
20 years of operating think of it like
COBOL mainframe nobody even knew we have
a COBOL mainframe until it crashes so
what do you do you actually have to call
a consultant who has been
in in the beaches of Panama's for the
last 20 years and you have to fly in
with a private jet or with one of the
Rockets from Ellen mask so actually you
know breaking things it's very similar
like the firefighter drills or the
military drills that we are doing so
there's no worse but you still have the
NS service for two years in Singapore
and they ship you to some of the hot
areas so at least you understand you
know what's the real world and there's a
very interesting part Thank You Virgil
is actually not the English word it was
added into the dictionary by Nassim
Taleb but more about it in the next
slide so I'd like to take you to this
scale of risk management or like a scale
of organization so there's a lot of
fragile organization that could be you
know your mum and dads shops you know
like very small businesses they're very
fragile they they go with the wave and
after the after the product think of it
like the Chinese porcelain so it's very
fragile the same is like our snowflake
service configuration resilient it's
more something like from nature from
flora so it's the bushes the trees you
chop the trees and they will outgrow
from the trunk robust is something that
would be you know for example the
diamond who is the defining material on
the mall scale of strong material
whereas auntie fragile is something that
it's more like its response to change
think of it is virgin group virgin group
is not the nail lined it's all of the
above its food its logistics its
financial industry it diversified that
so much that you cannot actually put an
identity to it so when organization
think of it like IBM IBM I think
three times over the course of the past
century from intelligent business
machine mainframe and now it's no longer
it's actually I think it was beginning
of this year when it's not longer
maintaining the mainframes it's all that
business and it's focusing on its Watson
business and professional services as I
said antifragile is not actually English
sport it was invented by this author
Nessie Nassim Nicholas Taleb who
actually brought very interesting books
about psychology about nanny-state about
politics economics he himself was a
hedge fund trader on the Wall Street so
he was looking very much at the risk
between organization what will happen in
the event of you know crashes in the in
the market political uprisings and other
it's very difficult books but it's I I
do advise you once you are interested in
the organizational aspect of information
technology you know our systems thinking
do have a read of these books Black Swan
and antifragile it's very important
because it builds on the fallacies of
distributed computing so I think every
junior programmer starts with you know
I'll just building up and we'll roll it
to production or currently as is it is
the case ship my docker container the
production or ship my laptop into the
rack I think there is a maturity level
where you know we understand that the
network is not reliable latency between
distributed systems as we go on this
micro services architecture we had hopes
the bandwidth is not infinite it's
actually now you have all these noisy
neighbors the network is not secure if
not actually need to be paranoid who is
sitting not next to your rack but who's
building is next to you if you know the
case
and I've listened recently to a FBI
podcast and they actually it said we are
that paranoid that for our super secrets
we still write them on a piece of paper
we maintain them in a safe in a vault
behind a lock behind the security zone
building and we never digitize it
administrate the transport cost is zero
the network is from a genius I'll
probably also add that our users read
the documentation as as we go with he
probably had about software is eating
the world it's true software is eating
the world but it's creating a bigger
problem actually software is not the
single point of failure if you if you
are looking at the recent news what's
happening in the industry or around the
world you know as we become more
software driven you know airplane
airplane airlines remain how that banks
cannot transact retail stores don't
accept your credit card and you know for
example a lot a lot of us probably do
shopping online and there's delivery and
credit card but you still want to have a
grocery shop next to you so in case if
something happens you can buy it is the
basics so there is this paper about the
evolution of software architecture and
in this study was you can probably see
in the lower left corner that unknown
unknown it's about ninety two percent of
all the years so this is a single point
of failure one example would be the
recent AWS where they maintain their
status page of s3
on an s3 bucket and other examples is
what I've seen in the past if you guys
remember where you would have the binary
of WinRAR or winzip in a in an archive
so as we build software and it's as we
distributed around the world and we're
actually putting it at the core we are
doing this digital transformation we
should not forget about the technical
debt or the frameworks of the platforms
that we are choosing because similarly
as how we laugh about the mainframe and
cobble developers at least those works
and you don't need to upgrade call
language every year you have this issue
in your company where there is a goal
goal and a new version and then you
start the build process around the
organization come and complexities like
in a dish addiction it comes slowly
forming weekly bonds that you barely
feel you know like you know it's not
really about like what Guillaume said
it's not really a bug it's out of scope
with it's a temporary workaround or you
know it's a little bit complex but as it
continues you know this bonds
strengthened and ultimately you end up
with systems that you cannot maintain
and that's the holy grail to provide all
the systems I'm very glad that actually
the industry or the open source
community has expanded over the past
decade so if you have the leaders I
would say one of them is Netflix and
Netflix had had its own problem so
Netflix is a streaming business yes it
used to ship DVDs by mail but then it
transformed into a streaming internet
business where you can actually watch I
think was about 4,000 devices that you
can watch instantaneously your
collection of videos and I think it's
really bad when something bad happens
because that's your usually enjoy
sitting on a couch in your evening with
your family what you need the house of
cards or some other movie which is
relaxing you know you try to
relax after hard work working on on a
Kabul mainframe or you know Java spring
choose choose your poison and what's
interesting Netflix was one of the first
adopters of Amazon Web Services and a
good part of it it's how big it became
became is actually the fact that AWS has
a dedicated cluster just to run the deal
for Netflix just think about it how many
how many how much that data they are
processing yes they're been bandwidth is
big and I believe that Netflix on its
own has a reporting system and another
big team just analyze what whatever
comes from that Hadoop cluster a good
part of it was they came up with this
new engineering concept which is chaos
engineering so they understood that
their systems are so complex and they
wanted to create a new practice around
it so it started slowly with you know
turning on and off VMs shouting them
changing firewalls rules having more
noisy neighbors all sorts of disruption
and they've actually contributed this to
the open source and say very similar to
the agile manifesto they created a web
page because this is what you do you
know in order to make it like a standard
you have two choices one you go to ISO
and spent five years regarding a
verbatim or you just create a static web
page with a fancy domain name so in this
case it's principles of chaos org and
their definition of chaos engineering
I'll read it it's a discipline of
experimenting on a distributed system in
order to build confidence in the system
capability to withstand turbulent
conditions in production well production
okay some of you will shiver like okay
why do we do anything to our production
is if not you have the famous gift which
DBAs are praying to keep the service up
but some of the outages in this region
so you have SingTel who has fine
a record six million for the Bukit
Panjang exchange fire
you have Telstra when it went down you
couldn't buy beer you couldn't take
cuber you have Amazon Web Services
outage when you know West back
Commonwealth Bank which means that they
here using a cloud right you couldn't
actually access your basics you know
like paying your bills paying your taxes
doing grocery shopping and whatnot so
it's very important actually to maintain
a reliable system how can you do that
well one of the theories is we always do
backups right so we do a disaster
recovery we have all these policies in
terms of the changes and the funny thing
is backups always work it's the restores
part that it's it's failing and there's
it's very difficult especially when you
haven't actually done it so we keep all
these backups for seven years on a tape
and nobody actually tried it to restore
it because it's it's super complex well
okay so out of Netflix ecosystem they've
actually contributed the Netflix simian
army so the simian army is a set of
tools for keeping your cloud operation
on top of your platform so it generates
all sorts of failures it detects
abnormal conditions it cleans up sweeps
up all sorts of anomalies and it's a
good thing that Netflix doesn't sell it
as a service so it's actually a very
good citizen of the open source
community first and I think the most
famous one is the chaos monkey
so chaos monkey is active during normal
work days so that's a very diff
it's in a very big difference compared
to what we currently do we do all our
changes during the weekend it's usually
outside business hours that means that
you actually if something goes bad you
get a call between 2:00 a.m. and 4:00
a.m. with someone calling you
this is escalation manager please join
our call and there's like a hundred
people there asking you to log into a
system and you're like coming out of
your bed and say okay give me half an
hour to get the VPN token to get all old
access sorted out in order to actually
get a sense of what's happening so
that's good you know we can actually
make sense of what's happening doing our
official business hours
cos manky breaks things in production
obviously this is on a maturity level
please don't install just monkey and go
and destroy some of your production VMs
or production systems they are doing
this because the engineers are selecting
a percentage of the traffic and they are
very very similar to how we do a be
testing are you familiar with a be
testing so you try to you experiment on
it and that by definition because you're
also it's a data-driven exercise you're
also building better software services
unless last but not least is you are
embracing failure so it's like a
military drill so if you have if you do
it every Monday then if it happens in
Tuesday you'll be ok you actually have
the script and we all seen you know what
happened with the ash tree disaster date
they were able to put it back up in
record time I don't think if something
like that would happen in a bank or even
in our gut in Singapore government then
that will be as fast
another interesting service which I
would like to mention it because this is
security monkey so security monkeys like
monitoring agent
that looks after your AWS and Google
cloud configuration and it's able to
monitor the insecure configuration so it
has like policies it's able you are able
to configure or customize the account
types the csps you can have your custom
auditors you can have custom alerts in
order to sweep and it also ensures that
your SSL and DRM certificates are not
expert or close to expiration it doesn't
a UI but there's also a command line for
it there's also other monkey's you know
you have like latency monkey which is
simulating a degradation in service it's
it's literally injecting delays in your
TCP connections you have janitor monkey
which is such searches for unused
resources or you know like dead zombie
gems conformity monkey so this is more
like detecting instances that are not
following best practices you know like
you have a style or a guideline and this
will inspect the ec2 instances and it
will do it in a budget manner and it
will give you an option either to shut
it down or notify the the owner and dr.
monkey like performs health checks let
me first demonstrate the chaos monkey so
I have an example here
I recorded all of this okay
chaos and the wrong one
so this is an older demo now the latest
ones are using go this is the Java demo
so it had a successful build with
brother which I don't need to go through
it now I'm actually pushing this this
application to a cloud foundry instance
which is a platform for running your
applications takes a while but basically
it creates after you give it the
binaries it figures out the dependencies
build the container and runs it inside
the process run the process inside a
container and it gives you a URL which
is internet accessible so it does the
routing and the network it's able to
update the routes and DNS
okay
there's a couple of things that is
happening so in the section below the
the lower down there is a post to create
a chaos in this section in the second
section middle there is I'm watching for
the events were happening on the AWS
infrastructure and in the first one I'm
listing all the activities okay you can
see that the post was sent you can see
the event that is saying that there is a
termination termination event and then
the instance is shutting down so I think
of it like you know a trigger button
please shut down my easy to instance and
this is you can have various
configuration in terms of which
instances you want to shut down how you
daggit you know in terms of how you
schedule it and all of the above okay
but the good part is there's a code by
Ken back which says you know it's very
similar to test coverage the fact that
you have 100% test coverage it's like
reading a newspaper you know you read
the whole newspaper but some articles
are more important than the others here
I think if we're looking at the tools we
need to understand the principle behind
it you know why do we do what we do so I
don't want you after this session just
to go and create a java application
pointed to a REST API and just start
shutting down the instances because what
is the goal what are we actually trying
to do what are the principles about it
because immediately someone will take
you please create a JIRA ticket to
install chaos monkey please shut down
this or like create a report off of out
of it and Alex Corvis key point is tempt
which is called get your education and
it's it's an interesting concept where
you know think of it like what we
currently do a lot of our meetings are
basically where we humans meet with a
tool to update the tool that will update
another human so and those port flows
are very interesting because you must
change the status to reviewed not closed
I need to change the status to closed or
I booked a meeting room for our two
hours scrum I think you know ultimately
you know the tools are important but the
conversation and the information that is
being exchanged is far more far more
important so as I said neck netflix
created the principles of chaos actually
I think all the sinus or the authors
were Netflix employees which is
interesting part
so the principle of scare was four of
them so you build the hypothesis around
the steady-state behavior and you vary
the real-world event then you run
experiments in production and then you
start automating those experiments in
production organizations such as Amazon
Google Microsoft and Facebook we're
applying similar techniques is they
never contributed it to open-source can
back is very famous about his a blog
about reversibility where you know they
were trying to tame the complexity and
complexity by inheritance you are
actually not able to to define it you
control it throw at it hundreds of
architects and they will come up with
fancy diagrams but ultimately you know
it will not be able to simplify it so
what you want in order to keep your
velocity is you want to make sure that
if you make a change you're able and if
that changes horrendous you're able to
reverse that change instantly so even if
you have a thousand breaking changes
that only take a thousand seconds you
know that that should be fine
because you know your customers are not
upset because they're happening in
various systems and you're able to
restart or roll it back instantly so
let's talk about the first principle I
would call it pseudo watch so it's about
building a pollicis so you start with
what is considered a good norm of your
system and you monitor the metrics that
are visible not in the principles they
say character is characterized ations
because they don't like the metrics
metrics is just like CPU utilization but
here it's more how many requests per
seconds how many active sessions how
many concurrent users so you need to
capture interaction between your users
and the system and it's very interesting
because utilization is a symmetric is
virtually useless you know we do have
hundreds of dashboards in our operations
back end where a monitoring the CPU and
memory but we are not able to correlate
yes when there is a you know red amber
green when when when a system changes
you know for 80% yes that means that
will have an impact the users but is it
really true
you know if our customers are calling
and complaining that actually a workflow
takes ages you can see the decision are
actually all green you know there's no
problems in our system so we need to
track other characteristics of the
systems not just utilization very event
or I call it pseudo halt you can start
with terminating virtual machines when
you're scaling up and down you can start
injecting you know to to your internet
explorer users or to your Firefox users
some sort of latency you can fail
request between services you can fail in
internal micro service like your
reporting or your feedback you can even
make an entire region unavailable just
to underlies what's happening with the
system so these experiments are very
important because you know we do have
environments in our IT systems that do
the performance testing that do the
system integration testing that do the
security acceptance testing that do the
penetration testing but end-to-end
testing is very expensive and it's a
very slow process and there's always a
configuration drift between what we have
now and what we actually what's
happening in the production and it's
mainly because you know we're not able
to replicate the whole environment that
we have you know down to DNS to
certificates to key stores or to
expiration you know on very exploration
on certificates and it's usually like a
very simple use case like there is a
paper that did a study that 92% of
catastrophic events which are not
including floods it's simple miss
configuration which you could probably
stop by just having a fail check you
know like for example as tree the havoc
that it caused it was someone on the CLI
who mixed the argument anak which is a
simple command so if that sort of
missile miss configuration creates a
havoc you're a you should have a checker
maker process in terms of who runs
scripts and how how the arguments are
passed and the other part is that your
customers are not behaving like jmeter
scripts obviously like they they don't
flood the gate in a thousand active
users they build up some of them have
sessions of 30 seconds some of the
sessions 4 5 half an hour they also use
it on mobile on DSL or on fiber so I
think you know being able to test it in
production you will come up with results
that will not be theoretical you know in
our performance environment and you need
to automate all of these experiments
because if not how are you going to
observe trends so once you start
capturing these metrics and
characterization you need to see what's
happening with the time so it's no
longer
we're just promoting our release the
production because the test or our
regression test is green we're able to
observe for a week or a day that the new
release is actually improving the
response rate or the peak of the users
were able to add 10% more rather than
it's worse because if it's worse we can
roll it back and that's very important
because we need to look at the system as
a black box and really observe the
events and interactions from a user
perspective
so here isn't short like principle of
chaos you know build hypothesis around
the steady state behavior the way I
would describe this principle as a quick
read of there's a chaos engineering
white paper done in 2016 is
intentionally break break things compare
the measured with expected impact and
correct any problems uncovered this way
over time you realize that there's a
common themes and the lying and you
could build automation tools you could
give dashboards it's not just simply
break things you need to understand like
what is the why is the reason we want
optimize you know the traffic for our
Chinese users or for Indonesia you know
in different countries because as we
build systems they no longer are tied to
a data center or to AWS region they move
around the geography yes there's the
data governance issues but ultimately
it's very hard to judge about the system
that is geographically distributed with
various versions so I'll give you an
example so I work for pivotal and this
is a reference architecture for a cloud
native platform so you have five domain
infrastructure Operations deployment
runtime data and security and obviously
you have these characteristics which is
a reference of what you have to have in
terms of modules or components in your
systems that will look after for example
your secret management or certificate
management Identity and Access
Management or CI orchestration and many
more there's a white paper which is
called the upside down economics of
building your own platform and the
implementation of this reference is
pivotal call foundry now I'll not go
into the details of how and why to know
Cassandra you can ask the pivotal at the
pivotal booth they're experts but as you
can see from this diagram it's a very
complex system
it's powered by 26
forty VMs across different regions you
can scale it to a hundred and in
production is actually very very massive
once you you want to scale it you know
if when when you hit a peak of adoption
where you have multiple line of
businesses that are adopting it so very
similar you have what you called chaos
lemur
so curious lemur is the same as chaos
monkey but with the other concept of PCs
which is pivotal Cassandra
so chaos monkey me show you the demo
okay let me mirror my displaces very
hard too
so Chios lemur is also job application
and what's going to happen is because
the platform itself is a set of 40 VMs
what you do is you first do a list of
all the available instances on Amazon
like a dry run so in this case you have
my sequel instance we've just changed
the flag from dry run to from false to
true so these were the selected VMs now
I'll actually go and kill the VMS so you
have dedicated node some of them like
the gear yourself this is a component
inside pivotal co-founder which is your
container which is running your
containers okay so we start seeing
failures which is which is expected and
that's very interesting because cloud
foundry has the inbuilt mechanism where
there's a monitoring script or the
health manager which is watching after
its instances and it's able to restart
these instances automatically so there's
you don't need to receive a call or
email to go and hit restart button and
it's able to restart them from a last
good known state I'll just show you
quickly that
so after about 5-10 minutes of the demos
you will actually have the boss director
which will inspect the infrastructure
and most gunnen fix it and this is the
AWS dashboard where you can actually see
that the instances were killed and how
they are restarted a more interesting
example is locust so locust as I
mentioned like a lot of the issues
inherited about distributed systems they
don't showcase unless you have high
traffic where you have multiple users
you know accessing or there is a
baseline where everything seems normal
up until you actually start having you
know multiple geo locations multiple
line of businesses using a certain
application and usually it's very good
to actually performance test and there's
two options there's many more you have
locust you have cuddling both of them
are open-source i will showcase the demo
of locust which is sort of creating
sessions for the users and then sending
traffic as you would have like a
thousand concurrent users with with
delays in their requests and different
session time so locust can will define
your behavior code so rather than like a
record and play you actually just set it
up like you know this is my my delay and
i would like to have a random factor
between that the the wait time is 1
second to 5 seconds so there's all this
randomness that you can inject into the
into the script and ultimately you can
have increased load over a period so you
can have example scenarios that actually
replicate the examples in how we use so
you know if you're familiar with your
online banking you know it's 9:00 a.m.
to 11 that you actually go and check the
page for the balances nobody checks the
balances that in the evening or midnight
so there's different buttons depending
on the system that you build so for
example you bir will have a different
graphic than than someone in the retail
so give you example of locusts so you
have you know a simple test again this
is an application that is being deployed
on claw foundry now if you do have
questions please raise your hand and we
can make it more interactive because I'm
about the end of this presentation and
I'd like to know if you are more
interested into the practice lessons
learn or you want to see more demos who
wants to see more demos who wants to
talk about more theory and practice
lesson to learn okay half half okay I'll
show one more demo so here we are
ramping up the users we create demand
and we try to simulate someone logging
in and just hitting a request to a to
let's say to an API be it a shopping
cart or see the catalog and then logs
out
so as we create the demand there will be
you know you it's very good if you have
in your platform elasticity because you
don't want to react on this based on
your dashboard and oh okay it's 9:00
a.m. let's ramp up our VMs oh it's done
I am let's scale it down or it's or 6:00
p.m. let's let's close it down you
actually would like to automate a lot of
it and it's great because you now have
tools like cloud watch you have all
sorts of auditors and inspectors which
are giving you ways for you to trigger
it in the Cloud Foundry concept you have
an auto scalar which is able to inspect
the traffic and depending on the not
just membrane CPU we've we've added a
couple of more features in a recent
recent release a
based on the delay in the response to
the user so if you see a degradation in
the response for the users you can
actually tell that please increase by
10% or 20% the number of instances that
we have in production and similarly you
want to do it the other way so when you
see over when you see system that are
idle you want to reduce the number of
instances so that you can save on the
bills so I think all of this is very
important because it's allowing you to
see characteristics of the system and
more importantly you know you can build
this lessons learned so you want to have
a systematic approach to your chaos
testing you know we want to test our
identification or want to test our
reporting this engine or we want to test
our fraud detection engine and this is
very hard if you are debugging the
system in the middle of the night it's
much much easier and more elaborate if
you are just failing like 0.01 percent
of your traffic and you're able to take
a dump and analyze the the system's
characteristics both from a user
perspective and then from what's the
reality in your data center and by the
way don't wait too long to start the
load testing in one one important
lessons is as you scale you actually
find that maybe your system diagram is
not performing well so there's a bug in
your architecture or some of the tooling
that you are using it's not able to
scale so you need to go back to point
zero where you choose different than the
solutions or you need to begin from
scratch so I think it's a good exercise
after you finalize your MVP and as you
build your systems and you're able to
how make predictions about the number of
users that you actually load that the
system
homes changing the architecture as I
said this last minute is extremely
dangerous and you need to join a
community because as much as we probably
have different domains the technology
that we are building the elastic
platforms you know the way we
orchestrate the software-defined data
center the way we build the frameworks
for our web applications and middleware
are the same there's a lot of lessons
learned that we can share with the
community in terms of the protocols in
terms of the tooling in terms of the
experience user experience because
there's a lot of than there features
where it's very simple to use or it's
easy when they are showing you let's say
a popping balloon exercises it's much
more harder when you have real
transactions when it's your bank account
or when you are doing foreign exchange
you know yeah cross-border transactions
and more importantly don't trust the
claims that the systems make or what's
written on a wiki or how the UML diagram
or what was the latest whiteboard but
really look at the data that you can
capture from the from the system
what what's inside and from a user
perspective like you know how many users
are we able to serve with the latest
release so for example I'll show you a
combination where you have a circuit
breaker you have spring cloud services
and you have what you call now chaos
lorries so here what we do is we have a
circuit breaker dashboard a circuit
breaker dashboard if you know família
is very much like the surge in your
house so when there is a surge you know
the the switch will flip so you'll not
fry your electronics so here when a
system is failing you do not need does
that internal system you basically have
a fallback mechanism
so here what we can do is you know we
maintain a load on the system so we have
the circuit breaker we have the response
time and then we have the locks so we
create application in the chaos Loris
which is a tool you know to creating
havoc on in organization so you are
creating here a schedule think of it
like you know every 15 minutes we want
every 15 seconds we want our system to
suffer a mishap so we create this
schedule and we basically create so we
created the application we created the
schedule now we bind them together so
the application targeted is is being
attacked by these cells okay so the
chaos are starting to happen
and you you are able to see a real
system and the traffic and the load
where the instances are going up and
down the services in this application is
very simple it's a it's a micro service
architecture but there's a client and a
service so you we might kill the service
whom I killed the UI and we are just
want to verify in terms of how many what
the characteristics of our service how
many requests can itself you know on the
heavy load so here you have the circuit
breaker
so imagine it's something like we're
doing an upgrade to a system so we're
taking like one of the data centers or
one of the availability zone is down and
where we want to simulate the traffic
that the application is using the
service and the service is being scaled
up and down and at the same time we have
events that are terminating the
application that are restarting that are
injecting failures so for us is very
good to understand okay what would be
the priority one to fix like what kind
of fallback will give us the the best
characteristics so in this case imagine
we could read from a property file we
could read from a cache which read from
a secondary database you could read from
the slave so as we start wandering on
when this experiments were able to
prioritize in terms of where should we
investigate the time where we should
actually spend engineering in order to
raise the availability of our selves
like what would be the best case for the
for the capital that we spend in order
to rate the availability from four nine
to five nine
okay that's about all I think I have a
couple of more slides you know culture
bits principles its tools you know the
old saying says culture eats business
for breakfast as we experiment with
these health issues or like when we are
housing a terminating VM instances we
want to have a process that ok the
incident happened we want to see the
impact of that event and we want to
create a post mortem which is a Kaizen
principle where you know we want to
extract lessons
so yes it was a unfortunate event what
could we do next to prevent it like do
we need to change the process do we need
to look at the tooling so in a way you
know long not only focus on the tools
and the principles behind it but you
also want to create an organization that
it's a continuous learning organization
so that means yes you know today's best
practices is going to be in five years
legacy right now what was the state of
the art architecture five years ten
years ago service-oriented architecture
now everyone is moving away so you want
to continuously learn and I think the
post-mortems is a way for you to clean
your process and don't don't follow just
the hardware we've been doing this just
because for the past five years everyone
was doing that you're trying to
experiment and look at the tools in your
context this is like this is a
whiteboard that I usually create where
you know you start with an exploration
phase planning iteration customer
approval and you want to break your long
releases into smaller releases and in
this case I'm really talking about
releasing into production not the way we
break the software release cycle we do
to experience a tree we experience a
weekly spin but we still release into
production every three months so we want
to have this feedback cycle where we go
you know from unit testing which is in
seconds to per program in minutes where
we do our daily standup so we can
collect the feedback from the team where
we do acceptance testing let's say every
user or every Friday and then we will
look at the results every week so we do
a planning session on Monday and then we
look at the release on Friday or we look
at the the newest feature released on
Friday so there is multiple practices
and I think as
you mature as an organization you'll
adopt different principles different
tools you'll change methods because as
you scale your organization the methods
will no longer apply
further reading there's a great number
of info cue articles I do advise the
city of engineering I do of advisor to
see the latest video recordings by Casey
Rosenthal about chaos engineering and
intuition engineering or by Josh Evans
who goes by the handle ops engineering
about chaos in a microservice
architecture as Netflix so he is sharing
the lessons learned of what for the past
four years how they change the way they
build the micro services and how the
platform underneath and how their
operations run book changed thank you
I'm open to any questions sorry let me
take raise your hand and you'll be given
a microphone
it this is more technical I guess so you
started talking about jmeter and move
the different tools so you don't suggest
a meter are those doesn't matter how you
use it
so as you adopt experiment new tooling
you need to understand why we do what we
do you know so for example why do we
have Jenkins pipeline to build Jenkins
job so I and I've seen it in the
industry we have a Jenkins job that is
configured to generate other Jenkins job
that are configuring to do build jobs
and ultimately in all of these processes
we are inherently adding layers and
wrapping in processes something that
should be very simple you know I the
customer want this feature in order to
sell more products or break revenue so I
think for us it's very much you know
what should you do as a priority is it
should you look at the Jenkins should
you look chaos monkey or you should
actually look at the way you know the
latency of the users and then adopt
something like distributed tracing where
you're able to patch together different
requests across your data center and see
it takes five seconds it takes one
second for our users you know to use
service a versus service B so in this
example we should probably not spend
that much time on back-end services but
really on the front end services because
that's where we can decrease the pay the
latency so I think ultimately beginning
with the Y rather than the what and how
is more important
so another example is like you know
cloud native applications you know you
have the 12 factor the way you build
applications in order to have a no
operations platform or the way anyone
who is doing continuous integration
you know it's able to look at pipelines
as the at the building block in your
system rather than configuration and
jobs and triggers so you know inherently
I think every organization is maturing
it will want to see a pipeline you know
from development production without
looking at various steps that take the
build the cucumber test or the metrics
or others you know I think that is a
more interesting output this similar is
the cloud adoption I think as Paul
Moritz is saying cloud is not about
where you run your workloads it's more
about how you run it so elasticity is
important security able to test new
services and new geographies it's more
important than where thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>