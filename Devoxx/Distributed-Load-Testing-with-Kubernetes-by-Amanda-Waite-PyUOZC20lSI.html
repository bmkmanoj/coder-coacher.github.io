<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Distributed Load Testing with Kubernetes by Amanda Waite | Coder Coacher - Coaching Coders</title><meta content="Distributed Load Testing with Kubernetes by Amanda Waite - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Distributed Load Testing with Kubernetes by Amanda Waite</b></h2><h5 class="post__date">2015-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PyUOZC20lSI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone hey can you all hear me
at the back and whenever I don't ask
that people can't hear me in the back so
I always checked Hey
welcome thank you for coming today
thanks for being a DevOps and thanks for
coming to this talk there are some
really really great talks happening at
the moment as well I kind of wish I
could go and see them
it's rather than listening to me so I'm
really appreciate appreciate you
deciding to come to this talk as opposed
to seeing somebody else so we're gonna
be talking about distributed load
testing with kubernetes and they ask you
some questions but I can't see many of
you so we're gonna start off with a
quick introduction to Cuba natives but
we're gonna look at it in the context of
performing distributed load testing
we're also going to explore some
features of the newly announced
kubernetes 1.1 and maybe look towards
the future as well a little bit and I'm
Mandy Waite I am a developer advocates I
work with the product seems building up
their products and making them suitable
and useful to developers because mostly
I live in a silo they don't kind of
really get what's going on with
developers say we need to come out talk
to developers find out what did do them
find out what they want to do and get
their feedback and push that back into
the product team so we can build bit of
products you can get me on plus many
ways on Google+ or at-te KGW our tech
girl on twitter my twitter handle
everything is on every single slide so
if you feel the need to tweet any
questions please feel free to do so and
kubernetes how many of you have heard of
cuban aces or familiar with it okay
quite a few of you and probably about
half and half so we're going to go a
little bit light on the details the
kubernetes here but I'm going to show it
in action as well through demos demos
that are completely new so they may not
work you never know which will be fun
you can now for me then and kublai sees
various different things about how it's
where the word came from and how its
said if you are interested in learning
how to say kubernetes then I will be
outside lace and I'll give you some
lessons and most people struggle with it
so but it's a Greek word and what it
does really is
it runs and manages containers
containers which were all using them how
many of you are using containers today
not as many as I thought
Wow okay well you should do I know we
have a slide saying containers are
awesome let's use lots of them and
that's where we're going with it
containers have really really useful
people will find much utility from them
eventually everything will run in the
container and at some point we're going
to want to be able to run those
containers somewhere and also manage
them and orchestrate them together to
form applications and micro services
that cool thing so Cooper Nations is
that actually inspired by something we
call at google borg borg is our internal
cluster scheduler we've not been able to
talk about it until recently but now we
publish the white paper on how we built
it and borg has been going on for 12 13
years or so and it's been built layer
upon layer and there's things we would
do differently we could go back in time
and the kubernetes takes that learning
and builds a new cluster scheduler new
container scheduler that can be used
externally we schedule about two billion
containers per week very lightweight
containers more like processes than
anything so it kind of number makes
sense in that context but we want
everybody to be able to do the same and
have the same kind of model even if it's
just from two or three nodes up so
clusters of thousands of nodes and so
Cooper Nations is inspired and informed
by everything that we've learned over
the last 12 or 13 years kubernetes
you'll find out more about what it does
if you don't know what it does currently
as we go through the talk then today it
supports multiple cloud environments and
also bare metal environments as well so
you can run this on your own premise
machines you can run it on your laptop
you can run it in the cloud and it also
supports multiple container runtimes for
some value of multiple because they're
not that many container formats around
currently as the container initiative
the open container initiative kicks in
hopefully we'll get to a stage where we
have a standardised
lower level container format and then we
may see a plethora of container one
times but they would all run ultimately
on Cuba natives that's the hope and
expectation Koopman exceeds 100 cent
open source and it's written in go
like many large-scale applications
nowadays and the whole theme that the
force behind it is to manage
applications and not have to worry about
managing the structural machines
although for DevOps people cooperate is
also is very very useful as well it
takes somebody nightmare out of managing
configuration so we don't talk about
load testing and we're also going to
talk about accumulators so we going to
combine the two and this is a completely
new talk it's got some of my slides from
my old effects but it's a completely new
talk 56 minutes left my card I can't
talk 456 please right so this is a
typical load testing setup at least when
you get outside of using a be on the
command line now how many of you do load
testing the baby on the command line
okay less reviewed and he does look
Michael so yeah so if you use a B on the
command line in this scenario may not be
similar to you although you may have
scripted this you may have scripts in
many many different stations of a be run
on what all machines but ultimately
you're probably gonna do this at a large
scale and larger scale I've ever done it
was for one direction day back in 2013
what we had to look at testing up to
twenty to thirty thousand QPS on App
Engine and for that I used a meter so
this would have been a very similar
setup we would have had master control
in everything and we would have working
modes that were actually generating the
load and pushing them out to the system
under test the sucked and as they used
to call it so very very very very well
loss of work we're very very normal
environment to see for load testing
variations on a theme
we may have workers and also master
nodes that are implemented as physical
machines physical bare metal ship
service as virtual machines either
on-premise or in the cloud or maybe even
modeled as containers and containers
when we look at cube natives start to
become more like logical hosts as
opposed to physical hosts that we used
to have and that's one of the key points
points we're going to make today when it
comes to talking about human ages
and this is a typical kubernetes
architecture used to have animations and
looks less scary but it's not that scary
really this is kind of similar to what
we have with Borg internally we have the
idea of a master and the master is in
touch with a bunch of nodes plus the
nodes we talked about cluster nodes in
much more detail shortly
and we have various services that make
kubernetes happen things like the
scheduler and replication controller
very very importantly the API server
which we're going to make use of today
and also this little thing called the
couplet that runs on each of the nodes
and is responsible for really helping
that node be part of the cluster and the
scheduler is one of the key things we're
also going to cover in this talk as well
you also have an internal container
registry as well so you could use hub
docker calm but we also have our own
container registry for Google version of
curators which we talk about later so
that's one there because that's an
option but it's not necessarily going to
be the Google one it could be talking up
so a quick guide to cluster node so I
want to kind of put this in the context
of what we're going to talk about next
is you need to know some of this stuff
up front and it cluster node looks
something like this it's behind me
address alone node has the notion of
resources in terms of CPU and memory ok
that's extremely important and again
it's very important for us internally we
like our engineers to be able to specify
how much RAM or how much CPU or and how
much CPU a particular job that they want
to run a containerized job on our
infrastructure so we're doing the same
here with kubernetes
and so resources are effectively caused
and CPUs today they may ultimately sense
or other things like this and network
i/o other things that are likely to be
used up as we increase in scale also
nodes have optionally labels which
identify something special about them
and that could be as in this case that
this machine has SSD disks ok I see
interesting to us because we may have
something that requires the performance
of an SSD disks that we want to run in
which case knowing where those machines
are is important
so we can actually select mode based on
their label it also be something like
type equals GPU like we have a CP GPU in
the machine again which is very
important for specific apps also we have
the notion of this physical disks or at
least network attached this look like
physical disks that are attached to the
machines we have one or more of those
that's actually load and that's
important and we're going to come back
to this soon so what is this okay so
we've been struggling for a while to
explain in pods and actually giving it
away so this is what a collection of
wales is called it's a pot a pot of
whales
I don't why because there is nothing to
less pot legs in a whale as far as I can
see so why does it's called a pod maybe
there's some etymological reason that
because somebody can explain to me at
some point but basically we have pods of
whales I mean as you can see these
whales are not the same
these will may always are all different
and likewise we have the notion of pods
in kubernetes
which is why I introduced them with that
lovely picture of whales and because
often when we speak about containers we
talk about them in the context of whales
and if you know you probably know what
I'm talking about right the gate docker
I'm not wearing my daughter t-shirt so
we often talk about them in the context
or else so calling a collection or
containers a grouping of containers but
not the same a pod makes a huge amount
of sense to some people anyway
and ultimately we're not using
kubernetes or schedule containers were
using it for schedule pods which are
effectively groups which could be a
group of one and it could be a group of
two could be group of others but we're
scheduling a group of containers along
with also potentially volumes as well
volume is that are even virtual or maps
or other other components and Meraz and
the port effectively represents an
application specifically logical host so
it's like taking the machine all the
things you would run a machine seeing it
up into containers and in bundle it
together in something called a pod and
when your kubernetes
so the pods we run the containers we run
with inside the pod generally makes
sense to run together and it doesn't
really make sense of run them
individually they live and die together
they also have
the ability to talk to each other on
localhost they share the namespace
support namespace IPC namespace each pod
has its own IP address which isn't acid
we can allow pods to talk to each other
directly one to each other you've run a
node or across nodes and these things
are ultimately designed to be ephemeral
as well so they will come and go as we
please we can make them fairly stable
very stay warm facts but the idea is
they shouldn't really maintain the state
and they can be easily replaced with
something that's absolutely identical
and also we've kind of touched some this
already that pods had their own IP
address well they do and that's made
possible through various different
mechanisms depending on where you deploy
cube later soon if you're using core OS
for example you'd probably use flannel
or maybe an Amazon flannel is also weave
and open V switch which overlay networks
which give you the ability to assign a
pod an IP address which means it has its
own port namespace as well so there's no
brokering of ports on Google compute
engine and container engine we get that
naturally from our infrastructure we get
that ability with no extra costs we
don't have to do any configuration but
these are ultimately fundamental
requirements of pods we have to be able
to talk to each other directly no proof
of brokering the port numbers and no
nothing so what does our load testing
look like now once we get to kubernetes
involved something like this so we have
a master a load test master pod and we
have a bunch of worker pods so very much
similar to what we had before but now
we've kind of abstracted it out onto
kubernetes slurp slurp so let's quickly
talk about groupings as well because we
need to know these things to understand
what we're looking at when we get to the
demo otherwise lemo will make add so you
know since just like he doesn't to me in
a moment even though he does so labels
labels are the single grouping mechanism
within kubernetes currently and properly
for ever
you never know things might change but
hopefully forever
and basically we can assign labels to
the objects within kubernetes and we
have first-class objects and we have sub
objects as well and generally - the
first art class objects things like pods
we can assign labels in this example we
have a couple of pods that do something
we don't know what it is and they have a
label called type equals Fe so a label
is a key value pair and it has no
semantic meanings the Cuban aid says
there are some system labels but really
this has no semantic meaning to
communities but it probably does to you
he probably means something to you so
when you say try people with their feet
you know this is a front-end pod and we
can effectively select on those pots
using the API you say to the API hey ABI
give me all of the labels all of the
pods of label type equals fa and it will
get invited and it you can build your
own tooling around that or you can build
own dashboards that kind of thing the
dashboards at all they can build any
kind of tool that consumes the API and
select some labels and in this case we
have a pod with two labels so pods can
have multiple labels everything can have
multiple labels and here we have another
dashboard a second one that is only
interested in pods pods we version
equals v2 so that's how labels work and
that's how we group things together and
it's a very important semantic construct
within kinases and ultimately last thing
we need to kind of understand before we
get to talking about the load testing in
more detail is a service the concept of
a service so having all these pods
running is one thing and we may have
several pods that are identical or do
the identical function running across
our cluster and they may be the kind of
pods we want to route traffic to and
maybe we want the load balancer to get
across them in that case we can use a
service and a service does perform or
can perform other functions other than
just load balancing across a group of
pods but we're not going to get into
that today with you just confuse things
so here we have a bunch of pods with a
container age for the single container
and each of a label type equals Fe so
these are front-end pods are designed to
serve traffic to somebody and we create
a service and we say service you only
care about pod
with label typing with Fe and so these
become the constituency of the service
and also when we create a service we get
a stable virtual IP address while it
doesn't change it may be ephemeral they
may be as assigned from a pool but it
will be stable and also will be it will
have a DNS entry as well so this is
discoverable as well so effectively what
happens here incoming traffic from a
client and the client could be some
other pod running within kubernetes
something else want to move include
places or it could be exposed and routed
externally and that could be done by you
with setting up routing tables and such
like to point to your service or it
could be done by your cloud provider as
in the case of Google
well we for container engine we expose
the VIP as a load balance port
forwarding rule and so traffic comes in
goes that hits the VIP the service wall
in randomly move traffic between the
pods we have session if you see in terms
of client IP but most people know how I
feel about state stateful pods and
happen to maintain state across multiple
interactions is not a really good model
or a good person so that's our service
works so we've looked at labels and
services and pods we're also gonna talk
about replication controls in me but
they're kind of like on the side so our
kublai load testing service now looks
something like this where we have a
service plugged in which is exposing our
master pod to the rest of the world in
this case externally as we need to be
active accessing externally and the load
master load test master pod talking to
the workers or the workers talking to
the master
okay last thing is a replication
controller and this is effectively the
thing that we kind of built queue basis
around this idea of desired States we
created template the crating pots and
within that containers within the pod
and was there volumes and environment
variable with some secrets and other
things that we can put into our system
and we told a replication to go off and
manage 2 or 3 or 10 or 100 of these
things that were created from the
template and it will select based on a
layer
in this case role equals worker so we
turn the replication controller you need
this template to create these worker
pods we want two of them any given time
do it
so the replication controller wakes up
it looks for pods with that label role
equals worker if that air it pulls min
and they become its constituency if they
don't exist misses her I know how to
create them I'll just send a signal to
my API and say create them for me and
the API will go off and create them for
you and at that point we have supports
and at some point a pod may break for
some reason for some for some idea of
breaking in how useful you miss
aliveness it could be many different
ways I don't have a slide for today's I
think it'd be useful but you can make a
pod be live different ways and you can
monitor aliveness in different ways and
when the pod becomes an alive then the
replication controllers job is to create
a new one to replace it so we can
maintain the fact that we always have to
so the replication controller becomes a
control loop it's continuously
monitoring to make sure we have the
desired States we have two of these
running if we don't have to run in it
will create one or remove one and it
knows that occurring because of the
template and here's another example this
one has type equals master also rolek
was merciless and it seems that life on
the slides and this one manages just one
pod this being a master probably makes
sense in this case and you all see this
pattern quite frequently well we have
one master pod managed by replication
controller just to make it highly
available okay so we've got passed all
of the accumulated key concepts so let's
talk about no we haven't
nearly this one this slide this is one
I've been distracted as I said my
photographs taken
so cube Nations load testing service now
looks like this one of my labels is out
of sync you should be animated so we
have a replication controller looking
after a master pod he called cares about
two labels what role equals masculine
name equals Locust from a look at that
shortly and the other replication solar
has been asked for managed for these
pods with name Luke was like locust
I haven't shown all of the labels on
there but basically we have two
replication controllers so now that is
our desired state that will be
maintained for us by both of those
replication controllers so let's talk
about deployment so to get clue blazes
up and running is fairly straightforward
it's dependent on where you're trying to
deploy it and maybe whose workshop
you're in did you go to see a Kelsie
Hightower workshop you'll build it from
scratch and it's fantastic it's really
informative and it shows you exactly how
kilesas works and those videos are
online as well you can look at them and
it's very very useful but it's also
fairly straightforward to launch
kubernetes so crate and kubernetes
cluster and get it up and running using
scripts for various different providers
and really what you have to do is choose
your platform with which to see AWS is
your Rackspace on Prem laptop whatever
and ultimately choose an OS again
they'll mail it mileage may vary
depending on which provider you use
because GCE for example we'll choose one
for you it's probably customizable but
you got to be careful you really want a
hardened docker runtime to be able to
run this and so you choose an OS could
be core OS atomic Red Hat Enterprise the
next song atomic Red Hat Enterprise as
accommodation via Debian CentOS have
been - and then you're going to run a
script probably coop up for SH and you
may change some configuration parameters
before that but ultimately that script
will run it will do various things with
scripts and depending where you're using
it it could be sort of slack and
ultimately you'll end up with a cluster
configured I'm ready to go the
individual steps are to provision of
machines so boot all the virtual
machines install and run your cube
components configure your networking you
may have to install final to make this
work all the rightly ranges for pods and
all the services in Sdn then start all
those ancillary services that make up
kubernetes the things that Kelsey walks
through installing them and getting up
and running and ultimately you had to
continually maintain that maintain your
cluster
doing upgrades and OS updates and such
like so that's not easy or the fun part
depend on who you are because I always
find this less fun right so I like doing
it although whenever you hit problems
was a bit of a nightmare so this is
where something like Google container
engine or other providers who provide
product ready solutions of accumulators
really come into play because they take
care of all that for you and basically
to deploy a container cluster on Google
cloud platform just press one button and
we're going to talk about visualizing
kubernetes shortly we're going to talk
about it will show it and this is the
way it works we basically are able to
proxy our API we have to authenticate
once you've authenticated we can proxy
JPI and do everything locally and that's
what we'll be doing today with this demo
clicker whatever so how many you
familiar with locust load testing tool
one of you now you're all familiar with
locust and next time they ask you be I
don't put your hands up so I did say
that in the blurb for the salk I was
going to talk about Jamie's friend
Gatlin so I've been working with jmeter
because I like Jamie tonight I've been
using it for a long time but I did have
some issues with demoing it not
necessarily getting it up and running
but actually showing it in a useful way
so some of you take me somewhere
understand where I'm coming from there
but it's a little bit more complicated
and I would like and I think it might be
hard to demonstrate very well so I'm
going to go a little bit simpler using
locust and also Gatling is not really
designed for distributed load testing
although probably somebody in the
audience would correct me at some point
and they have some way of doing it this
is written in Python sorry about that
but it's pretty good Python it's fairly
easy to understand and pass and fairly
easy to customize because it is open
source so you can change this thing to
do whatever you want to and it's also
very easy to get started with which is
one of the reasons why it's so
attractive for a demo because the
problems you have with demos go up
exponentially compared to the complexity
of it
as my raw so the deployment steps for
locust
the first moon we have to do is build a
locust image of docker image and push it
to a repository we have the image
actually stored in our container
repository within Google cloud platform
and we're going to pull it down from
there rather than from doctor hub we've
already built it I'm not going to build
it because again it's one of those
things that if you have a happy wife I
can actually you have a sewing machine
various other things come into play it
could take five to ten minutes to build
an image and I don't be standing here
waiting it to finish trying to fill in
time is I just a tap dance and that
would be funny so no you're laughing now
for me right so after we pushed the
image to the repository we need to
deploy our worker replication controller
actually got it in the wrong order it
should be we deploy our master
replication controller but our workers
like having a master to talk to so we
deployed a master of applications all
right then we deploy to work a
replication controller then we deployed
a service that we short saw in the
diagram previously I mean when we create
a firewall and some of those things are
already being done for us like the
firewall itself and in this case we're
going to be deploying it on Google cloud
platform on Google compute engine not on
container engine please by using one
point one of two places and container
engine doesn't currently support one
point one but it will surely I think
that shortly must be some value of
shortly so we created the firewall we've
got image available we really have to
create the replication controllers and
the service also one thing we talked
about earlier about
lookups the service discovery and DNS
it's very easy for the workers to
discover the master and connect to the
master because they can just look it up
in DNS so once we created the service we
can connect to the service buyer its
Danis name and the second part is I
which I'm going to demonstrate shortly
is there so here we can see we have
locus master and its value which is
local okay
Martha that's an environment variable
and the scripts that we use to start
locust both the master and the worker
can say - - master host equals dollar
locus master and pulled out from the
environment and that's how that works so
that's how we why things together for
environment variables and so this is
where the fun begins
this is Ludovic sample my he's still
reading way besides he's doing a talk on
Friday when I pinched him by the way
it's gonna be good I may join him to
that I'm supposed to be joining him
right okay so the first thing we're
gonna do is make sure we have such
pseudo for everybody I'm gonna move it
don't move it up there I always had this
problem and why I sleep quiet so we run
coop CTL version and coop CTL is our
command line tool for kubernetes and it
does everything and yep so good to CTL
version major one minor one plus this is
one point one because what we need to be
what we're going to do the first thing
we're going to do is deploy deploy our
locust master and we're going to do this
from a configuration file which I'll
show you shortly
and is located in the directory and here
we have a nifty little visualization
that we're going to use to visualize the
whole thing and I'll make this bigger
for now I may have to resize it a little
bit
there are visualizer is proxying the API
he's talking to the API locally on my
local machine and saying give me all the
pods get me all the services at the
moment is doing in a tight loop and it's
not very efficient and it means that I
can't drag things around this is Jay's
plan by the way it means I can't do
useful stuff because it gets refreshed
alone we're working on that I'm fixing
it so basically we have a pod locus
master
named Lakers master roll master which is
the labels and also we have a
replication controller you can see it's
select so at the bottom which is the
labels on the pod and we can also see
number is one we want one of these pods
it also has a template which you can use
to create new pots if anything horrible
happens for the one that's running so no
I'll come back to in a second next thing
to do is create the service so we want a
service and that's the service up in
green and here we go and we can see the
selector a selection on the same values
as the replication controller it doesn't
have to they could be completely
independent of each other in this case
they have the same labels and you also
see an IP address which is a I P address
for internal purposes so we can access
this service on tendril 0.1 21.18 from
moving the cluster very very shortly
this is happening the background Google
compute engine is setting up a
forwarding rule that will expose our
port externally so we'll go back to that
in a second but it takes a few minutes
to set up the plumbing now I've always
kind of never really questioned why that
is why does it take so long perhaps I
should do and then we're going to deploy
the workers the work of controller okay
and now it's gonna reconfigure itself a
little bit not got this let's just look
at the workers for now and so the worker
here as oh that's the yeah so the
workers only got one pot as well
currently we're going to scale that
shortly but it has a selector in the
replication controller O'Neill says one
pod so we have two pods this one here
and this one here and we have one
service and to replication controllers
and I'll make that fit alright okay
the next thing to do is go back to our
IP address for our service which has now
appeared open it in a new tab and we can
go to locus and we have one slave ready
this is Locust this is this use of
interface it's very basic but it does
the job so we have one slave reading
that cell worker will scale that laser
and see that change so what we can do we
have a very simple application when on
App Engine it has two end points one is
metrics slash metrics and the other one
is slash login and basically we're kind
of emulating a very very simple IOT set
up where metrics are being pumped out by
devices maybe sensor devices somewhere
being hitting the metrics endpoint
constantly every now and again they had
to real authentic eight and revalidate
and they'll hit the login and that
should happen very straightforwardly so
we're going to say we want to emulate
100 and the reason I'll come for low
values is because I want to show scaling
happen without having to get too much
individualization if we had a hundred
pods running it'd be very very hard to
visualize so we could do this at scale
much larger scaled and we if we wanted
to but for now we're going to keep it
low so start swarming and after a few
seconds it will start hitting the
endpoints as you can see it doesn't do a
huge amount those response times are
very very low and we don't get any
failures I've not seen many failures
except when I was pumping away on the
wrong the wrong endpoint which is the
one that came with the original demo and
I was hitching it around 2000 QPS I
think I must have got banned from
hitting their application so here we see
everything that's happening and that's
good we have distributed yes we only
have one worker currently and that's
doing all the work so we want to better
scale down and so what we're going to do
here is go back to our slides and see if
I'm jumping ahead of myself
so the scaling example and I'm not going
to do this bit specifically I'm just
going to walk through the slides because
I want to actually jump to auto-scaling
then show that instead so here's a
scaling example we have one pod
replication controller name book was
located locus in these cases lucaswnash
worker enrolled equals worker one pod
and so we have our pod and you can see
we have one slave and then we change
that to two sort of replication
controllers to change it to two and it
will sell the API to create another pod
for us now we have two pods and two
slaves so lastly we got the four and
again that's reflected in the user
interface where we have four and this is
from the tests I did earlier when I was
just going to do scaling manual scaling
before I decided to get all fancy and do
automatic scaling so that's how we scale
and let's talk about scheduling and how
this works and how we can prioritize
things on kubernetes and get the best
results and the best utilization out of
the resources that we have available to
us because we have lots and lots of
machines but we don't want them to be
sitting around idle we only want to
invest in machines that we can use if we
had to invest in maybe a headroom of
fifty percent that would be huge for us
that would be massive it'll cost us a
fortune
and even those smaller scales ten
hundred machines that's still
significant so you want to be able to
maximize the utilization of all of your
resources your compute resources you
know you know CPU and your memory and so
for this we use something internally
called resource based scheduling and
other things as well but also kubernetes
uses resource based scheduling as well
and that's fairly new and failing nation
is coming along quite quickly and it's
going to get really interesting very
soon so basically a resource based
scheduling will provide quality of
service for scheduled pods or allow us
to provide quality of service quality of
service been meaning guaranteed amounts
of CPU memory that they can have
because we want some things to run a
higher priority than others we may
actually say I don't care so much about
this this pot I don't care if you want
it just want it when you can and if this
is a dynamic cluster where we have pods
being scheduled and unscheduled quite
dynamically for out today
then that's quite likely that we have
some smaller lower priority pods that
will be kicked off the Machine and puts
back into pending while other things you
use the resources and then schedule back
home again when those resources become
available again and so we have the
ability to specify for each container
CPU and memory requirements and also we
can specify a request this is how much
CPU memory we think we're going to need
and also a limit this is the maximum
we're going to allow this pod so we're
kind of making a guess that maybe
hopefully an informed guess and we'll
talk about that another talk one day how
we actually get one of these numbers
we're going to say this is what we think
it's going to use and some of the CPU a
memory
I initially the limit that ever can have
it can never go above this okay and
what's going to happen in future
releases will have free classes of
quality of service mine is going to be
best effort and in that case we're going
to say request equals zero I'm not
requesting the resources for this so
just want it when you can listen is best
effort effectively this will only run
when there are resources available not
being contended by anybody else so these
will run eventually but only when some
something cut something else comes off
of the cluster the next one is burst of
all where we have a request and we have
the limit and the request basically says
this is what I expected to use but it is
allowed to use up to here and it can
peak if it needs to and that's what we
call burst or there'll be the second
tier of a second class of QoS QoS the
last one is guaranteed now this is the
highest priority jobs where we say the
request equals the limit what we're
requesting is the maximum you should
allow it but the same time it's not
system actually saying we want you to
give it all that resource up to the
limit straightaway so this is likely
where you should stop but we want
to run and guaranteed to be guaranteed
to run so this is the next highest what
the highest quality of service and pods
that are running that guaranteed should
never be preempted again and so we get
some more finer granularity of our own
priorities maybe that's not the case but
they may be contended with other things
that also have guaranteed but ultimately
this kind of best effort scheduling
improved our utilization by about 20% so
now we can actually say best effort we
don't care what he's run or burst of all
we can have this if it needs it but if
it's not available and have it these
things are really high priority won't
normally Nautilus home ok so that's how
we get our efficiency some ways and in
terms of declaration decorates declaring
accelerating declaring this we do this
within a configuration file I'll show
you the configuration file shortly let's
open up the yeah we don't know actually
so these are the configuration files
this is the locus master controller some
of the things on the slides there I'm
not going to go into too much detail on
these this is the worker this is the
gamma file and we don't expect you to
write you a more ultimately you'll have
other systems maybe CI systems that
create this disk configuration for you
dynamically and push it out straight to
the Kuban inches or maybe you'll even
have a pass that abstracts all this
stuff away something like open shift or
maybe a Google App Engine in the future
and they will abstract some of this
detail away but for now you create
configuration files and also the service
as well has something interesting that
wanted to show you which is type equals
low bouncer
where is it yeah so down here so having
this line type equals load balancer in
my service configuration file means I
want you to create if possible if the
infrastructure supports it an external
load bar at some point okay so that's
how what the configuration files look
like so here we have the worker
controller and we specify a request for
300 memory 300 mil easy P use and limit
of 300 baby bites and friend of many
CPUs for delimit as well so sir a
guaranteed one this is we want this one
to be guaranteed to run so all so let's
visit revisit cluster nodes before we
get to a test game in which is the most
important part of the talk grant so
Justin as you visited we looked at these
already how do we find the nodes we want
to run this stuff on this is extremely
important and we're going to dive into
this in the demo we need to ask
questions when we get a request the
scheduler pod what resources does it
need so how much memory and how much CPU
is it requesting or what is its limits
does it need a specific disk in which
case we need to even mount that disk or
schedule on machine that has that disk
already mounted
what node can it run on does it require
a specific node by name
again this is very snowflake a this is
not the best situation it means you know
there's something about this machine
it's special you want to run your pods
on it or some pots on it and it could be
the issue the only machine that has
photos through gigabytes of RAM and you
have a pod that means 28 gigabytes of
RAM to run so you can only run it on
that node you could do this through
labels though as well and also what
nodes can't run on labels does it need
SSD this is in the GP or some other
special characteristic of that node so
I've touched the first thing the
scheduler does it tries to work out what
what nodes can possibly run this pod and
then we're going to rank those nodes
individually to find out which one we
should ultimately schedule on and we had
different policies many different
policies and they may have changed in
one point one slightly when I first
wrote this slide it was the default was
a to balance CPU and memory out so we
tried to make sure the CPU memory were
the same - rather than consume normal
memory
running out of memory we would try to
make the sure they were balanced but we
can also preferred no that will have the
most free resources left after the pod
has been deployed or we can prefer nodes
if they specified label or we can also
try to make it such that the we minimize
the number of pods that are running on
an individual node for each service so
we have a service that has ten pods we
have ten nodes we won't run all ten of
them on one node making it officially
dangerous
you don't know goes away so do different
policies we have and you can even write
your own policies for this but it's
called a machine control so let's
explore super your memory load balancing
more bonusing machines in my opinion
have shapes a firm bare metal and
workloads have shaped see which is
interesting so in a container cluster
effectively these virtual machines which
will eventually go away I'm looking
forward to the day when the virtual
machine goes away at the moment it's
just really effectively a resource
boundary it has a certain amount CPU it
has a certain amount of memory you can't
really run different bigger on it than
that memory or that CPU although we can
overcome it quite dramatically even
maybe we want to
about today but generally the machine is
really just become a resource boundary
and so these are typical machine shapes
what we have four cores eight gigs of
RAM eight gigs - cause they gives one
core the workload sheets are a little
more arbitrary one gigabyte at one core
free point five gigabytes one core but
they have shapes and ultimately we can
play Tetris system and Kelsey Keitel has
done this already
like you didn't same day I did it as
well container camp so complain computer
sector is like this and it's just crappy
animations I'm afraid I should build a
game to make it work but basically we
have a job soon half gigabytes one call
and now what we see with that job is we
have the CPU is fully utilized but we
have five point five gigabytes of RAM
that's inaccessible we can't use that
and so basically we've stranded that
resource that five point five gigs
around is completely inaccessible to us
and that's a problem what we could do is
we could take a different machine and we
have a scheduler that sensible about
this it can say I'm your scheduler on
this machine which has to cause making
some RAM and so now we see we have
resources both CPU and memory available
and we can therefore on a different job
on it so now we have all of our cpu from
these fires and most of our memory fully
utilized and actually efficient bin
packing and that's one of the principles
we use in certainly Google so efficient
session is ultimately the keys to
contain the management so let's talk
about also scaling and how this works so
we'll start off we go back to this
shortly but let's show you some real
time the first thing I need to do is
create a configuration for my autoscaler
and go back to action I can buy my own
file here and this is still in beta so
this may change at some point but we can
specify the minimum number of replicas
and I'm a maximum number of replicas and
also a target CPU percentage now this is
taken across all of the containers in
the pod and an averaged out across all
of the pods okay
and so we effectively take the
utilization that we want the amount
we've used
and then divide them together and get a
number which ultimately will give us the
number of replicas that we should have I
said does this cut the calculation
dynamically every 30 seconds or so and
let's deploy that so we have one
actually deployed so we're going to
deploy this this is an object by the way
it has a kind which means it's an API
object that we can deploy and so we're
going to do ok so now we have HPA as we
call it so fortunately they've shortened
it it's easier to say or easier for
right we can get the HPA which is oh
that's interesting
I'm going to 70 percent utilization
already okay that's kind of worrying
this is why you should never do demos of
also scaling I did want to Google i/o
last year and it was really dangerous
but something interesting may happen now
and we should probably go and see that
but we can actually watch that as well
so we can actually wait for changes
using the API constantly polling the API
to see what's happening
well we actually get a stream of data
back and listen for that but let's do
one of our thing first let's look at our
individual notes and we have two nodes
in this cluster no we don't we have
three nodes
oh no I've got some rescale my cluster
well nevermind okay so we can actually
look at each one of those
and this will give us a summary of the
pods that are running on that node and
also what the available CPU and requests
are for us we can actually use and get
access to so we have a bunch of pods one
- we've already scaled our nodes already
our pods already a worker pods we also
have a bunch of system pods as well so
there's many pods that would have been
scheduled things like fluently the DNS
service all of these things are
scheduled as pods as well within Cuba
niches and so we can do this for each of
the pots but let's get back and revisit
our beers and see what's happened okay
so now we have four workers so it's also
massively scaled already so it saw that
there was one hundred and seventy
percent CPU utilization which I got some
it has taken me completely by surprise
because we're only one one hundred users
and they shouldn't have done that but
these things are always strangely
satiric so let's go back to our locust
interface and again this can be a little
bit quirky as well because he says for
this thing picks up the changement we
now also scale to four pod some workers
so I'm now going to bump this up to I'm
gonna bump it up to 500 and see what
happens and again this may break
horribly because I've never was this
particular configuration memory I've
never gone up to 500 users so we'll do
that now and we'll go back to the slide
and leave that to cook for a little
while
we kind of just break this down here and
present from the slides here no we do it
properly so basically this is our maybe
potentially our original configuration
where we have a replication controller
that has two pots to maintain and the
two points are there they have the
labels which the replication controller
is selecting on then we have this thing
called heap stir that uses an internal
service called C advisor and is able to
monitor of running containers within the
pots and get statistics from them in
this case at some point heaps that says
oh he's got 40% CPU and 70 billion CPU
averaged across them that's over 50%
which is our scaling target so now what
we want to do is better scale down so we
changed on the replication controller
number pods before that was done by our
calculation and ultimately the
replication controller will now create
the other pots and now we've also scaled
that's exactly how it works
that process is continuously ongoing
from the scalar and go back to hey
where's mine no he hasn't Scout again
yet maybe bump it up even higher and we
didn't know about HPA and watch it so
it's potentially at 41% again we don't
see everything that's happening I'd like
to be at the degrees calculation in
right live in real-time at the moment I
can't be sure that is 41% but we still
ramping up in a moment so let's go back
to the science
so also the rub the auto-scaling was
introduced in 1.1 as a basic feature so
it's available today if you build your
own kinases not available from every
provider but it will be fairly soon and
also with Google compute engine and also
Google container engine you can also
scale automatically your nodes number of
nodes you have and this is done through
compute engine manage instance groups
I'm not going to demo it because it's
gonna be hard to actually overload my
system but at some point if we scaled
that up more and more we'd have so many
pods we could no longer schedule them
those are asking for specific resources
and so we wouldn't be able to schedule
every one of them and some of them would
sit in pending at that point we could
scale out our cluster we could do it
manually by going into the cluster and
resizing it or we could ultimately hook
up the autoscaler which is already
available in Google compute engine and
also scale it dynamically and for that
we have this metric called cube target
node utilization which is a custom
metric delivered through our cloud
monitoring service and ultimately that
would scale all of the nodes for us and
the final thing was to go back to see
where we are so now we see we have lots
of pods but we don't have them all
scheduled the yellow ones are ones that
are unable to be scheduled currently
they are impending that are waiting for
resources to be made available to
actually we had to schedule them and
what we could do here is go into our
cluster this is compute engine this is a
Google developers console the new beta
version of it and we can select
computing June which already done select
instance groups these things run in a
thing called an instance group and
currently we have free instances in that
group and what I'm going to do is edit
it and bump it up to five and see if we
can get them all scheduled that will
take a little bit of time and we'll go
back to the viz see what's going on with
it we have quite a few pods will I know
more than I expected
it tends to slow down the user interface
as well so okay that's good last slides
so who places the state is currently
it's in 1.1 and that's since this week
it was announced that coupon in San
Francisco this week a Google container
engine which is effectively hosted
kubernetes we don't have high
availability with new places currently
but by looking after your master for you
taken out of your hands and taking out
your control we can effectively make
sure it's always up and running so we
take the master we push it to one side
you no longer have any visibility on it
and we make sure it's continuously
working container engine went GA in
August 2015 but there's plenty of other
options running kubernetes and so
platform is the service offerings Red
Hat and we shift Deus Stressless chorus
electronic Moranis Murano Red Hat atomic
missile some missiles sphere they also
have it as well so check out kubernetes
container engine again we've already
talked about this manages kubernetes
uptime the resources for this session
which you'll get the slides for which
you just follow we have a solution
that's based on this talk or my talks
basing the solution notionally and also
we have a github repository with
everything in it everything you need and
we go back to our jccc of our nodes are
up from running they are from running
but they won't be all ready yet so we'll
start scheduling some of those pods soon
alright anyway so we wait for that to
happen while there are some questions
and i'll just go back to the last slide
which is this one and yeah chelation is
open-source
i everybody's contributing sir
kubernetes it's really really got a big
buzz to it going new places to i/o is
the documentation and everything you
need to know about kubernetes it can be
found there go to github.com slash
kubernetes long ago change this now
because it is available from that path
but it's also available in this part
github.com slash cumulative cumulative
on slack we have a slack channel hash
queue abrasive users and on twitter a
cuban Asia's i/o and that's the talk and
I'll take questions now if you have any
wrote a microphones they have
microphones ok so any questions
I can't see anybody no no questions
well ok I have to please write their
questions is there a process for doing
questions no okay all right thank you
thank you for taking your time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>