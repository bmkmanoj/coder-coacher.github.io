<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Resilient Java based microservices with Kubernetes by Mete Atamel | Coder Coacher - Coaching Coders</title><meta content="Resilient Java based microservices with Kubernetes by Mete Atamel - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Resilient Java based microservices with Kubernetes by Mete Atamel</b></h2><h5 class="post__date">2017-08-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zkih72_nmto" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone my name is my channel and
today I will talk about Brazilian
microservices with guarantees first of
all thanks for being here this early if
you're careful enough you realize that I
cheated a little bit I changed the title
because I used to be table if you look
at the agenda says resilient Taiwanese
my services but then I realize that when
I was putting the presentation together
all the sudden I'm talking about if it
applies to any kind of micro service so
it doesn't have to be Japanese when you
are working with your entities you are
working with containers any containers
as long as you have it in a container it
doesn't matter what it is so that's why
I changed it a little bit because I'm
going to talk about micro services in
general and actually the Microsoft's
that I'm going to show you it's based on
your net core which is very interesting
so let's get started first there will be
information about myself I'm a developer
advocate for Google I'm based in London
my name is ethanol and this is like my
email and my blog so if you have any
questions about any of this and I say
today okay to reach out to me I'm also
going to publish this rights at my
Twitter account so if you want to get
this like just follow me and so the
agenda today is first if I said what
about containers and communities I want
to do an introduction I want
applications and what was wrong with
them I'm going to talk about breaking
more into micro services and how that
helped and then we're gonna get into
containers because my the services they
are not the solution by themselves the
containers help in that space what they
are and what containers themselves
they're not the solution you still need
to manage them so that's why we have
these activities so I'll talk about what
is given it is others it out and then
finally we'll get into the building
blocks of you thank you so labels as a
work there I'll see how much I can
but if I can cover everything you're
gonna have my sights and I'm gonna be
here for the rest of the day as well so
here in questions can get to me alright
so let's start talking about tomorrow so
what is tomorrow depending on who you
talk to you get different answers to
this question but in my mind this is
analogous simplified definition of what
a moment application looks like so you
have a bunch of modules they have some
kind dependencies but these dependencies
like they call each other directly so
they're not conjugate they depend on
each other directly
they are probably sharing a common state
so it can be an advantage or it can be a
bigger and more similar days or days or
something like that they are all sharing
that and then the worst thing is that
these modules even though they are
separate all this time and effort to
write great separate modules or when we
deploy them we on the level together
and deploy them all at once so an app
server on Webster or something like that
so in the Java world you can think of
more just as the web applications they
are con them into war files and then you
put together these more files into
what's called a Angel Eyes application
which is an ear file so you bundle
everything in the file and then you
deploy that ear file to your app server
all at once now obviously this has lots
of problems and these are some of the
problems first of all you have the
unnecessary coupling among modules you
can since you are bundling everything
together you can update the whole thing
or you don't update anything at all and
this is a little that because if you
have things work on your home one of the
modules and then you have anything work
on the Alamo jewel you need to kind of
wait for each other and integrate and
create this single bundle everything
it's hard to scale independent parts so
let's say your content module this is
scale much more than the
because defendant has been and the
Hasselblad it's time to do that when
everything's bundled together it's very
hard to establish ownership so I work
with places where everything on the
module that's great if you have the
ownership of the module but then who
owns the whole thing all the information
what happens is that you know things
they may make some households that in
the end nominals it and then you have
people doing in shadow banking scale and
then it's also it can be hard to debug
and test this all moment application and
the reason is that you know again each
module can be easy to debug and run
Windows laptop when you bundle
everything together it becomes a little
big and then becomes really hard to run
back up and actually work with a place
once where we just couldn't run the
whole application on a laptop so there
was no way so we realized the world
applications the demon quake so we
started in the last three years making
more with into my criticism so every
context you go to you here so that's
what I'm going to talk about to so what
is microservice again depending on who
you talk to you get different
definitions and my definition is that
first and micro service has to be small
it has to do one thing and I think it's
not realistic that because one thing
does like a number of things but if
scope is a little small so this number
one and then it has to be maintainable
by a small amount thing so I do like
four or five people she's able to
maintain and run attacks on their own
continue and look small it has its own
datastore this
really important because no matter how
you break your application if they
depend on the same back and in the end
it doesn't matter
yes don't ever coupled so they each
might a service they have to have their
own data store and they have to define
what define public API so so each micro
service they define a public API but
other sources can call so in this case
for example we can have three micro
services they each do one or a few
things really well they each and their
own data store they each define their
own public API and these like what
services they still call each other you
know because they need each other and
this what our application is and that's
okay because they're calling each other
to public me yes they are not
commutative directly so when this
dependency is through public API it
makes the dependency the micro service
is much more efficient and much more
exclusive this way you know what the
dependencies are and then if you need to
change something within the micro
service you can do that change the
public API if you need to change it up
again yeah okay version so you can have
version one and then you can integrate
in any version 10 higher version 2 and
version 1 and then your application
becomes this logical thing so these
micro services they're independent
they're deployed independently they're
they're run independently maybe they're
on the same machine maybe they're on
different machines by your application
but they are not deployed they are not
bundled together and deployed as a unit
so your application is this some of
these micro services it's a logical
thing that it's not one package like an
ear file all right now my services they
help with some other problems that we
talked about with monoliths you know we
can scale things independently we can
update things into them independently
teams can iterate at their own pace
stuff like that but now you have a new
set of problems first instead of
worrying about one big thing now you
need to worry about 50 small things and
that can be challenging
debugging and testing can still be
challenging because you know debugging a
single micro service is probably easy
but then usually when a request comes in
from a client it goes through a micro
service one and then it goes through
another micro service and another micro
service so and these micro services they
can be on same machine they can run
different machines if you don't have
proper logging and instrumentation then
it becomes really difficult to trace
where the request is going and where
things are failing so you need to make
sure that you have proper logging proper
instrumentation things like that so that
you can track when a request comes in
you usually use like a request ID when
the request comes in and then you
propagate that ID through different
micro services so that's how you can
keep track so we have this infamous
problem in software engineering called
it works on my machine you know so you
run a service on your machine it works
great then you deploy it to production
it doesn't work and you don't know why
actually you know why the environment on
your laptop is different than their
moment in the production no matter how
hard you try you know it's gonna be a
slightly different and then sometimes
this can cause problems so my services
they don't help with this you still have
this problem and then most importantly
all the common problems about running
services in production they still apply
so if you want redundant services you
need to have multiple copies or your
micro service if you want resilience you
need to watch for my services and and if
your micro service dies you need to
start a new micro service no one is
gonna do that for you you have to do
that yourself if you need to upgrade
your code you need to do that in a
consistent way if during the upgrade
something goes wrong you need to
downgrade so you need to do that in a
consistent way if you need to scale up a
micro service you need to plan and do
that if you need to scale down because
the load went away you need to you need
to do that so all these problems they
still apply so even though we took our
mice or monolith broke it into my own
services we still have all these
problems that we need to deal with so
that's when containers and kubernetes
comes in but before I show that I want
to start with a demo I want to create a
simple micro service it's gonna be very
simple and then we're gonna use this mic
was later to continue eyes it and to run
it on kubernetes I was gonna do this
life but then yesterday I realized that
the Wi-Fi is not that great I'm not sure
with this today I haven't tried so what
I did is I went back to my hotel and I
actually created videos or these demos
to make sure because I really want to
show you this stuff so I created a video
and that's what I'm going to show today
so I apologize that it's not live but
it's almost as good as my hope so what
I'm gonna do here is I have this video
and let me just stop this for a second
I'm gonna use Google cloud and Google
cloud has something called cloud shell
it's basically a linux shell running in
the cloud and then the good thing about
this is that you can run it from the
browser so from the browser you have
access to a linux shell and I'm just
gonna use that and what I'm gonna do is
for fun is I'm gonna create a net core
application any developers here I mean I
know this is a Java conference yeah
there's one guy good the reason why I
want to do that core is because first of
all it's still mind-boggling for me that
you can run that on Linux now like we
are living in crazy world now and you
can actually run that on linux and i'm
going to show you that the second thing
is i want to show you that cuban it is
basically cares about a container it
doesn't really care whether you're
running java or whether you're running
net or python whatever so i just want to
point that out by running a dotnet core
application so let's do that let me make
this fullscreen so what i'm doing here
is i'm creating I'm starting the cloud
shell so this is a linux shell running
in the cloud I can access it from my
browser and this shell has tools you
have your home space in this shell and
then you also have all the tools
installed by default one of those tools
is called net the net is a command-line
tool that you can use to create net
applications on Linux and you can also
use net to to run your application so
what i'm doing here is first i'm
creating a folder from application we'll
call it like hello world asp.net core
and then we'll go a little CD into that
folder and and then we're gonna create a
skeleton that application so we're gonna
say dotnet new - t web
this will create a web application a
hello web application in this folder so
if you look at it we already have all
these files already created for us what
I'm going to do is I'm going to edit the
program that j/s so this is like the
main entry point to my application it
creates a pipeline for my for my service
what I'm going to do is I'm gonna make
sure that my pipeline starts on port
8080 so I'm just going to add use URLs
HTTP and then star 8080 so this will
make sure that my application when it
sets up the pipeline it listens on port
8080 and then we're gonna do net restore
so my app has some dependencies and it
will basically by doing net restore
you're getting the dependencies from
nougat nougat is the package manager of
the dotnet world it's kind of like maven
so this will go and look at all my
dependencies in my project that JSON and
then it will download all the
dependencies so once these are
downloaded I can do or not run and run
my application here in this Linux box
and we'll take a look afterwards so
you'll do that run so this will compile
and run and then once it's running we'll
just use the web preview or Google cloud
to actually hear what's running on this
Linux box in the browser so we are doing
that right now
so this is the app it's very simple it's
like an asp.net MVC app with some
default screens and that's it this is
the micro service so we're gonna use
this later to actually continue is it
and then to make it run on Kuban it is
okay so let me just go back to my
presentation
all right so let's talk about containers
now what is a container again again
depending on who you talk to you get
different definitions to this question
but for me a container is a lightweight
way of virtualizing applications okay at
this point you might be wondering we
already have a way to virtualize
operating system we have we have virtual
machines right so we can use that to
build our applications on top so why do
we have containers I think the key here
is that it's lightweight so these are
Linux processes it started with Linux
but Microsoft also made Windows
containers that now so you can have
Windows based processes as well so these
are lightweight they're very easy to
start they are sealed and isolated so
when you have two containers running
they don't interfere with each other
because they use what's called
namespaces so they don't even though
they are running on the same kernel they
don't actually interfere with each other
they're really easy to deploy so it
takes seconds to deploy a container
rather than minutes or hours with a
virtual machine
they are introspect able meaning you can
get in to the container look at what
it's running you can look at the logs
stuff like that and for me the most
important part is their composable so
what you can do is you can have images
that's kind of like the definition of
your container and once you have an
image you can build another image on top
of that image so this way you can layer
your dependencies on top of each other
and this is really powerful because if
you can basically layer all your
dependencies on top of each other and
build your own image and you want to
have the exact same environment on your
machine and also in in production and
I'm going to show all of this later in
my demos docker is one of the main
container platforms but it's not the
only one there's also another one called
rocket from Korres that does pretty much
the same thing and there will probably
be more when it comes to container
platforms now if you still have the
question of why containers I think this
will clarify that so what we used to
have is shared machines before right so
we used to have a single physical
machine with the operating system kernel
and then on top of that we
the libraries and then on top of that we
had our applications running the problem
with this model was that there was no
isolation whatsoever so all the apps
used the same kernel all the apps users
we used this common set of libraries so
if if anything changed in in in the
downstream in the kernel or the
libraries it could potentially break
your applications now you know at some
point we decided that this is not good
enough so we created what's called
virtual machines the idea of virtual
machines is that on the same physical
box you can run multiple operating
systems virtually so you can have each
each each of your apps they can have
their own kernel they can have their own
libraries this is good because now your
apps are isolated and and they are not
sharing the kernel they are not sharing
the libraries but the problem here is
that instead of worrying about one
kernel and once our libraries now we are
worrying about multiple corners multiple
libraries so it becomes really expensive
and if inefficient it becomes really
hard to manage this now with containers
what you have is a common kernel so they
run on the same kernel but instead of
having virtual machines with their own
kernel so you have apps and libraries in
a container so the good thing about this
model is that you still have isolation
so the apps even though they are sharing
the kernel they don't step on each other
because they are using different
namespaces and they are not sharing
their libraries each library it belongs
to the container and within the app so
you get the benefits of the isolation
but they are not as heavy as virtual
machines so you don't have to maintain
multiple copies of operating systems
they're much more lightweight these
containers compared to virtual machines
so that's why we have containers and
that's why they became really popular in
the last few years and containers are a
big deal at Google
even though containers are kind of new
in in the industry at Google we've been
running containers in the last 12 years
or so
and everything at Google runs in any
container so Gmail web search maps
MapReduce everything even the virtual
machines in Google cloud platform they
are running in containers because we
allow everything about
they're much more secure they provide
isolation things like that and this
number is probably outdated by now but
we launched over 2 billion containers
per week so you can see the scale of how
much we use containers at Google so
containers are great they help us to
create this lightweight consistent
environment that your application need
so that problem that we used to have you
know where you run it on your laptop it
works but it doesn't work in production
that goes away because with containers
you create your environment and then as
long as you have docker running yeah
you're gonna have the exact same
environment but it's still not enough
because all these problems that I talked
about the resilient resiliency scaling
up and down deploying a new version of
your application
rolling back a deployment if something
goes wrong health checks graceful
shutdown all these problems that you
have that you need to deal with in
production
you still need to deal the deal with
them so containers they don't help with
these ok
so let's now take a look at our small
micro service we created and let's try
to continue eyes that using docker so
I'll go back to my videos so here I'm in
cloud shell again and I'm gonna do first
I need to publish my app publishing
means take my application take all of
its dependencies and create a single DLL
single file from that this is this is
good because I'm gonna use that single
DLL and I'm gonna tell docker run this
DLL so it helps basically to get all
your dependencies and everything into a
single DLL so now this is getting all
the dependencies on my application and
then building it and then putting it
interesting of the allow so once this is
done we're gonna create a docker image
but to create a docker image we need to
create what's called a docker file so
docker file is kind of like a blueprint
of an image so you you use docker file
to create images so we'll create a local
file next so once this is done
all right so I'll go to the publish
folder where the DLL is published so I
have a bunch of DLS but there's one DLL
here that has all the dependencies and
that's what I'm gonna use from docker so
I already have a docker file that I
created before so I'm just basically
copying the docker file into this folder
so let's just take a look at this file
briefly let me just pause here for a
second so this is docker file this is
the the file that defines how my image
is gonna work at the beginning we are
saying from Microsoft net10 one runtime
so this basically says I'm building on
top of Microsoft's dotnet one zero one
runtime image so remember I told you
these docker images that composable so
I'm basically composing on top of this
image which is great so all the
dependencies that I have to own that I'm
getting that by just having that one
line a line of code basically so once I
have that dependency I'm saying copy
everything in this folder on my machine
to app folder in my container and then
set my working directory in the
container to app folder so everything
will work from the app folder in my
container I'm exposing port 8080 for in
my container and I'm also setting an
environment variable called asp.net core
URLs so this amendment wearable will
make sure that my app my asp.net app
will start on port 8080 okay and then
the last thing is entry points so this
is how the image how the container will
will start so we'll just start with net
this is the donut comment and then hello
world s we got that core so this is the
dll that we publish so it will basically
start this dll that's what the container
will do so let's do that
so we have the dockerfile now we need to
actually build the image so to do that
we're gonna say docker built and then
we're gonna tag our image so you can
give names to your images in this case
I'm tagging it with GC r dot IO that
stands for Google container registry
because this is where I'm gonna push my
image so I'm saying I'm gonna tag this
with GC r dot io this is da @ ml is my
project name and then helena is the name
of my image and then v1 is the version
number that I want to give to my image
so this will get the dependencies on my
image so it pulled the image from my net
or actually it's pulling it right now
and then once it does that it will build
the other things that I told it so it
will copy my files to app directory you
will expose port 8080 and then it will
just call dot net on my dear ow so we'll
just wait this to finish and I was going
through the steps so the first step is
done now copying and then yeah so the
image is built and if we do docker
images we should see our docker image
that we just created and we should also
see our dependency images as well so we
let's do that docker images so as you
can see I have two images the first one
is my net this is the image that I
depend on and then the other one is my
own image so let's run this image I can
do doc we run - D means run in the
background - P means exposed port 8080
on my container - port 8080 on this
machine so everything that happens port
8080 in the container will be exposed to
port 8080 on my machine
now the the dock the dock where image is
running so if I do docker PS I can see
my container ID and then if I do a web
preview I should see the same
application again but the difference is
that it's not running on my box as it is
it's running within a container on my
Linux box so it's the same app and let's
just stop the container just to docker
stop and this will stop my container so
that's it so we took our micro service
and we continue as that
now let's push this image to Google
container registry so Google container
registry it's a place where you can
store images and the reason why I'm
pushing it here there is that I'm gonna
use kubernetes in Google Cloud because
it makes it really easy so I'm just
pushing my image there and just I'm
gonna use that image later from
kubernetes so what I did is I use
something called G cloud G cloud is
another command line tool that you can
use to talk to Google cloud and I'm
saying G cloud docker push and I just
point to my image so this basically
takes the image from my Linux box and
then it pushes it to Google Cloud so if
you don't have to wait for this and I'll
skip to the slides but basically after
like a few minutes um our image will be
in Google cloud and I'm gonna use that
later okay so let's just close that
all right so now let's talk about
communities
what is Cuban it is it's a Greek word
it stands for governor just to give you
just to give you a secret it's actually
key vanities in Greek but I think
Americans you know they just started
calling it Cuban it is and now everyone
calls it cuban it is but I'm from Cyprus
so I know about Greek so it's supposed
to be given it is in case you want to
impress someone
but anyway so what it does is it manages
containers clusters so you have come
this containers you go and with my
services you're gonna have lots of these
containers so it basically helps for you
to manage these containers it's based on
an internal system called Borg at
Google's at Google we've been running
containers for a while and we had this
internal system called work to manage
containers so the engineers who worked
on Borg they basically looked at it and
learn from it and they said you know
let's just create a new version of Borg
and let's try to make an open-source so
other people can use it as well so
that's how Cubans came along so even
though it's not Borg per se it's
inspired by a Borg and because of that
it has also lots of common constructs we
can work and communities the great thing
about kubernetes is that it supports
multiple cloud environments so you can
run it on Google cloud you can run it on
AWS you can run it on Azure you can even
run it in your own data center so you're
you're not locked in into a one-club
provider when you're using humanity's
and you can even set a cluster that
spans multiple clouds so you can set a
clear end in this cluster that spans
Google cloud and in AWS which is great
it supports multiple container run time
so you can use docker with it or you can
use rocket as well if you want and it's
hundred hundred percent open-source so
the great thing about Humanities is that
it basically once you set up your
cluster you specify which nodes you want
your containers to be scheduled but once
you do that you basically forget about
machines you know you you just manage
applications you you scheduled pods that
I'm going to talk about and then you you
let Q Benitez worry about the Machine so
it lets you basically focus on your app
and don't not
worry about VMs or machines and stuff
like that okay
at the very high level this is what it
looks like so you first have a master
that manages the cluster in the master
there's an API server that manages the
calls from the users and the users can
talk to the master using an API or a
command-line interface or a UI the
master has also something called hcd hcd
is a key value store highly available
key value store that that holds the
cluster cluster state basically there's
a scheduler to schedule containers into
notes and then there's controller to
make sure that things are running as
they're running and then you have the
notes where all the containers get
deployed on notes you have something
called couplet that basically manages
your communication between master and
the notes so this is most communities
clusters at the high level but as a user
you know you don't really care about all
of this all you care is that there's an
API that you can use either through CLI
or through the API itself and you talk
to the cluster you are actually talking
to the master but you don't care you
know so you just care about this API and
that's what we're gonna talk about later
so when you set up a kubernetes cluster
there are a couple of steps first you
need to set up the cluster so this is
kind of like the hard part to set it up
but even this part can be much easier so
if you want to use Google container
engine then with one command you can get
a cluster set up and get it up up and
running so it's very very easy but as I
mentioned humanity's also runs
everywhere so if you want to set up your
own cluster we're not having to depend
on Google container engine you can do
that but you have to follow these steps
so but you basically have to first
choose a cloud provider then choose a
node OS then you need to provision
machines then you need to configure
networking you need to start cluster
services you need to manage you know so
there's a lot of steps that you need to
do but it's possible or you can just use
Google container engine and with one
command get your cluster so once you get
your if you want to use a container
engine this is how it looks like so in
cloud shell that I show you you
your image from from the dockerfile you
create your image we just did that you
push that image to Google container
registry we just did that so once you
have that you use g-cloud and tell
Google Cloud
can you please create me a kubernetes
cluster with this many nodes with this
machine type and within two two minutes
you're going to have your cluster and
then you use cube CTL this is the
command-line tool for Humanity's and
talk to your cluster so this is how they
work for looks like and we're gonna
gonna look at this in the demo later so
I'll just do that I'll just create a
cabana this cluster on container engine
and see how that looks like so here I am
again in cloud shell I push my image to
Google cloud and let's actually take a
look at that make sure that is there so
I go to container registry and under
there I see something called hello net
and if you look at there there's an
image with version 1 that's the image
that I pushed earlier in my earlier demo
so I have my image ready now I can
actually create my kubernetes cluster so
what I'm gonna do is I'm gonna say
g-cloud container clusters create and
then I'm just gonna give give the
cluster a name so I'm just gonna call it
hello net cluster and then I'm gonna say
number of nodes 1 so in this case I'm
just using 1 nodes but you can have one
or 20 whatever you need and then you can
also specify the machine type or your
nodes so Google Cloud has different
machine types I'm just gonna use a
standard machine and then I'm gonna make
sure that this cluster gets created in
Europe West so I'm specifying your zone
so this is of all you need paste so just
with one command I'm gonna get a cube
area this cluster running in the cloud
so this will take probably back to 3
minutes and then in the end we're gonna
have our cluster that we can use to to
talk to so let me just fast forward this
so we don't have to wait so at some
point the the cluster kubernetes cluster
will show up here so I just want yeah as
you can see it's already up here and
then within a couple of minutes it will
be ready to accept
cause from you so that's what it takes
to create a cluster on Google cloud all
right now once you have the cluster you
can use it so you can run pods and
containers and I'm gonna talk about what
these are you can create replica sets
you can create services you can create
volumes so this is the fun part and this
is the part that you're gonna be working
on you don't create classes every day
clusters are usually created by like a
sysadmin and once you have the cluster
you can basically just run scheduled
your pods create replicas sets and
services and stuff like that so that's
that's what we're gonna talk in the rest
of the talk so let's look at the
building blocks so what is Kuban it is
and what does it give you as building
blocks for your apps so at the very high
level this is what I created this
cluster looks like so first you have let
me just show you here first you have
your containers in some kind of registry
so in our case we put them in google
container registry but you can put them
in some other register it doesn't have
to be in Google Cloud and then from
there you create what's called a pod
template so a pod in Cuban it is is
basically a single unit that you can
schedule usually contains one container
but it can contain multiple containers
because if you have containers that can
that needs to live together and die
together you can put them in a single
pod or it can contain volumes so you
create a template for the part and then
you create what's called a replication
controller so you replication controller
basically schedules parts here what we
are saying is that I want to have three
replicas so I want to have three pods
running with these labels and the
possible also has labels and by the way
I'm gonna talk about all these concepts
shortly I just want to give you an
overview right now so the replication
controller says I will talk to
replication controller create three
parts with these labels it does that
here and it basically just puts them on
nodes somewhere here but we don't care
which not where replication controller
figures are out and each part as I
mentioned it can run a single cone
we can run multiple containers and then
once our positive running we want to
expose them as a single unit to to the
cluster and also to the outside world so
for that we create a service so a
service basically groups pots together
and then the clients talk to the through
the service so you talk to the service
and then from the service you get to the
pots and your micro service basically
becomes the sum of these whoops sorry
so the Myo service basically is the sum
of your replication controller your
pause and your service so so that's how
it looks like in a containerized world
okay so now let's take a look at each of
these in in detail first I wanna talk
about deployment so as I mentioned in
kubernetes there's like pods and
services and and replication sets things
like that so the high-level construct is
called deployment it's a new concept in
humanities and you can think of it as
the high-level construct that you create
and under the covers
it creates the pods it creates the
replicate replicas States stuff like
that so you just created a deployment
and then that figures out all the
lower-level stuff that it needs to make
it run and I'm gonna show you a demo or
this shortly actually right now so I
just create a deployment first so
everything starts with a deployment in
humanities so let's just we have our
kubernetes cluster already so as you can
see I'm in cloud shell I have my class
already so now let's just create a
deployment in this cluster so what I'm
gonna do is I'm gonna say cube CTL at
first I need to connect to my cluster so
I need to authenticate basically my
cloud shell to talk to my cluster so I
did that and now I can run cube CTL
commands from my cloud shell to
communities so what I'm gonna do is I'm
gonna say cube city I'll run and give it
a name and well donut so that's gonna be
my name on my deployment and then I'm
just gonna point to the image so I'm
pointing to the image that I pushed to
Google cloud so this will create a
deployment called hello net and it will
create a replica set that will look at
the image template and then from there
we'll create a pot and it will
our image okay but the deployment
basically takes care of all that for me
so we created the deployment it was
quick so as you can see when I do get
deployment I have my deployment already
running and then if I do get parts my
pod is container creating so it's being
created but if I do get pause again it's
already running so it's really fast as
you can see and if I do get replica sets
I already have a replicas are created by
deployments and then if I do services I
don't have a service yet because this
pod it's not I'm not ready to expose it
to outside world I have a community
service which is a default service in
Cuba it is but I don't have a service
for my pod yet so we're gonna do that
later so as you can see with deployment
basically you you just create deployment
and then that creates the mobile level
stuff that you need to run it okay so
let's talk about those lower level
things so let's talk about pods and
volume so what is a part as I mentioned
pod is a single unit that gets scheduled
in Kuban it is okay it can contain a
single container or you can contain
multiple containers this is the case
where you want containers to start
together and die together and you can
also contain a volume a volume is
basically a pod scope scope storage that
containers can use so for example in
this case we have a container called
file puller that's pulling some pulling
sound files from some some place and
then it's saving them to some volume and
then there's a webserver that exposes
those files probably to consumers so we
have two containers and have a single
volume we put them in a single part and
these will be scheduled as a unit in
humanities so that's what a pod is and
then as I mentioned volumes are pod
scope storage so these are the storage
that your pod your containers use but
their scope for for the pod so if the
pod goes away this storage goes away as
well and there is support many types so
you can attach many types of volumes to
your pod so once you have your pause you
can label them and you can select them
as well so the labels in
when it is they're really important
constructs in every place in humanities
we use labels to access parts when you
create services for example you use
labels when you unique create replica
sets you use labels so you can attach
any kinds of labels to to pots for
example in this case we have four pots
and then we have some labels like so we
have the app label that has my app value
we have the phase label and then we have
the roll label you can have as many as
you want but then once you have these
labels what you can do is you can access
pulse using the label so you can say
give me all the parts with app equals my
app so this will give you all your pots
because all of your pots have these
stables and this value so if you want to
get your app but on the front end parts
you can say give me all my parts with my
app and then role equals Fe which is
front end and this will give you only
two two parts if you want to get back
end parts you can do this if you want to
get production parts you can do that
or if you want to get test pots you can
do this so it gives you all this
different ways of accessing parts and
grouping them together yeah so next
let's talk about replication so there's
this construct called replica setting in
communities so you can think of replica
sets as as a way for you to you basis
specify your this state that you want to
be true and replica sets make that true
for you no matter what so in this case
for example we have a replica set with
this name and this is a selector so this
is the label that that this replica set
will look for in the pots and this is
this is a template that it will use and
then I'm saying replicas for so what
this says is that you know make sure
that I have four pots with with these
labels running all the time okay so
that's that's my wish as an as an admin
that's what I want to happen
so what replicas that will do is that it
will basically ask the API server
how many poses I have right now if the
API services three then it will create
one more and they will ask again how
many do I have
now it's
for so you will eat one crate anymore if
at some point you have five pods then it
will take one away so basically you just
specify what you want and to be true and
replica sets make that true for you
without you having to do anything so in
this case for example we are saying I
want three pots and I want my pots with
these labels so my app is demo app and
the color can be either blue or grey so
as you can see in this case replica set
is managing three pots they all have a
pickles demo because that's what I want
and the color some of them have blue
some of them some of them I gray so if
any point if any of these pods go away
then replica set will create a new pot
on a different node and make sure that
this these constraints that I specified
here they're they're met okay so let's
look at this let's look at how this
works so here I am in in control again
my pods are running I have one pod so so
let's just kill this pod and see what
happens so I'm gonna do cube CTL delete
and pass in the pod ID so this will kill
this pod and then replica set detects
this right away and if I do get pods
again as you can see I have a new ID so
what happened is that this was really
quick what happened is that replica set
realized that I killed the pod and it
created a new pod already and nature
dies running so this way like if
something goes wrong with the positive
the machine goes down or something like
that
replicas that will detect it right away
and and create a new one so that's
replication and then next I want to talk
about services so as I mentioned the
pots there you know you can have as many
as you want but how do you access paws
right so at some point you want to be
able to talk to pots from from the
client so the way to access pot is is
through services what you can do is you
can create a service and say I want a
service that load balances basically
pods with
this label right so you use the label to
a group pods into a service and then the
clients will talk to the service because
the service will have this stable
virtual IP so the client will talk to
the service and the service at random
will will pick a pod when it gets a
request so you can think of services as
kind of like a kind of like a load
balancer for your pots so let's just
create a service for our app because
right now our pods are running we have a
replica set that's running but no one
can access them from outside of the
world yet so let's just make that happen
so here I am again using cube CTL this
is my deployment that's running and then
this is this is the one pot that I have
running so now what I want to do is I
want to expose this pot in a service so
I'm gonna say cube CTL expose deployment
this is the name of my deployment and
the type I'm gonna save load balancer so
this basically says create a service
that it's basically a load balancer this
way it can be accessed from the outside
world you can also have internal load
balancers so that it's only accessible
within the cluster so if I do cube CT
I'll get service now I have my service
it has an internal IP but the external
IP is pending because it takes a while
for Google Cloud to create a load
balancer and get it up and running and
then attach that to the cluster so for
so we have to wait a little bit for the
external IP of our service so listen
let's just fast forward so we don't have
to wait so at some point we're gonna
have an external IP should be somewhere
here it's pretty quick it takes like one
or two minutes so if you do keeps if I
get service now we have an external IP
and we can use that external IP from the
browser and and this if we hit that IP
it will basically wrap us to a pod and
remember our pod is running our micro
service so this will run the same app
that we seen before but instead of
running on my machine or instead of
running on my machine in a container
it's now running in cubanía single
cloud
and we were able to reach it because we
created a service for it okay
all right I am I have a little bit more
time so let me just go through this
quickly so these are services now let's
talk about scaling so let's say you have
a replica set with three parts running
with this version and with this type
front-end and they're being serviced by
a service again it's using by the way
this type should be F II this is wrong
because that's what they're serving I'll
change that so let's say you want to
increase the number of parts from three
to four what can you do
you basically just change the number of
pods in your replica set to four and
replica set scales it for you so you
don't have to worry about machines or
you don't have to worry about anything
basically just tell replica I said just
give me four parts I don't care where
you do it how you do it just do it and
it will do it and then since it has this
the same label as before the service
will pick it up and load balance it to
that part right away so let's look at
that let's see how we scale our app so
here I am again in cloud shell let's say
let's look at our parts I have one part
running right now I want to scale this
to say two parts so what I'm going to do
is I'm going to say it's cube CTL scale
deployment about net that's the name of
my deployment and I'm gonna say replicas
equals two so this will basically tell
replica set scale to two and right away
we have two pods running if I want to
scale to three I just change the
broadcast to three and right away I have
three pots and you realize how fast
things work like you have post schedule
right away if I want to scale down to
back to one I can change it to one and
now we scale down so that's how scaling
up and scaling down works you don't have
to do write scripts you know you don't
have to worry about yourself you just
tell cube I need to scale up scale down
and it does it for you
all right so that's scaling wrong
updates so this is probably my favorite
topic when you have when you have this
setup so for example I have my app
version 1 and I have replicas so I have
three pods running with this selectors
ok and then I also expose this 3 ports
through a service so I have them exposed
through the service let's say I want to
introduce a new version of my
application I want to introduce version
2 the proper way of doing that is as
follows so first I mean one way you can
do is is because you can kill everything
and create a new one and just write
everything there but that's not wrong
update and that's not the proper way the
proper way is this first you create a
new replica set with the version 2 and
then you create a pot just one pot there
and add it to your service so now your
service load balance is between three
old notes pots and one new pod then once
things are working you take one of these
guys out then you create another one
here and then you take one of these guys
out and then you create another new one
and you take the other one out and and
if everything is working you get rid of
the replica set and now you have your
service just serving the new traffic
right so this is what you should do and
if you have to do this yourself you need
to script this you need to make sure
that things are working and if if at
some point things are not working you
need to brought back right thankfully
akyuu Benitez handles all of this for
you so you don't have to do this
yourself and I'm gonna show you in the
demo how to do that but before I do that
I want to talk about cannery deployments
so what you can do in humanities is say
you have this replica set that's you
know that has these two paths that are
being served by this service and you
want to introduce a new version so you
can create a new replica set with
version two and then have that pot
running and you can have service serve
to those three parts because it
remembers the service just looks at the
label right so the
here is B E and all of these pots have B
e now what some of the spots have
version one and some of them have a
version two but the service doesn't care
so it only cares about the type PE so as
long as they had these same types for
all pots you can introduce a new pot
with the new version and do what's
called a canary deployment this way you
can make sure that your new version is
working in the environment and if
everything is good you can decrease the
size of the pot here and you can
increase it here and things work so
that's cannery and then you can also do
auto scaling so you can tell replica set
I want I want this number of pots but I
want to make sure that the CPU target is
50 percent or less okay and what you can
do is you can install something called
hipster hipster basically keeps track of
all the CPUs on on different parts and
then hipster will report to replica side
and say oh by the way right now the cpu
average is 60%
in that case replicas that will create a
new part to bring the average down so
you do an auto scaling is really easy
with replica sets so let me show you the
wrong updates so have the update your
application with kubernetes and I I
think I have five minutes so here I am I
have my app and what I want to do is I
want to just change one of the index
files of the main page and update my app
to use this new new index file so I
already changed this file it says learn
how to build as well not apps that can
run anywhere I change that too that can
run on Google cloud so I just this is my
change so this is my new version what
I'm what I need to do first is I need to
publish my app so I'm gonna do don't let
publish release so this will get my app
and all of its dependencies into a
single dll once that's done we need to
build a new image with the new version
number and then we need to push that
image to Google Cloud and then we're
gonna tell humanities can you please
update and use this new version so this
is building the yellow
and we'll go to the publish folder and
then we're gonna build our image this
time I'm gonna use the same tag as
before except instead of using version 1
I'm gonna call this version 2 because
this is the second version on my app so
this builds the image this time is quite
fast because we only change one file so
it figures out the diff and if I refer
you to cut my images I have the version
1 and I have the version 2 that I want
to use now I need to push this to Google
Cloud so I can use it so I'm gonna use
g-cloud for that so I'm gonna say G
cloud docker push and just point to my
image so this is pushing everything and
as you can realize it says some layers
exist so it knows that some some of the
things didn't change so it only pushed
the difference so it's gonna be faster
than before and that's why I like
containers because you know you can do
stuff like this in a virtual machine if
this would be difficult so now what
we're gonna do is we're gonna use cube
CTL and say edit deployment and give our
deployment name so hello or not so the
when we deployed the deployment it had a
it has a yellow file that defines the
deployment so all I'm doing here is
going to the llamó file and finding the
place where it points to the image so
the image that it points to is version 1
I'm just gonna change it to version 2 so
that's all it takes to do a rolling
update what this and when I hit save now
I save this this will basically go the
wrong update procedure that I show you
it will do that under the covers now I
don't have to worry about them now I'm
going at the service and updating my
service let's see if I have my update so
as you can see I have my update already
so it already happened so all the all
the steps that I talked to you about it
already happened behind the scenes I
didn't have to do I know that it just
happened all right
and let's see what does I have alright
so I don't have time but just to let you
know there are more stuff there are
demon sets so these are basically you
you basically run a pod on every note so
that's what demon sets are for there are
jobs so these are pods that run to
completion and then when they're done
they are killed so they're good for
batch processing
there are stay full sets so these are
pots that have some kind of state
because the pods that we seen so far
they don't have any kind of state but in
some cases if you want to run like a
sequencer or something you need a state
so these stay full sets kind of help for
that
and there are config Maps so you can
define the configuration or your app at
the central place and then when you
create when your pods are created a
volume gets attached that has this
config map that you can use so this is
good for configuration and then if you
have secrets you can define them in a
central place and then when your pot
gets created it creates a volume with
the secrets and there's more
I just basically scratch the surface of
this but if you want to learn more go to
cuba natives of io it has much more
documentation and samples if you want to
run kubernetes on container engine
that's the link and as i mentioned if
you want the slides i'm gonna post it on
twitter thanks for your time i have some
stickers or kubernetes and google cloud
if you want them come and get them
so thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>