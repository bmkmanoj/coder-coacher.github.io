<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning Exposed Introduction to Machine Learning by Katharine Beaumont &amp; James Weaver | Coder Coacher - Coaching Coders</title><meta content="Machine Learning Exposed Introduction to Machine Learning by Katharine Beaumont &amp; James Weaver - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Machine Learning Exposed Introduction to Machine Learning by Katharine Beaumont &amp; James Weaver</b></h2><h5 class="post__date">2017-08-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/P_4_bEXc1UQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and this one this one's okay testing
okay wonderful Thank You Morgan so this
is a machine learning and this is
Katherine Beaumont
we'll introduce ourselves a little bit
I'm James Weaver work for pivotal
Katherine's with foxed we both have this
incredible interest in machine learning
and have been coming up with some
curriculum and and teaching it at
various places and we just like to know
how many of you have some experience
with machine learning some experience
okay how about a lot of experience a lot
of experience so a lot of experience oh
who has a lot of experience with machine
learning I definitely saw a hand at the
back okay maybe because I'm wondering
okay good good so if there are questions
we can't answer we'll ask you okay so
that's who we are
I'll let Katherine explain a little bit
more about who she is alright so I work
for foxed so you might have recognized
that the title of the conference is fox
days if you're observant and fox's sits
behind works days and we write content
that connects the different conferences
together you might see me on YouTube
interviewing speakers and we promote the
content from the conference's so I go to
different campuses interview people
sometimes get roped into panels or
speaking and try and do some development
when I have time which is a tiny amount
of time and Katherine's being modest
she's got a deep background in
mathematics which is when we get into
the parts of the math for machine
learning that that I don't fully
understand I'm gonna punt to Katherine
and then she'll take it the rest of the
way and and and really give us intuition
and maths on on those areas my name is
James Weaver I work for pivotal I've
been a Java developer forever
I've written several books and I'm a
Java champion Java rockstar speaker I
play well with others I've got that
award in kindergarten so I've got that
going for me and what we'd like to do
now
is we've both taken this course by
Andrew ng or or whatever and he's a
luminary in machine learning he was one
of the cofounders of Coursera and he is
a professor at Stanford and he's the
chief scientist at Baidu and this is the
introductory video from that course and
so I just like to kick things off by
playing that video this machine you
probably use it dozens of times a day
without even knowing it each time you do
a web search on Google or Bing that
works so well because they're machine
learning software has figured out how to
rank web pages when Facebook or Apple's
photo application recognizes your
friends and your pictures that's also
machine learning each time you read your
email and the spam filter saves you from
having a way through tons of spam again
that's because your computer has learned
to distinguish spam from non-spam email
so that's machine learning there's a
science of getting computers to learn
without being explicitly programmed one
of the research projects that I'm
working on is getting robots to tidy up
the house how do you go about doing that
well what you can do is have the robot
watch you demonstrate the task and learn
from that the robot can then watch what
objects you pick up and where to put
them and try to do the same thing even
when you aren't there for me one of the
reasons I'm excited about this is the AI
or artificial intelligence problem
building truly intelligent machines we
can do just about anything that you or I
can do many scientists think the best
way to make progress on this is through
learning algorithms called neural
networks which mimic how the human brain
works and I'll teach you about that too
in this class you'll learn about machine
learning and get to implement them
yourself I hope you sign up on our
website and join us I mean that was the
definition that the way that he defines
machine learning machine learning is the
science of getting computers to learn
without being explicitly programmed so
as developers we're used to writing all
of the procedural or object-oriented or
functional code that makes a computer do
something and so we're kind of teach
the computer how to do something through
a code machine learning is the science
of getting it to learn without
explicitly programming it that way and
so what we're going to explore then is
the technologies involved in in in
pulling that one off so where have we
seen machine learning in in the real
world well we're seeing of course
self-driving cars we're able now to
generate in image descriptions so if if
it's presented an image it can tell you
not only what's in the image and what's
happening in the image but then also in
in a language English German whatever be
able to describe what's happening in the
image and so that's through machine
learning now there are three types of
machine learning it's broadly
categorized into three types the first
one is supervised the next one is
unsupervised then the next one is
reinforcement learning so in a nutshell
supervised learning is the idea where
you have your training a model where you
have inputs also known as features and
then you train it with the correct
answers for example from the Andrew ng
course the Coursera course there's a
very simple model where as input one of
the the only feature is a house size
size and square meters and then we have
housing prices in the thousands of euros
and so then how do we map those how do
we teach you know through machine
learning how do we make it so that the
machine can learn to predict given a
square meter of a house how many euros
it should cost so we do that by teaching
it using real data we supply the answers
and so we give a size and square feet
and so those are those data points size
and square feet on the x axis and the y
axis the
and you notice where that the data
points exist and then the machine
learning task then is okay I'm going to
give you 250 square meters you tell me
the computer you tell me you predict how
much that should cost so then there's
unsupervised learning
so unsupervised learning you don't give
it the correct answers you give it data
and then it finds the structure in the
data one of the most popular algorithms
are reasons for unsupervised learning is
the ability to find clusters where is
the data clustered and then for example
here's a an example of clustering it's
it's on the Google brain site Google
arts and culture experiment where it
takes works of art you know thousands of
works of art pieces from all over the
world yeah and and clusters them
according to visual characteristics so
this is just a visualization of that for
example if I wanted to go find ballet
dancers so I could go here now that
these aren't tagged ballet dancers or
anything like that it's just there are
images that are more similar to each
other than others and so the clustering
algorithms the algorithms used the
unsupervised algorithms are then then
clustered those ballet dancers together
apart from for example some other works
of Arts that had less visual
characteristics similarities and then
the last one is reinforcement learning
so the idea there is you have this agent
that could be representative something
in the real world and you're trying to
teach it to do something and the way
that you teach it is you give it rewards
and so it could be points or whatever
and then as it successfully completes a
task then you reward it and so it then
learns to to optimize toward
completing that task correctly so
alphago the the google deepmind project
where the mission where the the
application this machine-like
application beat the the world master in
a lingo is an example of using
reinforcement learning along with other
unsupervised and supervised techniques
so now we're going to dive into
supervised learning and katherine is
going to take it from there and kind of
dive in here this is Matt's talk just to
warn you that some maths is coming up
and you don't need to be scared
but not too much oh not too complicated
so linear regression is the first
example we saw with the house prices
there so the size of the house versus
the price so I took some examples from
where I used to live where the house is
you might see the houses were more
affordable and we've got ten examples
and if we plot them on a graph it looks
like this so what we want to do with
linear regression is try and find out if
there's a linear relationship between
this value down here size in square feet
and price in thousands so just to remind
you the equation of a straight line I'm
sure you're familiar with it but just in
case anyone isn't we've got y equals MX
plus C so M is the gradient and that's
the rate of change so that's how steep
that line is and see there is where
we're going to intercept the y the y
axis so we're going to change that very
slightly for our example here and just
by convention we use theta or theta or
however you want to pronounce it and
that's just a symbol so instead of using
M and C we're going to use theta 0 and
theta 1 just to indicate the first
element and then the second element
because as we get more and more
complicated examples we might have
hundreds of Thetas and run out of em
since these who is scared of theta by
the way ok so can you make us less
afraid of theta it's just a 0 with the
line in it but but it's exactly the same
you're using it for exactly the same
purpose as as the the as what up there
so if you move the C down from the
to the sea is going to be theta zero so
that's going to be our intercepts and
later on memories that again and again
we start referring to it as a biased so
it's how much should we moving the line
through the axis and theta one there is
M which is the gradient so it's going to
be the rate of change how steep is the
line that we're going to draw through
the data so right now those symbols
those Thetas simply represent the
variables that we see up there in our
very familiar slope and y-intercept
formula ok all right so if we were just
going to take a stab at this ourselves
we might just draw a line and go okay I
think this is right so let's guess that
the gradient M or our theta one is zero
point one and the y-intercept is zero
point seven so our equation of the line
is going to be y equals and you can read
that but now we need a way now we've
guessed of working out how right or
wrong that is we need like a numerical
measure so if we just look we can tell
from one example that the prediction is
way off so we've predicted that it's
sorry this is pounds and that this is
1200 sorry I can't read that number
there and but the actual price is way
off so for that one example our guest
doesn't fit at all and now what we can
do is we can measure for all of the
examples how different is the prediction
the blue line from the actual price that
we can see and then we've got this
column here absolute error and that just
means what's the distance you know one
positive number so just to remind you
that this is our hypothesis so instead
of y equals MX plus C we've got theta 0
plus theta 1 X so now the way that we
actually quantify that error between the
guests and the prices is called of cost
function or the squared error function
and what we do is for every single data
point we go through and we compare what
the hypothesis the HX has predicted with
the actual answer that we have from the
data which is y and we square it and the
reason we square it is
because that exaggerated s' the problems
that are really the really big
discrepancies so when we had to date a
point that was really far away from a
hypothesis that adds a lot more to their
error than when we've got a tiny
distance and then we sum them all up and
we kind of take an average so just
ignore the fact that it's 1 over 2m now
because that comes into differentiation
later and you don't need to worry about
that but we're gonna take an average so
we can see here we've got the squared
error for all of the differences and
then what we do is we add up all of the
squared errors which is that number
there and then we're gonna divide it by
the number of examples which is 10 times
2 and we get a horrible cost function
results so we've got a massive error
we've got this 4418 figure so the guess
is probably quite wrong by the way if
you have any questions as we go along
please ask them I should also say that
although we're going into a lot of
detail on math it's not necessary to
understand all the math to do machine
learning because there are high-level
libraries but the title of this talk is
machine learning exposed so what we're
doing is we're taking the band-aid off
quickly and we're exposing everything
underneath the covers under machine
learning so when you're when you're
using those libraries you know exactly
what's going on underneath right so but
any any questions before we before we go
on ok let's repeat the question why is
it 2 times 10 and not just 10 so when we
come to differentiate the cost function
later which I'll explain why we do that
in a bit and if you've got any number
like x squared the differential is 2x so
we take that 2 and we moved it down and
we times the whole thing by 2 so it's
just to cancel that out when we come
it's kind of it's not precise maths it's
just kind of a bit of a cheat to make
the differentiation easier ok so now
we've got our guess and we've got our
way of quantifying how correct or
incorrect the guesses
we can look at what the effect is of
changing the theta value so just to be
simplify this a bit we're gonna ignore
that
and we're just going to change this
value here so only looking at changing
one value at a time and we're going to
see how that affects the cost so if we
plot the cost function here so remember
with our example earlier we had this
huge number 4418 you can see that as we
change theta from one value to another
we've got points where the cost is
really high so it's an obviously wrong
answer and we've got this point at the
bottom here where it looks like we've
got a good value of theta because the
cost is the lowest point so when we run
the algorithm later that's what we're
looking for can we work out the point at
which it's at the lowest okay so what's
the line on on the bottom what's the
x-axis so this here is theta so we're
going to plot and those theta is the
slope yes in this example we're just
looking at the slope of the line so
looking at their M if y equals MX plus C
okay so so we've got all these points on
the graph and we're trying different
slopes to try to minimize our cost
function we're trying to get it as
error-free as we can as close to fitting
the the points on the graph and so as
we're changing the slope making it
increasing it which is represented by
going over to the right then we can see
based upon this graph what is doing to
the overall cost the error that we that
we described and so then as we do that
I'll let let Catherine take it from
there just wanted to make sure that that
we're all tracking so this is where the
differentiation of the cost function
comes in because you saw from the graph
we had this bow shaped function and what
we can tell is there's a gradient to
this bow shape so please could you go
back one slide sorry I'm sorry so here
as theta is moving from zero point one
they're sorry these numbers are quite
fuzzy too 0.16 the cost function is
decreasing so we don't necessarily when
we're trying to work out this linear
relationship we don't necessarily want
to run it through hundreds of different
theta values we want a way of saying if
I just give you one value can you work
out whether you'd go forwards or back do
you need to increase or decrease theta
so the gradient descent says okay the
cost here is decreasing so if we drew a
line across that bow shape the line is
going down so we know that we need to
increase theta to get a lower cost so
that's what gradient descent does so it
goes is the cost function increasing
okay so we're going to minimize theta
because we don't want to cost to keep
growing and growing so we can get
further and further away from the right
answer and if it's decreasing then maybe
you want to increase theta so this is
here the gradients in blue of the cost
function and at the bottom you can see
it's zero the gradient is zero we've got
to the bottom of the cost function the
mint their optimal value of theta so if
we had a tangent line at the bottom of
that it would be horizontal which means
that this the cost is zero yeah it means
we've reached the best value theta so
the cost isn't zero the but we've met
we've got the best cost at that point so
we've got the optimum value of our slope
that's right gotcha I'm just making sure
I'm catching up here see okay so you
know generalized way and I'm gonna skip
over this a bit so we can cover
everything what we would do is every
time we change data by a little bit by
this gradient and that you might notice
another symbol there and I'm sorry it's
alpha and that is going to represent the
learning rate because if we have a big
learning rate we're going to take a big
step we're going to decrease theta by a
lot and if we have a small alpha we're
going to decrease it by a little bit so
it's a way for you to control how big
those steps you take are so if anyone is
interested you can refer back to the
recording of the talk and have a look at
the equations here that's the oh please
clear background sorry and
for the benefit of the gentleman in red
this is where we've differentiated the
cost function we've lost our - so this
is just a quick example of how changing
alpha works so you can see in this top
example here if we have a tiny alpha we
take lots of little steps to decrease
the cost function and then as it gets
bigger it might get too big we can't
converge to a good answer
linear regression might not be the right
answer in which case you can create
polynomials maybe the fit the data isn't
a straight line it's a curve and then
you might want to look at increasing the
complexity by squaring your data or
cubing more whatever and when you've got
more than one variable gradient descent
becomes really difficult so remember
before we just looked at the gradient we
just looked at the M and if you look at
different variables then you end up with
lots of dimensions so if you have two
theta values you can have a
three-dimensional cost function graph
because you've got one value versus
another value first the cost if you've
got four you've got four dimensions and
I'm afraid I can tell a straight that
and it goes epinephrine often increases
in complexity so for example in the
housing price we had we had square feet
and then that ended up because of there
because there's slope and there is
y-intercept there's two Thetas there we
would have two dimensions which which is
here but then if we also had number of
bathrooms then that's another two
dimensions so now we have to represent
the gradient here on four dimensions and
so it gets more complex but that's
that's the multivariable thing that
you're talking about correct and of
course linear regression isn't the
answer to every problem you might have
data where it's just not obvious what
the right thing to do is and I'll leave
that there
okay okay so one of the classic data
sets for learning and the teaching
machine learning is the iris data set so
it's a it's a data set that has a
hundred and fifty right
and it contains the measurements of
different iris plants different species
and so there are three species the iris
setosa the versicolor
and the virginica here and then we have
the sepal length and width petal length
and width and then the training data set
then lists those out with the correct
answers so that's a supervised learning
problem and so we need to be able to
find the machine learning algorithm
needs to be able to find the separation
between those different features
actually between the different species
of iris and needs to be able to find
those boundaries those are called
decision boundaries so what you see in
the graph here are the sepal length with
the sepal width that's one dimension and
we see those plotted in that dimension
and then sepal with the petal length
petal length the petal width and then we
can also see petal with the sepal length
so with four dimensions there are there
are four boundaries that we have to
distinguish and so there's one way of
visualizing another way of visualizing
it is with with tools that will
visualize higher dimensional data and
bring it down into three dimensions so
there's there's a product from google
it's an open-source product called
tensorflow
and they have a visualization API or a
UI sorry called tensor board that allows
you to visualize higher dimensional data
and so I'll just pull up the iris data
set there it is okay so here's the iris
data set there's the iris setosa
versicolor and virginica so in this in
this three dimensional model then we're
representing the four dimension
that we need to be able to distinguish
between because there are four features
so that's a visualization technique that
you'll see so now we'll jump into this
idea of artificial neural networks so
very loosely speaking artificial neural
networks are based upon our our barbed
brain networks so our brain networks
have inputs there are also called
dendrites they have outputs called axons
and we also have neurons and we have
what's the fourth thing what do we have
synapses yeah that connect neurons so we
can model those in a in a computer
artificial and neural network so to try
to model that then our inputs are in a
layer and an input layer has all these
features like the the dimensions of the
the petals for the iris dataset or
whatever or number of bathrooms square
feet and then we have hidden layers and
those are the neurons inside the brain
and then we have synapses that connect
all the neurons and then we have an
output layer which then we make a
prediction for example is that you know
what is the species of the iris or what
is what is the cost going to be of the
house so I when I was first learning
this stuff I wanted to build a
visualization tool so that I could
understand the neural networks and and
as their training how the the what's
called the weights are being assigned
into the the neurons and the synapses as
it's being trained and so it's I put it
on github it's a it's a Apache 2 license
so you can use it anytime and it's here
so it's you run a server and it's
written in spring in Java and
other technologies and then you run the
browser against it and and so I can
click on iris flower for example and I
can see those inputs and I can also see
the neurons and the output layer and I
can see the weights I'll go ahead and
click it again you can see as it's being
trained as it's being exposed to the the
data set those numbers change and so I
can make for example a prediction here I
can say okay the sepal length maybe I
pick one in the wild and maybe the sepal
length is five centimeters the sepal
width is three centimeters the petal
length is one centimeter and the petal
width is two centimeters and if I say
predict then it does this feed-forward
pass through the network using the
weights that were in there when it was
trained and predicts with 0.9 9.99
confidence that that particular one is a
setosa yes question
okay so the question is when you train
the network you always does it always
result in the same weights okay so
anyway yeah if you if you use the exact
same data set and the exact same hyper
parameters you know configuration for
the network it's you know it'll all be
the same but typically in the training
cycle you want to train it and then you
want to optimize it and so it never ends
up you know being the same because
you're always tweaking things good
question
so this particularly here's the here's
the architecture for the application
that I just showed you we're using this
deep learning Forge a library and then
I'm using with spring I'm implementing
rest services and neural net sorry
WebSockets using an html5 client that
I've written in angular 2 I'm using the
deal forge a library it's found a deep
learning Forge a torque it's open source
and free and then start down spring dot
IO is the best way to start doing the
spring project and so now we are going
to cover unsupervised learning and ask
Katherine then to come back on stage oh
one question okay so the question is if
we supplied when we did the prediction
like if I supplied values that weren't
in range would I break it wouldn't break
it but it would it would probably it
might come up with an inaccurate
prediction because it's it's kind of out
of range of what the network was trained
and so so but no you would not break
their boundaries you can't break a
network
okay so the so the the assertion then is
if I supply the the wrong values as I'm
asking it to predict things it's
actually training the network bad
behavior and so there are actually two
there are two independent activities one
is where you train the network with data
giving it features and labels and then
and that can be a slow process sometimes
and then you are another separate
activity is then I make use of those
values and I I i leverage it with
predictions and i say okay now tell me
and so you can make it so as a matter of
fact by default when I do predictions
it's not actually training that at work
okay so Catherine take it away okay so
we've looked at supervised learning
where we've we have the labels so we've
said these are the right answers if I
tell you the data that I've got in and
the correct answers can you work out
what the pattern is between them and
unsupervised learning is when maybe
actually you just don't know what the
right answers are so an example might be
on Facebook you have friends and
connections with people and they want to
work out what are the clusters of people
what are the friendship groups but there
isn't an option on Facebook to say this
person's in my friendship group so they
need a way of working that out and so
imagine we have some data here and we
don't know what the relationship is we
can see just by looking at it that there
seemed to be two groups okay so just
just by looking visually we can see that
actually we might split this data into
two different segments and the problem
is though so please go back and the
problem is if we have this data we can't
always just easily visualize it so we
want a way to do this programmatically
so one ways the k-means algorithm and k
is just it is actually a confusing name
for an algorithm to be honest but we're
going to pick like two clusters so k
might be two if we were picked three
clusters or four clusters k would be
three or four
so it's a way of saying the number of
clusters I want means algorithm but okay
just to confuse you okay for confuse
yeah okay for cookies so what we can do
in the k-means algorithm is we're gonna
say here that K is 2 we want two
clusters and we're gonna randomly
initialize two points and they're called
the centroids and you can just think of
centroids as meaning the cluster Center
so you're going to say okay I want you
to find these two clusters here here are
two data points let's just start with
two random data points for our two
clusters and we're gonna call them just
to confuse you again mu one which is
that greets another we love Greek
letters another Greek letter there and
mu 2 and that's just a way of saying
that's when centroid and that's another
centroid so I'm just going to call them
centroid 1 and centroid two but we'll
use that symbol and now what we do when
we've randomly initialized those is we
go through every one of the data points
so every one of the red dots and we say
how close are you to each one of those
centroids so how close is the red dot
they are labeled with x2 our first
centroid and then we look at how close
is to the second centroid and we look at
the Euclidean distance which is just
what's the distance between these two
points and we can see here even though
visually you can see straight away that
it's closest to the first run
numerically it's closest to the first
one as well so once we've worked out for
every single data point which of those
centroids it's closest to we can then
group them so we say you data point
belong to the first centroids you're
going to be in Group one so what's
Euclidean distance and it's like a way
of measuring the absolute distance
between two points I know about the
Pythagorean theorem does that have
anything to do with it
yes Oh like what so sorry
laughter this microphone so it's like if
you I don't know if you sat at your desk
and you want to go to the bathroom and
maybe chips bathroom you have to walk
around a wall and
go like this turn a corner and so you
know how far you've walked in steps but
you want to know what the distance is
between where you are and where the
bathroom is so just like in a triangle
where you can work out that third side
the hypotenuse yes
exactly you're going okay so I'm gonna
work out using what I know about how far
I step using the Pythagorean theory to
work out what the distance is between
you in the bathroom that's what we're
doing okay so in two dimensions I can
use you know a squared plus B squared
equals C squared right yes
and if I had three dimensions I could a
squared plus B squared plus C squared
equals d squared and on and on and on
but I'm always measuring the hypotenuse
in however many dimensions between
between one coordinate and the other
coordinate and that's Euclidean distance
correct yes great so now we've measured
the distance we can see that for these
data points here in blue they're closest
to the second centroid the data points
in red are closest to the first-century
so now what we've done is we've assigned
them so we've randomly initialized the
centroids and we've assigned the data
points to the centroids the next step is
to so this is just an illustration that
you might keep track of where they are
with a vector C in the next step is to
look at those centroids and say okay for
my group my second group what's the
middle of that group what's the center
of that group so what we do here so just
using the red dots because there are
less if there was an example the top
group me one we're going to add up all
of the vectors all of the dimensions so
for example we've got six along seven up
we've got eight along seven up and so on
and we averaged them so we take the
middle distance of those points and then
we're going to move the centroids so I'm
going to move them into the middle of
those locations so now what we've done
is we've assigned all of the data points
to a centroid and then we've moved the
centroids to the middle of that point
then we can reassign the
eight points again and the k-means
algorithm repeats this and repeats and
repeats this until you converge into
your clusters so you can see now that
we've roughly converged into those two
groups that we first identified so just
to go over it again so we've picked our
K clusters - we randomly initialized the
points for each example we worked out
what centroid it was closest to so
that's this cluster assignment step and
then after that we for every centroid
work out what the middle of those data
points are and we move it and that's
called imaginatively called their move
centroid step and there's a way of
measuring the cost again because we want
to know how well it performed
we need a numerical way of saying this
is a good cluster or this is a bad
cluster and the way we do that is for
every data point now we say how close
you to the centroid that we think you
belong to and then we work out what the
average is so we can find out how well
it's doing and that's it nice unless
there are any questions so the question
was how do you decide what number of
cádiz is a very good question and one
way of doing it is to start with a
number like 10 for example and in the
cluster assignment step so when you're
saying which data points are closest to
which centroids if you have a centroid
that doesn't have any data assigned to
it you axe it so that's one way of doing
it and that's the tricky bit of the
whole thing is choosing the number of
clusters another way to do it to look at
the cost function if you've got a really
high cost function maybe you don't have
enough centroids
maybe your data points are really far
away because you've only chosen two
points but actually you've got five
different groups so that's the tricky
bit okay so I'd like to move on now to
getting into some other types of neural
networks we've got artificial neural
networks which we showed you which were
you know we're modeling the brain and
we've got neurons and synapses and
things like this so there are other
configurations of artificial neural
networks that that are used for special
things for example in in image
recognition as studies have shown that
that animals including humans when we
look at things we're actually picking
out higher-level features out of
something rather than seeing the whole
image at one time and so we use we model
this with machine learning algorithms in
what's called a convolutional neural
network and so there's there's this page
on the on the stamp sorry the stanford
website that then has a convolutional
neural network actually running in a
browser the the prediction size the side
and there's a link to this in the in the
presentation so it's just showing
pictures and then as showing in each
layer of the network in this
convolutional network what it sees and
so the next slide then kind of shows a
little bit deeper view of what a
convolutional network is so over here on
the right is our familiar fully
connected layers where we have neurons
and synapses between them but then up
front we have one or more convolutional
layers where we've got the image coming
in and we've got this convolution thing
happening and then we've got this
pooling thing happen happening which
downsides of the image and that way when
we get to here we're presenting
higher-level features to the fully
connected parts of the network and you
know rather than being you know maybe
thousands of values in these pixels
we're boiling it down to a smaller
vector that we can have a fully
connected layer on so to graphically
depict this there's a really nice
visualization that this person named
Adam Hartley created and here's the link
to it but I can
I can visualize a convolutional Network
that recognizes handwritten digits so
this data set of handwritten digits it
was actually trained with this data set
called
M nest for the post office so that when
people are writing zip codes that that
you could recognize them so I could go
ahead and draw a number here maybe I'll
draw a number 8 and so we see as soon as
I do that that this is the input and
then we have convolutional layers and so
you can see the lines going from pixels
in each of these vectors in the
convolutional layer showing what it is
examining and filtering for that
particular thing and then here's a down
is a pooling layer where it kind of down
samples the image and then we go again
here we we do filters in this
convolutional layer we down sample it
and then we end up with a with a layer
of neurons that's fully connected to
each of the each of the values the
neurons in this layer this last pooling
layer and then here we have another
layer that has its fully connected you
know with with our normal neurons and
then as with our artificial networks
that we've seen before I'll go ahead and
drill into this then we have our
prediction that that says eight so this
this last layer here is sometimes called
the fc7
the fully connected seven layer it's
arbitrary number but it it conveniently
stores this nice vector that boils down
these high level features for whatever
the image was into this code that you
can then use for nice nice things later
and so then visualizing high dimensional
space this Emnes data set has lots of
images of 28 by 28 grayscale pixels
and so to visualize that we can use this
tensorflow
embedding projector again and it's going
to use this what's called a PCA
algorithm principal component analysis
algorithm which takes high dimensional
vectors so so these high dimensions that
the code the the the actual images are
are 784 pixels of 0 they're 2255
grayscales
and so that's a vector with 784
dimensions so it takes and uses the PCA
algorithm to then be able to be able to
see those in in 3d space and so we see
how the twos are over here and and we
can see then we can begin to see how we
can make those decision boundaries and
and and tell which ones are which yeah
and so that's that's how to that's an
easy way to to be able to visualize high
dimensional data ok so then another
thing it's kind of a newer technique if
you're at a cocktail party sometime and
you know you're talking to some machine
learning people and you know all you
have to do is talk about hey have you
heard about generative adversarial
networks and you know because it's the
coolest thing and what what it is is
this ability for the for the neural
network to hallucinate to kind of dream
up images that don't exist and so these
are all images of faces that that that
aren't real images they're ones that the
neural network has dreamed up and so the
link by the way down here to the paper
or to the website is pretty fascinating
but what it uses is this concept of a
counterfeiter and a detective so what
happens as you train a neural network a
convolutional neural network with a
bunch of phases
and then and then you have this
discriminator which is the detective and
you have this generator which is the
counterfeit ER and they're playing this
game where the generator draws a picture
of a face and the the discriminator says
that's fake or that's real and then
shares with the generator you know why
he thinks it's fake or real and so the
the generator gets smarter in generating
the images but the but the discriminator
gets smarter in being able to
discriminate between them you know but
discriminate whether it's fake or real
and so then what you end up is with with
these these images that end up looking
more and more real and so then when
you're doing that then you can take that
remember that fc7 layer that kind of
last layer in the in the network before
the prediction in this particular
application they've got a hundred
hundred element or dimension vectors
with these grayscale numbers and it
turns out you can do math on them so you
can say you can take the vector that
represents the man with the glasses and
then subtract one that with a man on a
picture that was generated with the man
without glasses and then add a woman
without glasses and that equals a woman
with glasses right and so it just
generates then a woman with glasses even
though that one didn't exist either so
you can do this
kind of cool vector math and so the the
last thing I'd like to talk about is
recurrent neural networks and so the
networks that I've talked about so far
have deal with static information so
give them a house give a house price in
square feet or an image in this case we
want to be able to do things with time
series we want to be able to have this
ordered set of events that happens and
then maybe predict the next thing or in
the case that I'm going to so in this
case of the the cats if the computer
saw that you know if we ran that through
a convolutional neural network it would
say okay there's a couple cats in a box
but it can't really say what's gonna
happen next
so I don't know what do you think
happens next somebody tell me the box
closes right so but equally as probable
I suppose is maybe the white cat down
there is stronger than a black cat and
the the box opens and so this was fun
looking at gifts all afternoon the other
afternoon but but you are right actually
the box is closing but it could have
been opening right right so so pretty
much like every afternoon I watch cat
gifts but and so so you could use that
kind of thing with with music
composition and then in the slides I
don't have time to do it now but in the
slides there's a really nice site that
was made by Google brain and an
experiment off of that where you can
actually jam with a neural network it's
kind of cool and then I think we I think
we close with a video then of what
self-driving car sees so this is a one a
video that was produced by Tesla and
they put it out just to show what the
driver sees but the driver isn't you
know holding the wheel or controlling
this in any way but then also over here
what the the car sees with sensors and
via machine learning
so it's picky with convolutional neural
nets it's picking out things like
stoplights traffic signs people it's a
good thing it should pick out people for
sure and and then has can see what's on
the right of it in front of it in the
rear of it and then using that to make
decisions on on driving so thank you for
your attendance and we do have a few
minutes for questions after after this
who's got the first question I don't
know sorry other questions okay well
thank you for your attendance by the way
we have a follow-on session that we're
going to be dealing we're going to be
diving into deep neural networks and
reinforcement learning yet after lunch
so thank you very much for your
attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>