<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>From Tic Tac Toe to AlphaGo: Playing games with AI and machine learning by Roy van Rijn | Coder Coacher - Coaching Coders</title><meta content="From Tic Tac Toe to AlphaGo: Playing games with AI and machine learning by Roy van Rijn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>From Tic Tac Toe to AlphaGo: Playing games with AI and machine learning by Roy van Rijn</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yMRuYeOLf0o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Birgit you make it do it makes it let's
get started
if you were here for the programming
language go well no we're not going to
talk about go we're going to talk about
alphago and a lot of other things let's
look at the topics we're going to start
with a very simple three grain and this
three game will teach us how at research
works and how minimax algorithms work
then we'll move to knots and crosses and
we'll learn about perfect information
and game theory that will make a jump to
chess and we'll look at forth and
backwards pruning and alpha-beta pruning
and finally we'll jump to go the hardest
game in this list and we'll learn about
Monte Carlo tree search and the neural
networks that are currently working in
alphago so I want to play a game the
game we are going to play as a tree like
structure you are lucky because you can
always start and your aim is to get the
highest score and this is not the jigsaw
reference so this is our game you start
at the top you can go either left or
right and your goal is to get the
highest score this is pretty trivial we
pick five because that's higher than
three so we go to left but now of all of
sudden it isn't trivial anymore so first
it's our turn we can go left or right
then it's the opponent's turn which can
go left or right and then it's our turn
again so what do we need to do to get to
the high score well we can say well
maybe if we go towards the nine that's
that's the highest one but yeah there's
also a two next to it then if you use
minimax this is very easy to solve it's
a very simple algorithm
basically fills up the tree with values
and it will determine what you should do
minimax stands for you minimize the
maximum score and that's when it's the
opponent's turn and when it's your turn
you obviously try to maximize so you try
to maximize the minimum score this is
basically perfect play so let's go back
to the example we start at the bottom
that's our turn so we will obviously
pick the highest value this is trivial
and when you move up one level it's your
opponent's turn the opponent will always
pick the lowest value so between five
and nine the opponent will pick five and
between four and eight the opponent will
pick for the top one it's our turn again
so we have to decide between five and
four five is less so in this game if
both players played perfectly we'll end
up at five in a nutshell this is minimax
and this is how almost all the game
search algorithms work with variations
but it's a Java conference so we need
Java this is Java this is how you write
the minimax algorithm it's a recursive
method you start out with a starting
node and a boolean if you're maximizing
or minimizing the score if it's an end
note a leave note the bottom node will
just return the value of the node and
otherwise we initialize the best score
with either the minimum value or the
maximum value of an integer depending on
if we are minimizing or maximizing our
value and we'll walk all the child nodes
for each child note we recursively
calculate the score and we flip the
maximizing to minimizing and minimizing
to maximizing with the expression mark
and if we're maximizing we update our
best score and if we make minimizing
work data best score and that's what we
return so this code basically makes this
tree
so our game it has a branching factor of
two at each step we split into the game
depth in this case or three because we
have three layers three times a decision
before the end and we have perfect
information and perfect information
means both players know eventually what
you'll end up with it's too easy to see
to the end both players will note it and
in such a case minimax is just works
perfectly so what do you need if you
want to make a program that plays
computer games or board games in this
case you need first need a way to
generate all the valid moves so if you
want to make a chess-playing ball you'll
need a test engine which knows all the
test rules and which tells you all the
different kind of moves you can make
from a certain position this is very
game specific the second thing you need
is a way to evaluate the notes in case
of for example tic-tac-toe the
evaluation can be very simple you just
go to the end you see who won but in
case of chess for example you can't
calculate every final position so you
need some other way to evaluate the note
so you need to weigh it this is also
game specific the final thing you need
is a way to pick a part in the tree and
this is completely game agnostic it
doesn't really matter which which game
you're playing if you're playing
tic-tac-toe chess go the algorithm is to
pick a path like minimax we just showed
our agnostic let's look at another game
noughts and crosses which in Dutch is
butter cheese and eggs which makes no
sense at all to me nuts and crosses
completely describes the game
cheese and eggs no idea but it's true
sorry that's what we call it but it's
using eggs so nuts in crosses if we
would draw the entire tree we'll start
up with an empty empty board and then
there are nine possibilities so we can
either put it at the top left square the
top middle square that's a bright square
etcetera etcetera and after that there
are eight possible choices and if there
are seven possible but that three is too
large wouldn't fit on my slide so we can
forget that it's a large three if you
would draw it on paper but it's not that
large for a computer it's very easy to
just calculate to the end and we can do
that and we can assign a value like I
said if we win pick one if we have a tie
zero if we do is minus one if we do that
and we play to the end and we apply
minimax like we did before you've solved
the game you've solved tic-tac-toe and
you can play it perfectly tic-tac-toe or
not two crosses as a bracing factor of
five on average
so the first step you've got nine
possible choices then there are eight
then there are seven the nerve six and
finally there's just one position you
can put it in so on average it has a
branching factor of five so at each step
there are five possibilities
yes yes coming to this the maximum depth
is nine but you can lose sooner or win
sooner so sometimes if you just get up
to seven or eight and if you remove all
the symmetries because there are a lot
of symmetries in the indict Excel for
example if you put it in a corner it
doesn't really matter which corner there
are just 138 terminal positions and
interestingly if you start with X you
can win 91 times and the opponent you
can lose 44 times
and there are just three terminal
positions with which end up in a troll
but if you play perfectly and if you
apply minimax the funny thing is you
always end up in a draw if both players
play perfectly and you counter Exeter
you always end up in one of the three
tying positions which is kind of
surprising but that's how it works
you can never force win so if both
players play perfectly you end up in a
tie if one makes a mistake you can win
or lose
next game chess the noble game of chess
if you would throw the entire tree for
chess this is what you'll start up
you'll start with and then just for it
and then there are 20 different moves
you can make from an empty chess board
and below that there twenty more moves
the opponent can make and obviously this
quickly becomes very large it becomes
that large - just look at this table if
you start a depth zero which is an empty
board there's just one single note
that's the empty board a depth one there
are 20 different moves you could make
depth to the opponent makes a move e or
she can also make 20 moves so that makes
a combination of 400 notes and this
quickly grows until after just six moves
you're already at 190 million different
positions and surprisingly if you look
it is stable you can see there are a lot
of captures possible but also checkmate
so for example after four moves you can
check mate someone inches I didn't know
that but this table says it it does
these tables are very handy I wrote my
own chess engine and these tables are
very cool for two reasons first bragging
rights because it's very easy to
implement once you have a chess engine
just make all the moves for each move do
all the moves for each move do all the
moves there's three lines of code and
you'll quickly see at depth six if it
takes a couple of minutes couple of
milliseconds
so you can compare the speed of your
chess engine to other chess engines the
second thing is it's like the perfect
integration test because when I was
writing my chess engine I would end up
depth six would be one one nine oh six
oh three two two
so my chess engine was missing some
corner case rule which ruled out maybe
two nodes did those are kind of critical
so I didn't correctly implement all the
rules and there are the tables like this
so this is a table from an empty
position but there are also tables which
have a lot of castling and promotions
and checks and you can use that as like
an integration test to test if your
chess engine is is correct correctly
implemented so what's the problem with
chess well there's no perfect
information the entire tree for chess is
too large
you can't just compute every single end
node and work your way up using minimax
and find out what the perfect play is
it's impossible it's too large so we
need to at some point stop evaluating
and give a note a value we have to
evaluate that node turns out in chess
it's very easy you count the pieces if
Grand Master's are talking to each other
and they're analyzing a board they will
always say he is maybe one and a half
pawn in front he's winning by two pounds
which is which is very if you're a head
two pawns
you'll probably win the game that's it's
a big margin so basically you can count
the pieces but you can do other things
for example you can evaluate the
positions on the board in chess having
positions in the middle is stronger than
having position on the outside so you
can share your weight those higher and
you have things like where you pin down
certain chess piece that's very powerful
because the opponent can't move their
chess piece because at that point you
can take another piece
so writing an evaluation function for
chess easy ish but there's the horizon
problem if you go down the tree and you
evaluate a node you have no idea what
happens next so at some point you have
to stop thinking about what happens next
and just give it a number maybe the next
move is a checkmate we don't know we
stopped evaluating that's your isin
problem you just look up to one horizon
and what happens behind it no idea so
it's very powerful to look a bit further
and to do that you need either more time
computer time or you need to do some
pruning we need to cut back the tree
some branches are more valuable than
other branches
there's forward pruning which is risky
and there's backward pruning which is
safe I'll go into those now what is
forth pruning if the move is very bad
just don't look don't look any further
just stop evaluating at that point if
you sacrifice your queen in in after 10
moves there's no need to look at all the
nodes behind that just we're not going
to do that on the other hand if a move
is too good for you also don't evaluate
the opponent also won't give up his or
her queen early in the game and then
evaluate a fork in it because that's
another scenario that's unlikely to
happen
but like I said pruning is dangerous
because sometimes if the opponent
sacrifices his or her queen and maybe he
or she thought of something very clever
and eventually they can win but if you
stop evaluating you won't you won't you
don't see that that's your isin problem
but by cutting back to tree you are able
to go further deeper in other
interesting branches luckily there's
also off of that pruning which is a safe
way a mathematical safe way to eliminate
nodes
for me of better pruning every time I
have to relearn it and check how it
works but with these slides all of you
will understand of that spoon so this is
a game tree there's a minimizing
movement a maximizing move and behind
that there are a lot of other nodes
so we've went down the path and we've
come up from here and we found it at 3
and well we can just put our tree right
here now we're not done yet because
there's another node we go down there we
evaluate it and you end up with a 5
it's our maximizing turn so we go to the
5 instead of the 3 because we want our
high score with you 1 2 5 this branch is
done so we move 2 5 up and now we go
down the other path and the first branch
we hit will end up with a 9 we go back
up and we have a 9 and at this point you
can stop this is awful better pruning so
there are two things that can happen if
you go down here if the number is lower
nothing will happen because this is a
maximizing move it's if it's lower this
will always stay a 9 what happens if
it's higher well if it's higher if it's
an 11 or 12 or this number will change
this number won't change because this is
minimizing move and we've already got 5
here so because this is a 5 and this is
higher it doesn't matter what happens
below this you can just completely
forget that there's no way that 5 will
change that 5 will stay there forever it
also works the other way around if the
minimax
were reversed in this case we have a
maximizing move which has a 5 and
there's a lower value below that and no
matter what happens that number will
never grow
err then three it will only go lower
because that's minimizing move
so there are safe ways to stop
evaluating notes and you can do this
using alpha better pruning but ROI
that's probably very hard to implement
now it's not because we already had
minimax this you've seen this before and
this is still minimax so the great
things are the only things we need to
add the first thing we need to add is
alpha and beta just two values the next
thing we need to add is when we were
maximizing the score we update alpha and
when we're minimizing the score we
update better so that's easy enough and
there's a cut-off point if data is
larger than alpha stop that's the only
thing just with three extra lines we've
now greatly increased the speed of our
minimax search we're stopping evaluation
when we safely can and this isn't risky
where we aren't throwing away stuff that
that that so this is the completely safe
way of pruning so yes if you want to
make a chess bot I made the test but I
had a colleague who was he's 60 years
old and he's been playing chess for
forty years or something as an elo of
2200 which is pretty good and in one
weekend I decided to write a chess
engine which I did next I wrote a very
simple evaluation function just count
the pieces and a little bit about where
they are on the board and I slept on
that alphabet search I just showed you
and I was able to beat my colleague
which of course he didn't like because
he had invested 40 years of his life
learning chess but yeah and then the
little breath comes along with his chess
engine and he got beat but it's that
easy chess has been solved
some numbers chess on average has a
branching factor of 35 so that's much
higher than tic-tac-toe an average game
left for 40 to 50 moves games can go on
a lot further you can have games of
100-plus moves but on average after 4050
a chess game is done and array if you
want to make an evaluation function
that's easy we just showed you just
count the pieces you look at the
positions on the board that's okay and
with those things and a little bit of
aggressive pruning always the the safe
back backwards pruning but also for
pruning chess engines of chess AI scan
look 20 moves ahead and that's enough to
beat any grandmaster the final game go
for those of you who don't play Go Go
has a board of 19 by 19 your black and
white stones and your goal is to
surround and capture areas on the board
I've never played go but I kind of
understand the rules but it's it's a
hard game so why is this so hard
it sounds simpler than chess chess has
all those different pieces which can do
different moves but it's all in the
numbers because the first problem is the
branching factor where chess has a
branching factor of 35 go on average has
a branching factor of 250 so at each
given point in time there are 250
different zealot moves you can make
instead of 35 the second problem is a
game lasts much longer 300 moves instead
of 50 moves so in chess you have 35
times 35 times 35 that 50 times this is
250 times 250 300 times those of you
studying math understand that that's
kind of a problem
the final thing is an evaluation
function forgo is non-trivial if you ask
experts who's winning
they look at the board and they say well
my intuition tells me that he or she is
winning why do you think that yes I'm
not quite sure it's intuition they can't
really qualify it because the problem is
if you surround an area and you're like
ninety percent there
you can't count that maybe it's
impossible to capture that area but it
looks promising but that doesn't say
anything sometimes it's obvious that
that you can't really capture that so
you can just basically there's no real
evaluation function this is the number
of possible moves you can make on an on
a go board and like I said it's larger
than the amount of atoms in the entire
universe so it's kind of impossible to
calculate all the way to the end one
solution for this is the Monte Carlo
tree search when I say Monte Carlo what
do you think of for me it's Formula One
and harbor but most people will also say
the casino and that's why it's called
Monte Carlo tree search because what do
we do we take a node and we play
randomly to the end and we do it as this
as often as possible and just by playing
randomly to the end we can see if we
want 20% of the times or 40% of the
times maybe 60% of the times this gives
us this gives us an indication of the
strength of this particular node we
picked so if for each of the nodes we
play to the end we look at the
statistics well we'll just go with the
one that won most of the time or lost
least of the time that way you don't
have to write an evaluation function you
don't have to exhaustively search
everything but yet
it's kind of random and that's why
experts said just two years ago it will
probably take 10 to 15 years before a
computer can beat a professional go
player they were wrong forget that
because suddenly alphago came around
poor baby and alphago is using neural
networks so what is a neural network a
neural network is computer model
designed to simulate the behavior of
your own biological brains time for a
short demo maybe perhaps where are you
there you are what you can see here is
the playground of tensorflow tensorflow
is a library or framework library my
work whatever where you can implement
neural networks on a very easy way and
using this playground you can just play
around to get a feel for what actually
goes on inside a neural network so let's
just delete everything here let's no
let's just delete all layers and delete
this here we have our data this is our
input so right here you can see there
are orange dots and blue dots the goal
of this playground the neural network is
to separate the blue dots from the
orange dots right here we have certain
features so for example we have a
vertical line and we can even we can't
get rid of this now though we can yeah
so we have a vertical I'm if we play
well nothing happens obviously but we
can add a hidden node and we'll add just
a single node so what can this node do
it's working it isn't working wait
refresh works so what happens now we
have one line a vertical line and this
node has a certain weight to it and that
weight moves the line left or right and
as you can see in this this case it
tries to separate the orange from the
blue so it found a region with orange
and a region with blue and orange but
using this input the only thing it can
do is move left or right if we add
another hidden neuron you can see
the network is now able to make two
vertical lines so it can separate out
more orange from blue another
possibility is that we have multiple
inputs so what happens if we have an X
input and a vertical input and a
horizontal input if we add a random way
to this that's kind of broken don't know
what happened you can see it can now
combine those two inputs with a single
output that way can make diagonal lines
that's because these two inputs combined
in a certain way makes a diagonal line
if we have two diagonal lines so two
inputs two hidden nodes it's able to do
even better than just having two
vertical lines and this solution can be
solved completely by adding a final
hidden node which has weights and right
now the neural network is able to
separate every orange bit from the blue
bit so basically that's how neural
networks work it's just a set of weights
and inputs and with that you can solve
problems but yeah a different problem
with the same neural network kind of
works but kind of doesn't so you might
say well let's just make a bigger neural
network just add some hidden layers
connect everything up make a big brain
and we'll solve it in this case it does
but sometimes
but it takes much longer obviously if
you make the brain big enough it will be
able to solve this but it will take much
much longer because every node is doing
random things and is being adjusted and
in this case it isn't even solving it or
maybe it is maybe it isn't
it doesn't know what to do so beer isn't
always better
back to the slides this is just just to
give you an idea of how neural networks
where is my cruiser there it is if you
have more information on their own
networks and machine learning and the
kind of stuff
visit tensorflow tensorflow with its
playgrounds it's very easy to get
started if you want to do java you can
go to deep learning 4j which is a neural
network library for Java and there are a
lot of others you've cafe towards Fino
there's a lot to find on the Internet
but how does alphago work how can you
use neural networks to play go well
something about those neural networks
and the neural networks used in alphago
are convolutional neural networks that
means they break up the problem into
smaller pieces
those are evaluated with each layer and
they're propagated back the learning is
supervised which means that every time
one thing is evaluated the entire neural
network is being adjusted so it isn't
being adjusted layer by layer but it's
being adjusted after it receives a loop
and I just learned alphago has 13 layers
which doesn't sound like much but you
could already see now we add like ten
layers just yet but they have a lot more
neurons and a lot more confluence of
pieces they created a lot of neural
networks for in particular the first one
they made they took the neural network
and they took 30 million amateur matches
and they gave the neural network go
predict the next move
so the input is automatic at the output
for each single board position is give
me the next move the input is a board
position so a complete go board and it
was correct in 57 percent of the time
which doesn't sound like a lot but
actually it is this newer yeah we know
what the amateur matches did so we can
just give it a position we ask it okay
in our network what do you think is the
next move it will say this move and then
we can see what the amateur actually did
so then we can teach the neural network
what an amateur would do yes
the second Darrell Network they took a
copy of the supervise Network we just
solve and they said at the new go critic
the best move
not the amateur move but the best move
exactly what you were hinting at this
network played itself so it was learning
by self play small variations of itself
we're playing each other and the one
which had a better move got better and
the one that didn't have better move
died that's what the using self played
they try to find the best move so
instead of predicting what the amateur
did they were trying to find better
solutions then they played against Pachi
Pachi is a go AI which is using the
Monte Carlo tree search we saw earlier
it isn't the best it's just a a I
well-known AI and it could win 85% of
the time just this neural network just
give it a board position predict the
next move which is pretty pretty
impressive
this reinforce network is a bit slow to
evaluate one board it would take three
milliseconds which doesn't sound slow
but it is especially if you want to do
multicolored t-shirts if you want to use
that network to predict the move pretty
move
move all the way to the ends and keep
doing that it's just too slow so they
made a smaller network and they trained
it at the same way and this network is
less correct less good but marginally
but it's much faster so it takes I don't
know what that is two microseconds it's
15 on the times faster for identity they
weren't done they made a fort neural
network and this is the value network so
they took the same 30 million matches
and for each position they asked the
neural network predict the winner based
on this board so basically right now
this neural network is being trained to
be an evaluation function initially at
an error of 37 where 0.5 is random so it
could predict something then they did
the same trick as before with self play
and the error came down to point 23 they
decided to test this network how do you
test this network well for a given board
generate all possible moves for each of
those moves evaluate and see who's
winning and the one that has the highest
likelihood of us winning pick that move
and play the move this was able to be
the strongest known AI that was
currently written for go and this is
still without any tree shirt so just one
single depth look at the nodes evaluate
and go then I went on to combine all the
pieces so they're using the policy
network to look at the best moves
they're using the value network to check
this for those moves which of the moves
have the highest probability of us
winning and then they used the first of
all our network the 115 on the times
faster to just Monte Carlo play to the
end and see if it's actually a good move
and those three values are combined and
the
three various together decide which move
alphago is going to play and this was
working very well so they set up a
challenge that guys lease at all and he
is considered to be the best go player
of his decade at that time of the
challenge
he wasn't the number one in the world I
think it was numbered four or five but
he's being very consistent he's been in
the top five for ten plus years so he's
like the Roger Federer of go alphago is
playing a best of five and when I get to
million just just so Lisa dole tries his
best
the Challenger is a distributed version
of alphago with some mighty hardware
itself on it in two CPUs 176 CPUs and
the game started Lisa dough was pretty
convinced he will win because the
experts were saying it will take ten to
fifty years you have to worry go on
spend that million it's yours and right
here you can see a lot of things but you
can see alpha goes minion so alphago is
the computer screen
that's his minion that actually places
the thing on the board and on the
opposite end is Lisa tall and game one
started and they were playing and well
yeah there are doing pretty standard
things until move 102 and that's when
Lisa doll looked at the board and you
realize something this is what happened
what is that HC so because every 102 he
realized he might not win his hardest
this job brothel now it was literally
hot and in frogs was in our three
seconds early somebody
like if his mind is currently breaking
ah okay City Devon even somebody still
can't invest if he did it he did it
expect this by changing digested one
changes a day to Saudi Arabia yeah it's
like completely flabbergasted some be a
mere Samaha soul around Eva and he went
on to lose this game which was already
early game two was also very interesting
um if you look at chess chess in the
last 15 years has evolved a lot with the
rise of computer chess if you look 20
years ago chess was pretty normal
everyone was playing the same openings
they were just standard things you do
but computer chess
changed that computer has really opened
up the game for new creative ideas and
new ways to play and it really evolved
the game and experts are saying the same
thing might happen with alphago and this
became apparent in game number two move
37 you can see the the reporters they
are reporting the game and alphago makes
an unexpected move just look at look at
the river it changes the value of an
area when you have a stronger you can
see alphago already played the next
point the approach that they have a team
of yet though strong and this is what
sorry from the from the Google team was
talking about it's just kind of about
elation no value huh that's a very nice
and very surprising move I thought I
thought it was cut it was a mistake what
I thought it was a quick myth but
clinically I'm like no we flick oh yeah
it's a very strange something like this
would be a Morgan yeah than to just go
on them we expected this is not okay
you're going to enter so you know they
really did it didn't they couldn't
explained it locally they couldn't
explain what happening um but the
European champion said after the game
this was not a human move I've never
seen a human play this move it was so
beautiful and this for the first time is
when the game of Go is changing its
being played in a more creative way and
this is something that's probably going
to happen through this game as well the
same thing has happened to chess game 4
came the first three were lost by lee
sedol
and there's the famous move 78 and GU
Lee who is these arts rifle said this
move was made with the hand of God and
it's a move made by Lee SEDOL this
wasn't the move made by alphago and in
this case it was lee sedol who made a
very surprising move and that probably
caught alphago off-guard because game 4
after this move the game changed so much
that lee sedol
had the upper hand and was able to win
from alphago but yet they're very good
in art the hand of God and it's so
beautiful but in the end it wouldn't
matter because alphago 141 lee sedol
didn't get his million and the game of
Go has been beat so what can we conclude
well the surprising thing is nobody
thought alphago what a good or a bad
move is there isn't any go logic in
alphago nobody programmed email in
evaluation function for alphago so
alphago isn't an expert system they're
using this system for go at the moment
but it's a general machine learning
solution
alphago learned by watching others and
self play nobody said this is how go is
supposed to play it just watched games
and played itself and that's how it
became so strong and it's all done using
general machine learning techniques to
figure out for itself how to win at the
game of Go this is something that
happened as a response of the success of
alphago South Korea announced 863
million
dollar investment in artificial research
artificial intelligence research over
the next five years and then alphago
went silent they didn't play any games
darned any tournaments that was until
January this year when in online go
community a new player arrived which was
called Master P and the professional go
community was in a state of shock
because this new player was able to beat
everyone all the grandmasters all the
the best in the world
they all got beat it was even that bad
that this fella ke is the best Chinese
player in the world he was so
disappointed he got ill and he had to go
to the hospital because he could beat at
a game little childish but that's what
that's what happened he had to go to the
hospital but now he gets his tile he
gets his chance to revenge because I am
a 23 to 25 just a couple of days from
now there's a new tournament between
alphago because Master P turned out to
be alphago obviously and ke and they're
not going to play only the traditional
game where you have unlimited time not
unlimited a lot of time they're also
going to play blitz games and other
games but talking about K G nice segue
the next target for alphago is actually
healthcare their goal is to make a
neural network that predicts diseases
not go moves and they're going to use
the same network as they are using for
alphago so that's that's their main main
ambition that's their main goal protect
predict diseases based on a lot of input
parameters predict which disease certain
people have so that's basically it we
went from tic-tac-toe to healthcare
basically we have six
for questions Jesus we have six minutes
any questions no questions yeah yeah how
can you use the technology where the
machine is playing itself to improve the
healthcare I don't think you can you can
obviously use the the input data there's
a lot of input data where you have
certain parameters and eventually you
see if someone it was or wasn't sick
but thickness also doesn't really have
the problem of making not the optimal
move because sickness will always be the
optimal move sadly so maybe maybe self
play isn't really really needed in this
case but I'm not sure how they're how
they're going to do this yeah so the
question is how about a moral moral
moral implications but that's that's
true for a lot of neural networks
because the problem with neural nets
because you can't really see why they
are making certain decisions but that's
also the case I work for the port of
rotterdam and we're actually using a
neural network to predict times arrival
times but they're people often complain
why are you are you predicting I'm an
hour late that's just what we're
predicting but but the same thing is
about mortgages there are no networks
that predict if you can pay your
mortgage and yes you don't want a neural
network to say you can't pay your
mortgage and then you ask why not yes
because the neural network says but in
that case I think you should use neural
networks the other way around
so instead of just using the neural
network you can say okay for 80% of the
people the neural network says you can
get them of it so we don't have to look
at that
we trust the neural network with the
positives for the 20% of the people that
maybe don't get a mortgage or get
flagged that's when we said when we ask
an expert to look at the case and to
make a decision and that's the same for
a sickness in the trivial cases in the
positive cases you might go let the
neural network decide and in the cases
where it's a negative that's where you
just add an expert at that point in time
and you let the expert double-check what
the network has but it could still be a
youth time saver
other questions yep
I can hear sir
okay the structure of the input in case
of alphago they're actually using the
board itself as an input and it's
basically working like an image neural
network where you split it up into
smaller pieces
that's the convolutional part of it so
the input is basically the the go board
itself and the pieces on it and that's
put in a conflation or network without
going into details but that's split up
until you have individual nodes and they
are using structures so what the neural
network is seeing is certain structures
in the game so it's very visual and it's
also how how professional go players
look at a go board they look at certain
structures that arrive during the game
and that's how they decide if it's a
good move or a bad move or if they need
some defense or offense at certain
points so it's a confusion
all question is is Tara points it's all
statistics and it's all just weights
added together and is there a point
where where it's becoming more than that
I don't think so I think your brain is
just another piece of mathematical
equipment but it's just so complicated
we can really predict but it all depends
on but what you think it is if I look at
what alphago is doing I for me it's more
than just a mathematical thing it's it's
a it's actually be making beautiful
things it's changing a game that people
enjoy playing for hundreds of years in
in new ways so for me it's more than
just a mathematical thing and I can see
the big picture and I can see what's
happening inside it just like I can see
what's happening inside your brain so
it's just label you put on it I think
time's up Thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>