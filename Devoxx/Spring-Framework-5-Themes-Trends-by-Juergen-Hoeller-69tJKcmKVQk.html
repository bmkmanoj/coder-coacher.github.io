<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Spring Framework 5: Themes &amp; Trends by Juergen Hoeller | Coder Coacher - Coaching Coders</title><meta content="Spring Framework 5: Themes &amp; Trends by Juergen Hoeller - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Spring Framework 5: Themes &amp; Trends by Juergen Hoeller</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/69tJKcmKVQk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right well life I was about to say
good morning but it's more like good
afternoon welcome to this well kind of
second spring from a five session after
my my my quickie yesterday this is
actually the one that covers the more
strategic themes so it's they came kind
of an inverse order there's also of
course a connection to other talks you
might have seen today like the spring
boot to the dough talk or the reactive
spring talk all of those topics really
center around what Spring Framework 5
started and what Spring Framework 5
provides the foundation for I'm going to
use a bit of a different spin here so
from my my everyday role leading the
actual Spring Framework open source
project I'm not only intimately familiar
with the challenges in that we're facing
today it's in particular my job to plan
for the next iterations for the next 12
to 18 months anticipating where the
industry is going anticipating other
critical infrastructure releases that
will be released in that timeframe and
how our schedule may react to that when
are we going to pick up those things can
we do forward compatible measures up
front so all of those challenges well in
this industry and never going away at
this always just the next iteration so
what I'm going to talk about today is
what we've been using as the themes and
recognizing a central trends in the
industry for Spring Framework 5 2 though
I'll hint a little also how we we are
going to address the challenges of 2018
but ultimately we we we realize that a
release that we are a major release that
we are bringing to the mainstream now
like Spring Framework 5 2 though
generally available since September now
those kinds of releases are really they
need to be prepared for the challenges
that you are facing that we are facing
and that you effacing in well next year
really when when
when actually most projects many
projects out there are going to build on
this generation of the framework so much
for the 2018 plus part right all right
so just summarizing the hopefully
well-known facts this is basically the
fact sheet read so spring filmic five to
those chase in September it's JDK 8
baselines so we took the opportunity to
revisit the entire code base and make it
Java 8 plus in terms of its assumptions
so it may use Java 8 API features and of
course language features in the core
framework code base now that wasn't
possible before because if you remember
spring framework for even 4.3 is still
Jade looks at JDK six compatible JDK six
seven eight it has lots of JDK 8 support
so if you're using spring framework for
two three on JDK 8 it's going to feel
like Java 8 based framework to you in
many ways and almost comprehensively
right you're hardly going to notice that
it's not Java 8 based but there are a
few things that we can only do in the
framework itself internally can be built
and designed on Java 8 we are you know
and for the three we are constrained by
what we can do at runtime detecting the
use of Java 8 constructs in your code
reacting to it at runtime in your code
so that was fine provided a lot of value
but this is a measure that we have been
looking for a lot right and it's also
showing some value that we're going to
notice in a few places we can start
using Java util function completable
future other API types in Java it in our
core contracts core API contracts and
SPI contracts now so this Java 8 plus
baseline is actually a pretty important
step for us it's also the reason why we
skipped the treat his seven baseline
right there's no spring forever
generation that is JDK 7 plus we went
from 6 plus 2 8 plus straightaway all
right at the same time it's basically a
Java EE 7 baseline in in the
corresponding spec so so read through
that one plus bean validation one one
JPA to that one basically the 2013 12 ie
generation of specifications is is the
minimum that we require now if you are
integrating with providers of those and
we have support for chain unit 5 but not
quite as a baseline yet it's in parallel
to changing it for the 12 support but
definitely check it out when changing is
5 was a long time coming it's really
worth having now we've also been part of
the the group that sponsored the J unit
5 effort last year so we've been really
interested in making it happen and
immediately picked it up with 5 Dadaji
here so that's the whole bass line the
minimum requirements at the same time
there's no coincidence here spring FEMA
5 to dodge went GA in September
shortly after JDK 9 and shortly after
the Java EE 8 specification so shortly
after servlet for the DOE JP 8 to the to
bean validation to the door in Co so we
aligned with the timing of those
initially we planned actually to could
live a little bit earlier but it works
really fine for us in the end all right
so that's kind of the general story
let's pick a few themes that we dive
into a little bit more and in particular
I'll give you a bit of a background a
bit of background on not only did the
what but in particular the why and our
recommendations around it alright so a
central theme was jdk 928 is a baseline
the common jdk out there for years to
come for sure
a new GDK available to us JD King 9
right now and JDK 9 is a particularly
critical almost radical release since
its restructured meant so many things
within the JDK and lots of tooling had
to be updated and of course there are
plenty of features in Cherokee 9 there's
actually a ton of features that has
nothing to do with jigsaw at all right
we'll get to checks on a moment but JDK
9 is a sum of of many features that are
really worth having in the end many
runtime features the garbage collection
refinements g1 is the default now and
http2 ready artists TLS tech
out of the box at the JVM level a the
compact strings feature collection
factory methods map offset of list of
those are all really nice features and
there are plenty of them so even if you
don't care about jigsaw if you care then
stay tuned for a moment but if even if
you don't care about cheek so
continually consider the upgrade try the
upgrade if you're using the latest
framework versions of not only spring
but also say hibernate and mockito and
Co you might have a pretty smooth
experience upgrading to JDK 9 so just
know where you are in terms of
production it's a bit a little bit of a
different matter of course JDK 9 is not
a long term support release so if you're
embracing it right now you will have to
upgrade to be in a supported branch in
March 2018 already on JDK 10 and once
again in September 2018 on to JDK 11
which is the next long-term support
release the next JDK 8 like support
release read so from our perspective
that means that in production lots of
people are going to wait for JDK 11 but
there is an intermediate path try the
upgrade spring framework and everything
that we have an influence on around us
is perfectly ready the spring framework
built itself by the way if you've been a
contributor maybe sent a pull request to
Spring Framework or created the custom
fork for any reason our spring framework
itself the build runs on JDK 8 and 9 the
entire test suite can also pass on JDK 8
and 9 even at this point already and in
case you're wondering spring from a fold
of 3 is not explicitly JDK 9 everywhere
but we've back ported everything that's
necessary to make spring framework for
three applications run fine on JDK 9
even if there's no explicit support
right no yes in version that understands
module infos or anything else but it
actually works fine on the class path
and to a very large degree even on the
module path without explicit measures
just fine-tuning some of its behavior to
BJD keen-eyed forward compatible
but the build of course and all the
special measures are only in spring from
across the dough all right
the chicks our topic is it's a very
significant step being taken at the jvm
level for the first time in the jvm
history there's an alternative to the
classpath Noddy does this good old thing
that lists a eternal not just an a very
long number of potential directories and
Cha files that the JVM can find classes
and resources in it's a really almost
awkward mechanism really if you think
about it but it worked fine for such a
long time in JDK 9 that's the module
path a much more controlled way of
deploying essentially channel files to
the JVM so by putting the very same jar
not on not on to the class path but on
to the module path you're basically
opting into the jigsaw roles the module
path rules every Java file is going to
be kind of wrapped with a module as a
mod into a module at runtime the JVM
actually retains the understanding of
the structure of what you deployed so in
contrast to d2 the class path where it's
just directories and and zip archives
basically when the JVM knows nothing
more about this at runtime in in the
module path world it understands that
there's a sprinkle modulus bring beans
modulus bring context module it knows
the boundaries of those modules certain
visibility rules the names of those
modules the interdependencies between
those modules that's a really clever way
of optimizing the runtime representation
of the archives that contain our classes
and resources once you go onto the
module path be aware that essentially
you have to deploy everything that
you're using on to the module path your
application chars the frame of just that
you're using and all the dependencies of
your framework chars
this works reasonably well with the
current generation of open source
frameworks and libraries out there at
least the ones that we tested what we're
doing in Springfield 5-2 though is that
we actually declaring automatic module
name manifest entries so the the jars
that you get when you download spring
for book 5 to the over maybe in central
basically include a well defined module
name that is being ignored on Java 8 and
in in Java 9 the compiler and the
runtime understands that this is the
canonical module name of this particular
child file otherwise if such a head is
not being provided the name is derived
from the artifact name so like spring -
cor - after though the - the jar it
would drop the version number replace
the - with a dot and you end up with
spring dot core which is actually the
module name that that we've chosen right
it is the name that we declaring an
automatic module name in the automatic
mode enum header the difference is you
may rename the jar files and the module
name remains stable right so we are
providing stable module names as of
spring for mark 5 - though but even in
for the 3 you simply have the filename
derived module names works just as fine
really if you don't rename the archives
so from an application perspective and
that's the whole point in the end right
why do what you care about the module
path well for validating what you
deployed right so that there is no
overlap in the packages declared in
those jar files there's a bit of
validation that comes with the module
system but that's only really a small
benefit the much bigger benefit only
comes then when you start shipping
module descriptors in your jar files
right when you are opting into the
module system in your application code
base so an application might do match it
the module info Java that just has a
name right attached and requires for
example the spring JDBC module
implicitly gets the spring core module
underneath the same can be done with not
only the frame the spring modules of
course but any other open source modules
this is a really nice descriptive way in
the end of an in their concise way of
representing the dependencies very
explicitly that each of your application
modules has
so this is the benefit that we intend to
provide this is what we've been or what
we're focusing on and for that benefit
to be available to you we are already
doing everything that's technically
necessary so it is not relevant for your
purposes whether the framework itself is
really keen on + framework or includes
module info class files doesn't matter
really the only thing that matters is
that you can sing technically do what
this sketch illustrates in your
application modules and that's entirely
possible already so this is a reason why
we chose this compromise to keep the
framework a decade based but provide the
full basically module system value for
your application modules if you if you
opt into JDK 9 and if you opt into the
module path on JDK 9 all right keep in
mind you can happily keep using the
classpath angelica 9 the easiest way of
upgrading is take your existing dedicate
based application set to Java home to
JDK 9 and run it right there's no need
to opt into the motive path consider
wisely whether you go through the
exercise right there's just some pain
waiting for you if you want to avoid the
pain for the time being or even kind of
strategically you might want to stay on
the class path and if you don't have any
issues with the class path in particular
ed alright there's a related topic did I
find much more important and that's
http/2 for some reason in Java Lent we
seem to be having some trouble embracing
http/2 I mean I'm not going to go into
too much details about the protocol
itself but keep in mind that this is the
first major revision of the HTTP
protocol in 20 years
I mean it's really it's over to you is
an understatement right it provides so
many benefits in particular wire level
benefits right like the binary
representation connection multiplexing
hellos compression like sending a
sequence of requests and just saying yes
the same request as before essentially
not repeating the entire text
representation of all your headers in
every single individual request all of
those things are so worth having and
that actually transparent benefits
fortunately a traditional job of way of
building web applications doesn't really
have to be revisited much at all for
HTTP to the servlet abstraction doesn't
need any changes at the servlet API
level in order to have HTTP to
underneath the covers you can run an
existing so every based application
spring web Missy based application very
easily on an HTTP to ready web server
set up and you transparently get HTTP to
benefits for clients asking your server
to talk HTTP to write but that's not a
norm in Java and yet most of our Java
based servers downgrade those clients to
HTTP 1.1 they don't let them upgrade to
HTTP 2 because they are not set up for
it right
HTTP 2 in particular really focuses
focuses on secure connections in the
indie HTTP to world that means that he
LS stack that needs to be ready for HTTP
2 and that is essentially the problem in
Java 8 there's no out-of-the-box tag for
those purposes so they serve it for the
role you might want all right we have it
since September isn't that HTTP 2 ready
well yes sort of right it was designed
with HTTP 2 in mind but it doesn't
actually require HTTP 2 and the real
challenge is to not lie in the servlet
world what servlet for the DOE did is
absolutely fine right it's worth it they
introduced a push build API having this
one specific feature where you can
programmatically trigger pushes of
additional resources to an HTTP 2 client
that's fine but frankly it's probably
the least interesting feature in HTTP 2
it's the one where it's also unclear
when you're even supposed to do it it
might be better to leave that off to
some heuristics at the web server level
anyway all the other benefits in HTTP to
us are way more important
so Soviet for the dough doesn't really
bring much to the table here similar
three that one containers that
essentially fine for having HTTP 200
Easter covers the problem is more to be
found in the actual in the actual
service in the actual containers and
surprise surprise the current generation
of Soviet three that one containers
actually comes with HTTP to set up
options in Tomcat 8 at 5:00 in jetty 9.4
in under 21.4 there they are sometimes a
little bit out of the ordinary what you
have to do right you have to modify your
JVM installation usually put stuff on to
the boot classpath or a set up a tomcat
native up front it doesn't it doesn't
come for free and it's not just a flare
right you really need to set up your
installation accordingly but it is
doable
with all three of them in their current
generations already they are also very
that one based except for Tomcat 9 the
DOE Tomcat nine of those GA by the way
so the first suite for the dough
container out there in the wild
production ready for about a month but
all the other sauce every through that
one contains but can still be set up for
HTTP - by all means consider this at
least try familiar writers yourself what
it would take to enable HTTP 2 in your
systems and if you can choose a soviet
for container like tomcat 9 even better
but not actually a mentor a part of th
eb 2 story that you might want to
achieve right so servlet for the dough
is the bonus the necessity is HTTP 2
underneath the house all right and of
course on to make the connection with
jdk 9 here in chile keen on you have it
here let's take out of the box so
running tomcat hang on jdk 9 or even a
cherry or undertone Cherokee 9 might be
a significantly more streamlined mo
streamlined setup then you might have on
on JDK 8 but then comes to the port
question right GD 9 is a feature branch
not a long term support branch yet so by
all means if you want to do this and
dedicate in production try it
there are ways of achieving it they
might not be super nice but it's doable
and in spring boot to the dough we
started
being explicit HTTP to setup options
out-of-the-box we can't do everything
for you but we were going to smoothen
the path to enable HTTP to in spring
boot paste deployments for you and
spring boot to the dough is about to
enter its release candidate facing going
GA at towards the end of this year
alright switching gears a little in
spring for Mach 5 a very essential topic
at the API level is functional API
design you might wonder functional what
do you even mean by functional well it's
functional in the sense of Java 8
functional right functional API as in
Java util collection streams on JDK 8
that sort of functional right
functionally styled api's with the heavy
use of lambda expressions method
references that sort of API design is
what we mean here traditionally of
course we had a strong focus on
annotation based components this remains
true right so even in Spring Framework
5-2 though there's a strong focus on
annotation based components it's very
first class but also very complete
already so to some degree we wrapped up
all the loose ends in that story in
Spring Framework for the three that's
really very little left that we intend
to add to the annotation based model
fundamentally so from from that
perspective we really took we took
inspiration from functional API design
for Spring Framework five kind of
revisiting the the challenges the tasks
that you want your your framework to to
allow for ready to get the set of
options the registry a registration
needs at the cool container level or at
the web framework level we revisited all
of those topics from a functional API
design perspective which basically
conceptually means no annotations just
for you to take a position right say
like there's the annotation story let's
try something different
no annotations ideally no reflection
no classpath scanning so to have a
extreme position that allows for a lot
of fine-tuning and a lot of gray in
between right of course in practice you
can mix and match the notation based and
the function of the registration
mechanisms you can use classpath
scanning in to some degree you will use
reflection if you want to do annotation
driven interception of a pointer driven
interception without waving right so
there's it we are not being extreme here
we're just trying to explore our options
and to force the core container design
and also our web framework design to be
able to accommodate not only the
annotation base story but also a purely
programmatic functional registration
story this required actually quite a few
measures more than might initially
appear at the surface there are a few a
few new registration methods of course
but there's also a lot of lots of
internal work the co contain is very
efficient in creating instances based on
instant suppliers for example we're not
trying to bridge this anywhere it's a
very straight line so we are not only
trying to allow for this API model we
are trying to embrace that model to the
degree of very efficiently handling it
at runtime a measure that is sort of
related to this is to be is a topic that
I touched upon yesterday it's also being
touched upon in the coupling talk
yesterday is null ability so we
revisited the entire code base and have
very strict and clear not liability
declarations and all spring method
parameters spring API method parameters
and return values so instead of just
having some wedding in the Java doc
there's now a formal at malleable
declaration for every parameter and
every return value that is actually Val
nullable this is enormously helpful in
particular in programmatic API design in
particular in combination with Kotlin
where the Kotlin compiler is one
scotland as a language kind of being
very very suitable choice for functional
registration mechanisms to begin with
read
and kind of trying to be as friendly and
as as comprehensive as we can towards
the coding compiler the coding compiler
can make really good use of clean
lability declarations allowing
assignments to non malleable variables
and so forth so that's the other part
where coupling actually comes into the
picture first here the even at the cool
container level we ship cotton
extensions we're going to see this in
just a moment so what does this mean
concretely right and I'm just going to
illustrate what this can mean right
there there are quite a few ways of
accomplishing such a such a set up but
fundamentally you can start at a very
low level right take a generic
application context in spring that's the
good old generic application context
that also has scan methods and whatever
on it
and reduce the methods for annotation
based classes that you enumerate but it
now also has explicit register being
methods which are designed for a
functional style right
so for example the the little sketch
above says we're registering
a a foo class with default conventions
basically calling the default
constructor we're registering a bar
class and there's a callback which is
actually a Java util function supplier
of bar and a specified as an inline
lambda expression right so this little
line here is what we call an instant
supplier a Java lame the compiler can
say supplier being stored in the bean
definition every time the container
needs a new instance of bar it's going
to call that instant supplier it's not
going to use reflection to choose a
constructor and invoke it it's also not
using factory methods like editing
methods its dispatching to this instant
supplier which is technically not using
reflection it's an invoke dynamic
dispatch straight to your code the
example below is a little more extensive
has a few interesting twists that are
worth discussing it basically does the
same thing it adds a lazy NIT it
basically assumes this is a singleton
being and it's a lazy NIT like as well
but otherwise it's it's it
equivalent but look at the Arista pinfu
one what do we do here we say food you
write might look a little alien it's a
Java 8 method reference right
it's basically a symbolic reference a
compiler reference to the default
constructor on the foo class the
difference is simply in this case we are
not going to use reflection at runtime
because this is an instant supplier MHRA
method reference bound to a Java util
function supplier that we are
dispatching to directly no reflection
involved because technically even class
new instance is reflection right
reflectively calling the default
constructor on that class so just a
twist right if you really care about
those things you can be very explicit
even in this case in this simple case
below there's the instant supplier but
there's a second line and this is the
aforementioned lazy NIT flag right we
call this pin definition customizers
there can't be any number of those
basically typically one-line expressions
the resulting beam definition that is
being registered with the spring Co
container coming in and you can find
healing any of its characteristics this
is the same programmatic registration
mechanism that has been in spring for
ten plus years so it's the same pin
definition model and any tools or any
setup code you might already have that
fine-tune spin definitions could even be
invoked here all right so this is
fundamentally our idea of functional
beam registration now imagine a smaller
micro service with a any numerable
number of components write a reasonable
number say 5 10 15 20 components it's
still feasible to configure them like
this
you may also mix and match this with
scanning you can also register some
components this way additionally scan
for annotated components you can use
annotations on those classes if you
choose an annotation config application
context or otherwise inactivate the
annotation config features in this
generic application context you may also
have this set of code but the class is
like foo and bar that you're registering
internally declare some annotations no
problem with that at all
all right now this is the Java 8 style
of doing this there is a few interesting
examples and I've only picked two as an
illustration of how to accomplish this
with Kotlin this is basically the same
code the same code being called from a
little piece of Coughlin code where you
instantiating the generic application
context registering the foo class and
registering a bar class with an instant
supplier now let's revisit the code
before it we're saying Bharat class and
an instance supplier whereas in the
coupling version we are just providing
an instant supplier just there's a it's
it's a simple simple explanation for the
difference in coupling we can actually
make assumptions about the generics
declared by such an expression in this
case a could kind of be the return type
of a function in Java 8 lambda
expressions we can't so upfront if we're
dealing with a Java 8 lambda expression
we from the outside perspective do not
know what that lambda expression will
produce once invoked so up front we have
to get some extra information what type
it will actually be because that's
really important for the code container
to know so that is the reason why we're
registering while we're specifying an
exclusive bar argument and an instant
supplier in Kotlin that's not necessary
because coding functions have a random
API for proper introspection of the
return types basically refight in Eric's
allowing this richest Bean invocation to
make a clean and reliable assumption
about the actual pin type without an
extra parameter so that alone shortens
it quite a bit right the code below is
kind of equivalent to the code above but
uses a different syntactic arrangement
kind of inline invocations here instead
of the more traditional Java style
invocations I've been dubbing this
Gradle style usage the Gradle style
ticket with a big grain of salt
it's basically because the the Gradle
DSL the Gradle Coughlin's DSL
uses a similar structural arrangement
and it's quite interesting in what you
can do here Kaplan has a few variants
that all make total sense with these
registration api's and the reason why
this code is even possible is that we
are shipping cotton extensions in
several of our chars so when the
coupling compiler is being used with the
spring context char the cotton compiler
picks up certain extensions like generic
application context extensions of Katie
it automatically picks them up files
that are part of our standard charge
that you can get from maven central but
I only the cotton compiler understands
them basically like modeling for the
scripts in JDK 9 only being understood
on trading you know so there are
overloads certainly additional methods
on for example generic application
context that instead of an instant
supplier actually take a cotton function
right so there underneath those covers
there are overloaded methods allowing
the cotton usage model to be more
idiomatic which is the whole point here
and it's very very transparent to you
right so that is basically the lowest
level where we start having cotton
support there's actually cotton support
in in reactor as well there's cotton
support and in the co container the
Scotland support for JDBC template
there's of course also cotton supported
the web framework level in particular
for the web plugs functional API so
we're providing hot then support that at
many levels but you get the idea it's a
core and kind of very a streamlined part
of the standard framework arrangement
that we're shipping in fact at all no
extra charge needed no extra setup
needed just start using Kotlin and
everything else happens by convention
alright a topic you might already have
heard quite a bit about right if you've
been to previous previous sessions today
in particular or to the company in
session yesterday they sprinkled in
session yesterday is our reactive focus
some I'm also going to touch a point
here but coming from a different angle
and kind of trying to wrap up the story
from a different perspective here
so the motivation why we even go into
this it's interesting for a start right
so why why are we doing this well we
believe that there are requirements out
there for modern web architectures that
are really hard to to satisfy in in a
traditional web stack servlet based web
stacks come with a lot of assumptions
and so that's our basically an
abstraction the abstraction sort of has
a has quite a bit of baggage with it
right the assumption that there a
request is being processed by being
assigned a threat processing that
requesting that threat returning that
thread to the threat pool so we
basically own the thread for the entire
lifetime the entire server side lifetime
of that HTTP request this comes at a
price if you're doing blocking
invocations to some data store or in the
micro service architecture to some other
micro service you are basically waiting
you're doing some IO operations and
you're waiting on them to come back to
you then you're blocking one of the
threads in the server containers where
pull write one of those endpoint threads
with appropriate fine-tuning and there's
quite a bit that's possible in the
servlet world but there's actually a lot
that's possible in the separate world
right um so with corresponding measures
you might get pretty far with this but
there's a limit to how far you can take
it in extreme scenarios with a very high
number of clients very strong latency
involved lots of external systems to be
waited upon in such scenarios you might
not get very predictable behavior on the
high load whereas in a reactive
architecture it comes with different
qualities you have to code differently
to architect it differently but by its
design you will get more reliable more
predictable behavior even under extreme
conditions so it's we could spend the
entire hour talking about the motivation
for reactive but an inspiration for us
of course has been the what's being
called the reactive manifesto I'm not a
great fan of manifestos myself actually
but it really hits a few
key characteristics the idea of
responsiveness and resilience is
particularly essential here
responsiveness even to late coming HTTP
requests - in highly loaded server and
resiliency in terms of being able to
recover from almost any Arrangements any
any challenges that your server might
have faced even under under extreme
conditions of course the manifesto is
just a bunch of statements are at a
bunch of text more interesting is
something that followed from it is the
reactive streams initiative which
produced an abstraction on October 8th
or a live stream so the work as a
website right living in the orkut
reactive streams java package this co
abstraction models the intern sensual
part of a reactive processing stack the
interaction between resources in
particular a concept called back
pressure a kind of a level of flow
control between a publisher and the
subscriber in a reactive processing
architecture so reactive streams are in
a fundamental building block they they
basically literally consists of just a
couple of interfaces just a few methods
they model just the essentials of
runtime into action and interaction in
such a stack basically a publisher it's
only going to start publishing elements
once a subscribe is actually ready the
subscriber keeps taking elements if the
subscriber is currently blocked cannot
produce any further results to its
output to its its its clients for
example writing back to the HTTP
response stream then it's basically
going to say thanks your publisher
stopped pumping data my way with this
kind of model you'll typically have an
event loop backing it so very few
threats but those threats are always
busy because they are only being invoked
if a step can actually be taken you
never wait on something basically always
just back out and you're being really
invoked once the particular streams are
ready to process for the data reactive
streams are very low-level
so you're not going to work with this
directly your typical ego use a reactive
composition library that builds on
reactive streams underneath the covers
and our choice of reactive Colonel here
and directive API level is reactor in
spring for Mach five to do we actually
use reactor three that one already so
react already had quite a bit of history
reactors basically a sort of all
alternative alternative to ours Java red
it's kind of a modern-day server
oriented Java 8 baseline and reactive
streams from day one composition library
our extrav already has a bit of history
predates reactive streams it's still
Java six compatible because of its
Android Android user base so as Java is
constrained by different forces whereas
in in reactor land we're really focusing
on the same targets the same purposes as
in spring framework itself so we'll see
reactor shining through in just a moment
but let's talk about the reactive API
types first there's a bit of confusion
out there an all correct extremes
publisher
it's a very low level very minimal API
right but it publishes very essential
basically everything that you typically
interact with like an Rx Java flowable
or a reactive flux or mono is a
published implementation but you'll
always typically always use concrete
implementation that allows you to
actually express some concrete
operations so in reactor those concrete
API entry points both of them publish
implementations are called flux and mono
flux basically and sort of open-ended
stream of a sequence of elements and
mono just a single element or none so if
you an traditional are extravagance peak
that would be observable versus single
basically or a completable future is a
sort of variant of mono without back
pressure I think you could argue or if
you want an another comparison that I
put in here is like in the nonreactive
world right travel util collection
streams well there's a stream and this
Java util optional right the same kind
of idea sequence of elements single or
non and in our Java 2 it's fluid low
maybe there are plenty of those types
out there they all have their role
and they are all actually supported in
Springfield fives Webb flux framework
right so in annotated handler methods
you made this you choose to design your
methods with a particular API you may
choose to follow our recommendation of
reactor and use flux and Buono API types
you can also choose rxjava two types
arch travel one types in to some degree
even completable future so essentially
the the web flex framework that I just
mentioned is our reactive web stack in
Spring Framework five another important
piece of clarification spring for Mach
five comes with two distinct web stacks
there's the traditional spring MVC stack
to be seen on left here and there's what
we call spring wet flux on the right
both of them share a lot of they share a
lot of design they are aligned to quite
some degree they can be used with a very
similar endpoint model on top but they
are separate stacks with distinct
characteristics these things that
distinct kind of their own strengths and
benefits right the spring MVC stack
spring weapon BC remained servlet based
as it always was
if you hexif existing spring weapon with
CPS code just keep using spring weapon
BC and literally the spring - weapon
missing module on spring fan Mach 5 and
everything is servlet based your choice
of server container underneath the
covers the servlet API shines through to
the to the usage model right to your
components your handler methods may even
declare HTTP server to request or to the
observed response arguments very clearly
servlet based over here there's web flux
web flux is based on a reactive strings
foundation and reactors a kernel so it's
based on reactive stream interactive
strain interaction model and an event
loop underneath the covers no servlet
API shining through to any higher level
in particular there may be a very
similar usage model on top like our
annotated controller request mapping
model that can also be used on web flux
but it's adapted to this
reactive runtime underneath the covers
and has to live it has to be designed
for reactive interactions so it may look
similar but it's not as similar as it
may look right because iSpring weapon we
see controller typically does blocking
things it calls a JDBC operation it
triggers a cheapy a operation if if you
are designing for spring weapon we see
that's totally okay thread panel
transactions no problem right JP a JDBC
no problems stay on spring web PVC
essentially but if you can use a
reactive data store reactive HTTP
clients talking to other services of
yours if you can compose your web
endpoints to use non-blocking api's
underneath the covers then web flux
becomes interesting maybe you've already
got a data store driver that data store
drive is maybe our extravagance returns
our travel observables oh and ours two
other two fluids to you you can expose
those to the spring web flextec directly
they are a natural part of a regular web
endpoint model so there may be many
reasons but my favorite perspective is
this bottom-up perspective you've got
reactive data stores and reactive like
HTTP client api's for example for your
other services that you need to call so
from that bottom up motivation you might
want to design a spring web flex based
arrangement of web endpoints that are
reactive from the bottom basically from
the data store level to the HTTP
endpoint level in order to reap the full
benefits so what does this look like in
the annotation based world a rack of web
controller initially looks very similar
to a spring MVC controller you actually
have like even though I mean I usually
have to look twice to see the difference
because they are using the same the same
structure controller and points
controller notation are mapping
annotations get mapping post mapping and
Co as commonly used in spring framework
for the three but what the methods
actually do is different those methods
here seem to hold this is basically just
a sketch right they seem to call an API
some repository but that repository
doesn't load the user we asked for a
user
but what we get back from the repository
is a mono of user a reactive type right
we're basically getting a handle that is
capable of loading the use of for us
director streams publisher being able to
publish the user we are passing that
back to the spring web flextec and the
spring reflects tech knows when to
invoke it right once the HTTP streaming
Direction is ready to actually handle
the outcome of the rendering that we
need to do for that user object then and
only then we're going to trigger that
publisher take the object send it
through the codec step and render it out
to the HTTP response with a full back
pressure model running in an event loop
so the get user method
represents a single user or potentially
non that's why we chose the mono
representation here get users asks some
repository underneath the covers here to
load all users can be any number of so
we're using flux as the representation
of course you just at this very point
you could declare a public flow a block
user in our Java to flowable the spring
web flextec natively understands what
you mean right understands our travel
one and archetype two types that you
return from those endpoints for example
because your repositories or your client
API that you're using natively returns
our exchange us pass them through we
adapt them for you so annotation based
controllers are structurally similar but
the a design for a reactive world they
are meant to essentially return reactive
streams publishers for the particular
response that they are about to produce
an alternative model that the diagram
hinted at before is what we call router
functions or functional web endpoints so
rather function has an entry point this
is a different way of consuming of
tapping into our reactive web stack so
instead of using a notation based model
in the dispatcher handler that
understands those annotation based
mappings instead of that we use a very
straightforward functional setup
functional API that we call router
functions and handler functions so if
you look at this little piece base
he models the same end points as the
annotation based slide before it says
once a users a slash user slash some ID
request comes in dispatch this request
to hand a delegate get user a Java 8
method reference which is this method
down below and for another route if just
slash users comes in let's dispatch to
the get users method both of them need
to implement handler function handler
function is a server request going in
and the amount of server response going
out so for Java 8 method references to
work this is what we intend to do here
we need to follow that we need to comply
with that signature right that's why
both of them have the same signature
there's no way notation based model here
you can't do it request per am no
flexible signature sorry in the
functional world there's a strict
cleanly define the API and you have to
comply with that API so what do those do
like to find all method for example
those it's flux of user and then
programmatically bills as you ever
responses status ok here's the body the
publisher for the body elements and for
the codec step it's Java 8 after all and
travel after all no refi generator so we
need to pass in the user class to tell
upfront that it's supposed to be
converted to a user for get user there
are several ways of of coding this but
essentially you're asking the requests
to extract the path variable ID you're
converting that ID to a long because
it's natively a string representation
and then you dispatch to your repository
find by ID with the number and you
return the mono of user coming back from
this then you build a server response
for it in a functional API design or a
Java util collection stream style API
design this is a very natural thing to
do so this is the method reference
variant might look a little bit alien
maybe this looks less alien this is the
very same code just using Java 8 lambda
expressions right in line lambda
expressions so the router says route
users ID and here's the same code but
now in an in line lender the signature
disappears which is nice right requests
coming in produce the server response
and for the other for the other route
same ID
right so the signature going out of your
way the functional model sits in
parallel to the invitation based model
right so it's your choice of how you'd
like to consume the wet flux facilities
that we're providing to you the
annotation based models of course very
nice for a higher number of endpoints
that you want to pick up in a
distributed fashion from several places
all across your codebase the annotation
based model has lots of benefits the
flexible signatures but for smaller more
micro service oriented unit just a few
endpoints that you're modeling two three
four or five maybe ten endpoints this
sort of Java based DSL here can work
really fine
in particular if your weapon points
essentially just delegate to some code
underneath and adapt a few parameters so
it's a totally different way of coding
the routing information and the handling
information for your weapon points but
uses the very same facilities the same
codecs everything else underneath the
covers and I've for the sake of timing
we're not going into coding examples
today but you may imagine there's of
course a cotton extension for the style
of DSL and this is particularly sweet
when being used with Kotlin has actually
been shown in the spring cutting talk
yesterday last but not least
quick quick reference because it's often
forgotten we all chip a reactive web
client an alternative to rest template
because rest template essentially is a
kind of blocking style interaction API
we have a new web client stylistically
very similar to the functional web pain
point model on the server side that you
can use to build a HTTP indirection from
the client side and since it's the same
style of API design what you typically
get out of it is a reactive streams
publisher a reactor model or a reactive
flux the same kind of idea applied to
the client side to the client side of an
HTTP interaction so that's also part of
the web flex module to provide a very
complete picture so the spring WebM is
seen rest in plate basically and there's
the spring web flex server-side modeling
notation based the functional API model
for web blocks and there's also a
functional
style reactive web client in web flicks
all right so much for what I intended to
show in this to today thanks for your
attention
just quickly summarizing that all of our
the aforementioned
features and design variants are
available in spring for Mach 5 the doji
a so 5 the dough which is GS in
September already with the baselines
attached if you're on JDK 8 and on a
recent Soviet container you could just
straightforwardly
operate your application from for the 3
for example 2 5 2 though if you have
existing spring weaponry C code try the
upgrade on web M you see first if you'd
like to if you'd like to try to
familiarize yourself with wet flux be
our guest right now is a great time to
try this there are many pieces in place
not only the web flux here in spring
framework itself
there's also spring data k our spring
data system project with its repository
abstraction having a reactive repository
variant for all data stores that
actually support reactive drivers
underneath for example
MongoDB and Co so the there are many
pieces in place spring boot to the dough
of course wrapping up spring from five
taking spring data k combining them into
its world is about to kochi a towards
the end of this year also with a full
reactive story right but it's one usage
model it's still your choice even in
spring boot to the dough it basically
provides all of its facilities either in
the server burst servlet based web stack
world or in the reactive web stack world
and as mentioned start thinking maybe
stop thinking from the data store level
alright if if there's a reactive data
store reactive driver for your data
store that might be a strong motivation
to try the web block stack if you keep
using traditional JDBC drivers or JPA
other blocking api's stay on WebM you
see don't even think too much about it
there are ways of combining those those
things right we have some support for
reactive publishers rate of streams
publishers even in WebM you see we are
adapting this to the server through that
one aging stream model so if you have a
Rick a reactive driver for certain
part of your service you can even expose
the sins bring weapon we see there are
many ways of building combinations of
those texts according to your
requirements in web blogs which we
haven't explicitly mentioned yet you
also have a choice of providers
underneath you may for example choose to
use neti as the most capable networking
library out there but you may also use
Tom Couture Chetty or undertow core so
wet flux actually comes with a choice of
HTTP engines and the methods reactive
streams based architecture and you might
want a tomcat jetty when up those
servlet containers why can I use them
underneath wet locks well Tomcat and JD
are fundamentally HTTP servers HTTP
engines if you're using them in a
reactive stack you're not using them as
a servlet container you're using them as
the HTTP engine for a reactive web stack
and in particular on target with where
we have several Tomcat committees in our
Y that him at pivotal in target there's
a lot of work that specifically went
into improving tunk tunk its usability
suitability for reactive web stacks the
chatty guys are really interested in
alternative usage models for their core
HTTP engine in undertow there's even a
separation of under 200 and anger to a
servlet if you're using the reactive web
stack it works with undertow code
directly there's no need for the
undertow sibley bridge and of course
nettie remains everybody styling right
if you the the most capable most
customizable most human bill networking
stack out there of course is Nettie so
the for this choice of containers we're
not making a strong recommendation but
Tonkin and Eddie might be good starting
points for a start so basically make
make your pick or follow of boots pick
boot to the dough speaking in that
respect so don't don't be scared there's
a lot of power waiting here a lot of
choice and a lot of power that comes
with it I hope you enjoying the power
that we are giving to you here and let
us know how it goes
and how those things make sense in the
particular
architectures that you're designing
thanks for your attention enjoy the rest
of the show</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>