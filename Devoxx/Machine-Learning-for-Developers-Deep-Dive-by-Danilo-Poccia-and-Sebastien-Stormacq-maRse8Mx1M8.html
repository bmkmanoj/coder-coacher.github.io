<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning for Developers - Deep Dive by Danilo Poccia and Sebastien Stormacq | Coder Coacher - Coaching Coders</title><meta content="Machine Learning for Developers - Deep Dive by Danilo Poccia and Sebastien Stormacq - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning for Developers - Deep Dive by Danilo Poccia and Sebastien Stormacq</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/maRse8Mx1M8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so good afternoon maybe welcome back if
you were there in the first session that
we held this afternoon at two in the
same room my name is siliceous dogmatic
I'm solution architect working for
Allison in the Alex a team my my I'm
helping customer to develop Alexa Alex s
skittles good afternoon again my name is
Danilo and part of the Technical
Evangelist team in iws and this second
session is completely unplanned because
we were asked to cover for for a speaker
was not here so we are taking this
opportunity to dive deeper into the
technology that we use in the demo today
so on the Alexa skills of the voice
recognition platform on one side and on
machine learning on the other so just a
quick poll would attend the first
session at two p.m. this afternoon half
of the room okay if you didn't attend
don't leave now we try to catch up
really quickly on what we said not too
long to not bore the other ones but just
to give you enough overview of what
we're talking about so what we cover in
the previous session there was a very
long and boring introduction that I
delivered on machine learning just after
lunch the idea was to have clear the
terminology the use cases and how you
can use machine learning to learn from
data then we moved into creating a model
it was a bike sharing model to
understand how many bikes were used in a
bike sharing in a town we use data set a
public data set from the town of
Washington in the US and then we built
an app using a lambda function that was
used by Alexa with a voice interaction
with capabilities and what we are going
to show you now is really step by step
instruction how to create a lambda
function how to create an Alexis killer
and that will be the first part the
second part the needle will come back to
the to the machine learning and the data
model using a different that I said to
be
the different data set instead of
regression i will show binary
classification that it's very common use
case ok that's the menu for the next
hour thank you for being here we are the
last obstacle between you and the drink
tonight and the end of the day so this
is the demo that we use the architecture
we use for the demo during the previous
talk I was talking to Alex ah I'll
excited the speech recognition in the
cloud and send an intense which is
really the meaning of what you said to
some code that was happens to be hosted
on on AWS in a lambda function and I
will talk back about lambda that lambda
function was querying a weather forecast
API and was calling the machine learning
prediction model bit by danilo to get a
prediction about how many bags would be
available or used in a specific station
in Washington DC that was a setup and
during the next 20-30 minutes we are
going to talk about the left side of the
of this graph how to build a scalar how
to create a lambda function i would not
write code in front of you i will use a
template but we are going to go through
all the steps in the console so how do
you create your first alexis kill for
those of you that we're not there before
just how it works is that the flow is
the following I'm talking to Al exam and
Alex I is just a bunch of microphone a
speaker and a network interface that's
an echo device and the echo device talks
to Alexa who lives in the clouds alex is
the Alex a voice service it's free and
open API from amazon that everybody can
use as long as you have a device with
some compute capability is a microphone
speaker and a network interface you can
interact with we fed excel so this
device are built by amazon and are
interacting with al exam Alexa will do
the hard things which is the speech
recognition and natural language
understanding speech recognition is
going from what I say to a couple of
text words and the natural language
understanding is the second part of the
process it's to transform my words into
some intense what did I mean now if I
say Alex a play music it has recognized
that play
is the verb music is what I want to play
maybe I can say play Michael Jackson yes
to recognize that Michael Jackson is an
artist so it's giving a meaning to your
words so we are doing that on the cloud
and we are of course running on AWS to
do that and if we detect that the intent
is for your skill we will send a JSON
document or JSON request to your code yo
code might be hosted anywhere on this
planet any endpoint that can talk https
receive a JSON document and give back a
JSON document is valid to implement an
Alexis Killa of course we are amazon so
we love when you deploy your code on AWS
but once again it's not mandatory you
can run on premises you can run in
Google Microsoft IBM cloud provider that
that are out there your skill code then
must do something if you are ordering a
pizza your skill code will probably call
the domino pizza API if you are building
a skill to call you burn a you bercow
your skill will call the huber api to to
order a car what you doing your skill is
really dependent on the user interaction
and the function 80s you want to provide
to your customer but at the end you must
return as a JSON document so the output
of your skill is JSON the command we
will process that reason documents in
the cloud and we will generate the voice
of Alexa in a text to speech or you give
us text and we generate the voice of
Alexa in deployed and restream the voice
back to the device well that's the wrong
explanation all that happens in a few
milliseconds the time to trim to the
cloud correo code and go back with with
text so when you create a skill there
are two parts in the skill the first
part is the code and we are going to use
a lambda function written in OGS to do
this demo the second part is the voice
medela the voice medela its mix of three
different things intense utterance and
slot the voice model is what will help
Alex I to understand the dialogue and
the type of phrase you expect your
customer to pronounce so you have to
create a design for the voice
interface for the voice interaction and
this design is made of three different
parts intense you Terrence's and slots
the intents are the function inside your
skill you are developer so you know what
a function is if you are building a
skill to order pizza you will probably
have a function order something function
about status function about payments
these are the intent you define intend
by just providing a JSON document in the
Alex a developer console like this one
but I will create something more complex
in front of you in a minute to support
these intense you need to give some
hints to the alexa speech recognition
system so that we can better understand
what your customer will prone on so you
need to give us sample utterances it's
all the phrase you expect your customer
to pronounce to interact with your
skeleton and we will map these phrase to
a specific intent so it's very common
for intense to have hundreds of sample
lutherans all the possible variation
correct or not correct at grammatical
level that you expect your customer to
pronounce to do to interact with with
Alexa whenever we will hear say hi or
say hello of say good morning we know
that we need to map that to your hello
intent and what we are going to send to
your function it's the hello intent and
of course all functions in programming
in Alexa in all part of life or
functions f parameter and these
parameters we call that a slot if you
order a pizza you might expect with a
parameter which is a type of the pizza
if you are predicting the number of bags
that would be available that would be
available at a bike station maybe you
expect a date and a time as a parameter
to your intent so you can create your
own parameter your own slot which is a
list of value you expect your customer
to pronounce and to give to Alexa or you
can use one of the predefined as slots
that we have like date duration pincode
first name country name city names and
we have a growing list of built-in slots
that's enough for the theory no let's
do some hands-on and try to create a
favorite color skill so the skill we
work like Alexa open my favorite color
scale and Alex i will answer me hey what
is your favorite color we'd say red and
she will say ho your favorite color is
no rate I will remember that you can ask
me what is your favorite color I will
say what is my favorite color and she
will answer me right so it will show you
the basic construction of a skill using
the intense the central you Terrence's
and slots it will also you show you some
concept about session management because
it will remember value between two
different questions I will say my
favorite color is red and then in Sudan
Fraser we say what is my favorite color
and she will answer me right so she will
keep state of my dialogue she will keep
some value from my dialogue I was about
to say in memory but it's not really in
memory I will give more details ok let's
go the first part is to create a lambda
function to create a piece of code that
will receive some JSON document when you
talk to Alexa and that will give back
some other JSON document as a result of
your code execution and i will use
lambda to do that for those of you that
are not familiar with lambda lambda it's
called a service we can define that I'd
addto-container for your code as a
developer you write code you upload the
code to lambda and that's it we do take
care of running that code for you in the
cloud so we do take care of the
underlying infrastructure of course
there are virtual machines but it's
totally hidden from you of course there
is an operating system but that's
totally hidden from you we will run the
code for you we will take care of the
high availability of the code your
lambda function will always be available
and we will take care of the scalability
of that code so if you are calling if
you have a lot of calls in parallel in
the lab in the alexa world for example
if you have many customer interacting
with your skill you will receive a lot
of calls in parallel we will scare your
lambda function automatically for you so
you as a developer you don't have to
take care about
these low-level infrastructural details
such as such as high availability of
scalability so let's create our first
lambda function I am in the AWS console
which has a lot of different services by
the way this is a new console if you
didn't see it yet just click on on
lambda and you have a list of function
that are already created let's create a
new one one very easy way to discover
lambda aids to use one of the blueprint
we do provide blueprint it's just a
template it's a predefined lambda
function and actually for demo this is
really good this is what i'm going to
use today because i don't write one too
right no GS scripts in front of you so
let's search for a lambda function
called Alex a skill Kitco lata expert
and you can see from that that we have
two different templates one is in low GS
and the other one is in a bite on to dot
7 so let's take the new gs1 the second
step is to actually define what are the
service that will be authorized to call
your lambda function we don't want
anyone on these planets anyone connected
to the Internet to be able to call your
code you want only the AL accessories
running in the cloud to run your code so
when you create a lambda function you
have to tell us you have to tell you WS
what will be able to rise to call your
code and we call that the triggers so
you have to configure the trigger and in
the list of trigger we have Alex a
skilled kit so if you want to create
skill you define Alexa as one of the
valid trigger for your for your function
the next step is to give a name to your
function Alexa go wrong demo and you see
that the code is already populated for
you so if you have a very simple code
you can edit your code directly inside
the AWS web console of course in real
life you will probably not do that you
will use an IDE and we have an API that
allows you to upload a zip file and we
fall dependencies that you need for your
function instead of just editing the
code there once we had something about
lambda B form
into the code now I think we can show
afterwards the different parameters to
kill on the phone let's create let's go
down to the code level then in the order
of the screen this is a very simple
skill so we are taking care of all the
basic low-level stuff such as passing
the incoming document generating the the
output answer the core of the scale is
here at the bottom export handler this
is the entry point of that code and
basically we are going to inspect the
JSON document that we receive and based
on the type of request that we receive
we will call one function or another
function within the code in real life
you will probably not write something
like that because with sdk with an o gs
sdk which hide that for you which
provide a higher level programming
interface all these routing and jason
analysis and routing to correct function
is part of the no GS json sdk but it's
very good to learn because when you're
going through that code you have to go
through the details and understand
exactly what's happening behind the
scene so depending on the request you
receive it might be a launch request the
launch requests it's when you say Alex
are open and the name of your skill
that's a launch request and we will run
that too on launch method you can also
receive an intent request an intent
regreses when I'm answering a question
to a lexer so I say Alex I'll open a
color or demo she will say a give me
your name of your favorite color and I
will say my favorite color is red that's
an intent request my favorite color is
red red being an attribute slot so I
will route that too on intent JavaScript
method and the same for session ended
request so if we look at the on intent
function it's basically a dispatch it's
big if then else statement that we look
at the intent name you might have
multiple intent for your code multiple
function and we'll just dispatch that to
the correct function so if the intent
name is Michael or is into
we go to set color in session function
if the intern name is what's my color
intent we go to that function and that's
reverb these are the basic stuff that we
take care for you in the internal GS SDK
but it's good to go through that once in
your life to understand the logic behind
the scene from there we prepare the the
the answer so we prepare the speech
output I know that your favorite color
is blah blah blah blah blah and we call
a function called a built speechless
speech late response which will prepare
the JSON document that all function will
return back to the Alexa voice services
so pretty simple code there is what
comment include there is 250 25 line of
code the entry point for that function
it's the antler its index dot antler and
I need to tell I need to tell lambda
which permission to use so warning this
is more advanced AWS if you if you are
lost with that don't don't worry when
you execute code within lambda you need
to give permission to your code if your
code interacts with other aw acpi so you
need to tell explicitly that you
authorize your lambda function to call
other AWS API how do you do that with
with AWS in general you are using roles
roles just a container for permissions
and I have a role already defined called
lambda basic execution that role give my
lambda function just enough permission
to interact with the logging service
from AWS cloud watch looks so that
function will have enough permission to
put to write logs to cloud watch look so
I will be able to see what's happening
within my function and actually we do
that for you almost automatically
whenever you use console dot log in in
JavaScript or prints or the logging
framework in Python we redirect that to
close watch log so you need to give your
lambda function and of privilege at
least to write to the logging sir
this and this is what that lambda basic
execution role is doing and we can
create that role for you if you if it
doesn't exist yet the last part of a
lambda function is the size of the
memory that you will allocate to the
runtime environment of lambda so when
when you will execute that lambda
function well we will execute that
lambda function how much memory do you
want to allocate to the container that
will run your function and you have the
choice between 128 up to 1 dot 5
megabytes and we have a kind of
one-to-one mapping between the size of
the memory and the the CPU allocated to
your function as well I don't know the
number of sort of my head I have to go
back to the documentation for that but
the idea is that if you locate a small
amount of memory you have a low amount
of CPU power as well if you allocate a
bigger amount of memory you have more
CPU power so you your function might
execute a bit faster if it is CPU
dependent there is also an impact on
pricing during the first session this
afternoon I told you that the pricing
model for lambda it's based on the
number of invocation twenty cents I'm
talking in u.s. dollars and we fought
v80 so twenty cents per million of
invocation so every time you invoke a
lambda function a million time we charge
you for twenty cents except the first
time so the first median is free every
month that's part of the free tier of
AWS so you don't pay for the first
million invocation per month to be
complete it's not totally accurate the
number of invocation it's not the only
pricing for your lambda function because
if your lambda function is running for
two minutes or if your lambda function
runs for 200 milliseconds it doesn't
involve the same resource usage on all
sides and the general rule at the ws is
that anything that consume resource on
all sides as a price for you that's
pretty honest and pretty fair so if you
are consuming more CPU you will be
charged a bit more so on top of the
invocation price there is a very small
tiny tiny price per CPU cycles that you
are using within your lambda function
and we charge you per one
milliseconds of execution time and the
price depends on the size of the
container so small container will be
charged less than a larger container
don't ask me about the exact price
that's exactly the type of information
that i can not remember but with full
details on the lambda pricing page if
you google that AWS lambda pricing you
will find the details of the price VPC
for those of you that knows about AWS
this is a private network that you can
build inside the clothes we are not
going to go into these details so just a
quick review the trigger of that lambda
function will be the alexis calc it
alexa culo de mando GS for the three the
role the memory the timeout let's create
that function creating the function is
almost immediate so i can see the code i
can see my configuration I can see my
trigger I can change all these as well
but I can also test my function directly
from from that console so if I click
test here I can prepare a JSON request
that will be sent to my lambda function
and you so the Alexa requests in the
previous talk maybe it's quite long it's
quite complex I don't want to type here
something so error i can copy paste from
something i recorded previously or we do
provide sample request as well so if you
click on sample event template we do
provide templates for different type of
events that can trigger your lambda
function if you scroll down to the Alexa
section you see that we have a start
session and session smartphone control
and micro roles intent that's exactly
the requests which will be sent when I
will interact with that skill so we have
a session with a user ID and application
ID and of course we have the intent and
the slot so this is a my color is intent
will define that in a minute with a
color lot of value blue so this is
exactly what Alex a voice service is
sending to your skill when me as a
customer i will talk to Alex are saying
hey Alexa open my favorite color Alex I
will ask me what is your fav
ridker oh and I will say my favorite
color is blue when I say that the speech
recognition and the natural language
understanding will transform that into
this what you will receive your code is
that JSON document saying that the
intent was that intent that's what we
hear and that's what we recognize and
the value is blue the value of the slot
is blue so let's invoke that lambda
function with that JSON code I just can
click save and test and see what will
happen we see the execution result here
and the execution result is another JSON
document that's the one generated by the
my lambda function this time it's a
response with the output speech I know I
know know your favorite color is blue
you can ask me your favorite color by
saying blah blah blah blah blah blah so
that's a very convenient way to test
your lambda function you can do that
from an API you can do that from the
command line as well it means that you
can integrate you land the development
into a real development workflow with
continuous integration or continuous
deployment escuela everything I'm doing
here in the console as an API so
everything I'm doing right now in the
AWS console can be automated at all from
the common line error with through or
pressed based type of of API so now that
we have some confidence that the
function is working and returning a
valid answer by the way you can see the
log file that has been generated by the
function as well we receive an intent
this is the request ID the execution
time was eight milliseconds I'm sorry we
are charging by 100 milliseconds so we
will charge you for 100 milliseconds of
execution time for up for that when I
say charge it's really a 000000
something / / 100 milliseconds of
execution I have some monitoring
information as well the number of
invocation the duration of the
invocation because these are two
important metrics not only for your
customer in terms of latency and the
experience they have but also for your
credit card because these are the two
metrics that we are using to
to Bill you at the end of the month you
can monitor the arrows and you can
monitor the number of invocation that
have been throttled Trotter means if you
have too many concurrent invocation we
will kill them so we will throttle them
a bit I don't remember the limit i think
it's a 100 per default is 100 concurrent
executions but it's a soft limit that
you can increase is there more to avoid
maybe a human error if you launch too
many functions and you don't understand
so they're happy to increase it the
limits that we are putting on all
service is not to bother you it's just
to protect you from shooting you in the
feet because it's quite easy to write a
boogie script it's actually much easier
to write boogie script and a correct
line that will invoke your lambda
function and you don't want to have a
bad surprise at the end of the month
because you have your writing you have
written some some you know incorrect
code ok that's the part for my lambda
function my lambda function receive a
JSON documents and back response ready
to consume by the ethics of a service so
now let's create the skill and to create
the skills I'm sorry I need to switch to
another console and this is not the AWS
console anymore this is the Amazon
developer console so the address of that
console its developer at amazon.com the
good news is that if you have a retail
account if you are shopping on Amazon
you already have an account but to use
that as well you can just reuse your
email and the password to access that
console you click on Alexa and Alex a
skill kit the difference voice service
is if you are building hardware and you
want to integrate the Alexa experience
inside your Harbor the skill keys if you
want to bring another capabilities and
other application to the Alexa platform
so let's create a skill you see that i
have already two skills and i will click
here add a new skill on different type
of skills will not enter into the
details given the time we have but we
are creating a custom interaction model
you can choose your language as i said
earlier this afternoon we do support us
British English and German and we'll use
British English because this is what my
echo is configured for my dots let's
give a name column demo
the works and let's give the invocation
name the invocation name is really
important because this is what your
customer will need to pronounce to start
your application to start your skill
when you say Alexa open my coral demo so
I will need to pronounce Alexa open mic
or demo or alexa ask michael or demo
what is my favorite color so this is the
name that Alexa will recognize and based
on that name we know that the intent is
for your code and we will rue the
request to your code next next I need to
give my intent schema so what are the
intense i'm going to support in my skill
my custom slots if i have any and the
list of sample you Terrence's so for
this demo will cheat a bit and copy
paste these values because once again i
don't want to type that in front of you
so i have an intent schema ready here by
the way to public URL if you search for
a color demo Alexis skill on Google you
will find that it's a step-by-step
tutorial that you can follow to redo
what I'm doing here right now when you
will be back home tonight or tomorrow
night my intent apps so let's have a
look at that I've my color is intent
this is when I say my favorite color is
blue and that intent has one parameter 1
slot of type list of color I also
support what is Michael or intent and
help intent not is that this one start
with amazon it's a prebuilt intent you
can you have to implement that in yours
in your code but you don't have to
define any sample utterance for that
talking about sample you two runs let's
copy my sample you transform I to intent
I just told you that amazon help you
don't you don't need to provide any
sample you two runs for that so i have
to intend what is what's my color intent
and I expect the customer to say get
Michael or get my favorite color or give
me Michael oh in real life you must
generate hundreds of these and it's
quite easy to write a Python script that
based on couple of patterns
these the more you have the better the
speech recognition will be so the more
accurate speech recognition will be this
is a very bad example for example the my
color is intent we have only one sample
deterrence my favorite color is red or
blue so it means that i really need when
I will answer and exert to give that
sentence if I'm giving something else
Alex I will not be able to route what
you say to that specific intent so for
demo it's good in real life it should be
a big red flag on your development to-do
list when you have only one sample you
pterence for an intent let's create my
list of color custom slots so that's the
type list of colors the type that I've
use here list of colors and let's give a
couple of values to that it's not a
close list of value it's just some hints
for the speech recognition system to
recognize what you're expecting but if
the customers a banana and we have a
quite hard confidence that we correctly
here banana your code your skill code my
receive as a value banana even if banana
is not in that list so it's not a close
least it's an open lists just a guide
for us to guide the speech recognition
engine and click Save notice that the
safe can take one minute or two minutes
because we are really building a binary
representation of that voice model and
we will inject that at runtime
dynamically on the customer account when
the customer will actually activate or
enable the skill on the on their account
so there is some background processing
there we collect this value and we
create something that will be inject in
the speech recognition system at runtime
and we can see it's successfully update
the time depends on the time of the day
because we have a queue and it depends
on the complexity of your model as well
obviously the more complex issue is your
model the more time it needs to build
last step before testing that skill is
to tell the skill where is your coat
where should I call
where where should I pass where should L
exit pass the JSON document where is
your coat and we do support a door
lambda adder any HTTPS n-bomb so if you
want to run inside your data center feel
free to do so you just need a highly
available highly scalable secure a web
server to maintain and to operate so
that's why we choose lambda here I have
nothing to operate I just deploy my my
code my code because it's a UK skill
lives in Europe but if you are targeting
us and UK you can have two different
version of your codes or two deployments
on two different lambda function and for
Europe I need to give the reference to
my lambda function so I'm going back to
the AWS console and this is the
reference to my lambda function we call
that an Amazon resource name that's a
unique identifier of a resource within
the Amazon Cloud and next Ebola my skill
is ready to test so it's already
implemented its you have a test button
as soon as it is enable it's enabled on
your Amazon account so this echo these
dots is connected to my amazon account
and the developer console is connected
to my amazon account so it's already
live on the dot there but before testing
life on the dot I will do another text
based test to ensure that the end-to-end
system is working correctly and I can
say things like launch my coral dimbo
that was my invocation phrase so launch
is one of the many verbs we recognize
mighty open tell ask launch and we have
a long list documented in your
documentation if I click on that the
JSON request that will be generated it's
a long request so there is no intent
there so it will be routed to the gate
welcome javascript function if you
remember the JavaScript code so this is
also something you can copy-paste to
test your lambda function remember the
tests with lambda you can copy the
request from there and use that in the
lambda console and this is the response
generated by our scale so this is the
response that has been generated by
by the lambda function you can play the
response so if they do that tell me your
favorite color by saying my favorite
color is right so you can hear what will
be the sound of Alex I've something
sound strange you can change your text
but if this is working this should work
as well you can say for example Alexa
open my favorite color it's my color
demo sorry I screwed up so she would not
recognize that because I have no skill
with some illusion I can't find the
answer to the question I heard that's a
very good debugging experience because
this will happen to you in real life
time so Alexa open my color demo welcome
to the Alexa skills kit sample please
tell me your favorite color by saying my
favorite color is red my favorite color
is blue I now know your favorite color
is blue you can ask me your favorite
color by saying what's my favorite color
what's my favorite color your favorite
color is blue goodbye so 30 minutes and
you have your first kill working can I
take another two minutes on your time
just to explain something as long as the
blue light is on on the top of Alex I'd
means she's listening to you and maybe
you notice in my dialogue I say open my
core demo and the blue lights stay on
she talked to me and the blue light
continue to stay on meaning that she is
expecting an answer I give the answer
and during all that dialogue the blue
light stays on what what we mean there
what we have there on the background is
a session it's a dialogue it's from the
moment the blue light goes on until the
moment the blue light goes off and and
that dialogue might involve just like in
a real human to human dialogue multiple
question answer question answer and we
have a concept of session and session
variables or your code can store session
value
able between different steps of the
dialogue and this is exactly what we did
with a blue color I say my favorite
color is blue and she immediately answer
me okay I know no that your favorite
color is blue and I say what is my
favorite color in terms of lambda if you
think about that it's two different
invocation my lambda function here has
been called three times open the scale
say my favorite color is blue ask what
is my favorite color so it's three
different invocation of the lambda
function and lambda it's totally
stateless so it might even be handled by
different machines in different data
center we don't know lambda is totally
stateless so to keep that state and to
keep the fact that Alexa remember that
my favorite color is blue from one
question to the other we have that
concept of an Alexis session which is
the entire duration of of the dialogue
when the blue light is on on on Alexa
how does the session work it's something
that we give you in my favorite color is
blue it's something that we give you in
the JSON so there is no persistence on
the Alexa back end that wouldn't scale
so what we are doing we give you your
session content in the request it's part
of the session attribute there you see
you have this attribute and you as a
developer can use that field to give us
a couple of of values like to purchase
the fact that my favorite color is blue
so one of your response might include a
session attribute as well and the
promise we are doing to to you is that
for the next request in the same
dialogue you will retrieve the same
value in the in the attribute of the
session so it's not really persistence
on the server side it's very different
from HTTPS session for sure but it's a
very scalable and stateless way to
maintain some state in between question
and answer as long as you are part of
the same dialogue and this very simple
example of Kuro shows you how to manage
the session as well if you have a look
at the code you can see the
that we are storing the session
attribute inside these Jason these Jason
these design attributes we have
something here called session attribute
create favorite color attribute and yeah
we just returned the favorite color as
part of sog is an object so this is how
you can manage the state of the dialogue
when you ask a question receive an
answer ask another question by
persisting the state Adam in the
intercession attribute part of the alex
is talking with someone that wanted to
build a like an ordering interface so
you can build all the parameters that
you need for an order in the dialogue in
this way and then when you have all the
information you can exactly another
example is to handle the yes no intent
you might ask to your customer or
confirmation about something and you
expect yes no intent but that yes no
intent matter might arrive at a
different stage of your dialogue maybe
you have a very long dialogue and yes no
at the beginning yes no at the end so
from your code perspective you just
receive a yes no intent so you have to
map that he has no intent to the stage
where you are in your dialogue and one
way to do that is to press this the
stage of your dialogue inside the
session so that you know when you
receive yes intent and you are at stage
8 you know that the next step would be
that I hope I'm clear for everyone has
been some probably a bit hard for the
end of the day anyway machine learning
not yes because this will light up the
environment for machine learning so you
saw how to create the skill with a
lambda function and the skill let's see
the other part of the demo that we did
this morning with the machine learning
and do binary models thanks eps I think
I'm fine really voice voice interaction
model facility because they are so
different from what we used to program
on normal web interface and there are
different problems but maybe 1 1
parameter for recognizing the quality or
and interfaces the range age of people
that can interact no with something so
and we see that with this voice
interaction models you can have young
very young people and older people
interacting very easily wear
is not the DC with smartphones and web
interfaces okay so let's move to the
second part so today when we built the
divide the OL bike sharing skill for
Alexa there was an interaction with a
machine learning model that was
predicting the number of of bikes used
in in the Washington bike sharing
service that was a regression so I was
predicting a number and integrable
actually for the prediction engine was a
floating point I was rounding the result
because the prediction could say that
3.2 bikes were we rented that I was
running that up to avoid confusion now I
want to do a different example so I'm
still using the Amazon machine learning
platform as I said today this is a
platform that was designed to be used by
developers so that you don't need to be
a machine learning expert and that's
what the same engine is the one that we
use internally to Amazon for although
our teams we can build batch prediction
so you provide a set of data to predict
and we give the predictions or that was
what we use today give real-time
prediction so in the matter of
milliseconds you can ask a train model
to give a prediction depending on the
data we support regression and we tested
that just after lunch and then
classification I will do an example of
binary classification but it's probably
one of the most use cases as i already
said email spamming is a case of binary
aggression this email is spam or not
another example is customer that are at
risk of leaving your company so if you
want to predict if a customer maybe is
going to leave your company or not in
the next week you can build a model and
this would be another example of binary
classification so let's see how you can
do that and I will do a different demo
so using binary classification with a
banking product so the scenario here is
that you have maybe your own customers
you launch a new product and maybe you
start contacting your customer maybe
1000 customers to see if they are
interested in buying this new product
after you call your first 1000 customer
you can start to
use this data this is an example of
supervised learning to build a model
that will predict how all your other
customers can be interested or not in
this product so that you can focus all
your energies in calling only the
customer that probably are going to be
interested in this product and you will
also improve the customer satisfaction
because you don't are not going to call
people that will probably not are not
interested in in that so let's go on the
Amazon console I have an account with
the old console and here we have machine
learning in in the analytics section of
the console and here i can create a new
data to a new model we have this nice
interaction here in the in the bottom of
the console that gives you what an idea
of the necessary steps to build a model
also what's required on your side so the
first step is to upload your data and
also to you need to analyze and
understand your data and maybe clean
your data if you were here in the
session just after lunch when I was
looking at the data for bike sharing I
was drawing the data using different
parameters like the the day of the week
and the hours of the day and we were it
was easy to understand that they were
patterns so people using the bikes in
the morning and in the afternoon for
commuting and people using the bikes
over the weekend just for leisure and
then we understood that these were
different population of users so looking
at graphically at your data is the best
way to understand it and maybe change it
before creating the model the second
step is to create and train the model
based on the data and this is usually
not a single step so you create a model
you evaluate the model and based on the
evaluation you can understand how would
the model is working and then you can
try to change something so today for
example there was a date in the input so
of course in the data that i was using I
had the day the historical data of bike
sharing I have a date and then I was
looking at how much bikes were rented
but the day of the week was information
that
not very easy to understand for a
machine so it was adding a new column
saying okay I know that the day is
November 10 but this is also a Thursday
this can provide information because
bike rental on a Thursday is different
than sunday so you can reach your data
you evaluate again your model you
training and again your mod and you see
if this change in the data is creating
an improvement or not in the valuation
of your model and then you can start
building real time or batch predictions
so I will start creating a data source
so a loading the data and the machine
learning model I already stored the file
on on on s3 our object storage and I
have data here in the hannah bucket i
have you can see a few example this is
the banking example and this is the
banking csv this is a csv file that
actually we can also open here to a
brief look before loading it so this is
something that you can it's not big so
you can even manage it with excel and
what what you have here is a file that
tells you all the characteristics of
your customers or the age the kind of
job marital status the kind of education
how it was contacted it was a cellular
on the cellular on the landline when it
was contacted the day of the week he was
contacted the duration of the of the
coal and at the end of all these
parameters you have this final column
that is called why that has at 0 a 1
that means if the customers at the end
of this contact both or not the problem
so zeros means that it was not
interested than one are when the
customer boat so this is for example
what you can do with your first 1000
customers now i will load the same file
here let's call it the works banking
just to recognize it now this is the
platform is checking that we can read
the file and now we can tell the block
this is as csv and the first row
contains the name of the columns
so I can tell this to the platform and
the platform is looking after the data
and trying to understand the data type
so for example the age is a numeric
field the job is a category because
there's a Phoenix finite set of values
the day of the week is the same and so
on and the final value the Y is a it's
recognized as a binary value because it
does only two different values it can it
can also be two different strings it
doesn't need to be 0 and 1 to be
recognized as a binary of by the
platform now I need to tell to the
platform which is the target so of all
these variables which is the target that
I want to predict and it's exactly the
final column the Y and this will mean
that this is developed the variable I
want to predict all the other variables
will be features that i use in the input
for the prediction so I will need to
provide all the other values to predict
this final feature the why we don't have
an identifier this is a classic Iraq up
and at the click continue so this will
create the data source so importing the
data and now i can create the model we
have a default model that is what i
suggest you do as a starting point we
will use our own best practice to create
the best model for the data or you can
customize and you can change how we
manage data with what we call a recipe
an example if you have text you can say
how you want to manipulate text for
people that is into text processing you
can create an grams or structures of
that kind but normally you don't need to
do anything and that is really to work
in a direction so you build the first
model you evaluate the results then you
try to change something and you see if
you improve or not so let's use the
default settings and I can create the
machine learning model so now the
process has started if I go here in the
dashboard I see that we have activities
in process so the first is the import of
the data source the one hundred percent
of the file then we are splitting the
data source in two parts from zero this
is not very easy to see but
it's from zero to seventy percent the
first part of the file and this seventy
percent of the data will be used for
training the model and from seventy
percent to one hundred percent so thirty
percent of the data will be used for
validation and it is a very good best
practice for machine learning with
supervised data so you put seventy
eighty percent of the data on one side
for the training and then when you have
a model you test the model on the twenty
thirty percent of data that you put on
the other part on a side and see the you
can build an evaluation you can
understand how well is your model
abstracting the information from the
training data on the validation data
then give the model itself and the
evaluation this usually takes roughly
ten minutes so that's why I already
created it a couple of hours ago so here
we have the machine learning model I can
click here and we have it took three
minutes to be created after the creation
of the data sources two minutes were the
actual compute time and here we have the
evaluation and this is a binary
classification so the normal metric to
evaluate a binary classification is the
area under the curve and this is a value
that goes from 0 to 10.5 usually means
completely randomness so it's like
throwing a coin one means that you are
one hundred percent perfect in the
prediction 0.93 is a very very good
result and shows that this is fake data
that I prepare for this demo because
with real data you will never arrive to
0.9 0.7 it's maybe already good but
there's an interesting information you
can get if you click on the value you
can you have other information on the
underperformance of the Mexican you can
explore their performance so this is a
visual representation of the curve that
we were looking only at the area below
the curve and this is telling you
depending on the number of records how
many records are correct so it's
ninety-one percent correct
and how many are errors and there is a
very important information here because
the errors can be of two kinds can be
false positive or false negatives so you
can make a prediction let's say okay
this is this customer can be interested
in this product but it will not or the
opposite this customer is not interested
but actually this was the product that
it was searching for all his life so how
can you manage this we we can only tell
you what are the results and the value
of false positive and false negatives
depends on your use case for example
let's say that this is an aspiring
platform so spamming model so it can
recognize you from email is spam or not
maybe you receive so many males that you
really want to get rid of all your spam
if sometimes you miss an email from a
normal friend you don't care because you
really want to remove all your spamming
so in this case the the the the false
positive so if I recognize an email as
spam but it is not sometimes can happen
is not a big problem on the opposite
maybe this is the email for your company
where you receive the orders from your
customers so you want to get rid of spam
but you don't want to miss an order
because that's how you survive as a
company so in this case you really don't
want false positive because that means
that you can lose an order from a
customer other interesting use cases
where you can understand the difference
between false positive and false
negatives is if you apply this to health
care so imagine you have a large
population of people and you don't have
the resources to do some medical tests
on all the people you may want to select
a subset of people that is at risk and
then test all these people in this case
a false positive is not bad because if
you have someone that is not affected by
this illness but you test it again it's
not a problem but you don't want to have
false negative because if you say okay
this person is not to be tested because
it's not at risk but he was at risk then
you miss the opportunity to correctly
run the test and classify the person so
it really depends on your case and here
you can change the model moving the
threshold that we have on the graphics
and this is changing
the number of false positive and false
negative between the two range so you
can use these customized attract short
depending on your use case to lower or
increase the false positive or the false
negative usually it's 0.5 is it's a good
starting value and then you can you can
fine-tune here there are other classical
metrics of of machine learning such as
precision recall accuracy they have
basically the same meaning as this
information but they used as a standard
language among data scientists you can
change these values and this is
affecting the same threshold as before
so now that we have the model we can use
the model so how you can use it you can
run a batch prediction for example and
that means that you you take a large
file such as this one that I here so I'm
opening this file this is exactly the
same file as before with all the
information of my customers but there is
no final y column because I don't this
is other customers I don't know if they
would be interested or not so i can do a
batch prediction by giving all this list
of customer as a csv the platform will
evaluate all of them and return the
prediction for all of them at once this
is a one way to interact with the with
the platform and the other way is to
generate real-time predictions you need
to enable this if you generate real time
prediction you get an endpoint URL and
then you can call this endpoint URL with
a with our AP is to ask for a prediction
from with a single data point to predict
you need the endpoint and the ID of the
machine learning model this information
here on the top and just as an example
this is how you can use this from our
SDK so this is the java sdk for AWS we
have an Amazon machine learning
interface and here we have the predict
method that you can use you create a
predict request where you include all
the information also their ID of the
of the model the end point and all the
variables that are required by the model
and you get a predict result that will
tell you which is the result the same is
available in JavaScript for example in
Python if you want and in a lot of other
languages you can also test the real
time prediction straight from the
console so you this is all the field
that you need to to all the fields that
you need to fill to run a request
because all the fields are required just
to find some example I can run unhead
comment on the file that we saw before I
can copy one of the lines so this is one
customer from the that I want to predict
so you have the age he works in services
is Marya that I did the high school and
so on I copy this as a CSV I go back on
the interface I can taste a record this
will automatically populate the
interface then i can create the
prediction and this is what i get for
this prediction so in this case I get
the algorithm that was used the kind of
prediction is a binary prediction the
predicted level is 0 so this customer is
not interested and if I look at the
score is a very very low score it 0.03
so it's very low so it's really not
interested in in this product and it
would be really a waste of time to call
to call him and contacting so in this
way you can use predictions in your
application and it was exactly what we
did this morning so the only difference
was that it was a regression and not a
binary classification going back to the
slide I think we are really at the end
of this session I hope it was
interesting because we had the
opportunity to dive deeper into the
products and the technologies that we
were using today and we are more than
happy to take some questions please
yep
yep so let me repeat the question i miss
the second question maybe we can talk
about that but first and three are very
common so it will need to rest probably
several person so the first question is
how can i programmatically upload the
list of values or the list of sample
uterine sore or change my intent model
but your question was specifically about
the list of values for slot currently
you can note so you have to copy place
and go to the web console don't show it
me don't shoot me the way we know that
it's a very very frequent developer
requirement we have some kind of API or
programmatic access to that so we are
working on that stay tuned it's cooking
and the third question was how can you
know about the sample uterine so how do
you know how your customer I are
interacting with your skill and maybe
you will start with a small list of
sample uterine so you do your own reach
that we don't provide the direct sample
returns or we don't provide the direct
utterance to you to your skill as you
saw in the JSON it's the intent so it's
the translation after natural language
understanding so currently you can note
you don't know how your customer
interact with your skill if you have a
partnership relation with us if we are
working together on your skill we can
give you some hints because internally
of course in all systems we know exactly
what the customer tortue to Alexa so the
the big names we are working with we
work closely with them and we provide
that information if you don't have a
close relationship with us sorry as of
today you have to rely on customer
feedback on users of a very good
experience is just to lock a couple of
your employees or customer in your room
for one hour with your prototype and you
observe how they interact you just give
them minimal guidance and you recall
that on video this is super useful to
learn how customer actually will talk to
your your skill we do that with real
customer we lock them in a room we feed
pizza through the door and we don't let
them out after one or two hours
you cannot so the question is can you
make relationships between slot types as
of today you can note we are working at
improving the slot modÃ¨le I cannot give
too much details I cannot I cannot give
you when it will be there but we are
working on making a much rich from other
four slots in a very near future so the
question is is it possible to give Alex
a some memory yes you can do that but
you have to program it by yourself so
many customer use dynamodb which is the
the no sequel database as a manager is
from AWS it's something that you need to
program at your skill level but it's a
very good practice anything that you can
give a leg side that gives some feeling
that you're actually speaking to a
person so that she she we cook nice you
she remember what you said last time she
is happy to see you back if you didn't
use the skill for a couple of days or
weeks do that but you need to write code
to possess that in a database can Alex I
recognize who is she was talking to her
not yet stay tuned you can really set
thumbs up or down for a song playing on
a custom radio station when I say Alex a
she's listening so we are out of time
happy to continue the conversation of
line we for the the the microphone but
we have to give up the room to the next
door so thank you for your interest for
Alexandra thank you so much especially
to the people that came also to the
second section we really humbled by your
patience
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>