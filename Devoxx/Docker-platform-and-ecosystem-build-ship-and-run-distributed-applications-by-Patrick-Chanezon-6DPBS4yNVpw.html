<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Docker platform and ecosystem: build, ship and run distributed applications by Patrick Chanezon | Coder Coacher - Coaching Coders</title><meta content="Docker platform and ecosystem: build, ship and run distributed applications by Patrick Chanezon - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Docker platform and ecosystem: build, ship and run distributed applications by Patrick Chanezon</b></h2><h5 class="post__date">2015-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6DPBS4yNVpw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright so let's get started so hi
everybody my name is Patrick Shane is
all I work at darker and today I'm going
to tell you a little bit about all the
news that happen in the dark or
ecosystem this talk is focused on
orchestration and I call it welcome to
the jungle because it's a real jungle
out there and the goal of the talk is to
give you some ideas about the various
systems and the trade-offs you have to
make when you're choosing one or the
other and to give you a state of the art
of what's happening right now in in
orchestration for darker and I
understand that I'm between you and your
lunch so i'll try to make it
entertaining with a lot of demos alright
so i just keep what I've been doing i
just spent ten years building software
at various companies and then ten years
doing evangelism and i joined our six
months ago to help Solomon build the
platform there so orchestration is
really a jungle there are lots of
different players in there and and I'm
going to go through the various types of
players they are but basically if you're
lots of developers started using docker
in the past two years and the next step
after they start having a nap and they
want to put it in production is they
talk to their apps and they need to
start orchestrating all these containers
at scale in production and that's where
the fun begins hopefully there are lots
of people who are going to sell you
orchestration solutions this is one of
the gallery of the people involved what
one of the thing I wanted to say is my
reason for joining docker is many years
ago when I was building client server
applications in the early 90s the the
browser came out and i remember in 95
when i used netscape for the first time
I realized hey there's a new way of
building apps with HTML and we're just
going to put all the code on the server
side and the new client will be the
browser and then I spent the next
20 years building that kind of apps when
I started playing with darker while i
was at microsoft which is like two years
ago I I had the same kind of Epiphany
this is something this is a tool that
when you start using it every day you
just realize you're going to build your
apps in a different way so I'll skip
this one okay yeah I like that quote
very much the future is already here
it's just not evenly distributed so
darker has been used our docker
containers have been used at Google for
many years and lots of the large
consumer companies are using it to
manage their workload at scale what's
happening right now is darker made it
super easy to create containers and now
everybody starts to to use them and now
the problem is the tools for
orchestrating them as not are not as
mature as you would wish so our mission
a docker is to build tools of mass
innovation I really like the statement
there and what we mean by that is that
these days what's the most interesting
thing to to program these days is the
internet there are lots of different
devices but there are silos for
developers so if you're building for
android or for iphone if you're building
for cars you have different specialized
operating systems and what we're trying
to do is to do a unified layer that
people can use to program the internet
the the place of doctor in the cloud
market so that that's a slide I I use
when I was at Microsoft and I was
explaining to my team why I thought dr.
was important in the I'd say in the past
five years there's this big fight that
happened between the three giants of
cloud amazon who studied the market
Microsoft who followed suit suit and
then Google
who followed as well so you have these
three large players and then so they're
they're mostly public cloud and then you
have vmware who owns all the workloads
in the data center for private cloud and
when I remember when I was at Google and
I try to sell Google App Engine for
business and I talk to customers the
main the main answer they told they gave
me was we are not interested in
something purely public cloud we want
something hybrid so Microsoft understood
that and they have a pretty good hybrid
strategy vmware is trying to get a
hybrid strategy as well with a vCloud
air Google with KU banaras I think
starts to have finally a hybrid strategy
they did this partnership with core OS
where you can buy core OS plus ku
banaras to set up behind the firewall
and then you use a Google container
service on the public cloud so so
finally they have something where you
can use the same API to deploy your app
internally or externally amazon they
don't have a real story for that yet and
to me what happened is that when ducker
arrived two years ago it kind of really
reorganized the whole industry around it
and what I mean by that is that the new
the new system right now looks like this
the new platform it's at the bottom you
have the hardware so instead of hardware
now it's cloud services and
virtualization so that's the system that
provides your application all the
resources storage compute and networking
on top of that you have the operating
system and the operating systems shrunk
in the really in the past yeah two years
I would say they all shrunk is started
with core OS we started this
distribution that's really designed for
the data center that's very small with
just a few utilities and darker to run
workloads then very quickly Red Hat and
core OS Red Hat and ubuntu followed with
project atomic and we're going to core
VMware a few month ago launched photon
which is their own small linux distro
my favorite in there is Ranchero s they
went all the way we're in rancho you
just have the Linux kernel and you have
two darker engines you have a darker
diamond for system a system demon where
you run your system utilities in
privileged mode and then your userland
darker where you run your regular
workloads and even Microsoft followed
suit with that where they started
implementing darker for windows so they
re implemented the back end of darker in
terms of windows isolation primitives as
opposed to linux as duration primitives
so you're using the same epi but you can
deploy a dotnet application that run on
Windows and when they did that they also
created a new version of Windows Server
that's called nano server that's much
smaller they removed all the UI and all
the stuff that you don't need when you
just want to run containers at the
center of the ecosystem you have darker
on the left here what you can see is add
on to Dockers and i'll talk about them
today we've for networking a flutter for
for volume management and then on the
right you have our construction and this
is really where the jungle is there's a
lot of competition in there i'd say the
three leads in there are darker swarm
messes and cabana des but there are lots
of other options Cloud Foundry is
reinventing itself as an office as a
container orchestration solution IBM
with bluemix which is based on class
when we added darker support to it and
then there's des which is a Heroku like
orchestration solution that you can
thats open source and like you can
install behind the firewall initially
there were based on fleet and now
they're based on cuban areas so there's
lots of movement and action in there so
the business opportunity why why why is
it interesting to get interested in that
one of the reasons is that as developers
we love complexity and so a lot of
people have started building their own
paths internally and and instead of that
with darker it kind of gives you the
right level of abstraction for building
a system
that would have the same characteristics
as a past but would give you all the
flexibility to run the kind of workloads
you want as opposed to being stuck into
the opinionated choices of a pass
another aspect is a a July really gets
mainstream like it started around like
two thousand and now everybody is doing
it and one of the aspects that goes with
microservices that I like a lot from
it's a quote from a drain craft
that netflix they use this metric called
CBS the mean time between ID and making
stuff happen I like that very much I
think most of the tool that we're
building are really about that like
lowering that time and then agility
means that agility and using powerful
tools that at the right level of
abstraction it also means dollars and
what I mean by that is that it means
your developers are not spending time
building infrastructure they spending
time creating business value another
trend that happened in the past five
years this one I to me that the
continuation of agile is DevOps so from
the mainframe era Devlin ops weren't
really seeing eye to eye together they
weren't programming in the same
languages and and and sometimes I I
remember writing COBOL applications some
of the apps guys were running workloads
they didn't have the source code for it
anymore client-server it wasn't much
better the classic tale of the
client-server of the client-side
developer who has to argue with the
Oracle database admin during the web it
was horrendous we weren't using the same
languages all the seaside means were
using Perl on the on the other side were
using C++ or Java what happened with in
the past five years with DevOps is that
devs and apps are working hand-in-hand
and DevOps is more a culture cultural
movement than anything else so it's
about people and processes as well as
tools a little bit and I think darker
plays an important role there as a tool
for enabling that because the container
as a developer you
building a container and that's the same
artifact that's going to be run in
production by your by Europe's so dr.
itself it's based on basically to
packaging of Linux kernel features for
isolation and control so namespaces give
you a isolation for your process your
network the mounts that you're making
and then see groups give you control
over how much memory you want the
process to have access to how many CPUs
and stuff like that so basically darker
packages all that in a simple to use
user interface another aspect that super
important in darker and that I think was
a big reason for its success is the
image layers so when you're running a
docker image it's actually composed of
several layers and you can do
inheritance there and what that means
that if you're running like 15
containers will are based on ubuntu with
small changes for the first time you
download the in boone to image the
second time you download only the
changes and so thatthat's I think that's
very powerful compared to VMS where you
have to download for gigs with
everything on it every time so doctors
mission is built is to build tools to
build shape and run application so let's
take a look at each of the tools in
these various areas for so for building
you have dr. itself as a developer the
way you use it is that you you use a
declarative format that's called a
docker file where you specify the stuff
you want in your image typically you
would inherit from one of the official
images so here if I'm a Java developer
I'm going to inherit from Java and I can
specify your version in there then I
copy the source of my source of my app
in there I specify your working
directory and then here I'm running a
compilation of my code and then once
you've done that you can build the image
with a darker build- see you can specify
your name and then you can run your
container and when you're done with it
you can push it to the two docker hub or
a private registry so on top of that
typically when you're building
microservice applications very quickly
you have 56 services like front-end
back-end database maybe some workers
running in there some caching layer with
red s so typically you don't want to
have to write a shell script to launch
all these containers and link them
together in order to make that simpler
we have a tool that's called aqua Campos
so that's another declarative format
that's in llamo this time where you
specify all the containers that you want
to run you assign them some name you can
scale them independently so you can
specify some build instructions the
command to run the port many of the
options that are on the dark darker
command line you specify them in there
you can specify your volumes and in the
past which means that since until last
month you could specify links so you
could link container together the
networking layer and they could talk
together with the names that you gave in
the link the way that was implemented
was not scalable it applied only on the
same host so you couldn't link
containers were on different hosts which
was a big problem for orchestration so
people had a bunch of systems like
ambassador patterns or or different
hacks for connecting containers across
different hosts instead of that now i'll
show you in one dot nine one of the big
news is the new networking features that
render links obsolete ok then you have
dr machine one of the one of the things
that happens when you start working with
dr. that very quickly you're initially
you're running on your laptop but very
quickly you want to have some servers
for testing in one of the cloud
providers or in vmware or and different
virtualization layers virtualization
solutions dr. machine is a very simple
tool that has a bunch of drivers that
lets you provision a machine in any
cloud with darker demon installed on it
and configured with certificates and all
that stuff so it makes it super easy to
switch machines and
provision machines on the fly and
destroy them when you don't need them so
that's an example of creating in one on
Azure so i use the azure driver there
are some ezio specific data in there
where i specify which region which my
certificate on subscription ID the user
i want and then a name so dr. machine
has lots of drivers the last release of
dhaka machine that was released two
weeks ago I think it's zero dot five in
there Nathan refactored machine pretty
profoundly where before all the drivers
were in a single code base now he he
created a plug-in architecture so plug
so now plug-ins for each provider can
live in their own code base and then
they will be assembled by machine when
you're running it so it makes it easier
for maintenance then the skype medics
ok'd medic is a it's a UI for darker i
remember when i was at microsoft when i
started training people my colleagues in
docker after half an hour on the command
line one of the guys told me hey there's
no UI for this i said no at that time
there was not so now there's one that
works both on mac and windows I think
they're working on Linux right now so
that's a build part these are the tools
that as a developer you using to build
your applications then there's the
shipping part how do you ship your
application so for that this docker hub
so dr. hub has a I don't remember like a
gazillion of images some of them are
official so they are maintained apps and
all the security patches upstream are up
to date on them but then there are also
a lot of community images so when you
are really interested in some obscure
programming languages maybe some old
versions there is a high chance that
someone has built a doc of fun and
created an image for that I find that
super convenient dr. hab when we are
talking about DevOps this is really
where Devin ops meet together devs are
building their images and they're
pushing them to the hub and then ups are
pulling them from the hub and running
in production so dr. is a company it's a
private company so we need to make money
our business model is to build
commercial solutions based on our open
source solutions so hub has I think in
hub you can have one private repo and
you can pay for more but we also have
something called darker trusted registry
that you can buy to install behind the
firewall and it has enterprise features
like ldap integration active directory
and all that stuff so that's for
shipping and then for running yeah so
for running one other thing I wanted to
touch upon his plugins one of the
philosophy behind docker is batteries
included but replaceable and so what
that means is that we try to build
plugins for many of the aspects of the
tool that you are building so for
example for swarm we can plug a
different scheduler there's an
integration between swarmin mezzos for
engine there's the volume plugins I
think there are like four of them maybe
more now I discovered one like only last
week network plugins there are six of
them so we have batteries included with
the new networking feature in 19 but if
you don't like the way it's done you can
just switch to one of the plugins in
there and some of them have really
interesting characteristics like for
example we gives you a very nice
visualization of your network traffic
between your containers when you're
developing and then for service
discovery it's pluggable with a console
ETD and zookeeper as well so then for
running your application this darker
engine and with darker engine you
configure your client to talk to one
engine that's not very convenient when
you want to like launch 100,000
containers on maybe 10,000 machines so
for that we have darker swarm swarm is a
demon that sits be in front of your your
set of darker engines and it talks to
them and you as a client you use the
same darker client he talks the same epi
as darker and use your darker client to
talk to swarm you ask it to schedule
your workloads on one or the other your
workloads with some constraints so you
can specify constraints on cpu
affinities and aunty affinities and then
suam we'll just schedule it based on
strategies that are pluggable as well
you can choose which strategy you want
whether you want bin back where you want
everything on the same as little machine
as possible or random or evenly spread
among the across the cluster one of the
things that is really missing in swarm
and we got lots of comments about that
and that's part of cuban adesso
cubanelle s has a really nice load
balancing it's part of the platform at
dhaka we have something called
interlocks so that's a project by evan
has led it's an open source project and
the way it works is that it listens to
swarm events so every time there is a
container that schedule swamp generates
an event and you can listen to these
events so interlock is a simple go
program that connects to the socket for
for swarm listen to the events and every
time there are some events it changes it
regenerates a configuration for either a
cheap proxy or nginx and there's a
plug-in architecture so you can create
new ones and then restarts engine X rhe
proxy the problem with interlock as I'll
tell you a little bit later is that with
the new networking stuff it doesn't work
anymore because with networking the
network events are not exposed in in the
swarm set of events yet Madhu who's
working on networking is working on that
so that will come soon and then we can
have a new version of interlocked that
supports that and then the last aspect
is a project okay so that's a commercial
offering that we announced at dhaka con
last june there will probably be more
news about it at a dock Akane you next
week and that's a platform for
for running your containers and
monitoring them and all that that you
can buy and install behind the firewall
and then there's 22 so the October 21
2015 which is the day that Marty from
Back to the Future came back today
darker and to tomb joint forces so to
tomb came to darker and to tomb is an
interesting orchestration platform as a
software-as-a-service so so it's on
demand you just create an account over
there but you can bring your own
machines in there so we can give it your
as your credentials your amazon
credentials and you can bring your
infrastructure into 22 tomb will manage
to install dr. engine on it and we'll
manage your containers on it one of the
interesting aspects there that it also
lets you bring behind the firewall
resources if you set up the right
networking with it so that means that
you if you don't want to set up your own
orchestration behind the firewall you
can still manage work clothes with this
behind the firewall so basically once to
tomb and anoka will be out we'll have a
solution for SAS and for on-premise so
there are lots of enterprises who are
using darker nowadays and one of the
intra important aspect of abductor is
open standards last year yeah I think it
was last year we started getting lots of
remarks from lots of companies saying
hey you guys became a de facto standard
now it's really time we were all betting
on you on your technology but now it's
really time to create a formal standard
and so last june at dhaka con we
announced the open container initiative
there's 35 companies in there pretty
much everybody in the in the field and
we all agreed to create a standard for
container wrentham as well as the image
bundle that is run by the container
runtime which means the layout on the
file system of the image and so that's a
spec the oci charter is student
finalized we
finally agreed on the scope of the the
spec pretty recently now they are still
some discussion with lawyers that may
take a month or two and so we'll have
the charter soon finished on the specs
side the working group started working
right after dark on and so they have a
001 version of the spec already and they
made lots of advances one of the
important aspect of the spec is that we
established it with a goal of having a
strong reference implementation and so
doctor gave lib container to that
project and there is a project in there
that's called run c which is a reference
implementation of the OC ice pack which
is basically a command line on top of
lip container and so run c is so run c
implements the spec you can run it today
it's more advanced than darker in terms
of isolation features so for example you
can do user name spaces are part of it
already it just arrived in darker
actually this this release in 19 but but
it was already in run c and there are
some stuff like pre you for example a
snapshot and restore of containers I
know I know and Michael my colleagues
gave a super demo at dark on last June
of like playing a video game connected
to a server in Singapore they just snap
shot a snapshot at moved it to Amsterdam
and I could continue playing their game
in real time does it this video out
there on that so run see allows you to
do that today and the goal is for the
next versions of darker probably in one
that 10 is going to be the isolation is
going to be implemented in terms of
Ramsey Sedaka we'll just call run see
behind the scenes there's also Cloud
Foundry who decided to adapt run see for
the back end for their garden
technologies elation technology so it's
a it's a pretty successful project and
its advancing pretty fast and the last
aspect is plumbing so doctor is made of
a lot of plumbing but it's all makes
smashed in the same code base one of the
efforts we started last June is to start
to extract these pieces of plumbing and
make them separate utilities that you
can use by themselves without needing to
use the whole ducker which many people
find very opinionated so if you know
like our opinion just use our plumbing
so notary is one of these Plumbing's it
allows you to determine whether the
images that you want to run are exactly
who you think they are and then run see
is the first piece of plumbing that we
did but there are others that are going
to come out and that's a t-shirt I built
for rent see so dr. one dot nine one of
the main news in 19 is a darker
networking and volumes which were
present in experimental branch now they
find out they're part of mainstream so
out of the box you have support for
overlay networking in darker and also in
swamp so that's very important for
castration and I'll show you an example
of that no discovery is better now with
the cluster store and cluster advertise
options for the engine so now your
engines can just say hey I'm at this IP
address and they tell that to a
discovery service that could be console
or HED and then they will discover each
other and darker volumes as well as
networking both have a plug-in
architecture so you can use plugins
instead of the darker building stuff
there's been a few improvements in
builder a new AWS lager and one of the
big things is the user name spaces phase
one which means it's a very simple
version of that where you can map one
user in your container actually the fact
that you hear means that you are not
that interested in a user name spaces
because Phil estás who coded that he's
giving a talk right now in another room
about this so tough choices super
interesting stuff 1 dot 10 we are
planning to integrate runs into
drucker directly some improvements in
distribution networking there will be a
lot of bugs to fix I'm sure when we find
them when we people start using them and
user name spaces the the way it was
implemented is only a first step there
are lots of new lots of other things to
do in that area so let's talk briefly
about orchestration okay so darker swarm
I talked about it it's so you put it in
front it exposes a set of docker engines
as a single engine it's very easy to get
started so you can provision one of the
things that we improved in the past six
months is the integration between the
different tools so now you can provision
swarm with darker machine you can
provision it in a way where you can pass
all the information to your to your
darker engines about the networking
discovery and all that I'll show you
that so so it's very very easy to set up
and I'm actually one of the one of the
interesting aspect of this is that it's
so easy to set up compared to Coober
naraz for example which is very
opinionated in the networking layer it
needs that coop con I think it was on
Monday my colleagues Sam and Alex from
the from the swamp team did a demo of
installing kubernetes on top of swarm
soku Benares is pretty painful to
install I remember having spent lots of
time to try to install it on Azure you
have to use a virtual networking layer
either weave or flannel that's what
people are using usually and we swarm
now that we have networking built in
basically you install your swamp cluster
and you deploy all the corner desk
components as as just darker services on
top of that the only thing is that you
have to give them the couplet service
access to the socket of the underlying
darker engine on that node well that's
that opens lots of interesting
possibilities there
so the swamp scheduler is doing resource
management with memory CPU and network
and then it applies filters to exclude
some nodes based on what your you're
giving it so you can specify affinities
and then it uses a strategy to to pick
the best node swarm is integration is
integrated with machine and compose I'll
show you that and then there's am SOC
integration the way mezzos works is that
the mezzos master meses is a two-level
scheduler so the mezzo smashed ER is
really managing the resources in the
cluster and then based on these
resources it creates a bunch of offers
that it sends two frameworks and
frameworks are a second level of
scheduling and the notion in meses is
that the application knows best the
application developer knows best how
they want to schedule their resources so
you can build your own scheduler in what
is called a framework so there are a
bunch of frameworks out there in mezzos
and what we did is that we work with
mesosphere to create a swamp meses
framework so the way it works is that
you're talking to the swamp mezzos
framework with a regular doctor api so
you want to schedule a container with
some affinities and constraints and then
mezzos master sends the swarm is those
frameworks a bunch of offers if they are
some offers that fit swarm is just going
to schedule the container on these so
that allows you to if you have chosen
mezzos for your castration platform you
can still use swarm as a client so
what's new in swarm one of the big news
in swarm is that swarm is going 10 so
last week we release 110 it's stable now
and before we used to say swarm is not
ready for production it's not being
tested and all that in the past six
month a spend lots of time doing testing
and especially scalability testing and
stability and now it's it's ready for
production it's also integrated with lib
network so you can do overlay networking
over a swamp cluster and it has the
support for volume plugins so that means
that you can start
working with stateful stateful
containers with databases and schedule
them in a cluster with volume that will
follow you if your reschedule somewhere
else so in terms of production readiness
we've made some tests on Amazon on more
than a thousand node and the results
were really good which means even in the
99th percentile the time to schedule
container is 3 60 milliseconds and then
the performance is pretty good as well
yeah so so swarm works well I add heavy
loads and it's integrating its
integrated with a networking and volume
and load balancing I talked about it
already on the road map one of the
interesting aspect that's going to
happen in the next few months is that
swarm and engine are coming closer
together so I think in the current
release they started like using a common
API layer at the code level but in the
future like they're going to merge
together and be closer and closer and at
the end of it if you think about it you
could consider the car engine as a swarm
of one so that's kind of the the
philosophy with which we were going with
that now let's talk briefly about mezzos
so it's an Apache project it's very
mature it's used in a lot of companies I
think it started at Twitter and it's
using in lots of large consumer
companies who have very large clusters
and now it's getting into the enterprise
they have a whole ecosystem of
frameworks so the swamp framework is
only one of them this marathon and
Kronos yesterday I think it was
yesterday Yelp released a platform as a
service that they built internally and
they released it as open source is
called pasta and is based on mezzos plus
marathon and Kronos I think yes I talked
to you about how mrs. worked already and
how the integration is done cubana des
soku Benares is a I'd say it's more
complicated to install and there are a
few more concepts to learn as a
developer so the first concept is the
one of pods the in da colon when you're
building your micro service will
encourage you to do one process per
container at Google they were used to
having like a log manager for example
who I aggregated the logs in the same in
the same isolation space as the the main
workload and and so they have this
notion of pad water part is is it's a
set of containers who share the same pit
namespace so they can talk to each other
inter process communication they share
the same volumes and they have the same
IP address and they are scheduled
together so first you're building pods
after that you schedule your pods with
what is called a replication controller
so replication controller cubana des has
a declarative API with a reconciliation
loop which means that you can say i want
three of these and there should be
always three alive and so you create a
replication controller with a value of
three and if one of your pods dies
cubana des is going to reschedule eight
somewhere else and then your pods when
you schedule them have labels so there
are labels in darker as well and then
based on these labels you can create
what is called a service and a service
is essentially a query on a label so you
say all the pods that are labeled with
this I'm going to load balance them with
a service so they have load balanced
load balancing included in the platform
so that's we conveniently started I
think right now in one dot one they
introduced a new pluggable load balancer
so you can bring your own because load
balancers when you're using a cloud
platform like Google or Azure they have
their own load balancer and you want to
leverage that then there's cloud foundry
on bluemix so cloud foundry
really a big beast it was based on build
packs so that means there are certain
frameworks that are understood by cloud
foundry and the notion is that as a
developer you focus on your code push it
to the platform and the platform takes
care of scaling it and checking itself
and all that the problem with it is that
developers wanted to bring more more
stuff in there were clothes than what
was allowed by the past and so when
Cloud Foundry started to mature and see
that change in the industry and there
they are talking to lots of enterprise
like 14 500 customers I think that's a
sweet spot what they did is that they
created that new project called Diego
which is a container orchestration
orchestration engine it is based on
garden which is an isolation technology
and that's where they are they are
plugging run see right now but they
don't use docker itself so they are
pulling the layers from the hub
themselves assembling them on desk and
then in the future they're going to run
that with run see so you have Diego and
they created that sub project that's
smaller than Cloud Foundry cuz Cloud
Foundry is video big system to deploy
you actually need a distributed system
to deploy it that's called Bosh so it's
kind of hard to bootstrap they created
that smaller project that's called
lattice where you have just the log
manager the router the router emitter
and Angie a go and so they're trying to
reinvent themselves as a container
orchestration in there hmm then there's
IBM bluemix so bluemix is a super
interesting platform they made the
choice at IBM so there they go very
they're very fond of like building real
world solutions on top of open source so
they took OpenStack as a base they added
a cloud foundry on top of it and when
docker started to get traction they
added ducker in there see so you have
the three platforms in there ok so
that's bluemix and then they are so all
the solution that I talked about our
things that you can install behind the
fire
wall they are also now all the big three
today since the last month or two months
ago when microsoft announced their
container service all the big three has
have a container service and then
there's two tomb so I talked about that
so to tomb is now part of darker and to
tune goes way beyond orchestration
they're doing all the CI CD as well then
des Triton from giant that's an
interesting offering I'm going to
accelerate because I want to have some
time for the demo so in summary I'd say
it's a swamp meses Cooper Netta's that's
kind of the big the big three there and
different styles so let's do some demos
so I want to show you a darker
networking and how you can use that with
machine and compose so in order to do
that I'm going to show you a spring boot
application that my friend Josh long
built so it's called the spring doggy
and it's a very simple application that
has a an angular front end back end with
a spring API an epi built in spring and
then the back end is a MongoDB database
and they're using Mongo FS and so the
applets you like take a picture drop it
in there in your browser and it will
just manipulate it and serve it and
there's also some web socket for showing
all the pictures that are coming so I
used to so I i sent josh docker file and
then a compost file and when when that
time came out I started modifying my
compost file to see what it would look
like in the new world so let me show you
that okay mm-hmm did it work now the web
server died okay so let me show you the
code first okay so that's the yeah so
that's the spring boot application you
have a java source code in there and in
there you have a docker file so it's a
very simple docker file it's a java
application so inherit from Java 8
I expose port 8080 and then I suppose
that I have built my I've done a maven
package in my source repository
generated a jar file I just copy that
jar file in that path inside of the
image I said that as the working
directory and then the command is very
simple it's a Java minus jar of spring
dogged a jar and I passed with the port
that I wanted to start on and and also
the the URI for mongodb so I need to
pass a URI to that container that
contains the connection string for
connecting to the MongoDB database so
how do I start all that I have a compose
file and so that's the old style compose
file where I have my web container my
image is the one that I built before so
I pushed it on the hub I expose party a
li and and here you can see I use links
so in the old world you would use
lengths and you would schedule them on
the same on the same host and here I
link to Mongo and Mongo is here and it's
just running a Mongo database in a
production system you would just map a
drive on the machine for your data / DB
directory and so the result of that is
that when I money in my web container
the host Mongo is accessible to me for
that database which means that for my
MongoDB URI I can pass it as Mungo there
that's it so that works now with
networking let's take a look at what
that looks like so I kill that guy off
maybe I have it open somewhere already
with networking yes actually so let me
show you with networking so with the
networking you the same thing i enhance
the compost file a little bit because
now that we have virtual networking
where what will happen when i do a
compose up instead of just doing a
compose up I'm obliged to pass a minor
minus minus X dash networking just to
activate networking in compose and then
specify the networking driver and here i
want overlay which is creating an
overlay network of all my machines in
the swamp cluster and by default compose
is going to create a network that's
called the name of my application then i
can specify because there won't be on
the same machines i can specify some
some constraints for swarm so here you
see that composants warm i integrated so
here what i do is that for the the web
server I just tell I want an affinity
rule where I want the the compost
service is going to be the name that
compose is going to give to my database
there I want I i want the the web server
to be scheduled on a different host and
where my DB is and then for Mongo I have
a constraint that's label so I passed
with a label i say i want to be
scheduled on a host that is labeled with
SSD and then the last thing the big
difference in networking here is that
container name so here i can specify a
container name i say it's going to be
called DB and the result of it is that
the host name for that machine on the on
the private network just for this
application is going to be d be now
there are some limitations here so the
integration is not completely finalized
because that doesn't work if i want to
scale to scale that that container so if
I do a darker compose scale web equals 2
is going to generate two containers for
the web tier one that's called
application name dash spring doggie
underscoring doggie underscore one and
then I'm just cross pin dogie under
underscore too and there
cannot use that for service discovery
and I cannot specify a container name in
that case so you can use container name
only for services where you have only
one host so it's okay for development
not not really great for production yet
and now I wanted to show you another
example that I I fail to make work or I
made it work once and then I couldn't
kill the container so there are still
some bugs in there but I made it work
once so that one is using its using the
same stuff that I showed you but in
addition to that it's using its using
the Rex ray volume plug-in that has been
built by emc and so right what r x-ray
is doing is that it's it has some
drivers and notably they have a ec2
driver so you give r x-ray your ec2
credentials and every time you do a
darker volume create which is what
compose is doing behind the scenes Rex
ray is just going to provision an ESB
volume mount it on your machine and
mount that unmount the the volume into
into that so here i think so i used the
volume driver x-ray and my volume is
called Mongo data I'm mapping that to
the dallas / DB directory and that's the
only difference so when i tried that on
a swamp cluster on ec2 last night what
happened is that it was scheduled it
worked my volume was created the app was
working wonderfully but then I couldn't
kill it so I could stop it and but I I
just couldn't kill the container I had
to reboot the machine so there there are
still some issues in there the paint is
not completely fresh there the last
thing I wanted to show you before I
launch a demo and I have three more
minutes is how to provision a swan
cluster so you can provision a swamp
cluster with networking set up with
something like that so that one is on
ec2 so there are some easy two
parameters here i say i want this guy is
going to be the swamp master
and there I can I can specify your swamp
discoveries I'm going to specify a
console instance where is going to store
all the data about the machines in the
cluster in terms of engine options I can
specify the cluster store which is also
that console instance and then with
Angie nap with a cluster advertised I
can say advertise yourself to the
cluster with the IP address that you
have on a ethernet 0 network card and so
once you do that basically you have a
cluster with one master and two machines
you can see here that I added an engine
label with storage SSD and this guy i
did a label of a storage drive so that's
a very easy way with a simple script to
create a cluster with different labels
and then started scheduling some
containers on that so when I do actually
i'm going to show you maybe the darker
info so i'm sure so here this cluster is
just provision on my local machine i
have just two machines in there the
master and storage equals SSD the second
machine and here i'm just going to do a
darker compose up but i pass dash dash x
networking and dash dash x network
driver equal overlay and I pass the
Campos file that I just showed you and
this guy should start my spring
application is starting the database
it's starting the spring of the spring
application and then showing me all the
logs and I need to go to another oh no
ok so this guy is on that host so let's
try that in the browser ok
okay so let's see if it came up yeah it
came up so they're the application is
working which means that I can whoops
yeah which means i can take an image
there drop it in there and it's going to
store it in Mongo FS and show me the
result I'm just going to make that a
little bit bigger and if I go over there
it's serving it from Mungo FS and it
adds a bunch of gobbledygook let's josh
Josh humor but basically it works and if
I go there in my window I can see I
should be able to see the logs of the
application and yeah that's it yeah the
application of the database ok times up
I hope that gives you a desire to go
deeper with the new networking stuff in
darker I'll publish my slide after this
talk I have a bunch of other example in
there that you can explore and all the
code that i showed you is on my github
repository and these are mentioned in
the in the slides have fun thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>