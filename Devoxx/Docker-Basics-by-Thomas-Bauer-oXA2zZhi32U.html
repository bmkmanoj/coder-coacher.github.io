<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Docker Basics by Thomas Bauer | Coder Coacher - Coaching Coders</title><meta content="Docker Basics by Thomas Bauer - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Docker Basics by Thomas Bauer</b></h2><h5 class="post__date">2017-08-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oXA2zZhi32U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right good morning everybody welcome
to walks days Vienna I hope you're doing
good you had a coffee and ready for some
soccer stuff to be honest I have to tell
you this is my very first conference
talk ever
I'm very nervous and I will try to get
distracted by the content talk is called
Dhaka basics I would try to cover the
real basics
what is soccer how does it work what are
the elements of a Tucker ecosystems we
will see how it really works
by running examples I'll try to do it
all life and at the end I will try if
the internet internet connection works
to also do something online I'm very
sure everybody of you already heard
about Tucker who did not hear about
Tucker yet and when talking about Tucker
it is often mentioned together with
micro services and micro service
architectures who is familiar or has
some experiences with micro services
already ok
using Tucker ok so I would try to on the
one hand explain how how this whole
Tucker stuff works and on the other hand
always give a bit of advice or relation
to to the micro service world and this
is also why I put these goals on the
first slide so the goals of this whole
are technology and also what I am trying
to explain is we want to instead of
built software that someone can install
somewhere we want to ship around able
services so
someone can take this piece and just run
it with no installation preconditions
whatever that is basically what we can
achieve is docker services shall be
immutable that's all the whole darker
story we will see how this is realized
so instead of upgrading a software or
patching a softer we just shut down and
destroy the old instance and start the
new instance so not modifying anything
just releasing a new version of the
whole runnable service yeah we will see
how we manage the various life cycles of
docker instance of a service of course
as docker is available on the prominent
platforms you can run the service
everywhere so just as a Java program
built one run anywhere you can do this
with the whole application and also if
we have time we will see how to manage
to manage all applications with some
Tucker tools all right when talking
about micro service applications
something like this could show up if you
are familiar with for example the
Netflix tech spring cloud this will be
very familiar with you basically what
micro service architecture or
service-oriented architecture is is to
split the application into components
and those components are not software
modules like libraries or so but there
are real running programs and they
specify an interface how to interact
with them and this is called the service
and the word micro service shell shell
I shall note that we want to create tiny
services that really focus on one thing
at the time and rather have more of them
than just a few big ones so as I said
micro service has a specific purpose I
tried to come up with some ideas for for
example customer service contract
service 3d print service as one could
imagine we have an online website where
you can order 3d prints and we have
specific parts of the application and
each service just holds a single part
and the services between them and they
interact over network communication by
interfaces and therefore they are
abstracting away the implementation so
they manage their domain they had their
data I won't go into more details about
microsoft out just to give you an idea
they are ideally stateless and
parallelizable why is this important
interesting and how does this relate to
stalkers or docker containers can be
started very easily very quickly and
there are some tools where you can
easily scale out so horizontally scale
so start ends
instances of a service and if it's data
stateless and parallel say well it's
very easy to scale you can use just in
Tucker tools and without having
something in your software for it yeah
they have a clear interface and the
contract and this allows any other
service to talk to the service and not
depend on their implementation which
leads to the last point they can be a
technology agnostic so each service can
be implemented in their own technology
and when talking about technologies as
he might have not heard dr. encapsulate
everything that is needed to run a
service so all the dependencies the
technologies to libraries the
configuration and so
therefore from the outside there is just
this network interface and how to talk
to the service and from the outside you
do not need to know what technology is
used inside and as we don't ship
software that needs to be installed but
rather software that can be run
everything is included all right
so much for the background now coming to
talker what is it all about
first before jumping into starting a
container I want to explain a few
elements that seem important to me to
understand the main part of the docker
is the docker engine and from the
documentation it says docker engine
builds images and runs your containers a
docker image is a blueprint of a service
it tells the docker ecosystem how to
launch an instance and an instance is
called the docker container so a
runnable runnable instance is called
container if you have two instances to
near two containers and an image is the
blueprint which is the basis very
starred instance from and then there's
the darker command-line client and we
will see the basic usage later on to
explain it in an image here you see what
I mean there is a docker engine this is
a daemon running on your system and this
demon cares for running the containers
caring about the lifecycle storing the
images building images and so on we will
see how this works and then there is the
docker command line program the docker
command line program is really a rest
client which just over the network talk
to this docker engine and as you can see
here if you could have multiple docker
engines on multiple hosts and all always
use this command line client program in
other words if there is no
engine running this command line program
does nothing you cannot build images
with this command line program or run
containers or whatnot it just remote
control this docker engine and also
interesting the the images are stored
within the TOC range in context so in
order to share the images to add the TOC
our engines you would need either to
build them on the dock wrench in or use
the docker registry to push the images
onto and then you can pull it from there
docker registry is there there is a
official docker registry also you can
use something called Nexus or
artifactory typical artifact management
of which you probably already use for
maven or artifact right alright let's
see how this works
to
all right the first thing I want to do
is just run an image yeah around the
container
can you read yes so in order to to run a
service or a container start the
container you would need a running
Tucker engine which in nearly sits in
the in the menu par on OS X you can
download install it and then it's run
and then you can use the command line
client program Tucker to talk to it and
use the command run dash D which tells
us to detach in the background and then
the name of the image you want to start
the container from and you will see this
is pretty quick this is all and we have
a running container each container is
identified by a unique container ID and
this container ID can be used to talk to
to modify the container state start stop
and so on there's a command called PS
and with PS you can see you can see all
the running containers you see the
continuity this is like get where you
only see the first few bytes which are
necessary to identify the container and
you can see we just started our
container and Pertti fault
Tucker assigns a random name to our
container which can also be used to
interact with this container you can
also see us nginx I think everybody
knows nginx of observer
exposes two ports port 80 in port 443
and as you can imagine docker is a
virtualization technology which allows
for each instance to have their own IP
address and their on port range and in
order to talk to them
we need to port forward the ports to our
local machines like as we do is VM
virtualbox and so on or with a network
router so in order to do that we need to
start the container with the port
forwarding and we can do this with - - P
and use for example port 82 and for 32
port 80
in this container we do this we get a
new container ID and we we see this
running container here as a port for
running from our local machine part 82
to port 80 when we point our browser to
this port 82 we see our running nginx
so as you can see it's very quickly to
start the container you can run any
number of containers on your machine as
they are very lightweight they use up
only very few resources this is a kernel
virtualization technology which does not
need a full-blown virtual machine or
such it's just a isolated process in
your in your operating system alright
and then for the last example here it's
good to name your container with your
own name then you won't get assigned a
random name by Tucker and you can
identify your containers later on so in
that case of course 82 is already taken
and of course we have this name already
okay
I started it early on - and here we say
we see the name and we can say okay
talker stop up - all right I think
that's all for now
okay we started the container based on
an image and now I want to explain what
this image is all about and and then I
will show you how to build images by
your by yourself so a docker image is
basically a description how to how to
create and run a container the boot
start script and description of how to
how to run a container this script is
composed of lines and each line has a
comment and what docker does when
building an image it executes these
lines and with each line after each line
it saves the state in a so called image
layer and then it mounts this layer it
executes the next line and save safety
state again and create a new layer this
way first of all it's a very lightweight
in consumption of storage and you can
reuse the layers so if you built an
image say for example you start with
nginx and then you put up some websites
in it and then you put some
configuration in it and then you build a
similar image that also uses nginx and
some configuration you used before
images can be reused so it's very nice
to help this storage and you can reuse
it and and also very important those
images are immutable so it can never
change an image you can only build upon
it and then build a new image this way
those can be shared across multiple
images and yeah services there is a base
image so typically you will start from a
base like file system like for example a
base image which already gives you a
chopper virtual
gene or a web server or something and
then build on top of it
image I identified by a name and the TAC
attack is basically the version number
or you can use it as a version number
it's alphanumeric string so you can you
you can put anything there images a
layered in layers are reused and to
build an image you use this Tucker file
which is this script this describes how
to build this image and of course
there's a maven plugin how to create an
docker image from your java application
and as i said before there is a you see
the cursor now there's a give it of
course dr. and she needs to be round so
just building the the image with your
command-line client won't work in either
running Tucker engine Weist is important
because typically in your development
lifecycle you would not build your image
by your self upper hand but this would
be rather doing your continuous
integration server and in order to for
it to build the image it needs a doctor
engine running to do the job and then
push it to a docker registry alright
let's see how this works
here we have a docker file and this
docker file as I said every line is
executed and an image is created we
start with a base image with the command
from and then the image name and the
image tag all pion is very famous
minimal Linux distribution which is like
4 megabytes and if you are not sure
where to start you should start you
could start from Alpine and start from
there the idea when building an image is
to only include the things you would
need for this service as we saw before
the micro service architecture we have
multiple micro services and every micro
service as the name suggests should be
tiny and therefore just include what you
need start with nothing and just add
what you need then some meta information
and then there is a just one last
command
it's called entry point every image has
only or can only have one entry point
which is not true so if you have an
image which has an entry point and built
another layer on top of it which is an
entry point the first one is ignored and
just the last one is used and what is an
entry point entry point is the command
this being run when running the
container yeah and there are several
notations how to declare an entry point
here there's a JSON array with strings
with the command to to invoke in the and
parameters in order so this is
everything you would need to build an
image in this image would just put out
halliburton too now I will try to build
this image from this docker file we use
docker built - Tay T is for for
attacking the image with a name and we
call it hello world
and : and then the tech and we use just
one as a version number and then we need
to to put a path here and this is the
path to the dockerfile and what happens
now is very interesting as a remember I
said docker engine builds the the the
image and the dock engine could be
located on a remote machine so what
happens now you can see in the first
line it's sending the so called built
context to the docker daemon and what
this means it it takes this directory
which is the local directory plus
everything in it all sub directories all
files and so on and sends it over the
via to the docker engine and then tells
the taco engine okay there is a docker
file in the root directory use this and
build your image and this is what it
does it starts with the base image
creates an intermediate image with the
image ID used amid meta information
creates a an image again here it says
using cache because I did this already
so it does not does not do any work and
then it puts this entry point there and
creates a new image and successfully
built this image we stock our images we
can see we have this hello world image
here and when we run it
and we should see hello world alright so
in order to build this image use a
docker file build build it with with
docker
build and then you can start containers
from it let's try another example we
have another docker file here we start
from an engine X image we used before to
start the nginx web server and we
replace the index.html in the in the
nginx
configuration and see what what this
does again we're building this image
we're sending the context it creates the
image and successfully builds the image
we have a box trap here and we can just
run it detached because it's a server we
give it a name we forward ports I will
come to this in a second and tell it
which image to use it starts this this
container
you see it here boxed yep and I did
- big P instead of just forwarding at a
single port with a big P it tells take
all the exposed ports to service
declares and assign a random port on the
local machine why is this useful because
if you start like three instances of
this container you would need need three
different ports to use with the service
and this is how it does it and here you
can see the port
32,000 seven seven three it is used to
forward to port 80 and when we point the
browser do this we see the service
running in a container we just started
from the image we created so this is to
show you you can use an existing image
which is a service a web service
something and modify it by layering your
modification on top of it you won't
modify the original image it's immutable
so nothing nothing will happen like this
user for example you could create a
software which needs some configuration
and there is a different configuration
for different environments and you could
put the configuration file as a last
image layer on top of it and have
different flavors of your image with
different configuration files for
different environments and you're
assured that the software is not also
that the service is not modified because
it's a base image from from there as you
can imagine you can build a lot of
docker files each building upon each
other
all right okay next
all right one very interesting thing is
I told you before this the talker engine
demon and this taco engine demon needs
to be run in order to start containers
create images and yeah and this can be
located on a remote machine there is a
tool coming with docker
it's called docker machine and with this
docker machine tool you can manage
darker engines you can create docker
engines you can create docker engines in
the cloud and you can then use the
darker engines to run your services this
is a pretty useful tool it's pretty neat
and this is probably the tool you would
use in your automated environments to
start our engines built images start
containers do some integration testing
then shut everything down
delete the doctor engine again free up
the resources and of course you only
yeah
pay for the resources you would you
would use I will try to show that to you
all right
we are using digitalocean in my company
so that's why I'm using digitalocean and
what I do is I use docker machine create
to create a new digital ocean cloud
instance installed darker engine on it
and connect it to the local machine in
order to use it I already started it
because it takes a while
TACA machine is a program which allows
you to do that and how it's done it's
done with a plug-in system and you need
to specify a driver what to use
basically what remote technology you're
connecting to in this case I'm using
Dutch this driver digitalocean and of
course as you can imagine you need to
supply the access token to it and then
the last parameter is the name of the
machine which you're creating and what
it does it connects to the cloud to
digitalocean creates a new cloud
instance installs taka engine and listed
in the local inventory of course there
are a lot of other parameters which you
can find crane control the creation of a
cloud instance so what flavor it is and
how to assign a elastic IP address and
so on the drivers way label for all the
major cloud providers so Amazon Google
Microsoft digitalocean is also available
for OpenStack so if you're running your
own cloud infrastructure in your company
you can control it with docker machine
as well and also there is a driver
called VirtualBox and with - just drive
a VirtualBox you can create a new doctor
engine using VirtualBox on your machine
in order to test everything your
continuous integration environment would
do for example what is also task which
is pretty nice in order to connect to
the log to the remote machine it uses as
and it also takes care emetic Lee takes
care about key generation key
registration so every remote machine is
using their own SSH key and this is all
managed by docker machine and hopefully
it will complete in a few seconds and
then we can use it in parallel I can
already show you a few other commands
docker machine LS list the docker
machines which are registered and you
can have as you can imagine a lot of
different machines locally remotely and
so on all identified with the name oops
we can already see our digitalocean
instance and which is still installing
docker
hopefully very quickly I can in parallel
I can show you how to create a virtual
machine with virtual box our talking
engine on VirtualBox MV box 1 should be
probably a bit quicker hmm yes of course
thanks for the hint do you have any
questions so far I know this is pretty
quick try to cover few topics yes
yes so the question was the idea of
docker containers are they around in
isolated environment and the question is
is it possible to share resources
between these containers so of yes of
course first of all the idea behind the
whole micro-service topic is not to
share physical resources but rather talk
about network interface network
communication use for example a caching
service of whatnot
to store information but of course at
some point you would need the data
storage your persistent storage and you
would need local file system you can
mount the file system of the of the
hosting operating system like my machine
into a docker container and this docker
container inside the process can write
to this file system of course you can
mount it to to several machines this is
how it works
yeah is there another question no
somehow screen went blank
if the projector still working no I
think not hmm all right I think I don't
know how to handle this is anybody here
who can help me no well then I have a
couple of minutes left I will just
explain to you what you can do with
soccer machine I'm sorry we have no a
picture anymore so we created the docker
machine entry was on digital ocean and
it don't install the docker engine it
creates the SSH keys registers it and
then you can basically configure your
talker
client program to point instead of the
local torque wrench into the docker
engine on digital ocean and then a
really neat thing about this docker how
this docker implementation is done is to
use exactly 100 percent the same
commands you used before with docker run
nginx
docker built the image and as it points
to the remote docker engine in the cloud
it does nothing different and locally it
sensed for example the built context
over to digital ocean and so he built me
an image and store it locally and then
we stuck around nginx for example it
starts the nginx
on the cloud machine so you write your
basically your Tucker script and then
you can choose by at runtime which
docker engine to use so this is very
useful for your continuous integration
environment local testing and also of
course then the different our production
system staging production and so on what
is interesting is that of course
if there is an image you want to run a
container from an image that is you
don't have for example when you first
start to try to start the engine X
container and there is no nginx image on
your machine it works similar to maven
it goes to the central repository it
downloads the image and then stores it
locally in your dock or engine and
starts only you need to remember that
the images are local to the docker
engine so if you create a Tucker engine
in the cloud want to start the image you
would first need to somehow put the
image there either build it there or use
docker registry to share it what I
cannot show you now there is a maven
plug-in or the several maven plugins for
building docker images out of a java
application I'm using the maven plug-in
from Spotify just go to maven repository
and Google for or search for Spotify
docker plug-in it's perfectly works
together then when you build a chart or
executable application and then it uses
it as an entry point builds a docker
image and then you can start up and ship
your java application as a docker image
which runs everywhere without needing to
install java and so on and so on alright
I think I will close with it any more
questions or if you have more questions
later you can pick me up other coffee
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>