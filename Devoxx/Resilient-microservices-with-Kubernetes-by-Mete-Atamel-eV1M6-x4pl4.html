<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Resilient microservices with Kubernetes by Mete Atamel | Coder Coacher - Coaching Coders</title><meta content="Resilient microservices with Kubernetes by Mete Atamel - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Resilient microservices with Kubernetes by Mete Atamel</b></h2><h5 class="post__date">2017-06-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eV1M6-x4pl4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I guess we can start now hello
everyone my name is Matthias amel in the
in the session note in the agenda for
the conference it says SML matter but
that's not my first lay my first name is
Metta actually so I'm a developer
advocate at Google I'm based in London
and it's my first time in Singapore it's
a great city and we're very happy to be
here I'm a little bit jet lag but
hopefully it won't affect my
presentation alright so today we're
going to talk about my services with
kubernetes so I just in my presentations
I like to give you the whole topic
upfront so let's just do that from the
beginning so you know what you're
signing up for so I think software
development is hard
I mean who agrees with me like this does
anyone think that software development
is easy I don't think so and in the best
news is that it's actually it's not
getting any easier if you look at all
the development in software development
we have all these tools and frameworks
and languages and all this kind of stuff
that you would think make things easier
for us but but if you think about it
it's actually getting harder and harder
but the good news is their frameworks
and tools like kubernetes that can help
so this is the whole point of this
presentation I will basically go through
like about software development why it's
why I think it's hard and then then
we're going to go through containers how
they help and where they fall short and
then we're gonna look at Kuban it is
what is trying to do at the high level
and then we'll take a look at cuban into
the building blocks like one by one and
then we'll see how it can actually help
with the craziness in software on today
so that's the whole talk hopefully this
is what you sign up for if not feel free
to go but hopefully say all right so
that would be information about myself
as I mentioned I'm a developer advocate
at Google and based in London this is my
Twitter and my email I already have
these slides up on my Twitter account so
if you want to slice just follow me and
there should be a link there and also if
you have any questions about any of the
stuff I say today you can find me after
my talk but you can also always email me
from from this email account I also like
to get feedback about my talk so I have
a feedback link bitly slash my last name
if you fill it before the end of the
session I will right after I have three
t-shirts that I'm going to give out to
people who feel that it's the first
three people but then I also have some
speakers Google ad stickers so even even
if you don't get a t-shirt feel free to
stop by for its sticker after the talk
alright so let's get started so anyone
recognizes these anyone work with these
before yeah okay good it's always a good
feeling that I'm not the only guy who
worked on these so I'm not the oldest
one here so in the good old days when I
started programming this I actually I
didn't use the biggest ones I use the
ones in the middle that's what I started
using so I used to have this ms-dos disk
I would put it in my computer floppy
drive closet turn the computer on the
computer would boot then eventually I
would get the a drive and then from
there I'll take it out I would put the
other disk it was I think gw-basic or
qbasic one of them I don't remember it
was so long and then I was just so
gramming and if you think about it this
was like the only thing I had to care
about right you know in micro-services
they have this notion of bounded context
like this was my band the context it was
really bounded right you couldn't escape
from that so all I had all I had was
this disc and a book on
qbasic and I and and it was really fun
like I would just like sit hours and
hours and trying to hack things together
of course it wasn't always fun sometimes
I would get stuck and there was no
internet there was no spec overflow so I
would spend days trying to figure things
out but that simplicity was really fun
since then a little things happen
actually the first thing is obviously
internet and then from the internet we
had all these other things like we had
like app servers databases machine
learning Big Data IOT cloud computing
mobile it's like so much right so it's
really impossible to know everything in
detail so what I try to do and I am sure
it's the same for you is like they can
choose what you like and then try to
focus on a few things but then at the
same time try to get a good overview of
what's out there so that in case you
need to do something in other fields you
have an idea of what to do
so nowadays if you want to solve a
problem you still write the code so
let's just imagine that this is our code
by the way I'm totally ignoring this
because it's like so far out so I'm
sorry for that but that's how it's going
to be because I remember but you won't
happen so in the in so nowadays if you
want to solve a problem you write your
code let's let's just imagine that this
is our code and it's not on a disk
anymore so you need to deploy somewhere
so you find a machine it can be on your
own machine or it can be your data
center or Kim or you can be somewhere in
the cloud so your code gets deployed
it's not that complicated it's great
it's running but then someone says what
happens if this machine was done right
you can't just rely on a single machine
so what you do is you take the same code
and deploy to multiple machines so so if
one of them goes down you still have
your other machines working right but
then the problem is how do your clients
get to your machines they cannot know
all the IP addresses so you need some
kind of load balancer in front of them
right so the world balancer has the
static IP and the clients to connect a
load balancer and then from there you
use some kind of load balancing
algorithm to reach through to the
machines that's great
but then what happens like how do you
even know these machines are working you
know just because they're online that it
doesn't mean that your app is running so
you probably need some kind of help end
point on these machines so you create a
health endpoint where you check certain
things about your application C and make
sure your app is actually running and
then if it's running you say ok and if
it's not running then you say not ok so
that way you know if your app is healthy
or not but you know creating this health
endpoint is not enough you need to
actually have something checking that
endpoint so what you end up doing is you
probably create something called like a
health checker you either create that
yourself or you rely on your cloud
provider basically just pings your
health endpoints and make sure that your
app is running and then maybe
additionally if your app is not running
it might bring down the machine and
create a new machine and make sure that
it's healthy
so this health checker it checks for the
health and also provisions and new
machines if something is not healthy in
one of the machines so that's great
everything is working but this whole
thing is in one one zone in one one data
center
and and even if with cloud providers
sometimes the whole zone goes down so
what do you do you create the whole
thing in a different zone with the whole
the whole set up in a different zone
just in case something goes wrong with
this zone you can switch to another one
right now you have another problem you
have some kind of state here and then
you need to make sure that state
actually gets replicated to do to the
other zone right so what you usually do
is you have something in the middle it's
usually some kind of a task queue where
you you know you when you write stuff
here you put it in the queue and then
this guy pulls it from the queue so that
way the state of one's own gets
replicated to the other zone so that's
great I have two zones there they're in
sync for most of the time that's great
what if your application is kind of
successful and you need to scale up you
can scale up manually but then what if
you know it sometimes you're at your app
is cyclic so during the data you have
lots of users but then at night you
don't have that many users so you need
to scale up and down constantly so it's
hard to do manually so what you usually
do is you use an auto scaler so you
either write yourself another scalar or
you rely on someone else's autoscaler
but basically looks at your your your
usage how many people are using your app
and it scales up and down depending on
that right so our little app all of a
sudden got quite complicated and we
haven't even talked about having
different languages and different types
of machines so we are talking about a
single code running on a single type of
machine but if you need to do multiple
languages and multiple different kinds
of machines this gets even more
complicated when you want to deploy a
new version of your application you need
to think about it because it's not just
one machine and one code right if it's
on multiple places in multiple zones so
rolling that out in a reliable way
so that easy anymore let's say you want
to roll your your new version but
there's something wrong with it you need
to roll back to the previous version
that becomes complicated then your
configuration and secrets right like so
your code is one thing but the
configuration or your application and
the secrets or your application like
passwords and stuff like that that's
also that also needs some kind of
management and you need to think about
that and then finally the scripts you
know
time your your machines start they
usually has some kind of runtime as
startup scripts that needs to run so you
need to manage those as well as your
code in turn also manage your scripts so
there's all this other stuff that we
didn't even talk about yet so at this
point if you are like me you're like
kind of like this guy you know because I
am an application developer I like to
solve real world problems I don't want
to really deal with this kind of
operations right these these are kind of
distracting me away from what I need to
solve so I kind of feel like this guy
sometimes
so the reality of today is that this is
what I want to care about this is what I
want to work on the actual code but in
the end I end up caring about the whole
thing with all the replication and all
in health checks and also scaler things
like that and actually I worked at a
place once where the ratio of coding
versus operations got so bad that I
actually quit the job because I'm like I
was spending most of my time trying to
manage all of this rather than coding so
that ratio has to be maintained
carefully otherwise the workers don't
like to do just that right so what do we
do in this case now in the good old days
not so long ago actually I would write
my code and then I would just pass it to
QA guys and say can you please test this
for me because as a developer I don't do
tests right we are software engineers we
don't do tests and let them do the
testing for me and then we would fight
back and forth they will send me a bug
I'll argue with them that it's not a bug
and then they will send it back
eventually I fix it and then once
everything is bug free then I plant it
to operations people and say you know
can you just take this and run it in
operations in production because I don't
know how to run stuff in production I'm
a software engineer and another
operations guy right and he would figure
out all these all these details and I
would just take this approach or you
know it's not my problem you know let
them test it let them run it I just
write my code and to be honest I think
it was kind of felt good because I was
just doing the fun part and then the
hard part was done by other people but
in reality it wasn't good practice
because I wasn't getting
and I think it was same for most of you
guys probably before DevOps is that I
wasn't getting the feedback I need to
build resilient applications then the
notion of DevOps came along so the idea
in the wops as you must as most of you
know is that as a developer you're
responsible from beginning to the end so
you write the code you testicle to you
you run it in production if it needs
fixing you go and fix it you deploy
again so this way you have you basically
do the whole thing and as a result that
makes you write code that's more
resilient and it really helps I have to
pause here for a second
so when DevOps implemented correctly it
actually helps but I've seen places
where DevOps is not done correctly where
people just use DevOps as an excuse to
just ship code without really testing it
properly without really putting
automation properly in those cases
actually develops kind of like blows up
and then you have people quitting jobs
because everything is so not
maintainable so you have to do it
carefully so what do we do so if I have
to actually imagine how software
development should be there are a few
things that I want to happen so the
first thing is I want to be able to
write code in any language I want I
don't want to be constrained by one
language or one environment and I want
that code to run anywhere in the exact
same way I specify on my laptop I think
this is really important I want to make
sure that whatever I write on my laptop
the way it works here it should work the
same way everywhere because it's really
important to have the context everywhere
the second thing is I want to you know
take my code and optimally deploy it
somewhere so I want someone to basically
look at my code and say okay let's just
deploy this on this machine because
that's the machine that's free I don't
need to worry about the kind of stuff I
someone has to figure that out for me
and just deploy it optimally somewhere
for me as a developer I shouldn't really
care about that kind of stuff
too much and the third thing is they
shouldn't be even machines you know all
the resources that I need should be
automatically provision and available to
me on demand because in this world we
have we have demand coming in and going
all the time so I want things to be
elastic I want I want
seems to be added and machines to be
removed as I need them right so if I
have these things I think we're on the
right track and if you look at what
happened in the last few years we are
kind of getting there
so if you look at the first claim
writing your code in any language and
running it anywhere exactly the same way
well that's what containers are all
about so if you if you look at docker
and the other container platform rocket
they are basically trying to create this
notion of context that you can replicate
anywhere
the second thing or your app being
optimally deployed and managed well
that's what container management
platform is like cuber natives docker
swarm Nestle's
they're all about so they're they're all
trying to deploy your containers in a
way that makes sense for you in an
automatic way so that you don't have to
worry about it yourself and the third
things about the third thing about all
resources being available when you need
them well that's what to me at least
that that's what the cloud is about
Google Cloud AWS Azure
they are all trying to give you a
platform where things are automated
provisioned also scales and available to
you when you need them so we have all
the pieces the only problem is they're
not like really tightly integrated yet
but I think we are getting there we are
in the right direction to realize this
this dream of mine all right so now what
am I going what am I going to be in the
rest of the talk is that I'm going to
build a really simple service and then
and then we're going to continue it
using docker and then once it's
containerized we're going to push that
image to Google Cloud and then from
there we're going to create a cube in
this cluster and run the container in
cube entities and along the way we're
going to see what kind of things cube
entities provide for you for this
container and for the app I'm going to
use an asp.net core application who are
net developers here okay there's a feel
good the reason I know most this is
mostly a Java conference probably but I
the reason why I do asp.net core demos
is that I used to work with Microsoft
and back then this was like four or five
years ago you couldn't talk about net
and Linux in the same sentence you can
even think about it like just like even
even it wasn't something that you
actually thought about it
so the fact that dotnet runs on Linux to
me
still not an unbelievable so that's why
I try to do all my demos using extra on
the core on Linux so that's what we're
going to do but the thing is the example
I'm going to show is basically after you
build the container it really doesn't
matter what's wrong what's running
inside it can be Java community can be
Python whatever the point is not the
language itself it's the containers and
what they give to you right so let's
just take a look here I have to let me
just post here for a second so I'm going
to use Google cloud platform and in
Google cloud there's something called
cloud shell it basically gives you a
linux shell running in the browser that
way and in this linux shell it has all
the tools that you need by by default so
I'm going to use this class shop to
build my expert on a qualification so
here I am in Google cloud platform I
said class shell from here and then this
takes a couple of seconds to basically
find the Linux box for me and then
attach the true class shell now I have
my links box and my own space to build
my application what am I going to do is
first net command line so to build a
speed on the core applications it's
already installed there so I'm going to
use the command line tool for dotnet to
build my simple web app so what we're
going to do is we're going to say net
well of course I need to create a folder
for my application so I'm going to call
it hello world ethnic or and then in
here we're going to say dotnet new - T
web so this creates like a skeleton web
application and if you look at the
content I already have all the files I
need for this like hello world kind of
application the first thing that we need
to do is we need to change the program
dot JS file so this is the main file for
my app I want to make sure that it
starts on port 8080 so I'm just going to
add a line here and to make sure that my
app starts on port 8080 this way I can
test it from my browser so that's all
I'm going to do here so to do that I
just added ad like use URLs HTTP sir and
then 880 sorry it's a little bit hard to
see and then once we do that I need to
get my dependencies so I'll go donate
restore so this will look at my
dependencies in
project of JSON and it will download
them from NuGet so if you're a Java
person this is kind of like getting your
dependencies from maven basically so we
are downloading all the dependencies on
my application once that's done we're
going to do net run and this will
compile and run our application and then
we'll take a look at it from the browser
make sure that it works and that's it so
we'll use this app as like a demo app to
build our container so we're doing net
run now so this is compiling the
application and then within a few
seconds we'll have it running on this
Linux box and this is a this is not
running on Linux I will keep saying this
for a while because I really like that
you know so I am previewing my app in
the browser now Google Cloud shell has
like this web preview feature and now
this is this is the skeleton web app
running on Linux and this is dotnet all
right so nothing fancy but we'll use
this app and we'll build on it as we go
through the presentation
all right so now let's talk about
containers so first again as I said like
I always like to answer the question of
why so let's answer why containers first
if you look at how we use to deploy
applications we used to have a physical
machine then we install the operating
system then we install the libraries on
top of the operating system and then we
deployed our applications on top of the
libraries right the good thing here is
that we have a single physical machine a
single operating system
and a single set of libraries so it was
kind of easy to set up but the best
thing is that the there was no
separation at all between applications
so anytime you change something with the
kernel or with the libraries you could
break any of the apps so that was that
wasn't good then virtual machines came
along in virtual machines the idea is
that on a single physical machine you
have multiple virtual operating systems
so your virtualizing the operating
system and the libraries and then you
build your app on top of that the good
thing here is that your apps are
completely separated so if you change
something in here so it's not gonna
affect anything in here but the best
thing is that instead of maintaining one
operating system now you're maintaining
multiple operating systems so it's a lot
of management you have to do then
containers came along and the idea of
containers is that you have a single
machine and a single operating system
but your virtualizing your dependencies
your libraries or your application and
your app itself so this way you're kind
of getting best of the both worlds right
you don't have multiple operating
systems you don't have multiple machines
you just have a single machine and
single operating system but your apps
are still isolated from each other and
this containers a real lightweight
they're really easy to start so you're
kind of getting the best of both worlds
so that's why containers are big and in
terms of what is the container it's
basically a lightweight way of
virtualizing your application so it's a
way of working your applications but the
difference from virtual machines is that
it's very lightweight they are sealed
and isolated so you can have multiple
containers running on the operating
system but they don't step on each other
because they are separated by namespaces
and then they're very easy to deploy so
it takes like seconds to deploy they
they are int respectable so you can
actually attach into the container you
can you can see what's
there and for me the most important part
is that composable so what you can have
is that you can have based images that
you depend on so that's your dependency
and you can build your images on top of
that so you can layer your images you
can layer your dependencies on top of
your base images so this way if someone
need get your image they can build on
top of your image so they can compose
these dependencies or on top of each
other so doctor is the main container
platform that most people use but there
are others there's something called
rockets from core OS that also works and
I'm sure there will be more in the
future so just just to let you know the
doctor is not the only one all right and
then containers they might look like
there's something new but at Google
actually we've been running containers
for a long time for more than 10 years
and everything at Google actually runs
in containers so the Gmail search maps
even the VMs in Google cloud platform
they run within containers because we
like the security model containers and
our whole infrastructure is optimized
for containers and this number is
probably updated now but we launched
over 2 billion containers per week so
you can see the scale or containers at
Google all right so now now what we're
going to do is we built our simple hello
world app so we're going to take it and
continue eyes it using docker and see
how that looks like
all right I am I'm in class shell and in
the same folder as before first what I
need to do is I need to create a single
DLL for my application and to do that I
run a command called dotnet publish - C
release so this will basically compile
my application compile all those
dependencies and create a single DLL and
later I'm going to use from docker I'm
gonna call this PLL so that's why I'm
kind of putting it all together in the
general world this is kind of like
creating a single jar form application
that's what I'm doing here I'm just
putting everything together into a
single file so once we have this vll
what I need to do is I need to create
what's called a docker file a docker
file is kind of like a blueprint for the
docker image that we're going to run in
the container so it will tell docker how
to create the image so we'll create a
docker file and we will take a look at
the doctor file because it's really
important and that's where we define
everything and in about the docker image
so we'll do that so this created the
single dll that I need and what I'm
going to do is I'm getting into the
release folder where the DLL is in there
in the publish folder and now I'm going
to copy a docker file that I created
before into this folder and then we're
going to take a look at this docker file
and I want to explain you what this
docker file is and what it's supposed to
do so let's just take a look and I'll
close here for a second alright so this
is where all the magic happens it's kind
of hard to see but I'll try to explain
it here the first line says from
Microsoft slash net10 one run time so as
I mentioned to you this is in docker you
rely it you can rely on other images
right so here I'm relying on a base
image from Microsoft it's the dotnet
runtime image that I rely on so that's
what I'm saying here then I'm copying
copied dot app so this means that copy
all the DLL in my folder to the app
folder in the container and then I'm
setting work work director to app so
this is the app directory in the
container will be the working director
for my container then I'm exposing port
80 80 80 80 in the container that I'm
setting an environment variable called
ethnic or URL so this environment
variable will make sure that my X's on
the core application would set on port
8080 and then finally
the entry point this is what happens
when the container starts I'm calling
net this is the command-line tool to
certain applications and then I'm just
pointing to my DLL okay so in with this
docker file what I'm doing is I'm
declaring my dependency so this is my
dependence of the first line then I'm
setting up my environment so I'm copying
my DLL
I'm exposing my ports I'm setting their
memory variables and I'm I'm defining
how it should run so I'm defining that
issue Cornette and then DLL so with one
file and defining my dependencies my
environment and how to run it
which is great all right so once we have
this local file we need to actually
build image so to do that we're going to
use a docker a command line tool so the
local command line tool is already
installed in class shell so I'm just
going to say docker and build and then
I'm going to tag my image it's a good
practice to tag your images so here I'm
tagging it with GC r dot io GC r stands
for google container repository I'm
going to push this image to Google Cloud
so that's why I'm tagging it this way so
the first one says Google container
repository the second one is my project
name the third one is the name I choose
for my container and then then a version
name so that's kind of like a good
practice to do it this way and what's
happening is basically this is now
looking at my docker file and running
through it so the first step is to pull
my dependency so remember I depend on
the Microsoft image so it's pulling that
image because I don't have that image on
my machine right now it's pulling that
image and once once it has an image it
will go through the other steps this is
usually text the longest because you
need to pull the whole image once this
is done it will go through those other
steps or copying vll setting a moment
variable so now it's copying the dll and
now setting up the environment variables
and now it's done my image is built if I
do docker images now I should see my
image built on my machine so that's what
I'm going to do next and then you'll
realize that we'll have two images the
first image is my the image that I just
built the second one is the image I
depend on the Microsoft image they are
both on my machine the third thing I
need to do is I want to actually run
this image and make sure that it works
before I push it so what I do is doctor
run
means running the background - P means a
port 8080 this means that expose port 88
on my container to port 80 on my machine
this way when I hit for a date on my
machine it goes to containers for a
deity and then I point to my image
basically so now it's running I do a
preview and we're going to see the same
app now running exactly the same way so
nothing different from outside but the
difference is now this is running within
the docker so it's a basically a local
container running right now and I can
stop the container so if I the docker
stop this will stop my container so my
app is not running anymore
and the great thing at this point is
that I can push this image anywhere I
want so what I'm doing right now is I'm
using a tool called g-cloud it's a
command-line tool for google cloud and
I'm saying g-cloud docker push and point
to my image so I'm basically taking the
image that I built on my Linux box and
I'm pushing it to Google cloud I do that
because later I'm going to pull this
image and use it in Cuba natives so
that's the beauty of docker is that once
you build your image you can push it to
anywhere you can push it to docker hub
you can push it to the Google container
repository and you can pull it from
anywhere you want so it's really it
really makes your code really portable
you can push and pull from anywhere you
want so we are not going to wait for
this now because it takes a while and we
don't have that much time but in the
next step we'll I just pull this image
and work with that
all right so we built our hello world
app we containerized it so let's just
keep going forward so containers they
basically help you to create like a
lightweight and consistent way actually
a context for your applications to run
in but there's still a lot of things
that you need to worry about in
production right for example if you want
to have redundancy if you want to have
multiple versions of your app running
you need to take care of that if you
want resiliency so you want to make sure
your app is actually healthy you need to
create health endpoints if you want to
scale your app or down you need to do
that yourself if you want to deploy a
new version you need to do that if you
want to roll back to a previous version
you need to do that so there's all these
things that you need to still do and
containers don't really help for this
right it's still your responsibility so
that's when kubernetes comes in humanity
is trying to basically answer all these
questions and give you a framework to
basically do all this production stuff
in an easier way that's the whole point
of kubernetes
so what is kubernetes it's a Greek word
for governor actually the right way of
thinking when it is given it is everyone
says is wrong because it started in the
US I guess but it's a Greek word and I'm
from originally from Cyprus I know a
little Greek so if you don't learn
anything about this talk today just
learn that Cuban it is actually given it
is okay it tries to manage containers
container clusters it's an office 100%
open-source project it's written in go
it's supported by Google Red Hat and
bunch of other companies even though
it's open-source it actually came from
something called bork so at Google we've
been running containers for a long time
we built this internal container
management system called board so people
who worked on work they actually learned
from it and they created communities
from the learnings of bork so even
though it's open-source if they really
mature mature mature project because
people actually learn from bork and
created kubernetes and the great thing
about accumulative is that it supports
multiple cloud providers so you can run
it on your machine you can run it in
your own data center you can run it on
google cloud AWS as
so it really avoids when you're walking
so you can run it anywhere pretty much
and that's a great thing about it it
also supports multiple continued runtime
so you usually use kubernetes with
docker but you can also use it with
other things like rocket as well so it
tries to be really general and and
really plausible for whatever you need
to do at the high level this is what it
looks like so there's a master that
manages the cluster and master has like
API server SCT to to keep track of the
the the the cluster state their schedule
and controllers then you have notes
where you actually schedule containers
and then the master talks to the notes
using something called couplet but as a
user you talk to the master you usually
use the commenter's api but there's also
a CLI or na user interface as well so to
the master and actually as a user you
don't even care about this you you only
care about the API you talk to credits
through the API and the fact that there
is a master is kind of irrelevant to you
so to set up a command in this cluster
first you need to setup your your master
nodes you need to choose a cloud
provider you need to provision machines
for the containers you need to configure
networking so there's a lot of steps to
do to do if you want to do it yourself
or you can use something called Google
container engine that basically tries
that it basically gives the equipment
this cluster with just one command so
all these things that you need to do
yourself it kind of abstracts that away
for for you and then you can just use
container engine to get your gear in its
cluster and other cloud providers they
also have their own container engine to
make these steps easier for you so once
you okay so to do it on your Google
cloud platform this is what what it
looks like so first what you do is you
you build your application in cloud
shell then you create a docker image
with docker file you push that image to
to some kind of registry in this case is
Google container registry and then you
use g-cloud to create a cubensis cluster
so once you have the cluster you can use
cube CTL this is another command-line
tool to manage cube and it's cluster you
skip CTL to
scheduled containers into your cluster
so it will basically pull the images
from from the registry and they will
schedule them in here so in in our case
we built our app here we create a
document file we push our image to
content registry but we still don't have
cube entities cluster and we still
haven't scheduled containers onto our
cluster so that so that's what we're
going to do next in our in our demo
alright so in the next one let's just
create a query this cluster that we can
use
so remember we were pushing our image to
Google cloud so here I already push the
image so if we go to container registry
in Google cloud platform console we
should see an image for hello map and
then if you look under there we should
see a version number one so this is the
image that we pushed it soared in Google
cloud now I'm going to use that in my
credits cluster but first I need to
create a cluster so to do that I'm going
to use the g-cloud command so I'll say G
cloud container clusters create I think
and then I'll give my cluster name hello
net cluster and then you can specify how
many machines you want for your cluster
so these are the machines where I'm
going to schedule containers on in this
case I'm just using OneNote but usually
you need more than one node in your
cluster then you can also specify what
kind of machines you want for your
cluster so I'm using standard machines
that they have I think like two CPUs or
something like that but you can there's
a whole range of machines that you can
use for your use case and I'm also
specifying zone zone is where my cluster
is going to be in this case it's going
to be your quest so with this one
command I'm basically getting a
kubernetes master and then I'm also
getting a note where the containers will
be scheduled and everything will be put
together by Google cloud and then after
like a couple minutes I'm going to have
a cube and a squat so that I can work
with so it really makes it much easier
than having to do this yourself it just
with one command you get a cluster that
you can work with so I'm going to go
fast forward a little bit actually
almost at the end of it
so now it showed up here and once this
is spinning is done in which usually
takes like a minute or two I will have a
cluster that I can schedule containers
on so that's what it takes to basically
get a cluster on Google cloud it's
pretty much the same in other cloud
providers if you have to do your stuff
in your own environment it's a bit
longer but that's that's kind of like
how it looks like
all right so once we have the cluster we
can use it so we're going to run
basically what's called pods and they're
going to have replica sets and services
and volumes so I'm going to go through
these and explain what they are so this
is basically the kind of the heart of
the talk what are the building blocks
cube entities provides just to warn you
there's a lot of terminology that comes
with kubernetes so this is the
terminology that we're going to cover
and there's more so this is just kind of
like the basics at the beginning it
might sound a little bit too much but
once you go through them it kind of
makes sense and everything in here is
stuff that you don't have to do it
yourself so it's actually a good thing
that cube identity is really rich with
this kind of terminology so we'll go
through these one by one quickly at the
very high level this is what a cube a
nice costume looks like so first you you
have your container in some kind of
registry so in our case is google
container registry then you create
what's called the post mplet a pod is
basically a con single or multiple
containers that you put together so you
create a template for that and then you
create something called replication
controller so you tell replication
controller what you want it to be true
in this case I want three replicas so
this place it says create needs three
pots somewhere and then what replication
controller does is that it looks at your
notes so these are the notes that you
have in your cluster and it schedules
this pause in a way that makes sense so
as a user you don't care because it's
replication controller's job to find a
node and schedule your pots and then
once you have your pods running you need
to expose them to the outside world so
you create what's called a service a
service is kind of like a load balancer
for your pods and once you have your
service then people from outside world
they can hit your service and upon their
service they can get to your pod so your
micro service in this world is basically
not just your code your code is the
container but it's your code plus the
replication controller who watches your
port and your service that exposes your
port and everything about cube entities
basis so it becomes a combination or
Kuban it is and you're in your container
so that becomes your micro service so
we'll go through these pieces
individually now
but at the high level that's what it
looks like to you so the first thing
that I want talk about is what's called
deployment so when you want to use
kubernetes you create what's called the
deployment the employment you can think
of it as like a high-level construct
that a high-level construct that
basically creates the lower level things
that you need so you create deployment
and they create a part and it creates a
replica set and so on and so forth and
I'll explain what pause and replica sets
are so let's just create a deployment
abilities and see how it looks like
so here here we are we have the cluster
running and what I what I want to do is
I want to create a deployment with the
image that I just pushed so to do that
first I need to authenticate my cloud
shell with abilities so I can run
kubernetes commands so I just run one
gql command to authenticate once I'm
authenticated now I can run keep CTL
command so I'll say keep CTL run and
give my deployment a name so in this
case I'm calling it hello net that's the
name of my deployment and then I just
point to my image so this is the image
that I pushed earlier so with this it
will create a deployment and then under
the covers it will it will create a pot
it will create a replica set it will
create a create a service so it will
create everything I need to run this
image in kubernetes so I'm pointing to
my image and I'm also exposing the port
8080 so the deployment is created it's
very fast so if I do cube CT I'll get
the get deployment I should see that I
have my deployment or as a set up then
if I do cube CT I'll get pods so I
should see a pot but then it says
continue creating so Kuban it is
creating the container so it's trying to
schedule basically if I do get pods
again now it says running so within a
few seconds my pod is running and then
if I do keeps it I'll get get replica
set this is the guy watching my pot I'm
going to explain shortly replica set is
also set up and then if I do keeps it
I'll get services we have a service
already with an internal IP but there is
no external IP because I'm not ready to
expose my service yet but they're
already created for me so with one
deployment I have everything so now
let's go through these constructs and
replica sets and deployment and
everything and see what we have alright
so we went through deployment the rest
will be really quick because I want to
cover them but if it's too quick fine
after my talk and I'll explain in more
detail so I mentioned pods on volumes so
usually you have a single container that
you want to schedule but there are some
cases where you want to have multiple
containers together for example in this
case I have a container called file
cooler they put some file from some
content management system then it saves
it to a temporary storage called volume
and then I have another container called
web server that pulls that those
that's the content and gives it to
consumers so in this case I want my two
containers file cooler and web server to
live together and I want to volume also
to live together as well so I put them
in what's called a pod this way they get
scheduled as a unit so that's what you
do in Copernicus you can have a single
single container or you can have
multiple containers or you can have
multiple containers with volume in a
single pot so volumes as I mentioned
they're storage for pot and they can
attach to many things so you can have a
volume that gets attached to persistent
disk and things like that so we have so
be covered for them William
next thing is once you have your pots
you can label them so labels are kind of
like key value pairs for your pots so
for example in this case let's say I
have this pot and I have my my one
labels called app equals my app another
label called face proud or or test
another label called role front end and
back end once you label your pots you
can basically access them using
different ways what's called selectors
so you can say give me all the pots on
my app using this selector or you can
say give me all the pots of front ends
using this selector or back end or prod
or test so it gives you a lot of ways to
access your pot and this site is I also
use to create kubernetes constructs so
when you create a service you use this
selectors to create them all right so we
have deployment pods volumes we have--we
stack system using labels and selectors
now then the most important and I think
useful part of kubernetes is what's
called replica sets they basically help
for resiliency and redundancy so let's
go through the replica set in replica
set what you do is you you basically
specify what you want it to be true and
it makes sure that it is true for
example in here I'm saying I have this
replica set that's that's managing these
pods with the selector so it's managing
all the pauses that have app equals my
app and it's using this template to
create the pot and then I want four so
that means I want four pods running all
the time so replica set will keep asking
the API server how many phones do I have
if it's three it will create a new pot
somewhere and schedule it
at some point we have four pots it will
stop creating a new one so we just
basically constantly ask a test or how
many pots I have if at any point one of
those pots go down or you cannot goes
down replicas that will recognize that
and it will create a new pot so it kind
of watches your pots for you basically
so you don't have to watch yourself same
thing here for example you have a
replica set with three replicas and the
app and the selectors are app equals
demo and color is either blue or gray so
in this case I have three pots they all
have F equals demo and the color is some
of them are blue or some of them are
gray so replicas that will make sure
that this is true at all times without
you having to worry about it so now I
just want to show you quickly that that
they actually work so oops sorry so what
I'm doing right now is I have some pot
running here and it's being watched by
the replica set what I'm going to do is
I'm going to delete this pot and see if
Rebs gets a response so what I'm doing
is I'm saying keep CTL delete and pass
the idea of this pot and see what
happens so once I delete now replicas is
going to go crazy and it will if you
look at it it says there's a new pot you
can't really see it but it says new pot
and continue creating so what happened
is that as soon as I delete it apart
replicas that recognise that and then it
created a new pot and and scheduled that
so if this container is creating and
within a few seconds I have an import
running so this is great because I don't
have to worry about my pots going down
there's someone watching them for me
which is great alright
and how does replicas that know that
your part is actually healthy there's
health check link you burn it is so the
philosophy in Copernicus is that it's
your responsibility to tell humanities
that your app is healthy and you do that
in two ways one is called liveliness
frogs so you basically create an
endpoint and a port and then you
configure it with some kind of
configuration and cuba natives will ping
that endpoint once in a while with this
with this interval that you specify and
if you respond okay then it will say
it's healthy if you say no then it will
say it's not healthy and then once it
determines it's not healthy it will
basically kill that pot and create a new
one right away so it uses liveliness
pops to determine you if your products
healthy there's also something called
readiness probes in resonance probes
your your pot might be healthy but it
may it might not be ready to serve
traffic yet because maybe it needs to
get some data from somewhere so for that
you use readiness spokes so you define
your path and port again and and
kubernetes will ping that endpoint and
then when you're not ready to serve
traffic it won't send you traffic but
when you're ready all set sending your
traffic so that's that's what it uses to
do that all right so we we basically
have our parts we have our replica set
watching our part we have our health
checks the last thing that we need to do
is basically service we need to actually
expose our pod to the outside world so
to do that we create what's called a
service the way to create a service is
basically you use a selector again so in
this case we are saying I'm creating a
service with this label type equals Fe
so all the pods that have this label
will be exposed behind this service and
the service will have a stable IP and
the client will hit the service and then
it will be run more than between
different pods all right so let me just
show you that that how that works
so let's take a look at our deployment
it's running and then our pods they are
running as well so to expose my
prototype that world all I say is cube
Cpl exposed then deployment testing my
deployment name hello net and then I say
- - type equals world balancers so what
will happen is that Google cloud will
create a load balancer and then it will
attach it to the service and then the
service will load balance the pause so
so this way I'm basically exposing my
thoughts to the outside world through a
load balancer if you look at coops ETL
get service we have an internal IP but
the external IP says pending because
right now Cuban Google cloud is creating
the developed balancer
after a few seconds the low punches will
be created and will have an external IP
that we can hit so let me just fast
forward here because I don't have that
much time so yeah at this point we have
an external IP so if I go to the
external IP I will see the same
application running so nothing is
different in terms of functionality but
the difference is this app is running
within a container in docker and that
container is put in a pot that's being
watched by humanities so if something
was wrong with the pot it will be
recreated and stuff like that so it's
basically like being watched by
Copernicus that's the difference all
right
all right in the last five minutes I
have to go through it stuff really
quickly so what I want to do is I want
to just give you ideas on what existing
cube entities by one I won't show them
all of them because I don't have time
but it's feel free to reach out to me
after my talk and I'll go through them
with you p1 so there's a cube Anytus
dashboard by default it gives you
basically access to the pods and
services and replica set that you can
use I have a demo of it but I don't want
to show right now because of time and
then there are other things for example
if you want to scale in cuber natives so
let's say you have a replica set with
three pots and they're being exposed by
behind the surface if you want to scale
up it's basically as easy as changing
this 3 to 4 and then replicas that will
basically just create the part and
schedule it on some kind of note it's
just one command with one common you can
scale up and end down I have a demo but
I will skip it rolling update this is
really important let's say you have a
your app version 1 being managed by the
replica set and it's been exposed by the
service you want to upgrade the 2
version to your right way of doing that
is basically to create a new replica set
with version 2 and then add a new pot
this part is being served behind the
service because the service uses the app
equals my app for the selector so behind
the single service you can serve
different versions and then if
everything is good you add mock you take
one note here you add one note here you
take one out and keep going like that
and the Indiana if it everything goes
good then you get rid of this replica
set and then you have the new replica
set right so this is wrong update in
Cuban it is this is again with one
command you do a wrong update and it
does this sequence of events in the
right order the right way for you
basically so you don't have to do this
yourself it does it for you
automatically and then you can do canary
deployments so let's say you have a new
version you want to test that in
production before before rolling it out
what you can do is you you have a
replica set with the old version you
create a new replica set with the new
version you serve them behind the same
service and then if everything is good
you do a rolling update and then
have your new version so so doing canary
deployments is really easy in comparing
fees and then also scaling so let's say
you have your pods running with a
replica set you can install something
called hipster that collects metrics
from each part and then you can in
replica set you can specify I want CPU
target to be 50% so if they seek average
CPU goes above 50% replicas that will
realize that and it would create new
parts to bring the average down so this
way things are also scaled automatically
this is called also auto scaling so I
out scale automatically but also the
nodes under the pods
so the actual machines you can also set
auto scaling for them as well so this
way you have no auto scaling and part of
the scaling automatically so everything
is really elastic and just works all
right I think I'm running out of time
but just to in one sentence I want to
cover these so demon said let's say you
want to have a part you want to make
sure that you have a pod running on
every single node let's say it's like an
audit audit powder or something like
that where you do you doing some
auditing for those you create what's
called demon sets this way Airport gets
scheduled on every single node there's
something called jobs
so usually pods they they run forever
they don't they don't die and understand
not healthy but sometimes you want to do
like say batch processing where there's
some kind of job and then the jobs you
want the pod to run as much as this job
is but once the job is done you want the
pot to go away so for those you create
what's called jobs so that their pod
basically that that run as long as
there's jobs but once the job is done
the pods go away then there's staple
steps so the pods are stateless usually
but if you need to create some state
because you need to have like master and
slave or you need to have my sequel with
some kind of state you can create what's
called stateful pods and these pods
basically they have states that get that
get to persist it and then you can also
specify the order of the pods so you can
say this pod starts and then this
posters so you can have some kind of
stable pod basically all right
and then there's config Maps these are
basically configuration for your
application you define in a central
place for your app and then the complete
map get
attached to your pot as a volume so
every pot gets the config map as a
volume but your configuration lives in a
central place which is nice and the
secret same thing as configuration
except this is for like pastors and
stuff like that you create the secret in
a central place and then every time a
poster size it gets attached as a volume
okay so we covered all of this it was
really quick I'm sorry about that
because I want to cover as much as I can
but there is more
don't worry I won't go through them not
here if you want to learn more
humanities of IO is the link and this
link class of Google Chrome / container
engine is how to run it on container
engine this is my Twitter and email so
if you want to slide you can just get it
for my twitter and if you feel the
feedback form come here and i have three
teachers to give and if you want
stickers I also have stickers thanks
very much if you have questions I'll be
outside answering questions thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>