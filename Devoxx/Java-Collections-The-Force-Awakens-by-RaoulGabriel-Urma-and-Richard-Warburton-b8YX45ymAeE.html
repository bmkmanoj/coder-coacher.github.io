<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Java Collections: The Force Awakens by Raoul-Gabriel Urma and Richard Warburton | Coder Coacher - Coaching Coders</title><meta content="Java Collections: The Force Awakens by Raoul-Gabriel Urma and Richard Warburton - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Java Collections: The Force Awakens by Raoul-Gabriel Urma and Richard Warburton</b></h2><h5 class="post__date">2016-11-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/b8YX45ymAeE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello how's it going Richard let's uh
let's do that again guys how's everyone
doing good hmm excellent excellent
pleasure to be back here in devoxx
pleasure to be back here in Belgium
lovely to see so many people in the room
pleasure - doing some Belgian beer my
name is Richard and I'm role the title
of this talk is Java collections the
force awakens so hands up who saw the
new Star Wars film the other year that's
a good number of people if you didn't
don't worry we're not doing any plot
spoilers so you're still fine but you
should watch it but perhaps more
relevantly why talk about collections in
2016 at all they're like an old thing a
thing which we're all familiar with
we've been using collections for a few
years but I think it's one of these
things where even four things which are
mature and very good there's still room
for evolution there's still scope for
improvement even if what the improvement
looks like afterwards can be very
different from where we started so we're
going to be talking about some new ideas
when it comes to collections firstly
we're going to talk about a few kind of
very simple API improvements that you
can use in the Java collection the
framework today now we're going to talk
about things like persistent and
immutable collections so things which
Java hasn't historically supported very
well but which you can get the benefit
of through some third-party libraries
we're going to be looking at how they're
useful to you and how they can be
implemented and then we're going to talk
about a few kind of different
performance improvements different
performance discussions rating two
collections at the ends I hopefully
that's fun so got some bad news spoiler
unfortunately no light saber yet in Java
to help us develop but there's a few
other good stuff coming up so we're
gonna kick off is to review a few of our
favorite bugs with collection and you
know the first one which lady over on
arrow the array out of bound and this is
what happened to this little poor
machine here had a little out of an
exception or maybe drank a little bit
too much Belgian beer
who knows who knows who knows but
everyone's familiar of this book so what
we're going to talk about is two bugs
that may be a little bit less common the
first one is the concurrent modification
and then the check then act pattern and
to illustrate we'll look at a little bit
of code Richard so what was your doing
on him well you've got your array of
Jedi's then you're gonna print out your
Jedi's array and then you loop over it
see if the Jedi's name begins with a
lowercase letter and then remove it if
it does that looks good what happens if
we if we run this code the code compiled
so it must be must be working our lovely
mr. Shepherd and boom nasty nasty
concurrent modification exception why is
why is that happening well well it's
interesting to to see what's going to
the hood here we've got this nice little
fool over here which actually
abstracting any traitor object under the
hood so I've got a neat racial iterator
object header is responsible for
iterating over the collection and
separately regardless collection so just
to see a little bit what we've got going
on here I'm just gonna write it the the
vintage Java way axis we've got a any
traits object here and we constantly
poll to see if there is a next element
if there is we we fetch it and the
problem we have with this decoder here
is I've got two objects that are acting
on the same source there's a traitor
here and needs to keep track of an index
what current element it's currently
iterating over and there you've got a
collection here separately that's going
to remove the element but they're not
communicating between the two so we've
got to solve the unsynchronized problem
so and hence we got is conquered
modification exception hey that tells us
hold on lesson behavior header is
unpredictable those two objects here are
out of sync so instead what we do in
Java is to make use of the iterator
object is responsible for managing the
attrition and the removal of the
elements some like is him gravity
traitor and if the Jedi has lower case
then we use the iterator object to
modify the source okay
so the collection here in this case
we don't need a meal so from this code
what we'll see is we get the correct
behavior okay because we simply use the
truth object so that's great there's no
concurrent modification exception but
you've kind of used an iterator here
it's not really 2004 anymore is it
iterators a little bit old-fashioned and
not old-fashioned in a good way like a
fine wine more in the kind of you just
don't want to use it anymore way a
rotting piece of wood that's that's a
fair point and this is where api's can
evolve as new dramatic patterns come up
that may be error prone so who in this
room is using java 8 out of curiosity
awesome what I call it the same people
who went to see the force awakens
well in Java 8 a couple of methods were
introduced on the list interface of
actually on the collection interface to
make things a bit more convenient and
one of them's called remove F and what
that's going to do is immutable removal
on the collection if the element is
matching a given predicate so no K is
given a Jedi we we we want to check that
the Jedi here its first letter is
lowercase okay awesome
so let me just it's cold and you can see
you know take a few lines we can remove
this so Cody hey it's cleaner we've got
a nice method ahead that indicates
precisely what it's going to do and
we've delegated the internal
implementation the checking to the
library so that's great reduce the scope
for bugs awesome got rid of our F writer
brought things up 2016 vintage so that's
one of the you know common bugs and
there's another one that's fun
interesting which it called a check the
next principle so because we all of
thoughts and because if favorite movie
is the Phantom Menace what are you
talking about that is awful that is
awful Rich's favorite movie and what
we're going to do is watch this movie
lots of times just to support Richard
you know in this
time's watching The Phantom Menace
you'll lose your mind Big Data
hand-picked it's a big data survey too
big for Excel
maybe so let me walk you through this
code a little bit so you see what's
going on so we've got a sort of hash
ahead that's gonna keep track of them of
times we're watching the movie okay and
we initialize it to zero so what we're
going to do is to sequentially increment
the number of views to this map to
recall how many times it's being viewed
okay so don't worry about this executive
service stuff we'll look at it in a
second
so sequential ad very straightforward we
just pretend that we watch this movie
call a lot and then the ad one view here
gets a number of views check that it's
not now so we need to check whether
that's been initialized and if it's been
initialized then we can actually
increment it by 1 okay so very nice
straightforward code so let's let's run
it and if we run it we'll see that
actually we get a hundred tons of views
perfect well the tips a perfect
predictable deterministic but famously
terrible okay so what about the the
concurrent version of this code what if
what if we try and run that instead so
richard we need to go web-scale
so but scalability these days let's go
concurrent so what we're going to do it
just a method as implement a little bit
differently what it's doing here is to
use a an executive service under the
hood so we'll have a few threads and
with submitting jobs to that thread pool
and the job is essentially take the
hashmap and increment accounts so what
we're trying to do is to simulate that
many people concurrently could be
watching the movie ok so that's just
sending John to the thread pool so let's
run this code looks pretty good to me
it's compiling so let's ship it awesome
oh that's less than 100,000 so this is
good news if you go web-scale
less people watch The Phantom Menace
that is true but Richard we want to
write code that is deterministic
predictable we can test that this is not
good
I know what we can do I know we can do
that's
there's a concurrent hash map right in
Java so why don't we just use the
concurrent hash map I've heard if you
prefix class names with the word
concurrent it fixes all your concurrency
problems and what that's a great tip
let's let's just try this and see if
that works so let's let's run this
actually worse that's a bad tip as a bad
safe if they don't do that that's a bad
tip so let's let's go and have a look at
this concurrent add method what's going
on there so conquer an ADD submitting
job to do thread pool summiting just add
one of you Richard I know the trick here
okay
instead of using concurrent whatever you
synchronize synchronize is gonna fix
everything right makes things atomic you
know let's you know I don't know what
this code does but synchronized feels
like the right thing to be doing it'll
the big beautiful lock around that hash
map it's working
that's what but it's also basically
single thread at that point isn't it yes
that's the real problem so we're not
going web-scale we are not going website
so let's look at its good a little bit
and try to really understand what's
going on so we have all those stars head
are being submitted to you to the thread
pool and just gonna add one of you well
that's thick as the argument is the
movie views so that's all that's a
hashmap right that's the sort of this
global state head the hash map that that
is being shared around so we've got some
shared mutable states and what this
operation here is doing is a compound
operation that has several steps first
is to look up the new move use check
latinum use is not know if it's not
we're actually gonna act on this and
update the number of use so this is why
we call this the check then act pattern
because we are the condition and then
based on that we will act but because
it's a compound operation we could have
arbitrary interleaving happening in any
of those stages and threads they are
overriding each other's work and this is
why we get a date erase a and the result
isn't predictable so you're saying that
two threads at the same time both read
the views and then they both try and add
one to each of their different view
counts and then some of those updates
are lost indeed you know what I've heard
of this there's this replace method
isn't there with with with movie views
alright with concurrent hash map and
that will return you a boolean if it's
if it succeeded or not so this is the
replace method and that's the signature
and what replace is doing here is to
actually implement this idiomatic
operation right I decided that well
first we've got a value here we want to
check that it's the same value and if it
is atomically replace with a new one if
it's not then this returns false and we
have to try again
so what we want to implement here is a
mechanism where we use replace to
replace a value until we succeed ok so
we will loop we will get the views ok
we're going to check that the views has
been initialized ok and at this stage
what we want to do is to replace it with
an updated value so if we manage to
replace so we take the movie we take the
current view so this is one expecting
and if we get the same value then at
that point we're going to replace it
with this added value and break so let's
get the number of parentheses right so
there's a pass in the requires a lot of
patience that codes going to try and try
and try again until it succeeds where it
should this could exhibit complicated so
let's just check to make sure it's
working oh it does it does amazing this
is a bit painful it's really really
verbose very broad I really don't to be
writing this yeah but there is a new
friend in Java right right compute if
present in computed present is
implementing this pattern where you want
to compute a value if it's been
initialized so what it takes here is a
lambda expression that's going to
dictate what's the recipe to update the
value in the map
for that given key so the recipe here is
exactly the same one here we get a views
and we add one to it okay awesome so
let's get rid of this and run a code
again to make sure things are working
but already you can see it's much neater
the code here the name of this method
indicates what it's going to do complete
if it's present and we've delegated
internal implementation details at the
library so code here we reduce the scope
for bugs again thanks to API
improvements excellent awesome but
that's not the only thing that's been
added to what we've talked about so far
things are existing in in Java and Java
8 and there's a few goodies that are
being introduced in Java 9 there's a few
improvements to the stream API to the
completable future 2 optional which
we're not going to talk about but the
let's run this again one of the fingers
being added to Java 9 is collection
factories so traditionally it's quite a
pain to create different collection
objects and let's say I want a list of
string a bunch of CDs awesome I'm gonna
create an ArrayList I'm just going to do
it the old-school way for a little bit
and we're gonna empty array here by the
way this is called the J shell so to
repple has been introduced in jdk 9 mark
renho was showing a demo in his keynote
so that's quite nice to be able to play
with different api's and get a feel for
how they work so what I want to do has
just finished as an array list and add
two elements to it so maybe I'm gonna
address those to it that's why you were
warned
that's why I was born and in Belgium we
love the Welsh people thanks to the
football so we're gonna add Cardiff into
it that's where I was born that's where
Ritchie was born and if you look at the
cities we can see we get an ArrayList
with two elements the text color of word
just to create a simple ArrayList and
there is something else I was introduced
here
arrays as lessor and I could say London
but that doesn't really work for for a
set doesn't work for for a map what if I
want to have a convenient way to create
maps and sets we do actually have that
facility but Richard you know languages
that groovy and Python they've got
syntactic sugar for this collection
literals collection neutrals like
bracket Cardiff Brussels brackets
something like that exactly like this
syntax actually right like this wait no
we have this in Java
well that's a lot of costs when you do
these kind of things are there's a lot
of time that could be spent implementing
other features but what was added in
nine was collection factory methods so
works like that so you just say they
start off boom I'm getting a mutable
list those returned you want to set you
can do the same thing here we're gonna
say land and Cambridge actually my
favorite City Cambridge right so we get
a nice convenient way of creating
different sections and we can also have
a lab so let's import aesthetically all
the goodies in the map and let's say
I've got a map of different entries and
I have an entry here that tells me
Brussels how many people are they in
Brussels Richard 1.13 nine million one
four one three nine million people in
Cardiff 341,000 we win we win yeah not a
football that football right so this is
sort of a nice convenient way to create
from maps and you can see how you get a
a nice little map dice produced as it
results okay awesome
so as convenient improvements to the API
that we introduced in in JDK nine
fantastic cool so that covers a little
bit the different topics there but one
finger is interesting to look at you
said you checked in act a pattern that
we showed you may think actually it's a
really contrived example but there's
some research actually performs some
static analysis so they took a bunch of
open source project and they were
checking
whether this pattern actually happens in
real code and whether there are bugs and
they fund about two hundred eighty bucks
for the checked-in Act pattern in
projects that can Sandra you seen right
not just boys projects real big open
source projects that people genuinely
use so it's great though we've got a new
API improvements here to reduce the
scope for these kind of bugs so if you
interested more about Java nine updates
there's a link here that you can check
out afterwards so we've talked about API
improvements what we're going to do now
is to talk bit more about data
structures and possibly sort of
improvements that could be done to the
collection structures so Richard so
things always helpful when you're
thinking about a big topic area like
collections try and categorize or break
up that toping to different areas and
one of the ways that we've thought about
it in terms of splitting these things up
is you can first of all think about
mutable versus immutable collections so
collections you can add or remove
elements from change the state off and
those mutable collections could both be
unsynchronized just like a ray list or
something concurrent like the concurrent
hash map we saw earlier then we can
think about an unmodifiable views which
are kind of a wrapper around mutable
collections so we firstly look at our
mutable friends here very very popular
very very commonly used ArrayList hash
map tree set these are collections which
when we say memory efficient
modification operations we mean they're
just updating their internal state they
don't need to return you a new copy they
don't need to do anything like that they
can be thread safe but it takes a lot of
design a lot of care to get them that
way but Richard what tricks do we have
you know if we want to be able to
prevent those accidental updates what
can we use in in Java right now
well something that's been in Java for
ages and arguably is quite underused but
useful feature is this unmodifiable
concept so the collections class has
some factory methods for unmodifiable
lists on modifies modifiable sets blah
blah blah and what they do is they allow
you to wrap a single value a single
collection up and give you an
unmodifiable view on it so if you try
and add something so here for example or
adding darvon
reader into our list of Jedi's Darth
Vader is not a Jedi so we throw an
unsupported operation exception and and
stop that modification but obviously you
can still modify the underlying
arraylist now in some senses this is
really useful right you may well want to
have that modification but there's a
little problem isn't there to be honest
this is really cheap to you to to create
to get his view so that's one benefit
but the problem is a little bit
analogous to the two def style so
Richard really wants to have a Death
Star at home and the Brawn with the
Death Star it's like one tiny little
flaw right we can still exhaust port a
little thermal exhaust port on the
collections which is once you've got
that reference the underlying mutable
data you can modify it but you can break
the invariant that you might expect to
have so that might not be the right tool
at hand but Richard the alternatives
what I hear all those functional
programming languages they really talk
about something called immutability
right what's that about good question
so there are different types of a
mutable data structure so these are data
structures which you don't change that
reference when you've handed out that
reference you don't update or modify the
state now these are very useful for a
concurrency point of view because you
can hand off different instances of
these objects and because they're not
going to have modified state they are
not going to have any data races with
that modification of state it's very
useful for holding a reference I'll
object it doesn't have that Deathstar
problem where one person can completely
undermine your invariant that you're
maintaining and the simplest version is
non-persistent immutable collections
right so by non persistent we mean when
you add a new element in they basically
copy the odd values in add the new and
in Harran going nice and simple probably
my favorite characteristics about the
immutable structure decided I can
convert something more efficient way for
think about something like a mutable
tree you know there's a bunch of nodes
and they're putting each other's that
takes a lot of memory overhead but if
you know that tree
not going to be changed you could
convert it into a single array and use
an offset based strategy to look up the
elements so those are kind of things are
possible using immutable immutability
but Richard sounds a bit useless if we
come modify it you know what works
you're going to do the real world where
she need to change objects right so what
we're going to do well one collection
API which has got both immutable and
mutable versions of collections is what
you speak all the goldman-sachs
collections is now the eclipse
collections and what they have an
approach is Java has this list interface
which is a list interface for a mutable
list so when you add something it
modifies the underlying version but they
have a list iterable interface that is
just the read-only methods on the list
that lets you hand out a read-only view
and then that can be implemented with an
immutable list which has a method on
called new wave which would return you a
new list or a mutable list which would
modify its state internally so it is
possible to help you incrementally
migrate a code base and an example
library is something that implements
those non persistent immutable
collections that sounds great but there
is another option which is the immutable
and persistent collections operation and
this is where a change in the source
produces a new version the collection
but they try and share structure try and
share the values with the old version of
the collection so you don't have the
cost of copying all these elements every
time you want to add one collection so
let's look a bit more detail at this
right because when talk about
immutability in functional languages
there's perception that's really
inefficient we have to copy everything
and there's actually a few tricks that
we can do to reduce that problem so we
have to go back in time with to go back
to Lisp
Richard yes I do but a problem with Lisp
it's fun to programming but the
different bracket keys on my keyboard
eventually they just broke from overuse
so I've got a new keyboard for you here
this is your new keyboard say all your
problems awesome
and you wanna use list in the past keep
your hands up anyone's still using Lisp
oh come on it must be one person sure
there's one buddy one guy somewhere okay
must be closer these days okay awesome
nonetheless awesome nonetheless but what
list did which is really a fantastic is
to come up with this idea of a
persistent list AKA called the cons and
the basic idea with a cons list it's a
bit like the Russian doll concept right
you take the doll and you wrap it up
into new one and you wrap it up or the
Christmas box saying idea so what we're
going to do here is whenever you want to
add an element to to a list instead of
having to you may change your pointers
this actually wrap this element with the
next one in the line so let's say I've
got a head of hair so that's a new
element I like to I then I've got my
tail which is the other boxes well I'm
gonna give you a new box with the head
and the tail if you want to update this
again let's wrap it again and this
wrapping technique here doesn't need any
mutations because we're always creating
new objects around it that's quite an
important idea has that actually taught
to provide an updated version you don't
need to modify it you can create a new
version that wraps the previous version
so we sharing state with the previous
version so that's the key idea so if we
look at it from the more visual point of
view so we may want to also modify an
element within a list as opposed to just
append it so let's have got this element
here see and I like to change it to
something let's say the letter D so
brave brave so what we're going to do
well I'd like to provide an updated
value for C so that's going to be a new
element called D
unfortunately ba is pointing at C so I'm
going to change this so it points to D
hi AE is also pointing to B so if you
change B they need to change a as well
indeed so what's going on here is that
have to copy everything leading to the
new elements that we want to change
which we can then hook up to the next
element in the list so in this case say
we create the we create a copy for B
with create a copy for a those are
linked up and then we can share the tail
of that list and the previous version
here is still independent so it sounds
like what you're saying is if the
elements of the front of the list and we
want to modify it or change it we have
everything after that we can share and
it's nice and easy
if we have something that say the last
element in the list or the last but one
element in the list it's not really
giving us much of a win that's true so
the last element here we still end up
with a full copy but you know there's a
few other tricks but what's something
that's interesting to you too to mention
it has well it also works for merging
two intermediate lists maybe you've got
some work been on parallel you like to
merge them the other thing you need to
do is to copy one side to the right-hand
side you don't need to copy the whole
thing there's a few issues with this
approach one is yeah if we need to
modify the elements at the end then wind
up with a full copy so that's not great
the other problem we have we think about
something like an array it's really nice
in terms of caching the next element
it's offset is very predictable so the
prefetcher can just take it put in the
cache it's very cheap and convenient but
something like a linked list approach
each element is pointing somewhere in
the heap so we can't prefetch it and get
the win here from the caching point of
view so has poor locality so that's one
big yeah problem for me performance but
randomly walking around memory is often
you know a thousand plus times slower
than reading through memory in a nice
sequential pattern as well so that's
there's a huge there's a huge
performance cost there in some respects
so richard sounds like the trick here is
we want to be able to reduce the number
of elements that we want to copy and
reduce the number of times we have to
navigate through this sort of chain of
pointers and there is an a we talked
about this but there is a sort of
another data structure called the binary
tree right which lets us reduce the
number of navigation required to locate
a element but we need a trick and the
trick here is
well if those elements are comparable I
can decide which sites to pick if it's
smaller than whites I argue on the left
if it's greater than the other I can go
on the right-hand side and by doing this
we can reduce the number of steps
required to locate one specific element
and that means there is fewer copies to
do in this case hey if I want to modify
the elements on the bottom right corner
what I can do is to create a new version
for it copy the parent copy the
grandparent and then link that back to
the previous version of the structure so
what happens here is actually I only
need to copy three elements as opposed
to copying potentially the whole tree so
that's an interesting property here we
get this sort of structural sharing with
a previous version so we've reduced the
number of copying required and you're
saying as well we can use the same
binary tree concept for implementing
what a jar would call a list type data
structure by using the index that you're
going to look something up as a way of
defining order over these values even if
they're not comparable right precisely
but the issue here Richard is that you
know let's say we've got lots of
elements he's and it's less we end up
having you know quite a lot of
navigation to be doing still so what
we'd love to have is performance and the
safety that immutable data structure
providers we want to have the power of
digitizing a safe together wouldn't that
be fantastic yeah that sounds great to
me and you've got all sorts of different
color lightsabers if you do that as well
so you can't go wrong as a plan let's do
it
let's do it I don't know it well the key
intuition is we can go beyond binary we
can go beyond just like splitting a tree
into two parts we could actually have
more than two children right some people
have three children four children why do
we have to stick to two so it's good
form or more is better so this is why we
call it tri data structure it's called
try not to be confused with tree all
right so that's the but I heard they
originally called at a tree that was the
goal to call a tree but then they said
wait what's the difference between a
tree in a tree let's call a try that's
um
better idea much better idea and what it
means is the branching factor can go
beyond two so here's the sort of data
structure that's quite useful for things
like looking up the number of words that
start with a prefix and the key idea is
we can use the edges edges are gonna
have a label and are gonna be used to
locate the leaf nodes and information is
only container leaf nodes so if I want
to find out all the words in the English
dictionary that start with AC I can
navigate the edges AC and bam I'll get
the number of elements okay
so great data structure for this sort of
a prefix search but a beauty here is
that we can increase the branching
factor which will help us reduce the
death that we need to navigate through
okay so that's the key key idea awesome
so we can extend this idea to arrays
I've got this crazy thing here called a
bitmap vector that's why hitting that
vector try sounds like a dental
operation there's teeth all over the
pace blood all over the place children
are crying why why do you want to make
children sad Rowell lion computer
science you always need to have some
like fancy sounding you know
terminologies to bring up doing parties
and stuff so probably what happened here
okay don't know who's responsible for
this but what we're going to try and do
is to extend this idea from a try where
instead of having strengths for the
edges that lets us look up the leaf
nodes we're going to use a bit
representation of the index for the
element that we want to look up okay so
if I want to find the the element at
index number 45 I'm going to use the
binary representation 45 okay so that's
going to be the bitmap what we can do
with that is to use different parts of
this bitmap to indicate which level
detroy we're going to delegate it to so
let's say the first five bit here are
going to tell me what's the element at
the first level the next five bit are
going to
tell me what's the elements at the
second level that I need to be able to
look up and so on until we find a leaf
node so again serve efficient arithmetic
operation hey that lets us navigate to
the leaf node where the actual value is
contained and that's a basic idea with
the bitmap vector tri is that we use the
bit representation of the index of the
element so we can navigate Detroit so
this sounds very theoretical and
incorrect concept is anywhere actually
using this kind of approach well so this
approach is used in a lot of functional
languages like Scala is as a persistent
array implementation closure has a
persistent or implementation and bunch
of libraries in Java also using that now
but there's a bit of a trade-off Richard
the trade-off a is you know we've got
this complex data structure here we used
an arbitrary number of levels so in our
case we were using five levels and five
level means we actually only have five
lookup to be doing so it's near constant
time to look up an element that's quite
an improvement upon the binary tree
right when we get the log and complexity
I'm much better than the original linked
list approach where we had no rain to
get up there
we get a nice improvement but there are
trade-offs right having large branching
factor means the iteration become really
cheap but if we need to update an
element suddenly we're going to have to
copy every node leading to that elements
of 32 every time so we get caller of
copying going on but we get a nice
caching property though because we get
30 element array and a smaller branching
factor means that we get a higher
iteration problem so the death is going
to be larger but we potentially reduce
the number of copying required because
the nodes here are smaller so five is so
the magic number that a few libraries
have adopted and here's a bunch of
projects available in Java speak
election there's a poll of the closure
to the data structure a port of the
Scala data structure and Java slang
there was a talk about Java slang we
love Java slang hey bring functional
areas to Java recently introduced
a persistent array implemented through
this bitmap vector try I did I know the
Java slang guys as well the pull request
is only very very recently accepted on
that but they've done a huge amount of
work on benchmarking optimizing their
implementation so that's that's looking
really positive indeed
so we don't have performance blech my
hair but one interesting thing to look
at is the memory usage I love all those
different collections so we run a little
experiment here again we're going Big
Data 10 million elements this actually
might be too big for Excel anyone uses
Excel here anyone else but um here you
know if we want to sort n million ants
of primitive it's the memory overhead of
that would be a forty megabytes or four
bytes for an nth if we as the bugs
representation however of an array so we
paint the overhead of having an object
we get 160 megabyte outrageous
outrageous but what's really interesting
is that actually if we use an ArrayList
or this persistent vector from closure
or the scallop port one the pseudo have
equivalent memory consumption in fact
actually the scalar implementation has a
smaller overhead now that's a little bit
puzzling isn't it Richard but it has to
do because the implementation of an
ArrayList if a runs out of space just
leak its its memory so you've got more
elements available so you still paying
the car safe or having some extra space
in the case that we are over overloading
the data structure so we're paying this
custom and the thing is these numbers
you're talking about are with heat being
less than 32 gig is but we're talking
about numbers with compressed OOP
switched on if you have an even bigger
heap
you'd have even larger pointers in these
numbers would be even even larger for
the ArrayList over the primitive version
so the interesting differences those
persistent data structures they can grow
dynamically all right as you add a new
element you only paint the cost for
adding those elements something like an
ArrayList if you over flowing
you might potentially pay a higher cost
where you have to suddenly create some
new space in the data structure so what
are some takeaway
well we believe in mutability in general
is good practice an immutable collection
reduce the scope for bugs by preventing
mutable accidental oppressions but
unfortunate is always a compromise
between performance and the safety
benefits but that's something that we
see a lot of improvements we've recent
data structure and the persistent arrays
is when one example of them
absolutely so let's how to talk about
some of their performance improvements
that we've kind of seen in a few of
these places now everyone really really
does want some performance improvement
right you want to go really really
really fast and in fact we decided that
in the context of this talk we actually
need to update Big O notation don't we
yeah well newer faster form of Big O
notation so we decided that there was
order n linear time order one constant
time and all the hyper space for when
you want to go really really fast so we
can't wait to send a Java duck out of
hyperspace that's the new thing
excellent now the first thing we're
talking about is as you mentioned
earlier with the primitive interets
that's something very very simple if you
have primitive specialized collections
they use up a lot less memory and they
you they are much much faster for both
adding and removing things from so Java
rate has perimeter specialized streams
in the form of inch stream long stream
double stream and perimeter specialized
function interfaces and there's a bunch
of third-party libraries out there we
mentioned eclipse collections earlier
kolobok a and also the aronia library
that offer primitive specialized
collections but there's actually
improvements happening pretension future
version of Java is a project called
Mahalo that looks at having primitive
specialized generics so we can get a lot
of those improvements in the JDK itself
and if you've been using Java 8 you may
see things like functional interfaces we
got primitive specialized function
interfaces to make up for this
deficiency so there's a wider research
being done ahead to get some of those
benefits but for the language and the
JDK level awesome another very very
simple existing collection improvement
is that Java rate started a lazily
initial
in collections so there are loads of
places and code bases where things like
empty arraylists are passed around as a
potential value or empty hashmaps get
initialized with nothing ever added to
them an example might be say an API that
used HTTP GET parameters and put them
into a hash map and then never had any
parameters so pass them on and Java rate
added very lazy initialization so the
backing array in the ArrayList and the
backing array of entries in the hash map
never gets initialized until you
actually add the first element in so
reduces the memory consumption also
reduces the memory allocation rates for
things like this where they when they
don't get used so simple but effective
and there's a bunch of other
improvements that have been made in Java
AIDS specifically with hash map
con richard is do a bit of you to speak
and it's really the same time let me say
map hash we want together ready three
two one hash we want
fantastic so let's talk about hash map a
little bit here
excellent so very basics of hash maps
which I'm sure everyone's familiar with
but let's just mention anyway we have a
backing array of entries and we want to
put a key into that map so we rehash the
values in that key
we got a hash code and then we apply a
modulus of length of that array and that
gives a slot to put us in hold on
Richard I hate Chewbacca is Han Solo's
best friend and there's such good
friends that are gonna share the same
hash go to the best buddies really
that's awesome
what's gonna happen well you get a
collision don't you you get a collision
sometimes being really really good close
friends it's a bit too much here so once
you have a hash map with a collision you
need to have some strategy for saying
how do we deal with collisions and the
general approach that people talk about
its chaining versus probing so chaining
strategies are you have a little data
structure of each node to put things in
and probing strategies are where you
store things in line in the main the
main backing array and you have a
probing sequence you say oh I'll just
look at the next element or the next
or I'll I'll have some function that
tells us how to find the elements and
the interesting thing with these things
is that you get a lot of terminology
confusion here you get probing chaining
open addressing closed addressing all
sorts of things but it doesn't really
matter it's like this difference here
between Palpatine and Darth Sidious
they've got different names but they're
really the same guy equally evil equally
evil face that's an evil face it's an
evil face and they're responsible for
all those terminology is the academics
right yeah really sorry about this but
if you hear but close addressing open
addressing and open hashing close
hashing you know it's all under the
chaining and probing category so it
means the same thing the best thing
about this terminology confusion is
they've used open and closed to mean the
exact opposite different things
depending upon whether it's addressing
or hashing that's that's awesome
confusion for richard in java 8 there's
been a few improvements to the hashmap
internal implementation specifically
with the chaining strategy yeah so Java
is a chaining based approach now
historically this was a linked list
chain so if you have a collision it
plots them into a linked list but there
are other data structures you can use to
make that lookup if it's say a
comparable key you can use a tree based
lookup or something like that and that
as you say it was introduced in Java
right so it historically maintained a
linked list now if you have a high
collision rate you get an order n lookup
so the change in Java rate was to change
to use a tree based data structure but
they don't go for a tree from right from
the beginning do they know it's
interesting because they've got a
dynamic strategy where the hashmap hare
converts to add a tree implementation if
the number of elements are growing which
means potentially would reduce the
number of iteration required but Richard
we got those two strategies ahead we've
got the linked list strategy we've got a
tree strategy we need a winner right
like in general we need the best
implementation which one is the best you
are a winner you're like a massive a
lightsaber bass
between the different hashmap
implementations well let's let's have a
look at what what's really going on here
I mean oh I did a few benchmarks here
and in fact first before I wrote any I
had a look at a lot of benchmarks on the
internet and those benchmarks are what
I'd call jar jar benchmarks and charge
our benchmarks are a lot like jar jar
binks they're not useful to anybody at
any point in time ever
no modeling of the different factors
that influence performance things like
just calling a get on a single key for a
map of size 1 now there's actually a lot
of different trade-offs that you have
when looking at different collection
implementations so first let's have a
look at the difference between the
different implementations in Java right
so I started having a look at what
happens when you have looking up keys in
increasingly large maps and what I did
was shows the opportunity to see if the
tree based strategy worked by taking
comparable or income or keys that don't
implement comparable and are otherwise
different and the red bars are the ones
that don't implement comparable and you
can see that as it scales up you get a
very very significant improvement in the
lookup time so that that works really
really well at high collision rates like
his 60% of the keys collide with other
keys but if you have very very few
collisions this kind of optimization
doesn't really make much difference so
depending upon what your use case is it
may have either been a huge win or
nothing at all the other kind of
trade-off that we sometimes see is
probing versus chaining now we didn't
come up with terminology this is a pg-13
talk but we do you need to think about
the difference between probing and
chaining normally probing maps have
lower memory consumption because I don't
have to have this supplementary data
structures going on out of fact if you
get very very few collisions or small
maps probing often completely destroys
chaining as a strategy looking up in the
map very very hot just a straight array
boom-boom-boom can be 91% faster but if
you get really big maps with really high
collision rates probing scales really
poorly because you're not having these
long chains where you probe down the
chain and down the chain of fail and
fail and fail lots of collisions so
sometimes they can be much much slower
like thousand times slower in some cases
you're wondering if probing is used in
the JDK collections at all is actually
one implementation has medical identity
hashmap they use a probing strategy
exactly yeah very fast very low memory
consumption if you want that kind of
identity based key a quality concept
great use of entity hash map but really
there's no clear-cut winner the JDK
implementations generally try and trait
trade-off the worst case scenarios they
try and keep your worst case not so bad
if people have hash codes that always
return one it happens then they won't
fail quite so badly but third-party
libraries often pick probing based
strategies where you'll find they'll
often win over the JDK collections if
you've got smaller maps with really
really well distributed hash codes and
their keys so let's look at a couple of
conclusions shall we to to wrap up the
talk collections are improving both on
the safety side and the speed side right
so we looked at how things like
persistent and immutable collections can
really really help you make things safe
they give you that in immutability
characteristic that a lot of people want
and they're not as fast as they you
throw they're not as slow as they used
to be in the old list days
implementations have improved massively
over the last 30 40 50 years and even
existing core library collections which
have been around in a really mature like
hash map have improved their performance
over time as well
now I'll give you guys an opportunity to
ask me questions and if you want to ask
them on Twitter if you don't want a
shout out or find the microphone you can
tweet on hash Java force awakens and
will it will answer your questions as we
go along I hope you really enjoyed the
talk today it was a pleasure
speaking to you all and Rowell and I run
a training company called iterator
learning where we run training courses
looking at Java rates looking at
reactive and asynchronous Java and a
general kind of software development
master class bootcamp type thing
now just to incentivize you to ask some
good questions Raul has a few free
copies of this mini book on introducing
Java rate to handout so so come down
there's only five so if you want one
come and come and talk to us afterwards
thank you very much
does anyone have any questions in the
room I literally can't see anyone I
can't see but please use the Twitter
hashtag here we're going to look at
Twitter in a bit and reply one by one to
your questions give any</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>