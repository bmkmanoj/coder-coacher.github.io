<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploy microservice using Amazon Web Services S3, API Gateway, Lambda and Couchbase by Arun Gupta | Coder Coacher - Coaching Coders</title><meta content="Deploy microservice using Amazon Web Services S3, API Gateway, Lambda and Couchbase by Arun Gupta - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploy microservice using Amazon Web Services S3, API Gateway, Lambda and Couchbase by Arun Gupta</b></h2><h5 class="post__date">2017-05-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eT4EaU2mfL0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Birgit inflated do it make sense
all right good afternoon last session of
the day almost there
excellent my name is Arun Gupta I work
for Amazon Web Services today I'll talk
about how do you deploy your micro
service using four components AWS s3 API
gateway lamda which is our server less
offering and Couchbase as an individual
I am a docker captain I've been talking
about containers for a while I'm also a
Java champion I've been speaking at lots
of different conferences around the
world for a number of years let's jump
right away you know this is a definition
given by Martin Fowler in terms of it
what is this thing here ok that's not
part of my slide all right this is the
definition that was given by Martin
Fowler for micro-services
lot of vendors have adopted the
definition for their taste but if we
look at it in a very small way you know
it's basically a you take a big monolith
which is hopefully well designed and
then you break it into a suite of small
services each running its own process
the key to that is monolith should be
well designed if you have a big pile of
monolith you know you don't expect a
spaghetti ball to be broken on into
microservices don't expect that but
essentially you break down a single
application into a suite of small
services where they are talking to each
other using simple protocol like HTTP
and that's how they are communicating
with each other each of the unit is
independently deployable and they do not
require any administration or management
and then there could be coded using
different programming languages they
could be using different storage
technologies so in that sense it gives
you the ability to use the right tool
for the right job as opposed to saying
hey a company-wide we use Java or Python
or Ruby whatever that language is you
know end of the day HTTP is the protocol
that you agree upon for these different
applications to communicate with each
other let's look at the definition now
and then we will revisit this definition
towards the end showcasing exactly the
different components how we talk about
how they solve it
take a look at any classic web
application how do you design it bug
he's got a web page you've got a bunch
of JavaScript but you've got a bunch of
web pages and one bunch of JavaScript
each of those typically make a call to a
rest endpoint you know you don't you
don't care you don't worry about where
the rest endpoint is hosted then those
rich endpoint essentially call a code no
it could be in a Java EE application
spring application nodejs wherever it is
you got those applications hosted and
then finally it does a crud to the
database you may perform business logic
transaction security so this is a very
very extremely simplified definition of
how your typical web application may
look like if you see from another
perspective
it's basically an MVC kind of an
architecture you got your controllers in
the middle which is your rest endpoint
which is defining where the request or
the control should go to the view is on
the web page and the JavaScript part of
it and the model is sitting at the back
okay again a very overly simplistic view
of how your application may look like if
you were to kind of break this down you
know how would you do that so
essentially I could have multiple HTML
pages index update create delete those
HTML pages my rest api is are
essentially get put post delete how you
expose them whether you're using Jersey
or you're using node.js it doesn't
really matter in the backend you could
use for example a lambda function we'll
talk about lambda functions what does it
mean really
and then they could store to any
database in this case I'm choosing
Couchbase but you can choose any
database of your choice doesn't really
matter so the architecture that I'm
going to show you here today is how your
service the static files could be hosted
on s3 how your API is can be configured
using api gateway then lambda is where
your server architecture is going to sit
and then eventually your database could
live wherever you wanted to in this case
this card space so that's sort of the
broader architecture I'll talk about it
I will show how these different services
can independently evolved and
communicate
let's talk about serverless computer
there are certain typical challenges
with server based computing when you
what that means is okay I need a ec2
instance or I need a VM and I need to
run a server for it so okay how do you
do the budget and performance comparison
do you overcapacity it do you understand
how much money you got so you go to do
that capacity planning to begin with how
do you scale your servers up and down
I'm not saying these are not known
problems but just to be aware of some
challenges that comes as part of it so
these are challenges but there are known
solutions to this what operating system
you know I want to run tomcat should I
be using Center should be using Ubuntu
should I be using rel is it my corporate
license should I bring my own license do
you really care about that okay I got my
operating system what settings should I
do it which is optimal for Tomcat or you
should I use the army you know which is
already pre-baked with all those
settings operating system upgrades and
how do I handle with that who should
have access to servers how do I deploy
new code so these are some of the
challenges typically when you're doing a
server based computing that you need to
be aware of and you need to deal with it
so let's take a look at it you know how
virtual machines and then the next wave
that you're seeing containers and then
the future wave that will be seen which
is sort of becoming prominent now is
server less okay if you take a look at
it in terms of virtual machines your
unit of scale is you take one virtual
machine and you replicate it if you want
to scale it in terms of containers and
on each container could be or a bunch of
containers could be an application and
then you can scale them and if you want
to scale then your scaling really at an
application level in server less what
the unit of scale is function think of
it an application has broken down into
multiple functions is an even driven
architecture in that sense and that
function is what is the unit at which
you are scaling it in terms of
abstraction when you're using virtual
machine you don't care about what is the
underlying hardware you say I want for
CPU 16 gig you're running Intel you're
running Nvidia I don't care just give me
this processing power
in terms of containers you don't care
about what is the underlying operating
system hey I'm running a docker
container whether you're running or
Ubuntu or CentOS or Mac or Windows just
give me a docker container and I'm good
with that
in server less what you care about is
the language I want to run a Java
function everything else you know how
you wanna run it how you want to
provision it how you want to scale it is
up to you don't I don't worry about it
then in terms of packaging you know if
you look at virtual machines if you're
running on Amazon then your typical unit
is army or Amazon machine image in terms
of containers of course you're taking
your image or a docker file where you
pull the continue definition and then a
packet is an image and it goes into
docker hub or container registry in
terms of server less your unit is really
code hey this is the code I want to
execute you go figure out where to run
the code what did you configure in each
case you know in I mean virtual machines
essentially machine network storage
operating system all that needs to be
configured by you you can use
pre-configured army or you can have
somebody else bake the army for you but
in terms of containers excuse me
in terms of containers you need to run
servers configured applications scale it
and all that things that you are
responsible for so you need to run some
sort of a monitoring dashboard for that
in terms of server les is pretty
straightforward here is the code run it
scale it whenever it needs to be done
execution again you can see sort of the
different programming models
multi-threaded multitask as opposed to
servers which is single threaded single
tasks and as a single function running
at a given point of time non rien trent
and you can deal with that
lifetime you know if you are looking at
a virtual machine they are typically
running from hours to months if you're
looking at containers typically there
are minutes to days you know you would
typically recycle your containers from
minutes to days and last but not the
least in server less you know your
server less functions run from micro
seconds two seconds and then you're done
with it cost if you look at it and now
typically your virtual machine is per VM
per hour if you look at containers is
per VM per hour as well because
essentially that's where your containers
are running in terms of server less is
down to the granular level where you're
saying per memory second per request
okay and I'll talk about AWS lambda
which will compare and contrast these
things and last bullet here is in terms
of offering if you take a look at it
virtual machine typically when people
think about it they call it as ec2 is
sort of my standard way of building
machine images if you are running
containers then of course you have
different offerings darker kubernetes or
Amazon's ec2 container service and then
if you're doing server less and of
course there is AWS lambda lambda and
there's some other vendors who have
their server less offerings as well
another view in terms of you know if we
kind of flipped the table a little bit
if I'm looking at internet about
infrastructure to the service container
as a service platform as a service and
fast as opposed to calling it server
less I prefer the term fast which is
function less as a server or function to
the service because essentially
server let's kind of gives you an
indication that there is no server in
the background it's just that you don't
care about so
in the background so essentially to you
it is somebody is providing you function
as a service you say run a function and
it runs a function how does it scale
what is the server in the background
what is the operating system you don't
care about it so if you take a look at
it in the yellow part of it if I'm
giving you a fast I don't care about the
runtime I don't care about which JDK
version whether I'm using containers not
using containers is upon me what
operating system what virtualization is
it running on Google Google cloud or
Amazon Web Services it doesn't really
matter so that's not at the level of
abstraction that you want to look at it
so if you think about fast it really
gives you that ability to focus only on
the business logic that you care about
people typically get confused between
what is the difference between paths and
server less so the point is you know
Adrian Cockroft says you know my boss he
says if your pass can efficiently start
instances in 20 milliseconds that run
for half a second then call it server
less typically pass as we saw is it has
a little bit longer life you know in
terms of running time but server less is
even driven something happen do
something and store the result somewhere
else and I will show you some examples
of that so what is the AWS lambda well
AWS lambda is Amazon Web Services
offering for doing function of the
service it's fully managed in the sense
there is no provisioning that is
required to be done
it supports four languages Java node
Python and C shot what that means is you
can write your business logic in these
languages and you can say lambda run
this of course it defines the
configuration that you are using node
there is a version that will be
provision if you're using Java has the
version that'll be provisioned so on so
forth but it takes care of compilation
building the class file and running the
whole thing for you
there is absolutely no administration
and it is very highly available you can
say at any point of time I want to run
100,000 instances of the server less
function concurrently and behind the
scene it will scale automatically AWS
lambda or ticularly uses Aleksey
containers bhai
the scene but that's just an
implementation detail to you from your
perspective you care about it
I want 100,000 concurrent execution of
this server less and go do this for me
in terms of metering is charged for
every hundred milliseconds of execute
time so that's part of the unit at which
you are charged there is no charge for
storage of the function by itself and I
did something here ok and finally in
terms of continuous scaling you just
stored the function and you execute it
or invoke it as you want to how does it
need to scale how does it need to
monitor all that is completely up on AWS
lambda so that allows you to focus on
your business logic here's the business
logic that executes sits it's a little
different way of thinking as opposed to
like here is my one class with you know
three functions and another class with
three function it's a more event-driven
approach and I'll show you a sample of
that so how does it work for example you
upload your code to AWS lambda of course
you can do that using AWS console or you
can take your java code package it up as
a zip file and upload to AWS lambda I
have a project which does that using
maven plug-in as well then something
needs to trigger that serverless because
you know is either a click on a webpage
or update in a dynamo DB table or you
know invoking using the REST API gateway
something needs to say okay go invoke
that lambda function each lambda
function is given an odd or Amazon
resource notifier amazon resource
identification number and then it
invokes that lambda function lambda runs
your code when triggered using only the
compute resources required and you are
charged based upon the execution time
literally down to 100 milliseconds
execution time and so you're really
paying for the compute time that you use
no time for the storage so how to edit
this lambda pricing work now anybody can
go to aws.amazon.com you can sign up for
a AWS account the first million requests
per month are free
1 million requests per month are free
which which is pretty good to get
started with so if you are a small shop
where you think that you're going to get
up to a million requests for a now that
server less architecture that is pretty
golden that's a very good way to start
with and essentially what you get is as
Oh depends how you calculate that 1
million requests essentially you what
you get is 400,000 gigabyte seconds of
compute type per month and then
depending upon I want hundred and twenty
eight mega megabytes of memory or I want
one gigabyte of memory accordingly your
calculate time or the compute time is
calculated now remember the thing is you
are only asking for here is the compute
time that I want the CPU and the network
are automatically allocated for you so
that's sort of you know it's a very
open-ended way of doing lambda functions
it is a function that I want to run and
I think it will take about half a gig of
memory you allocate the CPU in the
network for me or Cottingley so and then
once you expire the feed here is
literally 20 cents per million requests
thereafter so literally you know in a
matter of a few dollars you can deploy
and build your entire application and
host it on AWS lambda this is sort of
what I was talking about you know if you
ask for say 128 megabytes of memory then
you can actually get 3.2 million
requests three per month if you go down
here you know if you're looking for say
384 megabyte or almost half a gigabyte
of memory then you're almost getting a
million requests per month free and that
Khoda kind of goes over every month what
is the typical use case so let's say now
you take an object we talked about how
lambda functions are triggered so let's
say you take a photograph you store that
photograph in s3 bucket as soon as it is
stored in a three bucket that generates
an event that event can then trigger a
lambda function that lambda function can
then say here what this is a full-blown
you know 10 megabyte image and I'm going
to take that megabyte 10 megabyte image
and I'm going to start creating a
different thumbnail
depending upon the device sizes so I
know for example this image could be
viewed on five different form factors
and I'm going to create five different
images for it automatically that
serverless function is going to do that
and I'm going to tour it back into their
three image by the way this is the use
case that that's how Seattle Times you
know back in the US use this exactly use
case on how they use serverless
architecture so Seattle Times you know
if you want to read it in a different
form factor images stored and it
automatically generates for you another
example a very classic weather web
application for example an online order
is placed you know as soon as the order
data is stored into dynamodb table that
then triggers a lambda so any update
into DynamoDB could trigger a lambda
function for you that lambda function
can then extract the data or run the
transformation code and loaded into a
redshift data warehouse and then
analytics could be generated from that
data so you can start chaining your
serverless functions to do the right
thing and then store the data into the
right source another one you know this
is other more classic web application
and all you want to do a front-end code
which is hosted in s/3 s/3 has the
capability by which you can host a
static website so your front-end code is
hosted on s3 as soon as you click on the
link it goes using api gateway api Gator
will talk about in a second but it can
be configured for your rest
front-end the rest front-end says okay
it's configured as soon as you invoke
HTTP GET it's going to go and call a
server less function and then that
server less function is going to query
from dynamodb and return the result back
to you so this is a very classical web
application that can be designed
instead of using you know your spring or
whatever java ee using server less so
what are the key components of AWS
lambda well i mean i'm a java guy so
here is a java function which is your
hello world of Java you know for server
less so I'm having public class
HelloWorld each job each lambda function
has to extend or implement this
interface request handler this is the
Java syntax but
the similar syntax with other languages
as well I'm saying okay give me a
request and I'm going to return the
response back as well so as part of this
you need to override the method handle
request so in the request is where you
get the data passed with a function like
parameters that comes to you like JSON
data etc that comes to you and then in
the context you get some of the runtime
aspect of it where you can operate upon
it and then return the result back if
you need to so that's sort of a very
simplistic way of saying how each lambda
function will look like so essentially
your public class override public this
would look the same now these requests
and requests of course request in
response or my pojos the way I've
designed them because I expect my data
to come in a certain format and the
response to go back in a certain format
but you are free to use whatever format
works for you and context is what gives
me more detail about lambda runtime in
case I want to get the request ID and
the time etcetera and some things like
that so how does my first Java plus
lambda would look like oh well first
thing is in a standard maven project I
will add the maven coordinates because I
need the lambda library lambda API so I
will include this maven coordinates
dependency essentially in my form XML
once I do that I'm going to write my
Java function and all my simple Java
project and it gives me the ability to
implement that interface then I'm going
to use the AWS CLI to create a function
all I'm saying is AWS lambda is the top
level function then create function is a
sub function so to say and I'm giving
the function name I'm giving it the role
this is the role in AWS I am then I'm
giving it a handler handler is you may
have packaged bunch of classes in your
function you need to identify one class
as a handler which is R the entry into
the function then you say okay there is
a head of the zip file now essentially
once you have created a jar file you
need to package it into us as a jar well
see if the jar file here essentially all
I'm saying is I'm using a binary file
protocol
and referring to this is a zip file this
zip file is sort of my entry point to
the function then I'm saying description
I'm saying runtime is Java 8 I don't
care
131 121 what patch are you using I just
care about Java 8 so you just say that
then you specify the region then timeout
memory size and publish so if you give
this command essentially this will take
your existing jar files and run it up
there this is actually published as an
example on my github repo our own -
Gupta server less so feel free to take a
look at it and then last but not the
least I can just say hey I want to test
it so I'm going to AWS lambda invoke
this is the name I gave HelloWorld so
I'm going to say function name
HelloWorld I specify the region region
could be left now if there is a default
region already set um you need to look
at it which region the lambda function
is available at and then I'm saying
payload this is the payload where I'm
going
first name is John last name is Smith
and that's the payload that get
converted to my request photo and it
says hey here's a JSON payload gets
matted to this photo and now in the pojo
I can access it and I'm saying just dump
the output into hello world or out so
it's a very simple and easy way to get
started with lambda functions and you
can invoke million of these now in your
well half a million of these because I'm
using one gigabyte of memory so what I
did is now for my micro service
essentially I created a whole bunch of
lambda functions you know I have a micro
service post get all get hello with name
all these are my test ones but
essentially in my micro service all I
wanted to do was get the list of all the
elements from the database and then
create a new one so all I did was and we
just created two functions and you can
see there are Java eight run time and
they were created a while ago
all right so that's sort of my quick
primer of you know what how would you
create your function over here now
Couchbase is a new SQL document database
that's what are that's that's where I
used to work earlier now in terms of the
database it has a lot of capabilities it
gives you full data capability of course
you can store document data documents
over there JSON documents it gives you
the query capability where you can run
sequel queries on your document database
it gives you all sorts of indexing
capability you know you can do the
replication across data centers it also
has a Couchbase Mobile which allows you
to very easily synchronize with the
backend database so I would encourage go
talk to the culture base folks at the
booth if they haven't shut down yet you
have search and analytics all kind of
capabilities that exist in the Couchbase
database so I showed you a simple Java
plus lambda use case let's evolve upon
that let's take a look at it how job of
the slam de plus Couchbase would look
like ok very similar actually
oh one more animation sorry is the same
side so the key thing that I'm going to
do here is so here is my server less
directory so if you go to my github repo
Arun - Gupta server less that's where my
code lives and there I have a AWS
directory then I have a hello couch bear
directory that's where all my code lives
for this Java plus lambda plus Couchbase
and here is my jar file that is
generated out of it now the key part I
could host my culture base of my
database wherever I want to in this case
the only thing that matters is I am
passing a environment variable where I'm
saying Couchbase host is this is where
the ec2 instance is running so on this
host is where I'm going to have
Couchbase available so once I have the
host information available to me I can
use that in my application and then say
hey go connect to this host and do
whatever database operations need to be
done so pretty much everything that we
have been doing so far but just with a
little bit neurons from serverless
perspective let me see if I have
internet connection here
so you hear some stuff I haven't even
booted my laptop to connect here
cannot be found to store whatever going
on okay connected good so if you look
here now it is my AWS and here is my
hello Couchbase and hello coach bass
here and his hello coach bass here and
it is my java file and if I look at
hello couch bass lambda here okay so
this is my hello couch bass lambda
implements request handler request and
as I said your request and response
beans are really what you care about it
I'm using a handle request method here
but I'm saying give me the request and
in this case all I'm doing is well this
particular example what I did was three
I was receiving the request from iut
button so I ordered a whole bunch of AWS
iot button every time I will click on an
array on an IOT button it will trigger a
lambda function so essentially what I'm
doing is I'm saying okay from the
context runtime give me the request ID
and the time stamp and I'm going to
create a button document button document
is a JSON document basically and that
document will then be stored into a
college based instance so essentially
every time I click on an AWS iot button
it's going to generate a back-end JSON
document in my server less function and
it's going to purchase that document
into college I so right here what I am
saying get the bucket absurd into using
a JSON document and if you scroll down
here on line 40 where I'm saying oh by
the way from the system get the
environment variable Couchbase host
which is what how I am configuring it to
talk to my database
but this is the third example that I
want to talk about so here I'm saying
every time I click on AWS IOT button it
triggers the lambda function
it talks using the Java SDK and passes
the data into college space all right so
what are the key things here is AWS IOT
button in order to talk to lambda
function well that's one of the events
that one of the ways by which it can be
triggered but if need be in order to
replace my IOT button with a web
application I need an API gateway
because the web application will
eventually need to call a HTTP get put
post delete and that's what needs to
trigger sort of my back-end server
function that's what AWS API gets a
comes in so what does it give it applies
api gateway is once again just like any
AWS service is a managed service here it
gives you the ability to create publish
monitor maintain your REST API so think
of your Java EE application if you are
building a Java EE you are spring boot
application you bake you annotate your
functions accordingly and it's all mixed
up with your business logic API gets a
is useful when you don't want to mix
your API is what api's are exposed as
what functions so essentially you have
your business logic and then you start
mapping hey here are my REST API so you
centralize all of your API is at one
point of it because then you can start
doing things like monitoring metering
then you can start charging your clients
based upon API usage then you can start
doing centralized API administration so
lots of benefits on why API gateway is
useful you can do you can manage
multiple stages and version so you can
say here is my test version here is my
dev version now I'm reducing a new API
and how I'm going to do the
consolidation across different API is
the AWS API gateway particularly is also
integrated with cloud watch so as you
are invoking your API on the API gateway
and as they are invoking the back-end
function all of that you can watch in
now you can see the logging of that into
cloud watch just like lambda functions
you only pay for the calls made to api's
and the data that transfers out as part
of the API itself okay so some other
aspects you can start studying
throttling rules so you know - for
example to prevent denial of service you
can say don't do not have more than
thousand concurrent calls if you're
going to this back-end so you can create
really sophisticated rules if you're
using API gateway which would not be
possible if your API and your business
logic code is mixed up into one tarball
particularly in the AWS infrastructure
with using API gateways you can start
getting integrated with AWS I am so you
can have your identity and access
management integrated with it or you can
also integrate with AWS kognito which
gives you full mobile security front-end
it's a mobile back into the service but
you can say do my mobile authentication
using AWS cognitive so all of that
integration is very seamless another
advantage of SDK API gateways once your
api's are configured it gives you a
simple Java Script ios and android
client by which you can easily embed
those into your mobile phone or your web
application and invoke those rest api so
how does the flow look like if you have
api gateway you could have variety of
clients essentially that you want to
invoke over the internet the internet
you know of course it goes to the api
gateway which is where you arrest api's
are hosted now if now you can configure
optionally configure a API gateway cache
so that if the returns the results are
available in the cache you can return it
right from there itself if not there
then of course you can invoke any of the
backends over here whether it is easy to
lambda or some publicly accessible
endpoint on ec2 or somewhere else and
then of course it's integrated with the
cloud watch monitoring as well so with
API gateway in that sense you get a
full-blown application which gives you
the ability to not only do security and
throttling and metering and management
but also you know
of full-blown function which keeps your
API logic and the business logic
completely separate and they can scale
at different levels in my case what I
wanted to do was build a simple micro
service and that micro service I wanted
to just say hey is a books micros micro
service and in the books I want to get
the list of all the books and I want to
create a new book so all I did is you
know this is a snapshot from the console
so essentially at the top what you can
see is I'm creating a new book a value
API and new API is booked and exposed at
slash books and in slash books I got a
get and a post method and you can see
we'd get there is no authorization
required but in post as well there is no
authorization required but it could have
if need be
I could start integrating with AWS I am
rose then as you are getting in you know
as you're invoking the API you would be
required to be in that particular role
so somebody is so let's say if you're
coming in from a web application and
somehow you will have to pass the
security context which goes through to
the API and then so that you can all
you're authorized to invoke it so then
what I wanted to do was I wanted to
build this is sort of basically getting
towards my application I have a client
here a simple web client the client will
talk to API gateway this is which is
where my all my API management is done
as soon as you click on the API each API
is configured to invoke a lambda
function so book list and book create
are my two lambda functions which are
going to get invoked and then my
culture-based instance is hosted on the
ec2 back-end so that sort of the broader
architecture on how I expected this
entire application to work so we walk
through this one actually
if you look at this here same diagram
but essentially the client could be you
know curl or postman or any web
application here and the slides by the
way are available or the same repo that
I talked about earlier and it gives you
the complete source code for it here as
well so if you scroll down you know the
first thing that you're going to do is
create an iam role because essentially
you do want this service to operate in
an IM role so it kind of gives you
exactly how will you create the iam role
okay and here is the trust policy how
it's going to look like then you will
create the lambda function and it gives
you the source code for the lambda
function and it gives you the AWS CLI by
which you will create those zip bundles
that we talked about so this is the
repos server less AWS micro service is a
repo and we can actually look at the
source code as well
if you look at this here here's the
simple book poacher and all I'm doing is
I'm saying okay how do you convert back
and fro back and forth back and forth
second stick it correctly to J's on now
I have all of my different methods here
these are my serverless
functions something book delete it gives
me a book and this is how I return the
result and behind the scene what I do is
I am invoking Couchbase util and I'm
saying okay from the database go ahead
remove this object if I go back here if
I look at Couchbase util Couchbase util
is again reading the value from
Couchbase host and in this case I'm
using system get property and get env
because get env is useful for the lambda
function and system forget property it
gives me the ability to invoke it from
the command line as well like a maven
project and then I'm just getting the
bucket and I'm performing the functions
on it okay if I do get all so pretty
much similar logic here all I'm saying
is from the buck-buck Couchbase util
give me the bucket name run the select
star query on it and limited only to ten
documents so I can very easily invoke
this you know how I'm coding my entire
business logic now one of the things
that you need to understand is I had to
build in order to particularly integrate
with API gateway I had to build a an
additional serialization layer because
the way essentially what's happening is
your your web page makes a request to
API gateway then the API gateway makes a
request to the backend server less
function their protocol on what kind of
data do they expect between each other
is a bit different so essentially what
I'm doing is here is if you look at this
couch page is a package where all my
pojos are living so bucket get one you
know just get me one buck one book from
the bucket
but the moment I am going through so
this gives me the ability where I can
invoke the server lash function directly
but the moment I am going through
gateway you know it's a different
serialization protocol so in this case I
have if you look say bucket - Oh
bucket post let's say if I look at
bucket get post here so then you can
look at it you know it's using gateway
request and Gateway response and those
are my classes that I have created here
so if we look at gateway request here
you know it does serialization in a
slightly different way in expects data
coming in inbound and outbound to be in
a certain format so I had to write those
serializers and that is one area which
it could be slightly improved here or in
my opinion but the important part to
understand here is if you are
communicating directly to server less
there is standard simulation protocol
but if you are going via Gateway then
the protocol is different because the
format is different so what is your
typical development workflow when you're
building your service like this the
typical development workflow would be
you will implement your business logic
you know of course it's all event-driven
that now the way we were thinking about
it you know weather app index.html click
on it go to API gateway get the data
from dynamo DB and return the result
back so you write all of your events and
you write your HTML pages you deploy the
lambda function you create or update and
deploy the REST API which goes through
guest API gateway then you need to
connect your API gateway to the lambda
function and that can be very easily
done using the console itself that ok
the moment I click on this API it needs
to invoke a lambda function then of
course it invokes the API to test and
debug and you repeat the cycle until it
gives you the functionality that is
really required from the application
take it a notch higher you know I mean
I'm doing too many things here and I'm
doing creating a module
well I'm creating a zip jar file first
of all then I'm uploading it to the AWS
lambda then I'm saying okay here is my
API gateway here is how you connect all
of them so that's exactly where the
serverless application model comes in
this is again an effort by AWS to define
a standard way of building serverless
application if you are familiar with AWS
CloudFormation it basically extends that
now CloudFormation is useful if you were
to manipulate multiple resources so for
example let's say for your application
that is running exclusively on AWS you
want to create certain ec2 instance you
want to install a database server you
want to install an application server
you want to create some IM roles you
want to configure the roles instead of
writing a script what you will do is you
create a cloud formation template and it
will do everything for you it will
coordinate all of that for you so what
does Sam do San basically extends
CloudFormation template and it adds new
resource types over there so it's a
server less function server less API and
server less simple table so now
everything that I've done so far for
building my micro service let's see how
I can simplify this very easily using
server less application model okay
again this code is available on my
github repo so if you look at this here
on the top where I'm saying this is a
server less application model from 2016
10:31 that's when when the first version
was announced and here I'm saying ok
there is a micro service get all I'm
basically defining a server let's
function here the type is just a
standard function and I'm giving it a
handler here I'm giving it a run time
now in order for server let's
application model to what the jar file
must be uploaded into s3 so this is
where I uploaded the jar file then I'm
defining other other variables other
properties here and then finally I'm
saying Couchbase host is living here
and then the I am role so instead of
using that cryptic AWS CLI which some of
you may find challenging just put this
into a configuration file and then you
say AWS CloudFormation deploy using this
particular Sam file and that's it
it will create the function for you it
will create the API for you but in this
case not because in this case we just
upload the function but let me show you
another example in this case it will
create an API for you so for example if
you look at line 30 it still says this
is a function on line 32 I'm still
specifying the handler runtime code
timeout all of those but if you come
down here all I'm saying is what is
going to trigger this serverless
function and that's defined in the
events I am saying every time a get
resource is called so create an API here
the properties head of the method we can
start defining all of this model very
cleanly using server as application
model in just one yeah Mel file
so essentially what will happen is you
will create one serverless application
model dot yeah Mel and then you will
have your code created and upload it to
s3 bucket and that's about it using this
Sam file and using AWS CLI you can
create not only your server as function
your API but link them together as well
or it last bit of peace so what is AWS
s3 basics I won't dig too much into it
but essentially it's a it's a simple way
by which you can store exabytes of data
an amount of data that you want on
Amazon now these are some of the
properties for it now you it gives you
11 nines of durability it has also some
access control authentication etc but
what are the key AWS s3 concepts and why
is even h3 relevant here well
AWS s3 has buckets bucketz have object
and object has metadata and data so
that's part of the very high-level
definition here now in metadata you have
a key and you have a version of the data
so it allows you to store multiple
versions of the data in there
the key part here is what defines the
data uniquely a bucket a key and a
version there is a bunch of other
metadata but these three things are what
define the data very uniquely so now
what I can do is on s3 I can create a
simple s3 bucket the key part to look
here is the static website website
hosting by default it is disabled but I
can enable this and what that means is
because s3 is across regions across
multiple availability zones it truly
serves as your CDN so my static website
could live on s3 and then I can say hey
I want to invoke my application I have
an able static website hosting it is
running a back-end web server just serve
my request
now this s3 yeah so if I once I enable
static web sites on s3 I can just say
use this web bucket to host the web site
I can say what is my primary document
what is my error document and I can
start configuring those rules so here is
sort of my deployment architecture how
it would look like so if you look at
this my client and now if I'm calling a
simple REST API then it will go to the
API gateway with this client could by
the way is still yeah this is my clients
if I'm calling the simple REST API I
will go to the API gateway get post
delete each of those have a
corresponding server less function then
they can talk to any database sitting on
your ec2 or if they are calling a static
page which could then redirect to the
API gate phase that could go to cloud
front which is basically your CDN so
that the page is served instantly in
your zone then you can have your domain
name server here and then this could go
to your s3 bucket so essentially with
your s3 bucket hosting your HTML and
JavaScript code with your second level
being API gateway the third level being
your server less and then the fourth
level being your database living
anywhere on AWS is sort of what gives
you a complete micro service deployment
architecture
let's revisit this definition once again
now we talked about a suite of small
services each running in its own process
that's exactly what our lambda functions
gives us they are independently
deployable because each lambda function
can be independently deployable there is
no management required for them because
all you say is here is a function
uploaded and AWS will take care of
managing this for you AWS lambda
functions once again gives you different
programming languages today it gives you
Java Python C sharp and node and more
language is going to be added in this in
the future and then similarly it doesn't
matter where your data store technology
is on this sample I'm using Couchbase
but you can use for example relational
database service which gives you six
different databases running on Amazon
for like Oracle Aurora MySQL Postgres
all of those database services are
available which are managed service on
AWS so you don't have to really worry
about where the database is running and
that's pretty much a wrap all the slides
and the code are available on this URL
and anything of course about Amazon is
Amazon Web Services is that
aws.amazon.com that's a wrap I think I'm
going to take questions off the mic
thank</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>