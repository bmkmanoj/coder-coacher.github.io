<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>HTTP/2 Two Years Later by Jesse McConnell and Simone Bordet | Coder Coacher - Coaching Coders</title><meta content="HTTP/2 Two Years Later by Jesse McConnell and Simone Bordet - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>HTTP/2 Two Years Later by Jesse McConnell and Simone Bordet</b></h2><h5 class="post__date">2017-04-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6tNqAFQ_gAc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to our 2 year retrospective on
HIV to support in jetty first off how
many of you use jetty excellent that's
what we like to see
so jetty is an eclipse project you can
track us on Twitter these are slightly
old slides due to technical difficulties
but we are located at github HTTP github
calm slash Eclipse slash jetty dot
project we moved out there about a year
ago but we are still in Eclipse project
we are now in our 21st year so jetty is
officially as old as Java we celebrate
our birthday with with Java and Yahoo
actually so the basic tenets of jetty
are high volume low latency promise that
this will get back around HTTP to here
very quickly jetty is is easily
embeddable we're very popular in the
developer community because it's super
easy to spin up jetty in unit tests or
on production environments are embedded
into your application and what have you
we're used in lots of different
applications cloud providers like Google
App Engine Google flex and then we're
also used in eclipse where the we run
the default help system inside of that
as a OSGi component anyway
we also have a great standalone server
as well so you can use jetty however you
like that's sort of a core tenant of
jetty we don't care how you use jetty we
just enjoy that you do so that's a
little bit about jetty and then who are
we
my name is Jesse McConnell I'm a founder
and CEO of web tied Simoni is a lead
architect for web tied and comedy we are
a longtime open source committer or
contributors i've been a committer on
the jetty project for going on 10 years
now we fully fund the ongoing
development of jetty and comedy through
100% developer owns company so I've got
a couple of painfully obvious points to
make I'll give a short little story here
and there and then we'll move over to
some money who can give you a little bit
more background in HDPE - and give some
of the data of the actual retrospective
aspect of this I don't think we're gonna
get a demo out of this but it's not a
big deal
so first painfully obvious thing is that
the businesses on the your businesses on
the web I mean that's about as
straightforward marketing's you can get
by that we mean that generally there are
humans they're not all BOTS interacting
with your website's the core takeaway
here is that speed is critically
important for your website's the it has
influences for the the human mind the
brain interacting with your site and
that sort of thing but then it also
influences things for like google page
ranks and those kinds of things so if
people are searching for content related
to your business or your website it's
the faster your website is the more
likely that you were you're actually
going to come up in search revised and
or search results and those sorts of
things a couple of examples I'm not
going to say that any of these guys are
web tied clients or anything like that
throughout the presentation that's not
the really the case we're just using
this as some sort of public data that
backs up the whole speed is important
thing so if you take a look at like
Shopzilla they had a an attempt or they
they made the effort and they invested
in the business to drop the page load
times from like 6 seconds to 1.2 seconds
had a 12% growth in revenue and a 25%
increase in page views Amazon had a are
they they were able to track down that
for every hundred milliseconds that they
improved the responsiveness of their
website that was about a 1% growth in
revenue now 100 milliseconds is about a
third the speed of the blinking eye so
it's not something that you cognitively
notice necessarily but it is something
that has your brain clues into and
you more likely to not get frustrated
with the site's performance and stuff
like that so 20 years ago the web looked
quite a bit different the HTTP
specification this one's quite often
shocking to the young ones in the crowd
but it is actually 21 years apart it's
over 20 years old now so it kind of
makes sense that at this point to take a
step back and relook at the the basic
core protocols of the Internet and you
know make the modifications acquired so
today things
I'm not saying BBC's a client either
this was from today so the web today is
a lot a lot more busy it's a lot cuter
and the point is that there's a lot more
going on on modern web pages there's the
actual you know the initial requests
coming in to your page of XML or a page
to HTML or whatever and then there's
also the huge amount of resources that
go behind it and then there's also the
the the dynamic content aspects of your
website and everything so one of our in
the last year we worked with one of our
clients and they're sort of the best
case scenario for HTTP to performance
they had a traditional Java servlet
based web app that was serving out HTML
or HTTP 1 1 1 traffic had dynamic
components to it and they wanted to
migrate over to HTTP 2 so we were able
to with with virtually no modifications
to the web app you tweaked a couple of
the components on the deploy side of
things they were blessed in that they
had not invested in components on their
networking infrastructure around the
edges that would prohibit a tower
prohibit the the ability to go HTTP
point-to-point from the browser into
their their applications so they were
blessed from that perspective but once
they made those changes they were able
to generally improve web the response
rendering of the first page and then
because of the dynamic content that they
had behind the scenes using Layher
comedy project they were able to have
reduced latency on the
dynamic aspects of the website as well I
will get in or Simoni will actually get
into a little bit more on why we don't
are not giving you no actual you will
save this much percentage type of thing
anymore because a lot of that is subject
to things outside of your ability as the
server side of things but anyway the
painful reality too is that the web
powers your business again I'm sorry but
the point here is that it's not just
HTTP semantics sitting driving the
traffic into the front page or a front
part of your website it is actually
quite often present behind the scenes as
well in data centers and those kinds of
things for you know distributed query
engines and all that kind of stuff so
you end up with a lot of that kind of
traffic behind the scenes so a quick
example here is a couple of our clients
have query engines I guess I'll say
behind the scenes where they have a
problem of hundreds machines where
hundreds of machines where traffic comes
into it and then it gets split up and
handled out to each of these the the
nodes on the cluster and you end up with
a situation where under you choose an
HTTP semantics because it's very easy to
understand it's very common there's a
lot of tools to be able to help you
debug it and take a look at it and a
wire and and and know what's going on
but the HTTP wire protocol the part that
actually goes across the TCP and that
kind of stuff ends up becoming
prohibitively expensive in the grand
scheme of things so when they were
establishing like point point connection
between each one of the machines in this
network and you have the the resource
consumption and those kinds of things
associated with starting up these
connections and tearing them down and
all that kind of stuff by a migrating to
an HTTP - in place of the
previous implementation they were able
to reduce the server resources and loads
and those kinds of things but and then
improve the performance of you know
something that's that's fundamentally
not exposed to the Internet per se and
exposed to the client browsers and those
kinds of things but you know dramatic a
benefit when you when you take a look at
the the wire protocol so someone is
actually going to go over here shortly
on some of the examples of what HTTP 2
is in case I went over your heads and
not understanding what page should be 2
is from a basic level but in a nutshell
if you want to think about it as you
know opening a big pipe and being able
to have one connection instead of lots
and lots and the browser Wars of the
last 20 years where browsers were trying
to go faster by just opening more
connections to your server and all that
kind of stuff when you're touching about
HTTP to it it becomes a different load
profile and that kind of stuff and the
moral there is that the costs and been
or the benefits and the savings of
adopting something like HTTP 2 which all
the browser's support now on the website
of things you can actually gain a lot of
the benefits by looking at the backend
services that are using that HTTP
semantics already not have to change any
of your application logic from that
perspective because you're still using
the same semantics but then gained some
benefits from the wire protocol header
compression is just one example of that
anyway and then h-2b two pushes also
another big component of that which
Simoni will offer some examples of and
that is my cue to let him take over here
thanks Jesse so let's dive a little bit
more into the details of HTTP to and and
so first of all HP 2 is a binary
protocol this is a breakthrough with
respect to the HP one one protocol
because it's a textual protocol you can
actually human read it HP to it is not
like that it is binary thing this is a
makes things much easier for
implementation to implement
the parsing and the generation of the
protocol frames in a much more efficient
way so that was a very good thing and
how does it work
so this is a like a scheme every time a
browser creates what is called a frame
in this case is called the headers frame
our headers frame contains the request
line and request headers and it's being
sent to the server if it is a post and
so it also has a body the request is
also has a body then another frame
called data frame is generated by the
browser and it's sent after the headers
frame so this reconstitutes the HTTP
request that was typically made using HP
1 1 and the server at the point has to
reply and it applies in the same way so
a headers frame can be reused also for
responses because it just carries the
information of the response line and the
response headers semantically they're
not really much different and so the
same frame can be used for both the
request headers and the response headers
and of course the resource content that
has been requested by the browser can be
delivered using one or more data frames
in this way another very very important
feature of HTTP 2 is multiplexing so how
does it work the blue one the blue
cylinder here it's a TCP connection okay
typically with HT p11 what do you have
you have the blue pipe you send one
request in there and then you cannot do
anything else until the response come
back so you have a huge pipe you send a
tiny little amount of bytes in there and
then you have to wait for the response
with HTTP 2 this is completely different
what they do is that we then the same
TCP connection they create smaller pipes
the green ones that can contain single
request response channels they're called
streams in HB to our parents and so you
can create multiple of one of these at
the same time so
that's a good thing you can actually
send multiple requests at the same time
on the same TCP connection so in this
case for example the lower pipe is the
one that gets sent first the request
that gets sent first top pipe sent
second and a third our request being
sent in the middle but the important
thing is that you don't have to wait for
the first one to return for example in
this case the middle one was a requester
that was served by the server in a
faster way maybe because the processing
the required was smaller maybe it was a
small file like for example the favorite
icon or something like that
so the the request that was actually
sent as lost returns us first so there
is no correlation between requests every
single channel is independent and so you
can have out of all the responses but
the browser will be able to correlate
them together and say ok this was the
response to this particular request that
I made before and so on with the other
ones
right another very important feature for
HP 2 is Heather's compression now
imagine if you're familiar with a cheapy
how does it work
for example a browser the sends a
request to the server what does it send
a sense for example a header string
there is the user agent it is a quite
long string that says I am Mozilla
number 52 you know this is my screen
size and what not information it's a
constant string that gets sent over and
over and over again for every single
request that lands on your browser ok
same happens if you have cookies maybe
you have large cookies there your
website is sent and so this could be
kilobytes in size and their constant
once you get them you have to send them
for every single request that you send
over so in HP 2 there is a mechanism to
compress these things in a very very
efficient way basically how does it work
our typical request without even cookie
and etc is 400 bytes in HT p1 1 in HP -
the first
request gets compressed or ready to
about 250 but then hb2 says okay I've
seen this header before let me put it
aside in into a table okay and then for
the second request I don't need to
compress anything I just need the
pointer to the table and say okay this
one is the third entry in the table and
that's why you can get four subsequent
requests you can get the same four
underbite into just ten bytes all right
and so this is very useful especially if
you pay for bandwidth and you know
consumption of the bytes that you have
on the bandwidth so we go back to the
business cases that jesse was making
before the last feature there is
paramount to how HTTP 2 works is what is
called a cheapy to push this is very
important because the analysis that has
been made in this past 20 years figured
out that HTTP requests and responses and
resources and how we arrange the web
content is based of a primary resource
that gets requested which is typically
an HTML page but then when that comes
back to the browser the browser starts
parsing it and then it finds inside
secondary resources that that resource
links and so it has to request those
secondary resources but there is a
correlation between these primary
resource and the secondary resource
right and so by being able to push the
secondary resources down we get a lot of
benefit let me show you how it works in
practice okay so we have a browser we
have the server and this is how it works
with HP 1:1 you make the request for
index.html okay and it's a one roundtrip
you get the HTML back the parser start
parsing the browser start parsing it
okay and then it figures out oh look
there's a JavaScript that I have to
request and there's a stylesheet that I
have to request ok so I can open up to 6
connection to my server and so let me
open two of those and then send requests
in parallel for those two resources when
the CSS come back
the browser starts parsing the CSS and
inside the CSS it finds oh there is a
background image that I have to request
and so it's another run trip so just to
get the resources necessary to render
the simple page made of four files here
I need three round-trips
now that's okay if you are in United
States but the round-trip are between
europe and the united states east coast
let's say it's hundred milliseconds but
if you go to Australia that's 250
milliseconds it's a lot of time so just
three round-trips
it's already seven hundred fifty
milliseconds could be one second very
easily and this is a super small example
that doesn't even recall what is the
normal web page in the web today just to
give you an example the normal web page
today in the web has hundred secondary
resources not just one so it is a very
complicated web and very resource
intensive so how does it work on the
server side well the service sees these
requests and you can say okay I
understand what's going on here
I can correlate index.html with the
other three files and build what is
called the push cache and once I have
the push cache then an HTP - browser
comes along and says hey I want
index.html but the server at this point
knows that not only has to deliver back
the HTML but also the other three and so
this is what happens in one roundtrip we
get all the resources needed by the
client to actually render the page okay
so we just cut by a factor of three the
time needed to fetch all the resources
from the network which is the major
source of latency it's not really I mean
the bandwidth these times is pretty high
we don't have anymore like 50 kilobytes
or kilobits even network speeds we have
now megha bits stuff so it's not really
a matter of how fast
can deliver big data it is the latency
that it takes for a TCP packet to travel
from a stray Australia to United States
crossing the Pacific or from Europe to
United States crossing the Atlantic so
here I would have showed a super-nice
demo that shows like it was very
impressive of course I can say that but
yeah we couldn't link my computer to the
to the screen so we'll skip it and this
is basically what happened so this one
is chrome 57 which is the current
version on HP one one asking for the
website.com webpage which is served in
both HP 1 1 and HP - ok he renders in e
you know the final time the browser has
all the resources down it's almost one
second 9 916 milliseconds as you can see
there's a this one on the on the right
is a waterfall diagram that you can see
on browsers and you can see that for
example the first resource at the top
was the index.html file it was requested
alone because the browser couldn't know
what else to ask okay let me ask the
index.html first then that guy came back
and you can see that two four six of
other resources the first six green bars
were resources the were associated with
the primary resource so the browser said
okay let me open six TCP connection send
those six resources to the server and
then let's wait for them to come back
they came back and when they came back
the browser could perform other requests
okay but you can see all the green lines
the green bars there that's time where
the browser is stalled because it
doesn't have enough connections to
actually ask in parallel things to the
server and so it has to stall is that
okay I would need to also ask for images
and other JavaScript files other CSS but
I can't because I'm waiting for the
other six resources so just to give you
an idea this work
this way you know get the HTML back and
then send six requests wait for them to
come back send another six wait for them
to come back send another six and so
forth right so if you have like this our
website has 34 of them so it's quite a
number of round-trip that you have to
wait right every time every single time
then of course one is bigger than the
other so you can actually squeeze the
main in in a more efficient way but
still the point is that you can see this
kind of diagram very easily so what
happens with hep-2 instead well first of
all we trimmed down the load side to
less than 600 milliseconds that's
already a 30% improvement on just on
that and then see the diagram the
waterfall diagram you can see all the
requests that were needed to actually
render the page were sent at the same
time to the server
there's no sense six and then wait it's
I need 34 because I'm parsing the HTML
and I'm figuring out I need 34 boom send
a 34 up to the server and wait for them
to return whenever they're ready okay
that of course makes the rendering time
much much faster but there's a catch
though and see the next one so this one
was Chrome but this one is Firefox 52
also current same hep-2 renders in more
than one second what's going on
well let's take a look at the diagram
waterfall diagram we see that it is
different it doesn't send all the
resources at the same time it actually
has some kind of you know waiting for
some but then sending others and and
everything so what's going on here well
basically the implementation in Firefox
is different from the one in chrome and
they have preferred certain things over
others so it is just different they've
chosen a different strategy as you can
see there's more than six
request that are actually sent after the
HTML the first line at the top came back
so it is actually it should be to the
only problem is that they they just
chose a different way of doing things
okay and don't say oh now Firefox are
performs really bad I'm going to use
Chrome forever okay because that's not
true it's just a matter of choices in
fact we have tried the same stuff this
is from Europe to United States when we
tried to use Firefox from Australia
Firefox was consistently faster than
Chrome because the latency is different
in perhaps the choices that Firefox
makes in you know deciding which
resources to ask at what time are better
at a better choice for longer latencies
for rather than shorter latencies so it
could be different now we can go back
and have jokes about Microsoft browsers
again finally because this one was a
clear loser as you can see that the the
waterfall is kind of weird it is doesn't
have that you know vertical line where
you can see all the resources going out
together looks like well I sent the
first then opposed a little bit then I
send a second then all the others are
sent like a small amount of time again
weird again don't throw away edge and
just because you you did this actually
was made on from a us to us website
because I don't have Windows but um you
know it's impressive it's it's a lot of
difference you go from one point seven
seconds of edge to 600 milliseconds of
Chrome for the same exact website so
yeah I mean we're here talking about
HTTP to two years later we gained the
experience it's not everything perfect
and there's still shadows here and there
but so we're presenting those so yeah
big warning mileage may vary
you know Firefox is winner
certain cases certain others is a
doesn't win but measure measure measure
how do you measure so we had the same
problem how can we tell whether a cheapy
2 is actually a winner or not so we
wrote a library a java library that we
call the journey load generator and can
process traffic in HP 1hp 2 and HP 2 and
push and so it basically simulates what
browser do and you can have a tree of
resources the guests requested exactly
like a website would be and exactly like
a browser would do and you can you can
code your website in that way in and see
what is the difference so we did that
for our own website and we have also
simulated 100 millisecond Network
round-trip over the network right to get
a some information about that because
the whole point is that if you don't
have network round-trip so you do this
through local host this is where HP 2
performs like a GP 1 I mean the network
bit is the important one because when
you have to request 34 resources and you
can do it request response requester
concepts request response in it's not
really much different from requesting
all of them together and then getting
them but when you have a latency between
requests and responses so you send 6 and
then you have to wait for 100 200
milliseconds and then the response come
back and then you can add you can
request other six then hep-2 as you can
see here is a clear winner we go from
700 milliseconds to 400 to 300 with push
so we shaved off 60% of the time in
rendering so that's a you know like a
it's a load test
so it's fake in a sense but it shows
that there is a lot of benefit in doing
that but then you have to measure on
your own website but it would be you
know
a particular situation where http/2 is
not a clear winner in optimal condition
we'll see later that there are a couple
of condition where hep-2 doesn't really
shine with respect to a to be one but
there are corner cases okay
who's convinced now that has to move to
Asia Peter here oh come on okay cool
so how do you do that and so the thing
is that HP 2m browser required TLS if
you want to deploy a website then it
will only work over HB 2 if you're using
TLS TLS meaning SSL right so
certificates and everything you have to
have HTTPS in the front of your URLs but
that also gives you if you are over TLS
better Google ranking so why not it's
it's a good thing plus let's encrypt now
gives certificates for free so you don't
have to pay 200 bucks a year or more for
all your certificates you can get them
for free but let's encrypt the renewal
process is very straightforward and you
know it's pretty easy so what is the
case of deploying hb2 when you have non
browser client typical case is I don't
know micro services where you have a HP
client the calls are REST API on a
back-end server from an internal an
internal server in your data center well
you can text it's I mean hb2 doesn't
mandate TLS it is only that browser
vendors decided oh we're not going to
implement hb2 over clear text we'll just
go straight TLS and that's it and that's
the only option that will give but
inside the data center you can have java
client the speak hup-two that can
communicate over clear text with the
server
this is a typical deployment Apache and
nginx both support HB 2 the problem is
that they support a should be to only
towards the browser's when you configure
nginx or Apache in reverse proxy mode
which is the typical deployment that you
do and then talking to a Java server in
the backend they speak HTTP one one on
the back end this is bad because
applications are deployed inside the
server container typically the war files
right and so it is those application
that have the the understanding and the
capability to the side oh I will need to
push this resource associate that every
time I get this request and so they
decide what what's needed to push ok and
if they cannot push because the protocol
is HT p11 then they will not push and if
they don't push then the front-end guys
cannot push and therefore you lose one
of the biggest benefit of ATP - and so
while this is a very common deployment
scenario it's really not the optimal one
ok
what we recommend instead is this
deployment here we use a different load
balancer software called H a proxy the
King tunnel can do TLS offloading and
then can tolerate tunnel clear-text
HB 2 to the backend when you have an
end-to-end solution that is baten based
on HB 2 then when that's when you get
the full benefit of hep-2 because now
application can push to H a proxy which
you will just get the bytes and send
them over encrypt them and then send
them over to the client and the browser
is super happy with what's what's going
on so super that's that's the best
configuration that that's possible so
point being that we are after two years
still in that transition where nginx in
an Apache can support they should be two
on one
side but not on the backhand side okay
and so we kind of need to push these
projects to say okay can you support the
HP to also towards the back end because
that's really needed that's important
for this kind of deployments we can do
more things if this is possible if we're
still stuck on a 20 years old protocol
then you know there's no much progress
that we can make you we're not just
picking on those two projects no no
exactly exactly I mean they're they're
they're super super cool project the
point is here is that the best solution
would be an end-to-end HCP to chain
towards the server
what about Java server 4 which is due
very soon I've heard from the spec
leaders that is going to be probably you
know this summer it is going to support
the HP 2 it will have additional API in
the servlet API that will allow you to
programmatically push resources and and
therefore get you know hold in the API
of this HP 2 features and so this will
be good if you write servlet directly
you will be able to actually use this
API directly if you based your
application on frameworks like spring or
whatnot then the frameworks will be able
to get use this API and maybe offer a
similar API to applications that will
eventually call the servlet API and so
in any case from your application you
will be able to push resources based on
your own logic JDK 8 is required who is
it in a JDK version that is less than
eight like seven okay a few JDK a is
required because the implementation in
JDK 8 requires the strong ciphers that
HB 2 mandates and so you need to move to
derogate if you want to use HP 2 not
only that but we work together with the
dedicate team on what is called the jab
to for for to support a particular
feature that is required by HB 2 that is
called a LP n so this feature was
missing in the JDK and without it you
cannot do aja p2 and so we work together
with the JDK team the Gerry team work to
get in others work together with the
jeddak a team and we have now this API
in JDK 9 since JDK 9 build 150 if I
remember well and we have already
implemented this in jetty yesterday we
release Gerry 943 it contains already
the modules that use this new API in
Gerry canine to leverage the dedicate 9
native support for a LPN and so these
are the new IP is that have been added
to assess all parameters and SSL engine
that allow you to well allow us
basically the servlet implementers to
leverage the possibility to use a LPN
which is required for HP 2 so right now
there's a bunch of tricks that we have
to make too many kcpt works but you know
this one will be totally fine so this is
really good what else um this is the
support in the Java world so Gerry nine
four we actually support that since
Jerry 9 3 we have server and client so
you can do whatever for example you can
write tests you can write a rest client
you can you know leverage that Tomcat
8.5 supports HTTP 2 it has been but
ported from Tomcat 9 while fly 9 under
throw one 394 ok HTTP is a client the
supports they should be 2 for Android
there was a jab hundred 10 to create an
HP 2 client API inside the JDK that jab
was targeted for Jerry k9 but it has
been moved to the ink
later project and so it will not be part
of the official Jetta k9 API it is now
in the incubator you're you're welcome
to play with it and report back feedback
on how do you feel the API is going but
you know it's it's a it's something that
it's it's there
I mean HB 2 is something that everybody
recognizes it's now time to move to that
and so we need a pi/2 support that we
need
you know low-level features like ILP n
we need to support all of that we
provide the dual project provides a pure
HTTP to client but we also provide a
semantics a higher-level HP client only
so when you request a resource to a
server you you're basically saying
something you're saying I want to get
this URI ok now how does this thing that
you want to do gets translated into the
actual wire protocol that goes over the
network that's kind of irrelevant you
have expressed the the will to get a
particular URI and then this can be
transported in the HP 1:1 format which
is you know classic everybody well now
everybody but you know it's pretty
familiar but can also be translated into
the hb2 format it's the same semantics
but different transport different bytes
that run over the network and so this is
the only difference that you have to
make to use the HP client which is the
high level client injury configured with
the default HP 1/1 transport and below
configured with the HP to transport
that's it that's the only change that
you have to make then once you have done
instance you can use the same instance
in your application in the same way you
don't change a single byte in your
application once you can inject a
pre-configured they should be client in
to your application so you can do that
in spring configuration file CDI
whatever you want and then your
application doesn't change and you get
the benefit of using HP to
let's go to the issues a little bit and
let's see what are the issues and how
they are addressed so it should be two
is two years old now it's a relatively
new protocol there is a lot of room for
optimization we have already seen this
you know Firefox and Chrome took
different decision on how to optimize
the in the request how they send out
requests and so they're still trying
every time and every time you get a new
browser version there's a very good
chance that that logic has already
changed and I myself I find that the
logic actually changing chrome from
version I think the last one that I show
in detail was 53 and now it's 57 and the
logic they're sending out it should be
request has already changed so they're
still working a lot gathering data
seeing what is the best patterns that
they can use for that so you know it's
it's it's a moving thing towards better
and better and better
hb2 there's a lot of difference between
implementation both clients and server
even nginx or Apache or Jerry or Tomcat
or whatever we're continuously gathering
date and say how we can do this better
and for example Jerry nine three versus
Jerry nine for the implementation at the
HP to level the scheduling and the
interleaving of how the frames are
returned back to the client has
completely changed because we figured
out that the Jerry nine three version
was not as optimal as could have been
and so we changed that in 94 and it's
now better so proxies and load balancer
are unfortunately not yet up to speed if
you I mean some of them are but they all
kind of share this problem of HTP one
one communication to the became so f5 or
rather a load balancer and others are
not really up to pair so it's okay
sometimes it's okay you don't want to
you know radically change your whole
deployment architecture that you have in
place you still want to get some benefit
from hep-2 for example just for multiply
but you know there are solution H a
proxy is one of these solutions so you
know you're welcome to experiment and
push vendors you know send an email to
the Apache mailing list or nginx mailing
me say hey can I have this and then you
know when you get 100 emails so of those
then they will do it like we did it
because they asked that the same stuff
so TLS everywhere I spoke about that
already but you know solved problem
already it's just a matter of you know
10 minutes there figuring out how let's
encrypt works it's really no more than
10 minutes you're done there are new
problems though like cloud
confidentiality if you terminate TLS at
the cloud edge and there are other
customers in the cloud they can peek at
your traffic so maybe you don't want to
offload TLS of the cloud edge you wanna
forward the encrypted traffic up to your
server or you want to be sure that the
cloud gives you a completely private
virtual network so that nobody can
actually peek at the data that it's on
your network very common pattern here is
docker container deployed wherever and
then inside of the docker container it's
running an H a proxy in term that's the
thing that terminates us to sell and
then it reaches along yeah yeah you can
you can compose docker containers in
that way and so you have you know dock a
container with a cheap proxy and then
one with Java need and so forth you
composing one with jelly we have a
official jelly instance in docker so
you're you're free to look it up and use
it and so yeah there are technical
solution to most of this problem HP 2
mandates 1 connection per domain this is
very efficient reduces a lot the number
of resources that a server in a client
have to use but as one big drawback if
there is packet loss at the TCP level
well that's your only connection and if
there is a packet loss and you have 20
30 outstanding
in there they will all be stalled until
the packet loss can be recovered by TCP
by a retransmission but that we all be
stalled and so there are cases for
example fastly did a very interesting
study on this first Lisa CDN at this
YouTube address you can see a
presentation by one of the fastest guys
very very interesting they measured the
packet loss in the United States so they
figured out eight 80% of the connections
had basically zero packet loss but 10%
had up to 1% packet loss and another 10%
had more than 1% 1.5% packet loss and so
for that twenty percent HP to was
actually not working that well with
respect with HP one why is that because
with HP one you have six connection open
okay maybe just one suffers from packet
loss but the other file they're still
running good so they are taking their
resources and then returning them and
then that single request that it's on on
the you know unfortunately CP connection
they got packet loss well you know wait
a little bit more it's gonna arrive
eventually but you know not immediately
but the other file five connections will
work fine now for hep-2 that's not the
case because there's only one connection
so again test try measure exactly but
there is a new project from Google a new
protocol that tries to address this
problem as well the protocol is called
quick and it is based on UDP or rather
than TCP and so because it's based on
UDP it's now connectionless it's just
UDP packet the flow the internet and
there are many benefits the protocol has
been designed to resolve a lot of
problems that TCP currently has in
especially TC fifties before the web so
for example there is a zero round-trip
connection establishment right now the
TCP protocol works in a
way that you have to send a syn packet
get the sing response back and then you
know it's a round trip to establish the
connection but but this one is zero
round trip there are tricks in TCP as
well to achieve zero round trip but you
know it's it's okay well quick has been
designed from the ground up to support
this feature is support independent
multiplex at streams so you can actually
send multiple UDP packets using quick
and each of those will be representing a
single stream and because it's a single
string if I lose one of those packets
all the others will not be lost because
their UDP packets one may get lost but
the other will arrive and so because of
that you don't stall the whole TCP
connection because you need error try at
this bitter try they are
quick is much more resistant to packet
loss it has built built in crypto
features and it supports what is called
connection migration and not rebinding
which is for example when you have your
mobile phone and you go from Wi-Fi to
mobile network to back to Wi-Fi every
time it is a network change that if
you're using TCP it's a different
network you get a different IP address
in and it's all complicated you have to
kill one connection and open a new one
and so quick doesn't have this problem
it's it's designed to support that
feature as well but what is the problem
with quick well by mixing transport
concerns crypto concerns and application
concerns there are there are people that
recoiled in horror because because the
history of protocols over the Internet
has always been that we layer them one
on top of the other we have a transport
protocol we layer a crypto protocol on
top of that and then we layer an
application protocol on top of that we
don't want a protocol that does
everything together because then it's
you know the story has told us well it
didn't work in the past why we want to
go that direction the hov working group
one of the most entertaining mailing
lists on the internet I think yeah
because there are people that as there
are super smart people in there there
are tons of experience and you know they
have very strong opinions of what should
be done and what not so it's pulling
income by the way is the guy behind
varnish the cash so it is one that knows
a lot about this stuff
so plus quick needs to re-implement a
couple of TG pcp features first one is
congestion control and the second one is
loss recovery I mean UDP packet can be
lost but you don't just lose them it you
were okay that's lost I need to resend
it so you need to reemployment this in
user space it's not anymore a feature
that the tcp kernel stack of your linux
box gives to you for free it is
something that you have to re-implement
in user land and so when you see all
this in you know as for example we would
do it in java as part of the jury server
and so when we look at this we say wow
this is a lot of effort to do because we
have to crack out TCP UDP we have to
crack out TLS in UDP and we have to
crack out congestion control and loss
recovery and so every one of this
feature is a lot of effort to implement
and implement right and so it's a larger
calling and recoiling in horror yeah
it's a big bit of effort but we'll see
where we go
so conclusions the good thing is that
for web developers there's basically
zero change that you have to make okay
your application will be able to
elaborate HP to push with several for
coming on you don't need to work around
HP one one limitation that you used to
be like for example you know packaging
all your CSS files into a single file to
reduce the number of requests or you
know image spriting gather HP one one
hacks and stuff like that
JD keen nine is up to up to speed and
you know it's
it's good you just need to move to a
server the supports hep-2 that's it take
your wire deploy injury done for
deployers though so DevOps sees ups they
need to take care of TLS renewals for
example and so you have to install a
process in your company to say ok we
need to renew we didn't have
certificates before but now we need them
and now there must be someone that every
three months which is the default
expiration time for let's encrypt
certificates or every year has to figure
out what to do with the certificate or a
new that or maybe add a new domain that
that's now required because your
business has expanded you want to always
keep Java up-to-date that's a good thing
anyway because you want to leverage
security feature fixes that Java puts in
from time to time
you wanna upgrade your server container
and you wanna take a look a close look
at your network infrastructure you want
to be sure that your load balancer and
every network component that you have in
between actually works if you don't own
the network infrastructure then you have
to look at your cloud provider and say
ok do you support this can I do HP - and
if not politely ask him well you know
why not
can I have it because otherwise you know
there may be other offerings that I can
examine or evaluate so it should be - it
is a good move in in most of the cases
when you get problems like the packet
loss or something like that
typically the grades - something close
to this HP one one may be slightly worse
than that but in average 80% like I
showed before it's going to be much much
better and then faster and better means
more money for your business so HP - at
the end it is all about your business
and making money and stuff
like that thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>