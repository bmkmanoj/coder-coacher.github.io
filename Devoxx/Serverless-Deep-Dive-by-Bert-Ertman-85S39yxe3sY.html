<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Serverless Deep Dive by Bert Ertman | Coder Coacher - Coaching Coders</title><meta content="Serverless Deep Dive by Bert Ertman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Serverless Deep Dive by Bert Ertman</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/85S39yxe3sY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning devops welcome to my
service deep dive so my plans for this
morning are to give you a glimpse into
the future of the cloud and I think
serverless will play a big role in that
in the next years to come so before we
dive into that just do a quick
introduction my name is Beth Minh I'm a
fellow at luminous in the Netherlands
we're based in the internet'll ins but
we also have officers in the UK in the
US and what we do is consultancy
services projects for our customers and
we also do product developments and a
lot of open source of involvement I've
been fortunate enough to be in around
Java for the last 20 plus years I run
into it when it was about one or two
weeks old while I was doing my
internship and I actually never left
doing Java for my entire career and
besides working with Java I also like to
speak at conferences perform trainings
and etc there's so much about me let's
talk about service and I'd like to start
off at this talk by giving you a picture
of what the evolution of compute looks
like from my point of view so it was not
that long ago if you look at the
left-hand side of this picture when we
were actually running our software on
physical hardware but if you think about
it maybe 15 years ago it was like pretty
common to run software directly on
hardware right and this hardware I was
either under your desk or was down with
a lot of other hardware boxes somewhere
in the cellar now beyond physical stuff
we've been virtualizing stuff which
basically meant we bought bigger boxes
and then we ran like a guest and then a
whole slew of guest operating systems on
on top of it right so we started
virtualizing our servers by running more
service on one physical box and then at
some point in time let's say maybe eight
years ago or some or Mia I think maybe
eight years ago we move this
virtualization stuff from our own data
center to somebody else's data center
what's we now call the cloud right so
this is not where the story stops right
so for the last
two or three years people have been very
busy with containers think docker and
others right so who here has experience
with docker all right it's like half of
you okay good so so some of you think
that containers are actually our well
most pure form of virtualization these
days rather almost cheap or most
lightweight for my visualization these
days but as I will try to point out in
the remainder of this talk is that we
now have a new high light in terms of
both virtualization also in terms of
compute where we talk about servers are
actually running functions as a
virtualization or abstraction and
mechanism so first question to ask when
somebody starts talking about new
technology is why on earth do we
actually need it right or what problems
is it trying to solve that we have now
right this question isn't asked enough
these days I mean we're really eager
into using new technology whenever it
sees the light of day
but we should actually always question
why first so the why for service is
basically twofold so far as I was
showing you on the evolution of compute
cycle we have been virtualizing servers
right and we care for service actually
we care so much for service that we
actually give them names right and we we
take care of them right and we give them
lots of attention and we are really
upset when the server goes belly-up so
in a way it's just like with bets right
so we care for servers as we care for
pets and what we actually are most
interested in is not the server so much
but we are actually interested in the
output basically and what I like to call
the compute right or the produce of the
server if you compare that to kettle for
example so with kettle we are no longer
interested in the individual animal but
we are interested in what the animal is
actually producing being in meat or milk
or whatever right and so if one or more
animals are underperforming you just
switch them out you replace it right
with another animal and the same thing
should be said of servers so we are no
longer interested in an individual
servers but we are interested in their
produce and their produce happens to be
compute power so as we're interested in
compute power right we
no longer care about servers hands the
name surplice so that's the first thing
the second thing is that if you think
about the original promise of the cloud
right it was that we were about to pay
only for the stuff that we are actually
using right pay-as-you-go that's what
the first acronym means pay go right pay
as you go
but then in reality if you look back
over the past five to eight years we
have been paying for everything in the
cloud which is the second icon M I made
it up myself which means pay-as-you-go
and also as you don't go right so okay
it's not very strong acronym but anyway
I think you you get it right so we pay
for everything in the cloud these days
right so therefore virtualizing in the
cloud is not cheaper per se right and so
we pay for everything and going back to
it original promise we only want to pay
for stuff that we are actually using
right and it also fits really well with
the time that we live in I mean in this
day and age we probably like to pay for
stuff that we use but we don't
necessarily have to own it right we
don't have to own everything we just
want to make use of it so the same thing
goes for the clouds right if you
consider the cloud somebody else's data
center which produces compute then we
are interested in using that compute
power every now and then but if we don't
use that compute power then we don't
want to pay for it right so for those
two things
that's where servlets was invented for
so I think the whole hype around service
started off around three years ago when
Verner Vogel's the CTO of Amazon came up
with this quote at a reinvent conference
I think it was back in 2014 or something
and he said well no server is easier to
manage than no server right and he's
absolutely right about that and this is
where the whole surplice thing actually
took off sort of think about the name
for a few seconds so the name is
actually kind of weird right server less
so apparently there are no servers
involved well spoiler alert this is
not true right there still server's
involved with server lists but you don't
see them right it talks about the
programming model so from a developer's
standpoint as developers we're
interested in compute but we're not
interested in managing servers so in the
programming model for server less
implementations you will not see
anything that resembles a server right
so that's the net that's what the name
actually is it's about the funny thing
is though that then the name mostly
describes something which is it is not
right just like with no sequel for
example right so we have a bunch of
databases are the only thing they have
in common is that they don't have sequel
as a query language so let's call it no
sequel well same thing with server list
you will see many implementations and
the only thing that they have in common
is that there are no servers or virtual
machines or whatever visible in the
programming model now servlet is known
by a bunch of names so some people call
it functions as a service actually
there's a difference between services
and functions as a service I'll talk
about that later on in the presentation
but some people think that servlet is
about functions as a service right and
functions are first class citizens in
service implementations and we'll talk
about that alone or if you want to be
boardroom compliant right you've got to
have your gardener speak so in terms of
gardener it's called function pass right
so functions on a platform as a service
and then there's people that say well
serverless
and functions let's call it back end as
a service right alright so this is
actually a bit of a funny name right so
imagine tonight I mean when we're done
doing this talk and all the other talk
today you're sitting in the bar of your
hotel maybe and then you talk to your
coworker you say well that's what
interesting stuff right back end as a
service and then there's some other
people sitting next to you they have no
clue about IT but they hear you talking
about this thing back end as a service
and you know what must they think right
yeah I know there's a code of conduct
here so try to be compliant all right
so with every piece of technology or
framework or semantics or paradigm that
that's introduced these days if you want
to be taken seriously then you've got to
have a manifesto right so does the
service and movement they have a
reminder fest oh so I'll I'll walk you
to it so first and foremost service is
about functions right so it's functions
are your unit of deployment and your
unit of scaling so when we start
developing software and I will do many
demos later on we have to think in terms
of functions right so we're no longer
thinking in terms of applications but
we're thinking smaller functions I hear
some of you think micro-services maybe
well let's save that for later functions
for now right so functions is what we
develop functions are what we deploy
right and functions is also your unit of
scaling which means that all requests to
your function are being skilled on a per
function basis and this is nice because
now you get a single threaded
programming model like I mentioned
before from a developer's point of view
we have no clue about underlying
machines virtual machines or containers
all right so we you just don't see them
you only see functions and api's and
that's about it right you have no clue
of there's a big processor underneath or
small one whether it has a lot of memory
whether it has very tiny amount of
memory that's all up to your provider
all up to your cloud provider to supply
you with just enough processing power
just enough memory actually depending on
use of your function we'll talk about
that later two functions are inherently
stateless at least for now right which
means that if you've gotta have storage
somewhere right then it must be some
form of a database or an intermediate
gas or whatever right so it's up to your
function if you want to remember
something after the function is done to
write it out in a database
somewhere alright so Berman storage is
still available but then you could think
of a database especially in the in the
cloud as a service thing too right so
there is someone providing you with a
database management system whether it's
sequel or no sequel that doesn't really
matter right you have no clue whether
their servers running on underneath
there - right so you have no clue
whether it's five servers or ten or
whether it's just one really big one
right you just use the database service
all right so you should think of those
kinds of services as service to service
skills per requests right which results
from the first bullet actually right so
functions on your unit of scaling so the
cool thing about this is that you can
never under or over provision right and
this is a big problem in terms of
getting stuff off the ground right so
imagine your web shop right and what
christmas is coming so you got a prepare
for a huge big lot hopefully right so
traditionally in the cloud this is a
problem because this means that you have
to have multiple instances ready for
your application
so that in order when it gets busy right
you can scale out now the thing with
cloud nowadays is that if you have a
bunch of CPUs either idle or an hot
standby or or whatever you pay for them
whether you're actually using them or
not the cool thing about functions is
that you don't pay for it
so as long as nobody is there calling
your function you don't pay anything all
right so the code is just laying around
doing nothing you don't pay anything as
soon as people start hitting your
functionality right that's when you
start paying so if there's like a single
user you pay a tiny amount of money if
there's like a million users at the same
time the scaling issue is up to your
cloud provider so your cloud provider
has to come up with lots of compute
capacity in order to run all those
requests simultaneously and then you
start paying more money but you only pay
for what you actually use so in terms of
running a web shop where you have to
deal with all of this over and under
capacity or when you're going to startup
and you only have a small amount of of
you need to get in business first before
you can scale out and see and scale up
right this is really interesting model
because you don't pay for stuff that you
don't use right and the fact that you
don't have to think about over or under
capacity that is actually really
interesting because it makes your life
simpler as a developer so I actually
already mentioned this right so we never
pay for stuff that is idle whether
they're cold servers or a hot standby or
whether their containers waiting to be
fired up right if you don't use stuff in
a service world you don't pay for it
then another interesting benefit from
this function model is that we have
implicit fault tolerance because we
skill per function so if somebody
triggers your function and it starts to
run and somehow it feels right then the
only thing that fails is actually that
particular instance so all of your other
users right they have their own instance
of that function so they are not and
well they're not not affected they sort
of say right and so you're implicitly
fault tolerance because your functions
can run on any piece of hardware that
your cloud provider supplies right so if
if the underlying machine actually goes
down or has problems then it's up to the
cloud provider to move your functions to
somewhere else in the cloud right where
it can run so it's their problem it's
basically the man behind the curtain
which is taking care of all of this for
you then it's bring your own code and
this means well depending on your cloud
provider this means pick a language that
you like write a function implementation
then deploy it add your cloud provider
define a trigger and this is how we will
run your function now the languages
which are supported of course vary per
cloud provider we'll talk a little bit
about that later and we talk about the
different implementations which are out
there but basically you just craft the
piece of code into a function which
means it has inputted his output you zip
it up and you upload it into the cloud
that's basically what you do
and then finally in a service world you
are entitled to metrics and logging as a
universal right for whatever that means
right so basically what that means is
that all of the cloud providers which
offer you a service implementation they
also offer you some form of centralized
logging which means that you can either
use a logging framework or you can just
write your standard out and then the
cloud provider will collect your logs
and will make them available to you from
a centralized place and the same thing
for metrics right so the cloud provider
should and enable metrics for all of
your functions so you can see that
whenever triggered for how long they run
how many times they actually ran whether
they failed or whether they were
successful etc etc I will show all of
this to you later on
all right so summarizing this right from
a developer's perspectives there's no
servers to administer right so there's
no infrastructure visible in the
programming model except for explicit
services that we use say and message
queue or a database right but we have no
clue about servers so we don't have to
scale them right so we get automatic
scaling we get automatic failover and
the other benefit is that we only pay
for the code that is actually being run
right so if we create something
beautiful we zip it up we upload it into
the cloud and nobody ever triggers it we
are never gonna pay a cent for having
the code available right but then if we
have lots of users and then we will
start paying but only for the stuff that
we were actually using so we are not
paying for over capacity
and when your servers are idle for 95 90
percent of the time right we don't pay
for that so in other words we are no
longer caring about applications and
therefore we are no longer caring for
application servers and also in terms of
containers containers are also not
visible in the service programming model
which means that if you've invested big
time into docker but you like this
service paradigm right you can forget
all about docker right so set for little
will over there but I mean unfortunately
containers application servers in a
service world they have no meaning to
developers
and then the marketing slides all right
you'll get your time short turnaround
because you just write a piece of code
you plug it into the cloud you define
your trigger and it's there all right so
it's really easy because it's on a on a
smaller skill it is really easy to build
something and have it ready if it works
it was automatically skill which is cool
for startups right and then I mentioned
it a couple times it's base you go
auntie alright well this is like a
general introduction so far it will it
sounds just like benefits right but we
should be aware that we've only seen the
hammer right so we've seen a hammer now
it's called service and now we should be
careful that not everything is a nil
right so we should figure out how this
model actually works and where it
doesn't fit so let's take a second look
so functions right we have a clue what
functions are right so it's a piece of
logic you give it some input a will have
some output
hopefully it's reproducible right what
we need for this is that we need some
sort of a sandboxed environment which is
able to run our code so we need a run
time and that run time is optimized for
stateless transient compute which means
as soon as somebody triggers our
function there will be a runtime
available for us and then maybe after a
function is done it will still be there
we don't know right so it might be
destroyed it might still be there so
when we hit it a second time right we
don't have any startup cost or what or
whatever we have no clue right we only
know that there will be a runtime
provided for us but we should not try
and optimize for that runtime because as
soon as you start doing so then a week
from now the underlying implementation
may have changed and we are optimizing
for the wrong things right so never try
an optimized for the underlying renta
you might say well this sounds awfully
familiar right we've heard this message
a couple years before right when we were
talking about platform-as-a-service
as an added layer of value on top of
infrastructure as a service
right so is actually new right this
sounds just like bass well there's a
bunch of differences between
platform-as-a-service and functions as a
service first off with platform as a
service like Heroku or Google App Engine
for example we're still managing
applications right so somehow we're
building something like a web
application we are creating like a big
war file and we are deploying that war
file onto some sort of a web server
right and then we add a bunch of
libraries etc etc so we're still
building applications because we're
building applications we have a clue
about the underlying runtime we need an
application server running underneath
right which could be that container it
could be something else with pass we
therefore also take care of scaling
right we need to determine when we
deploy our application whether it needs
a big server or small one and whether or
not we need to scale up right whether or
not we need a couple instances on cold
or hot standby so that as soon as people
are you know picking up on our
application right and the load increases
that we are still able to cope with that
compete with that load right so we take
care of scaling and therefore we need to
provision
enough applications on enough servers
right therefore we also need to - our
own runtime environments right we need
to take care of handling login
configuration whatever and then because
we need to manage all of this right we
also pay for all that right so we pay
for all of the server instances that we
use and it makes a difference whether we
pick a small server or whether we pick a
big server right it makes a difference
if we have like ten instances on called
standby or ten instances on on hot
standby right so it functions we have
neither of those things
so no clue about servers no clue about
handing the configuration of those
servers no clue about configuring
scaling and we don't pay for all of
those things and we also have no clue
about applications anymore we talk about
individual functions and this is both a
pro and a con as we will see later on so
to summarize this
we can create the picture lies like this
I just I think the other day I saw a
room Gupta I explained this so I asked
him can I borrow your slide and he was
so okay with it so if you go from left
to right we see the the type of services
that your typical club provider offers
these days right
and we go from pure infrastructure as a
service where most of the things that we
run on top of our virtualized hardware
is being run by ourselves and being
taken care of by ourselves and then if
you go to the rides you'll see we have
containers as a service where we just
add another layer of abstraction and
then with pass we just add another layer
of abstraction or actually two and then
with functions the only thing that we're
taking care of ourselves is the actual
little piece of code that we create and
deploy right so coming from the left
hand side going to the right hand side
there's less stuff that we have to
configure and take care of and there's
also less stuff that we pay for now
there's a whole lot of service
implementations out there so I just
listed the big four here and I think I
think it's fair to say that Amazon kind
of invented this right so they came up
with Amazon lenda AWS lamda back in 2014
that was when Werner was coined his
quote that I mentioned earlier and then
as you can see there's a bunch of other
vendors like Google who came about a
year after they had their Google Cloud
functions available I think that's only
able to run JavaScript and then IBM and
also Microsoft came with service
implementations so there's a whole bunch
of them available and even Microsoft
announced a couple weeks ago that you're
able to run Java on there as your
functions implementation so that's
actually pretty cool another thing that
was introduced a couple weeks ago is
project FN by Oracle so now if you heard
about it it was announced at JavaOne
it's also an interesting take to service
because they're not just implementing
the service manifesto but they're also
challenging some of the things in the
service manifesto like how to deal with
state and how to deal with flow across
functions we'll talk about that later on
and if we have enough time I'll show you
a bunch of demos
even as well if you're interested go
check it out so for the remainder of
this talk or actually for a large point
of this talk I will focus on the
features of AWS lambda it's not because
I work for Amazon or anything but
because it's very accessible technology
but now if you already have signed up
for a free Amazon account but if you do
you can get started with lambdas within
a couple minutes or if you brought your
laptop you'll be able to deploy your
first bunch of functions by the end of
this talk or maybe even sooner right and
well I think it's fair to say that right
now if you look in terms of features etc
they're actually the front-runner in
terms of service right but the orders
are catching up so maybe if you do this
talking about a year from now it might
be the other way around but for now a
thing they're still the front allure
all right so about AWS lambda it's
introduced as a service event-driven
compute platform provided by Amazon Web
Services all right so it runs your code
so a piece of code in response to
triggers or events so it's heavily event
based it was introduced about three
years ago at that same reinvent
conference that III talked about before
and it's part of the many many offerings
that Amazon's have so if you the
discrete shots actually from maybe a
couple months ago and there's a lot a
lot of services that they offer right
and so lambda is just one of it so it's
up there in the top left corner is one
of their compute services actually right
so there's a bunch of compute services
out there so maybe it's good to compare
them alright so you have a clue what
we're talking about so Amazon offers you
a couple of compute services first one
is ec2 which is basically their
infrastructure as a service offering
this is actually bets this is service
right so we have a server it's going to
be small medium large extra large
whatever and then on top of that you
manage everything you manage the
operating system configuration runtimes
application server whatever it's all up
to you
alternatively we have eg two container
service which is basically the same but
then you feed it a docker file right so
you say well I have a docker file which
describes my runtime environment and all
of my configuration issues right and all
of my dependencies so I just feed it the
docker file and then I instantiate a
server based on that docker file then we
have something called elastic Beanstalk
which is a funny name but it's what
Amazon is actually known for funny name
for all the services so for most of the
services you have no clue what it
actually does just from the name right
but elastic Beanstalk is basically their
path so it's like a web container and
then some right so it's like a platform
as a service offering which is able to
run applications and you can compare it
to what Heroku is doing what Google App
Engine is doing and a couple other
implementations as well and then finally
we have lambda and lambda is their
functions as a service offering right in
terms of runtimes
support they have support for four
languages basically so you can run
Python or a note I think they support
multiple versions of not actually so in
this case this is in interpreted
languages and you know on the fly right
so you can even just lounge there web
console you can start your typing your
code right away save it
configure it and you're done right what
if you do Java or C sharp then you
mostly edit your code offline then you
zip it up you upload it to the cloud
and then you define a trigger for it and
that's how it works right so as you can
see they only have support for one real
programming language which happens to be
jump of course all right so how it works
and I'll show that to you when we do a
couple demos later one you just create
your code in your favorite IDE or in VI
or whatever right you just trade your
code and then you create like a zip file
deployment of your function you upload
that zip file to in Amazon's case to
something called s3 which is their
bucket store right so you just upload a
zip file into the plant and it just sits
put right there's nothing then you go to
a
comes all or you can use the command
line interface in order to configure a
trigger for your code so you say well
when somebody does a database insert on
this table right then I want my code to
run or you can say when somebody does a
HTTP call to these endpoints I want this
code to run and then you hook up that
trigger to your code right so you define
which class to instantiate and then you
wait you wait till somebody actually
triggers your code so in this case you
do like a curl - HTTP endpoint for
example if you hook it up to that and
that will actually trigger an instance
of your code ends of your function to
run so Amazon will run it they will
meter it and then you pay for the amount
of seconds and the amount of memory did
actually used right and so they have
like a small calculation that they use
in order to determine the amount of of
money and then when your code is done
running they send you Bill well
basically to do it once every month but
this is how it works right in between
but nobody hits anything of your
triggers right you don't pay anything
right so you only pay when people
actually run your code so trigger and
run your code and you pay for the actual
runtime
all right so if it runs in like five
milliseconds you only pay for they
rounded up to the nearest 100
milliseconds so you only pay for 100
milliseconds if it runs for you know
five seconds you pay for five seconds
right sounds like a fair deal right they
for use alright so let's start building
our first lambdas so how do we do that
so there's a couple ways to get started
first thing we - sign up for a free AWS
account alright and then we get our
first 1 million lambdas for free per
month actually alright so this sounds
like a good deal and the other thing
what you can do is you can install the
AWS plugin for eclipse if you like if
you happen to like it eclipse if you
don't then there's also a maven plugins
available and I think for IntelliJ
there's also a plugin available that you
can use to interact with the AWS
command-line interface in order to
create
packages and upload stuff into the clock
and do your configuration and then we
can write a piece of code and when we're
done we can either use the plug-in or
use the command line to upload the code
into the cloud that's exactly what we
will be doing next all right so for this
I first going to show you now I'm going
to the editor straightaway so I just
have Eclipse installed here with the AWS
toolkit because it's great for demo
purposes so what I can do is I can
create a new lambda AWS lamda Java
project all right let's call it hello
dev Fox and let's configure the the
input event so because it's a function
it needs input right so let's set it to
custom so we can edit that later and
then I'm just gonna finish the wizard so
you get like a readme that shows me what
steps to take I'll skip that for now and
then it generates a little bit of code
for me so what I'm gonna do here is I'm
gonna set the input to be string and I'm
just sort of here as well and then the
output is also gonna be a string right
so function string as input string as
output and then what we're going to do
is write an actual hello world
impression is a little bit hard to type
at this angle but let's do your typical
hello world where we say well that's do
hello plus input all right very simple
function alpha save this then shown
something will show up in my problems
view because the wizard also generated a
unit test using the same scaffolding
template so I need to fix it so in this
case the input is going to be a string
right so the nice thing about the
plug-in is you get the implementation
class you get a unit test for free right
sorry I thought about that too and so we
can set inputs so let's well that's at
the input oops I said the inputs at
devoxx
and then let's do an assert here where
we say well the input should be
this and then hopefully we save compile
and now we can run it
you can say run as unit test and we have
a green bar right so it's nice it's just
a simple POJO right so that makes it
easy to unit test it's a function right
so it's it's just small implementation
and because it's small it's easy to test
now of course this is not running
service yet because not running in the
clouds is running locally on my laptop
so the next thing to do is basically run
this in the cloud so it can use the same
wizard or it's a well run this function
on AWS lambda I says well you need to
upload it first so say well right now
and what it does is it asked me to which
AWS region I want to deploy so my stuff
is running in EU West in Ireland and
then I can create a new function or
choose to update an existing function so
in this case I create a new one so let's
call it hello
that works what's next to just give it a
meaningful description right like we
always do and then it asked me to define
a function role now the thing with
Amazon is that they have very
fine-grained authentication
authorization models for their
infrastructural stuff so every time you
need to run something on something or
something needs to use something else
you need to have permissions for that so
in this case I just set up a very simple
role that has access to to run a lambda
and to access the log and metrics
alright so I don't want to bore you with
this so I set it up beforehand is
nothing special but just so you know
next thing is says well I'm gonna upload
this zip file which I will be creating
behind the scenes into an s3 bucket and
s3 is just their object store right so
crazy zip file uploaded and it will sit
there so I pointed to the right store
and then I need to configure a little
bit of memory settings and this is not
because we're actually configuring the
underline
server but this is because we want to
configure the amount of money that we
want to pay right so this is a very
simple implementation so I probably
don't need to have a gig of memory for
it all right let's start with 128
something and then the run time let's
set it to maybe 2 seconds or something
right or 3 whatever you want to do and
this is the amount of time after which
the function will be good off so it runs
the longer than 2 seconds the run time
will just shut it right so this prevents
me from paying for a function which runs
endlessly right so we set a hard limit
on the amount of time it is allowed to
run so this is basically configuring
costs not so much configuring the server
so now I press finish and hopefully
Wi-Fi is a little bit reliable so we're
creating a zip file uploading it into
the clouds ok everybody get off the
Wi-Fi please yeah there we go and now
it's in the cloud next to believe me
I'll show it to you in a in a minute so
now we can just repeat the run function
on AWS lambda and now we can configure
some input so it takes a string for
input so we can say 1 let's say box 2017
and then invoke it and now in my console
you can actually see it's invoking the
function it's sending the input into the
cloud then we get a little bit of
logging where and also a little bit of
metrics as well we say well we see a
start event because somebody is
triggering this function all right then
we see some input this is basically the
console dot lock which you saw in the
implementation and then at the end you
get a little bit of metrics in terms of
the amount of time that it took to run
then you see it's rounded off to the
nearest 100 milliseconds the memory size
like configured and then the actual
amount of memory that that it used so
now the interesting thing is a runners
again
this is much faster and this is because
it's Java right so it needs to fire up
JVM it needs to load some classes and
that takes a little bit of time so the
first time that you run this you'd
actually pay a small penalty for this to
run also not only in terms of time but
also in terms of money right so funny
thing is do we need to optimize for this
right so do we need to warm up our
servers as soon as we deploy our our
application well the answer is no you
should not because then you try to
optimize against the underlying
implementation platform which you have
no clue of right so if there will be
enough users using this it will be fast
enough eventually where everything is is
warmed up by your users if you use
another language like nodejs or like
python right you don't pay this penalty
so you'll see that it's much faster you
only take like two or three milliseconds
for this to run and that's also because
a lot of the external dependencies that
you need to use are already supplied by
the platform so you don't need to love
the classes for it alright so now you
seen it run now let's switch to the
browser for a second and what I'm
showing you here is actually Amazon's
lambda management console so if you sign
in using your account you can open up
the lambda console and this gives you a
list of functions so if i refresh this
then we'll see that there's like a Hello
dev locks here all right
and it points to a zip file in s3 which
I can show you but it has the
configuration for the row it has the
configuration for the memory and the
timeout setting and a description very
meaningful and then the handler which it
will bootstrap so basically it's like a
servlet maybe right so you need to point
to any methods that will be invoked
using the input and where you get the
output from second top over years called
triggers and our triggers is what we
actually use to trigger our function
right so so far we just uploaded
something into the cloud done nothing so
there's no way for other people to
basically trigger this function so in
this case we can define a trigger which
I'll do later on
and then we can start tricking our crowd
but then before we do savages when I
show you the third tab which is group
monitoring and this is where we get a
some basic metering right where we can
say well there's an invocation card it
was invoked two times by now we see the
duration we see whether there were
errors etc etc right so you get a little
bit of metrics out of the box and then
locks are centralized as well so we can
say view logs in cloud watch which is
Amazon service for viewing your logs
alright so we can open up the output and
this is where we can see the logs which
were shown earlier in the Eclipse
console now about those triggers let's
create a trigger so using the cloud
watch servers I can also set like a
scheduled trigger so for this I'm gonna
say well let's get a new rule let's
create a rule and let's make it a
scheduled trigger and so let's set it to
a fixed rate of 1 minute and then every
minute I want to trigger a function so
let's trigger the hello Devils function
give it some input all right so we can
give it a constant for example what
we're gonna do that once again a little
bit boring but go figure details you
have to give it a name let's call it
fire a ones minute and any meaningful
description again right we enabled by
default let's say create rule and now we
have a rule which will basically trigger
our function once every minute so if we
go back to the lambda dashboard and I go
back to triggers for this function we
now see that we have a trigger defined
so Amazon will take care of this so we
wait long enough eventually something
will show up in the lock so see that
wasn't triggered has to be patient
hard to read I can show you the locks as
well maybe doesn't just started watching
other locks
now those are still there charities
right so he just saw it triggered so
once every minute it will trigger this
function and now we have a trigger
defined so this is pretty meaningless
trigger but the trigger could also be
like an HTTP rest call or could be like
a database insert or whatever right and
I'll show you more useful examples later
on yeah I think for now that's that's
good let's switch back to the slides
so about triggers lambdas are
event-driven right so meaning we have to
wire up traitors to our functions
otherwise they can't get cold now Amazon
has a lot of event sources that we can
use as triggers right and if you're
familiar with the Amazon services then
these will be meaningful if you're not
then I'll try to do a quick translation
of it so basically what Amazon does is
they support HTTP requests so you can
define like a REST API or credit a P I
on top of your functions right and then
why are the individual operations two
different functions or you can wire
credit vents on data sources to your
functions right so if somebody does it
insert or delete from a database that
could be an event to trigger a lambda
function I think you can do something
meaningful with the data for example or
you can hook it up to some sort of
messaging service that Amazon provides
and they provide a number of them so
they have like a simple in memory
messaging service they also have more
elaborate messaging services they have
email services so somebody can send an
email to a certain account and that
might trigger a lambda service all right
so it could be meaningful implementation
to do some sort of customer service
thing on the other on the right hand
side we see that we have support for log
and stream processing which you can use
to do well to process big amounts of
data so for example we can hook up our
functions
- maybe the Twitter firehose or
something using Amazon's kinases or
whatever service and or we can start
processing the logs of other lambda
functions by giving it access to the log
files and then process everything that
gets written in the logs or we can hook
it up to more developer services like
for example Amazon's implementations of
of get right so if somebody commits
something into a repository than we
might trigger maybe a custom-built loop
right so we can use lambdas to build
like a CI CD pipeline right and using a
commit hook we can trigger the first
lambda to run produce something which
thing will then trigger another lambda
to ruin etc etc same thing can be done
for configuration management services so
if somebody rolls out new templates to
create servers or to or creates new
users in a I am kind of store right you
can all just respond to those kind of
events by triggering lambdas using those
events and then the funny one is using
Amazon's services for interpreting text
and voice we can also hookah lambdas up
to voice commands or maybe to chat bot
right which is also very cool and I'll
demo that later on so now that we know a
little bit about how lambdas and
functions in general work on a service
platform or just on one of them I'll
show you others later on let's try and
rethink the traditional architectural
concepts so would it be possible to
replace everything that we've built
before using this kind of technology
right just think hammer and nails again
right so how do we do this let's imagine
the typical web application for a second
right so we have like a three or a
multi-tier application that has a
database for storing data right inside
has some form of a web application
running server sites right whether
that's like a HTML generating
server-side framework or whether that's
just a bunch of rest services that
doesn't
really matter and then we have some form
of a client which could be a browser but
it could also be a mobile application of
course this is a typical web application
nowadays so it would be possible to
reimagine this concepts using a pure
function approach or using a pure
servlet approach well the answer is yes
it's possible that's a little bit more
elaborate so I'll talk you through so
first off we need to figure out a way to
actually distribute the static logic so
for example if we have a web application
then the browser need to download your
HTML CSS JavaScript from somewhere right
now for this we can use either a content
delivery network where we have those
files available just static compiled
files right or we can use in Amazon's
case we can also use s3 which has the
option of hosting one of its buckets as
a static web site so as long as the
content is static so if it's like an
angular application which is transpiled
javascript HTML CSS images whatever
you're fine you just hosted in an s3
bucket and then you make it available as
a static website so then you can hook up
by domain name to it and then your
clients your browsers can then actually
download the content from there instead
of having a static website it could also
be a mobile application in that case the
mobile application is being hosted in
the App Store or in the Play Store and
you can just download the mobile
application to your device and that's
how you distribute the client side of
things the second step would be to have
some sort of a third-party
authentication service right so you
probably integrate with something like o
or something similar or you hook up to a
Gmail or Facebook or whatever you use as
an authentication mechanism in order to
gain access to the application or
certain services of the application then
we need to get some content into the
application for this you can use one of
the databases that some cloud providers
offer because you just dump in a little
bit of data let's say product data and
then you make a piece of your catalog
available as read-only data so your
mobile application
your client can actually go to that
catalog directly and use that as his
data source and you have some form of a
crude API in front or in this case just
to read options or you have some form of
an API in front of it so you can
download the data into your mobile app
or into your browser right and because
it's redone it is read-only there's
nothing bad with sharing it directly
from a catalog then some of the logic
which used to be on the server needs the
girl to the client it's a little bit of
the MVC style logic that we have so in
the old days your server-side web
application basically was your
controller so you use it to navigate
from screen to screen screen and then it
also knew where to get the data from now
in the newer style web application that
we built for the last couple of years we
move at least part of the logic into the
client as well so if you use angular or
something similar right then we have a
Model View controller
alike mechanism within your front-end
right so some of the logic that used to
be on the server will now be pushed out
to the client if you build a mobile
application you already have that logic
in the clients then if there's
additional functionality that we need to
invoke right we need to make that
available through some sort of a gateway
so in this case eventually we'll keep
some of the logic in functions and
lambda functions but in order to reach
those lambda functions we have to make
them available to the outside world and
for this we will use something which is
now called an API gateway an API gateway
is what you use to define a maybe crud
style rest interface which can be
versions which can be documented with
examples as well so your mobile client
or your browser in this case is able to
invoke it and since its rests it will
play nice with either mobile
applications or with angular style
applications for example now API
gateways our services being offered by
cloud providers these days there's also
a lot of old fashioned ESB products
which are nowadays dubbed
be i gateway right so if you want to
spend the money again by an FBI gateway
and then finally when we have a piece of
advanced functionality right we can keep
that kind of functionality on the server
it saves you from abetting your client
every now and then it saves you from
adding a lot of logic in the client and
some form of functionality is probably
not suited to share with your clients
right so you keep it on the server so in
this case let's say it's advanced search
functionality and using this phone can
trigger this function via the API
gateway so somebody just issued a get or
post or whatever on an REST API that
will be the trigger for our lambda
function to run and that lambda thumbs
cannot basically use the same data set
on the server in order to do some
interesting sorting stuff and then it
will respond through the API gateway and
using the API gateway just as with an
ESB we also have the option to remodel
that data right to convert it to
something else or do some interesting
things with status codes or whatever and
then finally we have some piece of
functionality which is best suited just
to stay on the server in this case
purchase functionality which will walk
you to the purchase process and
eventually we'll save an order in a
purchase database alright so the answer
is yes in a pure service world we can
still build web applications warning
here of course is just because we can
may not always be the right reason right
so I'm not trying to encourage you to go
back to work tomorrow
and/or Monday and then start converting
all the our web applications and to lend
us right would be cool for a day or two
but then probably not such a good idea
so let's think of a couple reasons where
service might be a better fit
how something that I I should add and
here is that as you've seen in my
previous example servlets is more than
just functions as a service now a lot of
people these days especially on Twitter
etc are talking about service as if it
is just functions as a service but as
you could see in the previous example we
were using a combination of both
functions lambda and in this case and
also other service implementations via
the database being at a API gateway
content delivery network static website
hosting you could all consider them as
server those implementations too because
as a developer right you just use the
functionality do a little bit of
configuration we are not dealing with
configuring the underlying servers or
the underlying runtime for those
services so server is actually way more
than just functions all right now let's
look at better examples instead of
rebuilding all our web applications
using functions so prime example for
this is what they call event based
processing that's what we've been
talking about before so a thing that you
can do is for example you can respond to
incoming data so if somebody uses your
application and then needs to create
some data in this case your new user
needs to create a user profile then as
soon as the user is sending you data in
terms of either profile data or in terms
of a profile picture right you can
respond to that incoming data and then
do some back-end processing the
interesting thing about this is that
this this is pretty unpredictable logic
in terms of unpredictable when it will
run right so when you launch a new
application in beta
first you just have a small couple users
using your functionality so it's really
handy to have something that will just
only work when triggered right so you
don't have to set up a complete back-end
application on top of a web server need
to think about scaling so if I'm dealing
with 10 signups you know at a second can
I also get away with like a hundred
signups when I get really popular and
how about a thousand its etc I
so this piece of functionality actually
really interesting to build as
serverless and you can use it and
actually for small amounts of data but
also for batch data processing so what
we will be doing is let's imagine we
have an application once again could be
website could be mobile application that
asks you to create a new profile and
then doing the profile creation process
it asks you to take a picture of
yourself and then upload that picture
into the cloud in this case it will
upload the picture into a s3 bucket
store which is Amazon's objects database
and then that object insert or the put
of that object into the bucket will
trigger a lambda which will then process
the incoming image and create a
thumbnail out of it and then it will
place a thumbnail into another bucket
which can then be processed by something
else right or maybe the bucket is just a
place where all the thumbnail images
reside so you can use it to link using
HTTP request whatever so for this we
will use s3 and set enough about this
tree I guess so let's show you a little
bit code so first I have a precooked
demo let's go to the implementation so
what I have here is something called a
s3 event handler I'll make a little bit
bigger so you can see so once again this
is just a simple handle request method
that we're implementing so just a simple
lambda and the lambda gets input in the
form of a so-called s3 event which is
something the Amazon runtime creates as
soon as somebody doesn't insert I'll use
that insert as a trigger for my function
so get s3 venison as input and then I'll
send some string as output maybe a
status control message or whatever as
soon as somebody will trigger this
function do a little bit of logging and
then the interesting part begins here
where all say well let's look at the
incoming event and retrieve the bucket
and the key combination
because an s3 a bucket and a key
combination will point you to a record
in the database like a primary key for
something which resides in s3 so I
figure that out and then I will use a
Amazon s3 client right to actually
connect to s3 and then get the actual
object so I now know which objects to
get so I get the objects and from the
objects I will start reading the
metadata and then specifically I'll try
to exit the content type right because I
want to check whether the content type
of that image is of type image slash
JPEG so then I can process the image so
this functionally implements this
alright and then I do a little bit of
image IO magic here just a fairly
straightforward simple implementation to
read in the original image and then
compress it into a 100 by 100 thumbnail
image I'm not really fancy algorithm
just the most straightforward way I can
actually think of and then if I'm done
creating that thumbnail I'll create a
new file right I'll give it a file name
and then I do some conversion with byte
array so I get it like an array of bytes
which I can then write to a file so I'm
gonna insert the new object into another
s3 bucket which holds all the thumbnails
all right and then finally I'm gonna
write that image into that second bucket
and if I'm done writing I will delete
the actual incoming objects because with
s3 you will eventually start paying for
the amount of data that you store so in
order to keep my bill limited I just
throw away the incoming data if I no
longer use it right although there's
like a big free threshold but eventually
you start paying and then I'll just
return done when I'm done okay so this
is basically all the coded I have now to
save time I've already uploaded this
code into the cloud so let's go to the
lambda dashboard and then look at my
functions so there's an s3 event handler
over here and this event handler has a
trigger defined
which is of type s 3 and then of event
type object created so somebody in
certain objects then my lambda will be
notified so it's enabled so it's active
so now let's go through the s3
management console right which will list
all of my s3 buckets and then I have a
incoming bucket which I have called
incoming files for lambda which is empty
now can refresh it there's nothing up my
sleeves right and then I can upload an
image there so let's go to desktop and
find a suitable image so I very much
here of a job Lego thingy so I'll upload
that uploaded into s3 takes a little bit
of time now you see it's in there and
now if we wait for a bit hopefully it
will disappear all right that will be
good sign stuff disappearing in this
case it's a good sign since it's the
cloud it's eventually consistent so I
need to help it a little bit here
alright so now it's gone so that's a
good sign
and then hopefully in the processed
image thumbnails folder I have the hope
thumbnail yep there it is just created
right so then I can open it up and we
see that we actually have a 100 500
pixel thumbnail here ok so then let's
head back to the London console let's go
to monitoring see that was invoked so
let's go and view the locks you see that
I've been running this demo a couple
times before and here's the output
logging all right not sure we were able
to read it back so we see that we get an
input input event with event name object
created put then we see the rocky name
right we fetch the image from the bucket
figure out what the content type is then
we do the conversion thing and then it's
done running as you can see it took
quite a while to run because I need to
warm up some stuff if I run it again
it will be about one or two seconds
maybe this is also because I used a very
stupid implementation of the compressing
algorithm so if I optimize on the
rhythm it will be much much faster all
right Morse's show I think for now we're
all right so maybe this is a good time
to do a coffee break and then you just
arrived here I can
oh good time for coffee that's the way a
quick coffee break I'll see you back in
15 minutes and then I'm gonna show you
how to build microservices in the clouds
right all right so right back up I hope
we didn't lose much people a few of them
just people coming in okay so let's
continue so summary so far for the two
of you that were just here for the break
is what we've seen so far is just
triggers right we've seen triggers again
so somebody reinvented database triggers
hoorah
all right so can we actually do any more
interesting stuff of this just besides
database triggers all over the clouds
well I think so so the next example it's
going to be well going back to the whole
back end that's a service thing right so
actually this is I think this is
interesting in terms of mobile
applications because imagine you're a
mobile developer and you're really good
at developing the app side of things for
some pieces of functionality you want
stuff to run on the server but what you
don't want is to become responsible for
setting up servers in the cloud for
actually managing those servers for
scaling them yourselves
etc etc etc right this is a whole lot of
work and you have to pay for all the
stuff to think about scaling again etc
so using lambdas or similar
implementations at other cloud
preventers as back-end as a surface
implementation is actually pretty
interesting idea right so in this case
what you probably do is you have a piece
of functionality or more of those pieces
running in the clouds right you just
create the code and maybe you can even
create it using the language of your
choice so if you're an iOS developer and
you like building your application with
Swift then if you use ibm's open whiskey
implementation or open whisk in general
it's an open source project then that
has bindings for swift to write so you
can write your back-end logic in Swift
too and then deploy that into the cloud
and then just define a trigger now this
trigger is probably going to be an
intermediate layer which understands
crud like operations so this is where we
run into the API gateway again so just
to depict it into a scenario we can
either have like a mobile application or
have like little application again that
doesn't really make a difference that
uses angular or some web style mobile
framework or a native mobile application
that knows how to talk to a rest
endpoint which is defined on a API
gateway and this API gateway has done a
trigger to a lambda function which does
something interesting and then finally
persist something in a database in this
case instead of choosing s3 I chose
dynamo DB which is just another database
that amazon offers just for fun so when
we start doing this we immediately
stumble upon this intermediate component
which is the API gateway now in this
case if you look at the API gateway
through the eyes of the web console it
looks as a very simple thing but the API
gateway is not it's actually a very
complicated Beast there's lots of stuff
which you can configure and basically
figuring out the API gateway is what
took me the longest time in terms of
experimenting with all of this now
luckily there's there's a bit of wizards
and shortcuts that you can take which
I'll show you so that saves you a bit of
time and the other cool thing about this
api gateways that is it's sophisticated
right so it's also sophisticated in
terms that it knows how to deal with
versions so you can have multiple
versions in operation at the same time
it knows about stages so we can run
development stuff apart from running
production stuff and it has good support
for contracts and documentation so if
you're used to writing swagger documents
or swagger con contracts then the API
gateway support
those contracts so you can upload your
API contract into the FBI gateway or you
can generate documentation from it so
that's actually pretty cool stuff so
let's do another demo so in this case
I'm gonna be using a mobile application
and let's switch to eclipse for a minute
so I built a tiny application and I'm
not really good at front and stuff as
you'll see in a minute but I have like
this static HTML file and I included
jQuery just to annoy you
right just on purpose right so it's it's
J its static HTML a little bit of CSS
little bit images and then a bunch of
JavaScript which I put in the same file
of course right so basically what this
does is actually create some JSON
package that uploaded to a crud IP I in
the back ends and then show the result
that's basically what this does now let
me let me show it to you so here it is
unfortunately it's in Dutch you didn't
have time to translate it into English
but it's actually pretty easy to
understand so what this does is I'm a
big fan of cars in this case I Drive a
company car lease car right so I want to
figure out if when I start a new term
for an or new contract for my lease car
whether or not I will end the contracts
before the the term so if I leave like
in a four-year contract I want to figure
out if I've driven enough to maybe
return the car after three years or so
right so I build a small application for
this like ten years ago and and now
basically what I can do is I can say
well let's say I have a I'll lease a car
somewhere in let's say 20 2015 or so I
started a contract which ran for 48
months right so that's in the terms of
the contracts then the mileage on this
is like 140k in in kilometers so if i
eat across the amount of mileage but
then the car needs to be returned
and then I have like a current situation
let's say I've I've driven only 50
kilometres 50k all right and now I can
check hopefully doesn't work let's try
it again maybe need to reload there was
something wrong 48 months 140k
kilometers and then if I've only driven
50k let's check maybe I run into a
cross-eyed thingy here
let's see disabled restrictions
let's loaded again I switch network so
then it might run into a cross-eyed
thing again so trying to bore you with
this again able to input 140k and and 50
now hopefully it works
there it is
alright so you also see my amazing user
interface skills alright so I now get a
little bit of information back from the
back end so it says well starter
contracts if everything goes according
to plan
right you lease your car for four years
so then you should return the car on
November 7th right current date is
November 7th in 2017 so you're two years
in so you're you so the amount of time
has that has passed it's now 50% of your
contracts right if you want to return
the car exactly by the terms in the
contract you need to drive at least 95
kilometers per day your actual
kilometers per day are only 68 so I
don't expect this contract to ends
before the actual terms of the contracts
right and then but if you do and but
when it ends after 4 years I expect that
you've driven about 100k kilometres
which makes the average per year about
25k right so this is just very
straightforward stuff so I've shown you
the front end so the front end could be
an app could be some static thing in my
case is a static thing and I'm actually
hosting this static thing in s3 so if
I'm going back to the front and
implementation
nice tree here I have a bucket called
luck tied up and within this bucket
there's all the static stuff in there
and then if I go to properties I guess I
configured that I want this bucket to be
a static website right so you just
upload the stuff you just enable this
feature and now it's just hosting this
as if it was like a website so if you
look at the URL you see that it has like
an s3 bucket name in there but what you
can do is using Amazon's of route 53
service you can hook up a domain name to
this bucket and now just behaves like a
regular website so it's surplice right I
don't take care of servers I just throw
in a bunch of static stuff and now I
have a client-side application but this
could also be a mobile application now
let's go to the backend side of things
so I switch back to eclipse now I'm
almost ashamed to show you this logic
because this is something that I've
written a long time ago I think over ten
years ago so I just took the old
implementation which was a POJO and
which is basically just one function
predict end of contracts I get a little
bit of contract data as input and I'll
return a result so you can see it's old
stuff because it uses calendar to
actually deal with dates right so I
probably could have used like maybe 60
lines of code less if I use the new date
and time API but apparently this is all
stuff it works so I just took an
existing pojo and I created a lambda out
of it so I did this by wrapping this
Bojo in a handler right which got then
the contract data as input and I
resolved this output so and the only
thing I do is I invoke the function now
the contract data object this is this
one this is a POJO nothing special about
this and the cool thing about lambda is
that AWS will automatically
incoming JSON data to this object right
so underwater probably use Jackson for
this and if you know satisfied with this
you can do the mapping yourself as well
but I'm using the automatic mapping and
the same thing for the result object so
if you look at the result objects it's
just a POJO again with a number of
fields switch and then fill out and then
send back to the clients so I zip this
up upload this into the clouds which
have done already and then if I go to
the lambda dashboard and I go to
functions again there's my lobe tied
calculator lambda which contains the zip
file a little bit of configuration a
little bit of memory a little bit
seconds to run and then I define a
trigger and the trigger in this case is
the FBI gateway so I'm using an API
defined in the API gateway to actually
trigger this so to be more specific I'm
using a post on my lambda so somebody
posts some input data it will trigger
the lambda so let's go to the API
gateway to show you the definition of
this just refresh it for a second so
here's my API called loop tied lambda
and then there's the post operation over
here which will then be visualized by
the editor and then you see there's like
a client that sends an incoming request
which is then gonna be mapped using a
integration request to a lambda and the
lambdas over here on the right hand side
so this is my line if I click on it I go
back to the lambda dashboard and then
the end result of the lambda is then
mapped back to integration response we
should use a pass through to the method
response which will then be an HTTP
status 200 and it will then be sent back
to the client
now this is a very simple REST API but
it does support staging so I can
deployed it to either death or
production or whatever
it supports versioning etc also supports
testing so in this case I can say test
and then a little bit of input data
pre-configured so in this case a little
bit of JSON
I can input that Jason over here I can
press the test button and I will run and
I get my end result back she's pretty
fast
just a couple milliseconds alright so
this is a nice way of just doing a quick
smoke test here and then of course there
there's there's logging and other
interaction going on so you see
implications and once again you can go
to cloud watch to monitor the logs then
you see some incoming data and some
outputs that I I wrote either using the
logger or system mouth doesn't really
matter just just send it to the outputs
and then Amazon will collect all of
those logs for you and presented through
cloud watch yet so take care of if you
use system out a lot then it actually
gives you little bit of an eye out
penalty right so you should actually use
the logger
all right yeah so this is another way of
actually using service in order to
provide some useful functionality and
actually if you want to see this in
action you can just take your phone out
and go to the my devoxx app which you
probably all use right to schedule your
sessions and then underneath the my dev
fox app is also a lot of service
functionality right so in terms of
coding everything in the app like they
used to do in the years before then I
decided to move bits and pieces of that
functionality into the cloud so this
gives you a number of advantages first
if there's actually an update at the
function T so if you if you fix some of
the functionality or you you add more
functionality in the backend part you
don't have to update your mobile app
right so you don't have to go to the
whole process of updating it submitting
into the App Store update processes etc
because your logic is in the backend
right secondly there's gonna be less
code in the mobile app which is also
good right and then you have more
control over the over the backend then
you only pay for actually usage so it's
actually pretty cool model so let's get
back and let's revisit this scenario
right so what I just did is we have a
client
we do a call Troon API gateway where we
define an API or contract for our lambda
then we hook that up to our lambda now
interesting question that I get a lot is
is this lambda now a micro service right
interesting question and I think the
answer like a true architect
it depends right so our lambda functions
micro-services well first off there's a
lot of similarities between it right so
they both do one thing and one thing
well which is kind of like a definition
for micro-service and then this whole
thing is being triggered by events
so there's event based interaction which
is like choreography this is a model
that micro-services tend to like so yes
there are similarities then there's also
differences differences in terms of
granularity because one lambda in this
case is equal to one action and in the
case of microservices that might not be
enough right so you might have if you
want to do micro-services that crud
based operations you probably need four
or five lambdas to do the same thing
right so you separate everything out the
functions so in this case the lambda
will be smaller than a micro service so
let's call the nano service or whatever
Pico service up to you right so and in
my opinion in micro service is a bounded
context of actions and a little bit of
the main with autonomous storage right
and so the storage and the bounded
context and the actions are not part of
a single lambda service so in some
particular cases one lambda
might be a micro service it could be a
micro service but in most cases I think
you need more than the operations to
actually build a micro service so you'll
probably build something like this
alright so you have your clients left
hand side then you have something in the
middle the API gateway that defines the
interface or the crud API and then the
operations of that API of the contract
will be mapped to several lambda
functions and they all have interactions
with the same database or data store so
in this case I would say that the
entirety of this would make up the micro
service write the contracts the mapping
to lambdas the mapping from Lando's to
the database and the database itself is
also part of the micro service right
because in a micro services worlds the
micro service owns the data store right
owns a database nobody else is allowed
to touch it
well if you must for read-only maybe but
not for writing or updating data to it
alright so this would be a micro service
now if I would try and model this in
code it will probably mean that I would
have for projects in Eclipse
that all define like a single micro
service right and then I need to deploy
for lambdas into the clouds need to
define triggers for them need to set up
a database and configure it so that's a
lot of work and since it's all
sequential stuff that I need to do right
this will break about each and every
rule around micro services if there are
any rules in a microbial tactually so it
will be really hard to have like a
situation where I would say well I'm
pretty sure everything is in order now
so if I'm updating the micro servers or
if I'm rolling it out for the first time
I need to make sure that everything is
uploaded configured wired whatever right
so this is this is hard
if not undoable if I have to deploy
separate lambda functions so that would
be well waste of your time now if I was
about to speak at every conference in
the world I would probably make up a
title like this right so I want to go
and do I want to develop zero observable
as micro services running in the clouds
right that would be a really cool title
that's almost fully bingo
compliant if I have this using AI and
machine learning now I'm 100%
being a compliant right and I can make
up a talk like this with lambda as in
all of the other functionality that
amazon offers so let's try and see if we
can make this reality well apart from
the AI in machine learning
stuff because I go to the University
this afternoon about am she learning and
then I can edit it alright so for this
to work let's meet the little scroll
over here
he's called Sam and Sam is what Amazon
calls their service application model
and what this basically is is it's like
a DSL domain-specific language to do
surface composition so amazon reckons
that well just deploying a single lambda
into the clouds wouldn't really make a
difference well hello world is nice
converting thumbnails is nice but that's
about it right so if you want to do
something useful you probably have a
bunch of services and a composition
between those services and some other
stuff as well so databases message
queues email maybe just generic compute
GPUs whatever you need in order for your
application to function so they launched
Sam and they say it's a semi standard
day as a whole which means they're the
only one that actually using this right
and hopefully this will be better in
maybe a few months few years when other
service implementations start to do
something similar and so basically what
it is it's like a description file which
describes all of the services and all
the resources that your application
actually uses and in practice this is
like an extension to AWS CloudFormation
and CloudFormation is a way to create
templates in which we describe oh I need
to launch five servers of type
extra-large I need to configure this
database etcetera etcetera right so it's
an extension to cloud formation
especially for service implementations
so we use cloud formation underneath so
with transformation I can create
so-called templates which contain all of
my resources and then I can deploy such
templates and then they become stacks
and then I can also do managed updates
or manage the least of those stacks so
the cool thing is if I deploy like five
servers and three databases right then I
can also say under Blois and then it
will ultimately under ploy all of those
resources so I don't have to
individually and deploy them and the
cool thing about cloud formation is that
it figures out the exact order and we
should do things right should I deploy
the lambda first
should I create a database first should
I create the API gateway first right
we'll just leave that up to cloud
formation so we're not bothered with the
exact ordering of things
and then when it becomes available it
makes everything available at the same
time so we're in a consistent state now
this calls for demo so let's go back to
eclipse once more that's close the ugly
code from the previous example and let's
go to this project I've called it to do
corrupt projects so in this case I have
like a typical to do servers that
everybody builds right and then in order
to do crud on to do I need both
something of a model so I need like I
have like a to-do item in this case the
to-do item is like a POJO with an
annotation with a couple annotations
actually that could map this POJO to
like a DynamoDB table and this is well
if you know JPA then this looks familiar
right so it's just mapping of a POJO to
a table nothing special and then if you
look at my collection of functions in
this package you see I have functions to
create an item to delete an item to read
all items to read a single item and then
do an update so basically there's like
five lambdas in here now if I would
trade each of them in a separate project
I would have five projects would have to
do five deployments five times
configuration etc but now I'm using Sam
so I open up the surplice template file
place a logo and using this template I
now have a description language in which
I can describe all of the resources that
I will be using for my microservice
projects right so it's versions but the
version is serviced at 2016 10:31
interesting version scheme and then I
have a bunch of parameters well you
could say they're like global variables
just like you see with ant or maven
right so a couple of parameters which I
can configure later on so for example I
want to I have a dynamo DB table and
then I can configure the name for the
table in this case it's gonna be to do
right then I need to set something about
weight capacity write capacity this is
some
a configuration that dynamo takes I will
not bore you with that and then there's
a bunch of resources now the resources
for this project are of course a dynamo
DB table I don't need to have the to do
table so I set up the table and since
this is all schema-less the only did a
description that I give here is actually
the fields that holds the primary key
for this table so of the to do table i
only describe one field which holds the
primary key for every entry and then i
pass on the read capacity write capacity
in the table name using Refs
over here and they refer to these
properties of so first resource is the
dynamodb table so now i've described
that i can scroll down and then the
second resource that we'll see is called
create item and this is of type surplus
function so this is a lambda function in
this case so then I can set all sorts of
configuration so a function name the
handler name with this case is just the
class name and then it figures out what
the actual handler implementation
function is again sir the description I
can set the memory size the time outs
after which it will be cut off I can set
the role in this case all of the roles
within I am are uniquely identifiable
using this versing scheme all right so I
can just point it to a fixed role I can
also make this role a reference so I can
set it up in the properties later on and
then I can also pass environment
variables to my function so in this case
I'm using the name of dynamodb tail as
an environment variable so as soon as
the function launches it will figure out
the name from the environment variable
which also is a ref and then it knows
what table to talk to then for this
function you see I have events and so
the events are triggers so I define the
trigger for this function on the fly or
in this case the event type is of type
API which will make it an API gateway
the
and now I said well I define a path
slash to dues and then I method post so
if anybody does a boast on slash to
deuce that will trigger this create
function make sense right
I'll scroll down then there's the third
resource in this case it's read item now
read item is a little bit boring the
interesting because you've already seen
the create item the interesting part
about this is actually the definition of
the API because it took me about two
days to figure this out and that's well
maybe tell you something about me but it
also tells you something about the state
of the documentation right which is
horrible right so this is just stuff
that you have to figure out from Stack
Overflow or other people who are really
annoyed that this isn't working out of
the box so yeah in terms of
documentation they can really do a
better job what I'm showing it to you
now so this is how you can pass a
resource ID but basically it's a get
operation so it works the same so I'll
scroll down to another one read all
items and then I'm scrolling down to
this one because it has two events so
during the break I had someone coming up
to me and say well can I do multiple
triggers for the same lambda function
and the answer is yes so in this case I
trigger an API get very configuration so
a gets on slash to deuce will give me
all of the to deuce in the database but
I also a trigger and using a schedule so
every one minute I will basically
trigger this function to give me back
all the to dues in the database just to
show you that you can have multiple
triggers on the same lambda function
right and then there's an update there's
a delete and that's about it so now I
have a description for my five lambda
functions I describe the database which
it needs I described the API gateway
configuration and I also described a
trigger that will every now and then
list the contents of the database right
so
this is about to look like a real
microservice because now I have
everything configured as a single
deployment so the next thing which I can
do then is and this will take a little
bit of time is actually deploy this so I
say on my project I will I say Amazon
Web Services deploy service projects
once again it's a little bit
configuration so I pointed to the
correct region I still run everything in
islands I pointed to the bucket in which
it will upload the zip file containing
all of the sources all of the
implementation well before I do this
maybe I should show you a little bit
code now I'll show it when it's
uploading so then I have to give it a
name so let's call it the to do micro
service all right let's press Next then
I can override the parameters like the
global variables which I showed you in
the in the same file so I'll leave that
to the default ones and then I press
finish now we'll start uploading this
this is a pretty big deployment I think
is like 65 megabytes so depending on the
Wi-Fi speed it might take a little bit
so I'll just run it in the background
and I'll show you a bit of
implementation so for example if I go to
the create item implementation so first
off in the handle requests you see that
I'm getting a gateway request as input
and the reason I'm now using a gateway
request instead of a to-do item being
mapped adjacent is because I want more
fine-grained control over the either the
operation or the return value or
whatever so in this way using a gateway
request I map this to operation of the
API gateway and then I'm figuring out
some configuration so I want to know
what the table name and the region is so
if they are supplied in terms of
environment properties I will use the
environment properties if they're not
I'll set them to default values then the
interesting part is actually here where
I use the dynamodb client builder to
actually create me an IP I for Amazon
dynamodb and then I'm gonna use a mapper
which is able to do some mapping between
the objects and database table and since
I'm getting the gateway requests so I'm
basically getting the raw JSON now I
need to do a little bit of magic in
order to map that using Jackson here so
I get the incoming body and I'll map
that to a real object a Java objects
then I set the ID of the object and then
a save it using the mapper and then I'll
convert it back to Jason again with the
ID so I can return it as a response of
my create method here so I create a new
gateway response give it a 200 and then
I pass in the jason of the newly created
item all right so now the other crud
functions are actually pretty similar so
let's see how it's doing it's still the
plan okay there we go so a great timing
so when it's done uploading everything
into the clouds you'll see that it
triggers a an overview screen here which
will actually show me CloudFormation in
action so Amazon is now interpreting my
Sam file and it will then start to
create all the required resources so it
creates a database
it creates the triggers it creates the
API gateway and it figures out the exact
order in how to do things it also
figures out the new IDs for all of the
services based on either my description
or on some default values now still says
creating progress so we have to wait a
little bit before this is done question
okay so the question is how is the how
is the actual function implementation
linked to the SEM file configuration so
if I go back to a definition of a
function so for example that create item
here right so it has a field called
handler which is create item and that's
the class name over here so using Sam I
link him like this I could also supply a
fully qualified class name here as well
okay so let's go back to the tree
overview screen it still says creating
progress once again it's the cloud right
so sometimes you need to help it a
little bit access complete all right so
now if I switch to the left console
again let me switch to cloud formation
just for a second let's refresh it says
complete so now I have a cloud formation
stack rolled out and this stack has a
description for all the resources so
what I can do is I can say well for this
stack delete everything not going to do
that now but the delete everything and
then it will delete my database it will
delete my five microservices etc so I
have a little bit of more fine-grained
control of everything and I can create a
composition out of it otherwise for
example when I go back to my lambda
management console and I go back to my
function dashboard we now see that
there's a bunch of extra functions and
this list will grow and grow and grow
and this is a flat list so if you have
like multiple teams creating functions
and you have like a couple hundred
functions this will be mess nobody has
the overview of what will actually
happen just like database triggers right
you know they're there you think they
know what they're doing and then
something unexpected happens and you're
running around figuring it out so using
this concept of the stack I now have a
hold of these five individual functions
and I can under ploy them update them to
lead them whatever so let's go to one in
this case let's go to the create to-do
item function like
show you the trigger for it and it has
the API gateway trigger and then using
this I can navigate to the API gateway
and it shows you the API for this so it
has a slash to Deus exposed with a get
and a post operation mapped onto it and
then it has a slash to do slash resource
ID with a delete get and put on it so I
can get an individual one I can delete
an individual one I can have data
individual one so let's start with the
post so in this case I can say let's
open the test screen for this one and
let's try and insert an individual to-do
item and do I have one here here it is
all right so I'm just posting it to the
generic endpoints slice to do is post
and I'm pasting in a request body search
Manila typing and I press test now we
gotta have a little bit of patience
because apparently the DynamoDB and a
builder takes a lot of time so the first
time actually run this it can take up to
20 seconds for this to actually
initialize and this is it a little bit
of that's annoying because if this was
supposed to be the backing function for
mobile application I think your user has
already deleted the application by now
so now that it's warmed up if I run it
again it will be much much faster but it
will actually take it has a 21 21 and a
half second latency right so this is a
lot so there's tricks to dealing with
this by using static helper objects
which will be loaded when your code
loads this will prevent you from
creating the DynamoDB client API each
and every time your function handler
loads so that's that's more advanced
stuff but for now we just pay this
penalty alright so it gets something
back which is an ID name and description
so apparently there's something inserted
so let's open the dynamodb wizard here
let's refresh this and it should have a
table allows it to do table and then I
can look for item so now it also has an
item and there we have it again alright
so I can insert some more so I can go to
the console and do a create item with
curl but before I do this I need to
figure out the name of the API which
I've just exposed right so it gets a
temporary so I figure out the API name
and I can copy this skip it
and let's try an insert you see it's
much faster now so now I have two items
and but we had a lot of service which
was actually listing them every once in
a while so if I go back to the web
console lamda management dashboard go to
functions and there was this read all
to-do items function which can be
triggered by two separate events it can
either be triggered by a get call on the
endpoints or it has a cloud watch attend
events attach to it with a rate of 1
minute so every minute it will list the
contents of the database so let's see if
it actually works by going to the logs
and you see that every minute there's
little bit of logging so at first I
found zero items in a file 1 and then if
you wait long enough for another run it
will probably find two items well in
this case so the question is the
function doesn't the function return
anything well it does return anything
but in this case I'm interested in just
the logging the how many items it's
found that is just for demo purposes but
if I call it from the command line if I
just do a curl on the slash to do all
right then it will return us all of the
items in JSON format all right so what
have I proven now well I have proven how
to actually do micro services using this
if the operation that I'm trying to
model consists of multiple functions so
instead of deploying each and every
function you know myself and making sure
everything is consistence
once it is in operation using Sam and
surface composition this actually the
way to do it
now still if I switch back to the lambda
console right still the list goes on and
on right so if this is your pair of eyes
on to your collection of functions then
it will get a hairy very quickly so just
as with microservices the trick is not
in create
microservices the trick is in
transforming your organization so your
organization should be compatible with
this way of development so you should
have teams which are fully responsible
for trading and running the functioning
in production now if there's like a list
of a hundred functions right but I have
separate teams who now eat everything
about their functions and whether
they're operating normally right then
you you still have everything under
control but if this is your pair of eyes
on a list of functions then it will be
messy pretty quickly okay let's switch
back to slides so I think by now we've
seen how not to do it we've seen a
pretty of a couple of pretty useful
examples but then people are also doing
other stuff and with lambdas so one of
the use cases that you see a lot is that
people use lambdas to actually build
custom CI CD pipelines so for example if
they are all into the Amazon Cloud or
some other clap of provider they can
also use Amazon to to you to store their
version control right after you are to
use version control by Amazon so they
have a wrong gate implementation called
cult commit and then you can just supply
a commit hook and say well if somebody
commits something into the version
control system then that should trigger
a lambda and this lambda can then start
off a whole build test deploy process
right and there are several ways to do
it you can do it completely with lambdas
or you can do it using a jenkins image
that you probably run on on ec2 instance
so you just have your Jenkins server
yes that's like a normal server so we
you take effort you maintain it you run
updates etc etc but then use the lambda
to trigger a build or whatever or if you
don't want to have the Jenkins image
then you build everything yourself in a
build pipeline right so it's interesting
stuff there's a documented example I
think it was by Expedia who
gave a presentation at last year's
reinvent you can actually look it up I
think I have a link to it later on in
the presentation and they say they built
their built pipeline entirely on Amazon
and they have calculated that every time
somebody does a code commit and it
triggers a C ICD builds that it cost
them about $1 right so for every bill
that they deploy that they deploy into
production it will cost them $1.00
that's a pretty interesting use case
right you can sell better management
probably a lot cheaper than having your
own data center supporting this then
there's other cases that people use this
for and I already mentioned that we can
interact with services like Amazon Lex
which is voice and text recognition all
right so you can use this technology to
either build vaults or to do force
control and particularly force controls
interesting rights because this way you
can get lambdas into your living room so
that's cream for demo actually so in
this scenario we have a device in this
case the Amazon echo which is Amazon's
implementation of a home assistant
there's multiple devices
there's the echo dot which you see on
the picture over here there's the the
old echo which I have on the desk over
here tramp lavalla nicely and there's
now also new echo devices which also
have video displays right so they're
constantly coming up with new features
for the device and then you can actually
talk to the device send in a voice
command which would then be interpreted
using Amazon's lacks in the backend and
then using the so-called Electra skills
kit I can translate the voice commands
into something triggering my lambda
function and this actually pretty cool
because once you can trigger custom code
you can do about everything with voice
commands so as we wake them up let's go
back to eclipse
let's close everything
so for this I have created something
which is looks a little bit different
from the handlers which I've shown you
earlier so the principle is still the
same so we have a handler which
basically takes input and then supplies
you with output in this case this handle
is a little bit different because it is
a little bit on a higher level so what
this does is it's it extends a speech
slit request stream handler so it's a
little bit different beast from the
function that we've seen so far and what
this piece of code actually does is it
registers the application ID of the
application for the echo device that
I'll show you in in a minute it
registers that ID to this lambda so it
knows that when somebody triggers that
application that is to actually trigger
this function and then in the collector
over here I just launched a new hello
world speech slot and a pass in the
application ID ID and that's about it
so now I just basically instantiate a
class a speech slots my speech let the
hello world Switzerland and whoops and
that actually does the trick for me so
in the hello world speech slits this
thing is actually a bit like a servlet
basically well it actually is a surface
because it's built on the surface IP I
so the team building these skills for
the echo device they were separate team
from the lambda team and this is how
it's called converting and these days so
they built everything on top of the
surface API so a speech slit is
basically a servlet with some added
value so we see similar methods to I do
get Duboce but in this case we see a own
session started a on launched a on
intent at cetera et cetera right so it's
it's a similar interaction model that we
are used to in programming servlets now
I'll get back to this code in a bit but
I want to go to the to the other side of
things so in order to build skills for
your echo device you gotta you could you
don't have to not you not only have to
have
a regular Amazon developer account but
you also have gotta have a developer
accounts that supports building skills
right it's free right so you can just
sign up for it and then you sign into
the developer console and you can start
building skills so in this case I want
to go with the Alexa skills kit so
Alexis to wake word for the device or
try to avoid it a little bit and I'm so
let's get started and now we see that
there's a hello world skill in here so I
can open that up and I can configure the
skill so this is just configuration you
actually what the skills actually doing
is in the Java code and so for this I
need to setup some skill configuration
so and then I get appointed a
application ID for this skill which are
then copied into the Java code so this
is how I hope the two together then I
have to give the skill and name so call
it hello world and I have to give it an
invocation name so when I issue a voice
command this is the invocation name
which I will use later on so I just
called that demo then I go to the next
screen and then what I should configure
is so called intense so a skill has a
couple of pieces of functionality and a
piece of functionality of skills called
intent and you can have one intent /
skills in this case I have a very simple
skill which just has the hello world
intense so it knows how to say hello
world but if the skills more elaborate
it can have more in turmoil more ways of
interaction so then it usually has a
whole bunch of intense right then
depending on the intent I can enter a
session with it and then I can issue
with several voice commands so you can
build a game for example so you say
something to the device the device asks
you a question you answer and you go to
the next question etc so you can build
up a session just like with HTTP clients
the next thing that I should configure
is so-called utterances so utterances
are basically example commands that I
can issue to the device so it knows how
to sew from
the command I give to the device it
knows which intends to invoke so I can
give a couple of examples of how we can
interact with the device and then the
skill is smart enough that if somebody
says something similar to this it still
knows which intends to him invoke that's
when I have only one intent so if I
issue one of these commands it will
invoke the hello world intents which
will then invoke the code running in the
lambda so well then there's more
configuration which I can do and this is
this is advanced stuff and then I can go
to a test screen which is also
interesting so I can I can enter some of
the utterances I have in minds and then
I can test whether it actually works I
will just do a live test later on and if
I'm keen on publishing this skill so
other people can install it on their
echo device then I can go through a
whole submission process so I need to
supply a documentation for written
instructions how to work with it
and then I can submit it for
verification and if it's verified then
it's going to be published in the store
that's actually cool and I can even earn
some money with it all right so
basically what this does is just
triggering my lambda function that's
actually the only thing which which
comes from this and it defines the
interaction model so what kind of
commands can you give to this lambda so
then if I go to the lambda console I
have my hello world's skill over here
all right
it has a trigger in the form of the
skill skill and in order to configure
this you need to go to the developer
portal that's the the thing that I just
showed you all right so that's how it's
how everything is hooked together so
then coming back to the code now when I
actually run this I just issue a voice
command and then the device will
actually try and respond based if it
whether it can map the utterance to the
intent so in this case I hope it works
and stand close so you can hear the
response
true to Mike I say Alexa asked demo to
say hi hello all I hope you are doing
well and that you are having a blast at
Burt's serverless deep dive talk okay so
that works so Begley this is my hello
world message thank you
alright so in this case there is like a
get hello response method implemented
here where you can just well in this
case just have like a simple string with
text this is the most basic way of
putting in text if you want specific
pronunciation of certain words you can
did that they have like a special diesel
language to put stress on certain
syllables or two or two up the base of
the sentence or two to have explicit
bosses somewhere in this in a sentence
so you can configure all of this but
what I do here I just have a string I
convert it in a to a so called a simple
card and then I issue that card as
output in this case it's very basic
hello real thing but you can imagine
with when I activate the application in
this case the application is called demo
when I activate the application a
session starts so while the session is
active I can have multiple interactions
with the device so this is how you
create a game for example and there's
many of those skills available so they
have like a magic door skill where you
say oh I see magic door behind the magic
door that's like if you give a left you
see this if you go right you see that
right what do you want to do and so this
this goes on forever and ever and ever
so this is how you build actually your
session with the device she's asking you
a question and then you reply back
actually very interesting stuff and it
took a little bit because it needed to
launch the speech slit right so that was
in vogue for the first time so that
takes a little bit of time and then when
I say the wake word right it starts
recording or actually it's always
recording right but it then it records
the command and it's
sense that their commands to Amazon
which then translates it into something
it's gonna understand like adjacent
package with the actual command tenets
which will then trigger the Alexa skill
so that's that's why the little delay
and then you can hook it up to well the
lights at home or or whatever I did
that's what I do to drive my wife crazy
yet at home right so I hook it up to the
lights and then so you can give it like
a voice command go to turn the lights on
and off that's just basic stuff but
someone the internet I found someone who
wrote like a Phillips who we bridge
emulator in Java right so this means I
can hook the device up to my bridge
emulator written in Java and now I just
get a command into that emulator which I
can then use to call whatever I like
right so I can use that interface right
to do whatever I like in the home just
lights on lights off but also do other
things with the television or whatever
right so you can just turn devices on
and off and that's that's really cool
stuff because I don't like the services
where somebody from the other side of
the Internet is actually able to access
my devices right from the outside in
sorry I don't want to open up my
firewall at all so with this it just
sends the voice commands it gets the
command back and then the bearing
between the lights the hui bridge and
the device is actually local right so
nobody from the outside can actually
turn my lights on and off right but
that's why I use the hue bridge in
between
alright so a little deviation that there
this is how we do a speech and handle
voice commands using lambdas actually
that was I trying to what was I was
trying to demonstrate all right now like
I mentioned London's can be monetized
this way as well right so there's like a
like an app store for lambda so to speak
or an app store for skills so if you
have to impress some inspiration after
this demo well write your skill write
your game whatever it's a nice way of
making someone you know on the side
probably all right now with this I think
it's I think we're
undoing the hello world style demos
let's talk a little bit about you know
lamb dance in the real world right so
beyond the hello world messages I
mentioned Expedia
earlier I mentioned them because there's
like a really good presentation from
last year's reinvent conference where
they actually explaining what they are
doing with this kind of stuff as you can
see from the numbers this goes way
beyond hello world right so what Expedia
is doing well basically I hope you know
what Expedia are they are like a they
have like a Google search field where
you can either type in the name of a
hotel the name of a city airports
whatever and then they come up with
suggestions for hotels flights rentals
whatever and so as you can see from the
numbers part of what is running behind
their search box is now running with
lambdas and they've also fully automated
their CI CD build pipeline using lambdas
so they run over 2 billion computations
using lambdas per month that's quite
some compute cycles I can say and
because it comes down to over 200k hours
per month that they're actually burning
using this kind of technology right
that's a lot of compute cycles it's a
big mainframe and actually if you're
down at the number of the bottom of the
slides they are paying only $550 for
this per month
right so they used to have like half a
data center or more to run this
functionality and now using the
technology that I've showed you right
they can bring the build down to about
$500 per month I mean that's really
interesting business case and probably
well since they are doing the talks at
the Amazons conference they're probably
a little bit of discounts here and there
you never know right but still this is
just this is huge in cost savings
compared to how we do it the
old-fashioned way
all right so hopefully this just engels
your mind to think differently about you
know certain implementations that you
are using
I'm not saying once again this is a
hammer and everything is a nail so you
start do started with everything with
lambdas they can be downsides to it as
as well we'll get to that but you see
that I mean this
well beyond hello world and this is a
really interesting business case if
you're interested in the in the entire
story just do a quick google for the
link on the slides if you do if you look
for it as VR 306 at AWS reinvent you'll
find the entire story alright then a
bunch of pointers when you start
developing lenders beyond the hello
world scenario so first off logging I
think I already mentioned it but logging
and metrics are a universal right right
so whatever you do as long as it writes
something to standard out or you use a
logger it will end up in a centralized
locking implementation which will then
be picked up by the locking
implementation of your cloud provider in
Amazon's case that's going to be cloud
watch through the context API that you
have as an input parameter for your
handler you have access to a logger
object basically lock for J is running
underneath so you can just supply a lock
for j-dog properties file and you can
then you can configure it what's being
locked you can also do simple system out
print line statements but in this case
you are burning iOS on call so this is
probably more expensive in terms of
runtime right so you should be careful
with that then a few things about
testing so I think it was the first
example where I already showed you the
unit test which will be generated by the
wizard that is part of of the Eclipse
tooling yeah so for simple lambdas a
unit test is maybe enough right if
they're just a little piece of
functionality so in my case with the
lease calculator right there just a
little bit of you know date and time
wizard read going on all right that's
probably easy to unit test so you just
write a couple unit tests for that and
that's about it you can just test them
offline and since everything is
stateless that just makes it easy and if
you have some dependencies and you can
just mock them but as soon as the
lambdas become more interesting for
example when you think of my demo with
the s3 insert where somebody just
uploads an image and then that will
trigger the
right this requires to interact with
other services now for this you if you
would want to test that offline right
you would need to have an implementation
of those services locally otherwise you
can't test them right that's a bit of an
issue because Amazon is not really keen
on offering you a localized version of
their cloud which you can run on your
laptop right so basically compared to
other cloud providers maybe they're
really lagging behind on this one all
right so other cloud providers have a
well stripped down local version of
parts of their services available for
you offline so you can easily create
unit tests or integration tests and that
run offline but Amazon just has a few
implementations of that so for some of
their data stores there is like a local
mock of the data store so you can run
like a local dynamo or a mini version of
s3 but not for all of their services so
this is really something that they
should work on for the next couple
months the next couple years otherwise
this is pretty much unusable and to test
offline unless you are willing to do
what the big ballers are doing and they
run tests in production anyway right so
you can just deploy all your lambdas to
the clouds
but then using the API gateway for
example you just give them different
endpoints so the API gateway supports
staging so you can have like a prod
environment and a definite iron mint and
then you've run your tests in the dev
environment right which is not
accessible to your normal customers for
example if you do that then you will
have a solution for integration testing
in the clouds but then there's like a
little caveat which is that there's a
maximum number of a thousand parallel
running lambdas which is like a default
setting right so you might run into this
so if you have couple of popular lambdas
and you do testing right they all add up
so all of the lambdas running
concurrently add up to this 1000 limit
so you might hit that limit it's really
easy to get rid of the limit you just
email the lender support team and you
give them a little bit of a description
why you want the limit raised and then
they raise it for you
you might run into it and then what you
will see is actually that the next line
would just be cut off right so it's
really funny in the locks at first but
then you figure out it is it's this
limit configuration yeah well you've
seen me use environment variables in the
micro surface example right I used
environment variables to configure my
lambdas I don't do hard coding of
configuration please so using
environment variables you can configure
your lambdas using the Sam templates you
can have like a dummy value in the
template and then when somebody is
actually deploying your stack interview
into production they can actually
replace the variable values with the
production values so if you're passing
in username passwords etc that's the way
to do it but that's just no
configuration for the lambdas itself
then there's a whole bunch of other
things you have to configure especially
if you have lambdas using other services
by Amazon right then then the roles come
into play so your lambda gotta have a
role that has access to the database
that you're using to the logging a
solution that you're using etc so you
got to create those roles and
permissions this can also be done using
property files and also using the same
templates or using the transformation
templates so you can fully automate it
but it's a bunch of extra work we
already talked about the API gateway
that might be cumbersome to configure
while using the same template it's a
little bit easier but if you really want
to go all the way I highly encourage you
to describe your API as swagger
documents right the swagger contracts
and then upload those contracts so from
the same configuration you can also
point to a file which holds the swagger
contracts right then you can upload that
into the API gateway and like I said
before the online documentation for this
kind of things mostly sucks I mean you
really got to search for examples on
blog posts or there are some examples
sometimes it's in Python sometimes
in Java sometimes it's it's in nodejs
and then you have to figure out how to
translate that particular implementation
to another language so this took me a
lot of time to figure out in some cases
especially for the API gateway so
hopefully a documentation will get
better in the future then when it comes
to deployments there's a couple options
you saw me use the IDE plug-in a couple
times to do the deployments and
everything that the IDE a plugin can do
is basically also available in the CLI
and more so to see lives the more most
elaborate one so the command-line
interface you can just quickly install
that on all platforms right and then
using either jason or some or a llamo
configuration you can actually create
deployment packages you can do the
actual deployments you can set up the
staging you can just pass in each and
every parameter into the see a line and
then of course you also have the web
console but the web console is mostly
for demos right you especially with
lambdas and with clout watch and with
api gateway as well it just gives you
just a few percent of functionality of
what the actual service is capable of so
you can't do everything with the depth
console it's just for demos for quickly
setting things up it's easy to use the
web console if you want to do more
elaborate things I would advise to use
the CLI then in terms of CI CD we talked
a little bit about that earlier on but
most people do is they just run Jenkins
on an easy-to server right so they just
fire up infrastructure as a service
thingy installed jenkins on it and then
use that as their CI CD server and but
there's other ways of doing it there's a
lambda plugin for maven and you can just
use lambdas to build your own custom
pipeline like I mentioned before right
so you just hook it up to either github
or code commit and whenever somebody
does it commit you just fire off your
own build pipeline now you can't
directly trigger lambdas
lambdas right so you can't have one
lambda calling into another lambda so
then it must be something in between so
if you wanna divide the functionality of
the pipeline over different lambdas
which would be a good idea probably then
you must use something in between so for
instance you can use this simple
notification service by Amazon which is
a quick message queueing implementation
and so when the first lambda finishes it
just writes an event to SNS which will
then be picked up by another lambda
right so this is the way to do it so
it's event based interaction
you don't call into other lenders
directly or you just insert a file in
the database and you have a trigger to
find on on the insert in terms of upload
size as I find this particularly
frustrating if you do nothing and you
generate a new project they give you the
entire Java SDK plus third party lips
which will come down to about 63
megabytes of zip file now I have a tiny
internet connection at home
unfortunately so sometimes it took me up
to seven or eight minutes just to upload
a changed function into the cloud and
that's it's boring and it takes away all
of the focus and attention that you
basically have right so make sure you
have a big pipeline if you want to
upload things and also really think
about your dependencies right because
not every lambda and need 63 megabytes
of dependencies if you do a very simple
one you might not even need one megabyte
of dependencies you can just do with the
Java libraries and it's just your piece
of code just a few kilobytes but as soon
as you start using other Amazon services
like s3 or dynamo or some of the other
services then you need the client
libraries for those by instead of adding
everything you can just just figure out
your exact set of dependencies and then
manually add them to your pom file so
you have the minimal set of dependencies
now if you build Java applications you
have to take care of this yourself if
you if you choose node for example and
they already have a bunch of no
dependencies which are available
for the node runtime so you don't have
to include them in your implementation
right they're already there so they're
provided dependencies you have to figure
that out though and there's like
versioning going on because what if they
change those kind of libraries willed
them with my Lemnos then break answer is
yes
so there's downsides to those as well
but the upload size is far smaller than
Java services in this in this case and
well upload size means lots of classes
and if you start loading lots of classes
then it will also take longer for your
lambda to launch right so you pay the
price again then during the break I had
a couple people come down to me and ask
well what about lock-in right I mean you
talk about Amazon a lot right so in this
case we use all of their specific
features so and this just seems like a
whole big lock-in conspiracy right well
actually this there's a bunch of service
implementations out there and all of
them are proprietary implementation so
if you go to Google to go to Microsoft
if you go to Amazon they all offer you
different implementations with different
services different service levels and
also different api's so if you choose to
go this way you will choose lock-in
right so if you do the simple lease
calculator thingy
it's just Java API so there's no lock-in
just a POJO
you can deploy that as easily with
Google with Microsoft or with Amazon or
an open whisk but if you start to use
specific services like s3 or dynamo or
all of the other stuff that I use before
then you will start to hook into the
platform more and more and more and this
will lead to more lock it so yeah well
looking is your choice so it depends on
your business case whether you are
willing to pay that price right I don't
on the short term I don't see any
standardization going to happen right
now they are still heavily competing so
all the clouds vendors are heavily
competing in this space so they probably
have no well there's there's nothing in
it for them to standardize with in the
end as
all of the stacks of the different cloud
providers are starting to look alike
they will probably want to have some
standard stuff going on so then maybe we
will see more open source more
standardization and kicking in right for
for some of the stuff like the Sam
diesel like I showed you
Amazon has open source data but they're
still the only user of that project yeah
the other interesting thing that some of
them are doing for example if you look
at project FN which we will look on in a
minute or so then they have something
that if you have an existing lambda
function built with built with
JavaScript right then they can wrap that
function and then launch it in an event
server right so they do some handy
wrapping of services that you might have
created for other cloud providers but as
soon as those services step in to s3 or
or whatever then they don't have any
replacements for that so you need to
replace it anyway then terms of
performance well like we said JavaScript
and PHP are two of the runtime options
that amazon offers you their interpreter
on the on the go so they hardly infer
any startup penalty so if you want to
pay the minimum amounts right then you
should probably go with JavaScript but
then you have to take a shower each and
every time you're out were you write a
little bit of code if you're willing to
use a real language right then you paid
a penalty in terms of firing of the JVM
loading all the classes loading
dependencies right so yeah it's gonna be
a little bit more expensive now in terms
of expensive and expensive right is it
expensive in terms of just a couple
dollars per month right then it's
probably well you don't even think about
it but in some cases if you have
services which are invoked and just take
a couple milliseconds and you are built
for at least a hundred milliseconds then
you might come up with some scenarios
where using lambdas might actually turn
out to be more expensive than using a
pass
implementation right so before you start
building you should think about your
business case and you should think about
pricing now once again I don't work for
Amazon so I encourage you to check out
all of the pricing details in the
account in your accounts the explains to
you nicely and then you have the option
to create rules and triggers which will
cut off some services as soon as you go
over certain amount of threshold in
terms of dollars right out of scaling we
talked about that right the cool thing
about service is that you don't have to
think about scaling functions because it
happens automatically so as soon as new
users come in they start hitting your
functions then Amazon wild amenity skill
everything but once again here's a
thousand limits right so if you hit a
thousand limit $1,000 running at the
same time and that's the max amount of
scaling that you get well once more just
send the support team and an email and
they are happy to lift the limit for you
a little bit so you might say well all
the stuff that you've showed me up till
now is pretty much no low-level basic
stuff dealing with input in an output I
have to know all kind of specifics about
the run time well up to a certain limit
of course can we have more abstractions
right can we come up with something that
maybe is able to build functions
abstracted away from the underlying
cloud implementation and the answer is
well there's a couple of frameworks that
try exactly to do this so one of the
things that you should definitely check
out is a website called surf Alice calm
and servers dot-com basically is an
abstraction for creating functions in
about any language that you like and
then using some configuration templates
they know how to deploy those functions
to a whole bunch of cloud providers so
if you write something Java code for
example then you're able to deploy that
to Google IBM Microsoft and Amazon
the same time right so you have a choice
of where you want to deploy those
functions so they try to abstract
everything to a higher level so this is
pretty this is pretty interesting stuff
if you're into the JavaScript stuff then
they also encourage you to check out
cloudy ideas which is a very handy
command-line tool that integrates well
with the C light of the different cloud
vendors to actually deploy nodejs
projects to in this case Amazon so it
supports staging and versioning and
everything so it gives you a abstraction
so you don't have to work with either
the Eclipse plugin or you have to know
everything about the specifics of the
AWS command line interface but you can
just use the configuration templates
from Claudia J's in order to deploy and
they have a lot of defaults already
going on so this really helps if you
want to deploy micro services using
nodejs for example then you might be
enthusiastic by now you might not be
right good thing is that you're still
here though there's downsides to all of
this too right and this wouldn't be a
good presentation if we weren't talking
about downsides
so yes all this stuff is great but
everything that I've shown you is
heavily dependent on the cloud and in
this case also on public cloud offerings
and depending on employer that you work
for this might be a problem because you
might not be allowed to use those cloud
providers your employer might not like
Amazon or they might not like public
clouds in general so what can we do if
we are not allowed to run this in public
clouds right to view all forget about
this or are there other options well
there's a bunch of other options
actually first off if you like the idea
of having functions and controllers that
will trigger functions then you can just
use that as your programming framework
and there's a framework called funkotron
which is written by David Pollock who
you might know as the original author of
the lift framework for Scala so David is
now back doing java apparently
and he wrote the funkotron
implementation which is just a functions
controller style framework it's really
easy to develop with and so if you like
this then you can build your functions
the service way and then you can deploy
those functions onto containers which
you can then deploy into your Kuban at
each container scheduler etc so that
might be an option for you alright if
you like this but you have to run it on
premise then this might be an option
another option might be to use Apache
open risk open wisk is being used by IBM
and their public service offering but it
is based on the Apache open wisk open
source framework which you can just
download and run yourself on premise
right so open risk also takes docker
images as its runtime so you can
configure you know a scheduling
framework is able to use docker images
and then you write your functions deploy
them into docker images which you can
schedule using cuban IDs or whatever you
have right and this does not only power
IBM's implementation but also read ads
implementation of functions they used to
have their own implementation but I
think they replace that recently with a
with open wisk so open risk is
definitely worth having a look at and
then there's a third option which is FN
which you already talked about in the
intro when I talk to you about
interesting implementations so FN was
announced recently it's an open source
project it's run by the guys that used
to write the island functions
implementation for ayran io they're now
I think they're now part of Oracle and
oracle decided to come up with another
service implementation called FN I think
somebody at the marketing department
wasn't really paying attention because
now you have F and Java right that's
actually cool or you have F in back-end
as a service that's worse right okay so
so why another framework right because
Oracle says well there's a lot of
service offerings out there but only
some of them are open source like open
Wisc right and the other ones like lamda
and also the ones by Microsoft who etc
and they're not open source or not
entirely open source all right so let's
have an open source one so we can also
work on standards right so coming back
to the question of standards well this
is by open sourcing stuff that's an
attempt to work on a commonalities and
also on standards the other thing is
that there's poor Java support in some
of the offerings out there well that's
true Google doesn't support Java for
functions well Microsoft now does
support Java Amazon supports Java right
but there's limited Java support that's
called that way and there's a poor
development experience in terms of
there's low fidelity between death and
prot which means it's hard to deal with
stuff offline and online that's what
they trying to solve so they come up
with a pure Java implementation but they
support a lot of other environments as
well and the interesting thing though is
whether this still can be seen as a
service approach so coming back to my
service manifesto and I actually started
with if you think about this and you are
now no longer just responsible for
writing functions but also for mapping
functions to docker images and then
running docker images right
it no longer complies with everything in
the service manifesto so basically what
we're seeing out here is that there's
there's like a distinction in the the
part of the framework which is targeted
at developers will just write functional
pieces of code and there's a part of the
solution which is targeted targeted at
like an ops team which basically runs
the infrastructure for your development
teams to work on right so with with
lambda for example Amazon is responsible
for everything right you just supply
your function code and that's it but
with solutions like open risk and FN if
you run them on premise right then you
are no longer attached to a public cloud
right so you have everything on premise
but then you should distinguish between
developers you
using the framework and supplying
function code and a infrastructure team
or an ops team which basically runs the
infrastructure underneath because
underneath this there's docker images
there's cube Annette is probably running
and if you are as a developer become
responsible for running and scheduling
containers as well then it's no longer
service because it's violates about
every bullet of the service manifesto
right so that's how you should think
about this
so yes it's still service from a
development perspective but then there's
a whole lot of ops involved as well but
probably that can be held by different
teams of people with different skill
sets all right so let's do a quick demo
of fnu just to give you a feel for how
it works
I think we have enough time for that so
for this and go to the command line and
what I did is I downloaded FN it's just
it's a docker image of the server so I
downloaded it and I actually started it
by typing in FN start and now I have a
local project defense server running
right so this is a local server which
pretty much acts like a container
scheduler so to speak then I have a
simple project which I've called hello
def Fox and if I list what's in there
there's just one function in there and
just you know for demo purposes I wrote
it didn't go so if I do a kind of this
function you see there's a very simple
hello world implementation written in go
right now in order to get this started I
say well let's do a f'n in it first
right I only concern on writing code
let's do FN in it first and when I do FN
in it it will try and detect the runtime
and I create a bit of configuration so
it created a Yamal file and if I get
that you see that it gives it a version
it gives an entry point and it
determined the runtime to be go right it
supports a whole lot of runtimes go is
just one of them
Java is another and there's many
anymore so now I have my function set up
and then I can actually run it to make
sure that I know the commands so this
case for example is f n run what I'm
doing right now is I will create a
docker image on the fly based on my
function the docker image contains the
run time for this function to run and
then it will basically invoke the
function so in this case as a result we
get the hello world message right so
this like a local test I can now locally
do without the docker image and then do
an isolated run of the function on my
laptop next thing I can do is I can
deploy this thing oops
I can deploy this thing now creates a
new docker image and then I will deploy
that oops
I haven't said okay before it does that
I need to make sure that it and that I
set my docker registry name because it
will immediately upload the thing to my
docker registry I think it's this one
try it again so it will push the image
into my docker registry can either be
the public docker registry or it can be
a local registry that I set up and then
it will hook this image up to the server
which I have running in the other window
so we'll attach that and then I also
have a user interface running for this
in the other browser as a UI now you can
see that there's a bunch of applications
available in the server and hello devoxx
is one of them so in this case and go to
the server - this route for this
application and then I can even invoke
the service so in this case I can just
run it and then it gives me D and result
back and I can also curl it so we have
an endpoint and so through the server we
now have an endpoint to this local
function now of course I'm running
everything in a very simple setup on my
laptop here but imagine this to be a
little bit of a bigger skill where you
supply a whole bunch of servers you run
cuban IDs on top of this right and then
using the event server you have like a
load balancer for your functions and
then you can do basically everything
that I've shown you before using Amazon
lambdas but now you rendering your own
infrastructure using similar technology
right and then a fan ads upon this by
also thinking about how to deal with
state full functions and also how to
orchestrate flows over a
and function so that there's there's a
whole bunch of interesting aspects
through this service implementation so
it's definitely worth checking out if
you have the time so going back to
slides for a bit now I think so far
everybody finds that there's some
coolness to this servlet thingy whether
you perceive it as database triggers or
as something more advanced right and I
think it's good that you understand that
there's a bunch of other drawbacks that
we haven't yet discussed so we talked a
little bit about vendor control and
lock-in right everything's basically
proprietary you do have some escapes
with some of the open source offerings
like a fan and open ways that I just
showed you but then low-key and
especially if you use other services are
still very much a choice which you can
either will go with or try to avoid
other things that you will quickly run
into if you start to use this on a
bigger skill is that there's no support
from multi-tenancy in service
implementations so this means that if
you want to use the same lambda function
over different customers right and you
have to come up with a solution for this
yourself this is not that hard of course
if you just pass in an ID somewhere you
can distinguish between different
customers or different clients but for
simple things like this which we have
solved many times before there is no
support yet right so this is something
to think about
then there are security concerns in
terms of if instead of writing one
application we are now writing lots of
separate functions and we expose them to
the outside world and what we're
basically doing is we are opening up the
attack surface right we are increasing
the attack surface now of course there's
always something in-between so in this
case that might be an API gateway in
between which you can then secure I
didn't demo that but you can of course
secure the API as well but still you
would just have a broader attack surface
so you should just be aware of that
then if you've written code now that is
highly optimized for a specific server
instance for your particular cloud
provider right or it does lots of time
intensive calculations then lambdas
might not be the ideal choice because
you have no control over the underlying
runtime which is saw earlier there's a
bunch of startup issues as well so if I
use expensive client IP is right then
they take like 10 or 20 seconds just to
instantiate right so that's that might
be a problem now if you have highly
optimized code that must run on a
particular set of underlying hardware
then lambdas are probably not a good
choice what you could do in that case is
if you have very intensive calculations
going on for example is that you just
use a lambda to boot up an Amazon GPU
instance or an Excel instance for
example easy to Excel instance then run
the piece of code on it and then as soon
as you're done you just kill the
instance right so you still have this
idea of paying while you go but you have
the lambda actually managing the other
cloud resources so that's probably a
good implementation of of lambda but
coding against the underlying mechanism
trying to optimize against the
underlying implementation of lambda just
to get the most out of it that's
probably and not a good idea instead
that's not a good idea then your
execution time is limited I mostly
configure just a couple seconds from my
lambda to run that's basically cost
control like I mentioned before but
there's also a hard limit on a maximum
hard limit so the code I think it's 15
minutes all right so that's the longest
run time for a lambda so after 15
minutes it will be killed probably this
is worth sending an email to the support
team again maybe you can up it a little
bit but eventually there will be in
other limits so then maybe 20 or 25
minutes right so there's limits to the
amount of time for running a single
lambda so if
if the runtime is critical in the case
you might have to think about other
options we talked about performance and
startup latency before so I'm not going
to repeat that here talked about testing
as well and we haven't talked about
discovery yet the only way we discovered
lambdas so far was through the web
console right so we open up a lender
dashboard and we saw this flat list of
lambdas now there's no ways where
lambdas can directly discover other
lambdas all right so we don't have a
uddi for lambdas yet probably some
vendor will probably come up with that
eventually but you have different other
options so you can of course go outside
in so you can do HTTP calls into the API
gateway or you can just chain them
together using an eventing mechanism but
this is brittle right because you're not
entirely sure lenders there whether it's
deployed or not so if you want to be
sure about that
then they have to become part of the
same application model right so you use
salmon or to make sure that all of the
lambdas which you are dependent on are
then part of the same stack and this
might then again be brittle or might be
hard to release but because then you
just couple each and every lambda to
each and every other lambda in the
system that's probably not the idea
all right so lambdas discovering and
calling lambdas directly that's not
really supported and if you have a use
case like that you should probably
rethink the use case all right with that
we're also the time I think we have like
10 minutes left or so did you want to do
a quick summary I think in general
servlet is a really interesting paradigm
which is now being embraced by most of
the major club players right and
everyone else is creating functions and
frameworks and whatever implementations
for it too so yeah this is heavily being
picked up it's going straight to the
curve to the top of the hype cycle right
the interesting idea about this is that
we are loosening the concept of an
application and we go for functions
instead and these functions can be
triggered using events there
stateless and transient and you have no
clue what the underlying sandbox is
actually doing right the cool thing
about this is that it's infinitely
scalable well at least up until a
thousand right where the scaling is
being taken care of by the cloud
provider not by you so this saves you a
lot of worries and this also enables
really interesting startup scenarios
where you can start with a little bit of
money and then eventually when you
become popular and when the money will
be flowing out of your system right you
can use that money to invest back into
the lambdas it's kind of different from
traditional deployment models there's a
little bit of resemblance with bass but
only a little bit because we have no
notion of servers on notion of
applications no notion of scaling up
scaling down right and the cool thing
about this is it's truly pay-as-you-go
so we only pay for when actually our
functions are being run and we don't pay
for hot standby or cold standby so we
are giving the cloud I've run for its
money now instead of the other way
around I think that in theory is very
very interesting stuff hopefully you
have all kind of use cases in your head
now that you want to experiment with I
do have to say that this is still a
relatively young technology the IDs from
Amazon are now only three years old so
there's lots of stuff which will be
different in the next couple of months
next couple years Amazon is also still
doing lots of updates to their
implementations or every month or so or
every two weeks I guess there's new SDK
updates so there's a lot of stuff still
happening in this space it's very much
proprietary but looking is your choice
of course so with that I'd like to thank
you for your attention if you have any
questions you're free to ask them now or
just come down and I'll be around for a
next couple days so um I'll be around to
answer your questions thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>