<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Hijacking IoT with IBM Watson | Coder Coacher - Coaching Coders</title><meta content="Hijacking IoT with IBM Watson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Hijacking IoT with IBM Watson</b></h2><h5 class="post__date">2017-04-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/G3_aCxtzfFk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so with afternoon everybody thank you
very much for coming for one of the last
sessions over here my name is mike
sadarski i am a developer advocate which
IBM i am a founder of the company doing
robotics and i would like to talk to you
today and show the things i'm doing a
couple of things i call magic with the
regular thing so yesterday I was at the
science fair in elementary school
showing a complex things in a simple way
I have a roomba without vacuuming module
and this is a piece of my history back
in 99 I was working here in NASA Ames I
was doing a research on a virtual
reality system to manage robots on Mars
through this VR sets imagine oculus rift
20 years ago kind of thing so I felt in
love with robotics and I dreamed about
founding my company I did it and then I
moved from from Warsaw where I was
working and I founded the company there
to Silicon Valley to expand the company
and after selling a house to survive in
in this not the cheapest place to be my
wife told me go back to job so I look
around and I realized that I can rejoin
IBM and I can learn more about the
things that are cutting edge at the
moment and this is cloud mobile IOT nai
and the previous talk was very
interesting is was showing you how you
can how you can build how you can be in
systems deep learning systems in Java
this stock would be very similar how to
consume a I from various things using
cloud using IOT and how you can change
and empower IOT systems so-called smart
smart devices
two intelligent devices and there's one
of my startups idea I'm thinking about
one of the ideas that I can
commercialize while being an employee is
very hard to do it so so I'm building
that the prototype step by step you will
see maybe in the future the product
based on that or maybe not so what is
the difference between artificial
intelligence are this how how internet
is describing it so artificial
intelligence our h al or how kind of
system that was used in space others say
is the machine that imitate intelligent
human behavior and you have we have seen
the same kind of set of algorithmic in
the robot during the ex machina movie I
hope you some of you who have seen it I
hope I've seen it some some of us have
seen again so it's a really intriguing
at the horse the words is that I am
building this services in the movie
there is a wall not too bad not too good
example of managing the features with
this sticky notes so the guy is asking a
test subject what he feels about the
robot or this AI and he says something
and he comes to this wall full of the
post note and makes a update or so it's
a very tricky and I think this wall is
build of requests or kind of behavior as
you can see in cognitive computing so
cognitive computing the part of the in
my idea the part of the artificial
intelligence but focused on a one
particular task so let's call it the
visual recognition or a dialogue or
speech to text or text to speech kind of
functionality so so now having these
capabilities exposed
through various ways one is developing
it from scratch like we have seen on the
previous talk or just using it through
api's as i will show you today is the
way to kind of approach a new features
around us and I and myself I built the
competitive design to the just regular
robot vacuum autonomous machine that
senses around what is happening and what
they lacked I like the interaction with
the environment in sense that it can
really tell what is hitting it's not
like a half obstacle I would rather not
to push my robot against again against
the vase that is very expensive or the
glass of wine and so so these are the
the things that I was concerned about
before but when i started to leverage AI
or cognitive services i started to
really appreciate what we can receive
and from the sensor you can get some
information let's say it's a camera and
then you can get the idea what is on the
picture and this is the screen from the
from IBM cloud we call it bluemix and
you have about 20 cognitive services
what's on services and based on that and
i will show you a live system in a
minute so so it's it's very intriguing
you can have a ton ton analysis so if
you work with the text or speech to text
and then text then you can recognize for
example the changes in the behavior of
the person because maybe person is happy
having a call through call center and
suddenly it becomes very angry or it's
angry and it becomes tone down and
becomes agreeable because you propose
some new product in exchange for the not
working product
so you can have this kind of features
and now you can assemble them from these
cognitive services and having just 20 of
those you can use them in your system
and leverage it in a new intelligent
system so so I have this I have a couple
devices over here i'm going to show so
one of the devices i'm having is
raspberry pi i just put this new I got
this dish doing this Expo I got the very
nice shell for my raspberry pi it's
rather a by three laughs three by three
is going to talk to the to my stem robot
it's it's not room by its iRobot create
and I'm having a serial to USB interface
so i'm going to plug wraps with pi to
the roomba and it took me some time to
start to use it with something else than
Python so I started to use node red not
red is abstraction layer a visual
abstraction layer on top of the node gso
Java JavaScript based software or this
way to program program the device and
then i'm using standard protocols in
this case it's MQTT and MQTT is over
platform that IBM offers which is IBM
Watson IOT platform so you can you just
it's pure MQTT but but it's it's all the
server is based on the on the cloud I'm
using cloud services for various things
like speech to text recognition text to
speech capabilities i'm using a visual
recognition so you will see how it works
and in order to i was thinking long time
how i can talk to them to the device and
one of my ideas maybe you have better
ideas so we can discuss it at the end of
the talk is to use your mobile device so
from anywhere you you could get
you could get the access to your machine
and let's say remotely operated so this
remote operation comes from from my
previous engagements with my robots and
also with Mars it's very hard to move
yourself to Mars and say let's move over
there to the robot about the robot it is
so it's easier just to communicate
through the device and everybody has
everybody has the smartphone or tablet
so you can you can invoke the messages
and so I had couple examples how the
services work so just to reiterate i
will show too so I have visual
recognition and at the end we'll also i
will pointed out i have small github
repository with this example so you can
recreate what i what i have done it took
me a long time i think i was looking for
for the solution to move the room before
a long time if you want to do it
yourself you are more than welcome to
just use these repositories it's I BM
but be / devoxx / blue Marrakech which
are without a blue so and you can also
follow me on Twitter so let me go to the
examples in life live demos so so this
is a catalog i was mentioning we have
more than 150 services there we have
java no GS containers so you can deploy
them it's a bluemix platform as a
service so we don't need to deploy your
own server you are free to do it with
the containers so you can now there are
also KU Burnett Burnett is containers so
you can use them as well but mostly it's
used as a container so you just plug
your applications there and they are
living there but we have about about 20
20 services and these are the services
I'm a part of them i'm using i'm using
deprecated since beginning of of this
month i can the api i'm using a speech
to text and text to speech services and
you can use also tone analysis so if
your messages as I was saying if you are
communication is angry and going down to
agreeable let's say and i am using also
visual recognition so so these services
i'm using i'm plugging to my system and
over here is a small dashboard of the
systems it's it will ask me to login so
so i put these services in 11 spot i
will i would try to show you how to
deploy the first service and we will be
able to play with with that easily so i
have this small set I have database I
have the platform for MQTT so which IBM
has a name for that Internet of Things
platform Foundation and visual
recognition I by bind them together in
one application and I can run so in my
database I have a couple databases but
in a picture database I don't have
anything so I will go with the picture
pick your service so let me go to the
visual recognition demo so so you have
service and what we were shown on the
top before there are deep learning
services and you can you can leverage
them during doing various operations if
you want to go varied in a very refined
searches or data acquisitions you would
love to have ability to train it in
various aspects we call it classifiers
so i will i will use my classifiers that
are already embedded in the system for
4h and personal recognition what what
makes me really feeling strange is that
a
the system already strained in such a
way it can recognize the the things
about people over here and and it can
you can recognize over even the relation
between between people so so so that's
that's really scary about the system
because they are being trained and are
more that you train them they are
becoming more and more adequate and the
training is very easy we are having even
a command-line interfaces so CL eyes for
for that and so let's say excuse me you
would like to create an CLI for I mean
classification for the in the industry
of insurance like to create them let's a
system that is going to automate the
process of claiming broken windshield
and now so we will teach what this
broken windshield and then you will show
all the all the all the broken
windshields teach it to the fitted to
the system and system would respond
showing the picture of the broken window
you say oh really it's broken will
children are so we are going to replace
it and you'd what stays behind that
message is you don't really need
personal I mean agent that is going to
do it because it's such a simple task so
you are going to replace in this case
manual process with the automatic
process in a business business process
so this one case I wanted to show you
and I'm going to deploy it on my abs
reply and the other one was thing I had
it before it was here
it's personality inside so grabbing some
text you can start to understand what is
happening with the person and I'm going
to hijack this rumba over here with
Watson and the purpose would be to use
it for example for elderly care so
someone can talk to the robot and the
robot can start to respond to you and
you can have a chat and if we are young
we don't need this type of the service
however we are starting to use alexa
google and other services Siri to ask
questions for us it's may be awkward my
son who is 10 years old and moved from
from Poland over here three years ago
now he's having youtube channel his
video blogger he blogs in English and
his star is not you too but he's having
a concert in May but done BTM who is
recording all the minecraft games so if
you have kids you know that is a huge
gap between our perception of the word
and a day perception of the world so so
they will feed us with this robot and
they will have the conversation with the
robot so we will talk robot will come
over bump me in the head in the head and
in the leg and we'll ask me do you
remember you have a meeting have a
presentation today you have to connect
with your with your kids and how do you
feel so so this long introduction was
for that that I can respond the robot
various way maybe maybe I will kick it
back on but it can recognize my mood
shifts and if my mood shift is really
really huge it can set the knowledge and
the salad would go to the care provider
for for me because I will be probably
sitting somewhere I hope in Croatia on
the very nice beach or I'm never going
to buy a property probably in a bay area
but but you can you can say out of
things and people who were using that
let's
the Opera and if I analyze her hair
treats you can see that we are having 15
thousand words being analyzed and we can
see that we can predict we can kind of
get information that she can be
influenced by by family when she's
making purchases so maybe future
marketer would go to her family to wave
to flood them which the pictures of the
purses so so then she'll make the
decision to buy the pairs of disparate
this designing of the other one so I was
doing this for for for myself so blue
mark s and and I have analysis of it
over here it's not mine let me reload so
my Twitter analyze my Twitter
so one of the things is i am unlikely to
be influenced by by social media to buy
the things so maybe it's that that's a
good thing about about me and it's true
and and one of the things also it shows
over here it's a personality trait so
I'm really open but I was diving into it
and I usually I am speaking about the
code or development so it usually say
that my range now in my emotional range
exploded but probably I was tweeting too
much about Star Wars another movie so I
don't know maybe about that nonetheless
it's intriguing and you can consume this
very nice graph because it's in fact
it's Jason so you can go inside you can
see what are your big five trays and so
on yes
yes so so the question was how one would
use it so one way to use it is just to
provide rapper that is going to to go
with the RESTful API call to the cloud
and I would provide us an input I would
provide tweets other way would be sent a
cover letter to your HR department and
this cover letter would be shipped to
the to the system and it will check if
you are in a right area for the for the
department so you have to over here you
have to ship the in this case the text
as an input or reference to the webpage
so for example you can send a link to
the article and and let's let's say I'm
in a very bad mood today and I need some
sparks to to get the life and rise my
mood up so my robot can choose on the
positive articles that are happening so
it will skip all the Westminster stories
and I will get on the positive things
that are the Polish lot is becoming a
stronger currency for example I don't
know why but maybe it's because of the
current president doing some stuff over
here so so I don't know so these are the
things you can use and and now I'm going
to show you how I'm using it so so this
is a very high level view on the on the
soft software i created and we'll go
from the i will show you in we have
still are about 20 minutes so i will
show you and how you can create it
yourself very quickly and I'm standing
I'm injecting the request and it's being
passed through this no there's no this
MQTT note it goes to the other system so
it's my note read on the Raspberry Pi
it's connected through my rotor so in
this case it's my my phone over here and
it gets requests
it triggers the camera and and the
camera takes picture the picture is
being encoded and the name of the
picture is being sent back that there is
a picture and I'm starting the picture
in in in this case I loved it no dread
over here I mean it's loaded already
with Jesse Jesse Jesse linux so you can
you can you can have it over here very
easily and I'm describing how to do it
in on my blog so and so the message over
here so one thing is the image itself it
goes loaded to the to the cloud the
other thing is the picture and
information about pictures being sent
back and it comes here and and I am
getting the picture from the database I
wait 10 seconds because sometimes I'm
having a problem with sending sending
data and then I'm decoding the picture
and I'm pushing the picture to the
visual recognition so this is the part
of the Watson API that i'm using and
this picture then is being analyzed and
and i get result over here so i got the
results not so good for me so i will try
to smile more i will delete it so so let
me try so i will have a red you probably
won't see it but a gentleman over here
in the front we'll see so i'll try to i
try to smile let me see okay so i was
smiling there was a red dot so i send a
message now if we look on the on the
side over here we don't see anything let
me see the back
hopefully it send the picture so so now
we are analyzing and so the age is
better 24 years old and a an 18 minimal
but it took me as a female so so it's
not enough training maybe let me see why
why is that so so this is this is the
part of the exercise i created so so we
have a device that is taking pictures on
a request I didn't connect my phone to
this but it was connected over a cloud
so so so we are going to make it also
available from the from the mobile
platform so let me put it back over here
so we can I can detect I can get again
the analysis I can get to this picture
on the node-red on the cloud I can get
by just requesting I mean through the
and get get requests but also i have
created a small app one apiece in a java
but the other one is in in swift and i
started java developer thomas tell you
96 I was I was with researching a Java
system a server side java system in in
japan in entity and i stayed outside of
Tokyo for a modern about six months and
so now there is a new thing there is a
new language doing the same as Java 20
years ago so I'm backing the same shoes
i'm doing swift development so on the
server side and on the on the device
side so so i have i have a small up over
here it uses couple libraries but one of
the libraries is speech to text so so
the library over here supposed to reach
out to the database if i say magic word
so
can you show me the picture why I am a
female so now it gets the picture and
potentially we will see it why okay
maybe because i am shaded this is the
picture it has seen so maybe gentleman
over there or my colleague over there so
so so this is what what happened so as
you have seen i used one of the api's in
the in the system that is speech to text
and and you can analyze various things
so so such a system can analyze for
example if it's positive or negative
message so over here I have the same
kind of example very similar it's going
to check if the if the text input
inputted here is positive or negative so
so i can analyze that and it says
positive then i can say it's not the car
it should be natural and it's
we can get the information it's went
through so it's it's negative so so it's
just a small input of the code that
triggers or leverages the cognitive
service and you can really take it from
various you can use it in various
systems and I believe that this is that
the changes is happening so your system
that is smart and doing a lot of things
that are very positive now can become
intelligent so you're you can adopt not
only to the group of users so you can
have like five groups of users these
users are chaotic and doing stuff like
that so you would adjust a part of the
code to them but now you can really do
really one to one kind of marketing and
11 to one user experience so I think
this is one of the ways to dig dig
deeper into that so so now next step in
our demo is to leverage other parts of
the of the code so so now i will i will
attach my my raspberry pi to the robot
and we try other actions so let me go
over the actions first so i will send to
two messages to them to the wraps by pi
so i lost the connection it's not good
so let me restart this one
so I starting I really
I will I will demonstrate other aspect
of the demo so hopefully it returns
so I think I lost all the other network
let me let me try so what is the weather
forecast for today there is a forecast
for the temperature 62 and the very good
golf conditions so we can go and play
golf it wasn't that good two days ago
when I was driving here two hours from
from my part of the east bay so I'm so i
think i'm connected now so so what I'm
going to do I'm going to reload the page
that will that will take a couple
minutes so I'm now reloading the page
from the rubbish whip I saw revs bleep
ice here I'm going to put this wraps way
pie first I'm going to connect the cable
to my robot so I have a small connector
this one goes to the serial port by the
way are this this activities I I shown
on my on my on my page so if you go to
blue mark the box over here so to the to
this repository you will see three labs
and and the application in Android as
well you will be able to in lab three to
see step by step what i have done with
the with the robot so so now i am a
connecting a USB i cried it before this
presentation and will work so hopefully
it's going to work in France mark i'm
going to put so now it's connected
so whenever I'm inserting a serial port
into the robot it turns on in a in a
debug mode so now now let's say let's
hope it's loading so so we will go
through the through the procedure later
and I'm i connected yes and so now I can
enter my robot into the flash the sigil
port and ask it to just to start we
should seal the beep so it starts and
now I can ask it to dock so it's dies
and so now it with dog potentially if I
just show it the docking station so in
the front of the robot there is there is
circular light light light state station
and it gets the information from the
from the robot I mean from the from the
infrared emitters and it dogs because
they are like system for the for the so
it dogs successfully and so I'm using
MQTT just to send a message the message
is being a connected potentially i will
show you how it looks like not too nice
flow so this is Maxwell so we send
couple messages I got two messages one
was deep and one was let me just try to
show everything so so I'm receiving from
iOS I'm receiving this MQTT message it
goes the comment selector and I'm just
passing the pass to the serial port and
a safe I'm reading all the safety
measures and I'm just beeping so in the
beginning beeps and it starts to move so
it goes to the sea
us be 0 and then the other one is dog
and I'm having other commands like over
here I'm entering the clean mode so now
you can use any so imagine you have a
lawn mower in your garden you are just
plugging this very nice rubbery pie and
low noise can be turned on from from
office we are sitting here you're coming
back you would like to clean to have a
nice nice lawn so so you just do it now
whenever it hits something or recognized
there is obstacle you can even create
some kind of the system based on the
video you would start to analyze what is
on the picture so like in my case I
would get the who is on the picture
thing and I'm so sorry I'm so old on the
speech don't know I'm Yaga this picture
but I nice email so so you can you can
get the information what is in front of
the robot so it becomes really
intriguing because now your servants in
garden in your home can talk to you they
can tell you what is in your home and
you are not there and if you are there
you can have a conversation you can ask
robot to come over so I think it opens
opens now the huge new market for
everybody to enter with the intelligent
appliances and intelligent that you can
talk to you so if I'm in a very bad mood
and I'm turning on the light maybe the
light switch will look at me and say oh
this guy is really sad I will brighten
his life he's his day with the very nice
pink lights I don't know so it will turn
on that pink light but if I am very
happy so the so the light would turn on
in the in the blue bluish light so i
would be very efficient so this is the
thing that the produce that can come now
to us that are going to become more and
more responsive and arm and this kind of
devices also can
look into the dark type of the
information that you don't see yourself
you don't realize that sometimes they
are showing the videos and we see main
main theme of the video but we don't see
all the product placements or all the
things that are on the beyond the video
artificial intelligence can do it for us
I mean cognitive service that is going
to tag all the information on the
picture so so you can start to start to
look into the things in ways you can
analyze various interactions in such a
way that they can become very
personalized so let me go to the last
two items on my talk and we will wrap up
because we have just three minutes left
so so we have talked about about how to
make the system's intelligent which with
Watson or cognitive services in general
you can either develop them or you can
consume them we I was showing you how
you can consume them my my blog is bloom
eric s blogspot com my github repo this
one and other rapisarda vox / bloom eric
s so you will be directed to the
destroyer and you can follow me on the
twitter from time to time i'm i am a
broadcasting information that my son has
eleventh subscriber to his YouTube
channel he's saying he's going to have
16 million so so I hope you enjoyed this
one of the last talks during the box I
am I will be over here and I'm staying
in the east bay so you can contact me so
if you have any questions let me know</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>