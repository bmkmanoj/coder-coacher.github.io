<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Elegant Builds at Scale with Gradle 3.0 by Hans Dockter | Coder Coacher - Coaching Coders</title><meta content="Elegant Builds at Scale with Gradle 3.0 by Hans Dockter - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Elegant Builds at Scale with Gradle 3.0 by Hans Dockter</b></h2><h5 class="post__date">2016-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SuQXOpY2u5M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so the talk is originally called elegant
bills at scale with we all but late
isn't graded me to it i think the
release candidate three is out so and a
couple of other features are just in
great at our donor show today so why do
we kick about scale uh well there's a
lot of inefficiency and pain out there
it comes to build scalability and so I
want to start with showing you a picture
of the typical Enterprise built master
at work and in my experience and I've
talked and consulted many many
organizations over the last years is
that developer productivity is much
lower than it could be because of
insufficient inefficient builds and
build infrastructure and as always it is
fascinating how people and teams can get
used to pain right even if it cost them
dearly they might say well it could be
worse I still can see a little bit right
and one knows drill is not too bad for
breathing actually why this is already
not a good position to be n right we
want to work with a very efficient bit
infrastructure right the future will
give the octopus even more arms the code
bases are growing very fast many
organizations have growth rates twenty
percent fifty percent hundred percent
per year right even with twenty percent
it means your code base doubles in the
next four years and when you have let's
say a bill performance problem now it
will not get better and the multitude of
new platforms you have to deliver to
because of mobile and all the
diversification we see when it comes to
target platforms mighty language is now
the norm in enterprise software stacks
and finally microservices are posing a
big challenge from a continuous delivery
perspective right a lot of complexity so
this is the time to invest into your
bills whatever technology you're using
but
definitely you have to do something
right and and it is not just about the
obvious pain right the car industry had
no obvious pain in the 90s when it took
them 40 plus hours to assemble a car but
when Toyota managed to do it in 20 hours
it became a pain for the other companies
so if you look at LinkedIn in 2011 they
were a thousand engineers and they
released a new version of their software
every 30 days which is not too bad I
would say that is still today above
average for that size of a team right
and and that but if you look at it from
a factory perspective when a feature was
finished and ready to go the feature was
by average 15 days in the shelf before
it reached their customers and users so
a couple of years later they brought it
down there now at two releases per day
right so that means the inventory term
for future delivery shelf is not 0 point
two five days and get a lot of other
advantages at the same time the codebase
was growing and not there there are two
thousand engineers so my question is are
you there yet right a very successful
software companies like linkedin and
netflix for example the invest remembers
amount of resources in to build
infrastructure to make the developers
more productive to become more
productive as an organization and they
do it very successfully both by the way
you scrabble as their foundation but but
my point is that organizations that are
not able to catch up with such ambitious
companies are doomed software is eating
the world and the companies that are
most successful in officially creating
software they will succeed so so
regardless of whether you think or our
bill infrastructure is good or bad
better is better the competition is
getting hotter and hotter and those
organizations going to ever more
verticals right to compete with
traditional companies okay so when we
talk about elegant built built at scale
right what are we talking about a most
obvious thing that comes to our mind is
built before
yes and obviously performance is a very
important scalability factor but there
is much more right if extendibility is
not good you have a fast build but you
don't it doesn't automate half of the
stuff that needs to get automated right
in your organization deeply support
developer workflows and I will show some
examples what I mean with that later on
you can have fast build systems that
don't capture key aspects of typical
developer workflows like for example
working on multiple repositories at the
same time and I've seen that quite a few
times business systems have to be easy
to configure for developers and to be
used by developers otherwise you can
have a fast and extendable build system
but when it's extremely painful to it
for developers to work with then it is
also very inefficient right and I've
seen that a lot of times that the build
system exposed a lot of complexity to
develop us to build wiki's way you to
write and that is definitely something
that is very very important to me that
aspect and then build infrastructure
must be maintainable right that which is
not necessarily a trivial thing and
another aspect is monitoring analytics
of your building for structure right how
easy is it for you let's say you work in
a distributed team right to see hey the
team in bangalore right or the team in
the US do they have particular issues
that are not visible where I'm working
from right when they're for example run
their local bills and finally the build
should help to enforce software health
like separating the API from the
implementation we talked about that or
dealing with the health of your binary
dependencies we will also talk about
that later okay so and I show you a
couple of major features in Gradle most
of them on you that target one or
multiple of those dimensions so let's
get started with the performance
dimension and a big part of that is
built output caching so one question who
of you is using Gradle okay so it's
about 5050 that's good I think everyone
will get a lot of stuff out of this so a
first of all
what makes a task in greater the unit of
build output caching right as well as
the unit of execution in Gradle it's a
task right in and it would be a target
for maven users it would be a goal you
hook into a lifecycle a bit a unit of
work in maven right and and cradle
caches the output of every task we
talked about that in a second there are
some other areas where we do caching for
example external dependencies but that
is not build output right so in any case
every greater task right has inputs and
then actions right what the task is
actually doing compiling running the
tests jarring and they have outputs and
for example write an input for the
compiled task would be the source
compatibility setting right after
compiled task and of course your sources
and of course the classpath the output
obviously in this case are the compiled
classes so what is a special with Gradle
compared to the other Java build systems
right inputs and outputs are explicitly
modeled in Gradle every greater task
that ships with Gradle has its get us
annotated to describe the inputs and
outputs right and you can do that for
your custom parts right when you have
when you're extending Gradle and if a
task describes the input and the outputs
whenever you run cradle we store the
hash of all the inputs in all the
outputs of the task right so the actual
output of this cache is an output it
isn't a build directory right but the
hashes live somewhere else that that
that that fingerprint this output and
the inputs so the bill directory is
similar to the target directory right in
maven so the bill directory is part of
this cache and uh and the way greater
works is when you run the greater built
again it checks have two inputs change
of the task have the output changed
right and if not the task is up to date
and the task is not run
if any of the input and output has
changed the task is reacts acute and the
output is regenerated so sometimes draw
all existing output away and fully
rebuild Alice to it incrementally for
example the cradle incremental compile
task the crater provides an API for
incremental task to do this efficiently
to inform them what has changed but
we're not talking about incremented
tasks right that is a separate topic we
are talking about a task output cash
right that is binary has something
changed we execute the task if nothing
has changed we don't do anything ok so
in every greater user knows about the
up-to-date feature right it was
prominently shown on a command line
right when Gradle when a greater task
was up to date you can see that but it
is important to understand the details
of the current caching mechanism right
so the cash kicks in for a task when the
content is the same the last time the
build was run so for example when you
switch between branches within your
project directory right you check out
the master branch should check out a
feast up feature branch you built a
master branch then you built a feature
branch if you go back to the master
branch you you don't have any up-to-date
myths anymore because you've built a
feature branch before we only the
current credit cash only stores the
output of the last build well there's
only one bill directory right so it is a
way we're doing things right now it's a
natural constraint right so the other
thing is when you check out the same
project twice let's say in two separate
directories the build output is not
shared right you built after the two two
projects the same projects from scratch
it's only within the same product
directory that we do in a caching
obviously output between different
machines is not shared right and very
important it only works when you don't
run a clean build right so the clean
removes the bill directory and that's
the cash
content is removed so clean build forces
everything to be rebuilt some people may
say oh that is why I do a clean build
right Nathan users do that all the time
but we talk about this later we don't
think that should be always necessary
okay so I want now to talk about the new
task output cash in greater it is not a
replacement for the current up-to-date
mechanism which will continue to have
its place it's an additional caching
layer or potentially multiple layers so
what is the purpose of that new output
cash right so first of all this cash
stores to complete history of built
output so for example when you you can
from with this case you will be able to
switch back and forth between branches
and the builds results of all the
previous blood runs are all stored and
reusable right and it will work a per
machine right so you can have the same
project check the other two directories
and the build results are shared most
importantly you will be able to share
build results across machines so this
will enable a distributed cache for
creative build output and finally the
cash will also be used for clean builds
right as it stores to content outside of
the Builder Ector e so um and that has a
lot of very positive effect so let's
talk about how what we need how does it
work right so the first thing we needed
to do was to extend the input and output
model to make this reliable and
efficient right so first of all task a
task has to opt in the task
implementation has to opt in to be
cashed in a new output cash all the tard
ship with Gradle will opt in but for
your custom tasks you have to explicitly
tell cradle hey this task should should
use the new output cash right the reason
for that is that we want to make sure
that you have reflected upon the fact
whether your inputs and outputs have
been properly defined for example
the version of the tool train used by a
task should be part of the input right
if you you don't want to share the
output when one build is using version
10 let's say of a source code generator
tool and the other built is using using
version 2 dot zero those outputs you
don't want to share right you only want
to share between builds that use the
same version of the tool and when when
you when you have implemented a task in
a way that it just picks up whatever
version there is without making it
explicit right then you should not use
the new cash for that task to make the
cash efficient right because we want to
have as many hits as possible you you
annotate inputs that do not affect the
actual outputs like the verbose setting
right it is only relevant for the
console output and then we don't use it
for calculating the cache key and
finally that is one of the interesting
bits here right now when Gradle
calculates where the inputs or outputs
have changed a creator uses the absolute
paths to hash the file content right and
order hash the inputs and this basically
means you will not have cash it's
between projects that do not live in the
same directory on the same machine right
usually and that of course is not very
exciting right so that is why in an
extended input and output model you can
tell Gradle which part of the path
should be used to calculate the cache
key right for example for your source
files probably everything under source
main write Java and you can explicitly
tell cradle how to do that so that there
is 11 basically evolution of our caching
if we extended the input and output
model to reflect the additional needs of
the new task output cash and how does
this work in practice we're there to
look there are two locations for this
task output cash so one is a shared
server this is called a distributed
cache the CI builds they read from it
and write
to this cash right and see I built will
deeply benefit from this cash they
usually always do clean builds so they
run different jobs with different user
homes against the same project so the
same thing has to be rebuilt over and
over and over and so with the new cash
that should dramatically speed up see I
built x developer builds they usually
only read from a distributed cache that
reduces the latency and is important for
reliability all right so and the other
cash instance optionally is on your
machine to reuse output when you switch
between branches for example okay so um
what what are the pieces that that that
that are required so that you can use
the new cash so I talked about the
extended info toppled model that is part
of a cradle 3 2 which is available now
and and we will do some some improvement
some additional fixes in greater 33 the
greater Java tasks they already
configured to opt-in into the new cash
there's a REST API and a Java adapter to
connect to any cash back end you want to
provide for the distributed cache we
need to provide an authentication API at
the moment when when you have access to
the cash back and you have access to it
right there's no auto education
happening right now configuration dsl
where you can configure which builds
should only read which boots should read
and write there's already a cash back
and reference implementation that you
can use for distributed cache and a
cradle will ship with a built-in local
task output cash with version 33 or 34
so uh to wrap this up we have a public
performance enterprise large test
project that we used for performance
optimizations right and when you run
that with with the distributed cache or
without the distributive cash right the
effect is a traumatic pretty spectacular
right to 300 seconds versus a couple of
seconds and and overhead the distributed
cache or a cash-in general is
introducing is really tiny so it's
yeah very very much looking forward that
all of you at least are using cradle
start using a distributed cache okay so
now we talk about the next dimension
another feature I'm super excited about
how we can how a build system can really
support to pick deep in a deep where
typical developer workflows so and this
feature i want to show is called
composite builds so what do we what does
it mean composite builds composite
builds is about combining independent
grader builds and and binary and when
you combine them binary dependencies
they have between each others are
replaced with project dependencies that
are built from source so let's look at
an example so what we have here is a
java a project it's a java application
it applies the greater java application
blog in which gives you a run task and
task to bundle the application in any
case this project my app here's the main
class named application plugin needs to
know that and here's the main class of
my app and this project has two binary
dependencies on a number utils library
as well as a string utility library and
when we look into the main class you can
see how it's used right a string util
library is used to concatenate some
strings and the numbers libraries use to
add two numbers 15 and 10 okay so uh
when we run this app now see oh the
answer is 26 so there's a buck somewhere
so okay let's go back to our code let's
jump into the add method and let's and
we see oh the plus one shouldn't be
there but hold on this is decompiled
from the binaries in IntelliJ we can't
change the code here right so what we
have to do is we have to go to the my
youtube project have to find the class
that implements this the add method and
then we see okay here's the back let's
remove the plus one okay let's do that
and okay let's rerun the build and AH
still not fixed why is it not fixed I
need to republish right ah ok what a
pain in the neck and imagine you do this
you have some more complicated
refactorings you do this all the time
right you forgot to publish you wonder
why is it not working it's a it's not a
good work flow right so ok let's see
what we can do with Gradle with greater
we can say ok include another built and
combine it with the current build and
when you run this what you can see now
is that we have not used the binary
dependencies but have built my you tools
from source and you see the answer is 25
all right so and there there are more
refactorings I want to do so I would
like to do that conveniently in the IDE
and not in two different ide windows
right into different idea instances I
want to do that in one project so I tell
cradle to generate the IDE metadata and
inject the my you tools bill telling
cradle hey combine those two builds
right and after I've done that you see I
have now my utils and my appt both in
the IDE they have source dependencies
between each other so i can now go into
the main method of my app and say okay i
want actually I want to have a minus
method right and can use all the
goodness in IntelliJ to creators minus
method and um
right so let's see if that works
here we go the answer is 5 so nice and I
don't 11 way to do composite bills is to
do it to do it via the command line
another way is to do it in the settings
for greater so I can persist that
behavior in my app at least for a
certain period of time that I say
include build my utils and then I can
just go a on the command line and don't
need to inject it there but can just run
the build and the answer is five ok so
just to be a just to be sure if we
remove this right and run it built again
this will not work because now we were
using the stale binary dependencies and
they don't know about a minus method ok
finally what I can also do and that's I
can i can create completely synthetic
composite projects right so and in this
composite project i have a setting store
Gradle where i define all the bills that
should that i want to combine right
number of micro services that have a
separate repository for example and and
you see there are no sources in a
project nothing right just the setting
start Gradle and a built-up Gradle and I
can just say greater run and then it
combines those two builds into one and I
can import them into the IDE yeah so
that is the composite build feature and
I think the reality is with micro
service architecture that that people
that the number of repositories will
increase so I think it's a very
important capability to make working
with multiple repositories very
convenient and so for quick local
experimentation a cross repository
refactoring as we have seen right and a
typical scenario is when you have a big
monolith right and you want to now break
this down into smaller repositories this
is a wonderful thing right is this
feature and
and imagine to do this together with a
distributed cache how-how-how floon that
will be right when you have let's say a
big man unit that takes 20 minutes to
build right you started your day in the
morning right see is filter distributed
cache and you can start with a
refactoring right away okay another nice
use cases when you write Gradle plugins
standalone greater plugins you can with
car with composite builds you can now
easily combine them with a test project
to try them out it instead of always
publishing them and then consuming them
in a test project okay next feature I
want to talk about one of my favorite
topics it addresses many scalability
that mentions at one enforce your API
with Gradle so let's look at the
following project so this is a mighty
module built it could be in May in May
even or in Gradle right so it has three
modules that you built from source right
core that depends on you tools and
utilities on some lip and they also have
external dependencies right and so my
question is now when you compile a core
right with may even all the way grated
currently works right what what what
isn't in your comp I classpath
everything exactly yes so the whole
transitive graph and is that a good idea
you need it you need all the
dependencies to compile yes so in that
that's the interesting question right so
so first of all you pay a price for that
right from an avi perspective the build
system assumes for example that the
utils api consists of all the classes of
you two as well of all the classes of
some lip plus all classes of commons
lang and all classes of commons i'll
write em big api and
so so in general I think this behavior
is evil right it creates as I said a
vast through this area of your API often
two orders of magnitude for bigger
builds larger than necessary right
they're hard to debug and reason about
because of the size and the implicit
pneus that often comes with it it
introduces fragility right if you depend
on some of the dependencies in the
transitive path that is deeply nested
right and then you remove the parent
dependencies out of a sudden you you're
wondering why is my court no longer
compiling and the vast surface areas
leads to many many unnecessary compiles
especially in laga larger projects where
this hurts the most okay so why not
using the direct dependencies and
nothing else right for a compiled class
path in first in fact at the very first
spike I did many years ago for Gradle
had a non transitive compile class path
but for reasons we will discuss soon it
was not quite that easy to solve that
problem and I had to revert to
transitive as a temporary solution I
thought for just a short time but anyhow
finally we have addressed the issue and
and the short story is the new normal
with Gradle will be that the compilers
path is non transitive by default right
the new behavior will be opt-in so
existing builds will continue behave the
same way so how does this works with
with Gradle let's look at a demo okay so
here we have the project already a short
in in the in the craft right we have
caused some lip and noodles and let's go
to the to the IDE and you can see in a
core project we have the dependency on
comments collections and we have a
project dependency source dependency on
you tools in you tools we have a
dependency on some lip and a dependency
on commons lang and in
in some lip we have a dependency on
common style okay so um and if we now
look at this is now using the new the
new mechanism right where compile
dependencies are internal right so in
you tools to compile dependencies that
utah's declare declare or any-any anyone
else any other project declares I
internal they are not exported if you
like right so okay let's try this out so
first we compiled a uterus project right
and I have enabled some debugging
statement so you just depend on on some
lip and we can see the compile classpath
the compliant compile class path
includes the some lip dodge are so in a
new the this new set of features also
includes a mighty jdk support that's why
you have to compile java 8 a name in the
name of the library at any of its some
lip jar it's common slang but it does
not include the comments I or dependency
of some lip right so only the direct
dependencies of my uterus and everything
of you tools and everything worked fine
okay so let's compile core and here we
get an exception alright so a compile
fail to compile our csa there is a glass
okay first let's look at the compile
class part it's the usuals jar in the
comments collection jar and in the main
method of the core project we refer to a
class that the compiler cannot find okay
so let's go into the source code let's
go to the main class and we see a here
is this function class that we're
referring to actually it's an interface
right and uh okay and this interface is
defined in the some lip project which is
a dependency on YouTube but not I depend
see encore okay so um what do we do
right how do we solve that uh what do
you think yeah so we could declare it we
could declare a first-level dependency
in core right that that would work but I
don't think it's the right solution
right so we could do that compile blah
blah blah because the reason why I don't
think it's the right solution is the
following if you look why we use this
function class right the string utils
method which is part of the usuals
project right it's requiring an
implementation of an instance of
function to be passed to the method
right so it's so it's part of the API of
the uterus project right I in in core I
only use function to use the YouTube
project right and you can see right it's
part of the signature of the encode
method so so what what we should do
right and what you can now doing greater
you can say you can declare another
dependency as part of the API right boom
and then this dependency is basically a
will be exposed when you have a
dependency on youtubes right so and if
you do that you can see everything is
working fine now and we have in a class
part for compiling core right we have
you tools we have comments collection
and we have some lip yeah but not
Commons I oh and all the other stuff ok
so the recommended default for cradle
will be non transitive but as shown you
can tell a cradle easily that an
additional libraries need to be exported
and a part of the API and this solves
one part of a bigger problem
right so can we further reduce the
surface areas right so when core depends
on you tools and some lip it does not
depend on all classes of those modules
right there are internal packages it
should not require right wouldn't be
nice if we could drag cradle tell
somehow about that fact right so let's
look at the next demo so so so the utils
project has an internal package and
there is a string internal kind of
helper method in there which does some
which capitalizes a string uppercase a
string so and in the core project I
thing uh that could be useful right I
can or i can use that for a nice print
out in uppercase so uh so i create an
instance of string internal and and have
now a super nice Ibaka spread out of dev
ox okay so let's compile this right here
we have string internal let's compile
this and let's move to clean I only only
run a clean build so that I trigger to
compile to that you could see the debug
output was the classpath usually I don't
run clean bills okay and what you can
see the compile was successful right I
could easily use the string internals
class obviously it should work because
hey you tools is part of my class path
and it contains the string internal
class okay but the util steam is pissed
off all the people that use to internal
glasses write it they want to protect
them because they want to be able to
reflect them without paying attention to
backwards compatibility so they can't
wait to get the latest version of Gradle
to do the following
they cannot declare which packages
should be exposed so they say come at me
util is fine but not come back noodles
internal and if you compile this now you
will get a nice exception a compile
failed and because the string internal
the class is not visible it's not part
of the compiled last part of core so and
I think this is very very important big
AVR API surface areas big API surface
area is expensive right and the larger
is the more expensive it is and that is
true whether you provide an API to other
teams in your organization or to the
world it doesn't matter right they
impose massive refactoring constraints
right if the whole organization use all
your internal methods were good luck
with refactoring this code base right
and still have friends after that and
they require if you do a good job they
require expensive testing for backwards
compatibility you must not break those
right and that is even harder if this is
not part of one build but if the
consumer and the producer of the API
decoupled right and to consumers use
different consumers use different
versions of your API right then things
come really complicated bigger to
surface area is and um and this can
bring your developments be to a crawl
right talk to the JTA folks right how
hard it was to make the JDK modular
after the fact right those are the best
engineers on the planet and it took them
years to to to get modularity introduced
right talk to us right greater we have
2.5 million downloads per month right we
have millions of users and we we are a
very conservative to main we have to
guarantee backwards compatibility but at
the same time we want to continue to
innovate right reducing the surface area
is key right so you could ask now
instead an exotic opinion that i have
here how important that
well I would say not quiet because this
concept is at the heart of Java nine
right so and that is another thing I
want to talk about um so great it makes
it not extremely easy to enforce API is
right and created paves your way to
jigsaw right so in multiple ways so
first of all you can start right now to
enforce your API is whether using java 6
java 7 or 8 you can with Gradle and
force your API at bill time with all the
benefits we discussed initially we
recommend just to model how the IP eyes
are used current currently to prevent
further degeneration right enforce the
current usage but not through the
outreach into other internal packages
and then you can you can improve from
there right and the other thing how
cradle so so and that is a key thing
right modeling your API and your
implementation that is exactly what that
is what jigsaw is about so you can start
doing this now with Gradle get all the
benefits and when Jake when you're ready
for java 9 and jigsaw well then you're
definitely ready to use the jigsaw
features because you have already
defined that in Gradle so another thing
that will help you is it is easy to
migrate with great almighty JD case
report i will talk about that in a
second and finally a greater create
jigsaw module info and my to release
just all that out of the box for you so
i don't have time for full demo how this
works i just want to give you some idea
how this looks like so uh uh with Gradle
you will now be able to define target
platforms right and when you say I want
to try out my build with Java nine the
only thing you need to do you need to
add Java nine to the target platforms
it's the only thing you need to do
everything else greater does for you it
creates all the tasks automatically to
compile with Java nine right and
all the wirings between the sub projects
so it's it's that is super easy to
configure for developers although it's a
pretty complex problem that we need to
sort of dealing with all those different
jars for different Java versions but
greater does that for you and and then
when you add Java nine is a bad phone we
know our Java nine min jigsaw so we
created the module info automatically
for you just for the Java nine jars the
mighty released jar that is part of
jigsaw will be built for you so it
couldn't be more convenient imagine you
would need to do that with maven
profiles just little joke the other
thing you are able to do which is I
think even better than multi release
jars is that you can specify
dependencies / java version right you
can specify dependencies that are used
across java version but then you can say
the java 7 a version of my jaw uses
comments i owe two dot one and Java 8
users to dot five because there might be
some closures in there right so very
very powerful okay so the other thing I
want to mention is compile avoidance um
so great offers you compile avoidance
when a transitive dependency changes
when any code changes into internal
classes and when any change happens in
the implementation of avi class as well
I'll give you a quick demo on that
so so I'm running a greater compile Java
just to show you everything is up to
date right and and now I go to the
uterus project right entered remember
core depends on you turds and I change
the version of commons lang right and
when I recompile a compile Java 8 it is
still up to date you tools I needed to
recompile because the class pass has
changed but because this is no longer
leaking right I don't need to recompile
core so another interesting thing is
here's the string internal method right
that is not that is a not exported so I
reflected as I just changed the name so
I basically change the public signature
of of one of the classes in YouTube but
core is still up to date because hey the
internal glasses are not exported so
they don't trigger a recompile of core
right so we talk later about what is API
dry is about so the next thing i want to
show you and it might surprise you so
now we touching the string utils class
and that is a that is exported to to the
core project but what we're doing is
we're just changing the implementation
of the encode method right we're just
extracting a variable here so we don't
change the public signature and even
that doesn't trigger recompile and that
is why we built this API ja so the way
cradle will works is that a for every
jar that is consumed it creates an API
jar that is basically only contains the
skeleton of all the public methods and
their arguments nothing else right and
so so when when you change the
implementation of a method the API jar
will not change and that is basically
used to
to indicate right and that is part of
the compile classpath or compile of the
crop project so when you change the
implementation of of a class that that
isn't your class path it will still not
regard recompile so oops oh oops that
was not good sorry I wanted to show you
something else see fast-forward are
screwed up in a second
in there
No
okay so uh okay doesn't matter I just
wanted to show you how it actually kicks
in when you change the public API so the
previous demo has shown you in detail
how the compile avoidance works but it
didn't give you a feeling for the
performance effect right so let's look
at a more realistically sized and a
medium-sized project with 190 thousand
lines of code right so 19 subprojects
and they have dependencies between each
other I pretty pretty clean dependency
graph and relatives often it's often
much more messy right and so when
everything is up to date the compile is
very fast right second or so now let's
change and this is how greater works
currently or oh you would do it with
maven let's change a diversion in
project one of any of the dependencies
and because this is leaking right to the
old way that things are working you need
to compile everything because the
classified is leaking it triggers a
recompile of all this project it depends
on project one directly or indirectly
and now second so
sorry my goodness
in dual screen mode I don't have a I
don't have a control for the record a
demo and the fast forward is for some
reason not working for me so let's do it
one more time sorry for that or so much
more to show so this is taking now
change of the compile classpath triggers
all those recon pious and you could
argue well at the end of the day it's
only it's only 11 seconds right but it's
so much nicer there's only one second
right and for larger projects that can
be five minutes 10 minutes 20 minutes
right when you do some heavy annotation
processing and stuff like that so the
way it should be working is and will be
working with with the latest features of
Gradle right is that you are when you
change the compiler classpath in in in
project one right only project one gets
recompile the rest is not affected and
you have to feed back in one second and
that is much more fun to work with okay
so um some of you might have heard that
cradle is now also using offering
cortland as a language that you can use
to describe your build who is aware of
that that that yeah who knows about
Kotlin that's interesting only twenty
percent okay so it's a new it's a new
JVM language are provided by the folks
from JetBrains the creators of IntelliJ
statically typed wonderful language for
the JVM right it's used a lot in the
Android world for writing android apps
but it's now used more and more in a
Java world Netflix is a heavy user right
so I live in on the Bay Area many
companies they are picking it up it's I
mean it comes with all the let's say the
Skreet credentials off of jetbrains and
it's also very very nice for dsl's right
and we embraced Kotlin as an alternative
to groovy right to scale better when it
comes to ease of use for developers
because of ide support and
maintainability by the built masters
because of navigation between in within
the build large egg and for performance
reasons so um 10 of the
I will be ready by the end of the year
fully statically typed outstanding ide
support it's one of the problems with
greater currently that you don't have
good IDE support when you're right
builder grade on scripts I guess
everyone agrees to that right no content
assist no no no strong aesthetically
type checking no navigation no good
support for build class pass so all of
that is changing its high performing
because it's statically typed and
compiled right it's also very well
suited for developing greater plugins I
want to give you a quick demo
so here we have a hello world
application right and i want to quickly
create a build script with Gradle that
builds this application right and i can
now use full content assets they can say
apply application plugin and hey i have
quick dormant documentation look up you
can say oh what do I do with this
application plug-in right and I see ah I
need to configure the application plug
in conventional objects or boom say
configure application plug-in convention
right and our main class name that's the
property name so a full content assist
right and can also configure Java
plug-in right and again don't need to
look up the dsl reference finally right
I have everything at my fingertips right
and posit orys content assist for for
the whole for the whole dsl right a big
big progress something yeah one of the
biggest wishes of our users to have
better ide support and let's see if that
actually works let's try to build this
thing so cradled let's let's run yeah
hey so it actually works you can
describe your great a built-in Koplin
cortland and you can execute it right
can run it so and the other thing you
can navigate now into the greater source
code right so right that is completely
nude it's not it's it's it's very hard
to achieve today right you basically
have to have to create a source code
checked out to do that right and so and
again the whole dsl including builder
patterns are supported so when you want
to do a copy task let's say right
all supported and there's one other
thing that is very that is very cool so
when you when you want to use an
external plugin and you define that in
your build script section right after
you click Save this dependency in this
case a nebula plugin is downloaded in
the background and automatically added
to your build script classpath and you
have content assist for that right so
after you do that right you specify a
URL and to enter plug-in you can you can
see that there is now the resolution
roots plugin right that is that is part
that is now available in the content
assist okay good so and we still making
the dsl nicer so this is how it will
looks like probably when we have reached
one all right so but it's it's not
dynamic it's all statically typed full
content assist and the same look and
feel then you have for the crew vdsl
just with all the additional goodness
you get okay so another don't have much
time less left I want to talk about some
dependency management capabilities that
are available in Gradle as part of the
bigger crater plugin ecosystem so one
thing our resolution rules very powerful
declarative rules for greater dependency
management right so you can define
resolution rules with Gradle in a
centralized JSON file and you can share
this information across all the teams in
your organization and I think this is a
missing piece for keeping in control of
your dependency craft right so you apply
the nebula resolution blook rules plugin
and there are some default resolution
rules right that their chips with the
resolution roots plug-in and you just
treat that as an as a dependency right
that is that that is downloaded from
your repository and you can add your own
resolution rules right and can also add
them to the resolution roots
configuration and then they are
downloaded and automatically applied to
all the bills in yoga
right and and you can define resolution
roots for replacing dependency so you
can define a company-wide rule whenever
Google collections and guava is used at
the same time kick-out Google
collections because it's superseded by
guava right you can substitute you can
say whenever log4j but to replace rule
means when guava is not on the classpath
then use Google collection right the
substitute rules means whenever you find
log4j for example replace it with slf4j
/ log4j right you can specify minimum
version rules you can specify deny rules
that when this dependency or this
version of a dependency shows up let the
build fail right you can have reject
rules that basically I used when you do
dynamic dependency management you can
let you say you can specify a rejected
dependency explicitly but when you use
snapshot right they will never used as
the latest dependency that the ones that
are rejected you can specify exclude
rules you can specify align rules that
you say for certain set of dependencies
let's say from veggie Jersey right
there's multiple dependencies that
belong together they should all use the
same version right very very powerful
and this is how you define such rules
right you can say a line group example
foo and it means now all the
dependencies of example foo that they'd
have that group ID will use the same
version by default it's the highest
version you can specify other versions
if you want right this is how a replaced
rule looks like right Google collections
replaced with Google guava you can
specify a reason and other interesting
metadata very very powerful the other
thing i want to show is dependency
locking who of you is using maven
snapshot dependencies of the maven users
so they have their downsides that put it
like that right and and with dependency
locking right you can use dynamic
dependency you can say always give me
the latest but you can lock a certain
state of your dependencies down so for
example Netflix but the developers do
they use dynamic dependencies to always
get the latest but they only trigger
that in the morning and then there they
use the dependency lock plug in to tell
gradle hey create a log file with
exactly the versions I have retrieved
right now and I want to use them for the
rest of the day right because I don't
want to get interrupted by continuous
updates of dependencies you can use if
you sign Amik dependencies right you can
create a stable state to roll back to
you can commit log files for
reproducible release build so even if
you use dynamic dependencies right you
can check in the log file into version
control than when you take a release and
that build would be forever reproducible
with exactly that repentance ease that
have to be resolved when you did the
release builds so yeah when you apply
the law plugin you have generate log
update log safe lock commit lock the
other thing another interesting
dimension right is a build script health
and build script maintainability and
there is a wonderful great limb plugin
available right that maintains the help
of your build script it issues warnings
fake it can fail it can warn it can even
fix things that are not okay with the
build script to make it very easy for
the developer so examples are dublicate
layer classes are used in the classpath
unused dependencies an old create a
rapid version and you as a build master
can configure whether the limb plug-in
should warn and should fail and when I
developers get a warning or failure they
can run cradle in fix and then goes into
the build script source could and fix
this the actual problem very powerful
you can create your own rules right so
you have with rarely a very strong
control right how the build scripts are
evolved by the developers right because
often people say with greater you have
so much freedom well you have also
freedom freedom to be very strict
finally I I want to quickly mention
another important part of build
scalability created cloud services and
build scans right this is a service that
connects that collects and connects all
your built data in a centralized service
whenever you run a built right ci or
local the built metadata right which
tasks were executed which dependencies
where use which tests were run how long
did it take what was the memory
situation they are all collected and
sent to this service right so you can
use that to efficiently collaborate on
build problems you can use it for to
analyze to continuously optimize
feedback side
of your building quality of service you
can collect your own custom values it's
deeply integrated with Gradle learn more
about that at cradle calm or come to our
booth for a demo and yeah I hope I could
show you what a powerful build platform
Gradle is right so if you're not using
it yet have a lower look right a lot of
innovation is happening I think cradle
has the potential even if you're using
it with the new features or if you're
not using it and think about migrating
to it it has the potential to
significantly and positively impact your
organization thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>