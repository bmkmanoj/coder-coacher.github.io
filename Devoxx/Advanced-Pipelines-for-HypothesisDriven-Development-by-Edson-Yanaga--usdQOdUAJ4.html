<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advanced Pipelines for Hypothesis-Driven Development by Edson Yanaga | Coder Coacher - Coaching Coders</title><meta content="Advanced Pipelines for Hypothesis-Driven Development by Edson Yanaga - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Advanced Pipelines for Hypothesis-Driven Development by Edson Yanaga</b></h2><h5 class="post__date">2018-03-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-usdQOdUAJ4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello boxed Vienna it's a great pleasure
for me to be here again in this
beautiful city in fact I can tell you
that Vienna so far is my favorite city
in Europe so you have a very beautiful
city very nice place so that this why
I'm I'm twice as happy to be here
because you have this great conference
in a beautiful city my name is ed
ciénaga I'm a director of developer
experience at Red Hat my tutor hand is
Atiya Naga just in case you want to
follow me I talk a tweet a lot about
DevOps microservices Java software
craftsmanship and other stuff and today
I'm going to talk a bit about advanced
pipelines for hypothesis-driven
development because we want to make a
step further I believe that we we might
have already overcome the discussion
around DevOps and continuous delivery so
we might be able to take the next step
further more advanced at pipelines I'm
also a Java champion and a Microsoft MVP
which used to be a weird combination but
this day as well the word has changed it
a lot but so far I think it's as Google
can tell me and still it's still unique
combination I don't know for how long
and since we're discussing I have to
have the discussion about DevOps and
micro services because I need to get to
you too to the point and why are we
using DevOps tools and automations and
processes and why are you using micro
services to be able to achieve something
and in the discussion about continued
living in the past 10 years we've been
discussing about continuous integration
how can we automate our processes to
take some steps out of our way for us to
be able to simply deliver software into
production in a predictable way so but
and and in all of the teams that I've
been talking to about continuous
delivery and and everybody if everybody
believes that continuous delivery is a
good thing and we want to deploy
software in a faster pace so but I've
always visited teams and their number
one X
Q's that they always give to me when why
can't you deliver faster is that we
can't deliver faster because every time
we deliver some four into production we
break things which means that we have
too many bugs into production and since
we have too many bugs into production
when we make new releases of software we
need more time for testing but people
don't realize that the more time they
have for testing the more time have to
code and the more they code usually the
more bugs they have so instead of
releasing software every month they'd
start to believe every two months and
then later realize that we have we have
even more bugs than we had before when
we're leaves in just one month that's
the traditional human way of trying to
solve the problem of bugs into
production and that's the anti-economic
way we can do better
so the economical way of trying to solve
this problems of bugs into production
and trying to release things faster is
trying to reduce what we call a bad size
and technically a bad size in the devops
world to give you a complete scenario i
would say that bugs in production
usually are caused by changes between
each one of our releases and these
changes can be in compassed in three
different areas you can have changes in
behavior which means you change it codes
you can have changes in States which
means you change data or you can have
changes in your environment which is the
the servers or the configuration that
you have in your environment in which
your application is running so
technically the bed size between each
one releases is this amount of three
things I want to operate simplify this
concept a bit I'd like to say to you
that what causes bugs in two productions
between each one of releases are changes
in code so we'll oversimplify a bit and
the more changes in code that you have
between each one of your releases the
more bugs you have interpreting to your
production environments so that's the
human way of trying to solve that the
economical way is that instead of trying
to increase the amount of changes we're
going to reduce the amount of changes
between each one of our leases so we can
have fewer bugs into production when we
release software right and why is that
because we as humans
we need to improve the feedback loop in
our software development process and to
be able to improve that we need
something called context and for me
context is the amount of information and
at the amount of time that you can hold
this information in your brain because
we as humans we are very good in
establishing correlations if we have the
the right amount of context in our minds
so if I have if I do something and I get
this result I'm very capable of stablish
a correlation well I did this this went
right or did that it went wrong but if I
have too much information in my mind
it's hard for me to establish context
because well I changed a lot of things
how do i establish it what thing in this
is a huge amount
did I change that led me to this just
this result so it's hard for me if I
have too much information from me to
establish relation and again if I hold
this information for too long like if I
did something today and I only getting
the result of these things in the
production six months later it's very
hard for me to establish this
correlation so for us to be able to be
to deliver better software and safer
into production we need to have the
right amount of context in our minds the
right amount of information and we need
to hold it only long enough for us to
establish this correlation that's why we
need to reduce your bad size that's why
we need to develop software faster and
this way we'll be able to have fewer
bugs into production when we release our
software okay so that was the basic
discussion about DevOps so far and so
the main goal all of this develops in
Microsoft discussion that we had so far
was to try to reduce the risk of
releasing a new version into production
so if you're not yet into this astaire
plaque I think I already have a fully
automated software deployment pipeline
maybe I parted as the driven development
is not for you yet because you need to
achieve this point and is that the risk
of the releasing software production is
very low up to the point that you can
establish this
relational easily I did this I'm getting
this result introduction and if I broke
something it's very fast and very easy
for me to just spot the cause of the
bugs fix it and release a new version
into production so teams that have
sufficiently advanced much advanced set
software deployment pipelines they
usually don't even have a robach
strategy because it's much easier for
them to just roll a new version forward
fixing the bugs that they just created
into production so that's the the
baseline that we have on the discussion
about DevOps continuous delivery
continuous integration and something
else so far we just aim it at producing
risk now we reach to the next step and
if you think about this continuous
deliveries pipelines traditional
pipelines so far always folks on the
nernst next version so a traditional
pipeline could be seen like this if I
have like a version 1.0 I'm coding the
next release next release will be 2.0 it
will be better than version 1.0 you will
have fewer bugs if you have more
features and we will improve my business
results then you start coding the next
version 3.0 which again will be better
than the previous one so your path
between your versions is clear you're
always getting the requirements from
your nernst version your coding and
releasing that into production so your
your your trunk always goes forward so
this is a traditional pipeline and in
making an analogy about traditional
pipelines you can think about
traditional pipelines as if you're you
have a restaurant you have a buffet and
you in you have like all of the recipes
for the mousse that you want that you
need to cook you just cook all of them
and deliver that to production so your
users or your customers can start to
consume your food but if you ever went
to a restaurant you can quickly check
and ask us that well some dishes that
people like more than other ones so you
have to keep refilling that's that
recipe more often why are some recipe
usually known don't get consumed that
often for example broccoli and not
they're like nice stuff usually they're
left behind I don't know if you guys are
fans of broccoli or not in Brazil were
not usually fans of broccoli and
zucchini and other healthy things right
so you have some dishes that people
leave behind and other that people
prefer so you have this imbalance but
still if you're at the kitchen you have
the whole cook to cook the whole recipe
of broccoli or zucchini or our eggplants
and deliver that the be fair because or
else you don't have a full release right
you need to have all of the beef if
fulfilled to get a successful soft
release even if people are not going to
consume everything right this is
traditional software deployment pipeline
so when we're talking about
hypothesis-driven and developments we
can think it about it differently so
even if you're in the kitchen and you
want to cook things to your users to
your customers maybe when we're
discussing about hypothesis driven
development instead of trying to fill
the whole buffet you can just start to
create in small plate small dishes that
you can deliver to your customers and
instead of having to try to fill a whole
pan with your recipe maybe you can just
given a trial to your customer to check
if they want the food before you do
everything so if they don't want the
food you don't waste your time producing
that recipe right you can quickly switch
to another recipe that might be better
appreciated by your user or your
customers so that's one of the analogies
that we have and we're discussing
hypothesis driven development and when
we make this analogy I'm pretty sure
that you might be thinking in our mind
well if what but how that how does that
translate into code and we free thinking
about the code well if I might have like
two different things that I want to
deliver to my user into production and
he might he or she might like one or
dislike the other the best the easiest
way for us to think about
can we materialize these hypotheses to
code is to create of course a branch so
the first strategy that we had to create
hypothesis driven developments as well
we have version 1.2 0 now we want to to
assess this hypothesis I'm not sure if
users will be happier with with this
feature or these other feature the
classic example that people give is like
if I change the color of a button they
know I don't know if I'll sell more if
the button is red or if it's orange
which in my opinion is a very poor
example but it's it's nice for
simplicity because most of the times the
greatest improvements are in algorithms
so maybe you want to change your
recommendation engine or maybe you want
another algorithm for processing
something that you lead you to better
results but again when you do create
students and hypothesis a or B you're
not sure which one will be better into
production so maybe you just create a
and B you have two different branches of
development but version they didn't
perform that way on to production and
you want to go on with version B so we
have like two feature branches and again
a feature branch in used to be the
default way for you to perform what we
call a be testing and some people
believe that a B testing is very similar
to like blue-green deployment and
conceptually in the server side they
might use the same architecture but I
think one of the main difference between
a/b testing is that we are monitoring
some behavior from our users and
customers we basically blue/green
deployments again Bluegreen deployment
is a terminology from the DevOps word
until now and the go of Bluegreen
deployments was to reduce risk of
releasing new soft release in the
production so I perform a Bluegreen
deployment because the new version might
fail so we're not discussing about that
anymore we believe that our releases
won't fail now we want to know which one
will perform better so we need to
monitor behavior and of course
I'm not talking only at talking about
the statistics about uptime requests per
second or something I want some behavior
that it's meaningful to our my business
how much how much transactions
successful transactions per second how
much money I'm making per minute per
hour per day so this kind of discussed
some kind of behaviors that we want to
monitor and discussing about this
pipelines where traditional grew blue
green and a be testing is not enough I'm
going to show you some advanced
strategies that some companies are using
to be able to achieve these hypothesis
driven development first one is a smart
routing so let me show you a small demo
about that okay you can see my screen
first as as I said I think this develop
the discussion is Rover and you know
that this discussion is over when all of
the knowledge that you have on this area
is consolidated into the infrastructure
platform so as of today we can have a
traditional Bluegreen deployment this is
a console is open ship environments and
if you want to create a Bluegreen
deployment you can easily I have two
different versions of medication running
here and if I want to create and I call
that dump a be testing but there is no
consensus on this terminology so I'm
just going to create a new route saying
a be here and I want to say I'll say
here that I want to split my traffic
between blue and green and I want that
to be 50/50 so if or if I I'm just going
to create that I have a route and here
is coming bloom but you might guess I
hit refresh and it's always blue that's
PI by default open shift is sticky so I
get the new route here well got a green
a blue about another browser got a green
finally so this is basic a be testing
and I say it's dumb because basically
what infrastructure is doing for me is
round-robin
testing it doesn't doesn't know anything
about the clients you just get one
request route to an endpoint gets it on
the other request from another client
and issues to another endpoint we can
improve that because if you want to be
smarter if you want to perform like
great hypothesis driven development we
need to be able to profile and segment
our users so let me close this and for
that we need something one of the
strategy that we can use if you're using
future branching is to use smart Reuters
and we have a smart Rooter basically you
get your clients you pair the smart
Rudin in front of it and you have to
separate deployments with two different
versions from two different branches in
your back-end and your smart Rooter will
future and segments that the the
connections from your clients to the
appropriate back-end so far the most
popular is mark ruther that we have in
the market thanks to Netflix is Zoo so
what I want to show you right now is I
have a zoo instance running here in my
machine and zoo works basically like
this zoo is a very simple application if
you dig into the source code basically
Zoo is an embedded tomcat server with
some libraries for routing and it
dynamically reloads your route
configuration every by default every
five seconds and all are your
configuration is written in groovy
so it's dynamic it just paused the your
folder every five seconds for new groovy
definitions in F&amp;amp;E if anything has
changed it just reloads it works
beautifully on the Netflix
infrastructure because they have a
shared Cassandra filesystem and when
they write something they change any
room
this information was propagated through
the cluster and all of the zoo links the
Siskin data compile the file system and
upload updates their routing
configurations so what I want to show
right now Zoo is running but if you get
here to see my route configuration all
of that I'm doing is that I'm just
routing all of my requests to my blue
employment so if I go to my browser and
I try to access my zoo instances its you
it will always return blue for me but if
I just go here and just switch here I
comment the code I save the file I wait
five seconds for it to be reloaded I
just go back to my browser and reload
and it's green okay forgive me my
machine is a bit uh slow because I'm
running a lot of things and later I'm
going to show each do a surf smash so I
have a lot of things running on so it's
behaving a bit slow so dynamically just
change the routes and okay it's a very
simplistic again example but the
important thing to think about zoo rear
here is that zoo runs Java code or
groovy code in the application layer so
all of the knowledge that you have in
your application layer can be applied
here inside zoo so one of the nice
things that people use here at Zoo in
fact the other example that I had is
like if you have mobile requests come
from an iPhone you can route that to a
purple ruler but as of today even like
dumb routing like from from
infrastructure basic routing can just
get the headers from the your HTTP
request and route that to appropriate
backhand a nice way for you to a nice
thing for you to add here inside the zoo
code is that I'm releasing a new version
because I believe that our service is
performing pulling for a certain segment
of our users and that the female users
ranging from range 2025 that live in
South America I think we need to improve
because they have a different behavior
from my application so we want to test
this new version that I'm releasing
specifically for this target users you
know it's impossible for infrastructure
to have this kind of knowledge but since
you're in the application layer you just
get the user that is logged in you just
get the he her profile on this case you
J and you just point that to the
new deployment that you're testing okay
so Zoo it's just like a way for you to
add some beautiful ifs in your routing
rules to get to your appropriate context
and this is the most popular solution
that we have right now when we're
talking about smart routing which again
assumes that you're doing feature branch
development to different deployments of
your application running into production
now but I have to tell you be careful
with feature branches because future
branches enable back again one of the
huge problems that we had in the DevOps
world that we tried to solve with so
automated software deployment pipelines
we just get in everything back again so
and why is that think about a future
branching when you develop you have
basically you have the trunk which is
the code that goes into production and
when you enable future branching which
is very popular these days because if
you have a feature branch you can just
issue a pull request on github or any
other platform so many people seem to
like future branch these days but the
problem if you developing a project with
future branches is that of course I'm
saying that you already have a fully
automated software deployment pipeline
and you're using all the best practices
for that so even if you have a future
branch you're constantly pulling the
changes from them trunk to your branch
so like future branch a in future branch
beep even though people are coding and
committing to this future branches every
single day or every single hour people
are pulling the changes from from the
trunk even you're not doing that maybe
you not do even doing that manually
maybe your CI server is already doing
that for you right it's constantly
pulling pulling the changes from that
master it's already as acute in the
beaut so if anytime somebody commits
something to the trunk that would
creates a conflict in your branch you
get a you get a broken Butte and you are
notified about that so this is basically
the best practice that we have a future
branches
but the problem with that is that when
you're doing development in future
branch a and future branch B you're
never accounting for the changes if
you're in be your navin accounting for
the changes that people are doing branch
a you're just getting notified by the
changes that people are committing to
the trunk so imagine that you have
feature a in future be
you just keep developing these features
for like two weeks I have a lot of
different commits about that and then
somebody did somebody decide well we
perform an a/b testing in the production
and feature branch B is good enough to
go to trunk so we'll just finish trunk
future branch B it's going to be merged
to trunk what have you just done when
you merge your changes from B to
two-track you created a huge batch size
which consists of two weeks of commits
and you deployed everything in just one
and one time to your trunk
five minutes later people developing
future branch a they decide to pull the
changes and what do they have a huge
conflict and in all of the themes that
I've visited so far when these kind of
things happens the conflicts so huge is
such a mess that they don't even try to
fix it because it would take like three
four days one week trying to solve the
conflicts you just discard all of the
changes that they had they get the
future branch they see what did I change
here and they copy paste the code well
the copy pasting never sounds like a
good approach but that's what happens
when the conflicts so big because you
just created a huge bad size when you
merge it all of the commits from the
from future branch B into the trunk so
this is the one of the main problems
with future branches that we need to try
to avoid I don't know how many of you
have ever tried future branch in
development but it happens quite often
it happens to me of course a lot of
times that's that's why I want one of
the reasons I don't like this kind of
development I prefer to advocate for
trunk based development or if you need
if you still prefer future branching
make sure that your feature branches are
short leaves short leave black one day
or two days most it really depends on
your pace of development but make sure
that they are very small so that your
bed size can can can keep keep short and
when you merge your things your trunk
you don't just screw everybody's life on
that week right
so future branches these are the dangers
so maybe we have another kind of
approach for performing
hypothesis-driven developments and one
of these approaches might be feature
toggles
so feature toggles again is a very
sophisticated name for dynamic if thing
approach inside your code so it's a very
nice name but diplomat issue is kind of
easy and we feature tacos we are doing
trunk based developments and we're
trying to employ one of the the Vagos of
continuous delivery which is we're
trying to uncouple release from
deployments which means that traditional
software deployment pipelines releasing
a new version of software or releasing
new features of software every time I
make a deployment wave feature toggles
we're trying to achieve the fact that
we're issuing multiple deployments and
we dynamically can release the new
features of our users and we can roll
back these features to at runtime and
how does it work so I'll want to show
you here a demo first let me stop my zoo
instance and I want to show here with
codes oops I'll exit this presentation
oh I don't need to do any more no I need
these demo so I created a very simple
spring good application using a future
talk of framework FF for Jane which as
far as research went is the most popular
feature to the framework being used in
the Java world right now
so you use F
4j is very simple has a very simple
configuration all you have to do is just
create an F for J instance if you're
using spring you can just instantiate
the new beam you define everything in an
XML file FF for J dot XML and here you
just declare well I have this feature
called hello it's enabled by default
have the description I have also another
feature which is a new recommendation
engine which is not enabled by default
and I have the description which will be
help this description will be helpful
when I have this information at runtime
so if I go back here to my controller
which uses FF 4j basically just add FF
for J for dependents with the dependency
injection and I get here a check if FF 4
J dot check this future togo hello if
it's enable say hello and if it's not
enable I say hello
yeah ok sorry for my in German so if I
run this application I can just get here
and slash hello I get my result ok
hello so how do I change the information
at runtime luckily for us I can get here
to FF 4j console which gives me this
nice panel I can go here to features and
you see I can have this true future
tacos and it's enabled by default if I
switch off the taco I go here to hello
refresh it what was a very but now it's
in German now it's the right way so and
switch back flip back and it will just
say hello it's a dynamic
by default the f4j destoryed this
information in memory of course in
production you use
database or an in-memory cache like you
finished pan already s or something like
that but for demo reasons is just
showing you here but again switching
strings is a very simplistic example
maybe we can show something more
sophisticated and why did I create I
created a recommendation controller
which basically when you get a request
to that you have a being of type
recommendation engine and returns to you
your recommendations so basically I just
when I want to test you hypothesis I can
just create another implementation of my
recommendation engine interface you see
it's just an interface and if I go back
here for me to dynamically proxy this
information with FF for J I just have to
say F F for J feature new recommendation
engine and F F for J is going to flip
the implementation for me dynamically on
this controller and how do I achieve
that I just have to go to my FF for the
application here I have one instance a
default recommendation engine I just
need to create another instance which is
improve its recommendation engine return
new improve its recommendation engine
and I declared that by default as a
being if I run my application as is
spring will complain that I have to
beans implementing the same interface so
it's going to have a conflict so I have
to tell spring well one of them is the
default and the other one is like a
spare one which is going to be used by F
48 for me to do that I just have to add
annotation which is a spring annotation
primary being is the default
recommendation engine and the other one
is going to be used by somebody else so
I rerun my application here
and it's running real home so if I go
now to my recommendations you can see
I'm showing run right now some default
recommendations which are very poor they
are so bad that he screwed my okay so
burger is sodden hotdog maybe you can
improve this so if I go to feature my
feet ffs or take console and I decide
that I want the new recommendation turn
it on I just get here refresh and I get
much better food right
in fact it's so good nice that I've been
here at Vienna for two days and already
ate this three times so it's really good
yeah you don't know how good it is until
you you're not from here okay so that's
how you dynamically change your beans
using f4j and again up to my knowledge
f4j is the most popular feature taco
framework in the Java world and some
teams are using this successfully but
like everything in life you have
downsides for future tacos one of the
largest complains about feature talk was
that even though it enables you to have
trunk based developments you don't have
feature branches everybody commits the
code into trunk is that some if you're
using the if checks you have like this
distributed if checks spread all over
your code if people are using too many
feature toggles and they forget to
remove the eaves you have a technical
depth that you have to clean up later so
this is one of the complaints and I've
seen that myself in two of the teams
that I've visited is that people don't
realize that when if you have like a
large team and everybody is performing
they their hypothesis driven development
in one team particular I've just visit
that and where they were monitoring the
production result and they were
switching the tacos and well we get
these results we switch it back
getting and odd results then the next
day they do the same they monitor well
we do this and we do that and they get
different results they assume well maybe
it's the day of the week that they run
that there are other week and they do it
again they have different results what
they realize is that in the whole team
developing that that that service you
had you have so many hypotheses being
tested at the right time at a given
moment that you have like 40 feature
toggles being tested at the same time
which meant that no know that their
monitoring was useful because every time
they were flipping the switch you have
like too many flips change it at the
same time that you never get the
something meaningful in the end so since
they did they had a very large team the
solution for this problem for them was
that nobody would be testing more than
two feature toggles at the same time but
how do you do that you have like
multiple teams developing the same
software they had unfortunately to
create what we call a future toggle
governance they had to create an order
hierarchy of the earth of management and
these this layer would say well now this
week we are going to test this feature
tacos and that's it now the other week
we're going to test the other feature
tacos so they need to add like a
governance to be able to schedule the
feature toggles that they want to test
not the ideal solution but that's the
way that they solve it is the problem so
far if you're using future tacos and you
have two months too many people messing
around with the same codebase you they
added some I'm layer of governance and
the other solution for this problem of
trying to perform hypothesis driven
development is that today we can think
about using a service mesh and all
service mesh this might be a new concept
for many other for many others in fact
in this demo I'm going to use SEO as the
service mesh as of today SEO is not even
production-ready but will be very soon
because we have many companies investing
on that companies like Google Red Hat
IBM
lift and other many other companies to
investing in the source code of of vicio
so it will be soon it will soon be
production ready so basically in I don't
want to explain it because it's a long
explanation but basically what you can
do if you have like a lots of services
running into your infrastructure you can
add some kind of layer for governance of
the relation between each one of those
services so if you're concerned about
distributed architectures one of your
concerns probably is tracing you want to
trace how our request comes from one
node goes to another node then it
follows and when it comes back how long
did it take in each one of the nodes and
the traditional way of doing that is
that you need to instrument each one of
your endpoints to propagate the tracing
information with each toe you can there
are two different approaches for that
I'm going to describe only one I'm going
to describe the sidecar approach you
have the node proxy approach but I'm not
going to demo for you that today so what
you have is a sidecar approach is that
if you're using a platform like
kubernetes which has the notion of pods
every and if you have in your port you
have your application instance running
you can add another container inside the
same pod and this container will
basically proxy all of the incoming and
outgoing requests from your application
and what this proxy does well in the
default is implementation you're using
an invoice proxy which is a project open
source project contributed by lift which
is very small very fast it's implemented
in C++ and in each one of the instance
of application you have a sidecar
container called invoice it if you want
to add tracing and voi intercepts the
inbound requests ads the ads the trace
information to your backends then in the
outgoing requests and voi again to
intercept the request and that's the
tracing information for your tracing
server so you don't have to change a
single line of code you just go to the
East your configurations
as well I want in all of the instance of
my application to have sidecars that
your proxy and that trace an information
this is one of the things that you can
do but it you can also add like circuit
breaking a traditional way of doing
performance secret braking is add the
secret breaking your code if you think
about that it's just a distributed track
catch that's the traditional way east
you can add the distributed secret
braking can add retries king at pool
ejection can can insert thoughts if you
want to create your own chaos monkey
east you can inject faults in your
system to check how your system behave
how resilient is that but talking about
hypothesis driven development the
feature that we instead interested in
the issue implementation is mirroring
because we want to perform some some
hypothesis driven development but we
want to play on the safer side I don't
want to release a new feature in
production without assuring that it will
behave very well without impacting my
sales or even if I don't want to reach
up to this point I can like a mirror my
deployment and just check the statistics
for and for this mirror deployment to
check if I would have a successful
output of that and how does it work so I
want to show you first before discussing
data so if I go here to my openshift
instance I had like three different
services customer preference and
recommendation and I have two different
versions here I'm using future branching
because I have two different deployments
in my back-end
I have recommendation one and
recombination two and sorry for this
poor interface but it's all tax based
and if I ask you to occur here you can
see that by default openshift will
round-robin my request between the truth
months but what I want to end if I
decided to let me grease oops my font
size here if i have two different
lamentations what i want to show you
today is that I have this guy let me
check the log Stern recommendation okay
so if you can see the logs I'm receiving
requests my counter is increasing 62 66
and let me just stop here I'm going to
create an easier rule saying that I want
to mirror I want to mirror all of the
requests from my version one deployment
to the version two deployment so version
2 will be out of production so all of
the requests will go through version 1
and version one will produce the results
that will go into production but in the
east your proxy will they invite proxy
will generate a copy of the request send
this request to the version 2 and will
forget so it's a fire-and-forget
approach it just sends a request to
version 2 and forgets about that so this
is what you do is your desk so if I do
this I just created here and if I occur
again my service you can see that I only
get replies from version 1 but version 2
is still getting the requests so
requests are being sent to version 2
button being from product from the
production point of view all I get I
request from version 1 so this is the
first thing that enables
hypothesis-driven development with with
mirroring so I might be thinking how
useful is for me to get a mirror if I
don't get to check the results of the
outcome of this new version 2 okay so
what i'm what am
to discuss right now is like a bleeding
edge is what people were thinking about
today and what like many startup
companies are implementing first
discussions what about my data because I
have a new production a new version or
two different versions running into
production and they are accessing the
same data base the same data how do I
handle this if one of them might not be
performing well for example so one of
the approaches that you can do for that
is that you allow both versions to be
running successfully into production and
I've described it's some of the
strategies that you can do with that in
my in my book in fact chapter 3 handles
how you can have like two different
versions of your application regarding
to database schemas run into production
successfully at the same time if you
want to get a copy of the book it's in
the URL or at my Twitter profile but if
you want to perform further analysis of
mirroring is that I've done that before
like you mirror a service then what do
you do to ask to to to assess their as a
result of your of your new version you
just get your production database you
restore a backup in another instance and
this version 2 points to the the copy
database then you just check well just
open your database CLI or or your
application and check if the data is
being written correctly or if it's
giving the results that you would expect
the problem if that is that a witness
myself is that creating this copy
database takes a lot a lot of time of
working like in an environment that it
took me like 12 hours to be restoring a
backup to be able to perform this kind
of testing and so it took a long time
and you run for some time you check that
well and as the day goes by the the the
databases they differ so much that by
the end of the day it's not possible for
you anymore to to assess if the data is
being written correctly because too many
productions transactions went here and
here I made some fake transactions too
so I can't compare in a meaningful way
both datasets so
one of the solutions that we are
applying trying to apply about that is
to add a virtualization layer so you can
that's the proof of concept that we're
working right now if you add a
virtualization layer like to eat they
eat cancel you can create you can have
your production database and you create
an empty deep database which will only
have the requests the results of the
requests made in the and and the version
true application so if you any inserts
updates and deletes we will only be
recorded on the deef database and in
this way you can get your requests they
can be processed on both backends and if
your new version is processing the
request in a different way you can just
compare and see the results we get
because the the diff database if you
carried that through the virtualization
layer it will still contain all of the
production rose plus the diff rows so
it's a much more efficient way for you
to compare the data in both databases
this is one approach for you to solve
the data problem and another approach
which is like very new there is a
project that was recently released by
Twitter which is called DV in fact
Kristin pasta and Alex Soto which just
gave a presentation earlier this morning
for you they they written a blog post
about using defeat to compare different
versions of your services running
production using mirroring and basically
what defeat does is that even though you
can't see the results of your mirrored
instance into into production
DV gets both results it sends the
request gets both results and compares
the results from version 1 and version 2
and then logs it it into its database so
you can compare well version 1 is give
me this result version 2 is giving me
these results and then logs it in greens
database so you can compare the results
of mirrored services so this is another
thing that is brand-new people are
working on that right now
and another discussion is what about my
other services it's
as mirroring is simple if you just have
like the final endpoint but if you're
mirroring a service that that is
invoking other services the scenario
gets more complicated and the solution
for that is many people are using
service root religious virtualization
for that which I don't think it's a good
name for what they're doing they are
mocking like back-end services in the
mirrored service
I would prefer market services but then
I just realized that service
virtualization was a term coined back in
the ZOA world so it is a term that has
like 15 or 20 years and we're just
reusing the same term here now that
we're talking about micro services and
service and mirroring okay and that's
what I had to show you today again most
of the mirroring part is brand-new
feature branching with smart rulers and
future turquoise something that people
are already using the production
mirroring is something that's that is
being regarded mostly inside in startups
and unicorns or companies like Twitter
Facebook and this kind of which have
like very mature deployment pipelines
but that's what I had to share to you
we're discussing all of these and we're
publishing a lot of this information in
in the developers dr. breadhead comm
website and thank you very much I don't
know if we have time for questions but
as you know if nobody kicks ours out of
here
what's the overhead of envoi and if I
can use invoice to monitor that that
part of me is outside connections like
to other other end points outside the
cluster okay by default if you use Oh
first first question is that how is the
how much is the overhead of envoy so in
our test invoice has a very low latency
it's a very small sidecar implementation
using C++ but it's a network round-trip
right so it's a it is as as small as it
can be considering that you have another
round trip inside you're inside your own
localhost okay
and for memory wise I think envoi
consumes like 20 or 25 megabytes of RAM
which is pretty small compared to a JVM
but that's something that you might
consider if you have like 300 instances
running to production you have 200
copies to of your my proxy and if you're
really in East Europe by default the
security model of Eastern boy is the
invoice all outcoming connections to 20
endpoint outside your your cluster so if
you want to allow your application to
perform outbound requests or to to note
outside your cluster you have to go into
the easter configuration and ask envoy
to explicitly I want to allow request to
this domain name or these IP addresses
so yeah this is the way that you can do
it today
yes you can use it as an outbound
firewall application for anything
because again Easter is agnostic of
implementation is it sits on the network
level so you can use it for Java Ruby
C++ Python PHP anything that you want
any other questions
tacos e okay I've tested tacos in myself
but I would say I've only visited I
think three teams that were using future
tacos and with Java and all of them were
using FF for J and in my last project
before joining Red Hat I asked this at
some future talk of frameworks too and
at the time was two years ago I we our
conclusion was that feet F F for J was a
bit more mature but I don't have like I
can't make a statement right now because
it didn't look at back at o cozy in the
past few years so I don't know if
anybody knows the tacos the maintainer
maybe it's even more advanced than f4j I
just can't answer for that now in other
questions
No thank you very much again
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>