<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Cloud Native Development by Michael Willemse and Stef Ceyssens | Coder Coacher - Coaching Coders</title><meta content="Cloud Native Development by Michael Willemse and Stef Ceyssens - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Cloud Native Development by Michael Willemse and Stef Ceyssens</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2Gu2nuPs3Xo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon everybody welcome to this
talk about native development where
we're going to have a talk with
demonstration about several services
that work very well together on the AWS
platform and we're going to discover a
couple of patterns that also work very
well together on it let's first start
with Steph yes so in the past years I
have been working on as an AWS developer
and architect for enterprise companies
and also for startups yeah hi I'm
Michael Thompson and I'm also have the
experience of two years of an address
developer and architect several projects
starting from startups up to enterprise
companies let's give a small word about
explore group a company where we work
for so it's a company that is
specializing in the e-commerce field and
also the custom development feels mostly
Java and nowadays doing things on the
cloud is very popular and very efficient
so that's why we're running a lot on AWS
so during this talk I will give a brief
introduction of how we see cloud native
development and we'll talk about just a
five-minute crash courts about 800 s and
then just get on with it so most
important thing is that you create a
scalable and distribute the system which
means that regarding the true but it is
required for application you have enough
capacity and you can scale to that
capacity that's a very important you use
managed services provided by the cloud
provider that you are using that may be
a single provider if you're on a single
system or that could be an abstraction
layer like openshift sings on earth and
very important that
to architect things so that you pay by
the usage costs and not keep things
running if they don't need to be about a
SS web services basically it started off
as Amazon and they saw that during the
course of their development as a as a
service based company that they could
abstractor service the services away and
that they could reuse their services in
different parts of the company so that
means that they could also after a while
publish these those api's and let
external users use them that's when
systems like s3 which is an object
george n SQ s which is Q system started
right now it's available in several
geopolitical areas across the US Europe
Asia and the set of America in the
Pacific so basically everything is
splitting availability zones
availability zones basically as a set of
let's say infrastructure network
capabilities that they have data centers
and so they allow that within a single
reason they have a high available system
and we're going to use these services as
is without knowing that they are
distributed so several of the cloud
native services they have regard we're
going to split them up into different
components first part is to compute
parts so here we're going to talk about
lambda which is basically a function as
a service who here has used or heard of
lambda already probably near nearly the
whole room I guess then we're going to
focus as well on container development
on line 80 s and lastly we gonna con
we're going to focus on the platform as
a service elastic Beanstalk there
regarding storage we're going to quickly
pass by the object store s3
no sequel database system DynamoDB and
for sequel sequel service we will have
the RDS service regarding queuing and
streaming we're going to talk briefly
about SQS and Kinesis which is a
streaming solution that they have and
all about the different subsystem of
Kinesis other that's basically what you
have with each application you can have
glad watch which allows you to monitor
and have centralized logging within your
applications I am is something that's
always there it's anti access management
on a dress and API gateway is an
interesting service that goes well
together with with a serverless
architecture let's first talk about
something we're not going to talk about
ec2 so we're not going to talk about
virtual machines today let's start it
off with the easiest solution to get
start with which is a elastic beanstalk
so basically from that solution you get
a scaling on a single metric a system to
allow rolling updates and health checks
and since a couple of months you can
have immutable deployments on that on
that system so it allows you to set up a
basically a fleet of incest with a new
version before changing back so it's a
very easy platform to deploy on the
other flavor of elastic Beanstalk is a
worker instance which allows you to by
exposing an API to handle queues handle
a single queue and the platforms that
are available on elastic Beanstalk
basically range from Java itself where
you can easily run spring boot for
example right and in tomcat and the
whole lot of other things including
doctor
I will give a brief demonstration about
the elastic Beanstalk just to show you
how how easy it it is
so we're going to start it off by
creating a new application let's call it
devoxx just five I prepared a few
already just if this one fails let's use
just a web server and a platform we're
going to take a tomcat application
server and we're going to use the
default which is a load balancing auto
scaling environment type you can then
choose the binary that you have
available already the other settings
aren't going to keep them on default I
think I just want to put the emphasis on
how easy it is to deploy something in
the cloud but i was thinking stock so
all right let's give this
alright so this one is I now giving an
overview of all the settings I'm going
to launch it takes around five minutes
but i already have another environment
which we will go we are going to use
later on in the in the next demos with
just to give you an idea it should be
giving a simple hello defects again back
to us
all right I'm not going to give the word
to stuff about easy to contain serves
another very interesting service of AWS
is of course the ec2 container service
it can be used to run docker tasks on
AWS first I'm going to explain how an
ecs service or an ecs cluster is build
up an easiest course we will contain one
or more ecs instances which are just
easy two instances but they are built
using a special Amazon machine image by
doing this we have a doctor agent
running on it and we can start talking
task on it which is of course which is
the need of course next we have the
easiest service as you know or you may
not know honest yes you can have long
running task and you can have short
running tasks so a short running tasks
you just start the task after a couple
of seconds a couple of minutes it will
stop but for a long running task you
want to make sure that the task is
already all always running so this can
be done using an ecs service the ecs
service will look at the desired count
of tasks that you define for example 3
and then it will make sure that there
are always three tasks running in your
ecs cluster next such a task is built
using a task definition and in the task
definition you can have one or more
containers that are linked together next
I'm going to demo shortly how you can
scale your ecs service on AWS so we are
going to use an ecs service that will
manage a reader that reads messages form
a queue of from a queue and you also
have writers which are
short running tasks that will write
messages to the queue ecs service is by
default publishing matrix to clog watch
metrics those metrics are cpu usage and
memory usage for this demo we are going
to use the cpu usage and based on that
metric we are going to scale up or down
so you will see when multiple writers
are added to the system so the messages
on the queue will come well there will
come more messages than one reader can
process you will see that gradually the
ecs service will be scaled up and we'll
start other readers to manage the amount
of messages on the queue so I'm going to
show that right now
first of all I'm going to my ecs cluster
and I'm going to just run some more
tasks let's say eight of them if you see
that I need to define a task definition
so there's also as you can see we have
multiple task definitions one is an ask
us reader but now we are trying to
launch SQS writers so if I open this
distorts the definition you can see I
have multiple revisions of it and I'm
going to use the last one
then I run the tasks and you will see
that they are pending and in a couple of
seconds they start running so right
right now we have a task pushing
messages to the SQ sq and we will see
that the ACS service which is which can
be found here so it's the SQ s reader
service it currently has a desired tasks
of one and running task of one also if I
dive into the ACS service you can see
that for example no load balancers or
nothing else is configured it just uses
one task definition that defines the SQ
s reader task so this is an example
about of a talker task definition you
can see that you can define the amount
of CPU units and the amount of memory
that's the task may use of course an ec2
instance as a limited amount of CPU
units and memory available you will also
see that the image that will be used to
create this docket task the image will
be retrieved from ECR which is also a
service on AWS it's easy to contain a
registry and there you can host your
docker images another interesting thing
we can see here is that we can define
environment variables that are task will
use
so we see that the service has not yet
skilled up again but i will continue my
my next slide because i'm going to do
another demo and then we
so next to running just tasks on AWS
that well check a queue or write to a
queue you it's also possible to run AP
ice on ecs since a couple of weeks there
is a new service on AWS gold application
load balancer which is very useful when
you are running an API on ecs before you
had already an astral elastic load
balancer but the problem with that one
was that it will always load balance to
the same port of an ec2 instance and of
course if you have two of the same kind
to AP is like to product AP is on the
same ec2 instance that's not possible
because they both try to use the same
host port with the application load
balancer this is different in your task
definition of your API you can define a
container port like a DAT but you don't
define any whole sport the sport will be
set for you and the application load
balancer will load balance between those
ports this of course makes it very easy
to to scale a certain part of your API
and you do that by dividing them in and
target groups so we have one target
group for the user API and one target
group for the product API and this is
also something I'm going to show let's
first of all see if my previous demo
expert so yes right now you can see for
the SQ s reader service the desired
account is on too so it scaled up and
now two tasks are getting messages from
the queue and processing them
now for for my API demo I have two
services defined one is a pro API
service and one is the user API service
i'm going to start them right now so the
product AP i am going to give two tasks
and user api and giving one task what I
did to show you that is it's effectively
load balancing as i define the unique
uid / task so if i now use the host or
the domain name of the application load
balancer
so this is maybe something that I didn't
say so you have talked to target groups
you have a user API you have a product
API and the load balance will know based
on the path which API to call so
everything under / product will go to
the product API and everything under /
user will go to the user API so in this
case we have a product API which we are
using and you can see that we have that
we r load balancing between two darker
tasks because the uuid is changing
between two tasks to Stefan to you IDs
if I do the same for the user API you
will see that you ID will always be the
same because there is only one task
running for it
next service I'm going to talk about is
lambda functions which is also a very
popular service nowadays on AWS the land
of service allows you to upload a small
piece of code written in one of the
supported languages and that code will
be executed based on an event or you can
trigger the code by yourself in another
part of your application one important
thing about lambda lambda functions is
of course that it's service and it
scales transparently you don't have to
manage manage any infrastructure it's
all always done for you by AWS which is
of course one of the reasons that it is
a very popular service what you can
configure in a lambda function is the
amount of memory that we'll use and
based on that amount of memory also the
CPU power of the lambda function will be
calculated by AWS in to give an example
about the the pricing so if you create a
land of function in your account it
doesn't cost you anything it's only when
you start invoking the lambda function
that it will start costing you some
money the amount that you need to pay
per invocation or per amount of time
that the invocation lost is dependent
also on the amount of memory that you
define in the configuration I have an
example written down here for 1 million
calls to a lambda function that take on
average when each in vocational average
takes one second then and it's and you
have the 512 megabytes of memory probe
agent that will cost you about six
dollars so six dollars for 1 million
seconds of
processing power which are the supported
languages you have Java 8 by 10 0 GS
there are of course a couple of limits
on AWS lambda being that you can all you
can only run a land of function for five
minutes and you have a limited amount of
disk space that you can use next to the
pricing and being serviced and
event-driven it's also a very popular
service because it really easily
integrates with other AWS services and
these services we will talk about in a
few minutes maybe one thing that's not
on the slide but that's very interesting
is that you also gran creates a lambda
chrome which means that you can just
give a gather chrome expression and for
example the land of function will run
every hour or every 24 hours also I want
to shortly show you how to write a
lambda function in in Java I don't know
if it's if you can see it however what
you need to do is you need to implement
an interface and then you need to
override a method and this method you
can define as parameter the class of
what you expect to come into the lambda
function or you can define an input
stream and do the mapping yourself
next service is cloud watch so close
watch is used to do centralized logging
and monitoring the applications on AWS
they contain multiple service multiple
lambda functions multiple docker tasks
and it's it's really necessary to have
centralized logging you don't want to go
to every server to pull the logs and to
go to all the logs so using cloud watch
you can you have a centralized view on
your locks and you can also integrate
cloud watch with lambda functions to
index your log statements into for
example an elastic search service that's
of course very useful when you have for
example different lambda functions
trading each other and directly and you
want to follow the whole flow of of the
data next is monitoring there are a lot
of services of AWS that by default arm
putting metrics to cloud watch metrics
like CPU usage the number of messages on
a queue memory usage and search and for
example this is the image that we are
showing are the metrics of AWS lambda
which as the duration of of the lambda
function and also the number of
invocations next we have the database
services of AWS DynamoDB is a no sequel
database created by AWS itself so it's
really created for the clouds it's
really scalable it's can scale to until
infinity almost and it's also almost
completely seamless so you of course
need to define for example a primary key
to grab your data but the rest of your
the rest of your DynamoDB tables it's
Han Solo scheme honest also a nice thing
about dynamodb is that it's also
infrastructure less actually if you go
to the AWS console the only thing you
see is tables another important and very
useful feature of dynamo DB is dynamodb
streams with dynamodb streams you can
for example trigger a lambda function
when an item in dynamo DB has been
updated created or deleted this can be
for example used to update your caches
or something like that next we have the
relational database service of AWS there
are a couple of database engines
supported by AWS like Oracle postgres my
sequel Mario DB and also sequel server
RDS makes it very easy to set up a
database which is Isis available which
is easy to backup and you have of course
the replication over availability zones
which you also have with dynamo DB of
course one of the database types I want
to focus about focus on a little bit
more is Aurora Aurora is again a
database a relational database that's
created by AWS again really made for the
cloud made to be scalable and also
because it is created by AWS it also
integrates with all our AWS services
like for a for instance a lambda
function can be triggered from an Aurora
database next to databases you also have
object storage on AWS being simple
storage service or s3 you can create a
files there of one bite up until five
terabyte s3 when you start using it you
have to define a bucket in which you can
create a whole folder structure one
thing about the bugs is that a bucket
needs to have a unique name globally
another very interesting feature about
s3 is that you can create a static
website on on s3 Michael is going to
talk about that a little bit more and we
are also going to see a demo another
thing which is can be compared to
DynamoDB streams but then for s3 gold s3
events you can also trigger a lambda
function when an object on s3 is updated
created or deleted one of the use cases
for this is for example you you write an
image to your s3 bucket then a lambda
function will resize the image and will
write it to another folder or another
packet and next Michael is going to talk
about SQS and gang Jesus Thank You staff
regarding queuing and streaming the
first one we're going to talk about is
SQ s simple q service which is one of
the oldest services available on a Lewis
it's scalable without interference from
you required and it's easy to integrate
with the elastic Beanstalk or worker
instances mentioned mission to earlier
so its features are that the dairy try
is item based for every item you put on
there just like a classical q there is
retrying it's compatible with JMS as
well so you can scale it by the amount
of items on it for example those metrics
are available in in class watch and due
to being
cue system with getting single items
there's only one process of course it
get worse as a single item when we're
switching to karnazes which is a classic
streaming solution the retry stream
based so you basically get a get a point
of that stream and if you're handling of
that fails when using lambda functions
the retry time is at that moment of the
stream when you're using other systems
such as spark you have to manage that
time in the strain yourself of course
and the order in this case is important
than you have to choose a hash keys for
that and multiple consumers are
supported some more specific solutions
that we can kinda see service provides
apart from kindnesses streams it's kinds
of fire hose so basically you the 80 s
service exposes an API where you can
send data to for example clickstream
data from a website and this data is put
on s3 by by configuring kindnesses fire
hose so that it's drops the data like
every minute or every 50 megabytes so
that really helps when creating let's
say an entry point for a continuous
stream of data from multiple sources it
also scales transparently so you don't
have to manage manage that gynesis
analytics is a newer service that allows
you to run queries on can easy streams
so you can aggregate the data within
that within a specific time period and
you can just run sequel queries on it on
the on the data a service which I'm
going to demo together with with this
tree is API gateway which let's say
empowers the serverless way of doing
things on label us
so basically behind the scenes it's a
combination of different services it
starts with a cloud front which is the
CDN solution of AWS you have inbound you
have building totaling mechanisms in it
and there is some sort of D dos
supported row before the request that
this sent to API gateway I get sent to
your back-end services or lambda
function you can have velocity
templating so you can adapt the the
message you also have that support when
sending the response back to the to the
users so we could for example create a
compatibility layer with its if needed
just as a quick overview of what I'm
going to demo next so we're going to use
as three as a static website provider
and the few API calls that we have we
are going to use API gateway to route
those requests either to lambda
functions directly or to an elastic
Beanstalk instance
so on the API gateway service you have
overview of the api's that you have
deployed on the service in this case
we'll take the hello world service
basically the first unit you're going to
use when configuring this application is
you're going to have a resource view
with a with a standard hierarchical both
like any rest service and in this case
we're going to look a little bit deeper
into the elastic Beanstalk HTTP
integration and the lambda integration
so the first step is that you have to
define a method and in the integration
request you can get data from URL
parameters in this case it you can get
query string parameters you can get HTTP
headers that are being sent through and
basically in this case what we're going
to do we're going to use an HTTP
integration to send that request to the
backend URL from our demo environment so
in this case it the request will be sent
through as a whole and it will be
handled by elastic beanstalk then return
to API gateway and then sent to the to
the user now this doesn't make too much
sense when you're using a sadistic
because you're using infrastructure
anyway but when you're using lambda
functions you can basically just have a
lambda integration call a lambda
function specific lambda function and
sent requests based on the input
parameters that you received originally
so in this case we're going to build a
JSON object with a parameter it based on
the input parameter it which will take
either Heather query parameter or a path
parameter automatically
because most of these api's are going to
be called from browsers using a static
website the domain obviously is going to
be different from the API domain so you
have the option to automatically
generate a cross origin resource sharing
configuration for the method and it will
be configured that is obviously with
default default settings this
configuration can then be deployed as a
stage in this case we have the
production stage and every stage has
specific settings that it can either be
configured to add the whole API level or
for a specific endpoint so one of the
more interesting part is that you can
enable throttling with a specific amount
of requests per second you can also set
up this rattling for specific API keys
that you grant your end users so you can
have a built-in total mechanisms for
specific users also built in isn't as
the gang generation for android java
script and iOS which can be handy to for
rapid development and very good
integration for for example sending it
to test tools you can also generate
llamo swagger file basically it's just a
standard swagger file except you have
specific AWS in X Amazon API gateway
integration configuration in there which
is basically an extension of the of the
swagger specification but for the rest
it's it's just standard swagger output
you have a small overview on the amount
of API calls and the latency that you
you have there and also you have netflix
showing what latency you have between
the integration
because one of the issues that you can
have with lambda functions for example
if you have a cold start time that is
especially visible with Java functions
so with the node.js and bitin you're
looking at around 300 milliseconds for
the four gold boot java functions
between 23 up to 4 seconds if there's
not too much dependencies in there but
now in this case we're going to have a
view of the s3 configuration now all
right so in this bucket we can have a
configuration regarding the static web
site hosting so in this case we just
enabled it and we have a static website
on there which is just a bootstrap
bootstrap website so we are def ox all
together and we can basically choose
what back end the call so the Java let's
first use the elastic Beanstalk so its
response nearly immediately then we have
the note G s lambda function takes a
little bit longer and the Java function
with takes around two seconds let's say
so using this solution you can create a
static website and an API for it will
with not any server configuration that
you have used of course right now we did
everything in the console but typically
you do use infrastructure automation
tools to process this for example using
API gateway you can also import the
swagger confirmation backing back into
the contingent so API gave and
corrugation so that means that you don't
you can store everything it in code all
right I'm going to continue the
presentation and give the word again to
staff
next thing I want to talk about is
infrastructure as code so AWS has a
service called cloud formation in which
you can define for your environment or
resources and all connections between
those resources you can define it in
llamo format or a JSON format and it
makes it really easy to set up new
environments that are just like the
previous environment but also to tear
down the environments and to update the
environment of course when you have an
application on unable AWS like we had
one with over 500 resources you really
want to make your infrastructure as code
you don't want to set up 500 resources
for a production system because you know
that's going to film other than cloud
formation you also have other tools to
create your infrastructure as code like
a terraform or you can use a combination
of bottle and troposphere
so take aways about cloud native
development it's all about using managed
services it makes it really easy to
create complex applications without
writing too much code by linking all
those services together like for example
in Michaels demo about the static
website it's very easy to create an OLE
application using just a small amount of
of code of course it is all also very
important to make your cloud native
applications scalable and to start
learning cloud native development it's
good to start with elastic Beanstalk and
lambda functions because it's really
easy to set up you don't have to manage
your infrastructure too much and then
gradually you can include some other
services connect them together and start
building bigger applications of course
there are way too many interesting
managed services to talk about in one
session we have here a listing of other
name services that are really
interesting like an EMR an elastic
MapReduce to create big data
applications or do jobs you have for
example redshift which is data warehouse
you have elastic search service which is
to manage to elasticsearch next we have
also elastic cash for example to run
your memcache d or your Redis
so last slide the codes that we used in
our demos is available on on github if
anyone is interesting interested in how
to build lambda functions in Java for
example are there any questions I know
it was a really heavy talk maybe for
some of you a lot of services a lot of
new things so if you don't have any
questions right now later you can also
reach out to us any questions now not
really you want to say something Michael
hmm okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>