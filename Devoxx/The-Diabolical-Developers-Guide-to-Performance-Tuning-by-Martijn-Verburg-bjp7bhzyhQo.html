<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Diabolical Developer's Guide to Performance Tuning by Martijn Verburg | Coder Coacher - Coaching Coders</title><meta content="The Diabolical Developer's Guide to Performance Tuning by Martijn Verburg - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Diabolical Developer's Guide to Performance Tuning by Martijn Verburg</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bjp7bhzyhQo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">forgive you make it do it make sure all
right come on people don't be shy this
room in the middle if anyone saw
Catherine's ignite talk last night it's
all that hug your fellow developer so do
do move into the middle seats here
people don't be shy have a few more
minutes to go I hope everyone's enjoying
deadlocks UK so far I actually helped
start the very first one five years ago
and it was myself and a bunch of London
Java user group members who ran the
first DevOps UK we had no idea what we
were doing
it was absolutely menak chaos putting on
a conference like this is incredibly
difficult so the following year we asked
mark Hayes were to take over as quickly
as he could and he's done I think an
amazing job and this year has been the
biggest show yet it's fantastic to see
so today I am going to talk about
performance tuning and the thing I'm
really going to get across to you is the
methodology of how you go about doing
this right so when you get the call at 3
o'clock in the morning who hears had a
call at 3 o'clock in the morning we'll
quite a few of you right and your users
or your manager are screaming down in
front of you the e-commerce website is
down we're losing millions of towns or
millions of euros per minute the world
is ending it's all over and you have no
idea where to begin
right it could be the fact that the end
user has simply cut their internet
connection off right it could be your
data center is currently on fire who
knows so the one thing I want you to try
and take away from today there's going
to be some technical slides and quite a
bit of detail but the one thing you
really want to take away is the
methodology and I'll reiterate on that
point so this is me I'm the diabolical
developer some of you may have seen me
speak before I'm currently the CEO I was
demoted from CTO of a company called J
clarity we use machine learning to do
performance tuning it's a really good
fun what you do is you hire a couple of
PhDs you let them do some machine
learning stuff for about two
is you pray they will get a result and
you find build a product company out of
it
I recommend recommend it if you are if
you're a risk-taking person so what is
performance anyway performance is really
about the efficiency of something of how
something reacts or how something
fulfills its purpose so are you getting
the hundred thousand transactions per
second are you getting the response
times of the login page responds in one
second or are you not it's also got a
lot to do with how much resource you
need to process this work right
performance tuning is actually almost a
branch of economics you have a certain
amount of set resources certain amount
of set hardware some amount of threads
CPU power Ram so on and so forth how
efficiently can you make all that work
for you one of the interesting
interesting fallacies I used to see a
lot of is that when people see a fully
utilized or close to fully utilize CPU
they think that machine is performing
badly and I'm like no this is good the
CPU is one of the most expensive pieces
of hardware you can buy on the planet
today you should be using that damn
thing right if you're using it at 80
percent and you're still meeting your
performance time goals then that's great
you're actually utilizing your hardware
really well user requirements are very
very important and you don't want your
users just telling you I want the
website to be fast you actually need to
have a statistical curve of what the
throughput goals are latency goals are
and what the resource goals are as well
because you don't have unlimited budget
right you're not Netflix you're not
Amazon you can't just go out and say
well let's go provision 10,000 machines
okay your your managers or your chief
financial officer will be giving you a
budget so I'm going to cover eight
things I'm going to go pretty rapid-fire
through some of these but the bit the
first four sections are the bits you
really want to concentrate on right the
following four sections after that sort
of point in time how we do performance
tuning today given the technology we
have today but that changes really
rapidly and then while my one piece of
advice is do not performance tune from
it's a really really really bad idea so
the last four sections treat it like
Stack Overflow there's some reasonable
advice in there for today but it does
not apply specifically to your hardware
your application so on and so forth
first four sections
the methodology stuff is what you want
to concentrate on so it is all about
resources so I'm going to do a quick
poll how many of you actually know what
your production servers are in terms of
their hardware configuration so a paltry
sum of about 10% shame on the rest of
you you need to go out and talk to your
hardware people your system
administrators get out your hardware
manuals and actually understand what it
is your software is running on both from
a hardware level an operating system
level a virtual machine level since
virtualization is all the cool rage
these days and who here is using docker
or a container you quite live you well
okay so all of you also need to then
therefore understand how the docker
container stuffs being configured
virtualization is making it worse for
everyone when you think about it your
code is now running on a Java Virtual
Machine which is running on a docker
container which is probably running on a
virtualized operating system which is
then running on a real operating system
which is then finally maybe if you're
lucky running on some bare metal
somewhere it's not good and every one of
those layers take takes a hit talk a
little bit about cloud who here is now
hosting on cloud cloud cloud cloud oh if
you're not that many of you we shifted
from a non data center based application
to to cloud we're a software
as-a-service so we're a multi cloud
software is a service we have four
different cloud providers providing our
stuff around the world cloud is horrible
for performance it is absolutely
terrible
we are lucky if we get two nines worth
of up time from our cloud data centers
we're on the open Internet so the data
streaming between our data centers goes
out into whatever the open Internet is
which is controlled by God knows who
if for example we're running on about
dreamers on those which happen to be too
close to Netflix
on Christmas Eve our network is just
utterly destroyed because a whole bunch
of toddlers are out there are watching
Santa's Christmas to revenge of the
elves it's not good so when you're in
your own data center you have massive
amounts of control over your hardware
your network and all these things you
can get quite reliable performance when
you shift to the cloud even is
application developers you really have
to think very very differently you have
to start thinking about your fault
tolerance your resiliency what happens
when things timeouts what happens now
that all of a sudden all of our
transactions are you know an order of
magnitude slower because that database
transaction is going across the open
Internet so on and so forth so you
really have to think quite differently
up climber's Robert as I mentioned
before people always talk about R but
you can just spin up another 10 or 15
servers when I do a demo for my
customers and I spin up my 20 AMS on AWS
nodes to give my demo I have to do this
an hour before heads right so these you
know on-demand servers as they like to
be marketed I actually not truly on
demand as far as I'm concerned right
they take ages to spin up and so when
you're thinking about horizontally
scaling your applications and you get
that spiky load and say a little
five-minute time window and you think I
don't worry we'll just pushed an
educator lease button well it might
actually take an hour for those AWS
boxes to come up and by then it's
already too late so what the cloud
promises use is you have to check very
carefully and again it actually boils
down to reading some hardware manuals
talking to some system administrators
and some DevOps people and finding out
what the real numbers of these systems
are oh dear my phone's died can no
longer control from phone maybe okay yes
excellent cool you cannot virtualize
into more hardware I would say a good
twenty five to thirty percent of my
customers don't know how to count they
do things like we have 16 gig of
physical RAM on the machine and so we
will allocate 32 gigs worth of the two
operating systems on that machine
can anyone tell me how many 32s fit in
16 it's not very good but if you
actually check yourselves how your
applications are deployed I would double
check with your system administrators
and the people who run your
infrastructure as to whether they can
count and you may be unpleasantly
surprised and what will tend to happen
is that these virtual operating systems
and particularly these virtual virtual
machines actually very good at time
sharing it and very good at sort of
swapping the resources between each
other but all sorts of nasty things can
start to happen especially under load
right one of your vm's or all sudden may
just be completely restricted with with
any cpu or Ram that it actually wants
quite often that lots of nasty paging
from the hardware school occur so on and
so forth so just because you have these
dynamic virtual environments you can
sort of spin up and start up and
distribute across actual physical
Hardware you have to count the numbers
which is again why you have to go back
to your hardware manuals and understand
what you're running on so number one
technique that you take away so for the
90% of you who said you don't know what
physical hardware you run on go and find
out get it printed out a four piece of
paper wake it up next to your monitor
always always remember what it is and
find out when it changes as well right
what does performance tuning lots of
different people have lots of different
ideas what performance tuning is we sort
of have an idea that it's four or five
broad categories it's understanding of
the actual underlying technology right
this is the fun cool bit you get to
learn in that docker get to learn about
Numa architectures you get to do some
deep deep technical dive into fun stuff
you know how do you CPUs really work
level-2 level-3 caches all that good
stuff how does the JVM work
how do garbage collectors work how does
the just-in-time compiler work how does
3d ceiling work all the sort of good
stuff there is a methodology you can use
we have a methodology which we came up
with ourselves over 20 years of
doing this stuff as human consultants we
call it a performance diagnostic model
and I will show you some diagrams or
sort of a flowchart of how you can
follow this model yourself but
performance tuning is actually a science
right
most people think performance tuning is
sacrifice a chicken on the altar lights
and black candles go to stack overflow
change some - rent and random sitting on
your your Java Runtime rerun the test
and pray it's actually a very scientific
process you can go through and it's
really boring so one thing I'm going to
warn you about as well if you think that
performance tuning is cool and fun and
sexy it is not it is dull because you
run one tiny experiment you measure the
results you change one thing and one
thing only and you run it again some
performance tuning exercises we've been
doing have now been running for more
than 18 months for certain customers
just to give you an idea you need to
understand your architecture are you on
cloud are you in a data center where is
that data center who knows where the
data center is yes that's better so you
know what your data center is you just
don't know where the hardware is that's
sitting in it okay that's a start
diagrams diagrams diagrams diagrams for
those of you here who call yourself
solutions or Enterprise architects do I
have any of those in the room well it's
still a couple we thought it had died in
the 90s but you're still here actually
Enterprise architects that are still
surprisingly good at this they get out
Microsoft Visio and they're very good at
drawing the lines between all the boxes
that's exactly what you want to do you
don't use formal UML or any form formal
techniques get with your colleagues
around the whiteboard get out your
drawing skills from when you're a
toddler and start drawing out where the
boxes are physically and also logically
what the software flows are doing okay
are there remote calls between a service
and a database so on and so forth it's
important to understand the real
performance requirements if you don't
know what what target your tuning for
it's completely pointless tuning tuning
just to go far
is not good enough you want to have
things like we want the login pages to
always respond within one second between
the working hours of 9:00 and 5:00 after
five o'clock we don't mind as this and
degradation and if you really push us
it's actually okay if this is only true
99.999% of all transactions that come
through to the system right that's the
kind of statistical requirements
gathering you want to push your users
into and quite often you're going to use
non-technical language to get them there
but you can use hedge words like okay so
for a vast majority of the time you need
this to be back in one second but if
every once in a while it's three seconds
that's actually kind of okay and you
yourself can convert that into sort of
some statistical statistical curse you
need to understand a little bit of math
usually a high school or first-year
University statistics is good enough I
sucked at math this is why I'm the CEO
and I hire people smarter than me to do
the math you want some tooling you want
low tests right so unless you're really
really pro and you've got a load
balancer in front of your production
data streams and you're splitting off
your production data streams a B into
your test systems highly recommend
inspire you can set up that
infrastructure you need to have some
sort of load testing tool whether that
be apache jmeter gatling using blaze
meter which is a software-as-a-service
version of that so on and so forth
you'll need to get some metrics ins
monitoring editing system if you're not
measuring in you can't make any
decisions my companies J clarity so I'm
going to tell you to buy our stuff but I
will actually tell you about some free
tools along the way and you want a
performance testing plan if you remember
earlier I said it's a scientific process
you don't just wake up one morning grab
the team together and say hey we're
going to do some tuning this morning
need to have a dedicated plan what are
the use cases we're testing what's the
low test we're doing are we doing spiked
low tests are we doing endurance tests
are we actually doing unto you under
utilization tests so on and so forth
and I'm 15 minutes certain okay cool the
formats tuning is fundamentally about
this it's about removing bottlenecks and
a bottleneck is basically where a system
is oversubscribed right you're trying to
create too many objects on the heap and
Java can't keep up we don't actually
have enough physical RAM for Java to
keep up okay
you have asked your system to split this
task into a thousand concurrent threads
but your CPU only has four course going
to be a problem that sort of thing so
tactic number two the other takeaway you
want to have right know where your
hardware is know what this disk actions
are and know what your actual system
architecture looks like where are the
data flows going to where they're coming
back from next key things timeboxing I'm
going to run a little bit experiment
here humans suck at measuring time we
are absolutely terrible at it
and I'm going to prove this to you I
want everybody to close their eyes and
count to ten seconds and then raise
their hand when they think they got to
tenth on my mark of three so one two
three go
Wow okay about 80% of you have had way
too much coffee this morning so on
average people were putting up their
hands at about seven or eight seconds so
that is a huge inaccuracy huge but this
inaccuracy is also can also be used to
your advantage
humans can't actually perceive small
percentage gains and performance
improvements so you don't actually ever
want to or need to spend time improving
your end-user response times by say a
difference of four or five percentage
points as it were because humans like to
take that okay other in systems might so
if you're trying to improve performance
of a system to system pieces componentry
then you can start eating out these
types of gains but when it comes to
humans you typically need to have a gain
of more than 15% for them to actually
notice it fun fact you want to build a
response time budget and here's a very
simple traditional client-server
architecture whether database at the
backend you want to have a points which
measures time in and time out edek to
the dots that you see there on the
diagram and what you basically try to
identify is what part of my architecture
is a slowdown in it's pretty simple but
unless you've got these measurements in
place you don't know whether the fact
that the website didn't respond and ten
seconds was due to the client was a
JavaScript app slow the network does
someone cut a cable their app server the
data store third-party web server is not
responding so on and so forth if you're
using a fancy microservices peer-to-peer
style architecture good luck it's
actually really really hard to build a
time response budget for these things
there is a new standard our apps called
open tracing open tracing dot IO I
highly recommend you take a look at it
it seems to me to be one of the the
reasonable if it's out there at the
moment to try and sort of figure out how
to do this stuff
really really difficult otherwise it's
another way of saying is they do Micra
services just stick to the old-school
way of doing things much easier you can
even write your own simple timer API but
there are actually lots and lots of
tools and libraries out there you can
just do a Google search so tactic number
three make sure you have an actual
measurements in and out of each point in
your architecture otherwise you're going
to be completely lost you will never
even find the haystack let alone the
needle in the haystack
okay okay for time and now on to the
crux of the matter the performance
diagnostic model this is what we use as
human consultants to go in and very very
quickly performance tune systems and it
doesn't matter what the system is we
honestly don't care right it can be a
scholar system it can be a distributed
system we've diagnosed Twitter's core
messaging system we've diagnosed a
client piece of swing desktop
application we've done all sorts we
follow the same methodology every single
time okay so that always applies and it
actually applies to most managed
runtimes so if your performance tuning
python ruby nets note anything like that
you can actually follow a very similar
methodology to find out what's going on
and here it is in a nutshell looks a
little bit confusing but the question
you always ask yourself is what the heck
is my CPU doing right very simple what
does my CPU doing if it's kernel busy so
if you look at the CPU statistics and
you see it's doing lots of kernel
activity that basically means is a piece
of hardware doing an awful lot of work
all right
lots of disk writing or lots of network
writing lots of paging of memory
lots of context switching perhaps so the
CPU is being fought over by several
applications or several processes so on
and so forth there's an extra step you
need to go beyond here because you need
to find out what piece of software is
causing this Hardware to do all of the
work ok but I'll I'll go and go and go
into that shortly
so that's sort of one area need to look
at if the cpu alternatively is actually
what we call user or application
dominant so it's basically mainly doing
user activity then in the Java Will's
either it's a JVM probably doing some
poor garbage click thing that's usually
the most common course but there are
other JVM things that might be going on
like biased an and bias locking might be
causing some horrible long-term safe
pointing all sorts of other stuff might
be going on or it's your actual
application code which is which is hot
till it's just burning all of the CPU
time this is surprisingly rare as Java
developers you tend to want to look at
your source code and say oh it's a
concatenation of string we're doing a
million times which is causing our code
to be slow and rubbish almost certainly
not and I'll actually show you a little
bit later on on how ridiculously good
Java is at optimizing your code under
the hood it is stupidly good so I would
say out of all the issues we've seen and
we've tuned probably a couple of
thousand systems by now that user
application issue only crops up about
three to four percent of the time it's
almost never your hot code unless unless
you're working in a pretty specialized
area the JVM is quite common especially
around garbage collection today and one
of the most common ones today especially
in cloud environments is the node
Dominator black box and the bottom this
corner if your CPU is doing pretty much
nothing and your users are complaining
that your website is slow or why is your
CPU do nothing right it's because your
applications is not being is not able to
do any work why is it not able to do any
work
maybe this deadlock threads inside the
JVM maybe your database isn't responding
maybe a third party web services service
and responding and your app is just
sitting there waiting all right those
are the kind of three broad categories
so you just have a look at what the CPU
is doing because everyone know that all
VM step yeah who here runs on Linux from
the production excellent right after
this after today go log into a Linux box
type and vmstat
if you've never used it before or go
ma in space vmstat that's the manual
page for VM step tells you how to use it
and you basically just run VM step and
it will tell you what your CPUs doing
there it is on the right hand side there
that's what you'll see peas doing can
anyone tell me what the CPU is currently
doing is that kernel dominant use a
dominant or is it doing nothing it's
doing nothing right the idle come I de
la la' Mira's is in the high 90% of the
time so this system is as far as the CPU
is concerned pretty much doing nothing
so I instantly know that if my users are
complaining that the application is slow
on this box it's not garbage collection
it's not hot code it's not poor disk
activity I can eliminate all those
things now I'm starting to look at
things like thread pools database
connections that sort of thing okay so
very very quickly you can eliminate a
whole class of categories of performance
problems and you can start diving into
what it what the problem really is so
always remember what is your CPU 3
o'clock in the morning when you're tired
you have your coffee or you can a red
ball you look up at your monitor and
you've got the piece of paper next to
the monitor which just asks you what
does your CPU doing that's what I have
at home safely many many times so going
back to the top left-hand box where I
talked about kernel activity being
dominant there are a whole bunch of
reasons why the CPU might be kernel
dominant there might be context
switching going on so this is what
happens when an Oracle database wants
all the CPU and your Java wrapped box
all the CPU is not enough CPU to go
around and they're both just start
fighting over it and Linux does the best
it can to go yes Oracle you have a
little bit know Java you have a little
bit and so on and so forth sometimes
it's just Java itself right Java if you
if you haven't coded your threading
inside your java application properly
itself starts fighting for CPU cores and
CPU time it never a good look tools like
VM state and IO stet will very quickly
tell you if it's disk writing or disk
reading or some sort of hard
activity which is going on especially if
you're still running old spinning rust
or spinning ceramic drives as we call
them so non SSD drives remember go back
right to the start of the talk what is
your what actually is your physical
hardware do you have SSD drives or not
do you know find this out there
virtualization tools KVM tools this is a
whole bunch of monitoring tools around
docker with kubernetes etc and if you
want to find out if you're destroying
your network net step again free tool on
the command line
Wireshark also a fantastic tool also
brilliant for spying on your neighbor's
Wi-Fi networks to see what they what
they look at so Linux tools command-line
tools are the cheapest fastest ways to
very quickly figure out what's going on
so learn how to use them if you don't
know how to use them go talk to your
local system administrator it's actually
the best way to start bridging that gap
because I know most system
administrators hate developers and most
developers tolerate system
administrators the DevOps movement was
supposed to bring the two together but I
think there's still a major cultural
split there but this is one of those
sort of little peace overtures you can
make just be humble and say I'd really
like to understand how to monitor these
performance issues as the Linux
operating system Cesar and in return Oh
mr. or miss system administrator I will
tell you how the black box of Java works
with garbage collection etc and they'll
love you for it because they hate Java
Java is this horrible big black box they
can't get into they really don't like it
if the CPU is moving towards user
activity the first thing you want to do
to quickly eliminate a class of problem
is look at the garbage collection log
garbage collection used to be almost
this wonderful free thing that Java gave
you which never really used to impact
your system and that's because it was
just a sweet spot that hardware was so
powerful and the types of applications
we were building in the early 2000s just
never troubled it the problem now is
we're either trying to write run
applications and really small heaps
because we're doing micro-services
spring boot docker containers tiny java
heaps
or we work at big banks and places with
huge dedications so we're running 100
gig heaps or 256 gig heaps we've even
seen out there in the world and the
garbage collection algorithms that are
currently out there today just simply
can't cope new ones are being designed
new ones are coming in so G ones coming
in from Oracle shin and da from Red Hat
so on and so forth to try and help out
but what tends to happen is that the JVM
either has to stop the will to try and
clean up an absolutely huge chunk of
your heap or it spends a massive amount
of time trying to do cleanup while still
giving you a little bit of CPU so your
application can continue which is which
is what we call throughput either way it
tends to dominate the production
problems we see in terms of performance
those are the three flags you always
always always want to switch on in
production unless you are in the low
latency trading space and if you are
then you probably shouldn't be in this
talk anyway
less than 1% impact on your running
production JVM to switch this on alright
and it gives you the GC log you need to
find out whether it's a GC problem or
not use the GC log analyzer to find the
problems we obviously have a paid-for
tool there's also a free tool called GC
viewer if you don't have any budget or
if you know your manager will never pay
for anything here's a sort of example of
the type of analysis that a GC log
analyzer can do for you
GC viewer by the way will show you this
exact same view so I'm only using my
tool just because it puts out a slightly
prettier graph you can see that along
the bottom on the right hand side there
this Java heap is doing a full GC every
split second continuously and it is
recovering just enough that it goes yet
this heap is still alive so I'm not
going to add a memory error but I do
have two full GC again straight away and
if full GC stops your JVM none of your
application threads can continue running
so as far as the end user is concerned
this application is just stopped dead
alright as far as the CPU is concerned
you would see the CPU user activity
starts spiking you take a look at the GC
logging you go aha in this particular
case the heap is just
sighs right we'll just double the size
of the heat rerun the application see
what happens next
pretty simple here's a fun one this is
what a memory leak looks like from the
garbage flips and log perspective again
you look along the bottom of the graph
there is the size of the heap
after a garbage collection has occurred
the red ones are the full GCS the red
diamonds and the red crosses so
basically that is that is stopping your
entire application cleaning up
everything it can and then enough it
goes again as you can see over time as
this application keeps trying to clean
up after itself more and more gets left
behind and about two weeks time this
very very important trading system is
going to blow up with an out of memory
error
okay so again you would see increasing
CPU activity take place as more and more
full system GCS occur over time this is
what a healthy application looks like if
you see this type of log give yourself a
thumbs up you've clearly done a good job
people like to then know how to find
memory leaks there is a free tool called
visual VM with Java eight and earlier I
believe you can actually just find it in
the bin directory of your JDK or you can
download it just sit for visual view
it's a memory profiler it's a CPU
profiler it's a basic profiler for
everything Java it's it's got it's got
its drawbacks it's got its flaws but it
generally is good enough to do this in
what you basically want to do is find
the code which is generating all the
objects continuously not cleaning up
after itself
and what you do is you just attach
visual VM or the NetBeans profiler you
attach it to your running JVM you hit
the magic memory profile button you
profile for a good length of time okay
you need to do it for a good length of
time and if you've turned on the magic
record my stack allocation traces my
allocation stack traces sorry you will
then get a view like this
so basically concurrent hash map hash
entry is the dominant thing that is
being created in the seep okay this is
the thing that is constantly being
created you see the generations count on
the right hand side which means has been
alive for continuous generations it's
effectively not being cleaned up after
itself so new ones are always being
created and then we have to do is just
walk down the sec trace until we get to
the line of code which does not look
like a Java class because Java I daresay
almost has no memory leak lifts in it
right the the JT the java jdk jdk team
are very very good at not having memory
leaks inside java itself you see there
is an application they're called
Hawkshaw aha that's the application
source code which was creating the
memory leak so you go into your source
code and you find out pop the memory
leakers that's simple and after this i'm
happy to show anyone live for life how
to go about doing it so don't be afraid
of getting out the memory profiler
that's my piece of marketing but quite
seriously visual VM or eclipse as na T
or NetBeans as profiler can't remember
if IntelliJ comes with a decent one or
not but yeah they're all good I'm going
for time you get a little bit quicker ok
so if you've eliminated garbage
collection right so you got that in
lovely blue line spiky sawtooth pattern
but it was the fact that your CPU still
had lots of user time and then you need
to actually look at your application
code alright and this is all about CPU
execution profiling now as I said before
Java is stupidly good at optimizing your
code here is a tiny amount of the
optimizations at the hotspot C 1 and C 2
compilers run for you this is just a
small amount I can't remember how many
there are there are that there are
hundreds they are so complicated and the
interaction between are so complicated
that nobody actually understands how
they all work anymore so one of the
reasons why possibly hotspot will be
replaced in Java maybe 10 or 11 or 12
with this new technology called growl
which is similar compiler technology but
can be reasoned about and has a Java
interface which is a lot nicer
but despite that most people would argue
that java's hotspots profiling and and
dead code elimination and other
techniques is the best out of all the
managed runtimes out there today
that's why jobs are so good method
inlining is the killer feature of this
so if you have class a in your calling a
getter or a sitter in Class B and it
gets called often enough the JIT will
just go grab that code in Class B and
I'll suck it into Class A and and
effectively get rid of that closed code
in Class B and then all subnets got this
new slightly larger chunk of code that
it can perform extra extra special
clever analysis over it can figure out
things like will that if statement ever
be called or can I can i optimize that
loop because I always know that the true
path is going to go is going to happen
stuff like this 35 byte codes or less is
what you need to have one of your one of
your methods actually be optimized by
the distant time compiler as a rule of
thumb so when you're writing your source
code and you can pile that source code
down you can save a look at the class
file and you can use a tool called Java
P again this comes free and the bin
directory of Java itself you just go
Java P - the name of your class file and
it will tell you how many byte codes
each of your methods are and if your
methods are 35 boat code byte codes or
lifts then they can be candidates for
being optimized by the just-in-time
compiler so if you've got particular
myth important business methods that you
need to go really really fast you need
to make sure that it is 35 byte codes or
less some more in-depth detail about how
all that works which I'm just going to
skip so here's an example
who here has done fits Fuzzle fizzbuzz
interview questioned yes it's still a
stern favorite so this is a typical Java
Enterprise e very verbose source code
but extremely readable way of doing this
I would expect you know a junior to
mid-level Java developer I was I was
interviewing to come up with a solution
like this so you know we have we have
two good slides here worth of
source code just to do this does all
right so we get the numbers we process
them we figure out the range we figure
out what the division should be we do
some printing so on and so forth all of
the source code Jett turns into that
right which is perhaps how a/c developer
would have written this in the first
place
admittedly in terms of how the source
code is written but it's amazing the
amount of dead code elimination in
lining hold on to these other clever
techniques constant propagation all
sorts of other stuff that goes on so
guess what I'm trying to tell you is
when you're writing your source code
don't optimize your source code write
your source code for readability and
maintainability if you really care about
optimizing it just make sure it's 35
byte codes or less and then the jet will
take care of everything else for you
unless you have several PhDs in computer
science and compiler theory trust me the
jet is smarter than you are
okay here's another example of how that
works
can anyone tell me how long it takes for
example to create let's say 10 million
objects and Java because yeah a few
people have figured this out zero so
this is a bit of code I love showing all
of my node.js and Ruby friends telling
them how fast Java is we can create 10
million objects and 0 seconds because
what happens here is that object ov
never escapes that loop right it's never
used outside it's never referenced
outside so the just-in-time compiler
says well if it's never used outside
it's never use inside the loop I'm just
going to kill it completely just remove
that dead code elimination and so that
for loop actually executes nothing so it
returns zero seconds this is why micro
benchmarking in Java is hard again you
can use a free tool NetBeans profiler or
visual VM profiler instead of hitting
the magic memory profiling button you to
set the magic CPU profiling bun big red
bar is bad the big red bar is a bit of
your Java code which is causing the CPU
do all the work and again if you have
pushed the magic record my allocation
stack trace button you go down all the
Java classes because you'll see lots of
things like you know char array string
lots of lots of Java primitives at the
top of the stack trace until you finally
get to your piece of code and you go aha
it's that ridiculous call to hibernate I
made which is killing the CPU not
uncommon if you really really really
really really have to go tuning your
source code then there is a free tool
under the adopt open JDK organization on
github called jet watch jet watch has
this beautiful three panel system your
Java source code the Java bytecode it
produces and then the actual jittered
machine code that that produces so you
can take your methods and go Huell if I
just tweak this little bit of code or
now I'm under 35 byte codes fantastic
and the machine go code that gets thrown
out is well I can't read it but if I
could i will impress all my friends with
how I can read machine code but this is
actually the very tool that even the
Oracle engineers now use themselves from
time to time to figure out what the
heck's going on internally a guy called
Chris Newlands here from the London Java
user group is pretty much the the
primary author as a fantastic piece of
software also if you are going to micro
benchmark please please please use a
tool called jmh it was written by alexey
shavelev who was formerly the head of
performance for all things Javad oracle
and is now ahead of the job performance
team at Red Hat he has done lots and
lots of work to do things like make sure
that when you're running a micro
benchmark switch off the garbage
collector because that's going to
interfere your measurements this sort of
thing so if you need to do micro
benchmarking in use Gammage so if you
must optimize for JYP's use jmh from tip
watch it will tell you what's going on
and you can use java p- see if you can't
be bothered using those tools and if you
want to show off to your friends a
little bit about how you look at the
bytecode of a class while 35 byte codes
or lists don't forget it I'm definitely
running out of time so I'm going to go
very fast now so we've covered
the user space stuff is a garbage
collection or not if it isn't then its
application code you can use JIT watch
and things like that if it's kernel user
the Linux command line tools to find out
what's going on if it's idle then
something's waiting or deadlocked it's
all to do with basically there are no
threads or processes coming into the CPU
boring boring boring boring so there's
lots of different ways you can do
serialization and inter process
communication and you know about them
all everybody now just uses rest and
JSON right is anyone not doing rest in
JSON anyone here still doing JMS one
person one unhappy person never vines we
can skip that again Wireshark is a very
very useful tool to find out about
things going in and out of your network
if you've made a database call it is not
coming back or if you made a third party
web service call it's not coming back
Wireshark will actually sit literally on
the wire and tell you and it'll have a
look at the packets you can filter them
all that good stuff
if it's a problem inside the JVM and
there's things like deadlock threads or
live lock threads or there's the threads
of fighting for each other there is this
very simple thread state diagram you can
follow to figure out what's going on
most people don't bother most people
just use a tool again NetBeans or visual
VM comes with effectively a thread
analysis tool you just hit the magic
what are my threads currently doing
button and it will look at all your
threads you'll see is a difficult HTTP
thread pool probably coming out of
Tomcat I think and you can see here for
like a lot of time those threads are
actually waiting and in is a burst of
activity the green in the middle and in
there off waiting again so if you see
that all of your HTTP thread pools for
example are yellow they're waiting for
something to come in and your users are
saying you'll wait app to slow or you
like okay so somebody broke the Apache
web server in front of my Java server
and no data is coming into my Java
server that's why all these threads are
waiting all right those are the types of
conclusions you can make or you know I'm
getting Google Ads coming in from the
third-party web service and I'm waiting
for them to come in
anything along those lines you can also
find out whether your threads have been
stopped or locked as you can imagine the
red bar is bad if you're colorblind I
apologize I don't know if you can change
the colors in it bins actually there are
other tools that that do do cater for
colorblind people NetBeans also
hopefully comes with its own deadlock
detector again this is a free tool
visual vm does the same thing it will
tell you if thread 1 is locked on thread
to here is the big caveat no profiler is
accurate ok especially in Java right for
profilers to do profiling in Java they
have to do things like ask threads to
stop so they can go get information they
have to do sampling so quite often they
can either miss the problem or they can
miss count the problem or if you're not
profiling over a wide enough time window
or you're not sampling quickly enough or
slowly enough you're going to get the
wrong information and a fun trick you
can do to show your friends that this is
this is the truth as you generate some
some performance problem
maybe you deliberately did lock a couple
of threads or some along those lines in
fire every single common profiling to
edit and they'll all give you a slightly
different outside this is where the
mathematics comes into it and the
scientific rigor you need to make sure
that when you're doing profiling you're
profiling over a set time window the
same time window every single time that
you're doing your sampling rates the
same every single time that you're
making sure you're taking enough
measurements let so when the profiling
and sampling misses certain data points
you're still getting the right
curvatures right there are some really
cool profiling tools is starting to come
in things like the honest profile of the
async profiler which actually work under
the hood of Java they're kind of looking
at what the native threads are doing the
great thing about them is that they're
more accurate the bad thing about them
is at their native agents and if they
crash your JVM crashes some customers
don't like that apparently
so as a summary you need to know what
your resources are go and find out what
all of your hardware sitting on and
where it is fitting do the time boxing
draw your architecture diagram and make
sure you're getting numbers in and out
of each component you can follow that
performance diagnostic model what is
your CPU doing is it going towards
kernel is it going towards user or is it
doing nothing if it's system or kernel
using Linux command line tools is it
rampaging in and out is it disk activity
is it context switching so on and so
forth if it's in the user space garbage
collection log first within 30 seconds
you'll know whether it's garbage
collection or not otherwise you have to
go into the more difficult execution
profiling and if it's idle or wait then
get up the threads profiler and see if
you can sleeping find out whether it's
your database pool that's waiting your
thread pool that your HDD people that's
waiting or if you've got a deadlock
situation this is some of the stuff
we're doing to help so we work on open
JDK directly if you want to find out
more just seem to see me afterwards
we've used machine learning to try and
do the stuff quickly for you and I think
I've probably run out of time for
questions so you will have to just find
me off to the sides and enough time with
the Linux speaker now apparently our
four minutes left four minutes of
questions yes
so how do you get requirement okay
that's a very good question how do you
get requirements of users without them
picking out random numbers out of the
air so you can actually go back and show
them some some well-known users of
studies that companies like eBay and
Amazon have done and some of the large
gambling and e-commerce sites so for
example most users will just say a
website as fast if everything responds
in one second most users will notice a
delay but will still stay on the website
if it's three seconds or less if it's
more than three seconds they get bored
and they leave so you can start using
those kind of user studies to help guide
your users and giving you the numbers
that are actually truly important all
right so are they are they are you are
their end users an e-commerce site or
are they internal users and they if the
internal users are locked to your
application then hey even if the thing
pauses for ten seconds so they can only
use that HR application right to fill in
their timesheets tough luck so it's
maybe not so important yes no problem
which is you mentioned that firing
instances or containers on the fly in
production or on the cloud takes a lot a
lot of time yeah so can you can you
highlight briefly what could be the
reasons the reasons for for taking that
long he said that firing instances on
the fly when you are up what I say right
so what goals take a long time what what
what are there briefly the reasons
behind this it's all about how busy a
particular data center is in particular
for Amazon or Google Cloud or marks off
to zero right so everyone thinks is a
sort of infinite cloud of machines out
there well it's actually not the case
right so if amazon west coast is having
a busy day and is actually only five
physical machines left that can spin up
virtual machines on that physical
machine then you can have a bad time a
disaster 30 30 virtual machines right
because you have to wait until some
other resources actually come free so
Amazon and companies like that don't
actually have limitless hardware and
that's typically what happens and they
actually allow customers to
pay for priority as well and typically
for people like you and I we don't have
the budget to get priority at Amazon and
if Netflix wants an extra three thousand
servers they get it first yeah Amber's
Amazon are brilliant at billing by the
way so you know if you really want those
machines they're always happy to give
you that priority if you're willing to
pay a lot of money
two minutes left any more questions
everyone is now reading their hardware
manuals this one over here there is a
fantastic question what impact does
profiling have on the application I
actually forgot to mention this so bad
bad naughty me profiling all of the
traditional Java profilers so visual VM
New Relic F dynamics even our tooling we
try very hard not to do this they all
impact applications quite a lot you can
see up to a 20% impact in terms of
throughput can can actually occur
depending on how busy your application
is what our tooling does is we only
actually jump in and profile when we
know there is already a problem and so
we kind of work with our customers and
we say well your app was already dying
if we had an extra 10% overhead to that
to two minutes while we figure out
what's going on maybe that's not so bad
but if you've got a profiler which is
continuously profiling and I think some
of the tools do this like New Relic does
this we have a mode where you can do
this you will be adding that overhead
all of the time absolutely so yeah you
do fee you do have to pay that price
there is one tool which is probably the
most lightweight it's Oracle's flight
recorder they've got lots of hooks
internally into the JVM it's a fantastic
tool if you can afford Oracle I'll go
for it but the fording oracle body
reassuringly expensive and now I'm out
of time so thank you very much for
listening I hope you have a great risk
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>