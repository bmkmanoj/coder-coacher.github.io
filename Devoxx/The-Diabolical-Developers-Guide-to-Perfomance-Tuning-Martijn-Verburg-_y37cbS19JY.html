<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Diabolical Developer's Guide to Perfomance Tuning    Martijn Verburg | Coder Coacher - Coaching Coders</title><meta content="The Diabolical Developer's Guide to Perfomance Tuning    Martijn Verburg - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Diabolical Developer's Guide to Perfomance Tuning    Martijn Verburg</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_y37cbS19JY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome everybody it's very very good to
be back this is absolutely my favorite
conference due to the smart insightful
audience who typically fall asleep in
the back row and write some code in the
middle road and pretend they're watching
me on the front row so today I'm going
to talk about performance tuning and
this is going to be a methodology talk
it will not be deep dive diving into
lots of detail tooling or anything like
that so if that's what you came for
then I will not be offended if you leave
the talk may not be as humorous as other
talks you've seen me give if they're
also offends you you can leave for those
of you don't know me I am the diabolical
developer and I do some stuff lets me on
the Twitter's I run a small company with
my co-founder who's sitting at the front
here Pepperdine called Jay clarity we
use machine learning to try and solve
nasty performance problems and Java and
JVM systems it's an awful lot of fun I
help run various open community projects
at open JDK and for Java standards and I
caused trouble like I did today when I
arrived here 10 minutes before my talk
don't ask your phone so let's get into
this what on earth is performance anyway
as far as your end users are concerned
it's pretty much the bottom three there
on that on that list
they're usually concerned about some
sort of throughput you know they want a
million transactions per second or if
you're Twitter you just have that
transaction rate as soon as you open up
the 280 character limit go ask the
Twitter engineers how they felt about
that decisions I want a so it makes for
an interesting conversation latency is
also very important for many of you so
if that login screen doesn't respond in
one second most of the time you know you
get the angry user on the end of the
phone
any of increasing importance especially
in this brave new world of
virtualization containerization
microservice and cloud is the resource
usage so a lot of you are being asked to
deploy java applications that are now
running on hundreds if not thousands of
JVM all which are meant to be fairly
small micro-services and Amazon Finance
ears are rubbing their hands with glee
because every time you deploy a Java rep
they make a ton of money and so your
management quite often now is starting
to ask you can we make Java smaller can
we make the application that you've
built on top of Java smaller can we run
it in a smaller heap start performance
tuning please so I'm going to cover
these eight things in rapid-fire because
I've got 66 slides only 50 minutes to
cover them in the first four sections
are the very very important ones those
are the ones that you need to take notes
on memorize think about carefully take
away home with you it's some methodology
it's how we go about performance tuning
and how we go about performance tuning
@je clarity is we've got about 40 or 50
years combined experience and applying a
fairly rigorous scientific methodology
to finding bottlenecks and how to and
then going out and solving them so
pepperdine sitting in the corner and
entered this methodology goodness knows
how many years ago probably before java
even started and we've applied it to
everything from tiny micro services all
the way to massive data grids compute
clusters so on and so forth and it just
works right so this is the thing you're
going to want to take away from this
talk the following four sections are all
kind of technical tools and things you
can use today but they may not be the
right tools tomorrow and they may not
actually be the right tools for your
specific application so just like going
onto Stack Overflow and copying and
pasting that random person's code please
take anything that are written on these
slides as they are intended they are not
specific to tuning advice for your
application and if I catch any of you
using my specific advice on this slides
junior applications a puppy or a kitten
may die
so performance is really all about
managing these things resources who
here's a Catan player ooh my wife has
been banned from Catan she bit the
number one player on Xbox and the
ongoing storm after that the Twitter
storm and the abuse of tweets and things
just just made it was too much great
game though so it's all about managing
your resources how much hardware do you
have how much CPU do you have how much
memory how much networking capacity how
much bandwidth
what's your hard disk like their tutors
controllers is there one are you running
in a container are you running on a
virtualized hypervisor is that
hypervisor lying to you all these
questions and more need to be armed
answered
unfortunately most of you are now being
pushed onto virtualized environments or
to cloud environments so show of hands
who here is now deploying to some sort
of cloud environment for production the
super advanced crowd at devoxx see half
of you and how many of you are running
either on a virtualized operating system
so some sort of VM or a docker container
Wow even more of you you poor poor
people so the cloud sucks data these
these remote data centers with their
poor bandwidth from the fact you've got
to share it in with Netflix it's just
useless and annoying from a performance
perspective yes you can horizontally
scale more easily that is the one
overwhelming benefit of doing all this
virtualization stuff unfortunately you
now get less CPU less memory less
network less reliability less disk
control this all the nice resource
things that you used to rely on in the
2000s which made Java go fast so all of
a sudden your individual instances of
Java now suck from from a performance
perspective right and this is why we @j
clarity are enjoying this phase at the
moment cuz we get to make a lot of money
it's very important
so few little nasty facts about cloud
and a typical bulletproof data center
reliable data center at one of the big
banks they typically talk about five or
six nines reliability you're lucky if
you get a single nine if not two from
Amazon's right this is this is a huge
huge issue if you're running any sort of
mission critical application that relies
on having decent up type and uptime and
decent performance characteristics if
someone's detoxing your cloud provider
you're also being ddosed so make sure
that you know if you're hosting your
application that is not being hosted
alongside say some ole trite group which
is currently being hammered over in the
US or Donald Trump's personal website
perhaps people think that all it's a
little bit elasticity on cloud we can
just spin up boxes who here has tried
spinning up more than 10 Amazon AWS
instances and had that successfully
execute in under a minute
none five minutes still none tin gosh
isn't as brave new world great I can go
to my old datacenter and I can spin up
tin tin beer middle boxes and under ten
minutes but anyway so the issue we're
seeing with a lot of you unfortunately
is that because you don't read your
hardware manuals and you don't read your
software manuals and you're not reading
your Linux manuals is that you're over
subscribing to these resources we
constantly see customers going whoa cool
we've got virtualized operating systems
on this piece of bare metal we're just
going to allocate 16 gig of ram to our
virtualized operating systems forgetting
that there's only eight gig of physical
RAM on the box how many times does 16 go
into 8 it's a pretty basic mathematical
question and quite often people get this
wrong same goes for the CPU resources
the disks so on and so forth so rule
number one please be extremely careful
about doing basic arithmetic make sure
that the virtualized resources you're
allocating actually map on nicely to the
physical
resources and this at extremes includes
things like making sure you understand
how many physical sticks of RAM there
are for example if you're allocating 8
to gig of virtualized memory and that
fits nicely into an 8 gig stick assuming
the operating system is mapping that
nicely for you that's a much better
performance profile than it if that was
mapped over for 2 gig sticks so
understanding little nuances like that
if you've got real performance critical
applications it is important it's also
important to remember that the operating
system and the hypervisor needs some
resources for management so you can't
just go and tightly pack in say 8 gig a
virtualized memory into 8 gig of
physical memory because you've got
you've forgotten that the operating
system itself and the virtualization
management software itself needs a
little bit of that memory for it itself
to work now they pull all sorts of
tricks right resource sharing timeboxing
pinning things all sorts of fun tricks
but at the end of the day the math still
speaks truth don't over allocate very
important so here's my pro tip number
one know exactly where your resources
are who here knows where their Cloud
Data Center is so that's about a tenth
of the people who said they'll deploy
into cloud right so that's number one
piece of homework find out where your
data center is find out what's actually
running on that data center and what
your production application is running
on it includes the network the hard disk
all that all those features go talk to
your local system administrator they're
not trolls the human beings just like
you and if you want to get into this
whole DevOps movement then you may have
to be the first person to hand over
Olive Branch and make friends it's
really really important they actually
have all this knowledge and they usually
guard it in a text document or a
Microsoft Word document at worst and
usually if you buy them enough coffee
they'll actually share that with you
next section what is performance tuning
so it's understanding about all the
technology and this is why people who
are really
performance tuning spend long careers in
it it's not just enough to kind of
pretty much know how Java and the JVM
works it's about understanding the deep
dive detail of how each of the garbage
collectors work how they're just in time
compiler works how the JVM pushes down
on the Linux scheduler so on and so
forth and some of this is just hard one
bitter knowledge through painful
application deployments reading through
bug reports chatting quite often to the
core JVM engineers at Oracle Red Hat IBM
and so forth so if you want a career in
the stuff be prepared to spend a couple
of years of really deep diving into some
technical detail it is an awful lot of
fun though it's actually very very
rewarding especially from a computer
science perspective it really really
brings you back to the core user
methodology whatever you do do not like
the black candles do not sacrifice the
chickens do not sell your firstborn
child especially to the management right
try and use at least some sort of a
rigorous scientific repeatable group
reproducible process and we'll go into
the one that we use that we think is
very successful only fix one thing at a
time very important I'll harp on about
this later you need to understand your
architecture where is everything
physically located and how does it all
logically talk to each other what
protocols are being used are using
things like SSL oh it has a performance
overhead interesting are we doing that
handshake every time are we just doing
at once as an example understanding what
the real requirements are and this means
going back to high school at least high
school statistics maybe university level
year one mathematics
so when end users say they want
something to be really really fast what
they tend to mean is that they want
everything to happen under one second at
about the 99th percentile of all of your
response times that you have an a mess
of statistical curve so at the very
least 99% of time things should happen
in a second screen should be snappy
things should come transaction should
come back things should be responsive
so when you're drawing that bell-shaped
statistical curve that many people like
to do it's not the one in the middle
that you care about it's the one all
Lance is a fire ferrant and because I
got here so late on the train I don't I
can't show you one of those curves but
you can imagine it in your head so you
do need to know a little bit of math you
want some tools you need to be able to
load test your applications and if you
can't split an a/b off your actual live
production traffic and I highly
recommend you do do that if you can if
you can't then using a low tester such
as jmeter or Gatling is quite useful we
really like jmeter when you're modeling
user stories because it's absolutely
fantastic about taking a user journey
through a whole bunch of web pages or
through a whole bunch of interactions
and doing things like the user is
confused by this page so they kind of
pause for five seconds as they figure
out where the heck they're going so you
can really actually model how a user
would user gatling is awesome for
systems load testing so if you're
effectively trying to test Twitter and
you just want to hammer ten million
transactions at an API then Gatling is
an awesome Scala based Java based API to
go do that and all you're trying to do
is just remove a bottleneck and the
bottleneck is the bit that over
subscribes to a resource right are you
utilizing the CPU too much the memory
too much the Java heap too much the
hardness too much what is what is the
blocker what's the thing that's causing
this performance complaint and the key
here is to only remove the biggest
bottleneck one at a time because every
single time you remove a bottleneck do
you rerun that load test it's a
completely brand-new scenario and you
generally speaking have no idea what the
effects on the downstream system or
components are going to be so classic
example is you fix your thread pool in
your Java server and all sudden the Java
server now has 20 lovely threads to go
talk to the database oh the database was
only configured to handle two requests
and so the bottleneck now becomes a
database the overall impact on the
system is that he actually managed to
slow the whole thing down oops
that happens with performance tuning fix
the bottle of biggest bottleneck you may
actually find yourself going backwards
and terms your result into it until you
go fix the next one but eventually
you'll get there so pro tip number two
make sure you draw those logical and
physical architecture diagrams sketch
them on a whiteboard or use good old
Microsoft Visio if your manager really
insists there's lots of great
collaborative drawing tools now not
Google Docs and learn some basic
statistics you need to understand your
distribution curves and what standard
deviations are and significance and
things like that now we're gonna talk a
little bit about time and I'm gonna run
a fun little experiment
humans suck at measuring time they're
absolutely terrible you're horrible at
it and I'm gonna prove this to you now
so I'm gonna everyone to close in a few
seconds I'm gonna be everyone to close
their eyes and count to ten seconds and
then raise their hand when they think
they got to ten seconds no cheating I'll
be watching alright so on the count of
three I want you to close your eyes
count to ten seconds and then raise your
hand when you've gotten to ten okay so
one two three go
well some kids are fast out of the block
out they smattering around 9 10 11 still
going sometimes using a force multiplier
on the second fantastic you're not open
your eyes so that ranged from five
seconds to about 17
what an amazing variance and this is
only over a tiny tiny interval so you
have to understand that especially when
you're dealing with human beings and
users in particular when they say
something took a few seconds they are
lying to you I'm not kidding
so never ever ever trust your users when
they say anything about time and don't
trust yourself when it comes to time
take the proper measurements and you
need to understand a little bit about
human psychology as well unless you
improve something by more than about 15
to 20 percent in terms of a latency a
human won't notice the difference so
when you see people go we optimized that
webpage we've got a three percent
performance gain nobody cares you just
wasted two or three weeks work right so
make sure that the games you're getting
something that humans in particular can
actually see so time is a fun fun topic
and we could probably give a 3-hour talk
on time we have to be aware of a few
things when you're measuring time in
your systems you have things like the
NTP protocol which will send some of
your machines back in time as well as a
fun trick all mine transaction completed
in minus two seconds awesome
all the hardware clocks lie to you if
you ask a Linux laptop all on different
Hardware same Linux kernel to tell you
exactly how many milliseconds it took to
get to one second they'll all give you a
different number so again when you're
running performance tests make sure
you're running on hardware which is
pretty damn close to what you're running
on production because otherwise you get
different results quite significantly
different results and there's the old
adage of the more you measure the more
you're actually impacting thing a thing
you're measuring
so you have to be extremely careful not
to introduce jitter and lag into the
thing that you're measuring by measuring
it we call that either inbound or
outbound flow measuring and most people
get it wrong we got this wrong ourselves
to begin with as well you want to make
sure that you're taking timings at each
entry and exit point of your
architecture and because we're going
back to the 2000s we have a
client-server architecture here because
it's so much simpler exhausting area to
walk through so you want to measure at
the JavaScript layer there at one then
when it enters your servlet container
two exits that JDBC driver hits your
database goes back through and as long
as you've got timing points for your
transaction as it goes through you know
where the time is being spent so you've
already eliminated whether the problem
is occurring your front ends your middle
tier or your data store somewhere pretty
simple right there's lots of good free
tooling to do around the stuff you can
use p65 for example for your JDBC driver
there's a ton of open source and
commercial tooling that you can buy
which will do byte code weaving into
your code to put timers in we have one
of those usually the database vendors
they've got lots of lovely tooling
around that space so it's never a
problem if you're doing really cool
hipster micro servers peer-to-peer stuff
and you're trying to trace the
transaction timers for those you're out
of luck this is why karma is punishing
you for being a hipster there is no good
solution for this yet if somebody finds
one please let me know there is a bit of
an emerging standard called open tracing
or open tracer open tracing IO which
might help you can just start with a
simple timer won't bore you with that so
that's my approach number three make
sure that you have these measurements in
place because if you don't performance
tuning you're just performance tuning by
guesswork and you're relying on your
human instinct on what time is and as
we've just proven that's wrong so make
sure you get the timers also make sure
that you capture the times for each run
and you store them somewhere in a data
store doing that sort of historical
analysis you'll you'll find out actually
surprisingly important
section number four this is the very
very important section the performance
diagnostic model invented by coke piped
iron there in the corner you can go get
your model when you print it out signed
by him afterwards you have actors which
are the humans or systems which do stuff
which pushes down on the application
which is your code your amazingly
prematurely optimized code that you
wrote those really specialized loops and
and stuff that then pushes down on the
JVM and basically it pushes down on the
JVM primarily in about three ways one
memory so allocating objects on the heap
and therefore garbage collection gets
kicked gets kicked off at some point
utilizing threads so if you firing up
thread pools or if using some sort of
framework which does its own threading
that starts to use up Java threads some
Java threads then map onto actual
operating system threads that's using up
resources and you've got the
just-in-time compiler so if you've got
code which is running hot and the JYP's
believes it is something that can go
optimize that then gets invoked so it's
so on and so forth you're also asking
the JVM to do things like open up
sockets right to disk do all sorts of
exciting activities that all pushes down
on the what we call the OS or Hardware
layer and that includes your
virtualization your docker containers in
your actual physical hardware we just
lump it all into one one of these days
I'll actually get around to splitting
that into two two sections but for now
just you can just treat it as the same
thing so that's the mental model you
want to have in your head and everything
pushes down from the top and typically
each bottom layer knows nothing about
the layer above it right the operating
system doesn't know how the internals of
Java works it doesn't care the JVM
doesn't actually understand what
application code is being run that's
just a bunch of byte codes
you then go through this very simplistic
decision tree and I will stress that
this is an incredibly simplified model
of what is actually really a complex
spiderweb decision matrix which is
Kirk's brain which we've now replaced in
software so yes we are part of the AI
machine learning wave clicking everyone
out of their jobs
sorry Kirk basically what you want to do
this is the key question you always want
to ask yourself what the heck is my CPU
doing if the CPU is busy that's probably
a reasonably good thing but as a colonel
or system busy is it executing really
low-level kernel system activities or as
what we call user busy doing user space
activities in other words as a JVM or
the application forcing the CPU to do a
lot of work and if it's not busy that's
the bottom left-hand corner why the heck
is our not busy your users are screaming
down the phone saying your website isn't
responding
you CPUs not doing any work probably
means your application is not doing any
work
interesting that gives you a path to go
down doesn't it so what we do is we go
and look at what the CPU is doing and
that helps us guide us down this
decision tree and this is crucial to go
through a process like this because at 3
o'clock in the morning when you're
panicking and you're trying to read
through logs and look at your source
code and you're guessing all was at that
stringbuilder or that string buffer we
wrote or was it hibernate probably was
remember what I said about not taking
any specific performance tuning advice
so it may not be hibernate I have seen
some people read the 800 page hibernate
book and get it right not meaning so
what do we do how do we go look at the
CPU I'm only going to talk about Linux
because if any of you people I was going
to say something rude thin are running
on Windows or you exactly what good
thank you or Mac or heaven forbid even
Solaris actually I'll give you a pass
for Solaris although they're killing it
which is a bit said then you're tough
you're a bit out of luck there's a free
command-line talk with VM step you just
say I want to run it for
interval and I need to learn spell
clearly and the results get broken up to
a whole bunch of Citron's and it looks a
little like this so we're gonna ignore
most of this because that will take take
the talk far too long to go through but
on the right hand side there you've got
what the CPUs do it's doing some user
stuff and some system stuff for its idle
and I'm gonna ignore wait because that's
another little semi complicated topic I
don't have time for today
so either the CPU is busy doing user
stuff or it's busy doing the system
stuff or it's actually idle and in this
particular example it's idle right it's
it's meeting over 90% of its time doing
pretty much nothing now remember you
have to correlate this data with an
actual performance complaint that's
coming right so you got a man this is
why people actually continuously measure
what the CPU is doing because that way
they've got that capture of that data
and when the user says oh by the way 10
minutes ago I experienced this
performance problem you can go back 10
minutes look at this data and go what
was the CPU doing during that
performance complaint so it's really
important you kept to that at the time
that the performance complaint was
happening it's also important to only
care about looking at this if there is a
performance complaint if your CPU is
going at 90% 24/7 and no one's
complaining about the performance this
is good you've bought a really expensive
CPU you want it to work right make
intelectually work for its money or AMD
because they usually don't look so
tactic number 4 what is your CPU doing
with the extra bit at the time the
performance complaint or the bottleneck
actually occurred very important oh I'm
running out of battery on my phone this
will be exciting well I ran out of my
clicker speed I must go faster so if you
remember the decision tree which I'll
show you again in a second if we're
going up the CPU is doing lots of system
activity path and there's kind of some
fudge factor on what the percentage of
this should be and that changes between
versions of JVM and the operating system
and if you're not
doing Java of JVM performance tuning it
actually differs if you're Ruby or
dotnet or whatever it's doing a whole
bunch it could be doing a whole bunch of
things right there could be one of these
broad categories which is causing a
problem it might be context switching in
other words something else on that box
is fighting with you or Java for that
CPU and we used to see this a lot with
the typical client-server applications
because people would get the bright idea
of going
we need to co-locate that database
really close to our java rep for speed
and then they install the largest Oracle
database known to man on the same boxes
there poor little Java Web App and if
anyone's ever run Oracle databases in
production and seen what Oracle does to
resources it's pretty much what Oracle
does out there in the marketplace it
will eat you alive so if you see lots of
context switching have a look at what
other processes are fighting with your
Java and on other slightly rarer
occasions you might find that Java is
fighting with itself and that's usually
the fault of someone who's decided to
write their own concurrency framework
and he was not read Brian Goethe's book
who here has written their own
concurrency framework
did you read Brian's book yes one of you
did fantastic the other person is called
your Java concurrency in practice it's
fantastic there's also stuff going on it
could be disk writing right you could
have something which is writing a team
egg of logging data to disk per second
so your disk controller is completely
tied up and that's causing the whole box
to slow down and and you'll you'll see
that really clearly in fact vmstat will
even tell you right look at the bi and
Bo columns right that's your disk i/o
just so you know you got swap space
column there and you've also got how
your memory is being run and you've got
the little C S column there on the
right-hand side next to CPU as your
conflict context switching if you see
that thing going north of about 10,000
on most Linux systems chances are that's
your problem so I won't deep dive into
the technical details for all these
because as I said this is an overview
talk but if you want to
more about the deep dive detail of how
you read things like vmstat
come and find myself or Kirk after the
talk we'll go through it with you how it
all that's so just in case you've
forgotten on the diagram that's that one
so if your CPU is what we call system
dominant then go get out your cheap
Linux tools vmstat netstat IO step so on
and so forth and go see what were what
was happening now remember what I said
previously about capturing this data
during the time the event actually
occurred so it's not just a case that
you can log on to the to the terminal
and start running these tools and
getting an answer you need to make sure
that you are working with your system
administrators or if your devups pro you
do this yourself and that you're
capturing this data continuously 24/7
and to capture low-level data like this
from a Linux operating system is
extremely cheap and there's a whole
bunch of performance counters that Linux
gives you it's a tiny tiny tiny overhead
so we always recommend you just go and
do it so buy the cheap command-line
tools if you really really really need
to spend some money you can come at
seemingly half of the talk where we have
we had some solutions for you Oracle has
been a good role model for us if the CPU
is hitting towards the user dominance so
we're going towards the green bit then
we want to check to we want to check
something very quickly and the reason
why we want to check this thing so
quickly is twofold one is because Java
memory issues are probably the root
cause of about 60% of the performance
complaints that we've seen at J clarity
so I would say we've seen now over
probably over 10,000 alerts coming out
of our systems sixty percent of the time
it's some sort of GC issue so it
actually dominates most people don't
realize this it's the hidden secret or
the hidden pain point of Java today and
the reason is because Java is being
asked to go very small micro service or
extremely large something like data
grids and people just don't know how to
tune the garbage collectors or the
garbage collectors just don't know how
to work out of the box to support this
new paradigm that's why we're seeing it
but what you can do is you can actually
take a garbage collection log by using
the flags I've put up there
not Jeff not for Java 9 by the way if
you want the Java 9 flags you can
subscribe to my private mailing list for
13 pounds ninety-nine a month just
joking we will send that out and in a
later slide update and you can take a
look at the logs very quickly and in
about three or four minutes you will
know whether it is GC which is the
problem which in other words is JVM the
JVM box down there or if it's your
application that's the problem so again
we're just following a methodology here
trying to narrow down what the root
causes where is this thing coming from
so here we have an example and by the
way ours is not the only tool so please
don't see this as a commercial pitch
there's GC GC viewer HP jmeter which is
another free open-source tool to read
these logs you'll get extremely similar
graphs to us yes so there is free
tooling out there I know developers hate
paying two things that big red dot up
there is a 43 second stop the world
pause oops that is a pretty big
performance complaint and for those of
you don't know what stop the world means
that means stop the world the entire JVM
stops did so your whole application just
freezes so again if we've walked down
this path the CPU is doing lots of user
activity and we open up our GC log and
we see that we know what the performance
problem is it's garbage collection and
there's a whole bunch of stuff we can do
to go fix it right but please don't go
to stack overflow to fix your garbage
collection problems please please please
don't do that
maybe it's poor throughput this graph is
showing the percentage of time that the
JVM is spending doing garbage collection
instead of actually allowing your
application to continue doing useful
work and you can see there's a whole
bunch of spikes and banding that go
above the 10% mark and we argue that if
you go above 10% that means your GC is
just doing overtime right again it means
that there's something misconfigured and
this is going to then add an overhead
write a cost elation almost like a
latency cost to every single transaction
that goes through your JVM
right it's just this this overhead that
you just use having to pay for so that's
one graph you can look at your heap
might simply be too small so what's
happening here is that the heap has been
set to about 450 Meg and the application
starts up starts doing work and then it
starts doing a full GC just about every
point one of a second end on in so that
thick red line is actually made up of
hundreds of individual 40 CS now the
interesting thing is that the 40 C's are
actually able to bring the amount of
liveness or the amount of live objects
and the heat down to a a a level playing
field so it's not actually a memory leak
interestingly enough it might well it
might be but it's not looking like one
at this stage because we're actually
able to get back down to a stable state
but there's just no room for it to move
right there's no room for more live
objects to grow in that heat so for this
particular use case you just need to
double the size of your heap or stop
producing so many objects one of one of
two problems if you see this it means
you do not have a garbage collection
problem almost certainly not this is
what we call the sawtooth pattern and
this indicates a very healthy
application so at this point you can go
back to your decision tree cross out JVM
and hit across to the application node
okay hope hope that hope that makes
sense so this is a type of pattern you
typically want to see in your health
healthy jaebeum's
this is a memory leak so we're doing
lots of regular full GCS but you can see
that over time it's going up towards the
right hand side now this is a pretty
long log there's about three or four
days worth and I would say in about a
week's time this JVM is going to crash
with an out of memory error and also
over time its performance is slowly
going to degrade so when people start
complaining that I've app just seems to
be getting a little bit slower every day
then if you see this kind of pattern in
your GC logs again it's actually a GC
problem a lot of people want to know how
to find memory leaks you can just use a
free tool visual VM visual VM comes with
your JDK download if you're using Java 8
or less you can just download it from I
think visual VM github Daiya or
something Forge
what you want to do is you want to look
for the object age so how many
generations is this thing in and is it
alive in all of these generations if it
is you look for the highest one that's
your most likely candidate
you then have to execute visual films
glorious user interface you need to
check check the hidden checkbox on the
top right hand corner so checkbox as
opposed to a radio button we do not know
why this opens up a magical panel which
has another tick box called record
allocations detect traces you will want
to switch this on because this will tell
you the line of your Java code which is
creating all of these objects which are
living in all these generations and yes
it will be your code that is causing the
memory leak almost guaranteed if you
manage to find that that Java itself is
causing a memory leak then I'm
personally willing to pay you 50 pounds
it is extremely rare so do do call me up
on it if you find one so just visually
visual VM fired up press on the memory
profiler button see that settings
checkbox top right hand corner make sure
you've opened it up make sure you record
allocation stack traces and what you'll
end up doing is once you've taken a
memory profile as you'll get a lovely
screen like this concurrent hash map
entry was the thing which was basically
leaking but the code our source code
Hawkshaw which is of application that we
have to produce nasty memory problems
like this was actually the root course
so now we can go into that line of code
and we can start fixing the problem a
word of warning with memory profilers
several words of warning there will
heavily impact the thing that you are
measuring so again it pays to have a
clone of production or take a node out
of production and run this on that as
opposed to running on production you
have to think carefully about your
sampling rates so all memory profilers
will do some sort of sampling you need
to make sure the sampling rate is
appropriate to the rate of objects that
are coming into your JVM
so you actually
you genuinely capture what's going on
your JVM and you're not just capturing
only you know a one one-off event so on
and so forth all the different profilers
will tell you slightly different things
so sometimes it pays to use a couple of
different profilers if you're not
getting a clear result most of the IDS
Eclipse IntelliJ NetBeans all come with
free profilers so you don't to go pay
for one if it's not the JVM so if we saw
that sawtooth pattern we then want to go
to the green box which is the
application so it's likely that
application code is the problem which is
quite rare and the reason why it's rare
is because Java's JIT is exceptional I
think something over a thousand person
years engineering effort has gone into
the JIT nobody truly understands it
anymore which is probably why it's being
replaced by growl because at least you
can interrogate it with a Java API and
make some sense out of it but if you
ever do manage to capture Cliff click or
any of his early cohorts who helped
write the JIT then he he he can take you
through an interesting to her
so there's just a few optimizations this
is just a subset and the most powerful
of these is called method inlining and
the key thing here is to just write your
source code in a nice deRossett software
craftsmanship Uncle Bob solid principles
Menna
which means short sharp methods that do
one thing and one thing well the
interesting side effect of this is that
usually those methods are less than 35
byte codes which means they're eligible
for method inlining uh-huh if you can
method in line something that means the
JIT has got a much larger playing field
of optimizations that can play with so
very very important to go do this
there's some tooling to help you figure
out how on earth about you go doing this
I'll go into that shortly so 35 byte
codes again there's some free tooling
which will help you see that when you
look at your class file after you've
compiled it what myth is are 35 byte
codes or less
and the default rule by the way is that
this method must need to be executed
about 10000 times in order to be
eligible to be jittered unless it's a
really really small method right
something like listen six byte codes
they only need to be run about 250 times
before the tip can pick them up and
start running them that's really handy
with getters sitters or really small
mathematical calculations that you want
to run really quick those go walk
through a little example here who here's
Dunford's Fuzzle fuzzbuzz for their
interview did you pass oh really -
people said they passed the honesty here
is wonderful so here's a typical Java
Enterprise version of fizzbuzz here's
the first half of the code here's the
second half of the codes I do assure you
that you can run this code it is
actually correct and this is kind of
what I'd expect you know mid weights or
even a junior job because I've had to be
able to knock up on on a on a coding
test the just-in-time compiler takes all
of this code all of this nice readable
verbose code which is actually how you
should write it not necessarily this
particular problem but most java code
and it turns it into that under the hood
don't slice or automatically write so
you don't need to do all of these
premature optimizations that Stack
Overflow and all Java manuals tell you
to do
JIT really I'm really serious about this
the JIT will do this stuff for you and
it is far far better than most humans
there's I'd have to inline variables of
the compiler can do that too sorry the
method inlining technique I'm talking
about is something that the JIT does for
you so I apologize I wasn't clear there
so method inlining
is a JIT technique and what actually
happens is that you have class a which
say calls a getter or a setter from
Class B and under the hood so during the
JIT compilation phase it takes that
getter and sucks it into Class A and
makes them that makes the method in
class a bigger with all that extra code
and that gives it more
to play with more code to optimize right
where was I another little fun game that
the drip pulls who here can tell me how
fast it takes to create a million Java
objects was it guess here zero seconds
zero seconds is correct Java is
superfast wires Java superfast because
ou never escape set for loop and the
just-in-time compiler goes cool doesn't
escape the for loop it's not needed
bye-bye kills it
right so this is why when you're trying
to do your own micro benchmarking micro
benchmarking is really really hard right
there is a framework called the Java
micro benchmarking framework jmh which
is actually what you should do if you
want to use this stuff right now I'm
running behind time so I'm going to go
really quick knit beans or visual VM
also has an execution profiler so if you
need to find out what application code
is burning that CPU which can which can
happen if you're using if you're doing
some sort of CPU intensive calculations
open up open up the execution profiler
look for the big red bar at the top
remember to click the magical settings
checkbox and the record allocation step
trace and the execution profiler will
tell you what your Java not don't need
to record allocation of tetris apologies
NetBeans will tell you or visually le
what your Java source code is is
creating all this weights on the CPU
effectively again if you use an
execution profiler like this so J
profiler NetBeans whatever it will have
a heavy impact on the JVM that you're
trying to attach to so again try and do
this some tests and you'll be better off
if you want to have a torch will tell
you with you or 35 byte codes unless
there is a fantastic free tool called
jet watch it has a three pane editor
your source code the Java bytecode and
then the actual machine code so go to
get github adopt open JDK and under
there is a tool called JIT watch written
by a guy called Chris Nuland who is just
absolutely fantastic
and here's a quick sample of the Java
micro benchmark harness written by
Alexey Shibboleth used to be Oracle's
and now Red Hat's
Java performance guru this is a tool you
want to use if you want to micro
benchmark your code because it will do
stuff like take into account what JIT
will do and what the garbage collector
will do so it gives you more accurate
readings of what of how much time your
code actually takes to run so the last
pro tip is just rights solid code small
methods that do one thing and one thing
well typically that means it'll be less
than thirty five byte codes which
typically means it'll actually fit
nicely into the just-in-time what the
just-in-time compiler can do for it so
if it's not so if the CPU is not system
dominant and the CPU is not user
dominant so it's not that it's not the
garbage collector and it's not your
application code running hot and the
CPUs idle that you need to figure out
why and there's lots and lots of reasons
why this can happen right miss met miss
size thread pulls asynchronous
frameworks where the response doesn't
come back ordinary request response
where the response doesn't come back
database has gone down therefore
nothing's coming back so on and so forth
right or internally inside the JVM it
can be things like deadlock threads live
lock threads and so on so what you
generally want to do is you want to
reach for what we call a thread profiler
so just from reference back to the
diagram we're down in that bottom corner
if you want to look if it's C if it's an
external issue then there's an awesome
tool called Wireshark and I just prefer
this because it's a graphical tool that
you can easily filter types of traffic
on so you can filter the traffic's the
ports the protocol so on and so forth
it's great for spying on your neighbor's
Wi-Fi and it's also quite useful for
figuring out what's happening to the
network so why are requests and stuff
not coming back in if it's an internal
JVM threading problem then you need to
understand some theoretical background
of how the threading model works in Java
here is a nice simple diagram if you
really want to find out how the stuff
works then dr. hydaker boots are sitting
in the front
here and he runs probably the world's
best training course on Java concurrency
that that's where I learned to my
concurrency knowledge from he's the
person you want to go talk to but again
you can reach for NetBeans or visual VM
or any of these free profiling tools and
just click on tell me what the threads
are doing yellow is waiting green means
the threads doing something red usually
means it's blocked okay it's that simple
so if you're seeing an awful lot of
threads waiting and you will say your
servlet thread pull your database thread
pool you know that that thing isn't
responding properly it'll also tell you
information about that thread so you can
start tying it back to Java code ends
deadlocks are automatically detected for
you as well now so you don't need to
worry about that remember this is just a
free tool so just go download it and run
it so you use Visual VM or NetBeans if
you want to use the cheap free tool
there are more expensive commercial
tools that are a little bit more
specialized and are possibly a little
bit more accurate including our own in
conclusion do not rin by folklore that
is a really really really bad idea and
we've seen teams spend months even half
a year trying to chase down a
performance problem because they're just
guessing and they're costing themselves
an awful lot of frustration and their
company an awful lot of money so try and
follow a methodology like the diagram I
showed you and apply the tools as and
when needed some stuff we don't help and
I've got time for exactly one question
because I have 30 seconds that was well
done wasn't it who has one question one
question can I see it's gonna be no
questions I went quick obvious in the
front yes okay
yes so the question is visual Veeam is
already open source but oracle has
announced that they're opening an open
sourcing java flight recorder and
mission control this is true and flight
recorder and mission control are both
excellent tools but there will only be
allowed to be used in production
license-free
only after oracle has actually completed
open sourcing these tools so at the
moment you can only use those tools in a
development environment for free else
you have to pay I would personally say
that sometimes it tolling is worth
paying for your management and your
chief financial officer may not agree
technically how do they compare Java
flight recorder is by far and away the
most accurate recorder it's in the name
of telemetry information out of the JVM
that exists today they have got hooks
into the JVM that nobody else does which
means they can gather data in a less
impactful manner than any of the other
existing tools today so it is something
that we ourselves will be basing our
machine learning off once it's become
open sourced so thank you Oracle there
we go round of applause for Oracle for
that one it's really good all right so I
will exit the stage now because we've
run out of time for questions but you
can find myself Kirk or Hines probably
here for a few minutes and then outside
thank you very much again
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>