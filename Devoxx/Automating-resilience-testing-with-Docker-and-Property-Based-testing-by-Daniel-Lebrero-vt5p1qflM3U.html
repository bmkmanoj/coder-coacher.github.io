<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Automating resilience testing with Docker and Property Based testing by Daniel Lebrero | Coder Coacher - Coaching Coders</title><meta content="Automating resilience testing with Docker and Property Based testing by Daniel Lebrero - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Automating resilience testing with Docker and Property Based testing by Daniel Lebrero</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vt5p1qflM3U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Birgit inflated do it replaces hello
everybody
Daniel liberal thanks a lot for coming
and we are here today to talk about
Brazilians docker and property-based
before we get started really quick about
me I've been working on the JVM for 17
years I built all kinds of applications
in all kinds of architectures I'm
working right now as a Technical
Architect for IG IG is a world leader on
safety and spread betting part of the
footsie 250 and it has development
centers in London Krakov and Bangalore
and one of the things that we do I die
g8 build micro services so I was
recently involved in one of those
projects and we build new micro service
and I Peter press open
what's going on yeah so we have to build
the service and it has a very simple
service there it's only your watch to
move some messages messages oh my god
and I broke everything in the second
second second second second
yeah sorry about that
it sure was very simple just have to
move some some messages from Capcom to a
third party so we put this first version
in production and everything was working
the fully fine but then we notice that
some messages were getting stuck during
Kafka so we look at the logs and we
found a bug in an open source library
that we were using to consume from Kafka
so we raise an issue the issue table fix
and we deploy our second version in
inter protection with the second version
of the library and everything was
working fine but then some days later
half of the messages somehow they
started to get stuck in Kafka so we look
at the locks we did some thread thumps
we found the issue and it was basically
in the same library so we write output
requests they got fixed and we put the
new version with the new version of the
library into production and everything
was working perfectly fine for some days
but then some days after messages got
stuck a bit again in Casca so we did our
investigation we look at logs and we
found the issue again in the same place
so by now you can understand that we
were not very confident that this
library was the right choice so we did
what any good development team will do
we decide to build our own because we
don't write this and we don't write any
bugs so we put the new version of the
library in as the new version of the
service into production and everything
was good for some days and then somehow
we managed to duplicate all the messages
to the third party so we'd look at the
logs we did some thread dams sub hit
terms and we found a bug there yeah big
surprise because we never write bugs so
we put the new version into production
and everything was good for some days
and then some days after everything was
good
so we were really proud of ourselves you
know just one bug that's very good but
then some weak legs weeks after messages
got again stuck in in Kafka
investigations a little bit of Christ
and you know you know how how it goes
and we found the bus exactly exactly in
the same place so right now we are
running or we have been running with the
six version of the service in production
for some months but I'm sure that there
is still something there that is going
to blow up at some point so you may be
wondering well on this guy right unit
test and of course we do we write plenty
of unit tests but all these issues all
these bugs happen on the integration
points between components and they all
happen when the component was either
misbehaving or when the component was
having some stability issues so the
correct question to ask should be on
these guys to resilience testing before
we answer that question let's define
what is resilient testing so we look in
the dictionary for resilience we have
those two entries we're just going to
focus on the second one resilience is
the ability to recover from or adjust
easily to misfortune or change so what
does it mean for our IT systems to be
resilient the first thing is that they
need to elapsed they need to cope with
any component going back and we say add
up it doesn't mean that they need to be
running a food capacity or they need to
provide all the functionality it
adjusting can mean that they have to
gradually degrade to cope with that that
bad component the second is they need to
recover
so once the component is fixed the whole
system without manual intervention it
should go back to its initial state so
you should go back to full functionality
and full capacity so Brazilian testing
is just checking that our IT systems
they have these two properties yeah to
be able to adjust unto it to be able to
recover
so back to the question don't we do
resonance testing so at the gym we try
to follow all the patterns from the
related book and but we struggle with
one of those patterns that's a test
harness button if you haven't read the
book the test harness pattern is really
simple it only tells you to be really
mean to be really really able with your
application and the book it gives you
some examples about what does that mean
so you read the book and then you go to
your problem guys and you ask them these
reasonable questions
can you please kill the database can you
please limit the bandwidth to one byte
per second can you plug police and plug
the disk from the GMs server or can you
please stop the network but I always get
the same answer now so what kind of
resilient testing we can do is we cannot
do all those stuff but to understand why
we get always that negative let's look
at how we do resilience testing at a gym
so the first thing is that we are
running our resilience test in our
staging environment which means that if
we inject any false the whole company is
can potentially be affected the second
who are running all the personal stress
modeling so we have a wiki and in the
wiki we will have all the steps about
what we want to break and how what we
want to break and then there has to be
some poor soul that has to go in front
of things normally we also have a broad
plan again at the end of the day we page
with all the actions to recover and we
know that when you do things manually
what happens right because of all these
three we usually limit ourselves to stop
and to stop and start some of the
components in the system and we usually
avoid trying to touch any of the shared
components I'm running any of these
tests is very expensive right we need to
get the platform guys the QA guys the
developers and some architects into a
room and they have to agree about what
we are going to break and when and then
we have to go and manually run all these
things
and because it's very expensive and it's
very cumbersome what we usually do which
is run the Brazilian test once before we
put the system in production and then we
usually don't bother anymore
so what do we really want we want a
completely isolated environment where we
are sure that we are not going to affect
we are not going to bother anybody in
the company I will learn how long time
ago about how nice our automated test
and the same for robot we want the robot
to be completely automated but in the
case of the rollback we also want to
make be completely sure that the
rollback plan it's simple and it's
consistent because we don't want to have
any lingering folks in in the in the
system we want to be able to inject any
faults that happen in him that can
happen in production so not just
stopping and starting some of the
services what we want to be able is to
mess around with the network or break
some discs we want to be able to do
anything that can happen in production
of course we want the test to be really
shaped - right and we also want them to
be really cheap to run and last we want
to be able to run all these tests in our
continuous integration environment or
whenever our developer they'll feel like
so what tools can we use to get all of
this first one is docker compose docker
compose is part of the rocker switch and
it's going to allow us to define a whole
environment in just one file and it's
going to allow us to start a whole
environment with just one command as
part of the start in that environment is
going to create a private network where
we can mess around and inject false
docker compose is also going to give us
the ability to just with just one
command destroy the whole environment so
that this give us our drawbacks tragedy
that is just going to be burn everything
to the ground and start from scratch the
second tool that we need is some kind of
library to be able to play around with
the environment and to be able to
simulate those faults so IG has open
a library called IG Harbach that is
going to give us three things first it's
going to give us an API to be able to
start and stop or restart or kill some
of the components second thing is going
to give us an idea to be able to inject
folks in the network like for example
and delays or limited limited bandwidth
under setting that they give us is an
evil HTTP server that we can use as a
base to create a work to mock ourself up
the dependencies our external
dependencies and it's also going to
allow us to simulate falls in that
external dependencies so for example
returning always a 500 or return a huge
or an infinite response now you can use
these two tools for it doesn't matter
with language or runtime that you use as
long as it runs into courage you can use
these tools on this approach and the
second thing is that the you don't need
to be using the Korean production to to
use them as long as you can run in your
laptop or in your CIA environments it's
it's a useful thing so let's look at an
example about how to write a test so
this is the architecture for the system
that I was talking at at the beginning
just as a reminder is you know this
isn't the only thing that we need to do
with move messages from Casca to a third
party that third parties on HTTP
endpoint now because we are going to run
a test we don't want to talk with that
real third party so what we are going to
do is you are going to replace that
third party with a fake server and this
fake server we are going to use it for
two things first we are going to use it
to record all the messages that we get
from that service that we are building
and the second thing is as I said just
to simulate just to be able to inject
false and pretend that the third parties
misbehaving and each of these boxes will
represent will be one docker container
okay so let's look at docker compose
file to be able to relate to build up
that system
so this is all that you need so um one
bit at a time that's just how you create
a zookeeper so this is just one of the
zookeepers we will have three of these
entries and we're just using up vanilla
zookeeper from from docker hub so it's
very simple to spin up a new a new
zookeeper cluster the same for Casca
just a vanilla zookeeper sorry vanilla
docker image and notice that we are
going to run we're going to run it in
privilege mode because to be able to
inject falls into the network we have
fully need some good privileges as I
said as part of create docker compose a
box part of creating that that private
network it's also going to create a DNS
server so you can reference other
containers of the continuous one name
this is the service that we are testing
so in these cases it's a tomcat
application so again this in this case
we are adding a couple of things into
the image from docker hub so we are
adding at the root and XP cables that
have these two tools that we are going
to use to inject holes into the system
and notice that the path there of what
we are deploying to that Tomcat it's a
relative path and that's because we are
going to be building that war as part of
our bill plan so we want to run this
test in our continuous integration
environment and last fig server which is
just a java application so very simple
and notice that we are going to be
exposing a port so from our test for our
test to be able to connect to that fake
port to to a fake server and to be able
to know what what's going on inside the
system okay so let's write our first
test for our first that's what we are
going to do it well our system should be
able to work if one of the two instances
is done so we're going to have maven and
we are going to use something like a
unit to be able to run it so the test
what is going to do first it's going to
start the whole system just a token
compost
then it's going to kill one of the
services then is going to connect to
Casca and it's going to send a bunch of
messages come on and then it's going to
connect to that fake server through that
port that I talked about was talking
about to check if we got all the
messages and then we're going to tell
docker using docker compose to get rid
of the whole thing okay so that's our
drug plan which is going back to clean
estate so let's look at a little bit of
code for those not familiar this is
closure let's go one line at a time
now when you start talking when you tell
docker compose to start a whole
environment you have to give it some
kind of ID so if you are running this in
a continuous integration environment you
need to make sure that that project name
is called break name in docker compose
it's unique and so if you have several
branches or if you have several plants
you have to make sure that that break
name is unique this is how you define
that is like a unit testing in Java a
unit test so that that's basically the
same thing and then we did the first
step to start the system so we're just
using the docker compose common line
using the Java shell to start it and as
I said we are using that the project
name then we create a docket object and
we are specifying that that's the dog
hair API so we're going to use that from
the test to be able to connect to docker
and run the commands and then we tell
docker to run a command which in this
case is to stop service number one other
examples this will be for example to
start and if we wanted to inject between
5 and 50 seconds latency between service
to on the fake that's how a command will
look like then we send bunch of messages
and here's what we are doing our observe
p.m. so we are saying that we expect
that within 20 meeting if within five
minutes we receive the 20 messages and
we are giving it a little bit of time
because we are sending things at
synchronously plus the system if we are
injecting any false maybe need some
to detect that falls under cover and and
adapt to that fault and last we just
stop the system again using the dr.
Campos common line yep so we have
written that test probably now we want
to write more tests right probably we
want to make sure that our system is
able to cope with one of the gap cuts
going down or maybe we want to check
that our what happens if one of the
services is not able to talk with the
zookeeper cluster Cory this service has
some problem talking with the fake maybe
what happens when those two things are
broken or those two things or maybe
those two things or maybe those are the
things if you are good at math maybe you
are now thinking about well there are 14
things that can break maybe they can
break in four of five different ways so
how many tests do I need to cry to cover
all those cases so the answer is that
there is an infinite number of tests
because in the case of resilient testing
is not important just if the state of
the oven of a component is up or down
it's as important the order in which
things happen then now you are like me
you're probably thinking oh come on
let's be serious you know most of those
faults they are not going to happen in
my environment that's completely
impossible but I have a more famous
quote yes I didn't expect that because
if I have expected that I probably will
have a bit of code to handle that
particular case but in the case of
outages what usually happens is that
something impossible it becomes possible
so where we are we know that we want to
write some tests but we are not sure
which tests we want to write so how do
we do how do we go about it so one
option is property based testing
who is familiar with property based
testing - cool
I'm going to splaining sorry about this
I'm going to explain it very hopefully
quickly let's say that you have write
your own plus function and you now want
to test it so in the case of example
base testing which is the testing that
we do every day your unit testing what
you're used to what we are going to do
or what you will do is pick up two
inputs like for example a equals six B
equals two and then you will assert that
a plus B is 8 so you are picking up
those like those particular values and
then maybe you will say okay I'm going
to test with negative numbers or I going
to test with one positive on one
negative so you are specifying each of
the inputs in the case of property based
testing what you do is you specify all
the possible inputs to your function so
in the case of a what we are saying is
that while it can be any number and B
can be any number now we have the
problem of what can we assert because
you know in your code you are not going
to know if a is 6 or 9 or 25 it can be
any number so we have to assert
something that is true for any number so
that's called a property so in this case
a possible property will be that a plus
B is equal to B plus a and once you have
written this test what you will do is
tell the library the property based
library to go around a hundred of these
tests or a thousand of these days and
what the library will do is first it
will generate a random a then you will
generate a random B and then you will
run your ascertain if the test passes so
if your asserts are true if your
property is hope true it will generate
another a and another B and it will run
the thirteen again and we will do that
as many times as you tell him now
if the if the property if it's false so
if that excite is that a 13 fills what
the property based test library is going
to do is trying to spring the value and
shrinking the value it means that is
going to try to find the smallest value
on which that property that assertion
stills fails so let's look at a very
simple example let's say that you write
that that's your plus function and you
have that little bug so if a is bigger
than 100 you are going you know it's
going to fail so we'll run a propagate
property test we are going to get an
output something similar to this so
let's is focusing those two lines
what those two lines are telling us is
that the library was able to generate
106 cases 106 random 8 and random base
and everything was fine but then on a
hundred and sixtieth time it found that
the property fell and fell with us to a
particular value G so if you have a
equals minus 39 and B equals 104 then
the property fails but then it does this
ranking so in this ranking we try to
find indicates of numbers with trying to
find smaller numbers numbers close to
zero and it's able to tell us that if
you try the same function with 0 and 101
and notice it's 101 then add your
properties well again apart from that
it's going to give us a set so if we
want to run exactly the same test with
exactly the same input you can you can
use that set to generate the same inputs
and that's basically property based
testing so first thing that we need to
do we need to decide what are the
property so in our case for resilient
testing for the system that we are
talking about which properties do we
have the first one is that we want to
make sure that each message it gets a
list once into the third party right the
second one is because it's at least once
it means that we allow some duplicates
but we don't want a lot of duplicates
and the third property is that Kafka is
a topic it's something that's in Orleans
so we want to make sure that when we
send data there is no way that all data
over right
okay so those are three properties that
doesn't matter what happens they should
be they should be true for our system
now what kind of input
do we have for our resilience testing so
in the case of resilience testing the
input it's all the possible faults that
can happen in any organ into the system
and all the possible recovery reactions
for the system and so we need to
basically generate a random relative
resilience test plan for our system so
IG hubbub comes with a with a function
to be able to generate those random
resilience plan so a function and what
we are specifying is which things we
want to break yep so in this case we are
saying that we want to break but the
service oneself is two caskets and we
want to break the link there the network
link between those two components then
we specify how many entries we want
integrated in that plan and what this
function will return is at release the
sealant this plan like this okay so in
this example stop one of the cap cars
breaking the de network between service
one on the fake and then stop of one of
the other services now you think about
it if we generate just you know random
commands in our system
we can end up in a situation like this
in this situation it's impossible that
those three properties are going to hold
true because nobody is going to be
sending anything to the fixer so it's
not enough to just generate random
command we also need to specify what are
the healthy stakes of our applications
on which states with back the
application to be applied to be working
so in the library so a part of deciding
what things you want to break play
around with you need to specify which
are the healthy states of the
application so in this case we are
saying that there are three states both
services have to be up and running or
service one can be stopped or service
still can be stopped and so one of the
two services have to be a
running so now if we generate a random
plan a random Brazilian state plan we
can get something like this we stop
first service number one we stop service
number two and now when the system is
completely broken but the library would
decide I will decide we'll make sure
that the last set of commands take you
back to one of those healthy states
which in this case is just the start
service number one cool a little bit of
code that first thing is just how you
call the library and in this case we are
saying Oh from this test one hundred
times this is the input to our oops this
is the input to to our this is the input
to the to the to the to the library so
we are saying okay generate a random
plant and notice that we we passed they
all things that can break and all the
healthy states then we start the system
as we were doing before I will create
the docker and we start on a synchronous
thread send the messages in and while
that thread is sending messages so there
while there are some messages floating
around the system what we do is we are
going to execute our resilience plan so
we're going to do for each of the steps
on the plan would run it and then we
wait ten seconds and we are giving it
again a little bit of time to the system
to be able to recover or to detect any
faults once we have finished the plan we
are going to wait for those twenty
thousand messages to be sent and then we
check our properties this is where we
are checking them and three properties
that were checking its first respect
exactly twenty thousand messages or
unique messages because they have an ID
want to make sure that the each of them
was received by defect fake server then
we check the duplicates which in this
case we are saying that around 10
percent duplicated is it's a reasonable
armament and then we check that all
things doesn't overwrite new things and
then we stop the system so does its work
if you think about it we are
generating at random a random set of
random Brazilian says plan but the
number of tests that we have is infinite
so is this able to work so in our
experience we were able to reproduce the
first four outages with that test that I
just show you
yeah and some of the day of some of the
issues were not really trivial so for
example for the outage number two to
reproduce it you need to kill the Kafka
to start that service you start the CAC
again then you will start that Casca at
that and at that point that service is
not able to consume messages from that
Kaka so it's not something that you know
I will think about it now if you
remember we talked about five outages so
what about version number five so would
run this test for hours days and we were
unable to reproduce a ship but then
somebody realized well ok wait a second
what what are we doing where it's
starting system then we send a random
set of commands at the same time that
we're sending messages we do over a
certain we stop the system and then we
studied again now somebody says well how
do we fix everything in IT
so we thought well maybe on that restart
is when we are actually cleaning some
bad state so we wrote another test which
was we start the system we send it to
thousand twenty thousand messages plus
we run the random command now we make
sure that on those random commands we
never stop or restart any of our
services so we'll make sure that our
service is up and running then we do the
ascertain and then we start back again
with this test we were able to reproduce
the issue number five after several
hours of running now in the case of
issue number five and the issue was that
if the third party return of 401 and it
had to be a 4-1 if it was 400 or 500 it
was okay but if it returned of 401 and
then we send two hundred thousand
messages then the system will stop
working so the problem with this
approach is that what I talked about
shrinking doesn't work anymore because
you don't know if the cause of the
failure happen in the last iteration of
messages of of commands or it actually
happens like ten or a hundred iterations
before so it shrinking in this case is
useless so what about version number six
that have been running happily in
production for several months we found
out one by one but I think we all have
one of those even if you don't know it
it was interacted to find that we found
to raise conditions in the test code
itself we found that if the third party
returns for once we lose messages so at
least it doesn't crash but we lose
messages we will start sending
duplicates like crazy if we don't get a
well-formed JSON response any huge
response from the third party will kill
our service we also found out dependency
on this startup of our our components
and we usually try to avoid any kind of
startup dependency we also have fun or
somewhat the
tests remind us that our Casca setup he
wasn't present enough this was
interesting because as part of
generating the random plan we need to
specify what are all the healthy states
of your application one of the tests
that we wrote is okay we have all the
healthy states so we won we wrote a for
loop basically saying okay I'm going to
test each of the of the healthy states
to make sure that is happily true and
what we found is that a lot of the
healthy states what was spected to be a
healthy state were certainly not that
healthy and the last thing is that
between version 5 and version 6 we are
fully reactivated the system and it was
interesting to see that version 6 have a
bigger proportion of healthy states
which means that version 6 wise by
definition it should be more stable more
more stable than version number 5 cool
what are the drawbacks of this approach
the first thing is that this very very
very very slow to run so tests like that
can take several hours we sometimes
believe it several days you're running
to see what was able to find something
AB sometimes like as I explained for the
part number 5 it's shrinking is useless
then we still have known deterministic
in the system right we are doing things
in parallel there are a lot of tricks
going around so it's possible that you
hit an issue and you are not able to
reproduce it again you will have an
infinite number of tests which means
that it doesn't matter if you have been
running this in production for I'm sorry
if you have been running the test for
four hours of days you are not sure if
if you have anybody in fact version
number six we have another outage this
time around was an out of memory error
and it doesn't matter we will run the
test for days because the issue was that
the test was sending data to one Kafka
topic but in production this application
was actually consuming from tenth casket
objects and in our test we made the
assumption that sending it to one topic
should be the same as an in
two to ten topics so we're a little bit
lazy and production show us that we
shouldn't be lazy because we have
another outage but as it is this nice
paper called simple testing can prevent
most clicks critical failures where they
study they do an analysis of 200 outages
in distributed systems like HBase or
Cassandra and of those 200 outages they
found that 74% of them worth the 10
minutes and so you execute the same
three commands in the same order you
will always be able to reproduce it and
also they found that in 90% of the cases
you just need three three commands three
things to happen to manifest the system
to manifest a failure so maybe that's
why we were lucky and we were able to
reproduce all the issues so takeaways
doctor is your friend and don't write
this thank you very much sorry sorry
sorry
when I say don't write this just to make
it clear I'm saying state your
properties check your assumptions and
let the computer do the vetting work
thank you very much
some references if the last two papers
are a different approach they're really
interesting so just operate that really
interesting and with that I'm done if
you guys have any questions happy to
answer
yeah okay so I think I think it's great
and we're trying to get close to this we
see some of the unusual paths of system
failure that you're seeing when one of
the dependent systems such as solar is
attempting to rebuild indexes and isn't
ready to be taken over by the e and deal
the system failing but everything you
have here is is still on stage as
opposed to in production yes and a
number of the systems that we are
dependent upon despite our best efforts
don't belong to us and their stage
versions are not the same as the
production so do you have anything that
that helps you do a similar kind of
thing but in production cool so the
first thing is chaos monkey code so our
problem our problem is not a problem
which kills monkeys are annuities
ourselves kills monkey was great if you
are running in Amazon Cloud we are
running on premise which means that we
are not able to get close to production
because you know the the fix from
Netflix guys you're like I destroyed
this cluster if it doesn't work and I
credit in another place we cannot do
that so that's why we cannot use that
now I'm doing this things in production
we we still we are not I don't think
ever going to do that so I'm pretty not
sure how to you know a part of mock into
thing because you don't in theory you're
doing your test ensures you don't want
to want to hit that that sell party so
just you try to mock it you start
impossible that completely fake it that
completely out of we tried so I'm with
you I think we're in the same places
were which is what coffee turns into
time thank you
more questions this is the second that
fakes over for the third party how did
you did you or make sure to to have all
the kinds of Radio states of the
original system in the fake server okay
so it's an HTTP endpoint all HTTP
endpoint fill the same way you will get
a 500 or you get no response or you get
a malformed response
so it's HTTP so it really doesn't so in
this case we are not looking at if they
return a particular or in this
particular case is not important is a
return on how to say one form JSON that
contains an error inside it so from our
point of view just an HTTP endpoint and
so we just test it as any you know
generic HTTP I'm going to same failures
that you would expect yeah like you kind
of answered my question already but how
do you run this test and well my initial
question was how long two days a so and
so right now it's ad hoc
so we haven't put in a continuous
integration server the first thing
because we we don't have talker in our
continuous integration environment so
first I need to convince the platform
guys to give me talker so where do you
need a hook right now in you know in the
developer boxes like off just run it you
know I'm going to leave it overnight to
see if I find something next day
can you can you apply this to long into
docker or or can those commands be any
arbitrary moans sorry idea can you apply
this tool to only to docker containers
or can it be actually any any any sort
of hosts and commands ah seeing it's
your socket well it says everything
Indian Theory it's the same as that is
fixing nothing like Justin I don't know
if you guys are familiar with jasmine
there are a bunch of tools that do this
in this failure injection but they're
usually it depends on the platform that
you are running it
I copy most of the failure modes from
from from the next play from Netflix
chaos monkey is just I needed to go
through the docker API to be able to
apply them instead of what they are
doing with Amazon so you can copy the
failures how to do the failures is just
a matter of how you are going to deploy
that into or how you are going to apply
that into your environment anything else
thank you very much guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>