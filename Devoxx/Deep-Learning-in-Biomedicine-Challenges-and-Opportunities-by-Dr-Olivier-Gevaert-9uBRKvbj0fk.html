<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deep Learning in Biomedicine: Challenges and Opportunities by Dr. Olivier Gevaert | Coder Coacher - Coaching Coders</title><meta content="Deep Learning in Biomedicine: Challenges and Opportunities by Dr. Olivier Gevaert - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deep Learning in Biomedicine: Challenges and Opportunities by Dr. Olivier Gevaert</b></h2><h5 class="post__date">2017-04-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9uBRKvbj0fk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning and welcome to day three
final day of devoxx us tons of
interesting things on the schedule this
morning we have lots of language and
platform and mobile and embedded stuff
coming up but first we have two keynotes
this morning we're gonna hear from
Olivier
if art's talking about biomedicine and
tensorflow
and then we have a talk on a slightly
different topic the Brian Kane it comes
from the Rhode Island School of Design
and they started or have the only AI
design program in the world I would be
willing to believe that he's going to be
talking about art AI and apparently
walfish so enjoy the keynotes and I'll
see you in a few minutes oh one
important note we do have a timing issue
this morning we're probably going to run
a little bit long which means that the
first talk is going to start at 10:00
after the hour instead so it's going to
be ten ten to eleven and then we're
gonna push all the morning talks by that
same amount so everything on your
schedule it says it starts at the hour
and runs to 10:00 - we're gonna push
that by 10 minutes it starts at 10:00
after the ow and runs to the hour
Olivier it is your show
good morning so this morning I want to
introduce you in how we are using deep
learning in biomedicine so my name is
Olivia G farts and I'm an assistant
professor at Stanford University and we
essentially investigate how we can help
cancer patients to develop treatments
that are better focused on their on
their tumor instead of general
populations so deep learning and
software implementation success tends to
flow have a huge potential in
biomedicine however not all biomedical
data is a meat is suitable for deep
learning so there's a lot of challenges
and the biggest impact is what is now
called precision medicine and what is
precision medicine so precision medicine
is essentially treatment of patients
where we've really tailored the therapy
to their to their disease it's a very
data-driven
so the possible sources of data that we
can use nowadays or clinical data
there's a lot of wearables like Fitbit
or other types of devices we have also
molecular data such as blood tests DNA
tests and imaging data such as MRI scans
or CT scans so there's a lot of big data
going on in medicine nowadays and so
it's important to make a distinction
between big data and data science the
idea of big data is that collecting more
data is going to solve your problem such
as for example at Facebook is doing with
face recognition where essentially we
have millions of examples and we can
easily train complicated models and in
many cases these models are essentially
back box models
another example is image nets which I
may be some of you are familiar with
this is very large database of images
that has been used for many deep
learning and tensorflow developments and
it essentially contains more than 14
million images that we can use for
developing machine learning models on
the other hand we have data science
where essentially we are more focusing
on on the problem itself and using
domain knowledge because in many cases
we don't always have enough data
especially in biomedicine
have these huge millions of data points
and then we essentially want to
incorporate information about the domain
to be able to model this data so
typically what we have in buy medicines
we have lots of features we have
thousands or even millions of features
so we have high dimensional data but we
typically don't have that many instances
so we need data size approaches and we
need to use deep learning approaches to
overcome this lack of annotation and we
need to adapt deep roaring to be able to
to have feasible solutions so today I'm
just going to give you an introduction
in how we're using these methods in and
how we're using deep learning in
biomedicine and first I'm going to
briefly introduce like what sort of data
that we have then I'm going to talk to
you about some more traditional modeling
that we that was done in biomedicine
before deep learning and then I'm going
to give you some cases of how we use
deep learning in medical problems so
just a brief overview of what is
biomedical data and what are examples of
biomedical big data so one of the things
that you might have heard is Omegas data
this is maybe something that has you
have heard gene the genome transcriptome
proteome these are all sources of these
are all molecules that we can measure in
high throughput and then similarly we
also have a lot of imaging data such as
images from pathology or radiology and
we can essentially have all this data of
patients and use it for precision
medicine and using deep learning just a
very quick background of molecular
biology so essentially all the genetic
information in your cells is stored into
DNA and that's essentially just like a
dictionary it's it stores the
information then and we can measure DNA
we can measure the all the nucleotides
all the a CG T's in your in each cell of
your body and that essentially gives us
millions of data points then DNA
essentially creates RNA and RNA is not a
nothing less than the messenger it's
essentially the the the way that
information gets transported and then
essentially RNA forms protein a protein
is the protein
essentially what is active in the cell
and that's the workhorse of the cell and
that performs all your cellular
functions and all these three levels of
MicroBot you can all measure them and
they have different types of challenges
and opportunities and we can use them to
predict diseases to diagnose patients to
enter predict treatments and this is has
been possible the last two decades
because of technology of course
initially there was microwave technology
which is essentially a chip based
technology that is able to measure all
these molecules then Hydra put
sequencing and more advanced
technologies were developed other
technologies such as mass spectrometry
can be used for protein measurements and
so on right so we can essentially get
thousands and thousands of features and
sometimes we call this like this is
essentially molecular data tsunami we
have lots of molecular data and
physicians doctors cannot really handle
this data they don't know what to do
with it so they need data scientists and
machine learning and they need
essentially approaches to find these
patterns in the data so one example of
such a large data sets is the Cancer
Genome Atlas and this is a project that
was funded by the National Institute of
Health and essentially it provided
information of tiya of about 10,000
cancer patients and it has produced this
data for all these for all these
different modalities and also the there
are images available for these patients
and you can add these data's all
publicly available and you can access
this data so here is more an overview
and an estimate of how much data is
available so there's more than 14,000
patients and over 500 terabyte of raw
data that we can use for analysis and we
also have a lot of images because of
course for deep learning images are very
natural way to be modeled with deep
learning techniques and we have two very
different types of image data in
medicine one of the data sources is
seller images where essentially we have
digital pathology images and these
images look like this is the essential
give us an idea of the seller Harket
hierarchy and the seller architecture of
of a disease for example a cancer piece
of cancer tissue
and typically what happens is a
pathologist looks at these images and is
manually going to interpret them but
this is very tedious very time-consuming
and it might also be subjective if you
ask one pathologist who to look at such
an image and another one then they might
have a different opinion similarly we
have also medical images like CT Omar
scans which are maybe more familiar to
you
and in this case what is important to
say is that these images are 3d images
so compared to a lot of deep learning
that is being done in non-medical images
most images are 2d but we definitely
have 3d images and when we are using MRI
images we essentially have multimodal
images so we have multiple sets of 3d
images because we can look at different
types of properties using these types of
scanners and these images gives us more
information about the morphology of for
example cancers of tumors size location
and so on and again there's there's a
publicly available data that we can use
so one of the big databases that is
available is the cancer imaging archive
that's essentially provides this this
ditch data and that we can use for for
mining so how are now these types of
data however it is may use before we
essentially use deep learning so
traditionally we use more more common
computer vision techniques to look at
these images and this field is when it's
applied to medical images it's called
radiomics and it refers essentially to a
semi automatic extraction of features so
we need to look at these images we
define some features that we think are
important and then we extract them from
these images and what these features
represent are essentially shapes
textures intensities and so on from
these images and there's two types of
image features that we can extract and
we can extract computational image
features and just use algorithms to do
this and in this case these features are
very qualitative but we also asked
radiologists to annotate high-level
information about these images for
example here is an image of a lung tumor
and four properties that we want to
extract from these tumors for example
what is the age of the tumor so the
image on the left has very
mood adds the image on the right is much
more irregular and so this is just a
brief overview of the competition
features that we extract so we look at
several texture features and wavelets to
see what is the texture inside is it
very homogeneous or very heterogeneous
we also look at shapes is this a very
smooth or spherical type of tumor or is
it a very irregular and finally also
like we look at the sharpness of the
edges is it is is the edge of this of
this lesion is it a very sharp edge or
is the very blurry edge so altogether we
can we can extract hundreds of these
types of features but in most cases we
don't really know what they do we just
plug them into a machine learning model
and we use them for prediction so here
is a brief example so these are the this
is a project that we did where we use
data from Stanford patients and these
are lung cancer patients and we had 85
image features and we wanted to break
one particular characteristics of these
lung cancer patients which is a mutation
in one particular gene and we used a
simple decision tree model to do this
and essentially we were able to predict
this this molecular property so using
these images we were able to predict
something that's going on on the
molecular level and this is this this
very simple decision tree so it's
essentially just used for features to
predict this diagnosis so now how how
did we use deep learning and why are we
now using deep learning for modeling
these these data so deep learning is
essentially a reincarnation of
artificial neural networks and this the
theory of these models has been
introduced already in the 50s between
the 50s and 70s but what is new about
the pruning is the idea of convolutional
neural networks where we have a
convolution operation that will explain
a few minutes and these these are very
powerful techniques to use on text or on
images because there's inherent
correlation between the features in your
data so what is very important in
medicine is that we have growing
datasets
we also have lots of different types of
data but the most important point for
deep learning in in biomedicine is fully
automated analysis is that we can
essentially automate these
interpretation of maybe the pathology
images or medical images of course
there's a lot of challenges as well
because we have lots of we have
demographic biases in these datasets we
have differences in quality
there's also security and privacy issues
in medical data and also that deep
learning models are essentially blackbox
model so we we cannot always interpret
them and this is a very important point
for physicians because when we use a
machine or model to help them they want
to also understand why a model comes to
a certain decision so just a brief
introduction of convolutional neural
networks and deep learning so
essentially this convolution operation
what it does it's a essentially kernel
that is applied onto an image and it can
extract certain features from your image
such as it can do blurring sharpening of
the image or edge detection so here is a
very brief example so you have this
little matrix which is your kernel and
essentially what you do is you do a sum
of products and this kernel goes over
the image and essentially has we go from
an input image to an output image and
this kernel does some operation on this
image so for example this is a kernel
where you just your your input image and
your output image is going to be the
same you can have kernels like this
which essentially detect edges in images
we can have these type of kernels where
you sharpen edges and then more advanced
kernels that do different operations of
course we don't know in these medical
images what operations are important so
we're going to learn is essentially from
the data so now I'm going to give you
three examples of deep learning
applications in medicine so the first is
how we can use this method for diagnosis
of melanoma
so most diagnosis of melanoma is done
visually and automated diagnosis is very
challenging because there's a large
variety of skin lesions as you can see
here this is like a picture of all the
different
types of diseases there's a lot of
benign diseases there's also malignant
diseases and we want to physicians and
she wants to classify these also this is
a very common disease more than five
million new cases are being diagnosed
every year and there's about 10,000
that's to melanoma every year here are
some example images so these are just
photographic images where the top part
are essentially benign lesions and the
bottom part are essentially cancers and
as you can see it's not easy there's a
lot of heterogeneity a lot of
variability how can we distinguish these
two types of images also there's
different types of images in melanoma we
have smartphone images which are these
photographic images and from these
images we have a lot of them and then
there's more clinical images like these
demo they're Mosca p images and
histological images but these are very
more hard to get so this is the model
that was used for this particular
project so they used about 130 thousands
of these photographic images and they
represent over 2,000 different types of
skin diseases and they essentially
compiled over 18 different types of data
18 different data sets and then they
used Google NAT inception architecture
so this is a already developed deep
learning model that was already pre
trained on about 1.3 million
photographic images and this is a very
important point that we need to do this
this concept of transfer learning where
essentially these 1.3 million images
these were non-medical images you were
just images of cats and dogs for example
that were used to pre train this model
and then we're going to use about
130,000 clinical images to to further
train this model to a specific medical
task so this is the deep learning model
that they use I'm not going to go into
detail here but you can see they have an
input image on the left this all these
convolution operations and layers of of
the network and then at the end you have
over 700 different diagnoses that the
model is essentially going to predict
and this is a visualization of the
performance so this is essentially
showing that a deep
model outperforms dermatologists so the
blue curves are essentially a
visualization of the performance of this
algorithm and how sensitive and specific
it is and the red dots are individual
dermatologists that make predictions and
what we what this research group at
Stanford observed was that we actually
can train a model that outperforms these
dermatologists so what what are the
lessons that we learned from this from
this project is that completely
automated the gnosis is really possible
and we can train deep learning models to
help physicians but pre training is very
important because this model was already
pre trained on a lot of other data and
also this medical this this task or this
prediction was very similar to a
non-medical to non-medical images
because we have 2d images and we have
photographic images so it's a very
similar problem so now I'm going to go
to a more complicated problem because
now we're going to use radiology images
to predict lung cancer survival so
there's so essentially we have we have
lung tumors and we have CT images that
essentially give you an idea of the type
of the tumor and we are going to use
that a deep learning model to predict
the prognosis of these patients so this
is this essentially the question that
we're going to ask is this possible can
we can we use a deep learning model just
based on images with no input of a
radiologist or a physician and can we
use it to and can it's outperform
traditional techniques so this is the
traditional approach and very similar to
the example I gave earlier we are
typically what we would do without the
deep learning model is we would define
some features that characterize these
tumors and these features would
essentially give information about the
intensity of the image about the tumor
shape texture and so on and then we
would have a we have we would have these
features and then we put it in your
favorite machine learning model like a
support vector machine or any any type
of model and we use that tend to predict
survival and and people have shown that
this is possible so now what we did is
we essentially you
to deploy during model and as input to
use the CT images and we also use the
clinical data and then we use a
convolutional neural network to predict
the survival of these patients what is
important in this project is that we
have multiple data sets because we had
data from different Institute's because
each Institute has its own bias so we
need to be sure that when we develop
such a model that if we develop it at
Stanford that we can also use it in the
Netherlands for example so here are
three data sets that we use we use one
Stanford data sets we use this at from a
Cancer Center in Florida
and used data set from the Netherlands
in from the Maastricht Clinic NME use
traditional techniques also to evaluate
these models because we need to train
models on part of the data and then we
test them on data that model has not
seen to prove that we can actually do
this task so one thing that we observed
is so we compare different types of
models we compare models where we only
use clinical data then we use mouse
where we use 2d images and then we use
models where we use 3d images and here
we found that when we that we really
need to use the 3d image information to
to outperform and to have the best
possible performance so using 3d deep
learning was very important in this
particular application to predict a lung
cancer survival here's some more results
where essentially we used which trusted
different types of combinations of
training and test sets so we we for
example trained they a model on the
Stanford data and then we test it on the
day from the Netherlands and data from
Florida and vice versa just do to make
sure that if we train these these deep
learning models and different types of
data that we can actually generalize to
new patient populations and this is a
visualization of essentially the
survival of this patient so that's
that's what we've tried to predict here
and what you can see here are what these
curves represent is the probability that
a lung cancer patient will die after a
period of time after treatment and with
the picture on the left is essentially
where we use both clinical data and the
deep learning model and we found that
that model was the best in separating a
good group and a
prognoses group whereas if you only use
clinical data which is the picture on
the right we were not able to separate
these two groups so what are the lessons
that we learn from this one from this
application is that we need data from
multiple institutions because there's
different biases and different
populations different ethnicities that
can create different types of response
to treatment and how people are going to
what their outcome is going to be and
what we also found was that 3d images
images are very essential and a lot of
the deep learning development that's
going on right now is really focused on
2d images because in non-medical
applications we see a lot of 2d images
finally I'm going to briefly introduce a
church application where we're going to
look at another type of images which are
in more images and we're going to use
essentially the the tasks that we have
here is segmenting these images so here
we have data from a challenge and this
is data that's also publicly available
and was provided by the Makai Society
which is the imaging informatics Society
in medicine and they have essentially
created the data set of over 220 brain
tumor samples where we have multiple
sets of 3d images that represent
different types of properties of these
of these tumors what we also have is we
have this grant route of these of these
images so we know from a panel of eleven
radiologists they have essentially
classified each voxel in the image and
categorized it in different types of
regions what part is the is the the core
of the tumor there's also a edema which
is which are the cells are essentially
spreading in the brain and they have
essentially provided us with this
information so we can use it to develop
our models this is another visualization
where you can see all these different
regions in in the brain so for more
details about this my graduate student
Rogoff is going to give you a very
detailed
overview of how we developed a deep
learning model using tensor flow to
solve this problem and you can see
already some images here about our how
our model is essentially segmenting
these images so overall what our goals
are really to investigate of how we can
use deep learning and this these
advances in machine learning to solve
problems in biomedicine and the main
idea is really to have automated
analysis of these images because we want
to save time for the physicians and we
also want to improve the the prediction
of diagnosis prognosis and therapy
response I hope I've shown you a few
examples that transfer learning is very
important because we did the amount of
data that we have in biomedicine is
where it's more limited we don't have
millions of of data points and we need
large multi institutional cohorts the
main challenges are actually not
technical so we died I don't believe
that the main challenges are technical
but there's a lot of other challenges in
biomass and we have issues with security
and privacy also as I've said already a
few times that the debate is the
databases are small there's also a lot
of heterogeneity between institutions
and there's also more work needed on
deep roni for 3d images these are the
people I have to acknowledge for all the
work that we do and thank you for
attention I'm happy to answer any
questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>