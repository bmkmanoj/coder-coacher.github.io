<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Serverless beyond Functions by Danilo Poccia | Coder Coacher - Coaching Coders</title><meta content="Serverless beyond Functions by Danilo Poccia - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Serverless beyond Functions by Danilo Poccia</b></h2><h5 class="post__date">2018-04-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2EOELazbcGs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so good morning thank you for being here
so exciting to see this room fully
packed so my name is Danilo and I'm
Technical Evangelist in Amazon Web
Services and as you can see it's not
difficult to find me because I'm Danilo
at amazon.com I'm Danny loop on Twitter
and so boring as I am I also done elope
on get up where I share some of the
coders I write so I joined Amazon Web
Services six years ago so every year
there was something new to learn working
with our customers and in 2014 and of
2014 when we launched a new services
called ADA breast lambda I was really
excited by these new possibilities of
serverless architectures I was so
excited then I shot we brought a book
that has been published in the u.s. in
China and in Korea is called the SS
lambda in action and I work with my
publisher also to create a free ebook is
the last one it's called agile
development for several s platform it's
a collection of chapters from multiple
books it can help you have a basic
understanding of all the technologies
you need to know to be the surveillance
application so what surveillance is what
agile is in this case what a web api is
and so on and the idea with several s is
really to move our development faster
and to do that the idea is that you can
create application without thinking
about servers so you don't need to
manage provision that they are
infrastructure installed the OS install
the patches install the security patches
periodically everything should scale
automatically with usage including the
price so that if you don't use anything
so if you're idle you you never pay for
anything and the idea is that you can
create an application that you call once
per month or 1,000 seconds I wonder
sometimes per second and you don't need
to change the architecture everything
will scale up and down automatically and
when you create something we will do
something today everything is built with
availability and fault tolerance so
enable in initial our region in the AWS
regions like we are one in Frankfurt and
one in Paris one in London another one
in Ireland all those regions are built
using multiple data centers we have we
grouped those data centers in what we
call availability zones
and currently if you create some piece
of code on lambda everything is
automatically deployed across three
different data centers and it's in
highly available availability and it's
scalable and you don't need to do
nothing and if you don't use it you
don't even pay for it it's just don't in
the week create for you and the core
flow of a service application is this
the idea is that you have multiple event
sources can be our Web API call can be
someone uploaded a file in an object
store like Amazon s3 someone updated the
database this can trigger your business
logic that is a function that you can
rewrite in lots of different languages
we currently support nodejs Python Java
C sharp we recently have also added the
support for dotnet core 2.0 and also we
recently added support for the go
language and there's no dependency no
libraries then you need to do it's
really just just your code you just need
to understand the syntax of the event
that you receive and then your function
can do anything normally you have
internet visibility so your function can
call other internet services or do
whatever you want if you want you can
connect your lambda function to your own
private data center on AWS and then for
example access your own private data
base or your own private data it's it's
really up to you and we've seen
customers use these to build lots of
different applications from from we have
like web application probably the most
common example were backhands so mobile
backends ati driven backends but we've
seen several has being used also for
other use cases such as data processing
is very easy to use lambda for real-time
data processing together with all the
services that we provide like hynny sees
we have an open source project on the
AWS account where you can do MapReduce
with lambda so basically you give some
big amount of data on Amazon s3 and the
lambda function can start in parallel
work on this and then in parallel then
reduce the the result altogether and
something similar for example there's
Fannie Mae it's a federal agency in the
u.s. they monitor the mortgages in the
US and they run Monte Carlo simulations
using lambda and in this way they can
scale from the
to 1,000 concurrent execution so like
1,000 servers in a few seconds and then
they can scale down in a few seconds
when they don't need this power again so
really really flexible and we've seen
lots of interest in chat bots and
building skills for Amazon Alexa so
conversational interface where you can
power the business logic of your
conversation using lambda function and
one other use case where as we've seen
some interest is you know those little
scripts that we write to manage the
infrastructure that sometimes runs
somewhere and sometimes they don't run
and you don't know why if you put that
on lambda normally the cost is zero we
will see why and you can schedule that
in our ability so your housekeeping
scripts that clean the stuff moves the
stuff take some backup from database you
can run them in a lambda function
they're highly available multi data
centers as I said and it's a very way a
very nice way to start automating and
also adopting this new technology and as
I said you you you have almost no cost
if you use lambda for IT automation
because with lambda you pay by the
hundreds of milliseconds of execution
time so it's really fine-grained so if
you don't run it you don't pay and
there's a very small request charge also
for the invocation but this is usually
an impact that the compute time cost and
there's no minimum you don't even pay
for the storage so if you upload code to
lambda you don't use it you have 75
gigabyte of space for your code and it's
without any cost and on top of that we
have a free tier we were freed here
where every month so all accounts this
doesn't expire after the first year so
all accounts the first million 1 million
invocation and the first 400 thousand
gigabytes second of compute time are
without any cost with lambda so 1
million invocation is clear 400 gigabyte
seconds means that if you give one
gigabyte of memory to the lambda
function you have 400 thousand seconds
and since the pricing with lambda is
linear with memory the more the memory
the more the cost if you reduce the
memory you get more time so if you give
128 megabytes of memory it's the minimum
that you can give to a lambda function
it's one eighth of one gigabyte so
you multiply by 8 you have 3.2 million
of seconds for free every month and
we've seen startups building application
with thousands or tens of thousands of
users without any cost with lambda and
then if your application is successful
you'll start to have some cost but
usually that's let's not a problem and
as I said the cost with lambda it the
more memory you give the more the more
you pay so the first idea would be ok I
give the minimum amount of memory so I
pay less
actually when you get more memory you
also get more CPU and more on your
capacity because we create a container
we are partitioning a physical server
somewhere to give you this power so if
you give more memory you to get more
compute time so probably your function
will also be quicker so at the end
reducing the time you can absorb some of
this cost so this is an example of a
completely compute bound function used
to create a function that computes
computes all the prime numbers below 1
million and we run that function 1,000
times if you give the minimum amount of
memory 128 megabytes this takes slightly
less than 12 seconds and it costs 2.4
2.5 cents if we give more memory you
also get more CPU so it's finished
quicker and if you can see with 1
gigabyte
you can get to 1.5 second to get the
result and the cost is exactly the same
so not all functions are completely
compute bound but consider that maybe
you can play a little bit maybe you
double the memory in your cost increase
just by 10 or 20% the lambda cost I mean
so it's something that you should try by
the way we increase the memory limit so
now we can reach up to 3 gigabytes in a
function and just to since you we don't
use we add power if you give if you go
beyond 1.8 gigabyte of memory you start
to see 2 cores in your function so to
use all the computation you need to have
at least 2 threads or two processes
otherwise the single thread will be the
bottleneck and you don't use all the CPU
power that we give to you so this opens
up past 1.8 gigabyte and there's lots of
integration with other services on a
tablet that can be used as a trigger for
your business logic
so definitely endpoints is very common
so you can have the Amazon API gateway
that receives an API call a Web API :
can trigger a lambda
to execute the business logic of your
back-end this works also with IOT
devices you can evaluate devices that
trigger lambda function and to power the
the business logic in the backend Amazon
Alexa to create conversational
interfaces and interesting use cases
data stores so if you upload a file for
example on Amazon s3 like you create a
mobile app the mobile app uploads a file
on Amazon s3 then you can trigger your
business logic that maybe is building
thumbnails for this picture is using AI
services to understand what's inside
this picture doing content monitoring
whatever you want
and there's also management tools so you
can integrate lambda with code
committees our git repository so if you
trigger you commit your code on this
repository it's private git repositories
you get maybe to execute something
automatically for managing your
deployment and so on
there's also crowd events and and it's
also as an SNS is in testing is a
publish to subscribe service so you can
create topics for example I have a topic
whenever a new user is created and then
you can subscribe to this topic and you
can create subscription depending on the
data that is published like if a new
user is created and is based in Romania
a trigger is function if it's based in
the UK a trigger another function
because maybe for tax purposes there's
some difference in the business logic
and the execution of model of lambda is
not always the same so when we launch
this function there are two main
categories so we can launch this code
synchronously or asynchronously so
services like the API gateway is
triggering lambda function synchronously
because you need to understand what's
the response from the lambda function so
you need to trigger the code run some
business logic and get a response that
you give back to the client other
services like s3 our object storage they
use an a synchronous invocation so you
upload a file there you start a function
that is processing these documents but
s3 is not concerned anymore in the
result so this is completely
asynchronous and the function starts and
goes and can run for a few milliseconds
or or a few minutes just as
synchronously nobody will listen to the
feedback and there's a third way it
stream based it's for data streams where
order is important because with the
synchronous invocation
don't preserve orders so if you upload
1000 files to s3 we trigger 1000
functions but there's no Xiu runs from
the order of that sometimes if you
receive a stream of data from a database
for example or there is quite important
no because if you update something and
then do another update the order of the
plates is it's quite relevant for the
final result so we have this different
stream based execution model where we
preserve the order of the execution
which services like DynamoDB in Conesus
the main important difference is here is
how you manage errors for synchronous
invocations if there is an error you get
it immediately and you can process it if
there is an a synchronous invocation
like you upload a picture on a stream
and then you want to analyze the picture
to understand it the content is ok for
your website you can do that with AI
services for example maybe someone is
uploading a picture that is not a
correct file format you get an error s3
is not there waiting for your response
so you need to manage that so how can
you do that for a synchronous invocation
we automatically retry functions two
times and then you can create a dead
letter Q so accused or or a topic where
we publish those errors that we can
manage and you can manually or
automatically listen to this dead letter
Q where you receive the events that are
creating errors for your functions so
keep that in mind for your architecture
another important topic is permissions
so sometimes I see developers when they
create the first lambda function that we
force you to give some permissions to
this function but normally when you
develop locally on your laptop you don't
have to think about permissions or
security I think this is very good
practice so I think development security
should be part of any development
project of any architecture project so I
see this additional complexity as a good
thing and identity with lambda is that
there are actually two sets of
permissions one is the execution
permission so what's the function can do
so I execute some code and this code
what you can do maybe you can read from
an object storage like s3 you can write
on a database so you have to give the
permission that the code is using during
the execution the second part is who is
able to run the function and this can be
another application
can even be an external user so the fact
that you can decouple the security in
two layers what you do inside and who
can call your function can give
additional benefit in the security
design of your architecture one of the
most common integration with the lambda
is the API gateway so to provide a Web
API interface to lambda so that you can
create our REST API for example and when
you call it you you call a lambda
function this is actually working with
different services and it can even work
as a proxy for a traditional web web
service that you already have so I've
seen lots of customers that want to
adopt lambda function starting with the
API gateway to wrap something that is
already there I web application and then
peeling the onion also extracting some
business logic and creating lambda
function without changing the
interaction with the customers in the
consumer of the API and there's lots of
benefits in using the API gateway the
there's authentication throttling
monitoring you can monetize your API if
you want to our marketplace and there's
also DDoS protection so we will
automatically protect your API is from
distributed denial of service attacks
using all the techniques that we have in
place in Amazon so it's a quite robust
way to protect your API so when we
created the API gateway we wanted to
give maximum flexibility to our users so
we said let's use an open standard that
we used velocity templates from the
Apache velocity project and using these
templates you can remap the input
request from the client to the syntax
that you want to send to the function
and then you can do the same way back
that works but we've seen our customers
doing the same templates again and again
and again so after some time we created
this standard lambda proxy integration
so this is the default syntax now I
suggest strongly to use this syntax it's
just a flag on the console or default if
you create using the CLI and this is the
syntax on the top you see the input
format so all the information that you
receive from a Web API call so we send
the HTTP made of the debtor's the the
path parameters the body support also
binary binary payloads and then there's
the output format over lambda function
so the lambda function
must reply a status code so HTTP status
code like 200 okay 404 is amiss and then
optionally headers a beaudion
and and you can flag this as binary
encoded if you want so if you start
playing with lambda you get an error
from the API gate most probably you
don't respect this syntax in the answer
back and you get a 500 error from the
API gate so double check this so let's
see how this works actually so I am here
this I have here my lambda console and I
have a couple of very basic functions
sort of hello world functions where you
give your name and you say you give
hello by your name and let's open them
so so this is greetings on demand so
this is a function that it's just you
give the name and you get Hello by your
name and if you don't specify the name
you get the classical hello world so in
the new console we created this
dependency graphics so on the right you
see what we can do and you can see that
one of the things that we can do is
write logs so that's why you always need
permissions in a server let's world
because it's a distributed environment
we you can't trust anybody so if you
want your function to write locks in a
centralized repository you need to give
those permissions so if you don't give
any permission your function will not be
able to write locks so that's that's not
good as you can imagine and on the left
here there's nothing those are the
triggers so who can trigger this
function there's nothing so this
function is all alone in the cloud
nobody is calling it and it's more just
for demo purposes this is the new editor
we acquired a company from the
Netherlands it's called cloud 9 we
acquired the company a couple of years
ago and it's now integrated in our
portfolio so it's a service and it's
also the editor you can see here I think
I already tried because and it was
really not working so what I can do I
can maybe zoom a little bit so that's
the easiest way otherwise if I get lost
in the in the preference we would just
lose time so this is a simple function
here on the on the bottom you see the
the handler of the event and here I have
my business logic so this is a very good
practice and not everybody is doing that
so this is my top suggestion maybe today
so I hear a lot of people that says I
want to use lambda but I don't want to
tie my coat to lambda maybe I want to
run the same code on another platform as
a web application so how can I do that
so we have lots of tools that can help
you run Express application or a bottle
flask for Python we have similar tools
for go but the number one tip is just
use the event function that we trigger
with Lampa lambda as a wrapper where you
just manipulate the syntax of the event
that is a WS specific and then you
create a business function that is
completely independent from lambda in
this case is breeding on the man that
will create the the normal processing so
create an event wrapper that will just
call this business logic then if you
want to use this with other integration
you just need to add a wrapper or a
router that will trigger this function
when you want to run something else so
it's much much easier and they don't
even need to be in the same file so you
can have two different files one is the
lambda dot a J's file ever example here
that is doing the wrapping and another
one is the the core business logic of
your application there can be one or
more files so to do that we can also
test it so we have test integrated in
the console and I created a test with a
name and without a name so for example
without a name I get now
hello word then you get some information
like how much memory you use how much it
lasted and if you select the with name I
have an event where I get hello for my
name so hello Donnie loss or nothing
fancy so this is our first function just
consider this splitting business logic
from event wrapping I have another
function that is a little bit different
it's exposing the same service as an API
so now you see here I have the API
gateway on the left it means that this
is one of the triggers of the function
and if I go here I get the URL of the
API gateway is something that you can
customize but for now let's use the
default domain
and this function as guess what exactly
the same business logic as before so
this code here is just a cut and paste
and then here I have the event handler
that is now a little bit more complex
because now I have to manage the syntax
that was in my slide so I'm looking into
for example the event query string
parameters and then when I get the
results back from my business function I
can't send this result straight out
because I need to respect the output
syntax so they have to give the status
code that all their information so I
created an internal function here this
one that is basically taking the the
optional error and the message and then
is wrapping this with the syntax of the
of the API gateway so in this case you
can see I have a wrapper but for the
input and for the output of the function
and my business logic is completely
independent I didn't need to change that
and as I said it could have been in
another file in another part of my code
repository so this is an example of how
that good practice works so you can add
multiple events triggers you can move
this to a different platform your
business logic is untouched you just
need to manage the integration and the
wrapping and wrapping of the event and
now we can use this amazing function
this is a URL that it goes on the
internet and this what we get hello
world and if I give here my name I use
query string parameters so I give now my
name in the URL I get
hello Danilo so this is as I said
running completely in high availability
across three different data centers I'm
using Ireland now so it's close to
doubling but there's other regions that
are close to remain if you are sensitive
to latency and and this will
automatically scale a considering the
fit here I only pay if I could use it
more than 1 million times per month and
and then it will automatically scale
from 0 to thousands of requests so this
is just to give you a brief introduction
to how lambda works and how you can use
it but the console I like it it's good
but if you start to create
application so we want to go beyond
function in this session after two three
four functions using the console
probably is not the best approach that's
why my suggestion and this is for
everything not just for server let's
think of a way to map your
infrastructure your architecture into
code now that all the cloud provider
provides automation you can describe
your resources in the cloud in a text
file and then we can use this text file
to create the lambda function the
database whatever you need in this way
you can put this code description this
template of your infrastructure of your
architecture in the same repository as
your source code and then you can update
both together so it's version two of my
application has a different business
logic and is using a different
configuration of the database you update
the infrastructure file and when you
send the update to the cloud we will
update the code and infrastructure
together so it's a very good good
practice and we have a tool that can do
that for everything vehicle server
containers and it's called
CloudFormation it's been there for quite
a few years but it was created before
serverless
so it was very verbose with serverless
technology so we saw that the user
experience was not good so I'd like to
introduce you to Sam Sam is our server
application model is an extension of
that information that is specifically
designed to describe a server less
architecture in a text file and it's an
open specification with Apache 2 because
we want everybody in the community in
the service community to be able to
reduce this syntax we don't want
everybody to reinvent the wheel and this
is a prototype of a very small function
and we have white background here and
here you get like the declaration of the
function there are almost the same
options as in the console and this first
part here is saying this is the event
that triggers this function is an API
with this URL and this is the this means
anything that I receive send it to this
function so it's the default integration
that we were seeing and this will create
lots of that the first line there at the
top is the line that tells
to confirmation hey I'm using the same
syntax here is not just affirmation this
will create lots of things under the
hood because to run a lambda function we
need a role a policy the API gateway
needs to understand how to map the API
we have to create permissions so
everything is automated by that if you
were to use cloud formation by the way
this would be the equivalent script so
now you understand why we created Sam
and we don't want you to use
transformation for several as it would
be just boring and when you have this
file so you can put your code somewhere
you can put this template describing
your service application with multiple
functions database whatever you can use
these two commands that you can include
in your continuous integration and
continuous deployment pipeline and the
first one will package everything and
put it in the cloud and the second one
will take this and deploy this creating
an actual implementation of what you
described here in code and
infrastructure and this deploy is also
managing updates so if you send the same
if you change something in your code or
your change don't take your architecture
and you redeploy we will not create
something new we will check the
difference the dependency and we will
automatically update your environment to
the new version so you can just loop on
these two comments every time you want
to deploy the new version everything is
managed and automated and you can create
something like this where you have lots
of database triggering functions
triggering stuff actually this makes no
sense it was just to create something
nice to see and when I created this when
you start to do thinking architecture
there are a little bit more complex
still the same syntax is a little bit
boring because you have to translate
this into Yambol so I created this
project it is a personal project is not
endorsed by AWS and it's open source
it's called service severus by design
and with this project you can
graphically design your architecture and
then we you can use it just for thinking
brainstorming and then you can we can I
can automatically generate the same
template for you so let's just have a
look at it so let's go here know here
so this is the the application and this
is actually the get up repository so if
you want to have a look so it runs
completely in the browser so there's no
running on the cloud so you can download
it locally and play with it locally you
don't need a net a blessed account to
use it and you can start for example to
say hey I want to create an API so I
need an API gateway this is my API then
I want to add a lambda function and this
lambda function is my back-end so
because all the business logic from the
API will be executed by this lambda
function and this lambda function needs
to read them right from an s3 bucket so
this is an object storage where you can
write and read files and maybe I also
need the database tables so I can use
dynamodb for example and I can create a
table here and then you can connect this
and I will automatically infer what you
want to do so this is an integration
this is a readwrite from from the bucket
this is a readwrite from DynamoDB and
then maybe you want to brainstorm and do
something more so maybe I want to add
another lambda function here that is my
bucket processor and every time
something happens on the bucket I want
this lambda function to be triggered so
they can process this logic and I can
create another lambda function here that
is my table processor and this table
processor every time I write something
on the database update something is
triggered and it's my business logic
so maybe I'm satisfied with this I can
create a picture and put it into my
slides or I can just go here and give it
a name so this is my demo app choose
between node and Python I'd only support
those two one for now and then you can
export to the same template and since
this is open source a guy in Dubai in
one day added support also for the
several s framework is an open-source
framework that has a different syntax in
its more scaffolding oriented I would
say
like Ruben Reyes or Express but for now
let's use em so I can click build this
is just a reminder of those two comments
I can open this zip file that I just
unloaded and here I have my application
I can go now into this directory so
let's zoom it a little bit more so this
is in under downloads my demo app so as
you can see there's the template and the
other files so let's open just open just
an editor this is the template where I
have the description of the function the
resources the buckets the permission
everything is described here and you can
then edit it because it's much easier
and then I have the starting code for
all of my function those are just empty
functions for now and if I want to build
this I can I can for example just go
back here so let's go here so I have
let's put my bucket here I call it I
have a bucket with guess what
Daniela and then let's go back here I
just paste these two comments so the
first one is packaging the code and the
second one is applauding and now if I go
on a WS I'm actually building this
infrastructure and this automation can
be used to build one environment your
production but you can create multiple
environments you want to run some tests
you create it environment you use it for
a few hours then you destroy it it's
completely up to you so if we go here on
the management console I can go on
CloudFormation
I should do this in ireland i think and
and i we have works bucharest now
building and if I go on events I see
that no the role the permission dynamodb
table everything is being created and
then if I have updates I can send
updates and this will be automatically
updated so this is a way where you can
brainstorm a little bit if you want and
and this is what we built and just for
reference this part here I think it's
really interesting from an architectural
perspective it's the it's a good way to
implement event sourcing so what I mean
by event sourcing normally when you have
a distributed architecture
keeping the state of something is
complex so sometimes you receive events
that are not just infrastructure events
like someone called my API but events as
a business meaning like a new user must
be created or a user must be suspended
or a payment has been received so this
kind of events you can store all the
events in a table and these events if
you think of them are business
information that is immutable because
this is not that you need to update at
at 12 to a new user must be created if
this user will be considered others will
receive may be another event in two
hours that says that so are two
different events so immutable
information in a distributed
architecture is always easier to manage
so one way to design a good service
architecture in my perspective is to
create a database table where you put
all these events is a sort of is a time
series of business information that is
immutable and then process this
information as triggers to execute the
actions that are there and as I said we
preserve order in this case so you know
that a user is created and then a user
is cancelled you will process this in
the right order so think of event
sourcing as a good way of implementing
managing business events in a
distributed architecture there are still
some challenges here so for example
testing and normally someone at this
point tries this and how can I test this
easily you can test in the cloud but we
also created a an open source project
where you can test and we created docker
containers that you can use where we
emulated the same environment where we
run lambda and we also help you generate
the events so this is the syntax of an
event that you can receive from s3 it's
not something that I want you to
remember by heart so that's why we can
help you create this so we have this
some local tool it's open source on
github in AWS account and can emulate
lambda function on docker images and it
can also generate the synthetic events
that you can use for your unit test so
that you can unit test your lambda
function locally and very quickly so
this is how you can generate an s3 event
for example for a specific bucket this
is where you can find the project and
this project supports Java not Jas pipe
and recently we added support also for
Galang and it can hold so support live
with the backing so you can do live the
backing of your lambda function locally
where you inject your event and test
what happens you can install it using
NPM and this is what you get so the
those are the commands so the most
important one is same local and same
local means that you can do some local
invoke to run a lambda function locally
you can do some local generate event to
generate the event that you would
receive from the API gateway or from a
Lannister e bucket to create your own
unit test so this is the input for the
lambda function and also you can run
start API that we run an emulation of
the API gateway locally on your computer
so it's a web server that will also
invoke your lambda function so you can
build the door well application locally
test it and then deploy only if you want
and this is integrated also with the
full AWS cloud 9 editor that we have on
our account so in this way is really
easy to build a complete continuous
integration and continuous delivery
pipeline so you have your suit somewhere
in Geetha bond our git repository you
can trigger a build phase you can
trigger automatic test and then you can
use confirmation with those two commands
to deploy automatically if the new
version of your application and we have
a tool that you can do to coordinate
that if you want it's called code
pipeline it comes from our internal tool
that we use in Amazon so it's quite
robust and we also have another tool
that is free to use is called code star
that can help you set up an entire
project using this configuration so
basically you go there say I want to be
the server s application or a known
service application and this is the team
with the person and their app permission
for my team I want to keep my code on
github or I want to keep my code on AWS
and then we will create all the
configurations for you so that it's very
easy to kickstart so the last part that
I want to describe to you is before the
define are ending on something
completely different is how to manage
upgrades so as I said we can just take
your new updated architecture and put it
in production automatically so you make
your changes you say deploy and we apply
the changes
but what we see is that large customers
they want to do something different they
want to do canary deployments they want
to do linear deployments they want to
more endure their deployments for
example Netflix they do canary
deployments and they that means that
they release a new feature - like five
10% even less depending on this on the
impact of the users and then if they see
that this works they roll it out to
everybody and to see if it works
you can check infrastructure metrics but
normally you should look for business
metrics so for example for Netflix the
top Matic is the number of play per
second so many people is clicking play
and it's working per second so if they
see that a new deployment is
statistically impacting the number of
play by second that means that this
deployment is probably doing something
wrong so if you want to do canary
deployments and test this think of what
they want to maximum three business
metrics that make sense for your
application and if you see a statistical
impact on these values after a
deployment then you can automatically
rollback and that's something that we
can do automatically because we
integrated that with Sam so this is the
same template to create a function if I
add these four lines here this means
that automatically any deployment will
go live and I want to do a canary 10%
for 10 min so I want to test this only
on 10% of my users for 10 minutes there
are other options of course and and
after this 10 minutes if everything
works if it goes public so you can
manually rollback but you can
automatically also add pre and post
checks so this is again lambda function
that you can optionally write that can
do whatever check you want and if they
fail they will roll back automatically
and you can run this this before and
after the deployment and then you can
add how as much as many alarms as you
want and these are cloud watch alarms on
AWS so it can be infrastructure alarms
like the latency of your API is
increasing or it can be business metrics
that you upload so you can inject
business metrics from your application
and we will chart them and you can
create alarms so you can automatic
monitor your deployment and if something
is wrong on infrastructure or something
is wrong on your business metrics we
roll back automatically and there's a
graphical console where you can follow
the the rollout so final step because in
this session I really wanted to go
beyond function is graphic ul so I
talked a lot about creating api's but I
think that where we are now we should
think of what syntax which should use
for creating this new API and I think
that graphic ul is really a good
platform for creating new api's so with
graphic you normally with old applique
traditional approach even if you try to
respect the rest architectural model as
much as you can
we've seen customer ending up with
having lots of different end points
because maybe you want to build a blog
and you have a slash post URL where you
give the blog post but then you want to
get only a subset of the information
then you want to search by title by out
or and even if you can do probably
something better than this using the
rest model still is not very easy and
flexible with graph QL that is an open
standard that started in Facebook a
couple of three four years ago and now
it's been endorsed in a lots of api's
you can just create a single endpoint
and with graphic UL you start by
defining the the application schema for
your data so for example I want to build
a to-do list
I want to create a to-do object and then
I want to be able to queries this to do
to get a list of my to-do items and this
is how you describe your API so it's
much easier and describable than a
traditional REST API and then when you
want to run the query this is the syntax
you must use in your clients so you
should say something like I want to run
a query I want to get the to do my to-do
items and you can also list the subset
of the information that you want so if
you want to build a web list of to-do
items you don't need to display display
maybe the description there because it's
something that it's only if you click so
you can optimize bandwidth and also the
speed for a mobile application because
you only say
you want annually get the data that you
can ask and generally you can define a
schema that is very complex and you can
connect one piece of object with another
one that's why we use the term graph in
graphic UL and let's say that we want to
create an event a system where we can
monitor events like this like works days
and then everybody can post their own
comments on this event
oh the the survey last session was
really bad never I will never go there
again so we create an event type in a
comment type and then you see the
comment the event can accept comments
and these comments is a link to another
type so this is why we use the term
graph in graphic you are and then when
you have a schema in graph QL we call
mutations the way you update the data so
inserting new data or updating data so
in this case we declare three way of
mutating data I want to create an event
delete an event or add a comment to an
event and then queries is the way you
can read data so I want to be able to
get an event by ID and I want to list my
events and if you see the list events
there is this syntax with limit and next
token and that's why with graphic ul is
very easy to build pagination so how
many people here created an API in their
life how many of you work on pagination
and when you enjoyed working on
pagination so that's why we we want the
debt to be automatically managed so it's
part of what we want to provide and more
recently graphic ul also added real-time
updates what we call subscriptions and
this is a way to subscribe to a mutation
so I want to say every time someone is
adding a comment on an event I want to
receive us a real-time subscription and
this is part of the specification and in
this way you can create real-time
application very easily and it's
covering lots of complexity that
normally you have when you design an API
also evolving an API is much easier so
you don't need to change your endpoint
so API evolution is much easier to make
this easy to use we launched a new
service last year and the new year is
called up sync where you can create your
own graphic you
keema you upload it and we can
automatically map this schema to
DynamoDB tables so no sequel database to
the execution of those lambda functions
that we just see so or to our fully
managed elastic search service so you
can run queries on elastic search using
the SQL and then your client can connect
and run their own queries mutation
subscriptions we automatically we use
the open source Apollo client for graph
QL and we added an SDK that can manage
real time subscriptions using WebSockets
so you don't need to do that you just
need to say every time I receive a
subscription trigger this function in my
client code and it's managed by the SDK
that it's on github and you can also
manage the authentication if you want
with users and we've seen lots of use
cases like for example using those small
lambda function you can very easily
write a wrapper for a legacy system so
maybe you have a legacy trouble
ticketing system you can write a lambda
function that can map the input and the
output and you can create a graphical
interface to a legacy system with one
lambda function so very easy all you can
use along the function to get the data
that you write on dynamodb and send it
also to elasticsearch in this way you
can use DynamoDB for small transactions
like thousands of transactions per
second and elastic search for complex
queries where you need more more power
more recently we also added the
possibility to start from a dynamodb
table and infer the graphical schema
from the table so if you create if you
know dynamodb better than graph QL maybe
you want to start there and then do the
opposite so depending on your knowledge
you can start with class QL or with
DynamoDB M so let's have just a brief
look at how it works so I have an
application that I created before and
it's here in the app sync console so by
the way up sync is currently in a open
preview so you can play with it and
there is no cost until it's in the
preview so there is absolutely no cost
for now so you can play with it and see
if you like it there is already the
public pricing for when they prove you
will end so you can understand if the
pricing is come
with your business model or not so I
created an application here and if we go
on I have a couple of browser browsers
open here so and there is a react
application running here locally but
this react application is then
connecting to the cloud using dynamo DB
if from the if I need actually is the
client to do that so this is exactly the
same schema that we saw before so you
can create events like this event we are
now and then you can add real-time
comments so lets this is running on
Safari and this is running on Chrome
just to show you that there's no trick
so I can create an event here this is
Vox days it's in Bucharest and it's a
really nice event apart serverless
session and then since there was no
real-time subscriptions for events if I
I don't get any update so I need to
refresh this is just by design for now
and now you see that both to see the
event here this has been mapped to our
database but now I can add comments so
if I click here and I add comments and I
hit here add comments I can say well the
venue looks great
looks great and then I can add the
comment and since there is a
subscription here this is automatically
sent to both client so the first client
rejects the duplicates and then you see
that the computer piece here and Brad
break fast was nice I can add the
comment and then it's sent to the other
side so currently I'm using us east so
I'm in the east coast of the US so you
see some latency but this is also
available in Ireland and we are going to
add more regions so we will get closer
if you have some specific locations and
this works also with this connection so
if I go here and I switch my network off
the the graphic your client can manage
that and we have conflict resolution
that you can customize if you want so I
can delete but now my so let's double
check that my ping okay my ping is not
working I can now delete here is really
sure yes I want to delete now if at some
point in time I get back my network so I
get out of the elevator with my mobile
app or something the the client will
automatically racing to the cloud and
then you can just refresh and then the
data will be synced we do automatic last
twins conflict resolution but you can
add your own custom logic if you want to
do something more more advanced and this
is an example this is all open source
code that we have on get up to see how
you can build this we have this for
react web we have this for react native
and we have this for native iOS and
Android application if you want to build
something more focus on the mobile and
in a similar way I have I can create an
API for example now I want to create a
book store API for example in graph QR
and I already have a table so I just
created the API I can then create a data
source and the data source can use its
my books and I can connect this as soon
as you said to a DynamoDB table to
elasticsearch or a lambda function
this user DynamoDB table I have this in
US East and I have this books table
so this books table looks like this so I
have an outer on ESPN is the primary key
a price a tighter than a year and
something like that so it's just a
standard stuff I can say automatically
generated the graphic UL and this is
automatically generated so the object
and the queries and since DynamoDB is a
non sequel database that has no schema
only the primary key and only the
attributes were you created indexes will
be automatically discovered here so i
have the ISBN
the outer of the title if i want to add
for example the price i can add it here
so the price is a float the year of
publication is an integer and everything
is automatically updated here in my
mutation and queries so I can now create
my graphical graphic you API the schema
has been automatically generated and I
can run queries so let's run a query so
this is the syntax so the first thing I
want to do is to list my books this was
automatically generated I didn't write
any anything and when I list the books I
can get all my items and the next token
so for a pagination and so I get the out
of the title the price and the year so
maybe I don't need the price in the year
because this is for displaying in my
initial web page so I can remove them
and I get only the information I want I
can add pagination so I can only ask for
the first two and now I get only the the
first two books and then I a token that
I can use for pagination so I can use
the after common here and pass the token
and this will paginate so you don't need
to build pagination is managed by us and
then for all indexes we are the the
automatic query so I can query my books
by outer if I want so I can specify only
the books that I've wrote then actually
wrote one but there are two here and
again I can list the items and the next
token so the pagination is always
automatically built and probably the
outer is a redundant information since
I'm queering by outer so I can remove it
from here and get only the specific
information I want so this is as
flexible as it gets so last thing is
that to give you an idea I also created
a a lambda function to emulate let's go
back
a legacy trouble ticket system so in
this case as data source
I created a lambda function and this
lambda function is just emulating a
table ticket system that doesn't exist
but what you can do you can pass trouble
ticket as an ID a title
the description and if you have a legacy
system you can use whatever libraries
protocols you want to create this new
interface and then I can run queries and
if we ever look at the lambda function
they should be here it's just again with
the black background is just taking the
input event and it's just building a
response that is just hello from lambda
and it's using either the title that you
pass or generating a random title by
itself so it's just a simple code so if
I go here and run a query I can for
example get a trouble ticket by ID and I
can pass a string or an ID and this
trouble ticket must return the ID and
the title and the description and you
get one two three and hello from lambda
because this was generated by lambda so
this is I think a nice way to create API
is very very quickly with pagination
authentication all the usual things that
normally create problems and slows down
your development so if you have time and
you want to give it a look then give me
your feedback because part of my role is
to give the feedback to the preview to
the team especially in for preview
products together Stan what we do
correctly and what you don't like of a
new product there's lots of other
developers tools here I also invite you
to have a look at the open source
frameworks that run on top of server
list so if you don't like our console
you don't like to Sam there's for
example the serverless framework and
there are frameworks to run these on top
of other standards so severus Express is
a library that you can take any Express
jes application and run it in lambda
just as it is and those are my top
takeaways today so I hope it was not
boring but the idea was you can start
playing with the lambda console create
your first functions think of
infrastructure as code to go beyond the
first three five functions because it's
really and this is independent from
server less so infrastructure as code is
really the good way to manage your
infrastructure in a template text file
together with your source code develop
in the cloud we also
of an editor i WS cloud9 build your own
continuous ink on the integration and
delivery pipeline it's super easy now
with the tools that that we have if you
need to build a new API consider graph
QL compared to the standard rest api is
because the tooling is getting very good
there so there's our back-end but you
can use lots of open source tools to do
that
I think it's really a an interesting
approach and if you build that severus
application out of this session that
would make me super happy we also have
the surveillance application
repositories a place where you can
publish and share your application you
can do that privately in your account
within your company but you can do it
also that publicly and it could be a
good way to share your knowledge with
the others or learn from other people
because there's lots of applications
there where you can see how to build web
application a URL shortener or stuff
like that using the surveillance
approach and with this thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>