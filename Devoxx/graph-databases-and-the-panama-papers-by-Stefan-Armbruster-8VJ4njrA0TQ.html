<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>graph databases and the &quot;panama papers&quot; by Stefan Armbruster | Coder Coacher - Coaching Coders</title><meta content="graph databases and the &quot;panama papers&quot; by Stefan Armbruster - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>graph databases and the &quot;panama papers&quot; by Stefan Armbruster</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8VJ4njrA0TQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so good afternoon to my talk on the
Panama papers and graph databases great
to see so many people here I hope you
all enjoyed the coffee break had some
cake and hopefully you don't fall asleep
now due to the nice meal and some drinks
so I will do my very best to entertain
you a little bit and also to teach you a
little bit so hopefully when you leave
the session you learned a little bit
before getting into details anyone in
the room who has net not yet heard about
the Panama papers there is one person
wonderful so you don't follow news at
all okay so I will tell the story or the
other hand side who of you in the room
has at least who knows what new Fateh is
as a graph database wow that's
impressive who actually has used it
still you still have a couple of hands
and who is using that in production yeah
there's some people there cool okay so
this I don't have any condo I don't
require require any kind of previous
knowledge on new Fujio graph databases I
want to introduce that concept together
with how Panama papers worked out before
going to the talk itself a little bit
about myself you see on the on the that
doesn't work fair enough
so on the top of the screen you already
see a kind of small cipher path which is
part of our language to interact with
the graph database and use even if you
haven't heard anything about that
you will still realize that you can read
it so Stefan works for you for J which
is apparently true I'm one of the field
engineers at neo4j which means I'm not
one of the core developers but I'm
helping customers to get started by
doing workshops trainings also assisting
them with product repair project in
terms of coaching and I'm also part of
the support if things don't go
with that well as expected so everything
that is to do with the technical side of
the product and the customers that's
what I'm care about in the Europe in the
german-speaking countries I'm based in
Munich Germany so since I do speak
English today you will miss my nice
Bavarian accent which I had would have
in German sorry for that if you got any
questions after the talk you'll see my
my contact data there please just reach
out to me and shoot me your questions or
comments okay the Panama papers what
happened earlier this year there was
kind of combined publication of a lot of
different newspapers on offshore on data
that has been leaked from offshore
companies offshore companies is well if
you're a rich man and you want to
basically hide your your money for
whatever reason maybe you because you
don't want to pay tax or the money does
come from channels that are not official
maybe you stole something or even worse
then you can go to some of these kind of
tax paradise islands somewhere in the
Bahamas or in the in the Caribbean in
Panama we used to have some in Europe as
well which are now a little bit less and
of course if you're a rich man you don't
go there and fund your company yourself
you want to hide the identity so you
basically take a kind of law firm in
front of you that does all the actions
for you and one of these law firms was
mossack fonseca which is originated in
panama city and probably one of the
employees there or one who has very deep
insight in the IT systems sent all the
data he could grab to public newspapers
that's the big picture of the story some
before going in the details some big
kudos to my colleague michael hunger if
you know neo4j you probably have to know
michael hunger he's the most prominent
guy probably that we have out there in
the
community I've shamelessly stole most of
the slides from from him
the rest of the material is based on
presentations from the eye cij also from
some some record recording some publicly
available online publications from the
eye cij website so that's where all the
material is originated from so what
happened this is more than a year ago
who have you know tsutaetai doing in
germany some hands go up so it's a very
very prominent newspaper one of the
would say the three largest in the in
the country they're based in Munich
which also if I want to travel to them
it's about ten minutes from my home so
these guys are known for doing
investigative journalism and they have
already some infrastructure in place so
if you want to leak some data from your
organization company or whatever you do
I didn't tell you to do that but if you
want you they have a kind of encrypted
communication channel that you can
supply the data without telling them who
you really are and exactly that happened
more than a year ago so there was a guy
who named himself John Doe and he
offered some data and he said ok I want
to give you a lot of data but there's
some rules one rule is that data is
highly sensitive so if I'm if if my name
is is is going to the public I mean I'm
fearing for my life so I will stay
anonymous there will be no physical
meeting ever we always communicate over
encrypted chats and encrypted files and
what journalists do with that data is
totally up to them he doesn't care he
didn't take any money for that because
the investigators journalists typically
don't pay for it so the motivation for
that guy was basically he wanted to make
these crimes public owning a company in
Panama or some of these texts Islands is
not a crime on its own and that's the
real scandal
like that that you can do that but
they're almost everytime used for hiding
something and they're forced there's a
lot of crimes behind it yeah and then he
started to transfer data to the
journalists this was in the first place
yes some random files of some companies
scanned articles ownership documents
emails all the things you can all the
kind of documents you can think of and
of course they look journalists
collected them in their local hard
drives and to investigate on them they
use the desktop search these guys are
not IT people so they can just know
about Desktop Search basically and the
material that came in was more and more
and more like that
so over the period of a year that guy
delivered more than two and a half
terabyte of raw data to not assuage each
item alone but to the ACLJ because the
the journalists a to touch each item
were pretty smart at at the point of
time they realized we cannot handle that
on our own and also lot of the data
refers to all kind of different
countries so if a guy in Germany would
do something bad the new due diligence I
don't guys would probably have a good
chance to investigate further on that
because they know everyone and know how
to make a nice story on that but if
something happens in let's say Argentina
or some other faraway country you need
local people there to write a story
around that and therefore they got in
touch with an organization called the I
CIJ the I CIJ is a consortium of
investigative journalists worldwide it
is part or it would be to be precise it
was part of the Center for Public
Integrity which is an nonprofit
organization and I CH a was a project
project underneath them but just a few
weeks ago there was the decision to make
the IC IG a separate entity so it's also
a nonprofit organization
from the thighs it's basically close to
200 journalists are using that
consortium they work together they're on
on stories they're distributed over more
than 65 countries of course there are
countries in the Western world are
almost everyone there but there are
countries in the world where you don't
have so much fun as the journalists
think of countries like China Turkey
North Korea Russia soon u.s. I don't
know I have a bad feeling too since
yesterday
yeah and and these guys work together
there they have conferences so it's a
good like like a conference we do here
they meet up and and discuss stuff the
stuff of iccha
is pretty small it's about it's twelve
people who work there full-time and out
of that four people it's 50% who work on
on data and do data research so
apparently there were six people working
on that huge amount of data so what did
they do basically they had delivered a
whole mass of data
it consisted of emails it consisted of
Word documents Excel access databases
and all the fun and also a huge amount
of scanned documents yeah and this stuff
needs to be somehow processed so from
these raw files you need to first
extract text also extract metadata
metadata and then store that somewhere
in database or multiple databases and
then provides easy-to-use tool for the
journalists to do some queries on that
and by curious I don't mean that these
guys type sequel or any fancy language
they want to have like a Google search
thing where it just and the names or
something like that and also they the
journalists build up kind of list of
prominent names in the country so they
try to get all the members of parliament
from Germany for example plus the
government guys and all the guys who had
a kind of history in doing some bad
stuff with money
there was this president from
for a local football team FC Bayern
Munchen you probably know him RunAs he's
not part of the Panama papers but he's
sure on the list to do investigations on
that yeah and this stuff is then put in
in the database the amount of data it
was about 3 million files that were
transferred there and for doing the the
text extraction they use the OCR
software called new weeks which is I
think based in New Zealand they got free
licenses to do that and they spun up
yeah this is 35 something servers on AWS
and the average processing time was
about 10 seconds per file so they it
took them one and a half weeks if they
have just one server it would be way
more than a year to process that amount
of data ok so that is a kind of
screenshot from this tool they used for
collaboration and search for the
journalists of course this is massively
hidden behind VPNs and all kind of
security infrastructure which I don't
know and of will no one really talked
about that it is based here on backlight
backlight is a open source collaboration
tool which you can use and customize for
these things so there's the kind of
forums where you can collaborate
together join joint editing and all that
kind of stuff and what you can do here
as well is you can act on on the
full-text database ACLJ decided to use
solar Solar is very prominently known
it's based on the scene so you can use
blue scene syntax so you don't need to
name names exactly so there's fuzzy
search possible you can do proximity and
all that kind of stuff the full stack
they're using or most of the stack to
extract the raw data as mentioned they
use this OCR service then to in to get
some some inside in the text to
understand the semantics they used like
some
software written on their own it's
available in github called IC IG extract
which uses most prominently Apache tika
and some other tools on top of that a
huge amount of pison scripts the
databases they used was mainly Apache
Solr for full text part Redis for
keeping the the reference to the rod
documents and neo4j to connect the data
and this is what I'm gonna focus on on
the application level we already seen
black light and there was another tool
used linked curious which is a graph
which realization tool that runs on top
of the new forge a database link areas
would look like that so on the left hand
side you have also card of query
interface where you can type some names
or specify what you want to find and
then a full text search is triggered
retrieving some notes and then you can
explore the environment you can drill
into the data by double clicking then
the next node opens and so on so by that
you can understand okay we have here a
person that owns a company and in this
company his wife is also involved and
they own another company so you can
close the circles and get more insight
in the data which you wouldn't find by a
pure text search only so it's about the
context of the data yeah without using
graph technology we would have boring
disconnected documents you would have
kind of data I isolated data pieces
laying around somewhere consider that is
what you would you get when you store
these pieces of data you so you have
various things people emails documents
entities companies with you have some
some data with them properties like name
some values and so on and the
interesting data is how are these things
connected so if we add relationships to
them so that this person owns that
company the other one acts as a
intermediate for that company that is
in a certain address where a lot of
other companies are based then you get a
good insight in that data and you
understand how how that thing is
structured let's talk a little bit about
new vajay the leading graph database
what we use as an underlying data model
is the so-called property graph models
the property graph model consists
basically of four building blocks the
first block building blocks are nodes
nodes represent the entities in the real
world so everything that is a thing on
its own is modeled as a separate note on
these nodes we can store properties
properties are key value pairs so for
example you have a node here the left
one might be a person with a name of
something that would be the property and
you can also the next building block are
the labels so on the nodes to indicate a
kind of group membership you can assign
a label to them most people would use
the type of that node as label so the
nodes on the top might be a label of
person the node on the bottom
might carry a label of entity or company
or something like that the last building
block are the relationships the
relationships basically put your
entities in a semantic context so the
person has knows another person
relationships always have precisely one
type and they have always a defined
direction be careful the direction does
not imply the search direction so it's
the semantic direction of that
relationship
so if I work for a company I can
traverse from myself to that company but
you can also at the same speed traverse
from the company back to myself so it's
pure semantic thing the direction here
what are people typically using neo4j
for so we carefully listen to two people
who are using us we basically identified
that we have a lot of projects focusing
on company internal applications we are
which are not public phasing and the
other hand side we have also
customer-facing applications so the
internal applications are typically
things like master data management which
is mostly about connecting different
data silos in established enterprises
which don't know each other if you
consider any project that has to deal
with network structure or let's say
logistics network or something like that
that's pretty obvious also a graph thing
not so obvious is things like fraud
detection consider in a kind of
financial system you have all the people
and companies represented as nodes and
the money that flows between them is
modeled as a relationship by that you
can easily identify things like money
laundry because then money is flowing in
a circle so you're searching for closed
for a closed graph structure for closed
path on the customer facing side we see
a lot of people using real-time
recommendations just typically in an
e-commerce case where you want to see ok
I'm in my history I bought feed these
five items and now let's look what other
people have purchased these items and
let's see what their additional behavior
was and this is something we can
aggregate and filter and then probably
propose as as the next purchase for for
for me myself the the big difference
here is it's about real time most of
these recommendation engines typically
work nightly in a batch mode so they
consider only historic behavior but not
session data so consider your you just
write a very negative comment on a
product which would be based on the
nightly Petron a recommendation for you
in the next page you get recommended the
thing you just write and I wrote a nice
rant about
as a recommendation that kind of sucks
and if you can take session data enough
to account that helps a lot the reason
why I can do that is because everything
in a graph database is optimized to jump
from one node to one of its neighbors as
fast as possible we've measured on a
single core up to six seven million
operations per second which gives you
immense of traversal speed graph based
search this is also what what we do
together with Panama papers it's about
you start off with some full-text search
and then the the nodes are the things
you find from from full text are the
starting points for drilling into the
graph so by that you can do questions
like well which of my friends in New
York can we recommend a sushi restaurant
which involves a geographic graph with
New York with continents with cities
which involves a kind of category graph
restaurant type sushi which is Asian
which is food and also the social graph
friendship okay
so what is it what is the graph database
about a graph database is about
basically persisting data structures in
the form of graph so it's about writing
graph structures and also about reading
graph structures there is a difference
there's a lot of different graph
databases out there we need to
distinguish so-called native graph
databases which implement from the
storage layer all the stack up on their
own in the knowledge that we have to
deal with graph data on the other hand
side there are also non native graph
databases which use existing storage
technologies like let's say Cassandra or
something like that which is does not
know about graphs as a ground lying
technology and therefore at some level
they need to map graph to some other
format and on that level you typically
lose performance so as mentioned the the
core operation is quickly traverse
relationships it's since we don't have a
fixed schema this plays very nicely with
kind of HR approaches where the domain
changes frequently you know these cases
when you probe
owner comes over the corner every other
week with a complete new different ideas
at and you need to change data model a
lot of times this can really help you in
that context also in terms of
performance just please raise your hand
if you have handwritten SQL statement
containing more than 15 joints there are
a few hands okay was this fun to write
this statement okay most people object
was it considered a half a year later
you need to revisit that statement and
apply change to it is that fun not at
all so it's SQL is basically in my
opinion
well writing might be okay but
understanding a complex statement later
on is at least for me almost impossible
and also in in in relational world you
have always to mess around with to date
different models you have two logical
data model which in most cases is a kind
of graph which you draw on the
whiteboard with circles and arrows and
then you transform that into tables
remember these four normal forms of
relational database theory and and all
that kind of stuff so you have a
persistence model and in the persistence
model you write your queries when you
need to change the query later on you
need to transform that query written for
you back to them to the logical data
model apply the change there and jump
back and apply to change back to SQL so
you're always jumping back and forth
between these two models which is
cumbersome in a graph database world we
only have one model so the logical model
is the data is the persistence model few
operational aspects one focus that we
have is neo4j is easy to use I will show
this later on in a demo schema is
something that we consider optional so
there is no fixed data structure so you
can add new relationships at any point
of time if you learn about new facts you
just add them there is no alter table or
something like that
it is highly scalable so we can build up
of clusters of tens hundreds of machines
right now with the new clustering
technology in three one and it's also a
transactional database if you're if you
only work with relational database
that's boring because every relational
database is transactional but a lot of
non-relational data stores weaken the
transactional guarantees for tweaking a
little bit more performance out of that
we think that your data is valuable and
therefore we applaud we strictly
transactional guarantees on that ok one
thing to do on data modelling is this
whiteboard friendliness this relates
back to the that we only have one data
model so if you ask one of the would say
domain experts or here that must be a
guy from from the business side because
he wears a nice white shirt if you ask
these guys to explain you the domain and
give them a pen on a whiteboard
label in most cases start drawing
circles and arrows how how is the things
structured if they start drawing tables
then they've worked too long with
relational database and that kind of
structure is our data model which gets
them into the database directly so there
is no mapping between that and therefore
these modeling sessions together with
the with the domain experts are also
extremely worthful
to build up knowledge on your own
because you need to know that the
language these guys are talking you need
to understand the concepts to build the
software in the right way so it's it's
super helpful for communication
let's go a little bit more in in
technical detail here about patterns
neo4j the most important part to
understand cypher language is to
understand patterns and pattern
can basically being feared from the
graph model so consider we have here a
small sub graph where Dan knows an
cipher is intended to be ASCII art like
notation which means if you consider a
node which normally I have through the
whiteboard here but is currently we
don't so a node is drawn as a circle on
the whiteboard in ASCII something
similar would be opening and closing
parent this that makes a node an arrow
which you draw on the whiteboard in
ASCII art would be - - larger than and
this is what you see here and of course
we need to in tight DD parent s we need
to specify that this node is a person so
the colon person means that note carries
the label person and in the curly braces
you have the the properties in a chase
and like notation so that is a person
with name property called Dan and
between the two dashes we have the
specification of the relationship so you
pull the two dashes away insert square
brackets and then you write here the
relationship type so we're looking here
for Dam who knows a person called an
that is a pattern now we need to put
that pattern into some some some query
language constructs so in the front we
write the word match which means find me
that pattern and then we have on the end
the return Clause return who so the
person here is it's not longer and it's
basically the question is who who which
people does then know so we have we only
have two constraint here that the other
end of the knows relationship needs to
be a person but no restriction on the
name and that node is referred with a
kind of variable name who which is only
valid in the scope of that query and
then we return to who node so you can
the return if you take the bridge to SQL
what in SQL would be to select is the
in cipher the match is somehow the from
part so how is the world connected how
is it connected to joins basically okay
this pattern we can use it in a match to
find something but we can also use it in
with create to create relate notes and
relationship and the same part of
notation applies to that and there is
another clause called merge in a lot of
cases you don't want to unconditionally
create something you only want to create
something if it doesn't yet exist
consider in the Panama papers so we are
have the first document on a new company
and we create a note for that company
that company is registered in an address
and we don't know if that address is
already in our data set so for creating
the address if we would just use a
simple create we would end up with
having that address note multiple times
which is kind of stupid so with a merge
you prevent application basically so
it's it's a lazy combination of match
and create so it first applies a match
and if the match doesn't succeed it
triggers our create with the set clause
you can change a note so you can add
properties you can overwrite properties
you can set new labels on things
the latest obvious we can delete
something remove is for removing
properties basically when you want to
find something in the graph in a lot of
cases you want to apply filters
therefore you can use the rare followed
by a predicate that might be matching
some properties matching some paths or
there's a huge variety of things you can
do here well it made sense we took over
a little bit of syntax from from SQL
here for example if you want to do order
a result set you can do it with order by
you can do pagination with skip and
limit
and at the end of course you need to
kind of return you can do a li SS to
rename column names very powerful thing
is the width Clause
the whiff Clause is kind of similar to
the pipe symbol on the UNIX shell so the
output of the first part of the
statement acts as input for the next
part of the statement so the width
allows you to structure your statements
into multiple steps and also allows you
to terminate certain branches rather
early to get more performance out of
that unwind is if you get a list of
things kind of collection and you want
to convert a collection into number of
rows so you want to split up a
collection that's unwind a very powerful
thing and I think the most easy way to
get data into new voce' is load CSV
which allows you to load CSV files
directly I have a little bit more on
that
so load CSV operates on a full on a
functional database in a transactional
way so in the example here we load CSV
with headers which means our CSV file
the first line contains headers from a
URL a ul might be a local file it might
be HTTP HTTPS or any kind of URLs which
your JVM has a URL stream handler for
and then for each of the lines in that
CSV file we merge a person node with the
name column of the csv mapped to the
name property and the age column of the
CSV is converted to an integer and
stored as a age property so properties
can be strings numeric stuff boolean's
arrays and so at the end of the day for
each line we have one person node so
that load CSV works nicely for small and
medium data sets if you go I would say
beyond 10 million or even
hundreds of millions there are other
tools too before getting to that so
there are other tools to import in the
same way you can import CSV you can also
work on JSON data directly I leave off
the details since we're a little bit
short in time already for if you have
huge amount of data and you want to have
a count of initial data load there is
also by a kind of batch inserter
be careful that tool does not work while
the database is online it creates the
initial database for you in a non
transactional way and you can work there
with billions of things in a rather
performant way so we can create millions
of nodes per second way with that tool
but your CSV files need to be need to
fulfill a certain format okay let's get
a bit back a little bit to the Panama
papers so in total over over all the
data collected they identified more than
35 people who either are in a leading
position of country or used to be in a
leading position of a country that are
part of the data set if you remember do
we have someone from Iceland here now
don't see one sorry I cannot see anyone
because of the lights here but the
former Prime Minister from Iceland needs
to resign his job because he was part of
the data set so he owned a company and I
think today a few days before he paid
became prime minister he sold that
company for $1 to his wife and that was
not not legal in and recently they had
also a kind of election in Iceland which
caused a kind of big change in politics
there there's also a big friend of Putin
is in the data set you see Prime
Minister of Azerbaijan iliev holds a
couple of companies I think the chief of
state of the Arabian there Arab Emirates
are as part of that and some more
so what did they do basically with first
first that all the steps for the
document analysis they first acquired
documents and don't underestimate that
if that amount of data if you need to
transfer three terabyte in small pieces
in an encrypted way that is work and
then you need to classified documents
you either do scan or OCR extract meter
data and then to identify domains and
questions on a white board extract
entities and their relationships based
on text analysis think about what
properties do you wanna store also the
data set not only consists of that leak
they also have the the offshore leak
data set which was leaked before merged
into that so they have different data
sources then you need to think about
analyzers and all that stuff you need to
care about getting the metadata and and
point six is interesting you can in fear
relationships so in fear relationships
let me make a simple example so if so I
work for neo which is a company of 130
people
so either works for relationship with
that company and here in the room there
is a colleague of mine Constantine he
also works for that company and that we
can apply a rule that if if two people
work for a company with less than 150
people we assume they know each other in
person so we can in fear a knows
relationship between me and Constantine
so you can apply this kind of logic to
close triangles and get so with that
there is a technique to basically unreal
hidden data and yeah then you can apply
some some calculate similarities because
sometimes names are not written in the
exact way so if you think these people
are the same you make a same
relationship between them and then you
can go into visualization and do some
analysis so that is the flow that the
guys did so the data model so
potential entities stay working with us
well they have you have people you have
representatives you have addresses you
have companies we have accounts so meter
entities would be kind of in which
document was that located contract
numbers also dates and all that kind of
stuff
potential relationships think about I
own a company I have shares our manager
company as general manager I opened an
account the company has a reaches that
address somewhere
money flows and so on family
relationships that's that's roughly the
domain that they're dealing with so that
would be a kind of snippet of the data
model they worked with so there is a
client registers the company then there
is an officer which is a kind of
shareholder of that company this is only
a short excerpt so these kind of models
you build up during when you try to
understand the data structure yeah the
data model they used a set it was rather
simplistic think about it was only a few
six people who worked on that so it's
about four kind of entities a few type
of relationships and the I CIJ released
subset of their data to the public as a
directly as a graph of course they
scraped data they removed sensitive data
like credit card numbers and other stuff
and on that data set we can do run now
some queries that data
of course misses a lot of information
like metadata family relationship it
contains a lot of public eight so it's
not really cleaned up data but it's good
enough to do something on it so if you
had more way more resources you can
easily refine that kind of thing so yeah
let's go to this example data set so
yeah so here's my new for change stance
yeah that looks good I think I should
have make it a little bit larger so what
you see here is
I've started a new Fey instance using
the docker container well every talk on
this conference needs to have to go
docker in it somehow so what you see
here is the the neo4j browser the new
voce browser is a tool that is intended
to be used by the mighty developer or by
a domain expert who wants to write ad
hoc queries it's not something you want
to expose in a project scenario to the
end customer so what you see on the left
hand side there's a few panes like here
the database vocabulary so we know here
which labels are used we see which
relationship types are used a couple of
them which property keys are used we see
the size of the database and some other
stuff we can on that the star is
basically for queries so you can store
your queries that you once wrote in in
the browser to reuse them later at a
later point of time there's some links
to documentation some tutorials and all
that kind of stuff
and some more which I don't want to
cover right now so the mechanics is here
here on the top line I can enter a
cipher command and for every time I
enter a command I get a response box the
response might be an error message like
now or it might be a visualization
consisting of nodes and relationships or
it might be a table like result set what
the browser also has the capability to
render guides so guides are HTML files
in a certain format that you can easily
view in the browser so here for a Panama
data set we created a command of guide
for the Panama data set I don't want to
go through all of them but the
investigative queries is interesting so
you can so these cards contain a little
bit of prose text some images and when
you see these the cipher blocks when you
click on them you can directly execute
that so there is a function to extract
the meteor model of that graph let's try
to get that
so we have here so an office so this is
the meter model so an officer might be
cher hold of an entity an entity might
have an intermediary an entity and an
officer might have unregistered address
and then there's similarity
relationships for all three entities
that's the meter model and that's that's
nowhere explicitly stored
that's just calculated from the graph
okay let's do a kind of query we want to
understand we don't want to look for
intermediaries which have more than 100
relationships to whatever and one a
filter but so which intermediaries host
the most companies and here you see a
lot of company names and here is the the
famous law firm mossack fonseca which
was the source of the leak by the way
there was recently a few weeks ago I
heard any news that most active on Zika
has to lay off a couple of people
normally I'm always think about well the
people lose their jobs now but in this
case I'm really happy about that to be
honest so they're almost done I think
with their business ok let's go a step
further
so yeah let's get some visual results so
let's assume we want to find
intermediaries that act for companies
and so we have here the path would be so
we're looking for node with label
intermediary we name that node i we're
looking for an intermediary off
relationship to something that is an
entity I know that variable names should
consist of way more than one character
in real code I do that but I would just
break the line here so this is a rather
bad example here to have only one I want
character variable names and the
intermediaries the name property should
contain the word ma sock and the
restriction of that entity should be the
seashell Islands and then we just want
to return
the intermediary the relationship and
the the entities and we want to limit
that down to a hundred results and you
get here now kind of visualize results
because I've returned notes and
relationships and then you can go grab
any of these notes you can move them
around if you double click on them you
explore the environment of that so we
have here a guy called mr. loss Eric
something Eric Larson and that one has a
registered address in where is that in
Myanmar okay so there is a way of how
you can interactively drill into the
graph so that guy is already in
relationship to three companies Raffles
net kill limited privilege and so on
yeah that was already pre useful so we
can also do return tableau results so
this was kind of graph view that is nice
for exploring the data but in a real
application like context when you write
an application that uses the graph
database under the hoods you want to
have kind of projections so you won't
have all the research which you can
iterate over so that would be an example
queue so we want to list officers that
are beneficiaries of entities and we
want to find out which officer has the
most and it's related to most entities
and therefore we apply a count account
aggregation and we order by the count
and we cut off after ten and in order
descending so this gives us the 10 the
ten people or entities who are related
to the most companies and here you see
already the data is somehow a little bit
chilly so it's not really scraped but
good enough ok what we can do as well is
so if you want to find a certain officer
so let's do this guy from from Iceland
gun locks on
this was the former Prime Minister and
here we see him and if you click if you
if you look at the bottom you'll see all
the properties of that note so here you
see sigmundur David Gunnlaugsson let's
just open that guy and you see there's a
company called Ventress incorporated
which and he has a registered address
somewhere in Iceland look at look hard
key school 424 so if you ever been to
Iceland go there have a coffee with him
and on that address there's another
person registered it's it's his wife and
he sees you should also share hold of
that company okay so any specific name
you should query right now Trump that's
yeah let's just try that yeah it's it
specific Trump Enterprise new Trump
technology limited from tech and so on
so it's not related to that person in
the US as far as I heard
I think the journalists have done a very
spend a lot of time to find him there
because that would probably change
yesterday results but he was smart
enough not to get into the data set okay
next one yeah there we want to so forth
so far we just did the kind of look up
and now we want to find an officer which
name contains Trump and to want to
return back the entities he owns so we
are a firm kind of match here that
already does some traversal and these
are the three companies or the three
officers officers might be companies as
well
yeah there's there's more queries I
think I gonna let it go little bit
faster now because I want to show you
something rather interesting let's do a
kind of query here so who's involved as
well so we want to find the pattern here
is we're looking for a node that is an
officer that has a relationship to a
company or an entity that has a
relationship to another officer and then
we filter out that the officers must not
contain the word limited because we're
interested in a natural persons and that
these officers should have each of them
more than two relationships so who's
which two pairs have other companies on
the side and then we do some want to
collect them and get some nice report
out of that that is already pretty
complex because it is a kind of global
theory it goes through the full graph
and here you see there's mr. Chun Ling
Chuck Douglas and mr. Chun Carl Henry
Tory I cannot really and they are
involved in in that amount of companies
and I think if you are associated to
multiple companies the likelihood that
you're doing something something illegal
is even higher yeah another interesting
thing so far we did not do a lot of so
we just did we started a query somewhere
and we traverse the path which consisted
of a few relationships but what we
didn't do so far was something from
graph theory what we easily could do in
a database like neo voce so we have we
have one person we have another person
but you don't know how they are related
and we can probably ask what's the
shortest path between them so how does
the relationship look like and what I'm
gonna do here so we have mr. Smith and
mr. grant so we look them up in the
first place because there's multiple of
them we
limit that down to 20,000 and then we
want to find all the shortest paths
based on officer in the media and
registered address relationships up to a
depth of ten so we can do multi we can
do variable puffed reversals and we want
to get back fifty results right now
that's the takes a few seconds because
it is a complex query already okay some
background music blah blah blah come on
when I tested it upfront it was faster
okay anyway while we're waiting for that
I do have stickers here so if you want
new 4je stickers or these wonderful
graphs are everywhere stickers after the
of the talk just grab them here yeah
here we go
also it and we can now assume that a
little bit you can down here and we have
here intermediary nine here is Stuart
Onslow Smith and there's Stuart grant so
that would be the and here is this other
guy this is grant moi take him so
there's a would be the shortest path so
you can easily follow over which and
there's multiple shortest paths of
course so how the how their relationship
is structured and then you can probably
ask get more details on the companies so
this is how you find out relationship
between people yeah so I think I'll stop
the demo at that point to have a few
minutes left for for questions I do have
a kind of announcement which was just
released today so my employer new with
new technology today announced a new
finance round seriously with 36 million
in the bank
so that was impressive news today was
just released on half-past one this this
afternoon so that is the last the kind
of announcement and then according to
the time here we have seven minutes left
for questions so the question was if do
we have any feature the API to report
progress not directly there is a way to
extend neo4j with your own JVM code and
with that you can write a progress
indicator and it's it's hard to do that
because you don't know the work the the
results that up front what you can do
with an extension is say I have this
query and run that for let's say 10
seconds and finish it then and just
return back what you found so far that
is there is a very valuable extension to
neo4j called the epoch library and a POC
a POC this was the kind of mechanics guy
from the neighbor cabinets are in the
Matrix movies so that library features
that kind of thing ok some more question
there I can't care how this you do to
the like yep yes so the question is can
relationships have a weight or a
strength you can put any kind of
properties on the relationships in the
same way you can put them on the nodes
and typically on the relationships you
store meta information like Manhattan's
thing being created or a weight consider
logistics network so the road between
Brussels and Antwerp is 40 something
kilometers I assume so then we would
have a weight of 40 and you can use
these weights then for weighted shortest
paths based on the extra algorithm or a
star too far to do route calculation
more questions just shout at me I can
hardly see you okay there's there's a
question please go out
how the question is how do we handle
time in such a graph so there is no
separate type for date and time in neo4j
as property type every time you will die
a date and time data you can store it as
milliseconds since epoch so the unix
timestamp and the april library i just
mentioned has capabilities to format
that back to resume in readable time
with index operations I didn't cover
indexes at this talk at all with index
operations you can do range queries on
on on these time properties and by that
you can get everything that happened
between that time span another approach
to that is you model time explicitly in
the graph so you have kind of time root
node underneath you have a node for each
year underneath a node for each month
and then you go down as granular as you
domain model mandates maybe two minutes
or something like that and everything
that happens at a certain minute is then
connected to the time node and to find
then do a range queries just you need to
traverse down the time hierarchy and
grab everything that is underneath there
is an extension to neo4j from our
partners graph aware called the time
tree just inspect that webpage there's
another question how to do history in a
graph this is not a built-in feature but
you can tackle it nice with modeling so
there is what you basically do you
separate this entity from the state so
each entity is a node and the state of
that entity is a separate node and then
you have a has state relationship
between them with the time stamp from
and - and when when the state changes
you take a copy of the state node apply
change the old state from current time
it was to current timestamp and then the
time that the state nodes might have a
next relationship so you have kind of
they are around the entity node
basically and by that you can track
every change and do history
there is a great blog post of my former
colleague Ian Robinson out there just
Google for new for che time version and
you will find that blog post it's were a
very very good description of the
concept
so you basically tackle it by proper
data modeling but take care every query
will get much more complex due to that
another one do we have a concept of
paging on the number of notes we want to
retrieve of course cipher has a limit
function so you can ask I'll give you
just one hundred things and then done
yep okay so I do have some stickers left
please I'm around this evening and maybe
tomorrow so grab me for questions thanks
a lot for attending</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>