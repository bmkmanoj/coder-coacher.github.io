<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Cassandra - an introduction by Hanneli Tavante | Coder Coacher - Coaching Coders</title><meta content="Cassandra - an introduction by Hanneli Tavante - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Cassandra - an introduction by Hanneli Tavante</b></h2><h5 class="post__date">2017-04-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fnl_F2nBt9U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi I'm surprised to see people here 530
so thanks for coming to this end of the
afternoon session this is not a talk
about yet another database this is not
what it meant to be this is also not a
marketing talk I don't work for they
decide for Ferguson a trained team I
just think this is a very useful
database and I would like to share some
of my experience by getting started with
this awesome database and why it could
help your project okay so this is not
marked my name is Hanley I'm from Brazil
I am a software developer I've been
working with programming since almost
ten years now and those are the things
that I like to do I like Pokemon so if
you're a painful c'mon please him your
friend code quick agenda here let's
understand a little bit about the
motivation why Cassandra could be useful
to you what's behind your texture how do
you write and eat reach to the database
a little bit of structuring a data model
that makes sense for Cassandra and some
combos I'm going to leave some
references for those of you who are
interested to do a tutorial on getting
started with Cassandra but that's not
the main goal of this presentation I'm
going to show you some Intel content
it's going to be a crash course but
that's not going to be a tutorial I can
pretty much you know Google like
Cassandra tutorial and you're going to
have you know those commands that he ran
one after the other but that's not the
goal of the presentation we're going to
see the theory behind Cassandra database
and why it makes sense to adopt
Cassandra in some scenarios okay okay
yes no so this is not a tutorial you're
going to do some gifts because I see
that you're tired after a day full of
interesting sessions so that's going to
help us to keep engaged with the
presentation there's going to be a point
where you're going to be paying
attention to this just because of the
gifts not because the data
if I know that so what happens or what
could it happen if you have a bunch of
data inside a relational database let's
say 300 terabytes maybe nothing bad is
going to happen but sometimes bad stuff
happen all the time so imagine that you
have you know a terabyte of data and
you're running a query and it's getting
slow what could you do one thing that if
you think about doing is the normalizing
creating a column called user IDs so you
can avoid performing some joints by
having the ids is stored in a column
right have you ever done something like
that yes the problem with the
normalizing data is that well relational
databases are not meant to be using this
kind of data model right you're breaking
rules of relational databases so it's
very easy to mess up your data and the
DBA may be very mad at you at the end of
the day mother's life is another
strategy do you use monsters live very
common strategy for my sequel for both
ways or you know many relational
databases all three you do the strategy
but the problem with master slave is
that you have a single point of failure
right if your master database fails
there's going to be a few seconds until
the the slaves they debate assumed
correct so that could be a big problem
sharding have you ever been to charting
yes I've been to charging of several
times and that's also a common strategy
but performing scheme updates on
charting or on different chartings can
be a challenge also imagine that you
have I don't know you split your
database or table and ten different
table let's say you got your big users
table and you split them in 10 different
slice for the charting so what happens
if you want to run
query ah that's for example something
like you want to know the users of
California you run a single query but
for this particular query how many
queries are going to be in the cuted 10
you got to go through all these laces so
one query becomes ten queries and that
can be very very expensive so all of the
strategies are they can solve some
problems but create other different ones
that you'll never expect that you have
two quick questions for you do you need
consistency one hundred percent of the
time for all the cases I know it's
difficult and it's the end of the day
but please talk to me that's not a
monopolized session well sometimes you
might not need consistency all the time
did it ace it all the time how can you
ensure that has high availability if
you're using master slave I can tell you
that you don't have high availability of
the time though sleep seconds that have
between the switch of a slave to a
master you're not available so that can
be a problem so if you take a deeper
look into the prisons of strategies they
can create your new problems so to sum
up if you don't normal eyes your data
you'll break the third normal form and
then it can call you a lot of trouble if
you have master slave again you have
consistent problems and then can tell
the trouble so the same thing for
charting I'm not criticizing there's a
strategist I'm telling you that it
should be aware of the problems that can
have by adopting them there is no super
boat we all know that so what would be a
good scenario to have a database that
can handle a bunch of data without
giving me extra headache a good scenario
would be a snare where consistency is
now necessary 100 since the time I do
have monster slaves because having
master slave is going to provide me a
single point of failure
on I want to be able to scale my
database in an easy way I don't need to
come up with you no more machines that I
have to set up and run scheme update and
things like that I want to I don't know
use something like easy to you and just
add more machines and make sure that my
database is going to be able to handle
more data I don't want to handle chart
charting manually because it can be a
really complicated too so big scheme
updates and so on and that's when
Cassandra comes to the rescue so
Cassandra can perform all this benefit
for you and that's the goal of the
session to make you understand why
because Cassandra could perform all this
all these activities so if you go to the
center website and I know that's
terrible but you're going to see this
all fall 1996 page it's like nine inches
page and then that's not comfortable to
you know to interact with you're going
to download the file and there's going
to be a tutorial like how many of you
try data center tutorial was it very
engaging sort of like it's going to be
like the default so you create a schema
and then you create a user's table and
then you had these columns and then you
run this command like what the hell is
that you create a schema renders command
and then you I don't know around this
does query to create a table and then
you seek you all which is very similar
to ask you well what does it even mean I
mean why would you be adopting Cassandra
so I think most of this tutorials that
you'll find on the internet for
Cassandra they really don't tell you why
the database can be helpful to to your
use case they tell you about the syntax
they tell about creating key spaces and
tables but they don't tell you about the
features that the database has so quick
history Cassandra history it was open
sourced by Facebook in 2008 it's mostly
written in Java although they have some
code in school I guess
but I think my ninety percent of it is
written in Java and why Java whoa there
were lots of slippers for java by the
time they could get potential
contributors to the database by open
sourcing it they were looking for
compiled language that could provide
them a good performance and more than
that they had jmax to help to profile
and monitor what is going on in the
database should have a bunch of tools
for profiling they could perform a
deviant turning and get some benefits
from the database and it was pretty
confident to manipulate data structures
by that time in 2008 so how does
Cassandra work so I concentra has a
bunch of nodes it's a distributed
database and you can see the notes at
machines and inside every machine
there's going to be a change in running
Cassandra JVM with the cassandra jar
okay when you get started with Cassandra
are you can access all this information
about the node by running a tool called
no 2 and this nulls are are always
talking to it to each other they're
always interacting on so they're like
always sending messages to each other
and this is called gossip protocol so in
Cassandra you don't have mastered slaves
remember massive monster slaves can give
you a single point of failure and that's
what cassandra is trying to prevent so
it had all the snow talking to each
other equally there is no master node or
anything like that they're equally
distributed with equally of equally
functional we can say that and these
notes are going to distribute the data
under as a hash shrink which means that
each of this note is going to handle
part of the load so we can think about
something like that that's easier to to
understand so when you have some data
being sorted here the nodes know which
is the range that
every node in the cluster should be
handling so for example you have a data
that's blue and you know that the blue
data needs to end up at the blue note
and the green note knows how to send
this data to the flow note the note that
receives the data is called coordinator
and this note in this case the green one
is going to send the data to the correct
position that's the general idea of
Cassandra I know it sounds abstract but
does it make sense having a hash shrink
and every participant of the drink which
is going to be an else going to handle
parts or slides of the data think about
a charting but a sharding that's always
communicating between the port next
question like you are talking about
ranges where does it come from so every
time you have a table you create a table
you provide this information here and
this information is called partition key
so in this case is going to be the last
name so imagine that I'm going to insert
a record with my name which is Hannah
Witton content so what is my last name
so this information is going to be
throwing to a hash function and that's
going to produce a number which goes
from 2 to 6 24 33 I guess something like
that which is a huge number and that's
going to be on your your hash yes that's
the soup correct range you can choose
different hashing functions Cassandra
provides you famous ones like more more
three or so on you can also add your own
customized hashing functions in order to
get the information that you have here
at the partition key and transform that
into a number inside this range here ok
so that's how the ranges of the hash
ring are distributed and of course like
you can have drivers in different
languages that are able to calculate the
spoken for you one of the most adapter
adopted partitioner algorithms is the
former three I can also choose random or
many others so how can you guarantee
availability because if you have a
single copy but remember the blow they
are going into the cluster and then you
are assigned at flow data to the Blue
Note what happens if the blue note is
not available that would not be very
helpful so we need copies and for this
copies we have the concept of
replication factor RF we create a
replication sector purchase pace and key
space is the structure that holds many
different tables in Cassandra and their
application factor ah it's basically the
number of copies that you want to have
in your cluster so how does it work
imagine that you have application factor
of three what do you met geez oh so
imagine that I have this data coming
inside the cluster what do you think is
going to happen how many copies I'm
going to have this data three thank you
it's at four I'll be very sad so this
not here is going to receive this data
and it's going to make sure that this
node this node and this node have copies
of this information but where what
really happens is that you know one
passage of the order what happens the
replication of the range so you can see
the green range three times they can see
the blue range three times then you can
see the poor prevent three times and so
on you replicate the ranges so for
example of this is not here knows that
it's responsible for the green Range the
green range and the green range I know
that I need to replicate that three
times that's really what happens you
have backups of your hash rings it's
important to understand that the
replication sector is going to provide
you a synchronous copies so you write
once and you're done you don't need to
wait wait for having extra three copies
of your data okay you can ask what what
if this note here that would be
responsible for the grain data goes down
concentra can also restore you of this
data that should be ridden to an extra
copy of the replication factor for a
period of time that's called on hand it
handles so cassandra is also ready for
this situation so remember replication
factor is an a synchronous copy of a key
space replications factor is Percy space
per group of tables another thing that
might ask is about consistency sometimes
you have saved queries that are a little
bit more dedicated and you need to make
sure that the result is going to be
consistent so how can you handle this
problems is there a way in kissimmee to
increase the consistency because up to
now we saw the replication factor that
can ensure more copy to us but even
though we don't have the grantee that
we're going to receive the most updated
a slice of data so how can we is there a
wage increase consistent Cassandra there
is there's another concept in the center
called consistent to level and that's
per query and every time you perform a
query either to read or write you can
inform the number of nodes that are
going to acknowledge you back saying
that that that operation succeeded or
not the same thing for reading and
writing so imagine that you are trying
to read some information here have
applications factor of three and you
have a consistency level of oh so you
want all this replicated that data to
acknowledge you back three times so
you're going to have three responses and
they all need to agree okay so when you
have school supplies of all this note
here is going to ask for the three
responsible notes and all the three
responsible nose needs to perform this
query and then acknowledge your backs
okay and the oldest oldest notes here
need to agree about the information that
they're going going to return to you the
coolest slide was for query which means
that it's not by
space like the replication factor and
that's kind of interesting because we
can control the consistency of the
Aquarius that you perform it's probably
obvious that if you perform queries
constant levels all it's going to be
much more expensive if you perform a
query where you need a single response
from thrown a single note from a single
copy does it make sense it's going to be
much more expensive here so again years
conscious level fall for parents that
are really dedicated or need very
precise data now I have different levels
Pirkle for consistency the default is
one I can also use all or the most
common is 40 we're going to talk we're
going to talk about some problems of
using conscious level 0 at the end of
the presentation so it's totally fine if
you have a replication factor of 3 and a
consistent off of one remember the
replication factor is a number of
synchronous copies that you have the
constant level is the number of nodes
that need to acknowledge your client
back when you perform a query right is
it clear to everyone goes it level
preparing a revision factor perky space
so that's kind of interesting because
you can have some sort of interchange
between the availability and a
consistency that you want to provide in
certain situations of course if you
require too much consistency this those
cars are going to be expensive for the
cluster and they're going to require
more machine time so you can't like
measure according to your needs so how
do you read and write data in Cassandra
so to simplify the process imagine that
it has some data here being written and
then once the data reaches of the note
two things are going to happen pretty
much the same time a commit log file its
going to be written on the disk it's a
single flash in the disk it's not an
order structure under this with just a
flush and then instructor is going to be
created
and ram this is structure is called main
table that's going to represent the
information that you are actually
inserting on the cluster and then once
it's done then you're going to
acknowledge back sorry you're going to
acknowledge back to the client okay you
only need this tube quick actions in
order to have a successful writing in
Cassandra once that is done after y ou
are synchronously this is a structure
that is in memory is going to be flushed
in the disk in another structure and
this one is a sort of structure indexed
structure that's called SS table alright
but this is a synchronous you don't need
to come up with an SS table in order to
acknowledge back to the client right and
all the data comes OS x x so everything
in cassandra is immutable which means
you can't really perform a delete you're
not really removing a thing they're just
marking that as I don't want this piece
of data anymore I can you can really
perform update you're going to write new
records and so on so that provides you
very fast right ok so every time you
write in Cassandra those two actions
here creating a structure in memory plus
flushing of single file and the disk or
very quick actions does it make sense
please talk to me i know its end of the
day come on you can make it so a problem
here is that for every right at some
point you're going to end up with this
annoying structures called SS tables
isn't it really annoying you think it's
healthy for your disk to have this kind
of structure of course not so from time
to time contender needs to perform some
sort of compaction she grabbed all the
senses tables together and combine them
and provide better indexes to the
information that are actually right so
again this image this is kind of obvious
is called compaction and have different
algorithms for compacting
your data all right again this is
necessary because you're going to end up
with a bunch of fascists tables on your
disk and that's really bad for
performance so it's better to have like
a little bit larger files that you can
actually check them instead of like
really small chunks of data so how do we
reach data so imagine that you have a
query here on this client is asking for
a piece of information but it's much
simpler simpler so Cassandra just goes
today at this table finds the data that
you want and acknowledge us back to the
client this SS table here again it has a
bunch of levels of indexing and it can
return your data in a very fast wait so
sorry for consistent level of quarrel
and all what really happens is that
consumer is going to read the data throw
all the notes if the consistent level is
all and then it's going to agree on the
most recent one in case you get a
different result so let's say this note
got returned to you like one the son
returned the return to you and this one
returning to you like four so consumer
is going to fly to try to try to find
the most recent information remember the
all the information that you're right
comes with the time step it's going to
return you the most of any more and not
only that after acknowledging back to
the client Cassano is also going to
update the out data nodes so that's
quite convenient so every time you
perform a query and custom to realize
you have outdated information it's also
gonna update the updated notes for you
so how can we structure our data model
so remember that i mentioned that
cassandra rose created a Facebook and
Facebook you have something like that
you're a user with a bunch of boats and
every post can have a comment and a like
so can you picture this scenario it's a
master destructed scenario Sokka center
came up to solve this kind of problem in
a similar way we could
about a music education where has
playlists and tracks and a bunch of
artists and see this information could
be repeated indifference for example
artists could be repeated for different
tracks the same artist could be present
in different tracks but in different
playlists right so turns out that it can
be masking to try to solve this kind of
problem inside relational database
because you would need cells
relationships and so on so Cassandra
comes to so and in a good way this kind
of scenario here so how do we create our
data model we're going to have a bunch
of replicated data again the same way an
artist can be in different tracks of
different playlists we are going to
write this data replicating it across
different tables so give you to give you
an idea for a music app we would have
tables like track by ID track by user
track by artist trek by style and think
and things like that right so we are
going to replicate the track information
across several tables and that's going
to provide us I could speed to to fetch
data so one thing here is that consumer
doesn't have grouped by so you got to
rely on closer in columns and that's
combos Cassandra works pretty well with
spark if you're working with event
sourcing or even tracking for example
it's a good coma because it can provide
your first read and fast right again
Cassandra spark and Kafka if you have
some sort of real-time streaming
customer and solar can provide you an
interesting way to use a text search
with a database and consumers are
flexible and it's open source so it can
pretty much create a connector or on a
new framework that can make a center
interact with it and then how can you
get started with Cassandra sphere
I totally recommend this project called
CCM the thing with cassandra is that you
need more than one machine at least so
with cesium you can kind of walk your
own local environment to make it look
like a cluster with different faiths IP
addresses and it can pretty much work of
simulating a local cluster on your
machine I also recommend data sex
Academy they have very interesting
courses and they're free and here also
some reference for you in my last minute
I want to talk about Cassandra
complaints one of the top casella
complaints is about it garbage collector
but it's not only is that really
Cassandra it's more more about the GCM
Java people found different bugs on
center because of that it's not a issue
but some people sometimes they complain
about the GC another thing from time to
time we need to update your information
so if you don't have queries that run on
the consistent slab of all how are you
going to to perform an update for the
outdated note so from time to time I
need to run an operation called reread
repair and that's going to update you
obtain your updated data what the last
thing here it's about the confidence
level if I have to the confidence of all
you require that all the data that have
a certain information to acknowledge you
back but what happens if she if one of
your nodes is down York where is going
to fail so be careful which consists
love of all that's why I told you focus
on using conscious level quarrel which
is going to provide you a very
reasonable consistency sometimes
modeling can be another struggle because
if you're coming from relational
databases you're not used to create a
bunch of tables replicating data and
that also means that you need a bunch a
bunch of space on disk so be ready for
getting SSDs on your infrastructure as a
service
so I'm sorry this session was really
quick 30 minutes only but if you have
any questions I'll be around and I'll be
help you to get started with Cassandra
so thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>