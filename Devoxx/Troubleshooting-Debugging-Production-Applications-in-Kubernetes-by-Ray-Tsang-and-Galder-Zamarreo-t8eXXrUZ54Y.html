<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Troubleshooting &amp; Debugging Production Applications in Kubernetes by Ray Tsang and Galder Zamarreño | Coder Coacher - Coaching Coders</title><meta content="Troubleshooting &amp; Debugging Production Applications in Kubernetes by Ray Tsang and Galder Zamarreño - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Troubleshooting &amp; Debugging Production Applications in Kubernetes by Ray Tsang and Galder Zamarreño</b></h2><h5 class="post__date">2018-03-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/t8eXXrUZ54Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you so thank you everyone for
joining this session the last session of
the day I really appreciate it
my name is Ray I'm a developer advocate
for the Google cloud platform what that
means is that being an engineer for the
past 15 years or so and now I'd like to
bring some of the latest and greatest
technology and experiences from Google
cloud developers over the world and also
of course the open source projects that
we are doing that that could be useful
for everybody so if you have any
questions about this session please
please contact me on twitter at standard
ism and prior to Google I used to work
at Red Hat and it's actually very very
nice to be able to have Kaldur joining
for this presentation so go out there
hello my name is Calder I'm a software
engineer at Red Hat I work on the
infinite plane project which is memory
data grid for Java developers and
previously I used to work a lot in
support so that's why I'm bringing a lot
of like JBoss application server and
clustering support into this talk and
you can find about me god that's it yeah
and like I said we used to work actually
together on the Infinity and project
before I joined Google as well I used to
be a small contributor to the project so
thanks again for joining thank you all
right so what we're going to show today
is you know this application that I have
written a while back I have to say this
is probably the best-looking application
I can have ever written developer no I'm
not yeah I'm trying to be a back-end
developer myself and I mean but then but
come on look it's got this nice
horizontal line that's a HR I know that
much right and but what this application
can do is that it's a micro services
application that will do two things it's
two of the best example application put
together it's got a guestbook
application or you can say a nice
message hopefully and then you have the
hello world servers behind the scenes
that will say hello to you right very
very simple and behind the scenes is
doing them using micro services
architecture we're not here to say
whether
it's something you should be doing or
not but if you chose microservices for
some reason right we're here to show you
to solve some of the problems so here we
have the front end we have a UI service
here UI component and we have two
containers running behind here we'll
have the holloway service you know
guestbook service lots of our services
just for a HelloWorld application right
yeah yeah I know it's always said it
only does is to say hello to you but but
it will help you to understand and
navigate some of the common problems
that you're going to run into with micro
services okay so rather than going
through the details why don't we just go
take a look so here I have my
application running in a kubernetes
cluster this is running on Google Cloud
at the moment is using kubernetes engine
which is a managed service right but
that doesn't matter but what you need to
know is that we provisioned very quickly
like five different VMs here oh through
the platform and and we are running the
criminalised applications here so we
have the Halliwell UI we got two
instances because you know we have that
much load because you need it for a
hello world yeah of course yeah and we
have two instances of each for high
availability right and here we have the
guestbook service and so on and so forth
just to show you very quickly like what
that may look like so here is the the
Yama files right with kubernetes what we
always do is to write the deployment
descriptor so for example I have the
guest book the appointment here and if I
scroll down I can see for example the
the number of instances that want to run
and also the configurations for
kubernetes and also the image we want to
run ok so I got this so deployed and we
also provisioned a load balancer again
this out-of-the-box company's concepts
so we provision the internal load
balancers here with an internal IP and
we also have this external load balancer
which automatically provisioned the
external IP on the cloud platform in
this case right is Oh transparent or
automatic so how many people here
already used crib entities will have
used kubernetes
yeah ok yeah almost half the room that's
pretty cool so with a simple
configuration we're able to just you
know provision low balancer expose it on
public Internet everybody can see this
app today
right now and as you can see there's a
spring application so we still now go
take a look
oh wait a sec wait wait yeah oh no my
level error page yeah five hundred
another error in a four four in the same
place no no no well that's that's not
screwed that means we're writing a java
application or go
could it be go know what the go has new
pointers I don't have no more pointers
so no this is definitely job I mean look
at that spring I counted hop yeah so do
you have a backup you mean like a video
yeah just to show the people right now I
thought you're creating a video yeah oh
I didn't have time I was walking my dog
last night my dog last night yeah well I
said the speaker's dinner last night I
don't I thought you were doing okay so
this is embarrassing
yeah even though it's the first time
we're doing a talk I'm so sorry to you
wait wait wait gallery no don't go don't
go wait a second so I know that all of
the people in the room like they
probably went through a whole day of
talk they're just waiting dying's we see
a presenter fail I their demos and I
guess this is your day this is your
session right so I guess we have to kind
of figure this out and I can't just
leave I mean we're only six minutes in I
don't know I'm waiting for the party and
the beers the beer is a beer afterwards
how many people want to go get beer oh
my god everyone yeah well well but no I
think we should do some due diligence
and try to figure this out let's see so
what happens when you do have a
production issue somebody calls you up 2
a.m. in the evening what do you do first
maybe Lucas take it staging that's a
good practice right yeah if you could a
production environment ok before you
arrive top production you could have
gone through a staging right you will
have created an environment where you
test I hope to deploy it right
I hope so everyone here everyone has a
staging environment right you don't you
nobody is raising your hand nobody has
staging everybody should have a state
like some kind of environment that
allows you to test of course you never
go to production without going through
staging first so hopefully everyone has
an environment like that and in my
cluster I have a music community so I
can carve out my cluster of my machine
into what we call namespaces right so we
can do something like hey keep steel get
namespaces we can see that we have a
default namespace and also have a
staging namespace okay and in the
staging namespace I have exactly the
same application running there because
in kubernetes the namespaces
you know separates the the applications
so you can't use the same name writing
different namespaces okay so with the
point exactly the same app and we have
my UI application there and everything
so let's see here I have a different end
point maybe I can try and there we go we
have the UI front-end so let's go give
it a try so this is not working
production yeah oh ok well that's
interesting my staging works but of
course phasing works you never go to
production yeah you never go to
production without going through staging
right you go to stake in it works then
you go to production it doesn't work or
vice-versa somebody has a issue in
production but now I'm staging yeah this
is very obvious right now this actually
works so what's the difference between
the two but what do we have running in
stating this the same application of
course yeah so yeah so what we're going
to do like incriminate is right we're
checking all these declaration files
right I just showed you earlier like I
have this UI deployment yeah and at this
UI deployment and if I scroll down a
little bit I can see that I have two
instances I can also see what image I'm
running so if I go down here I have my
image right this is my configuration I
am running a hollow were you I lay test
so done is a docker image right yes and
you're running latest of course because
it's all about CI CD right continuous
delivery were deploying the latest all
the time now yeah but what what latest
is that is the latest
like an hour ago latest yesterday latest
a month ago
Cary's latest latest but no what are the
issues I mean you should be version in
your dokkan images right you should be
saying one two three I mean latest could
be anything
ladies could be I could be different my
machine and your machine remember that's
true yeah the latest on your machine
like if you view the app like two
minutes ago it could be the latest on
mine so there's no way for us to tell
then I guess the question is are we
running the same image on production
versus staging right you know tagging
your your docker containers is
definitely a must you definitely do not
want you to go with the latest so we can
actually check that very quickly so if I
go and you know get all the current
instances of my application here is the
hollow wall UI okay and what we can do
is you can do a describe on this thing
and when you describe any resource
increment Eddie's it's going to give you
all the latest details and so for
example in this case we can scroll up we
can see the environmental variable
that's being used to configure this
application instance but if I go up even
a little bit more there we go I see the
image ID okay so and you know here's a
hello world right and that's that's the
that's the latest version so we need to
remember the number yes and then compare
it with staging staging yeah that's easy
you got this cover right okay what's the
number
yeah you have the whole thing alright
okay I don't wanna do this you remember
the first four yep I remember the last
okay six to four everybody remembered
everybody pick a number and remember
what they sell all right so now we can
go to staging environment right so we
can say good pot and we can say let me
get a staging environment and I can do
the same thing and I can't do what is
right on this pot as well some God
describe and let me see if there are the
same thing so I'm pretty sure we deploy
the same thing so if I go up at sea yeah
I can see the configuration right that's
there and if I go up even more what was
yours again I don't remember
sorry 6 2 4 P right that's all right too
many digits here but yeah so they are
exactly the same application well no we
know is the same docker image yes yeah
but does it have the same thing behind
what does it have the same application
behind it what does he
what do what what is that behind that
docker image what do we have what God
kind of application web version of the
what is actually inside yeah well that's
easy for me to tell hey somebody
somebody said the cool guy nice that's
somebody in the room is saying good
stuff just make sure you say good things
so yeah so I can show you the doctor
thing that I created right so if I go to
my example Java here and if I go to my
UI application right and I got my docker
file and this is how I'm building my app
and oh look there this yeah that's my
app it snapshot ray what the heck dude I
mean what you used to be a crop
developer before when we worked for us
no then you went to developer you even
worse now now depending on when the
snapshot wait no wonder your application
doesn't work on your demo so I cannot do
the front-end and are you saying my
back-end is not doing well either that's
quite horrible yeah but what's the
problem with the Pena snapshots I mean
it's you never know what you're gonna
get right it could be any any jar files
yeah that's true but you know you are
going to run into issues like this
hopefully not in your company but when
you go to a new company might run into
issue like this right you just don't
know how operations are running and you
need tools to provide you some insight
so potentially some of the tools is you
have a really good CI CD pipeline you
could be using some kind of registry
that stores the metadata of how the
beaut came about so the things that we
have here is actually we we actually put
this image into artifactory so what I
means is we can describe the part right
and we should be able to get the hash
where's the hash there's there's the
hash and we have no idea what this hash
stands for and if you have a system that
can tell you and that keeps record like
in this case I'm going to use Brooks
repository here I'm going to log in oh
you know so I nobody reads my password
yeah oh there we go
anyone see it no good so we can actually
do a search and maybe we can find the
the checksum here so we can go to
checksum and they do we can see what
image is this oh there we go yeah this
is version 50 latest
version 50 okay versus 150 but that
still doesn't tell me anything
no what does he want no that's look
here's we got
27:31 what happened 28 I have no idea
but we got four feet that's the latest
one but 50 is deployed by mark ye-yeah
Marchi I'm not Maki you're not Marky I'm
not machi either is that somebody you
know who's Marky I have no idea
yeah well that's too bad but mark
created this image oh I know I've been
using it for a while - we trust mark too
- I trust mark right now that's my only
hope
yeah I I don't know I mean I have no
other things I can't deploy this is the
latest one okay I must be the good one
so let's let's take a look even more
like we can't actually potentially go in
if you have to make our data you could
you know potentially say what beauty
skin about so you can see the beauty a
point now in this case because we built
it from a CI CD server I believe was
marks a CI CD server but mark left the
company so yeah the CI CD server is not
there anymore
how typical yeah yeah often does that
happen with Jenkins Oh Hudson like it
becomes unavailable yeah or like you you
lost the configuration to deploy but
that's okay because the metadata is
still here
so you could actually go in and see the
modules in whatever its associated with
this file right but that's one way for
you to get that the key here is you need
a good way to keep track of your
metadata during your artifacts but I
think at this point gal drive I feel
like we have the right application I
mean it is the only version it is the
latest version and it's the same
versions on both environments so so you
know do we do well we have to arrow
maybe here
yeah maybe we can check locks that'll
show me the locks some psychological
step everybody wants to see a stack
trace
so in kubernetes that's also very easily
done so for example when you have the ID
to that instance which is we call the
pod right we can always do something
like cube CTO cube CTO logs - Jeff and I
can just give you the instance name and
then I can see the lock I can tell it
but now now this puppy happens for
everyone I got two instances
here right of course they only have two
instances what are the odds for me to
find this exception in my log
fifty-fifty you have to think that long
they're only to know and to think I'm
working all right got it
but but by incriminating environment or
in any micro service environment right
you don't just have two instances you
may have ten senses right if I scale
this up to things densities and guys
good the good part you know wow I have
so many then what are the odds are
finding the exception in the logs
fifty-fifty how well you either find it
or you don't find it right what yeah I
guess I guess yeah you either find
everything I guess they are independent
probability but I don't know but there's
something wrong there's something off
without Matt but but let you say we are
able to find a log I think yeah it
sounds good to you oh there we go I'm
very lucky today yeah there we go I have
to do log and and I can see all the
exceptions I'm telling it and yeah
that's not too bad but but I have ten
huh well but that's okay I guess yeah if
you don't find it right you have to go
find another one right that's okay are
you are you is this what you're going to
do in production I mean when I was in
support I normally had to kind of do
these in going to production systems
going to fetch the leo logs okay I had
to grab them I had to find them am I
gonna have to do the same thing again am
i back to ten years ago ten years ago
yeah well how many how big was your
concert well I used to have 20 30 no
clusters with logs from multiple days
and then I had to go into them had to
kind of go individually take them
download them okay I spent many hours
going through logs and your mic
spreading grip yeah yeah am I gonna have
to do that again I hope not how many
people hear you scrape to you see their
logs gonna see a show of hand you know
there are some people out there that's
doing it hopefully no one has to do this
but like incriminating there is a really
easy way for you to tell all of the
locks not just one there are some tool
right like one of them's called cube
tail so you can use cube tail to say
just give it the name of the application
and you can just tell the log and all
course if you're worth nothing there and
if i refresh if it works yeah wait why
what's going on here me you need to wait
a little bit yeah maybe I need to wait a
little bit other sales yeah oh there we
go oh my goodness oh so now I'm seeing
the logs it's the Wi-Fi that's killing
so well you can see now you see your
dogs so what you got now is logs with
colors yes but from all of the instances
right I can use another utility coaster
that's another really handy utility I
can use turn and I can tell the logs
this way to okay and and yeah I can't
just see all the logs right that would
help you to not having to ssh to other
machines to see what's going on yeah but
that's gonna work as long as you've got
one request per minute like that I mean
in any production system you're gonna
have a lot of customers a lot of users
the great heat in your application are
you going to see if you use the tale
approach you're just gonna get like and
then let's scroll an inland scroll of
logs Grove rocks yeah and it's not very
useful when you're in production
environment in this case right you're
absolutely right and that is why in
kubernetes there are a lot of
integrations with some centralized
loggers so for example you can set up a
elk stack like elasticsearch e and log
stash in Cabana and in different
communities clusters they have different
setup like openshift communities cluster
what did they use ALK as well
elasticsearch qivana and yeah and yeah
but so so you need to look into
integrating with some kind of
centralized logging with a centralized
logger all of the logs that you output
to STD out or SCT arrow will be captured
not just by community so you can inspect
it with cubes ETL logs but you can also
inspect it in the centralized logger as
well most what most of them are able to
pick it up directly from your output
stream so then I can run grep on those
then you don't want to run grip then you
go into the console thing you can do a
search right and and these logs it's
very important to remember do not write
the logs to the file system because the
file system in a container might
actually get filled up and if we don't
actually rotate the logs or if you don't
restore the container your file system
will get blown up so it's
very very important that you output the
log to the console and remove any file
system logs but if you do it this way
then you can use the centralized logger
so for example here in the kubernetes
cluster I provision in Google Cloud
right out of the box there is a
centralized logger basically you know
it's a logging tool right you can use
anything like I'm prayin in the cloud
they're a little bit different but like
here I can actually navigate into my
cluster I can see the namespaces I need
to look at right so rather than creating
the log you can't just run the log here
okay so let me close I don't need to
download them once I my logs out there I
don't need to download that I can well
yeah for them you can you can do a
search you can even narrow this down to
the application now you want for example
in most of the centralized locking tool
you can do this and this is far better
than what you have to do before right so
far so good
I preferred yeah but but but this is not
enough right I mean some cases even
though you're you have access to the log
you may want to analyze it a little bit
yeah I mean just being what you're doing
here is what you're showing me so far is
what I could do with grip right I could
take a look you could just grab through
a particular thing and I got all the
matches yes what what what's different
here well so one of the things that I
like to do when I was troubleshooting a
production system for a hotel company so
this is where you book your hotels I
remember they had like six ten servers
or something some big servers and
whenever something goes wrong in 2 a.m.
the morning the first thing I want to
determine is ok is the working staging
is it just production issue right we've
looked at the logs we try to look at the
logs we see the arrow and then I wonder
is this exception happening only on one
machine or is it happening on all of the
machines because the way I deal with it
could be different if I found all the
machines I know I screw up something
huge and you know I gotta fix it quickly
it found sound just one machine maybe
it's a new environment the issue or
something else then what do you do if
you just happen in one instance you kill
it
what we started you just restarted yeah
no no no no that's bad if you find
since as bad because it's 2 a.m. Swami
starting go back to sleep
well if it's a job application that's
quite common right you've got garbage
collection issues suddenly your JVM it's
not accessible what do you do but if you
don't figure out the core problem you're
going to see the same problem again like
a week later so you set the cron job how
many people here have cron jobs that
kills your jvn sigh this to be true oh
my god there's some people who are
raising their hands here
alright yeah but that's the problem if
you kill something you won't be able to
debug it anymore but so let's ask the
question first let's figure out let's
see it lets see it
not yet well we gotta find the who to
integrate first right so for example we
need to be able to extract more
information from the log so a lot of
people they dump the log into Hadoop or
something and then run a script or
MapReduce tree try to figure out these
answers it's no different here except
you can't get the answer potentially
much faster so from the login console
you might be able to dump the log to
somewhere else and then you can stream
it you can do real-time analysis on your
log messages or in my favorite is
actually this one potentially if you get
your log into a system like bigquery
then you can actually query the logs
with sequel whoa ok yeah so instead of
crap I use sequel yes yes but your Java
developer you know how to write sequel
right or just use hibernate I don't know
I use high mana that's a way to go but
then you have hql everybody knows how to
write sequel I hope I hope I hope
everyone here knows how to write sequel
right but if you don't is really easy to
learn so so here we can actually go to
the bakery console for example if we
have to log in a system like this then
what you can do is to ask interesting
questions so in this case we're not
using grep interrogate interrogate
asking questions nicely yeah we can ask
a nice question simple question of like
hey what are all the exceptions only
hallo Rui I want to count the number of
times it happened I want to know which
instance is happening and then I want to
group it by the name so I can sum it up
and want to order by to see if there's
just one instance that's having the
issue or multiple instances that has the
issue so I
Rhonda scurry oh look there's there's
definitely one instance that has more
issues than the other kill it no no no
no we're not killing anything here today
no no no I try not to at the very day if
we cannot kill it what about we put in
in isolation in isolation like to
interrogate it right stop just ask
questions ask questions yes but but what
I wanna isolate how do you wanna isolate
well I think normally what I would have
done in when we had a problematic
instance we were probably separated from
the traffic right so you want to keep it
running but we want to kind of make it
stop serving requests okay I mean that
way we can do fun things with you and
while the rest of the system works okay
how's that yeah so that sounds like it's
something that we can actually do so in
Crippen Eddie's the way that you set up
the load balancer is by specifying these
special labels that you can use to
determine what instances of the
application can route the traffic to so
in this case I have my load balancer set
up that Rosses traffic to holloway UI
but also with a special flight that like
I created myself code serving is equal
to true so what that means is all of
these running instances if I say get pod
if I see serving flag of the serving
label I can see that all of these
instances has this the the serving flag
to be set to true okay so I can isolate
one of these instance if I just set it
to false right so I can do something
like override the flag like that and let
me just label the pod so I know which
has the issue okay then I can write the
fly to say serving is false and what
that's going to do is to take this
instance off of the load balancer and
now you can you know try different
things with it but one that I can yeah
yeah but now you've got there's a new
instance here right yeah yeah so so what
is that I specify remember I scaled my
instances to ten and I took one of them
out of service so kubernetes is smart
enough to be able to create other
instance for you to take over so in this
case it
I remove one instance he added one
instance back and that's used to being
started for four seconds ago so that
means that if you say replicas equals
ten yeah I mean you one of the stop
serving yeah kubernetes is always going
to try to create enough instances that
I've node up but serving yeah right yeah
okay
yeah pretty much if it crashes we'll
restart it for you automatically like
when your GC has issues like rather than
writing a cron job what you do it for
you but don't depend on that right all
right so now we have this but if it
restarts it then you cannot interrogate
it anymore
exactly so now we have the instance
isolated right now we can do interesting
things like why would you want to what
questions would you want to ask in this
case like what is going on with this
application well we can maybe try to
access the UM that application in okay
okay maybe we can I think in communities
you can do this port forwarding thing
right oh you can forward one of the
ports
yeah yeah so we can actually if you want
to try to see if this particular
instance actually has the issue rather
than going through the load balancer
which we have no idea where it's going
to end up if you want to pinpoint a
single instance you can set up a pull
forward and what this will do is to set
up a local port and stos tunnel into the
system into your cluster if you have
access to do that and it's going to
listen on port 8081 right in this case
because I said 8081
and I can actually just go ahead and try
it out so I'm gonna say 80 81 and oh my
goodness what this actually works this
is actually oh whoa what drop table huh
cool who is that person
nice try nice try nice try so so this is
this is fine yeah but this this this is
quite confusing so you we've got the
main entry point
you're not working but I mean we hit the
particular instance it works yeah so in
case this instance is okay
well but that's can we can we do
something else I mean how is this all
interconnected I mean why is it
different
I get the feeling whenever we write in
this kind of mic
service architecture right there I'm
right it's quite complicated to know how
how the different parts
interconnect the load balancers because
if I'm hitting that note it works but if
I go through the load balancer it
doesn't work
yeah because because Michael services or
architecture can be complex you may have
multiple multiple services you're
serving well one could be calling
another of a sudden we have 10 100
services how would you know who is
calling what and in this case right we
can actually go and I got this great
console by the way this is open source
you can actually do this yourself and
you can clearly see right the hollower
UI is talking to you the guestbook
service ok also clearly see the holo Yui
is talking to Redis and so on and so
forth right I mean that this will help
you to debug it now but it's that you
are you showing me is this being updated
real life almost almost
so for example if I scale in the number
of deployments right right to 5 i watch
the show five instances here okay but
what if i add a new service if you add a
new service you have reroute your
requests so this lines one out you are
properly and that is because i
hard-coded them you hard-coded them yes
so for example in my deployment
I have little annotation here that this
specific visualizer talks to you and I
hard-coded which ones that they are
talking to you of course right just like
doing diagrams by hand this is like this
reminds me like when I when you have
situations where you've got these
documentation right where people have
written these nice diagrams at the start
of their productions in a system like
this yeah and then you suddenly go into
production you say you have to debug a
problem but someone comes a few hours
later and says you hate you know what
you're looking in there that's not how
it works
uh-huh yeah the documentation could be
outdated yeah it could be outdated and
you can spend hours like going through
information that doesn't match or
represent what is happening in real life
that's right yeah in this case
added a new service you wouldn't show up
because our jaco today is it's a piece
of our if you made a mistake for example
like yeah if I made a mistake then
that's not good enough so this is why in
a micro services the appointment you
need for observability and insight into
what it is that your services are doing
so I'll show you one of the tools that's
pretty cool to get a real-time view of
what's happening there's a little
utility you can still on the cluster
it's called we've let me see here where
is it we've we've we've yeah it's out
writing on for 80 80 40 40 so let me
just go find we've here no Google no now
there yeah but you can find 8 is it
every cool things we thought I oh is all
right no yeah it's very slow no not that
one
we've calm let me see why is the Wi-Fi
so slow here that no definitely not our
one no yes we've works it we've works
right we've worked so if you install
something like we've scoped what what
you can get is potentially a real-time
view into the networking of your of your
cluster so if this internet is any
faster this console will load and you
should actually show me all the existing
connections that I have from my servers
to other services and these network
connections are represented in real time
and so when there is a new connection
then they will go it's going to show it
eventually eventually if I have mine
what all right let me let me that
deafening crash let me try this again oh
there you go oh there we go
so you see here if i zoom in a little
bit I can see very clearly my hollow
will you eye is talking to you
Redis and it's talking to you hello a
service and if I do a refresh it still
doesn't work but you should see new
lines coming up there you go did you see
that that the new lodge is created yeah
yeah but the that's that's not gonna cut
it
why not because all these this is
showing you is showing you that hello
wall you I talked to her the wall
service yes yeah this is not what we
want to know no whatever you want what
about we use something like distributed
tracing here okay I'm designing what is
that the idea behind distributed tracing
is that we can
represents individual requests happening
within a system within a micro service
architecture okay and we can see
requests which requests are going
through which services how many times a
particular service calls another one
okay and then we can see things like
information like login or like
information about the particular service
and it for example we can see how many
times it goes right if you have an a
slow service we can see maybe we're
calling it too many times and how does
that work like 40 to be tracing to work
normally you there are tools like Zipkin
or with their open tracing as well that
allow you to distribute tracing to
production systems in ways in which you
don't impact performance which is very
important so like what they do is they
will attach like a request ID or a trace
ID if that one doesn't exist yet and
then when you make another call to
another micro service you'll hopefully
automatically attach those IDs to the
headers of the outgoing call and when
you have all of these different requests
that can be correlated by a single
request ID then you can go back and can
build an entire Coast ACK now the
multiple services right there's some
cool yeah user interfaces to do that as
well yeah do we have anything like that
yeah so you can use Zipkin Zipkin has a
nice console for you to do this type of
visualization of the co stack if you
don't want to host your own Zipkin right
the concept is very similar you can use
other components to same thing here like
on the cloud we have some hosted service
too that you can use so you don't have
to kind of worry about what is it how
much trace you need to collect so for
example with you should be tracing I can
click into any one of them oh wow this
is not a very efficient application is
it it's not see yeah so like here you
have the entry point and then you can
see exactly what's going on throughout
all of the services call so the home
page made the code to the guestbook
messages and our code other other things
and you can see that this is sequential
so it's not very efficient but I'm more
interested in the one I had issues I'm
going to find the one that has four
hundred four four oh four or five
hundred for a row
found real uh-huh so there we go so
these are the services call now has
found earlier so there we go so here's
the the thing that came in I can see
that there's the 100 arrow okay and I
can see that he made a ho - hello right
and and I can see that the hello service
returned very quickly and there is in
fact a 400 404 arrow that's caused by
one of the services okay okay
so that's not bad okay but so yeah so
now we need to so we need to look at the
logs now we can we do look at the looks
to see what what happened yeah so if you
tie everything up properly when you
click on the V lock in the system in the
right system it will actually give you a
correlation to the actual trace ID in
the log system and if you actually find
relevant logs in the system - and as you
can see we have no logs no okay no but
let's let's try this I'm gonna see if we
really don't have any logs so I can go
back to the system that we know we got
this no more grating right I can
actually go and see if we have an issue
here with hollow or service yeah I can
go see this and loading your logs
nothing Wow I have no I have no lock
whatsoever okay yeah so that's no good
that's so so we need more looks right
yeah so like during the production
troubleshooting it's usually we you know
checking environment we check for the
right versions we go through the stack
traces we try to figure out that
visibility into the cluster and then
finally when we have no other options we
need to see more logs we need to see
what's going on yeah but that's that's
gonna be quite a pain to deal with now
why it didn't add another log no yeah
but now you're having to okay you've got
your application you need to figure out
what's the source code for it okay you
have to go check it out okay add your
login message yes
compile it yes deploy it how long is it
going to take to deploy it well I don't
know about you but as you can see I
deployed the latest all the time so it
takes like 2 minutes ok what if you you
have like a very little window why are
you going to do
no that's true yeah so in some in many
of the customers I talk
the turnaround times maybe like an hour
under orders of hours right to deploy a
new thing into the system and if we
don't have the log that you're looking
for what do you do you go through the
same process again man that's gonna take
a while yeah it could be right so this
is where you do need this right CIC D
pipeline set up do not deploy the latest
but you want to know what versions are
being deployed but if you're out of
options and like in my hotel experience
you know the traffic comes in at 8:00
a.m. in the morning so if I have a
production issue at 2:00 a.m. I need to
deploy everything and fix those issue by
8:00 because otherwise we're looking at
the entire day of downtime right because
when all the traffic is coming in
there's no way for us to catch up and
serve everything or your job yeah yeah
yeah exactly so when you're out of
options this is the only thing that is
attached only that works on the clown
environment is code debugging so what we
can do is if you share the source code
either you upload that the version
that's right or if you're on github we
can synchronize the source code
automatically you can come to this
console yeah and you can find the right
version of the application this is done
automatically and if you want to have
more log message you just add more log
message so for example here I'm going to
add a new log for example here I'm gonna
say how do we debug with the log
messages in production environment you
say one one here is that how we do this
all the time right I said well I'm here
and maybe I want to know what the name
is so I add another one I say - I'm here
in this name just like that and then
finally finally I say three I'm here
right we do this all the time in our
logs and that's it yeah but how does
this work are you actually modifying the
source code no no so what happens behind
the scenes is that we are running a
agent as attached to your JVM so you can
configure this yourself
but once you configure the agent let me
see if I can find out a particular
example let me see here once you're
running the agent you just
- your GV startup coming online what we
can do is to just make a secure
connection to our debugging tool and
this is just intercepting the calls and
then we generate additional log messages
for you okay yeah yeah so for example if
I want to show you how this is done if I
see the docker file and here's the agent
that we're adding and not saying right
and we determine the name of the agent
and the kind of shows up now even though
we're running ten instances of this
service when you add this log message is
automatically propagated to all of the
logs all of the application instances
with a matching version this is quite
cool right so this is going to
incriminate this the way it works is you
you is gonna install it in one
application then another one no is it
going to deploy new pots or how doesn't
so no so there's no restart it just gets
applied and you just get to see or the
lock message so if I do a reload and if
I go to my log console and if I look
into here oh there we go
a lot of point I'm here there's no
restart there's no read appointment we
don't modify your code and it just works
and if we go down here more I can see
more of it right so it's pretty
straightforward
yeah so that's that's pretty cool but oh
there we go there's another log message
here and I'm here why is people just
hitting my service right now I think
it's getting very very popular or over
something like everyone is trying to do
this right but this will eventually
catch up right but what's more important
though is that if you still can't
determine what the issues are from the
logs wouldn't it be nice to be able to
debug your application in production ray
we cannot debug application server
just a touch with debugger no you can't
why what's the problem there well then
you if you're a touch a debugger then
you're gonna have to kind of press a
button not because he stops the world
yeah and I have to go through the steps
through all the code yeah that's great
as I kid I get to keep my job whenever
something slow I'm sure your bosses are
gonna be very happy now if you do that
no but wouldn't be nice there wouldn't
be nice to just go into your Patong
environment in
see the Cossack see everything that's
going on and we can't redo that with a
sim agent that you put onto your
application for example rather than
adding a log point you can just attach a
snapshot so what this will do is to say
okay
I wonder what's happening here I wonder
what is happening in this service right
here so I'm gonna add a snapshot here
okay so now if I go and make this call
refresh oh and if I come back to my
console right here oh did you see that
just it gets attached to every running
instance and now we can actually see
what's going on the name is empty name
is empty yeah the name is empty sure
somebody forgot to put the name in the
in the UI so then that's a user error
that is definitely a user error if the
name is empty
yeah if you're doing a hello one yeah
exactly who wouldn't put your name in
there user error
yeah but I guess I was the user wasn't I
yeah it was me it was it was my error
right so but to show you why this is
happening and this is uh I stumbled upon
it myself
in another presentation before and
somebody said I'll shoot your
application is not working that is
because if you look at the code and
again this is a bad stupid issue right
if I look at the code
here is where the name is being wrapped
right and the name is a session
attribute okay so if I make the first
code with the name of the name this kind
of gets to the holloa service and when
the hollower service doesn't get any
names in the parameter then a three
times four four so I guess that was the
problem
right yeah so long story short
right when you have a complicated micro
service appointment you really really
need some toolings to help you navigate
and solve these issues because sometimes
a simple issue like this could take a
long time to resolve right so for
example we want to quite a few different
tools here just remember you know like
there are tools within kubernetes itself
that can help you isolate your instances
and you know pull forward through a
specific instance to debug
there are ways for you to remove
instance from the running serving patch
and then there are other tools like
stirring and keep tail that can help you
to see what's going on right now or a
weave in weave scope and of course you
need tracing and right so microservices
architecture is not just about running
and deploying your application it's
about gaining insight into what is
actually happening okay and there are a
lot of things that we can do of course
and we have to lean from google cloud
and you know different unprimed
installation has the right tool in to
and you really just have to figure out
what is right for you in order to allow
yourself to not to get stuck in a
production environment production issue
for so long okay and yeah I think that's
all we have so far and if you have any
questions that feel free to reach out
reach out online and if you want to see
the source code and how everything is
running you can go to my github on
southern ISM slash spring boot Ducker
okay so without that said any questions
in the audience
are there any questions that you may
have no yeah well that's good that's
good some people always ask about the
debugger because they will be saying
well what on a second if you actually
said you know you wanna print the name
here you can actually add an expression
and this expression is going to go
together if you're on an object then the
question is what happens if this
expression modify the state of the code
right wouldn't that make everything so
much worse and it would definitely makes
everything so much worse right if you
are arbitrarily adding code into your
production system without going through
you know the proper kid repository then
you don't know what's happening but in
this case yeah but in this case we
actually detect whether the getters
actually modify the state of your
application and if it does we will just
fail this call and just never allow it
to be called at all okay I have a
question yeah what if you make a
compilation or order what if you add in
your long message you yeah you you make
a code to a non existing variable
lock point here doesn't have like a
semicolon at the end oh you don't need
it you don't need it right this is this
Ruby no no no Ruby no but but the
templating engine allows you to have
this kind of template with the variables
right but however if you've referred to
a non-existing variable then we will
fail the call this will not kill your
production system yeah well okay
that's that's at least something to be
thankful yeah I don't want to be an
Amana this otherwise feels like PHP
right well not quite not quite this is a
much much better I think yeah so without
I said if there are no questions oh
there's one yeah go ahead
uh-huh just a question about the
breaking point yeah the breaking point
is not really breaking the application
but is spread to every every instance is
correct of our cloud correct how what's
happening behind the scenes right so
what's happening behind the scenes is
that this this is not a breaking point
we call it a snapshot well because we
don't and we don't stop your your code
we don't stop the world you don't have
to step through but as the code is going
through this and when the agent
intercepts this what is going to do is
to capture the co stack right and
therefore this back to the central
console so it's out being down
transparently and then it gets forwarded
here then you can see what's happening
for that particular line of code for
that particular request so you can
actually begin into all of these things
one by one and you can see all the
details now however if you are trying to
isolate a problem if you have a thousand
QPS flowing through your system the
first one is going to hit this snapshot
point right the first one everybody's
going to get their logs you may just end
up with more and more logs so that's why
we actually have a way for you to add
conditionals so you can actually isolate
this if you know a request ID
or something in the the request in in
the scope that you can access like in
the in the code you can actually write
an expression to say do this only if the
request ID is equal to something or only
if certain conditions aren't true then
you can really debug this in production
environment trying to extract data from
it before you actually try to reproduce
it in your developer system right this
feels very similar to what you get like
in other IDs right yeah like a clips or
IntelliJ yeah yeah in fact you can
actually run the plug-in in IntelliJ so
we have a plug in IntelliJ if you have
the right permission you can attach the
same debugger and you can do this in
real time against the system that you
have access to right so like a lot of
the times is that you cannot reboot you
cannot reproduce on your staging
environment you don't even know why this
is happening that you really need to go
to production and just take a look yep
we have one more question okay go ahead
do you support languages yep so there
are some support so I don't recall what
the latest set is someone's gonna look
it up oh I don't want it like that first
one nevermind yeah I don't know what
that was alright so here's the debugger
oh there we go so we have Java Java and
Python pretty much in production
partially because we're on the same
debugger practically the same debugger
in production Google code so some people
ask that how much how much overhead are
we adding it's nominal where we actually
run the same production today ourselves
but here are the other ones that we can
support go node and Ruby and PHP oh so
you don't have to write a console
dialogue anymore in JavaScript
potentially yeah right okay
any other questions no no yes one more
last one okay
so my question would be how much of this
is depending on the Google cloud and how
much is only kubernetes Pacific and we
could just run it on any kubernetes
cluster for debugging specifically or
for other things in particular yeah yeah
so on Google cloud everything is based
on the API so you can actually run a
debugger agent in your application
outside of Google cloud that is not a
problem at all the only thing is they do
have to be able to connect to our server
in order for you to use this console or
to be able to propagate the information
so so it's just this you need a
networking port open to be able to
connect to us and then you're okay
similarly like with like trace and
everything else you can always run a
open source alternative right like ELQ
stack or Zipkin right and a few other
things yeah if you write an open ship
for example there is integrations with
open tracing and there are open to
integrations with elasticsearch as well
for for log aggregation as well so a lot
of the parallel features are also
available for open suffuses which is
very interesting for on premise but
because it is API driven so you can
actually send traces to here to if you
want to buy this now current it's now
like necessary you can always host your
own if you need to but if you need a
host it like completely hosted solution
you can always use these solutions
separately that's not a problem at all
okay cool well I guess that's that's it
right I mean anything else Andre no all
right well thank you everyone for
staying for the last session I really
appreciate it thank you thank you thank
you right on calendar and so as you know
there there is a welcoming party in
downstairs there's some beer there's
some apple don't forget to vote when you
live in the the room please ray ungodly
would appreciate your feedback and
thanks for joining box does uruk's again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>