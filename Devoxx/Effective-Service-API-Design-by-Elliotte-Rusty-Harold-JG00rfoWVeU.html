<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Effective Service API Design by Elliotte Rusty Harold | Coder Coacher - Coaching Coders</title><meta content="Effective Service API Design by Elliotte Rusty Harold - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Effective Service API Design by Elliotte Rusty Harold</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JG00rfoWVeU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to day four day two depending on
when you showed up of devoxx this is
effective service API design
I am Elliott rusty Harold and glad to
see everybody this morning at 9:30 and
there we go so why is this topic of
interest to me currently I'm tech lead
of cloud tools for eclipse at Google
which we'll be talking about more this
afternoon but before I did that going
back about eight years now my very first
product at Google was what is now called
the analytics reporting API which was a
as they'd say the word web service but
it was an HTTP endpoint to which you
could send requests using Java
JavaScript or any form of HTTP library
and received back XML that contains your
Google Analytics data from your own
websites in your own accounts and you
could organize it you could use query
strings to pull out different you know
subsets of your data because most of us
have huge amounts of Analytics data and
you don't want to get that all at once
that's a subject we'll talk about this
particular product was incredibly
successful way more successful than any
of us on the team that had any idea in
terms of how many people are going to
use this how much data we were going to
have to transfer it was one of those
products that sort of came out of
nowhere and in terms of usage just
skyrocketed once we launched it way past
anything we had planned for expected so
I sort of said you know this is
interesting um we should pay more
attention to these sorts of things I
will say I haven't been on that team for
several years now they are now on
version 4 so various people including
Jitendra Soneji
multiple other engineers have you know
been continuing that project for the
quite a while now
and it looks a lot different now than it
did then for instance now the data you
get out as JSON not xml that's a common
feature of a lot of modern api's in 2016
less common back in 2008-2009 when we
launched it a little later on my next
project
I call it redacted here it's nothing
super-secret it's just an internal
corporate application at Google for
managing internal you know business
things and people management what not
nothing we publish nothing we really
talk about but it was something that was
useful to expose the information in our
local databases to other companies other
projects other teams around the company
working with that same data and the way
we did that is we built an API for it
you know in this case this was based on
JSON it was based on some newer
technology that was not available when I
first did the analytics reporting API
and that moved along I have also been on
the other side of the API fence on many
different projects where I've consumed
api's are published by other teams other
companies other projects currently I'm
working with various Google cloud
platform API s for managing Google cloud
platform projects because in the Eclipse
plugin for working with Google cloud
stuff we'd like to enable you to do
things like create a new Google cloud
project get a project ID you know create
a new database etc all from inside
eclipse this isn't there yet don't go
looking for today look for it next year
but that's the sort of thing I'm
thinking about right now so what do I
mean when I say an API technically the
acronym expands application programming
interface it is a we've had these
depending on what you mean by exactly
we'll get into that for at least 50 or
60 years it's a means by which your code
invokes functionality provided by other
code probably written by other people
other teams other projects other
companies and okay those last two points
sure
be there so here's one example of an API
I'm sure many of us have seen this is
part of the JDBC API that's part of the
standard JDK you know as seen in the API
documentation or Java doc this is the
java dot sequel package lists all the
classes or at least all the public
classes and then if you drill down into
it you get all the various public
methods your own code can invoke you
don't see everything it's deliberately
like an iceberg it's showing you about
10% and hiding all the implementation
details under this interface and that's
very important some classes this will be
true more in Java 9 make a bigger
distinction between public and published
api's things that are not necessarily
public or that our public may not be
published it may not be available to use
but that's not too incredibly important
for our talk today or in current work
that however is an example of a local
library API not a remote API not a
service API the difference is critical
to understand if you're developing one
you're not trying to develop the other
and if you try and apply the lessons
you've learned explicitly or implicitly
about developing local library API such
as JDBC or math dot agency or Microsoft
foundation classes we still use that
probably not in the dotnet world but
it's been so long since I did Windows I
don't know you know those are local
services running on a single computer
you know possibly replicate it across
many that's not a remote API that's not
a service API and if you try and make
your service api's look exactly like
local api's you're going to get into
trouble so what is a smote api or
service api i really want to try and use
the two words they're together rather
than just api because the single word
just gets too confusing it is a network
service almost always not quite always a
server by which programs communicate
with a bundle of functional
provided by code owned by someone else
running on their computer not yours
q Richard Stallman here this is
something you do need to consider when
you're accessing API that you're tying
your program pretty tightly to a service
that may go away for any number of
reasons
yeah no number of developers who built
products around the Twitter API for
example have had some problems as
Twitter's business model has changed as
they have changed the rules around what
you can and cannot do with the feed that
they provide what they do and do not
provide etc how much of it you can use
so you're it's you know you're putting
some extra risk by using these things
even if you're using an API purely
within your company provided by one team
what happened you know to your own team
what happens if that team gets D staffed
do you have to take control the API
yourself you know can you do that these
are things to consider most importantly
I want to drill down into the I in API
because that that's stands for interface
and an interface for our purposes is an
additional layer of indirection it hides
everything behind it
so that the client and the consumer of
the API do not need to know is it a
sequel database on the backend is it a
no sequel database is it load-balanced
does it not load-balanced you know what
is the data format things are stored in
etc all the clients should care about is
the published advertised API and the
rest of it is just hidden that's really
really important now in practice you
know that's sort of general this can
change today in 2016 more often than not
it's going to be HTTP or better yet HTTP
we should all be using SSL and I know
that I personally am NOT on some of my
websites and I really need to fix that
but
for API certainly its uses as arguments
as input URL paths query strings name
value pairs or or and or I should say
JSON usually you can send other formats
but that's more often than not what we
have and the responses usually come back
in JSON most likely XML is still out
there and still possible works better
for some use cases and then in certain
special cases you may have JPEGs PDFs
you know some other sort of weird binary
format but that's commonly how it works
now differences between local library
api's and remote service api's you need
to keep in mind big nut they're not not
everything is different about them but
these really are number one service
api's are fundamentally unreliable just
like any network program just like any
form of distributed computing if you've
ever encountered peter deutsches eight
fallacies of distributed computing they
all apply here you know the network is
not homogeneous the network is not
reliable etc unreliable networks fail
you know the you've just may not be able
to connect to the service when you need
to for any number of reasons such as
you're at a conference you're on a Wi-Fi
connection and the Wi-Fi goes down
that's not going to happen if all the
code is running on your laptop the
server may crash the server may go down
the server may not be there this happens
it may be overloaded it may be slow to
respond that happens so you need to
worry about it the vendor may decide to
change the API and then you have to
update your code to match now if you
have a local library and sun decides or
let's say more likely J unit decides to
change the signatures of some of the
methods in the J unit jar file well you
can still use the old jar file
have to upgrade until you're ready by
contrast if google deprecates version
one of the analytics reporting API and
says now you should be on version two of
the analytics reporting API and now
instead of XML you're gonna be getting
JSON back well suddenly you've got a lot
of work to do and that and how much work
you have to do may depend on you know
their schedule not yours
how much announcement do you get this
actually happened to the Google Eclipse
plug-in a couple of months back we when
we release version 39.5 the only reason
that went out when it did was because
one of the other teams at Google came to
us and said oh you know this API you've
been depending on for the last four
years we're turning it off and at the
end of the year so you better migrate
now and suddenly we had to do a new
version and a new release of a product
that we weren't actually planning to do
another release of ever so that and that
was all with api's inside one company so
that's something to consider if your
code depends on somebody else's API you
need to maintain it you need to be ready
for these sorts of changes or
you're using a vendor they go out of
business or they just decide the API is
no longer part of their business model
they're turning it off it isn't there
anymore you can't use it what do you do
then
it's a risk service api's tend to be
slower than local API simply because of
network round-trip time as well as
having to execute across multiple
computers better ones are faster but
it's never going to be as fast as the
same algorithm well I shouldn't say that
I mean maybe in certain special cases
like tensorflow or something where the
API itself is pulling together the power
of you know thousands of computers and
data center maybe then it'll be faster
most of the time though it's not doing
anything that complicated and it doesn't
work as quickly as your local stuff if
your API becomes part of an interactive
application ie there's a user sitting
there waiting for things to happen and
pressing buttons
then you're probably going to want to
invoke it asynchronously and wait for
the response to come back because even
if it's fast most of the time it's not
going to give you the sub-second
response time you want all of these are
not really considerations if all you're
doing is adding a jar file or DLL to
your project few examples of remote
service API is I've already mentioned
the Google Analytics reporting API
certainly I know the Google API is
better just because that's where I live
but you know Microsoft has many the
outlook REST API is an interesting one
for reading your Outlook mail Amazon
seller accounts many many different API
s for managing which products you
putting up for sale how things are
selling adding new products removing
them changing prices etc twitter has
api's that are probably not as public as
I would like you have to sort of sign up
for them and get approval and have you
know the appropriate developer keys and
so forth but they're there IBM I heard a
couple of days ago talking about some of
their Watson API so speech recognition
and other products in many cases when
you have services running in your cloud
like Watson like tensorflow like Amazon
seller accounts there many AWS api's as
well you know and you want to expose
them this is simply the easiest way to
do it to let the world in and get some
control over who's using it so let's say
you've decided to write a service API so
what comes next what are the design
considerations I'm going to talk now
mostly from the perspective of an
implementer of an API rather than a
consumer of an API this is my single
biggest takeaway of this session so if
you want to pull out your phone and take
a picture of one slide this is the one
start with the documentation another way
to think about it start with the design
think about what your API looks like do
this before you worry about the
implementation you may already have a
back-end service that you're exposing
for instance in the case of Google
Analytics we had
huge amounts of analytics reporting data
in a data warehouse you know custom
built at Google I don't want to tell you
how big it is but it's pretty damn big
and we were not going to expose all that
or necessarily in that format the
question is not what data do you have or
what services do you have it's what does
the client want to do so first think
about the operations that client needs
and then set up your endpoints that are
going to support those operations then
figure out how you're going to say okay
well we've said this is what the API
looks like now how do we connect it to
our back-end what does that look like
assume there's gonna be some custom code
in the middle I would particularly avoid
the anti-pattern which is all too common
of and I've seen it in more than just
the API space I've seen in the database
space and XML and a variety of other
things of some sort of data binding
approach where you say well we have all
these classes already and let's sprinkle
a few annotations through them or run
some reflection code to just turn it
into an API automatically I think this
requires some human intelligence and
some human thought you can use those
tools if first you know what your API
looks like but don't start with them
start assuming you're using HTTP you
know not there are some other things out
there like message buses for example
things like pub/sub and ActiveMQ but I'm
going to assume for the right now it's
more often not HTTP what are your URL
paths what are the query strings look
like what are the name value formats
what are the responses begin with your
sample requests what does somebody want
to send for example for Google Analytics
maybe a very simple request would be
give me the hit count for you know this
URL on my website or give me a list of
all the pages on my website I'll you
know match to the number of hits on that
page on a certain date think about the
queries the client is going to want to
make
and then how can you reasonably
incorporate those queries into ideally
the URL itself possibly including the
query string component if it's really
complicated sometimes
then maybe you talk about request bodies
and maybe you talk about a JSON format
if you need to I wouldn't start there
but sometimes that's useful even more
complicated maybe you talk about exes
sending XML special use cases maybe even
you send binary data mostly though URLs
work here but most but where there's
URLs are JSON or binary focus on the
requests and the responses the client
needs first even though you're
implementing the server you know try and
think like the client things try and
think like what they're going to want to
do if we're doing a traditional library
of local code and you write your code
test first then you're gonna start by
writing your API because that's what
your tests are calling we aren't writing
necessarily tests first here maybe
there's way to do it I haven't figured
it out if there is but it's the same
sort of general principle start from the
outside and work your way in rather than
starting with the implementation on the
inside and working your way out that's
gonna give you in the end a much more
usable API that clients gonna like a lot
better it may also be safer to and there
are some security implications people
often if they just try and expose their
data model they expose too much they'd
suppose more than it's needed and then
they have to have complicated white
listing and black listing schemes if you
only ever build what you actually want
to expose it's like automatic white
listings do not start with a schema I
would say think again think about the
requests in the responses schemas can be
useful for documentation and whatever a
schema language is appropriate but I
would begin don't start there start with
the use cases if you're going to write
client library code being in Java
c-sharp Python whatever or back-end
model code that's later first start with
the interface the interface usually is
HTTP I already said don't try to
auto-generate an API so that's my
biggest recommendation for this whatever
language you're using whatever tools
you're using now what do you put in the
API I'm a big fan of the Minimum Viable
Product start small and grow in the case
of that API for the corporate internal
application we started with a read-only
approach to one table essentially we
said well there's this data in this
table and that's the data we want to
expose that's what other people need now
once that was done once that was out
that actually solved a lot of the use
cases other teams in the company had you
know that was all the need not
everybody's use case not every team's
use case but some of them and then we
could say okay we've got Table one done
now let's do table two now let's do
table three now let's think about how
we're going to go from read-only to also
allow people to write which is a huge
step which is why recommend starting
with read-only first because it's
simpler it often has weaker
authentication and authorization
requirements sometimes in our case there
were rules that were not implicit in the
database in terms of how the different
tables and fields had to line up you
know if you had this record in table a
you had to have that record in table B
but you couldn't just work the tables
did not maintain that constraint the
application code needed to do it so that
was tricky
again read-only is a really good first
step you can push your API out there you
can get feedback the beta version of the
analytics reporting API the very first
one we did we pushed it out there it was
useful and we immediately saw we'd done
it wrong I mean it was pretty clear from
and in our case we were exposing certain
particular reports similar to the ones
you could get by logging into the
analytics website and looking at the
standard web user interface and we said
you know that's not what people really
need they need a lot more customization
and that was very clear as soon as we
had launched so we went back to the
drawing board and we did a much more
general-purpose API but we wouldn't have
known
that if we had it launched early with
only a few of the reports we initially
planned if we had instead said okay
we're going to take two years to write
all the reports we think we need and
then launch and then find out we're
building the wrong product well that's
two years of extra wasted time so get
get as little as you can out there as
fast as you can see if people like it
see if the people you want to use it or
using it collect the feedback and again
read only is a very good first step
often third point
yeah Guinea who knows what yeah Guinea
means see a lot of hands going up you
ain't gonna need it this is another
reason to start small and grow if you
aren't sure if you're gonna need a
particular you know piece of data in
your API don't put it there if you
aren't sure you're going to need
pagination well maybe you know you need
pagination but if you don't know you
need pagination don't add it yet it is
always easier to add things to your API
later than to remove them certainly
anyone who's ever worked in Java knows
this how much deprecated stuff is there
in Java eight now that just sort of gets
in our way and that still hasn't been
taken out I'm hearing rumors maybe in
Java nine they're finally going to
actually start removing some of the
things that were deprecated in Java 1.0
point two who here remembers Java 1.0
point two few hands 1.0 1.0 beta one Wow
am I the last hand up I think I started
with 1.0 alpha 3 if I'm not mistaken
maybe alpha 2 was one of those but
whatever you're doing in an API people
are depending on it it is much easier to
add things that are missing later than
it is to remove things you don't want so
again start small leave things out
general design considerations this is
sort of assuming HTTP here but that's
probably where we are
aim for single request single response
no side effects no ordering of calls you
can't always get this depending on what
your API is doing if it's read-only it's
pretty easy to do this once you have
right api's once you have api's feeding
data and ok it's still pretty easy to do
this if you have api's that actually
commit to things purchasing
manufacturing it gets harder but if you
think about this up front it's more
often than not possible the big fancy
word for this is it impotent which just
means that if you send the same request
twice you get the same answer twice it's
the same as sending it once that helps a
lot with retries and failure modes this
is something clients are going to need
to do a lot they're going to send a
request and the request times out or
they don't get a response back so they
send it again meanwhile the first
requests especially they're sending
asynchronously finally comes back now
they've got two responses what do you do
your server-side API should be resistant
to this it should be perfectly okay if
somebody gets the same data three times
in a row or two sends you the same
record several times in a row generally
focus on the nouns think about your API
is an interface the things not actions
may or may not be true you know there
are certainly api's that can do things
that amount to actions you know make a
product place an order but even that it
would be more like create an order focus
on the order itself rather than the act
of creation within HTTP assuming that's
what you're using assuming you're not
using something like pub/sub stick to
your standard events get put post delete
I'm not going to go into them in detail
plenty of other you know talks about
that they're fairly well known at this
point if you are careful and design
upfront and think about your API in
these terms you can usually get away
with only these four the tough one is
sort of some sort of patch or merge
opera
raishin sometimes that comes up when you
want to update pieces of an object even
there more often than not I find if you
find yourself needing that means you
haven't designed your URLs properly now
one tip is you can have URLs both for
things and parts of things so if you
have a person record the person record
may have name social security number
address etc but the name of the person
can have its own URL and the address of
the person can have its own URL and the
social security number the person can
have its own URL and you can use those
also there's no rule that says each
resource or each thing in your system
has to have exactly one URL or that you
can't have sub resources that somehow
belong to another resource so try and
stick to your standard verbs were
possible this will make it a lot easier
to implement on top of existing tools it
will make it a lot easier to handle load
balancing and other nice features of the
web will give you a lot of benefits of
HTTP so try and avoid custom verbs if
you can let's see now
as part of the URLs one way of thinking
about them as endpoints be liberal in
your use of URL paths I often see people
struggling to do things in query strings
that become almost obvious if you use
more the path component of the URL try
and avoid having a single path such as
slash call API or slash soap where you
know all calls go through it's easier to
split up a server that handles API calls
across different machines if you need to
if different API calls different herb
map to different paths that's just how
our infrastructure seems to work these
days every resource is going to have at
least one URL that independently
identifies the resource not necessarily
only one but at least one the resource
of a URL is fixed and never changes if
the URL changes that mean
you've got a new resource what is a
resource that's what do you RL
identifies what does URL identify a
resource bit of a catch-22 there but
that is how it's defined so try and keep
your URLs consistent the next point is
officially against the rules but I like
it anyway if you have meaningful names
in your path components you know human
readable strings in English or whatever
language it makes development easier it
makes clients happier even if
technically URLs are supposed to be
opaque strings it's just easier to work
with if you use the meaningful path
components now that's the URL the next
piece is the data formats this is part
of your API also something we don't
think about in a normal library API
which all just instance strings and
objects and their data types everywhere
and it's all just passed back and forth
on the stack or the heap sort of by
magic we don't have to think about it
when you're doing this remote API a
service API you do have to think about
it this can be the data format for the
client to the server the request or the
server back to the client the response
for server to client generally JSON is
good it's simple it's easy to process
there are a lot of libraries there are
some rough edges where the spec isn't
actually defined very well but you can
usually work around that as long as you
don't push the boundary conditions
deliberately as long as you specify that
yeah we're going to send all our data
and utf-8 for example if you need
something a little better defined or
something that supports somewhat more
complex use cases xml works very well in
special purposes for instance you're
returning photographs or etickets for an
airplane a JPEG a PDF some other binary
format usually I prefer text formats
again unless it's something like audio
video photograph for everything else
text is just fine you know whether it's
JSON or XML or something else all text
should be in utf-8 in 2016 there's
little reason to use any other encoding
certainly not for an API that's new that
doesn't have legacy issues to deal with
so utf-8 please the storage format is
not the exchange format whatever you're
storing just because you're storing data
in JSON or XML or sequel database that
or protobufs that's another example
comes up a lot at Google not so much
outside of Google that doesn't mean
that's what you have to send to clients
that was actually a big decision we made
back in the analytics reporting API use
days one possibility was well let's just
send everybody protobufs problem was in
2008 even less so than today
no one outside Google knew what a
protobuf was so we sent him XML instead
even though internally guess what our
data was all protobufs we just
translated it before we sent it in
general this is important this is often
our data format should rule things in
not rule them out they should say this
is what you can expect in a response not
there will be nothing else in the
response you need to allow for future
extensibility along these lines schemas
be they for xml or json or databases
they should be documentation not part of
your processing chain if you build them
in you make it inflexible you make your
system slow allow optional data this is
something it took Google I don't know
how long 15 years to learn maybe but in
the latest style guide for protobufs in
proto 3 we say very strongly
don't make any fields required ever just
don't do it it's still possible but we
really strongly recommend you not do it
this is what we're saying to ourselves
internally because sooner or later that
required field there's going to be a
reason not to have it it just makes life
too difficult going forward so don't
make anything required try to make
everything optional to the extent
possible
generally speaking API said it's all
text everything's a string if you're
going to have things like dates in your
API then use an ISO standard date format
if for instance for just a day that
would be something like 20
sixteen - eleven - ten-year first then
month then day that's the ISO format you
know ditto there are formats or times
use them their libraries to process
these things in pretty much any standard
language so it just makes life easier
for everybody
numbers are trickier I could give
probably a three-hour tutorial on number
processing with floating-point numbers
and decimals and so forth but I'll spare
you I would say integers and be really
careful about specifying what ranges
people can expect in particular if
you're promising the Ninian tis always
going to come in in the range of a
32-bit signed int say so if it's your
not promising that say that too
similarly for real numbers I would say
just assume a decimal representation and
do use those words decimal not
floating-point number if it's scientific
data then you want to specify the
precision some other things for most
other purposes you don't need that for
money for instance two significant
digits is almost always exactly what you
want try not to use the words double or
float in your API because you're not
actually sending doubles or floats and
the processing of those things is really
really wonky if you dig into it that's a
subject for another day so there's
standard decimals okay I think that's
what I want to say there so that's your
data formats now something else very
important for the people going to
consume your API is how much can they
trust you
what do you promise them this isn't just
about this is what my response format
looks like and this is the name value
pairs that you send me but you know
what's the service of agreement is this
API going to go down can you take it
down for maintenance you know how what
is how much response time can they
expect is this gonna respond within a
minute is it gonna respond within a
second is it going to respond within an
hour that may depend on what it's doing
if you've got some really complicated
speech recognition thing like Watson
it's doing offline maybe that takes
hours or maybe you want real-time you
don't want to use that if you've got
real-time responses because you've got
somebody on the phone and you're trying
to recognize their speech and your
automated call response system then you
need an API that promises will get your
answer back within you know five seconds
or less or one second or less ideally
even more important than the response
time
what's the deprecation policy if the
vendor of the API decides to change it
and they do all the time we do everybody
does it's just part of software
development are they gonna keep the old
API around until you get around to
upgrading how much notice will you get
three months notice is not very much
especially if you're the team that's
working on your product that consumes
this API has been D staffed two years
notice is good I have seen companies
advertise two-year deprecation promises
though they don't always keep them so
that's something you absolutely want to
know before you commit your product to
someone else's API what are they
promising how much notice will you get
what if they're going to change the
billing of it usually prices go down not
always I I'm not talking much about
billing in this I don't have a huge
amount of experience with that but it is
something to be concerned what does the
API cost and can the cost change and how
much notice will you get if the cost
does change that's important generally
speaking as a developer of an API not
only do you need to define your
deprecation schedule and get management
to sign off on it up the chains they
know they're gonna have to support this
for a while
plan for versioning be ready if you're
going to have version 2 of the API in
version one of the API working at the
same time think about that up front
assume you will need to have multiple
variants in production at once if you do
not have schemas if you do have optional
fields this is easier because you can
just throw extra data into your existing
responses you don't
have to publish a completely new variant
of the API and then finally another very
important issue for clients and
consumers
what's the lock-in can will some other
company some other vendor implement the
same API if I decide that you know the
IBM billing for the Watson speech
recognition API is to ownerís for
whatever reason I don't know if it is I
haven't looked at it myself I'm just
throwing that as an example then you
know can I take my code and point into
someone else's server that is offering
the same service at a cheaper price or
just if a cheaper can a cheaper product
come along without requiring me to
rewrite my code that's a very good
question to ask and it's not one I see a
lot of API vendors answering upfront or
even necessarily thinking about before
they launch but it's also good for your
own market envy and say yeah you're not
locked into our product we have to give
you a good product and you have to use
it because you like it and because we do
it better than anyone else not because
there are no alternatives you know it's
the same value proposition of open
source it makes customers feel a lot
more comfortable depending on you when
they know there are alternatives
sometimes in government prospects this
is a requirement okay
next point next subject client libraries
up till now I focus I've said well
there's HTTP or maybe pub/sub they own
their clients connecting to it we can
connect HTTP in anything and Python Java
c-sharp etc Swift but it is often useful
and helpful to provide a classic API ie
an installed library a local bundle of
code that runs on people's own laptops
or servers that talks to your system
that abstracts away some of the details
of the HTTP communication the response
processing your parsing the JSON or the
XML and the authentication authorization
especially because that's really
complicated and I'll get to that next
this is useful it is not required do not
assume that the people consuming your
API will only use your client libraries
to access this service this is actually
a mistake we made on v1 of the analytics
reporting API we sort of had in the back
of our heads yeah you know we're gonna
support you know Java developers and
JavaScript developers and they're all
going to use our client to talk to our
API and we made some decisions in terms
of you know what we did and did not do
based on the assumption they would use
our libraries well what about Perl
what about Python I think we planned on
Python support that we didn't get there
why was on the team what about go which
didn't exist at the time or c-sharp etc
I think we planned on c-sharp again took
us a while so provide client libraries
to help your customers don't require
them don't assume they will be used
don't assume only the client libraries
you write will be used if you have a
very successful API other independent
developers will also write then publish
their own client libraries your API
doesn't happen a lot but it does for
some of the most popular for instance
some of the Amazon Web service api's
there are four different client
libraries to access those things
none of them official none of them
published by Amazon and you can find
these on github so provide them but it's
a separate effort it's not required it
does not hide the fundamental
unreliability of a network connection so
even if it looks like you're calling
local code because you've got a local
client library it's still going out over
the network it still has to deal with
timeouts with server failures with
disconnects etc still probably gonna
have a lot of a synchronicity built into
it and then the final point when you're
building a client library this is
something we sort of learned at Google
handcrafted is better than
auto-generated we don't really publish
our own tools and libraries for building
these sorts of api's but we're currently
on I believe by my count our
worth major complete different way of
doing this since 2008 and the first
three all were sort of Auto generated
based on protobufs are based on code and
the four the fourth one there to say and
nope
write it by hand with some tools with
some support with some help but write it
by hand think about it you just get a
better same reason you design your
remote API by hand because it's better
same reason you design your local
library API by hand because you'll get a
much better more effective API decouple
the API from the client do not as I
already said this do not assume only the
client you wrote will consume your API
not even if you don't publish your API
people sometimes find it servers in
general should assume nothing about the
client AG don't check prefer headers for
example don't assume it this is a
mistake we make inside Google a lot we
say well it's always going to be Chrome
because inside we use the Chrome browser
well no actually people do hit our
internal services other Googlers talking
to purely internal things that have no
interest to the outside world like how
do you schedule a vacation will come in
and use Firefox or Safari or Safari on
their iPhone so you try not to assume
anything about the client it's just HTTP
it's just standard stuff okay
authentication and authorization this is
the single hardest part in my experience
of designing a web API there's anything
other than read-only and open to the
entire public and anybody can grab as
much as they like which is rarely what
you want because even if you don't even
if the data is open to the world there's
still do s issues to concern yourself
with quick review authentication who are
you who's calling the service
authorization what can this
authenticated person do or what can this
all unauthenticated person we don't know
who they are do what resources are they
allowed to have access to and what
operations can they perform on these
resources
two separate questions and then the
third question this is the one that has
got to draw more than any other
authentication is not what resource you
want authorization is not what resource
you want that's in the URL people get
this wrong on the web all the time an
example would be almost any email
provider you look at where it will be
WWE example.com slash mailbox and that
gives you a completely different data
depending on whether you're logged in as
food example.com or barred example.com
that's not right which resource you're
going to which data you're getting
should be purely defined by your URLs
never by your authorization your
authentication if you I should be able
to have a URL that points to your
mailbox that doesn't mean I can see your
mailbox if I'm not authorized to do so
and that has a lot of implications it is
true on the web and violating it on the
way up all the time to bad effect it is
triply true when you're working with
api's do not confuse confuse the
authorization authentication with the
resource there are a number of different
ways to do this if you don't need to
factor authentication of some kind basic
over HTTP still works twenty years into
the web 25 years in how long has it been
I'm not sure but that's still pretty
good actually
if you need something beyond that you
for instance you need to factor
authentication which for many
applications is a really good idea these
days try to piggyback on existing login
systems if you can rather than roll in
your own because they're really
complicated they're really hard to get
right be that Google Facebook Twitter
whatever
try not to re-implement this if you can
possibly avoid it if you have to
yeah and use existing libraries to
handle this because it's really complex
three-legged OAuth open ID JSON web
tokens we've had several talks of
this week these all solve slightly
different problems use them if they
solve your problem use the existing
libraries don't try and implement this
yourself that way madness lies do not
ask for more permissions than you need
especially if you're doing auth your API
should require the minimum amount of
permissions necessary just because I
want to log into your service with
Twitter doesn't mean I want to allow you
to post my Twitter feed that's a common
one or read my gmail contacts or
anything else leveraging existing flows
in the browser especially if you have
two-factor authentication especially the
you know where either you have to enter
a code on a phone or receive a text
message on a phone or press a little you
know USB buttons stuck in the side of
your laptop over here whatever it may be
this is complicated this is something we
experienced recently in cloud tools for
Eclipse the old Google plugin for
Eclipse just did every you know did some
things in an eclipse browser window but
turned out that couldn't support the
complicated two-factor authentication
flows we're using today
so now instead we just launch Firefox or
Chrome or whatever your installed
browser is to do the authentication
service and robot accounts this is
something you need to think about when
you're handling authentication
authorization in many AP is the things
that are talking to your service are
themselves services or do not
necessarily have a user handy how do you
deal with that how do you make sure that
they can log in what credentials do they
run as do you treat them differently do
you recognize them as service and robot
accounts it's a hard problem and a lot
of the details of that are going to
depend on what stack you're using on the
backend to actually implement the API
service but think about it up front
because if you don't think about upfront
you're gonna think about it later and
it's going to get you developer Keys
authentication authorization about
establishing who is communicating with
your service developer keys I wish you
could do away with but they seem to use
in practice they're establishing which
program is communicating with your
service who wrote it
so I Eliot Harold may be using a program
that was published by Twitter to access
some other service somewhere else and he
wanted to know both things one reason to
use developer keys for example is
suppose the let's suppose a third party
writes a Twitter client that accesses
the Twitter API and there's a bug in it
and suddenly it starts requiring way to
fast and effectively do essing Twitter
you may want to block all requests in
that client now that's not to say the
same is blocking all requests from that
user you want to understand the
difference there this is a really hard
problem in my opinion it's not a problem
we've really solved it does help you you
know if you have developers register get
a developer key include that developer
key in their application that they
didn't distribute to users it helps you
identify the developers with good
intentions you know who aren't trying to
deliberately break the system you know
it helps you avoid those sorts of
accidental bugs where someone is do s in
your system it does not stop bad actors
it does not stop people from accessing
your API without registering for
developer key all such things kinds of
developer keys are trivially stealable I
mean if they're in JavaScript less than
a minute typically you just pull them
pull someone else's Maps API key off
their web page and you know using your
own program don't do that not telling
you do that but it's doable it's
possible and on the server side you need
to understand that people can and will
do this if you're really clever maybe
you can raise the bar to steal someone
else's developer key from a minute to a
day if you're extremely clever I'd be
surprised if anybody could make it take
longer than a day so it's a bump in the
road for API adoption it will make it a
little harder for people to use your
service maybe you want that maybe you
want to know who's signing up to access
your API write code against it but if
you can avoid using these things do so
performance considerations for a lot of
api's this is not as important as the
performance of webpage because the
program on the other end doesn't get
bored
doesn't twiddle their fingers waiting
for the page to load unlike a real user
so a few seconds of latency may be
perfectly acceptable on the other hand
if one of the use cases the API is
there's a JavaScript program running on
a web page talking to the API loading
the data into the web page where a user
will see it then performance is a lot
more important if the response time is
going to be on the order of 10 seconds
or more I'd say make sure you support
asynchronous requests in your client
library if you have lots of data use
pagination this is a common mistake
I still see made today you know someone
I want to request all my page hits on
each of my pages organized by day from
January 1st 2007 to December 31st 2015
and oh yeah I've got you know a thousand
pages now dump that all out what are you
gonna do with that if the batch job
maybe but in general paginate especially
if there's a user involved give them ten
hits at a time ask them to come back for
the next ten or a hundred at a time come
back for the next hundred this depends
on the nature of the data exactly where
you cut your pages but include
continuation tokens if you're using HTTP
don't try and optimize around the
transport protocol let it do the work
for you for example no custom binary
formats please you don't need them use
text let the gzip encoding on HTTP on
most servers do the work and that will
reduce your bandwidth very close to
optimal use keep alive an HTTP 1.1 use
batch methods and speedy slice HTTP to
use conditional get use last modified
sense etcetera all these sorts of nice
tricks are playing with it if you have
good server libraries for implementing
your API if you have good client
libraries for handling HTTP
this comes almost for free you may not
even need to think about it again it
depends a little bit on the library
especially for the newer fancier stuff
like batch methods in HTTP - but mostly
it's a question of reading the
documentation and making sure you're
using the right libraries there and then
life is really nice and simple rate
limiting along with performance clients
concern Leedy us your api's this was
certainly concerned for us on the
analytics reporting API still is because
a lot of data and even somebody just
wants to say yeah give me all my data
for the last ten years well it's their
data and we should give it to them but
it's gonna take a while so set this up
you know be at ten queries per second a
total of 100 queries per minute maximum
whatever and have sliding windows make
sure you check this this is where the if
you can do it by user good that's a lot
more secure use a developer key for this
if you're absolutely must but watch out
it's for jables one thing that's new and
nice is there's an HTTP status
notification for this these days it's
429 it says you're being rate limited
this is something we tried to wrap our
heads around back in 2008 before this
status code was conceived like well if
someone's rate limit is that a 403
unauthorized is into 404 not found is it
a 503 server error there's nothing that
really fit the answer now is it's a 429
so use it
okay specs and tools to help you do this
I've talked about design but when the
you know code hits the keyboard what he
used to write this stuff swagger in on
the open api's project are an
interesting idea for documentation if
you're using primarily JSON if you're
using XML or something else not so much
but a lot of us are using JSON these
days so I would say worth a look
I would suggest design your URL
structure outside of swagger first by
thinking about the use
cases thinking about what the client
needs to do and then document that in
swagger treat his documentation not as
design again line keep coming back to
that theme frameworks and platforms for
actually writing the code there are many
these are just a few Google Cloud
endpoints nodejs Apache Jersey you know
the Amazon API gateway spring boot
actuator spring data rest somebody did
talk on yesterday etc there are a lot of
these that can help you I would just
warn you again first design then
implement so don't start here until you
know what your API is roughly going to
look like okay final thoughts then we
may have time for a couple of questions
remember remote api's are very different
from local library api is you cannot
always assume things you know to be true
about making a method invocation to be
true about a network api like it's going
to return it's not going to time out
it's not just gonna fail silently a
network api might a network api might
change while even though nothing your
own code has changed stick to standards
like HTTP where they exist work with the
stack rather than against it again part
of sticking with standards start small
and grow think Minimum Viable products
get something smaller out sooner and see
what your clients think of it and most
importantly of all do not let your
implementation define your interface the
interface the I and the API that comes
first that is the first thing you design
and then you figure out oK we've got the
interface here we've got the backend
data and service over there most of the
time that's done before the API is done
now how are we going to connect the two
it's a question of connection not of
it's just exposing the backend so with
that I think we have time for one or two
questions this is not jeopardy you do
not need to phrase your comment in the
form of the question you do not need to
give a two minute rant and then say what
do you think about that at the end to
turn into questions so questions
thoughts especially
front of the room where I can see people
yes okay
regarding the question is regarding
pagination how do you handle page
boundaries changing because the data is
changing this is going to depend to some
extent on the nature of the data to some
extent on how the data is sorted to some
ascertain how what your back-end looks
like you may in some not all cases
actually have the response stored in
cached so that even if the data is
changing the response to the query is
not changing so even though ten records
have been added on the backend in the
meantime since the second query comes in
those new ten records are not included
option one option two is write the IDS
of the start and the end of the
pagination do not necessarily have to be
the have to be just indexes into a list
they the start may be you know the URL
of the first record the end may be the
URL of last record and it may have even
have a next link to then following
record which is then supplied as the
continuation token so there are a lot of
different ways to do this you do have to
drill down at the specific nature of the
data in the system though yes right
okay for it impotant see how to prevent
the creation of a resource twice this is
exactly what put is for because if I
send the data to create the same
resource twice the second resource with
the new you with the same URL doesn't
change anything
assuming the you know I send a request
to create John Smith as the name and
then I send the same request to second
times great John Smith again that is in
a put request the URL you're sending
does not change and it's recognized as
the same resource and the same thing
that's the difference between a post
request okay I think we're out of time
but I'll be happy to hang out of the
hallway if anyone has any further
questions thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>