<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Docker for developers and ops by Patrick Chanezon | Coder Coacher - Coaching Coders</title><meta content="Docker for developers and ops by Patrick Chanezon - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Docker for developers and ops by Patrick Chanezon</b></h2><h5 class="post__date">2017-04-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HY6H5lsCdzo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let's get started thanks for coming to
this session my name is Patrick Shanna's
oh my work at docker and I'm going to
tell you about docker for Devlin ops
what's new and what like there's been
lots of changes announcements in the in
the past few weeks a little bit about
myself so I'm a platform plumber I spent
ten years building platforms at Netscape
and son then ten more years evangelizing
platforms at Google VMware and Microsoft
Google it was app engine vmware it was
God's laundry and Microsoft was a sure
and then I moved to docker two years ago
so first a little bit of a story of how
I hear the market right now and why
docker i think has been successful so
and i'll use movies analogies of the
different companies right now are right
now let's say in the past four years
we've been in that transition where
enterprises started to look at cloud
infrastructure to deploy our
applications traditionally they've been
in the data center highly virtualized
view with vmware so vmware kind of owns
the private cloud space and then the
public cloud providers their offerings
have matured a lot in the past few years
and so a lot of enterprises were
wondering when would be a good time to
start migrating their workloads and that
happened over the last two years and
it's happening at full tilt right now
one of the things that Enterprise want
on the on the public side cloud is they
want to have a hybrid story they want to
deploy some of their workload internally
some of their workloads in public clouds
and they don't want to be stuck with one
cloud so in the context of that
transition there is a big fight between
these four companies and i'm going to
use movie analogies to explain their
position and that's my point of view so
vmware to me like the movie 300 i don't
know if you saw that it's the story of
the Spartans who are
listing there are 300 and they're
resisting an army of 10,000 persons who
are invading their turf they're very
courageous they shot spotter so like
vmware has great technology and
virtualization thats everywhere in the
data center but we all know how it ends
at the end they all die to me that's the
position of vmware today they're trying
to push it back a little bit by doing an
alliance with amazon in the cloud but
i'm not very hopeful on that then we
have amazon who created the public cloud
market i think back in two thousand six
or something like that with ET tube so
amazing to me the best analogy is the
movie King Kong or actually the set of
King Kong movies so it's this huge ape
who lives on this island where they're
selling books and he fights with
dinosaurs like barnes and nobles own
company and he's stronger than them he
really rule the island so then one day
he decides to go to another place which
is New York which is the enterprise
market and there he he breaks rampage
and wreak havoc everywhere and people
think that he's going to rule New York
and at the end he goes on top of the
Empire State Building and he shelter but
then at the end all the planes coming
from the azure are kind of destroying
him so we'll see how that how that goes
in that big fight between Microsoft and
Amazon in the next few years two new
google is very much like back to the
future when I was at Google we had this
product call appengine that created the
pass category and i try to sell fast to
enterprises we had a version called App
Engine for business at that time so i
went to see enterprises and told them
yeah you're just pushing your code to
our cloud and we take care of everything
and they just laughed at me they think
no way there are some compliance issues
we want to know where our data is
running we want to run some of our apps
inside the firewall and we don't want to
be stuck with one cloud provider and so
Google technology in general is really
advanced and it's it feels as if it's
coming from the future and the feeling I
had in these meetings was the same
feeling that mati had sumati the
character in Back to the Future he's a
kid from the 80s who goes back in time
in the 50s and there he comes on stage
at a prom ball and he starts playing
rock and roll and they are ready they're
ready for rock and roll so they they
start to dance and it's fantastic and
they're discovering rock and roll but
then at the end he gets a little bit too
excited and he starts to play hard rock
and then there's a dead silence like
nobody understand that music from the
future they're not ready for it and
that's really to me the the feeling of
the Google club the technology is
fantastic but they don't give customers
the path to go from where they are today
to where they need to be in the future
then Microsoft so Microsoft to me is
typically Terminator 2 in Terminator one
movie that the Microsoft of Steve
Ballmer from the 90s for whom open
source with cancer he's the bad guy in
Terminator 2 it's the Microsoft from
satya nadella which embraces open source
and he's coming back and this tank is
the good guy and then docker in the
middle one of the reason why I think
docker was successful is that it
appeared four years ago at a time when
enterprises were starting to wonder how
to leverage cloud with that desire to do
hybrid so to have some workloads
internally and to use several cloud
providers and docker provides that
isolation layer where once you have
installed docker on each of the cloud
providers and internally you just use
the doctor API and you're insulated from
what happens behind it while still being
able to leverage all the capabilities of
the underlying infrastructure and so I
think that's one of the reasons why
doctor has been successful the second
reason is that the the daka file and the
compose file are great abstractions for
DES and ops to collaborate together
and docker grew at the same time as the
DevOps movement where devs are not
starting to work together instead of
using the same tools instead of fighting
each other so the the old stack was
hardware and then you put a fat
operating system with lots of packages
and then you were you would just run
your application on that the new stack
looks more something like that where at
the base layer you have either your
virtualization of lot brighter sometimes
bare metal as well and like in the
majority it's one of these three cloud
providers or VMware for virtualization
then on top of it you have a shrunk OS
and core OS started that trend many
years ago by creating a small linux
distro that is just designed to run
containers and very quickly the whole
industries followed suite so Red Hat has
atomic wing to have been to core rancher
I think when the further in there were
they literally have nothing on Ranchero
s but to docker containers 14 system
containers and 14 userland containers
then fattened from VMware and even
Microsoft followed that trend with in
the latest version of Windows Server
2016 there's a version called nano
server that's really small doesn't have
any UI you only manage it with
powershell and it's designed to run
workloads and high density in containers
in docker containers in the data center
so on top of that you have dr. which is
a platform to build ship and run the CBD
applications it's pretty open there's a
bunch of plug-ins for volumes with
gluster they used to be flattered but I
think they went down but they are there
a lot other more and then networking
with a cisco new hash calico we've and
then on the right you have orchestration
and so orchestration it's been a big
battle over the past few years now I'd
say it's it's down to two or three
players there's a docker itself with SWA
mode so dr. is an orchestration engine
coogan a death by google
a whole lot of other participants in the
open source project and apache measures
so let's talk about darker the company
itself what we our mission statement is
to build tools of mass innovation we're
trying to find technology that is useful
to create stuff and then we package it
and we make it usable for everybody in
order for people to innovate the area
that is the most ripe for innovation is
the fact that all the devices are coming
online and can be programmed and so our
first goal is to build tools to let
people program the internet every
devices that are connected and typically
the devices all have different operating
system and text acts for programming
them we're trying to create a layer that
uniform where you could build an
application that could I've seen some
example that customers for example where
they are they're having some code to
reduce data from they have industrial
automation equipment that generates lots
of data and they build software that
runs really close to the automation
sensor and reduces the data sends it to
a local hub that's already are also
running docker where they reduce it
further and then this app sends that to
the cloud where they're doing their data
processing and eliza's so having that
uniformity in the in the in the whole
software supply chain to be able to use
the same construct on the same platform
to run your software is really valuable
so the way we're building that is as a
stack so we start with standards so the
standard soccer are created in our the
standards for containers are created in
an organization that we co-created with
40 members of the industry there's
nearly everybody who's doing containers
is part of that is called the oci the
open container initiative it's been
managed by the Linux Foundation and
there there are two specs
one for runtime and one for image format
the specs are approaching 10 in a few
months I think there is a 100 °c for
the spec already in a few months there
will be a final implementation of that
or finals why no spec for runtime and I
think image will follow then on top of
that will build infrastructure so
infrastructure are small components that
can be used independently and one
example of that is runs either the
conquer the part of docker that is
created container that is creating
container you can use it as a command
line and use it by yourself I need order
to to use run see just need to have a
root filesystem somewhere in your path
and then you specify how you want your
container to be isolated in a big JSON
file that describes all the isolation
characteristics of the container what
the user is what kind of capabilities it
has and then you use run c and it will
just create the Linux namespaces and see
groups for that container so that's an
example so run to the reference
implementation of the oci runtime spec
but they are like a dozens of other
components like swamp kit intricate VPN
kids and a docker we're assembling all
these components that you can use
independently into a development
platform that's called darker so
developers are using that to build their
apps and then they when they want to
move into production in enterprise
settings we build a commercial product
that's targeted to enterprise so let's
talk about the darker platform it's a
platform to build shape and run
applications on any infrastructure so
physical virtual or bare metal any
operating system it works on linux and
windows so the Microsoft team in the
past few years has been adding the same
kind of isolation primitives that exist
in the linux kernel's namespace even see
groups they added something similar in
the kernel of Windows Server 2016 they
had it already in some private versions
windows they're running in Azure but now
it's available to everybody in windows
server and then they implemented a
back-end for doctor that takes care of
that uses these primitives in order to
create native windows containers so with
dr. today you can use you can create
both windows and analytics containers on
top of that you have darker which is a
platform and then you can build any app
in any language and it works for devs
and ups so as docker evolved from a
single purpose tool for Linux developers
over the past four years so we
celebrated our birthday last week it
grew into into a platform that a lot of
different type of people are using so we
have mainly for different constituencies
developers where developers want is more
productivity and they want to get
updates faster the apps community they
want to have a predictable system to
deploy and run the wraps on the
enterprise side they're running
business-critical applications so they
want something stable but also with a
back port of patches for a longer time
and plus they want support and
subjugation and then we have a whole
partner ecosystem who are creating
containers all these independent
software vendors who are container
rising their application as a good way
to consume them so what they want there
is an ability to satisfy their
containers when they're targeting
enterprise customers and eventually and
ability to monetize so in order to
attend to these different constituencies
we created to two different editions of
dr. what we call Community Edition and
enterprise edition as well as
certification programs so so for
developers you have darker community
editions typically people are using them
on a mac or on windows so they're using
doctor for Makka pakka for windows also
doctor for Linux community edition has
an edge channel that's really dedicated
to developers so this channel updates
every mob
so then you get Constantine if you
choose every month then every quarter
you get a stable release so we we move
to a new versioning scheme last two
weeks ago where we went from 112 113 to
month to Europe month so the latest
version is called 1703 it's the version
that shipped in March 2017 the next edge
version will be 1704 in april of 5 and
then there will be another stable one in
june with 1706 so then we have so the up
by using the stable channel and there we
have editions for amazon and azure and
the different cloud providers that do a
lot of work for you to set up the swarm
securely and manage the load balancer
and integrate with the underlying
infrastructure and then on the
enterprise side we have a version that
certified for the underlying
infrastructure and where the it's the
stable version so every three months a
recorder with ship a new one but we'll
do backports of security patches for one
year for this one and then for the
ecosystem we have dr. store and a
certification program let's talk a
little bit about the this edition's
model that spit in you that's really we
generalized it two weeks ago we started
doing that with docker for mac i think
it was almost a year and a half ago when
we introduce dr. for mac and the notion
there is that to set up ducker and
optimize it for a specific
infrastructure operating system hardware
infrastructure there's lots of work
required so for example for doctor for
mac you have to integrate with local
file system with a local net networking
layer and you have to build a native UI
for the mac for people to manage it an
installer where you just drag and drop
the docker application in your
applications folder to get started
and that worked really well a lot of
people are using docker for mac so what
we did in the next year and a half is
that we started generalizing that we
created darker for windows and then we
created cloud versions Dhaka for Amazon
azure and gcp more recently and the
doctor for amazon one is really
integrated with the amazon experience
when you set it up you can leverage your
existing ssh keys on amazon it
integrates with s3 and with lb and when
you're deploying a service and you open
a port it will reconfigure the lb
automatically so it's doing a lot of
work for you to set up a secure swarm on
amazon so we generalize that model to
everything and now all the editions you
can find them on the coast or so the sea
ones are free and the e ones come with
the subscription so that's what this
looks like we have a community edition
for a bunch of platforms mac and windows
stand for for desktop Asher and Amazon
for now for for cloud but we introduced
the beta it's still a private beta so
you need to sign up to get in for gcp
two weeks ago at Google next and then
you can find it on the free distribution
of linux vbn fedora we're going to and
sent OS then docker enterprise the
difference is that it's certified for
the underlying infrastructure so so
there we are typically shipping it for
the type of infrastructure that people
are using in the enterprise so the same
cloud providers imagine a sure but we
have windows server there so when you
buy Windows Server 2016 you get darker e
for free with it then there's a suse
linux suvi ubuntu oracle linux and os
and red hat and in addition to
satisfying for the underlying hardware
and infrastructure walls of certifying
plugins that you may use for volume and
networking and we certify containers
so what I'm talking about here is that
for example the Cisco or networking
plug-in of the Hedwig on lieutenant
volume plugins are certified so if you
run into issues and your user under
subscription you'll be supported by both
docker and these partners same thing for
the kind of workloads you may one in
satisfy containers like Microsoft sequel
server gate lab with scope always will
be supported in conjunction with each of
the partner and so when you're going to
dock a store you can find this label
certified for the containers that have
it a docker Enterprise Edition comes in
three keys three tiers of subscription
the first one basic just has the the
engine and the darker platform the
standard one is what used to be called
Dhaka data center so in there in
addition to dr. platform you have image
management container management with
what is called a GTR for images
container management and management of
your running containers with which we
call UCP universal control plane
multi-tenancy role-based access control
for your team's integration with ldap
and Active Directory secrets management
with role-based access control and then
the advanced here in addition to that
has image scanning that works also on
premise so what we're trying to build is
what we call Cass container as a service
that's a layer between is and pass and
that's a layer that fits better with
what ups and devs want from a platform
and so it helps you create a whole
supply chain for your enterprise from
death to apps including the
collaboration in between with the
registry for managing images so at the
base of it docker on especially on Linux
using Linux kernel isolation primitives
namespaces and see groups and there's
another aspect that's very important is
that unions file system
with image layers so when you're running
15 workloads on a host that are all
based on a noob in two days you're going
to base will be downloaded and run only
once and then although all these layers
are added with the Union filesystem and
at the top there's a writable layer
where your container can write since the
last summer ducker has built-in
orchestration so scheduling of
containers declarative service API what
we call cryptographic node identity
where when nodes talk to each other they
each have certificate and they're
talking over TLS and we have a built-in
routing mesh for for accessing your
services so for example when you expose
the port in your container you can you
can you can have what we call host port
where you say I want to expose port 8080
for for this service on all the host and
potty vad will be open on on all the all
the hosts in the swarm and then any
requests coming to it will be routed to
your services whatever internal port are
using in there so what's new in docker
1703 a lot so first of the darker EE and
he that we talked about so introduces
additions only two or three weeks ago
one of the big big news that that we
useful especially for apps is a new
support for in compose a new support for
compost pile in dr. itself so docker
introduces the service model when into
and when it introduced orchestration
back in the summer but swamp mood was
not working with compose files so now it
works with compose files which means
that you can use a compass file and in
the three dot one version of the compost
file they are more detailed that you can
specify if you are not for how many
replicas you want of that service and
what is the update body teach for
service what kind of Secrets you want
associated to it
and then when you have this compose file
that developers have been using for
developing the app you just enrich it
with the new information and then you
can do a darker stack deploy and specify
the composer and to create the service
on your swamp one of the big new feature
the secret management I talk about it in
more details some system commands that
people have been asking for many years
to prune your unused images and
containers some monitoring improvement
and there is a new experimental feature
where you can have an endpoint that
exposes matrix in the promises format a
build improvement with the squash
command that allows you to squash all
your layers into one more understandable
CPU management and then the docker for
AWS and Azure additions on our GA so
let's talk about Dhaka for developers
typically there they're going to start
on a mac or windows and they're
downloading one of the additions and
then that you start with a docker file
so who here has used daughter already ok
so I'll skip click quickly through that
just the new stuff so dr. file you
inherit from a base image you can expose
sport typically you're you're building
your your artifact using another
container and then you copy the build
artifacts somewhere in there inside of
your container and here you can launch
your command so I'm so the example I'm
going through through all this talk is a
spring boot application using MongoDB so
here I have built my spring application
with a sad jar I just copy the job
somewhere and the way to stop the app is
a java minus jar of my screen doge doge
are so that's the name of my application
and i can pass up some parameters to it
this report i want to open and the uri
to the MongoDB database i'm going to use
so here i use an environment variable
that will need to be passed
when I run it one of the new things that
and not many people know about is
something that we introduced in i think
in last summer last June a new new
directive in Dhaka file that allows you
to specify your health check so here my
health check will run every five minutes
with a time out of three seconds and it
will be required three times before the
container is deemed unresponsive and the
command here I'm just curling localhost
on port 8080 to see if my app is is up
and running so you can you can craft
your own health check and then a swarm
will know whether your container is is
healthy or not and it can we start it on
another host or or on the same one so
one of the advantage of docker is that
you're not obliged to replace completely
what you're doing you can adapt it
piecemeal so some people are using it
just to compile you of their application
so instead of having to install made one
or or ruby in this specific version or
Python in that specific version you're
just using a compiler or go in that
specific version you're just using the
compiler tool change from a container so
here it's a job that using Java 8 so I'm
just going to compile it with maven the
maven container and so I just do a
docker run- I key to get a terminal to
see what's happening minus R M dash dash
RM to remove the container when it's
done and I do a maven package for my
source so the way I get my sauce in the
container is by mounting a volume with
I'm on the current directory inside of
the container the working directory here
will be the directory where I have
mounted by source there is one thing
forge a developer out there one thing
that's really useful to know are one
optimization trick so when you're using
maven maven download the whole
internet with all your dependencies and
put them into a local cache if you're
running a container like that containers
the next time you're going to run it is
going to redownload everything so one
good way to do that to avoid that is to
create a volume called maven so it will
be created inside of the vmware ducker
is running and then to map that to the
the user dot m2 repository so that that
cash can be shared between different
build build runs then once you build
your artifact and you have your dacha
file you can build an image so here I do
a docker build I tag it with my darker
by d Shannon all / windows but you can
use other tags and then I'm building
what's in there so you're just going to
copy my jar and create the image and
once I've done that I can run it so if I
have MongoDB running on a host that's
let that call Mongo I you a doctor run I
pass an environment variable mungo URI I
open for 80 90 and I run my image and
then after that I can do a doctor push
of my image to go to docker hub docker
hub I think you have a few free private
registry if you want to use that but you
can buy more or else a lot of people are
using a the open-source registry and
they run it internally or they use
another type of registry and for the
enterprise we have the dr e standard
edition comes with a GTR which is a
trusted registry now very often the app
that you're building is made of lots of
containers so you want to run all of
them at the same time especially in
development so for that you are using
what is called a compost pile it's a
declarative way to specify all the
containers in your application and once
you do dr. compose that all of them will
start up so here are you find two
services one for my application with
port mapping
I put a link to a MongoDB to the Mongo
container and I have a second service
with Mongo with just the image among go
so I don't need it to be persistent for
that and I pass the environment mungo
URI with a Mongo name which is the name
of the service so then I can do a darker
composed up and it will just start all
my containers so I'm just going to show
you how that works so I have my
application that's there and here i had
my my java source i have my three
applications windows web spring doujin
spring douche photo so i can start doing
a maven build so I'm just going to use a
container yes I have that there so
that's the command i showed you before
and let me make that slightly bigger so
here i'm running a maven container and I
just mount the maven volume in there so
that it doesn't have to redownload all
the dependencies and just going to build
my spring Dozier jar if it's compiling
my appt building my jar when I'm okay so
it's repackaging that stuff so when i'm
done the way with that i'm just going to
i'm just into a package or to build my
image then i'm just going to do a darker
build
and I'll tag it with one dot one and i'm
using a doctor file that's called
duck-fat death because i have another
one that I use for citv and so when i'm
done with that i have a compost pile in
there let me show you what the oh that's
a composer that i showed you before so
that the compost pile i showed you
before i'm just going to do a darker
compose up and so you're going to stop
mongodb it's going to start sorry so dr.
Campos minus laughs
Holly I do
oh maybe I'm nothing the right maybe
just darken some fun OIC to talk a
composed run or maybe I can
yeah this one is simple so I use the the
prod one so I'm just going to
ok so it's starting my application it's
starting starting Mongo starting my job
and it's exposing for a DAT so if i go
to localhost on port 8080 no it's not
because
so here i need to do about nothing i'm
just going to remove the label where I
just go back there
so I'm using my containers and then I
restarted and so this time it's just
going to recreate all that stuff and
when I go on localhost I'll be able to
you just see it so while it's starting
that I continue with the presentation
because I'm running a little bit late
and there's other stuff I wanted to show
you so there are lots of examples on
github that you can find a for people
who are using gte there's a good example
in darker labs that I really has been
doing with couchbase now once you finish
your development you want to deploy that
to production so let's talk about docker
for apps so we have dr. for AWS and dr.
Frasier and in bed a doctor for gcp I
talked about that one of the new things
that shipped if you're using the edge
release is a axilla beta where it's
called swamp management and so it allows
you to create a swarm directly from the
desktop have the swampy manage in dark
cloud and it's deploying a doctor for
amazon or or dr. Fraiser addition and
then you have access to that addition
directly from the menu without having to
create to ssh and manager ssh keys and
all that the other thing I wanted to
show you is dr. stack deploy so once
I've once I've done all that now I can
update my my compost file to version 3
or 3 dot one and there I can add some
new keys in there that are tied to
deployment of my services so for example
here I can specify that in production I
want my my web tier of the application
to have two replicas and I can specify
the update config so if I have lots of
containers I want to update to at the
times or more the delay between updating
containers when you're doing a rolling
update and a restart policy and so you
use that with darker stag deployed so
let me show you what it looks like so
here I have this new menu 1 i'm logged
whereas channels on here so that's my
daughter ID so when i'm logged in with
my daughter ID i have this i can see on
my repository here and i can see Mike's
warmth and here i could say hey I want
to create a new swarm so I'm led to the
dark cloud you I and there I can i have
put on my amazon credentials in dark
cloud and then i can say i want to
create a new swarm that's called that
awh to i click on amazon and then i
specify the region where I want to
deploy it so I want to deploy that in I
don't know north California the swamp
size also do I have my acct I don't
remember yeah I have it so i have my ssh
key that are coming from amazon i can't
specify how many managers i want how
many workers so here I'll just reduce
that to this and then I can specify the
size of the VMS I want that I can click
create so I've done that before and it's
using cloud formation behind the scenes
and spherical can see my path AWS swarm
that's been deployed and when I go there
in swarm I he might form a helix running
and when I click they're just going to
open a terminal and do all the setup for
me to to be able to to connect to my
swamp so if I do a darker info in there
I should see the information about the
remote swarm on amazon that's running in
there so let's take a look I have six
containers running on that on that
version I have one manager and three
nodes and if I'd so and let's take a
look at the environment variable that is
created to me what it does the way that
that is that doc is reintegrated with
dr. for mac so it's creating a local
unique
get then then there's a channel to the
swarm there's a container that's running
on my mac they're doing the ssh tunnel
to the swamp and set it up all for me so
here I can do a darker service less and
see what services are running today on
my swarm so only the docket cloud server
proxy is running because I haven't done
any workers there that he were am maybe
I should go back to my Windows
applications so i just take that so i
have a darker compose file there that
has the deploy parameters for that i
want to use so here i can say dr. stack
deploys dash dash campos file it's
called ducker can put the channel and
i'll call it those and so so now doctor
is talking to my swarm in swamp mode
that's on the that's running on amazon
and it's going to deploy my application
so it's going to create the service
Mongo the service web if I do a darker
stack yes of those
I can see my various services who are
running and if I look at so I so I have
a sweet task those web one and those
were two that are running here yeah on
different machines so the Mongol and web
running on one worker dosha web is
running on another worker and then when
it's ready it's going to reconfigure the
load balancer from amazon automatically
to open the port that I exposed so I
think I exposed port 80 so I'm at 482
8080 so that means Pauly D is going to
be taken on the load balancer for my
application it may take a while to start
but that's the elb address let's see if
it's already up and running and while
I'm doing that maybe I can oh yeah so my
localhost one at which is running now
let's see if it's running on AWS and
before instead of waiting that it for it
to start i'll show you later i'm just
going to talk about the enterprise
version and the goal is an agility
possibility for developers and control
for apps i talked about the subscription
tears when I expect that's super
important and very differentiated
inductor is security so we're trying to
make you what we call usable security
when you set up a swarm by default each
node has its own certificate all the
nodes are talking together using TLS and
recently we introduced app secret and
i'll show you apps across are much more
secure than other platforms I've heard
of then trusted delivery we have image
signing with dr. Conte entrust image
Skynet scanning encryption at rest TLS
encryption and then a user role based
access control Universal control plane
looks something like that there's a
pretty deep permission model where you
will give you only for people who only
need to view containers rest
shit control is for your team where they
can create as many containers that they
want but they won't see the containers
from other projects and then full
control is for seaside mins and the
admin manages all that stuff so let's
talk a little bit about the integrated
secrets management so you have a new
command in darker called darker secret
so you can do a darker secret create and
create some secrets that are going to be
stored encrypted in the internal
distributed store that swarm is using
and then when a container is scheduled
to use a secret the secret will be
transmitted over TLS just to the node
where that container is running and
exposed just to that container instead
of a temp FS a file system that these
appears that in RAM so it disappears
when the containers dies so you can
contrast that with a for example coogan
edit secrets management where the
secrets are stored unencrypted in egv
and if so if someone compromises your
cluster he has access to over at secret
security scanning I talked about that I
just want to show you how all the last
thing I wanted to talk about it so
building HTTP routing mesh that's brand
new it's on it in a daiquiri so now we
have HTTP level routing in addition to
the rotting mesh we had with HTTP level
routing you can specify your host for
your application to be routed to and so
I'll show you an example of deploying
our are so let's see oh so it's running
on amazon now on my two replicas and
i'll just show you a quick quick compose
file so this one is for BBC it's the
same application but here i'm using a
i'm using a cheeky routing mesh so here
i need to add that application on the
UCP HRM network which is managed by
universal control plane and which will
allow the load balancer which is an h a
proxy to access the container and then i
can put a label so come docker UCP mesh
each
GP and I say on port 80 I want the
external route for that load balancer to
be spring dos chinos all calm and the
internal port that I'm exposing is a DAT
so I'm just going to take that stack
file and I'm going to go to my UCP
instance this one is running on Azure so
I deployed it using the dollar store so
dr. store when you go to the azure
version just goes into the other
marketplace where where you're led into
the azure portal and you'd apply it in a
few clicks after specifying a few things
so I have that running in there I'm just
going to go to resources and in the
resources i'm going to deploy a new one
i'm going to call my stack dos I just
paste it in there I want to see verbose
logs and I'm just going to create it and
so the result of it is that I have
changed so Shannon autumn is my own
domain so I went to Gandhi and I put the
IP address of the azure load balancer
that's fronting my install as as the
host of the IP address for the spring
doze and spring those one and test one
and a lot of different domains mapping
to that and so now it's deploying my
stack and when it will be deployed if I
go to spring those Shanna's all calm I
think it's great those the app should be
routed to from there it may take a while
for these containers to start but what I
wanted to outline is that here I could
have a different version of the
application running on the same port on
spring those 1 i'm going to take the
version one that one of my image and i'm
going to create a new stack and deploy
it so it's not deployed yet but I'm
going to deploy the new one
so that's version one that one of my
screen notification just going to put
them on any nodes in there but then be
HRM load balancer is just going to bed
load balance anything we spring those 12
to that host okay so has it been created
I think it has okay oh yeah I took Dave
now and let's see if it's up now like to
do oh yeah its up its up and running and
then if I go to the screen do it
deployed yeah just may take a little
while I should have my new one that one
version of it running so I think I'm out
of time so that concludes the top do you
guys have any questions
alright so to go further to go further
in order to get the duck or additions
you go to become / get ducker Baedeker
calm if you want to try up the gcp
version of it all my slides are on
SlideShare and I'll put these there and
some of the code of the stuff i showed
you is on my github repo in decor tips
and if you go to dr. labs you'll find a
more to play with all right thank you I
he up there for questions thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>