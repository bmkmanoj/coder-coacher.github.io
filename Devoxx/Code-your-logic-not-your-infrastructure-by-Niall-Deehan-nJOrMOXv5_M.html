<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Code your logic, not your infrastructure by Niall Deehan | Coder Coacher - Coaching Coders</title><meta content="Code your logic, not your infrastructure by Niall Deehan - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Code your logic, not your infrastructure by Niall Deehan</b></h2><h5 class="post__date">2017-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nJOrMOXv5_M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody
well come along to this little talk I
hope you guys are looking forward to
talking about infrastructure what a fun
word so I am this guy if you're more
specific and that one I'm nya daehan and
I'm a consultant I go around at building
things on top of Kalinda and helping
people understand how to use it in
various ways the bird in question named
by public vote is haki macaque face of
course so I wanted to really talk about
how we're actually how it's possible to
use commanda and basically how to use
certain architectures and have this
layer that is basically infrastructure
that gives you a lot more than just
being able to have to build something
with a bunch of different systems all
talking together and relatively
anonymous things happening in between
them I am NOT a particularly I'm not a
particularly obsessed person with
different types of architectures
generally speaking something things are
either micro-service in which case
everything has their own domain which is
perfectly fine their own data sources
completely independent in fact they have
things like independent independent
components which is really really handy
and make sure that everything is totally
separated I really like the idea of
having separate people be able to give a
domain so they can deploy things when
they're micro service needs - I love the
idea of decoupled components because I
don't like the idea of having to rely on
another micro service before you can do
something and of course I also like the
VI the the ability to be able to decide
in my micro service we're going to use a
certain data source in a certain
language and so on so I do like my
cursor versus they're really fun I build
those the stuff with those but there is
also kind of these nice benefits to the
always be seen as an older-style system
where you have a centralized point where
you have total visibility you actually
know what happens and what has happened
and probably what will happen because
it's all contained in the same place you
can actually monitor that and that means
that you can see the history of things
you can also handle errors in one place
which is really really handy deal with
the retry is in one place so I actually
quite liked
certain aspects of both they're also of
course downsized to both with
micro-services I don't quite like the
idea that I'm not really sure what has
happened when an error gets formed I
have to trace backwards being what
service have been called what where do
the arrow really occur it's a bit of a
given issue so on if we were to have a
little scale between centralized
well I'm gonna say BPM I guess and these
are new sort of entirely event-driven
stuff my personal preference is kind of
somewhere in there somewhere sort of
closer to micro services I definitely
further away from centralized stuff but
I want to keep some of that stuff that
civilization gave us one thing I really
like of course is the idea that we can
just a micro service is just in charge
of sending an event and it has some sort
of payload and then we just need to have
this layer somewhere in between that
deals at how we're actually going to
deal with that event and what's going to
happen next and of course these guys are
not supposed to know about each other in
any sense or really know about that
little layer in the middle so I want to
show you guys a little simple
architecture that them is that allows
you to build infrastructure in a really
easy way and it looks kind of like this
so the idea is that you can have your
service you have your independence all
your business logic are these services
ok so they can be written in whatever
they have their own domain language
their own data source if they want it
and what we have what connects these
guys is well some people might call an
Orchestrator but it's basically the
state management the event management
the history the everything that's
happened between all this and so
commanda is an open source orchestration
or workflow engine that allows you to
build a model your infrastructure and
how your services or how your processes
are going to work deploy them and then
it just runs that way it's it's quite
quite easy actually and generally these
models here bpmn is kind of how it works
and I'm actually going to build this
infrastructure just now and if that
three slides time from scratch so I'll
start off these services I'll build my
infrastructure and I'll have it all
basically running but as I said this
will be a live demo so I will see how it
goes
hey before I even start going to say it
worked an hour before this presentation
okay so I just get that in early so come
under itself is this little engine guy
here it's got loads of tools around it
an important thing that you should know
is that this is not the only
architecture in which come winter
happens to be used it's one that I quite
like and I tend to end up building so
we'll have more sort of brief discussion
but other ways of using it later on but
the idea here is that I do not want any
business logic in my orchestration layer
I want that all separate I want that all
version Abul separately I don't want my
the change in how my process runs to
affect anything else else is running
including services that start my
processes and services are continuous
and as I said commenda has a bunch of
tools and things will look at for
basically observing what's happening and
reporting what's happening and fixing
problems and things so for this it'll
architectural fun thing I'm going to
actually get some requirements first of
all of course like every good project
and the first one very very simple I'm
going to keep adding some requirements
this so the very first one is we want to
order something they can either be
hardware or software and it can it can
sometimes be free of charge because as I
said come Monday is open source and it's
a software so if you want to you can go
download that I'll be talking about a
little later on and you can use what I'm
going to show you just now and pretty
easily and maybe even contribute back to
the code base so this means from a
design perspective we want to actually
get these services running that's could
be a total separate thing our services
where they are it doesn't really matter
that they are a separate thing they
should be running somewhere then we need
to make sure that these services are
called in us in the correct order
depending on criteria for instance if
something is hardware I need to reserve
that physical thing in the warehouse if
something needs to be paid for I need to
make sure the pay service is called and
that involves taking data from all my go
service and calling another one without
dependency it's pretty easy so let's see
if I can get through this so let's see
if we can build it so let's start here
so the first thing is that this is a
little Java Script modeler what this is
doing is its allowing me to build bpmn
2.0 it's a
it's an open standard for describing how
processes work and you can basically use
this for doing something like the
missile guy I say let's say decide on
item type so we'll find out whether it's
Hardware where there's software whether
it's free whether it's not and depending
on the result of that I'm just going to
have an inclusive gateway here meaning
that we will either go up here if it's
Hardware okay we could also go this way
that's the wrong symbol there we go
let's go to this way if it's an ease
payment okay and then we'll just join
those guys back here in this gateway
here so now what I've done here is not
design some sort of oh yeah I need to
actually give these guys a proper
service task right so this is going to
be a reserved in warehouse and this is
going to be needs make payment maybe
okay that should be a service task as
well okay so one designing here is
actually not just some little picture
this is an executable model it's a
little XML tab and the bottom right
shows that there's a bunch of XML this
is standard be from in 2.0 our engine
basically understands that I can turn
that into a state machine more or less
and also can handle events and all sorts
of other fun stuff so now let's talk
about what these services are okay so we
have this layer this is where we're
going to call things is a very simple
example get more complex but this is the
the opening gambit where we have these
things we want to call them this order
so where are our services so my services
look like this okay they're a little
JavaScript guy they have a location of a
rest endpoint okay which is where the
engine is running it knows where the
engine is and it knows what work it can
do okay that's all it knows it doesn't
know about the process itself does know
but the task that needs to be done it
just knows there is a central component
that if
ask that's where I get my work it's up
to the the engine to decide what happens
when this guy finishes the task and how
the process route is further so I'm just
going to start these guys up I have them
here there's item type do okay there
okay so if I start these guys up they
will do not much more than polling okay
they're just asking for work to do and
right now there is no work to do so now
we actually need to add a bit more to
this and then give it to the engine so
right now what I've designed can be done
with basically anybody if I actually
want to make this runny to give it a few
additional criteria and that's all here
in the properties panel there's lots of
as I mentioned already this is one way
of implementing things I could just
attach a java class to this and then it
would run that java class but personally
I don't like that approach straightaway
because it means that I have to have
code very close there's class loadable
near my m in on this container and
already want that so I'm going to use
external I'm not going to trust my own
spelling so I'm going to copy this so
this says that when we arrive when a
processor rises the state where our
token is at that point we are at the
point where we're writing to a topic to
say okay now we need this work done this
determines status needs to be done okay
along with the context of the current
instance we have this topic and the
worker basically is going to say ok
that's for me I'll do that ok and we'll
do that for the rest of these little
guys so reserving warehouse is this one
here
oopsie that's the wrong button ok so
once again external great payment let's
go here again external and now I just
need to give this an actual name which
is an ID if I process so I can actually
start it
okay and as I said I'm gonna save this
to my desktop because this is basically
just an just a simple to do is a simple
XML file and what's gonna make this run
is the fact that I'm going to deploy to
this so this is the front end that
represents commander this is a fresh
install so I just this is all you would
see if you just downloaded it we have a
single little demo process that's
running here it looks something like
this
and of course I want to deploy my new
process to this okay
and once it's deployed that basically
gives it this rest endpoint will then be
able to be fired off and started so
let's just go to deployments I just need
to find that file and then we basically
get re our infrastructure we get our our
state machine from what we designed I'm
gonna type something very important in
here great okay so if i refresh this
we've done of something very simple
which is we have this okay and now we
can actually start this this is now a
live running process so I can go to
postman here and I can just send a rest
call to the engine to say if you have a
process with this key cam delivery then
just start an instance of it so I can
just do that and that gets sent great
meanwhile our workers are doing all
sorts of weird stuff because I started
this it moved the process on we found
that we basically started here we did
something here presumably we then with
the database here we arrived do they
here here or both we could do either and
then we arrived at the end now the nice
thing is that that definitely happened
because we know how it works we don't
have to trust my word for it because we
also have history of exactly what
happened so this actually shows the path
that we actually taken so far so if we
do something like start up a runner so
this is a really simple remote it's
going to start this process lots and
lots of times 12 not lots and lots 20
and let's run that so this is now
starting the process with data and all
of these little worker guys are working
away and they're all perfectly dependent
and they can die pretty easily so I can
kill the item worker for instance that
can go down
and I can refresh this and we can then
see how you've done so far we got six
guys went through here
this is started to pile up probably this
is two there so if i refresh this my
other two workers are still running but
they don't have any job to do so I just
need to go back to my item worker here
and just start him back up so not only
can they die and be started back up
without actually affecting the state of
our process which is a really nice thing
to have as soon as it starts back up it
just gets this software in starts going
again because it's independent because
it has no requirement that I come
undersized up and come on it has no
requirement that this stays up so it
means that we can then suddenly take off
again and start there going or we left
off and allstate has maintained here ok
so that's a pretty easy example it's
pretty straightforward but let's just
pop back here and let's talk about the
fundamental problem with when you write
something that's simple and great we get
new requirements so we need to add two
if we need to improve it because we
never need to have to deal with the one
thing so let's say we have some new
requirements we need to wait for some
confirmation from our user because after
we've done all of this we would like to
make sure that they actually want
something we don't wait too long we
don't know wait forever ok so we need to
wait for a certain time to expire and
then we give up waiting ok so what we're
going to do is we're going to wait for
an external message to come in and we're
going to wait for about 20 minutes I'm
gonna make it two minutes for this demo
and then we're going to make this change
without disturbing anything we don't
want to we have a running process is
very very popular now and we don't want
to have to change any not have to stop
our service just because we're changing
some stuff so for instance if I open my
runner back up I'm going to go back here
I'm actually gonna run this maybe 200
times I'm going to kick it off hopefully
it'll work ok and I'll have that running
in the background and then improve and
deploy my new process so that will be
starting processes the whole time and
these guys will all be running doing
their work I mean well I'm just going to
add something to this I'm going to add
another task this is a different type of
task it's a receive task so
wait for confirmation okay but as I said
only way too long so I'm actually gonna
add a timer to this so as well as just
being able to maintain state the engine
also has asynchronous processing behind
the scenes so we can do all sorts of
really fun stuff like it can start
processes every X number X amount of
time if this if we are live at this
point we can wait for a certain time to
expire and then we'll move in a
different direction and we don't need a
microservice story about that or any
other part of the system it's all taken
care of by the engine so let's say two
minutes two minutes a very short but so
is this talk so there we go suits great
so I'm going to add a message this this
is the message where we're waiting for
confirmation great and we're waiting for
a certain time to expire which would be
a duration I'm gonna give it PT to em
normally you would put an expression in
there you don't a hard code anything but
there we are so what do we do now that
we have a new model we have all our
services running happily doing their own
thing and we have this guy here an
external system you can imagine like a
website you just constantly ordering
more stuff so how do you get this thing
to actually take off well we go back
here to our deploy we click this we
click on the thing we just created which
I'm assuming I saved I did and click
deploy okay great so now that's it
that's it done if i refresh this page we
should see actually that we probably
have a few instances maybe floating
around there we don't but we do have
this little drop down here we do have a
new version I know we do have a new
version we have instances running in
this new version because this call has
been made was starting then just start
this process we never specified in this
rest call anything a better version
because we don't want an external system
to be trapped to a specific version of
orchestration rather it just says start
whichever one is new and it just does
that so instead we have a scenario where
we just can add these changes to ploy
them and no micro-services or the no
services are actually affected by this
and any service is starting the process
how many sort of messes in don't really
have any problems either so
let's just stop that for a moment
okey-dokey so let's have a wee look at
this okey-dokey
so yeah let's actually have a wee look a
cockpit so if i refresh this I've killed
a bunch of stuff so there's also as I
mentioned already some things we can
maybe do to like sort of ad hoc admin
stuff here it's quite nice to look at it
okay and it's it looks very pretty but
it's it's not really it's an admin tool
this front-end it's talking to the
engine we can see what's actually
happened but we can also manipulate
State in a really important way so let's
imagine that we have a problem
we got a call and we got a problem with
let's say one of the processes is
waiting for confirmation but actually
for some reason they use it different
the wrong item and the tick box with
something so here we have all the
details we have hardware yes and let's
say it wasn't actually hardware at all
so I'm gonna change this to no okay
that's easy enough I've changed a
process variable because we have all the
variables right there but that doesn't
really help because we've already gone
through the process it's a nice way the
really nice features we have here is the
ability to manipulate state at this
level very easily without affecting the
processes so for instance I can just
decide I would like to run this again
but from over here so I can drag the
state and then drop it to any other
position in the model either before its
current location or after and I can just
decide ok apply that we get this lovely
message you were playing with fire
income under if you were about to do
something cool you will see this message
and it means that something might break
in this case and it didn't so it moved
through it then probably ran a bunch
more stuff let's check the history okay
so this instance what this shows is
quite interesting it shows first of all
the audit log is here so I know exactly
what happened at what time but I can
also see that we've started the process
here we then did this twice okay we
arrived here we did these two twice we
arrived by four tokens right here and
then we're back here what this little
guy here indicate
is that we got here before but we never
actually completed this state okay so
all of the state information is
maintained and it's all changeable here
again because we have the separation
between our services that we don't need
to worry too much we can manipulate data
and stuff from here
okey-dokey so let's move on to something
a little more complicated a little more
interesting
so okay next up we made a teeny problem
okay this does happen as you may know we
have problems with our services that
we've just deployed something it's very
very easy to change your process which
means it's maybe a little bit too easy
to change your process so we have a
problem in which if you look at our
model we could possibly make charge
people ok reserve something in the
warehouse and then when they make
confirmation if they don't make
confirmation in time we could end up
just forgetting about it and we've
actually not done anything to solve this
payment problem so we're charging a
bunch of customers stuff and because
this is very very popular let's starts
up it keeps on running so we this
process is right now causing all sorts
of havoc so again one of the nice things
about this centralized way of doing
things is that I can go into my process
that I know is not working very well
because for various reasons and I can
decide ok I couldn't shut down all my
micro services that would definitely
work that would means that I wouldn't be
doing this anymore but it's a little bit
drastic so instead I'm gonna go back
over here and I'm just going to say
that's a run time there we go I'm just
going to pause ok I'm going to just say
stop this process pause everything and
the current state it's in don't start
any new ones this is just this is now
this is not working and the nice thing
is that all our ma as a settle and micro
services they just adhere to that it
freezes the state of the current process
ok so all those guys have stopped our
runner is probably failing yep there we
go it's failing specifically because it
doesn't actually it's not allowed to
start a process as suspended and and we
can control when these suspensions
happen and how to lift them if you're
wondering about the relationship between
this front end and commander this front
end is
written in angular I think probably yes
definitely and it communicates the
engine via rest from the same container
it's unlike in this case is on along
with the engine which is written
entirely in Java it's it's got a REST
API built on top of that and all this
communication including dragging and
dropping that token suspending a process
doing all of that including deploying a
process is all done by rest so you can
either you can do it yourself in a REST
API or you can use this have front-end
as well you can embed the engine or you
can also deploy it with this front-end
okay so now let's try and solve our
problem our problem is of course that if
we take a look at this okay we need if
if now here's a fun thing if we have
made a payment we have to refund it and
if we've reserved in the warehouse we
also have to release okay and now why
that's interesting is because we have a
we have a scenario in which it is
possible that we could do either both of
these or one of these are either so we
actually don't know at this point which
one we have done okay that's another
important thing and the nice thing is
that to actually this is a classic
compensation issue I need to know that
if I arrive at this point that I will be
able to undo this if I happen to have
made a payment during this process okay
now there's a very long-winded way of
doing this I could have another gateway
I could maybe query the engine and find
out where it's been and then I could
maybe try and run their task to undo it
but BPMN the reason we use bpmn like
this is because it has a lot of really
really great features like one of them
being if I attach this event here it's
called a compensation event and I attach
this little task here and I call this
release item okay and then I add this
event here okay this means that if the
stage reaches that top corner there at
that event it will check where it has
been and it'll check what service
it's actually run like this guy right
here that it's run and it'll say oh I've
run this and therefore I shall run this
okay
now usually if you're talking
micro-services these two guys these the
release item and the make reservation
that could be this that's probably the
same service the same domain right so it
could be the same micro service in this
case it is the same micro service is
pulping for multiple things that can do
because that's the the warehouse service
is this domain so and I'm gonna add
another one for payment as well because
now it's possible once we wear the gun
there it is once we throw this event not
only do we go back and throw let's say
your refund okay
now only do we go back and run these
guys we also run all of the required
compensation by default we don't have to
about will in this case so we'll go back
and find everywhere we've been that has
this symbol and run the three funds so
let me just and again this is
implemented in the same way we'll use
these guys and I will make sure I can
copy this so this is release item and
this one here is make refund okay great
stuff so now I'm going to start this guy
back up let's actually go back here
let's run out like 20 times maybe there
we go great so that's started probably
failing yep but have no fear our
services actually don't know but any of
this cuz they're still on their own
little weird little plane so let's drop
all those guys and now I just go back
and I'm going to again redeploy this so
click on deployment choose this there we
go something important deployed and now
I think what should happen is that they
should start working there we go because
we've now deployed something that is not
suspended the newest version is no
longer suspended so if we go here we can
see able to see that there's a bunch of
stuff happening here and let's just take
a look at history see what's happened so
these have started everything star
back up okay now that's quite nice we
have that working but that does not help
us with our broken build here okay these
guys are these 60 guys are stuck because
they're in this broken build and so what
can we do about this again it's quite
easy because you maintain all state we
have the possibility to do something
like this there we go
that little subtle button basically does
migration so this on the left is the old
version this on the right is the new one
and we've automatically not where the
engines of the favor and told us where
we probably want to put these tokens we
don't have to if you want you can be a
bit crazy and decide to map this one I'd
know over here maybe if you like sorry
the problem but this guy here is moving
to here so then I can go ahead and I can
look filter which ones I want to move
I'll just move them all yep I can do
they synchronously if I like once again
we know we're about to do something cool
and I can do it synchronously there's
hundreds of thousands of instances and
just execute that and now they migrate
to the new version and now they're able
to deal with this problem of
compensation quite easily because
they're now in the new version which has
same history I was able to do that okay
so now we have a very very simple way of
being able to build all this
infrastructure between our microservices
and what do we get we get a really nice
wave handling the the path we've taken
and a really nice history view of what's
actually happened and I wonder if any of
these have run yet apparently not so
that's to me a really great benefit we
keep a certain amount of the
microservice principle not all of it
because microservice don't like anything
that's centralized but we have enough of
a micro servers principle to say that
everyone does have their own domain
language I happen to be using JavaScript
for these workers but of course as we
know because this worker is just a rest
call to an engine it can actually kind
of do anything it likes so it can it can
actually be in c-sharp and stuff and we
have all sorts of other languages and
Java as well if you happen to like that
which I suspect you might okay
so yeah and there we go we've actually
run ten of these have fired and we can
see that they then gone ahead
run these and all sorts of fun worker
stuff is going on the background okay so
that's sort of how we can do that but
there's also one more sort of level to
this and this evolves this has a lot of
data it's produced ok stepping through
each of these has given us all sorts of
weird stuff it's given us a variables
it's given us a timing we know how long
everything takes to run and we can
actually visualize that a lot better and
usually a different kind of person would
do that I'm gonna see if I can get this
working let me see if I can open this so
this is so this is another application
that I'll just start up and while it's
doing that I'll just pop in here very
briefly and show you one but we show you
what we've been looking at so far ok so
so far we've looking at is this
architecture in which we have if this is
the the container that we're looking at
we're looking at a sequel database which
is communicating our state we have the
engine built here we have our REST API
we have task lists which I haven't
really bothered with which is a
front-end application so that users can
complete user tasks with like forums and
stuff and cockpit is where we were doing
all our work the modeler is here and we
also we haven't shown yet is this guy
here so as I said this produces a whole
bunch of data loads and loads of data
and that data is and not a low slot of
data it's not the place you want to keep
in a sequel database ok you wouldn't
rather keep that in something that's
scalable and somewhere you can actually
do some sort of reporting on which is
why we have this other little thing on
the side they're called optimized which
basically takes all that data from the
from the engine and puts it in
elasticsearch and then gives you this
ability to visualize what's happened for
usually aimed at non-technical users but
and that's just because it's read-only
and they can't break anything so let's
see if that started up ok ok all right
this has been giving me a bit of hassle
so see who worked okay so this already
got the data we needed and this is the
versions that we have of this process
and this is what we saw so we can now
see something really simple like where
was the most common path through our
process that's something really simple
where most of the tokens went we only
ran 38 so it's not very many instances
and we can also find out about other
bits and pieces like I can filter by
what about variables like Hardware for
instance what about just the Hardware
ones where did they go how we can do
that sort of thing
it's kind of and this data is taken and
kept in the idea is kept for like a much
longer term than in our sequel database
if I'm here for instance in seeing this
I mean if this is starting like you know
a couple of like hundred instances per
second I cannot store that forever so I
can simply tell this on this right-hand
side here I want to keep this data in
MySQL database only for about twenty
days and then it'll at the engine will
actually go and clean that up
and get rid of if you don't want it and
it'll be left in the elasticsearch
database a nicer sort of thing I wanna
show you is this guy here because it's
much easier to see the power of this
when you actually have data we only have
about 30 something instances so here's
another model it's involves hiring
somebody they apply for a job and over
here they either get it or they don't
and once again we can see for instance
the frequency how long we've actually
spent on each time on where all the
tasks went we saw most of the candidates
get rejected here for instance and then
in the end we get these but if I'm a
specific user I'm only interested in for
instance this month that's all I want to
know about but more specifically I also
want to know about this the jobs that I
happen to ask about which would be in
department so maybe I'm in sales or
marketing which I am definitely not and
no offense to any sales and marketing
people and we have a 345 instances but
this is our data this is now all we can
see now while this is really useful to
see the most common
through our process so we can kind of
figure out how we might want to help
that if to find bottlenecks you really
want to know about duration and this
works as well for like straight through
processing very shortly but this shows
how long we have actually spent in real
time on our process what takes the
longest and so we can see in the middle
here we have this two weeks which is
quite a while on this we have three days
on this guy here and so on and so forth
and so this gives us a really good
indication that maybe we should spruce
up how we organize a second interview
okay but it also could be true to say
that conducting a second interview takes
maybe a while maybe a week or two it's
actually this guy here screening an
application should not take three days
that seems like a very very long time to
take so they can do is we can just go
into this guy here which is where we
actually give specific requirements like
and KPIs so this should only take two
days
this guy here two weeks is fine let's
say so now we have a very different heat
map but it's showing a real life versus
expectations so I would expect this
takes my expectations here are four days
and two hours and it's actually taking
yeah one week so it's 71% above target
so there's all sorts of really fun stuff
that we can do with that and yeah it
might be a it's a nice amount of data to
play with and we can because of
elasticsearch we can scale it really
easily get it up and running as I said
it's also really good for straight
through processing if we have a scenario
where we only have here we have a really
simple task these are just all services
no user tasks at all and we can still go
down and take a look at how long they
took all right because we're still
measuring this took three milliseconds
this guy here - 79 - that might be an
issue and so even if you're technically
if you if you don't have any user tasks
so you're not dealing with users
themselves a technical flow can also be
quite easy to to visualize in this and
again we can also then add specific
requirements for that and also add
variables and things okay so let me
quickly return to my cell
doot-doot-doot reporting yep okay so the
kind of things that we can achieve on
this are basically this ability to
monitor the operations okay we can also
deal with versioning really really
easily because what I didn't show you
but it's course possible is that I can
start up or bring down a different
versions of Microsoft in the flow we can
also deal with timeouts and timing in
general lots of asynchronous processing
we can deal with we get actual
visibility on what happened in our in
our flow and to our processes and where
we might make improvements we also allow
users to use domain languages that they
might especially in Pali goss's systems
where you have a proper ddd sort of
environment where everybody actually has
their own requirements for data and
whatever and they're releasing their own
endpoints for instance and of course
scaling is really easy and performance
is really great because now instead of
having to call code at every point
instead we could have 20 workers to do
the same work but are just getting all
this information getting all this work
to do and doing it asynchronously and
just telling the engine back when it's
done
I mentioned at the beginning it's not
the only way that people use commanda if
it is a micro service thing you're
interested in people tend to use
something more like this in which
instead of having come under in the
center you would actually embed calendar
in the domain and you can maintain
basically the service flow and in
another sort of way so and yeah that's
good for local orchestration I guess so
and now I just want to basically tell
you guys what you should do which is of
course going download this everything I
showed you is open source except for
optimized but the engine itself is
entirely open source and so is the api's
and cockpit and the modeler and
everything there so go download it and
use it it is a big friendly download
button right in the middle of the
calendar org webs web page so click on
yep so go go ahead to calendar org if
you're interested in more stuff we have
lots of things going on so you can
follow us in all sorts of usual outlets
so do that it's you know the Internet
it's a fun place
okay and yeah thank you very much for
listening to all this so I have a little
a little over 10 minutes for questions
so any questions at all
yes yourself yes you're a security
question so what about security how do
you deal with that so commanda itself is
deployed to a server like a classic
server so you can we offer a basic
recitation for our REST API but
realistically you can wrap whatever
security you use around or with the
container and then decide how that
communication works because it's over
rest there's a lot of options there it's
a basic rest call so you can use
whatever security yeah you want in terms
of we do have a certain amount of
authorization and stuff so for instance
people can shouldn't just be able to
everyone who has access to come on they
shouldn't be able to go in them drag
tokens around that is not good news so
we do have authorization for certain
things within command and within and all
the rest calls that actually happened
within cockpit as well but as far as the
the Micra services are concerned your
security is basically up to you you can
decide how that happens it's kind of a
slightly removed from exactly what
command does because it's surrounded by
container okay cool any other questions
yes
oh absolutely yes so in this particular
example I showed at Microsoft
architecture in which command awaits for
services to poll for us the reason I did
that is because in this architecture I
do not want Kalinda to have to know
about endpoints because there's lots of
them in micro services we don't want to
have to rely that a certain micro
service will be there and will be active
right but of course is perfectly
reasonable to do that you can really
easily do in a few different ways if you
take a look at this guy here this is our
our fundamental building block for
calling services I selected external it
could be calling a Java class that then
goes and calls the service it could be
using a connector that directly calls a
REST API it could be calling a beam with
the delegate expression you have a lot
of options here but personally for this
type of architecture I prefer to have
that separation using external tasks but
there is of course a downside being that
you do then do have this polling which
might end up being a bit Sam we usually
serve suggest you have some sort of
exponential back-off system sort of from
your micro services so they don't find
work that maybe every every poll this
back off for like a certain amount
before the next call okay super any
other questions
nope okay great stuff thanks a lot for
listen to me and enjoy the rest of de
box</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>