<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploying Docker Containers with Netflix Spinnaker on Kubernetes and Titus | Coder Coacher - Coaching Coders</title><meta content="Deploying Docker Containers with Netflix Spinnaker on Kubernetes and Titus - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploying Docker Containers with Netflix Spinnaker on Kubernetes and Titus</b></h2><h5 class="post__date">2017-04-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ySdqDGfEOHo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello what if I told you that you can
use the same tool that is used to deploy
the Netflix service today to deploy and
orchestrate your container deployments
well good news you can today I'm here to
talk to you about spinnaker spinnaker is
the continuous delivery platform that is
being used at Netflix to deploy the
Netflix service my name is tamas Lynn I
work for the delivery engineering to
steam at Netflix and this is largely
works on the spinnaker team at Google
the Netflix service the Netflix service
is available in a hundred in over a
hundred and ninety countries we have
over 93 million subscribers every day
over a hundred and twenty five million
hours of television movies and even
comedy specials are streamed through
Netflix the Netflix footprint is
enormous
in fact we run over in over a hundred
thousand Amazon ec2 instances if you
look at the Netflix service itself
you'll notice that it's deployed as a
series of micro services this is a token
visceral is open source and what you're
seeing here is request coming in into
the Netflix service and all those big
white dots represent a service that is
being hit within the netflix ecosystem
each of these services also represents a
team that manages that service there is
no centralized DevOps Tina Netflix so
there's not one team that goes around
and deploys everything each team is
responsible for the tools that they
choose to deploy manage and and build
their services so what the spinnaker
tool tries to do is take the deployment
processes available to each of these
teams and allow them to build very
flexible fairly easy to modify
deployment pipelines so here's an
example of a deployment pipeline we
designed deployment pipelines and
spinnaker
be easy credit so as your team's
deployment process changes and grows it
should be easy to just come in and add
new stages remove new stages and move
stages into other pipelines here's an
example of me just coming in and adding
a new pipeline pipeline stage so as you
can see adding a new stage in spinnaker
really is just choosing the type of the
stage that is available and then any
information that I need is available to
me contextually so here you can see
adding a Jenkins job I just picked the
job I have all the parameters that I can
set pipelines can grow quite large the
nice thing about spinnaker is that it
gives you that nice overall view of it
kind of the end to end process your
deployment process this is a real
pipeline and what you're seeing here is
actually over maybe 175 Jenkins stages
that get executed
so what spinnaker does is it gives you
that nice and a bird's-eye view of all
the steps that are needed there are a
lot of really cool things built in so
you can for example turn off a branch of
this execution kind of particular stages
restart the stages in the execution and
so forth now even though this execution
is super complex and big and complicated
all of that process is really
encapsulated into just one pipeline
right so in order for me as a user to
use this pipeline I don't have to have
an intimate understanding of all the
steps that are needed to orchestrate
this as far as I'm concerned I'm just
coming in and running the deploy to
product I plan so I come into the
spinnaker I click on run the Pareto plot
I get this nice little dialog box that
allows me to then hide all the
complexity of that orchestration behind
a simple dialog box most users don't
even see this dialog box because a lot
of this automation gets triggered
automatically through either somebody
checking in code to a git commit or
Jenkins stage now spinnaker has been
widely used within Netflix in fact we
deploy to more than 99% of all the
services in Netflix are deployed with
spinnaker last month alone we ran a
little bit north of 100,000 pipelines
and that translates to about
six million manual tasks that are needed
to do we are very excited about
spinnaker because we believe that
spinnaker represents the
state-of-the-art in multi cloud
deployment and managing deployment
processes so we open source spinnaker in
November of 2015 and we really really
excited to have a lot of community
partners they really came in and
collaborated with their own stages and
their own cloud providers Google was one
of the first companies to come in and
help us with the open sourcing of
spinnaker so little large talk to you
about why Google was interested in
spinnaker thanks a lot
so like tomasa said Google is not
involved in spinnaker for a long time
now and let me motivate a little bit why
Google is investing so heavily in
spinnaker and it really comes down to
the fact that Netflix and Spinnaker's
core tenants align really closely with
those of Google what I mean is that
Google's been a very early adopter of
the continuous delivery and the mutable
infrastructure paradigms and these are
really what spinnaker is built on most
of the tooling you'll find inside of
Google is very expert level and
self-service meaning that at the cost of
complexity you have a very fine-grained
and high level of control you get into
the application you're managing and this
is really what you see inside of
spinnaker so given the opportunity to
contribute to open source software that
aligns with these tenets and also helps
foster building an open cloud is really
a big win for Google worth mentioning
I'm one of six engineers and the Google
New York spinnaker team we're all
working full-time on spinnaker we have a
full-time manager half of a project
manager and there's a couple of teams
internal and external at Google using
spinnaker like ways for example they
manage all their active active cloud two
point deployments across Amazon and
Google's clouds so in 2014 after a
Netflix started the project a few months
later one engineer our current tech lead
joined in and helped before was open
source holy s--t out a lot of the
interfaces and make spinnaker more
amenable to
a multi provider model and in doing so
he added support for the Google compute
engine provider we've added support for
kubernetes Netflix is added support for
Titus other providers have been added by
other community members but for the
purpose of today's talk the interesting
providers are kubernetes and titus
because they focus entirely on container
based workflows so one thing to mention
here is that whenever we talk about
multi cloud deployment we're not really
saying you can only deploy to one cloud
what we're saying is within the
spinnaker system we enable you to have
more than one cloud enable in the case
of ways they deploy to the Google
compute engine and Amazon Web Services
in the case of Netflix we deployed
through Amazon Web Services and Titus
all the work being deployed to
containers is being done on Titus and
all the work being deployed to VMs is
done to Amazon Web Services and Titus
itself is deployed by us vinegar on to
the Amazon Web Services so like I said
Titus is hosted on AWS it is billed
Netflix kale talks really well to other
tools and systems in a Netflix
infrastructure so if you're familiar
with tools like Eureka or Atlas Titus
was built to talk to have first-class
support for this Titus also is very
aware of all the components of the
Amazon Web service that it sits on top
so it's able to use security constructs
searches I am profiles and security
groups you can also mount things like
ifs volumes on to Titus itself and you
also have things access to resources
such as GPUs that are managed directly
and map to the underlying implementation
running on AWS Titus is able to run both
batch jobs and service jobs so
long-running jobs and one-time jobs and
they're very successful last week alone
they ran over 800,000 containers just in
a week if you're familiar with
kubernetes it's
systems built and designed by Google the
redesign of an internal system called
borg borg is a system inside of google
that runs and schedules pretty much all
of Google services which also run in
containers so it's Google search
calendar Gmail you name it
but countered aboard kubernetes also
runs outside of Google that's on public
clouds and private clouds you can get it
running on a bunch of raspberry finance
if you wanted to it's worth mentioning
that Google has a hosted kubernetes
option called gke that makes it really
easy to get up and running with a
production kubernetes cluster a lot of
what kubernetes does is it simplifies
the operational experience that you'd
expect to run into when you're
scheduling and running your own
containers so it has built-in
co-chairing service discovery auto
healing auto scaling all these things
that might cause headaches if you're
trying to orchestrate and deploy
containers yourself so let's take a look
at that in spinnaker before we get to
the container specific bits let's take a
look at spinnaker at a high level right
here so when you open up spinnaker
you're greeted with this cluster screen
right here and there's a lot of
information here let's take it and break
it down from the bottom up the green
squares you see up there each of those
represents an spinnaker what's called an
instance and the instance is an
abstraction of spinnaker which in Kerber
Nettie's maps to a pod that's just a
group of co-located containers that
together form an application those
instances in spinnaker are grouped
together into server groups and again a
server group whose vinegar is just an
abstraction and kubernetes that the
replica set an amazon that's an ASG and
GC that's a managed instance group and
the important thing to note is that
every single instance in that server
group is running the same exact
application on the same exact
configuration spinnaker groups these
further into clusters we have two
clusters up there demo devs and demo
products you can read that and a cluster
is a group of replicated versioned
server groups and typically you'll have
at most serving traffic at a time at
most one serving traffic at a time and
just like you see out there so for
example here we can click on the server
group to get some more details
we see the docker image that it's
running if you're familiar with
kubernetes you'll recognize this right
here as the resource animal that's
backing the kubernetes resource you can
post the saqib control if you wanted to
to recreate this we have links into the
queue Brunetti qi for example to show
some other information the surface from
the perspective of the kubernetes
cluster and then the spanker UI also
offers a number of remedial tool tips
that you can use to manage things in
case they go wrong so you can click on
the server group and say I want to roll
back to a friar known good version or
you can click on an instance for example
and say you want to terminate it if you
think it's misbehaving and have kerbin
ninety-three scheduled it for you and
what America is doing here is it's
talking to a shared cloud provider
abstraction layer and we're creating a
series of steps against it to get to
some desired end result so this leaves
the question how do you actually use
spinnaker to deploy a new version of
your application and of course you can
go through the UI and click through it
and update your dog or container but we
want to automate this so let's jump
ahead here there's many ways to do this
in spinnaker the canonical example is
the promotion pipeline we're going to go
through how these run and there's three
core steps to it so the first thing you
want to do is you want to deploy your
dog or container to a dev environment
and what the flips you do is confidently
validate that whatever you've built
actually behaves the way you want it to
and that's the second step once you
validated and you're confident you can
for much of reduction that's what you do
you take that same doctor image you
validated and redeploy it inside of a
production cluster so there's many ways
to get a docker container into spinnaker
one way is spinnaker can bake to docker
container for you you can point it out a
git repo where you have a docker file
tell it how to tag the container and
have it do the rest or for the purpose
of this demo here we're going to use an
external docker bakery so same exact
cluster screen we were looking at before
we're going to click on the server group
and have them select with load balancer
tooltip on the production
cluster it has a publicly facing IP so
let's take a look we're serving it says
hello def box with a blue background for
the purpose of this talk here we're
going to try and get that background
color from blue to green so we navigate
back to the pipeline's tab here and see
is the same three steps we mentioned
earlier so we deployed it as we validate
and finally when we're ready we promote
the prod so before we can do this though
we need a docker container that we can
push through these pipelines so Logan
upper text editor we're going to open up
that application that we were looking at
before so we change the color from blue
to green we commit that change and once
that's ready we can push that upstream
and have our docker container builder
pick up on that change for today's talk
we're going to be using a Google
container builder it assumes you have a
git repo that you can point it out so
we've pushed our change we'll open up
our container builder and it has a lot
of nice features we're going to focus on
the basics here you pointed to get repo
like I said you say anytime any chant
any branch changes with a commitment
coming you build using this docker file
what we're doing here is we're tagging
this with the branch name and the commit
sha it's important here to generate a
unique docker tag because if you keep
using the same tag over and over again
will very quickly lose sight of what's
running in your cluster so in this case
the branch name and the commission gives
us a reasonable degree of traceability
so this filter has been kicked off by
now we're going to our build history and
you see the builds already running and
the one thing to look at here is the
image ID that commits Shaw in this case
it starts with the character 16 CV we're
just going to use that for a
verification that we're actually pushing
the right image to these pipelines so
while it's running in the background
let's open up that deploy to dev
pipeline and what was configured years
we've said we're looking at this one
registry and any time a change comes in
on a master branch take that docker
image and put it into this pipelines
execution context
so we're going to deploy that image and
what we've done is we said take an image
from the execution context and use it as
my docker container to deploy you can
configure pretty much anything in this
UI here that you could with that regular
kubernetes resource file but if you
don't like clicking to the UI you can
also import stuff that you already have
running engine cluster so I'm taking a
replica set that I've already deployed
and pretty much again anything that I
could have configured in that resource
file is already imported for you here
into the spinnaker UI
so the docker build usually take a
little while so we're going to skip
ahead until the build completes you see
the deploy to death pipeline just
finished so we're going to navigate over
to the replica set that a deploy for us
we see all 10 of our pods are healthy
and you can read it it says 16c be on
the docker container right there so our
validation sending approval there's all
sorts of validation you can do inside of
spinnaker
we're going to keep it simple we've
template a link to this deployment UI
right here and we're going to pretend
that we're looking at the metrics and
say that they look okay for us so we
continue I want this finishes our
promotion pipelining to do two things so
one needs to find that docker image that
we deployed and that's where we've
deployed in the developer environment in
the in the first pipeline which it did
right here we can see that we found pipe
docker image 16gb and that matches
exactly what that trigger found and the
next step is to take that image and
employed much the way we did before but
this time deploy it into the production
cluster which is what we did right here
if we can take a look at what it
deployed and the end will navigate over
to the load balancer and open up that
publicly facing a team and we can see
that the background color is now green
so we talked a lot about the fact that
there's more to continues delivery the
dist orchestration but the orchestration
does get a little interesting and some
of Spinnaker's deployment strategies
especially in the case of kubernetes
where we can make use of kubernetes
deployment api to handle the updates for
us and
just like you can configure in that
deployment API resource you can say I'm
want to use a rolling update with these
parameters you can configure in the
spinnaker UI and have spinning your hand
off of work to kubernetes to actually
update your replica said I'm more
canonically and for every cloud provider
you can use the spinnaker red-black or
more commonly known as a blue-green
strategies bigger updates and if you're
not familiar with it what it does is
instead of killing instances one by one
and spinning up new ones it spins up a
whole new server group wait for it to be
healthy and then once it is switches
traffic over from the old server group
to the new server group leaving
something like with something like this
with the old server group sitting around
until you want to kill it off for very
fast roll backs in case something goes
wrong and there's benefits to both of
those approaches but they also have some
fall backs so we've talked with this
rolling red-black strategy which we're
implementing which allows you to define
a series of larger percentages in your
rollout and if you're stuck with a
linear rollout strategy and you're very
confident after rolling out the 10% of
your users and it's taking 3 hours you
shouldn't have to wait another 27 hours
to roll it to the next 90% so instead
you can say rollouts faster and faster
as I get more confident I also validated
every stage that what's running inside
of my cluster meets whatever criteria
you you put on it finally because we
chunk the rollout we also lower the
pressure you put on downstream
dependencies as you roll out if you have
a shared cache that you write to one
startup or if you contact service
discovery when you come up red-black
deployment might take those out if you
bring up too many instances at once and
like you'll see here because we keep
around the pool of instances as we roll
out by progressively enabling disabling
more instances in the old server group
and spinning up more instances in the
new server group we again have that pool
of instances ready to roll back at any
time and do that very quickly
thanks large that looks great
I'm here to Tokyo or the Ron job stage
in spinnaker so like I said before
springers pipelines were made on many
stages and the advantage here of the
round row of stage is that we just run a
Doppler container as per our deployment
process so I have a pipeline here what
we're doing here is we're doing a
deployment to Amazon Web Services and
afterwards we just want to run a set of
smoke tests now before this stage became
available we would normally run this as
either a Jenkins job or a script job
however now that we have the power of
containers we can run this set of smoke
tests as as a Jenkins job and there are
several advantages here right so I can
test this locally and if it works I can
then just push it up to the docker
registry and then my code up for the
stage itself is just going to be change
right away I can take advantages of kind
of the flexible resource management so
in case my smoke tests take twice as
much memory to run I can just simply
come into the stage and change you know
the memory allocation provided here you
can also here see here that I take
advantage of Titus's ability to use the
curators from AWS so I just pick a it'll
be a security group and use it at the
bottom it's worth noting that the round
drop stage is available to you both in
Titus and kubernetes so I run this job
and what I see here is links to the
tightest execution that was executed and
you can see that I have the ability to
drill down deeper and look at the SV law
look at the logs of that execution
they're updated to s3 because this set
of smoked has passed that means the
container finish successfully you can
see that the stage is now green and then
I can move on to the next phase so so
far we talked to you about kind of the
mechanics of getting new containers up
and running in the cloud and maybe even
as part of a deployment pipelines one of
the kind of essential design principles
of spinnaker really is to be allow you
to kind of build appointments that are
fairly low risk they're fairly safe and
this is manifested either in ways of
features within kind of the pipeline
execution engine
or as separate stages available in
spinnaker let me give you an example
let's say I have a cluster and I have a
server group in the cluster that is
taking traffic now if the server goes
away there's nothing serving traffic
there's a knowledge right this is bad so
what spinnaker allows you to do is set a
traffic guard and what the traffic guard
is going to do for you is it's going to
protect this last server group take in
traffic so if that traffic arts is
enabled and somebody tries to come in
and disable this last running server
group division occurred is just going to
say no so if you try to run this step
manually you'll see that a trafficker
has been enabled on this last server
group and instead of allowing this step
to go through so what Spirit is going to
do is just going to protect that
resource if you try to run this as part
of a pipeline the pipeline will fail so
that's one of the several safety
features are built within spinnaker and
there are many more and they're
available to you right now if you start
the point your containers using
spinnaker now I don't have really a lot
of time to go through each and every one
of these steps but I do want to
highlight two the last two in this list
automated canary analysis at Netflix is
a technique that allows us to look at
new code and old code and say is this
good like this does pushing this cause
how any sorts of regressions and the
process that is used here is there's a
mathematical model that is used to
compare all the metrics that are coming
out from old code and a new code and if
things are okay the pipeline progresses
if things at any point filled with these
meet this criteria then the pipeline's
automatically finish and then the other
thing I want to highlight is this
practice at Netflix called chaos testing
so in spinnaker you can run what we call
a chaos experiments so what a chaos
experiment does is that it does an
experiment it does a test in production
and what it tries to exercise is the
fallback behavior so for example I can
insert a latency into the test
automatically and make sure that every
time that around my pipeline the scares
experiments get exercised
there's a lot more on that blog post so
if you're interested in learning more
about spinnaker and how that spinner
great enable safety practices in your
container deployments I highly encourage
you to check out the blog post finally
so far we show you a lot of URL likes a
lot of little screens that you're
clicking with your hand but if you're
not there is an API in spinnaker in fact
one of the design principles of
Spinnaker's was really to allow you to
have this API that allows you to talk to
both spinnaker to get a good view of
your cloud state and also to kind of
mutate your cloud state taking in
account all the safety features that are
available to you the nice thing about
the pro your containers are spin up here
today is that all the good tools that
have been developed in the last few
years that talk spinnaker for virtual
machines are now available to you for
containers here's monkey my favorite
tool and Netflix what chaos monkey does
is you set here's monkey up it looks at
a server group and I'm just going to go
terminate a random instance what do we
do this I mean that seems pretty weird
what chaos monkey does is it gives the
developer illness because if you know
that the instances in your server group
are going to disappear at any time
you're going to work harder into
ensuring that the fallback behavior of
your server group works correctly kills
monkey is open source and version 3 of
chaos monkey talks to regulator
spinnaker that means that the moment
that we added Titus and kubernetes
integration now chaos monkey is able to
go in look at your coronary spot and
shoot the pads in the head terminate the
parts are at present metaphor so I hope
this gave you a good case of what the
point containers were spinnaker looks
like we're really excited about
spinnaker we think that it has a lot of
very cool safety features and
and we encourage you to really check out
the spinnaker website you can spin it
out try it out pointer to your grenades
container there's a very active slack
community so you know if you guys want
to join us and have any
questions were there to help and in case
you're interested in working at either
Netflix or Google please come talk to us
we're very happy to answer any questions
that you might have I'd like to open it
up to questions I do want to point out
that Diane over there has a stack of
stickers so if you want spinnaker
stickers Taita stickers they're over
there so and kills monkey stickers so if
you have any questions we're open to
answering right now or you should just
come to the front thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>