<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Turbo Charge CPU Utilization in Fork/Join Using the ManagedBlocker by Heinz Kabutz | Coder Coacher - Coaching Coders</title><meta content="Turbo Charge CPU Utilization in Fork/Join Using the ManagedBlocker by Heinz Kabutz - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Turbo Charge CPU Utilization in Fork/Join Using the ManagedBlocker by Heinz Kabutz</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/12qM3GFnfzI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">work it make it do it make sure and
we're gonna look at at fork/join and how
we can improve our performance slightly
with managed blocker and it sort of
startled fire by showing some cpu graph
this is on my little pen TMI seven
laptop and you can see that I've got it
looks like a four eight cause I don't
really read cause there were four cores
but what happens waiting so it shows it
as eight cores and if you look at the
graph United States is there's quite a
bit of green all right if you're color
blind you've got a problem with these
graphs and there's a little bit of red
very little which is not a bad thing
right not too much rate and but at the
beginning especially on the real cause
which is not to form six there's a fair
amount of black and black means that
we're not fully utilizing the variable
hardware
now up to now we've been getting we've
been very lucky as programmers because
um first of all when I was when I was
younger every two years the process of
speed would double and so you're
automatically the system's automatically
came fast without actually doing any
real work so there's this whole thing of
the doom principle you basically play
doom for two years and by the end of the
two years your program is twice as fast
because all the hard ways twice as fast
don't touch any code but you code
automatically gets faster and and so
that was the principle we used a lot
actually too much we're now Vinod
younger and and in this process of clock
speed of course we reached a sort of
limit day and but they do a lot of
instruction level parallelism and
pipelining and so on and the you know we
had lost performance benefits from that
but we are reaching a limit day too
and unless you're going to buy a quantum
computer with like five million lasers
pointing at you and all sorts of cool
stuff you're going to have to deal with
this at some point I'm really working on
larger problems and so it's getting
multiple to software having to solve
these problems so the problem here is
that are not fully utilizing the cause
and
I put in the managed blocker rather than
this normal blocker and you can see it
at the beginning the the CPU graphs were
not much greener so it's less blackened
for this this was a quite a large
calculation it actually completed also
about 8% faster so we got performance
improvements and we got you know and a
base utilization of edible hardware
now I'm going to show an example that
starts very simply gets more more
complicated as we go through first of
all this is algorithm that you probably
have all heard by now called the
Fibonacci series which we f of
north-north f of 1 is 1 and then the
next number is equal to the two previous
numbers and so the numbers get very
large like if you have interests every
word about the Australian rabbit problem
they had the Civil actually series and
rabbits which was a very big problem now
if you implemented this as a
mathematician you might say well this is
equivalent to that right so let's write
it like this and because Java doesn't
have a decent tail recursion mechanism
it works out if of note over and over
and over again and F of 2 &amp;amp; 3 will just
get many many times so the funny thing
about this algorithm is that the
computational complexity is itself a
Fibonacci series so you basically have
if f of n takes you know one second and
if of in comes one takes one point six
seconds then F of n plus two will take
two point six seconds and and so on and
things get very slow very quickly what
no you can't get slow quickly yes
after very small in it gets it gets slow
and so scarily you'll find this
algorithm actually like this described
or used inside javadocs
so I don't read Java Docs it's bad idea
now if you did an iterative algorithm it
would look like this you remember the
first the previous two numbers and so
you don't have to work out the numbers
over and over again and if you working
out the number on and long you'll be
able to do this in like a second
but the answer won't be correct
because you have a float about to not
see a tea or serving to your server on
the other flood so you could use big
integer but then begin to just an
immutable object so you not a fireball
so it makes new copies every time that
you change it so if you make them if you
can add it's actually a linear operation
according to the size of the number so
if got a linear algorithm not in x the
linear ad gives you quadratic and you
will be able to work out relatively
small numbers like this like maybe
similar if you have a million but you
won't be able to work out from that
Shifa billion it just gets
computationally too difficult even a
million will take a very long time okay
now the third attempt is to take decks
to sum of squares so I've changed the
algorithm and the algorithm now looks
like this F of 2 and minus 1 equals F of
n minus 1 squared plus F of N squared so
if it's an odd number use one variation
if it's an even number use a different
variation and and actually and the the
real algorithm for for calculating the
numbers is the logarithmic algorithm
every time you're dividing it by two
like a binary search M and the
multiplication since Java 8 has improved
significantly it used to be ordained
squared but they now have two different
algorithms either to karatsuba or tomb
cook karatsuba takes you a very big
number and splits it into two parts and
it does some maths magic right something
I don't know that's us and then the
three-way trim cook splits the number to
five segments and again does the more
wizardry to come up with the correct
multiplication so and dividing it into
multiple chunks gives you the
opportunity to paralyze it but they
didn't do that it doesn't it does over
decrease the computational time
complexity this matters there's a big
difference between in ^ 1 5 8 5 and n ^
1.46
5 is a big difference once the numbers
start getting larger now you might want
to either they're always use Tim Cook
well the set up cost is higher so
it takes a bit of time before you start
seeing a difference in performance now
at the moment you begin to just still
single-threaded
in Java 8 it probably stayed that way
for a while but will hack that a little
bit later now I'm going to do a bunch of
demos and the way that I do this is I
every time that I do one demo I commit
it and then at the end of the talk I
push it if you remind me any project
managers here no project managers ok
well then I won't push it
it just won't happen if ludley reminds
me but I'm going to implement this using
using big integer unfortunately we don't
have operator overloading in Java yes
maybe - so maybe drop a 13 or something
we'll have it and but we'll do the first
one and and by the way if I if I if I
try and work up to not see a thousand
with this with this current algorithm I
estimated under the calculation it's
made it's going to take approximately 10
to the path 200 years to complete but
not 200 years 10 to the power of 200
years so it's quite a long time we're
going to do it in like three
milliseconds in a moment M so what we're
going to do is we're going to say first
of all int of 1/2 equals n plus 1/2 then
we're going to say big integer if naught
equals F of 1/2 minus 1 and F of 1 will
be F of 1/2
then I'm going to use if it's an odd
number use the 1 calculation of a sieve
number use the other calculation that
you see over here right so let's do that
if in percentage 2 is 1 then return if
not multiply with F note dot add F 1
multiply 1 so that's F 1 squared plus is
notes great else if it's even then I
other calculational it's multiplier if
not by to heidi x - any guesses shift by
one very good so return if not shift
left by one add f1 to that and multiply
that with f1 so this gives you the same
algorithm that we saw but with big
integer okay and you know the purists
mine amongst you might say why doesn't
he use bit masking here it ends up being
the same compiled code and so let's run
this and see whether what what comes out
we'll just trick something he is that's
correct okay good all right so I've got
as you see
Falacci 1000 calculated in like five
milliseconds and then as a number 50 go
it's it takes more and more time to
complete the reason I'm outputting the
GC is is just to make sure that I'm not
going to that I'm not doing any full GCS
in the middle of my calculation because
they tend to take a bit longer than one
or two milliseconds and they can disturb
the the results or screw them in a
certain direction so after running it
for a while and this remember this is
soon or to 100 million it's a very large
number it comes out with some results
hopefully that's useful today
and come on up only got 40 40 minutes
left so it'll be done okay so it starts
at 46 seconds 46 and a half seconds and
and that's not bad continuing that the
other mechanism so we're not Chi 1000
would have taken came to the 200 years
so this is not a bad result at all um I
thought you asked me before I started
what is this newsletter it's the Java
specialist newsletter you should
subscribe to that end to the performance
tuning newsletter to come at once a
month and sometimes it's interesting
thank you I appreciate that so you your
project management Errol at least and
gifts commits - a and this is demo one
okay now that's the first demo and now
if you run that at the moment everything
is single threaded so um if you run it
then you look at the CPU which will do
once more went not to the end but just
to start and you can see if I run top
that my CPU is sitting at 100% for come
on foot for job 100% sometimes if I'm
slightly hundred percent because you do
have GC events happening in parallel but
most of the time it's just around 100%
because only one thread actually in the
calculation but I've got four cores so I
should be able to do it in parallel and
get better performance that way so let's
do the second approach which is to
paralyze this algorithm of it the idea
is we can take to do this with them with
fork/join and we can say let's let's
work out the F naught in a separate
thread now I'm recursive what we're
doing is something called recursive
decomposition and the focus on framework
is specifically built for that so you
can see here I'm working out F of 1/2 -
1 in a separate possibly a separate task
a forked which would sin might allow it
to start the cipa thread and then then
I'll work on f1 and afters are joined
with the tasks that I created so let's
put this into the code and see if we can
make our speed four times faster and so
we're going to make a recursive task of
big integer I'm a big integer which we
if not task equals new recursive task
it's it's a it's not an anonymous in a
class it's a I mean it's not an
interface it's a class so you can't use
lambdas here and and computes we'll say
return just the code that I've got done
here so moving this code up to the
compute then I say if not task fork and
after I've done f1 I'm going to say if
node equals if node task dot join okay
so before it was wearing a three six
seconds now I would expect it to run it
four times faster ten eleven they live
and a half twelve what about something
like that
sixteen someone it's at sixteen
somebody's a pessimist here don't be so
pessimistic this is performance its
powers everything should be fast okay so
we run it again and this time after
sixteen seconds or twelve seconds it's
going to be finished and it's going to
be much faster and then mmm okay so it's
G seen TC TC and by the way allocation
failure is not something bad it just
means that even is full and it wasn't
able to allocate more memory without
doing it easy now and if you go to the
bottom you notice that an action took 22
seconds so it's it's just run about
twice as fast it's not four times as
fast and we're not started playing with
this I saw this and thought oh maybe I'm
not actually paralyzing properly now
we'll just make a note of this and put
it into our list over here demo - okay
and I'm going to run it again and I'm
going to run it next to top top it I
need to do this once more one second
please stop this I'm going to start at
once more because I want to show you
that initially running out like hundreds
of percent so that's like I'm really are
um using all day to cook all eight
Hardware threads and then after not too
long it goes time to like 400% then down
to two hundred percent and eventually
it's done at hundred percent for the
longest time it's actually 100 percent
and if you if you go back and you do a
thread dump you'll actually see what's
going on here and you'll see that the
only thread is actually doing anything
is a single thread that's main that's
doing a big multiply and the reason is
that this is combining really big
numbers and towards the end what you're
really painful is the last calculation
the last multiplication right and I
mentioned you that the the multiply is
is not parallel so we're ending up you
know Amdahl's law tells us we really
can't optimize this much more okay now
commit before I forget this is demo2
and let's see demo 3 so the demo 3 is to
basically hack up big integer now begins
as a closet works very well but it's not
power so what we can do is we can take
multiplier Tim Cook and square tomb cook
and we can make this into these into
parallel functions now what I'm going to
do is I'm going to copy and paste begin
to from Java math into my project or
actually into different module within my
project with the different license with
the GPL layered license and then I'm
going to to set up my boot class path to
point to the hacked begin to German
class that's my little trickier so let's
do that and when you say boot class box
you can say slash P to prepend my hacked
class to the normal boot class path so
it becomes my official begin to the
class okay let's do that so we're going
to go and first of all go to big integer
the class and now I'm going to teach you
a way in which you can actually program
a huge number of lines for code lines of
code today all right let me show you it
goes like this
control a control C alright and then go
here new press control V and it was
probably like a sales on the 2009 spin
it
very all good I'll get a bonus in a
figure for this and then just to make
sure that I'm actually using this class
I'm going to output here aesthetic
initializer block that says using hacked
big integer just to make sure make sure
using it so when I run this code I'm
going to now here where this this boot
class path we're going to say boot
crossed paths slash P for prepend so my
heck is going to be the first class that
they see before the official Java math
big integer and big and just actually
uses other classes as well but there's a
dependency but we don't care about that
because big integer are B's between the
first one is when the speed plus pause
okay just be careful don't don't ship
code like that to other people
because you're going to violate license
agreements okay now if you run that
yield you'll notice that it's it outputs
here using hacked big integer so we
could it's using our class and now we're
going to hack it so that's the next part
we're going to go to the multiply tomb
cook now I windows in school our photo
was not too bad at mathematics until I
went to university my make the people
who really are good at mathematics and
then I realize actually under very much
at all and when I look at this type of
algorithm I my mind just goes like you
know I don't know what these guys are
doing and you know what it doesn't
actually matter I don't have to
understand this stuff all I need to do
is paralyze it so what I'm going to do
is I'm going to make a multiply task V
naught task equals new multiply task
with a naught comma B naught for self to
construct this class am I going to make
an inner class here with with big
integer a and big integer B and this K
is going to say extends recursive tasks
of big integer like that
and then a and B must be fields and then
I'm going to have my compute function
say return a dot multiplied B right and
I'm going to do something very similar
for the sky task is only that as well
squared tasks and squared tasks will
only be for one big integer of course
cause identity is great too so I just
have to get it to a like that
and here I'm going to say but in
computing Minister a dot a dot square
and square is the function inside begin
to the but it's not public so we can't
call it from outside but it figures out
we doing a screen if does it internally
so there's my screen my multiplier now
if you go back to our other code where
we had this I'll make my V naught tasks
and then say V naught tasks dot fork and
are then instead of doing the V naught
multiplied directly then do some other
work I did a second multiply and before
I do my third multiply I joined and I
say V naught equals V naught tasks join
I still haven't got a clue how this
algorithm actually works I don't need to
know or just need to know how to
paralyze it and then I do the same thing
for v1 I except this time I'm going to
do V one task and V one task and it's
going to be da one and DB DB one
so that's going to be here and I'll do
another multiple the infective five
multiplies I'll does it off to the last
month I'm going to say v1 equals V one
task dot join yeah so basically now
paralyzed the tomb cook algorithm this
is GPL so if you take a photograph test
you need to put that in the license
agreement okay next thing we're going to
look at the square term cook square tomb
cook and square Tim Cook is going to
make a square a task very similar to it
at the Foursquare task V naught task
equals nu square task of eight nodes
and then this is going to be V naught
task dot fork and before I do my third
swear so after the second square before
to the sir it's going to say V naught
equals V naught tasks join and then I do
the same thing for V 1 so we'll say a
square task V 1 task equals nu square
task of DA 1 and then we have to say V 1
task fork and then I'm going to say V 1
equals v1 task dot join okay now did I
make any mistakes maybe see because I've
make mistakes when I do this especially
whilst I'm talking 4/2 code and talk at
the same time and hopefully this works
and hopefully it's going to get us
better performance let me just also run
top are they stop running okay you can
see that the Java process is running hot
so you're running it like you know not
100% but it's running it like all the
cause and it's gone it's all finished so
basically our we've now utilized our
cause fully so that's great that's
fantastic and the performance is
hopefully going to be better and
performance here is 14 seconds so that's
that's that's not too bad I mean we
started a 46 we've added to paralyze a
little bit and now stand to 14 seconds
so that's actually not not bad at all
and we managed to utilize our hardware
fairly effectively as well so that's
also a good thing so let's put this into
our code up here this is demo 3 and test
that's that's not bad and we also want
to of course commit that demo 3 and now
we look at demo for em yeah I've
mentioned the three if you the the
fourth thing we'll want to show you is
in fact we show you something else
before I do that one more thing I want
to show with demo 3 and that is I want
to measure how long it actually takes to
do the multiplications so we get some
idea of what we what we're dealing with
over here and I'll do this I'll say long
time equals now it would be sort of
obvious to say system current remedies
but it's not a good idea why not
and it is why this is a bad idea here
correct it's a system chord it's going
to be too expensive
so we are going to care if n is actually
quite big so if n is bigger than 10,000
for example then we're going to use
system current remedies otherwise you're
going to get a qubit at 0 then I'm going
to say try and finally you're going to
say in time equals if n is bigger than
10,000 then we're going to say system
dot current time Millie's - time
otherwise just keep it at zero and then
if time is bigger than surf example 50
milliseconds we're going to print out F
off whatever it is took percentage a a
pristine at the end
ever since the milliseconds and set it
in common in common time we're going to
see how long each of those took if it's
more than 50 milliseconds less than 50
minutes takes we don't really care
that's a for the hundred million m2
something look at the numbers and see if
you notice anything about the numbers
do you notice anything here yeah so it's
you know first of all they're two things
one thing is it's either 909 or zero
zero zero but that's only because I'm
starting at one hundred billion if I
thought or some other and number it
wouldn't be exactly that but the thing
which which is more important is that
you actually work not the same number
several times all right so if you want
to make this faster you can make it
faster by caching the previous results
but not working a lot over to go into
put into a into a hash map so that's the
that's the demo effective minister
commit this and say demo three with
timing and what we're going to do is
we're going to do this now as demo for
we we actually create a hash map now it
needs to be a concurrent hash not
because multiple three is going to be
putting elements in and take them out we
also need to be careful not to generate
a memory leak we want to not have a
static map rather created on the stack
on created within the method and then
never let it leak after of the method so
no static maps so a couple of things
here now first thing we'll do is we'll
make a new method the new method is
going to have in here a map from integer
to big integer cache and I'll make a
private now I'm going to construct a map
of integer observable integer comma big
integer cash equals new concurrent hash
map you want that one and cash not put 0
comma 0 and cash put 1 comma 1 like so
and then we're going to say return if in
comma cash so we basically returned that
now
and the thing is that inside of if I'm
not actually using that if I'm using
another so a good trick that I use is a
trick that's a bit funny but it does
work well just rename that method and
then you can spot all the places where
you need to use the new method threat
so there's come occasionally it's come a
cache there we go and then you change it
back to just being called if so what I
do is inside my ethnicity to change that
of it as well I need to say up front I'm
going to say big integer result equals
cash dot get off end and if result is
null then I'm going to work out the
actual number to be here and I'm going
to say those things up determinant say
results equals and resolves equals I'm
going to put it into the cash will say
here cash to put in comma result and
then going to say return a part of the
if return the result so I'm going to
basically do something called computer
FAFSA so direct you don't you can't use
computers absent here in India's why you
can't use computers absent
why would computers absent not work
nobody knows I'm not surprised
and not cuz of block threads not because
of that the reason why now it actually
wouldn't actually run it wouldn't run
and the reason is very obscure and not
documented very well at all that you're
not allowed in the if you if you have a
function that generates the the enter
the value for computer of absence that
function is not allowed to change the
map at all and if you do bad things
happen with the normal hash move it
happens to work concurrent hash from if
you get an infinite loop live lock top
situation so and in Java nine then I'll
throw an exception when you do that so
they actually they're specifically code
against that okay so as nice as compute
of absent looks on the outside it's not
usable for this let's run it and see how
we do now the total time hopefully is
going to come down a bit
let's have done something wrong it has
come down so four hundred million we're
now doing it in ten seconds let's demo
for noticing
it's not happening because of the nature
of this particular algorithm all right
because we were dividing by two and that
we dividing the two in two different
directions so it is still a possibility
this can happen but we have actually
saved like 30% of our of our you having
P plus 30% our performance so then
that's not too bad at all this is now
demo 4 so we are getting better and and
we're going to just do commit demo 4
okay so how do we get around it now one
way to do it is to is is with with our
map do not just put the enter in but to
put a placeholder object into the into
the map that sort of sees the result
reservation of I'm going to work this
out so this is one way of doing I'll
show you another way or TalkTalk another
way week later but this is one way we
instead of putting the value in I use a
method called put of absence to put a
special place hold object into the map
and if the result that comes back from
put of absent is null then we were the
first and we can immediately start doing
the calculation if it's something else
then it's a placeholder and we wait
until it's until it's done now I'm going
to show you the like one of the simplest
ways of doing it there you could do a
debate away but this is just a simple
way and it's unlike the actual wait
notifies are nice to be the bottleneck
here so we're not going to be the most
efficient but it will hopefully work ok
so here's what we do is instead of
putting in something called calling gate
we say put if absent in comma reserved
and reserved is going to be a constant
under chronic constant fields going to
be a private final field equals value of
minus a thousand so it's going to be
unique per Fibonacci object so to make
multiple philantropy and also get of
different reserved objects and then
we're going to over here and say if
result is null that stays almost the
same so for rocks odds no we were the
first to actually successfully put
reserved into the map
but if the result is equal to reserved
then we were not the first somebody else
beat us to it
and but they haven't finished doing the
work it but they beat us to it and now
we're going to basically say while
result equals cash get n is equal to
reserve while still city for two
reserved we want to wait until it's
until it's ready so I'm going to just
use a very primitive mechanism here
synchronized reserved and and over here
I'm going to say reserved dot wait so
we're to wait until it's no longer equal
to reserved and then around this I'm
going to put a try try catch dropped it
except to throw new cancellation
exception interrupted for example okay
so this is this will suspend the thread
and wait until the job's done so and
then once I've put it in where say cash
not put I'm going to wrap this as a
synchronized and I'm going to after
putting it into the Cashman if they
reserved dot notify also anybody who
cares about this gets a notification to
say hey some things change now it could
happen that that unrelated threads or
there are ways for different numbers get
woken up but that's it's such a quick
operation to sort of go back to sleep it
doesn't matter and if it does matter
you'll see it inside the thread dump
because Universal threads blocked on the
monitors but I think it's very unlikely
that you'll see that let's run this
again and now you should see every
number only being calculated a single
time right I think that's clear so any
everyone's only so if we look at a 100
million for example same every one is
only once and we've improved up
performance of course you work out less
and you get better performance so we got
down from like 46 seconds with some
caching and stuff down to seven seconds
so that's that's a nice improvement and
let's put this in as well
this is now demo five and demo five now
and if you I'm going to run this once
more this I'm going to do some three
dumps while that's running okay and what
you'll notice is that at the beginning
if you look at the beginning of if you
look at the beginning of the run they
are this is now the this is the dumper
took me the beginning there's work of
seven and six and five are waiting work
of four is working with the threes
waiting wicked twos waiting worker one
is waiting and the main thread is
working so it's basically like was a two
two or three threads actually doing any
work it's like two threads doing work
and the race is sitting around waiting
now the fork joint all the comments of
the Fulton pool concept is built for
parallelism it's not built for for for
for IO based concurrency or former for
any blocking operations so we don't
really want to block when we inside the
the fork current pool now there is this
idea that you can you can optimize this
by telling the fork to and pull when
you're about to start blocking called
the manage blocker
and it's implemented by two classes at
the moment and driver the phaser driver
seven phaser which is a replacement for
countdown match and cyclic barrier and
the second one is completable future
that one also internally uses a managed
blocker let me show you how it works
before do that did I commit that last
bit isn't it okay good so it's committed
that so the next steamer
is due to implement a managed blocker so
that when when the threads are all three
threads are blocked the foreign port is
allowed to construct additional threads
you see when you configure the fork
trample you cannot specify the maximum
number of threads you can specify what's
the desired parallelism Levellers how
many threads do you want to work to have
work at the same time that's the thing
and and and so that really is going to
be pretty close to the number of
Hardware threads in fact the typical
number for the desired parallelism for
the common tool is number of Hardware
threads minus one so my machine have got
eight hardware thread so it says seven
and the reason why it's minus one is
because the main thread is also working
whichever thread does parallel streams
or does fork/join is also going to be
doing calculations so that's why it's
minus one okay now what you can do is
you can give hints to the fork to n tool
that that you're going to start blocking
now you'll be propagated block now and
it allows the fork gruntal to construct
additional threads to keep the
parallelism high so that's what this
does and it gets rid of the the time at
the beginning we've got blackly you're
not actually really parallel let's try
and do that it's it's very easy and all
you need to do is to take this code here
this waiting code and wrap it in a class
so interface so we're going to here make
a private class reserve this court of
reserve blocker implements manage
blocker which lives inside forked rental
it's got two methods block and is
releasable and i was like writing is
reusable first is reasonable against
basically this and there's precondition
over here this is conditional predicate
over here so this is what we call a
conditional predicate
and it's going to be the reverse of that
to basically return that the result is
not equal to reserved so beginning we're
going to call cash gate and that
shouldn't be reserved once it's not
reserved then it's reducible and you can
exit okay so and we need to create
fields for this so we're going to have a
private big integer results we're going
to have the the cash let's make a copy
in pairs of that because it's bit of too
much typing in factors take both of
these and make them field and there we
go so private final int and private
final cash and we make a constructor for
those and in cash and then it's release
but is basically done so we're going to
pass into this constructor the end if we
working out and the cash and it's going
to query the cash and say is this than
equal to reserved yes or no once it's
not equal to reserved then we got it
it'll never go and it will never become
null okay but it could become because
you don't remove entries from there but
it could be it could become the actual
number and then block is going to look
very similar to the this over here it's
going to be basically say inside here
synchronize reserved whilst not is
releasable reserved odd wait and then
once we've done we say return true okay
return true and now if you the way you
use it as inside here we said try we're
going to say
reserved blocker blocker equals new
reserved blocker passing in the end and
the cash we're going to say fourth join
pool dot manage block off the blocker
and blocker dot sorry result equals
blocker dot results get the result from
the blocker now because there's only one
thread reading and writing that's
particular field results we don't need
to make it volatile you can make it if
you if you feel unsafe abut unsure about
it but it doesn't have to be in this
case now for a hundred million you won't
see such a big difference I'm just
telling it because it's it's it can
happen that it's actually seems slower
but if you get to take a bigger number
like 250 million or a million then you
will see it quite a big difference
because at the beginning just naturally
as much thanks yeah at the beginning
there's quite a bit of black inside
inside the run so let's run this again
this demo six and 100 million and and
I'll show you some three dumps in a
moment that will demonstrate this 100
million completed in 6.90 the last two
last two times I'd show this was slower
so I was quite lucky this time but it's
very close with such a small data set
the problem is it doesn't really work if
I'm showing you a demo that takes 10
minutes to run you know we can actually
see the difference right but here we
were lucky it what did actually come
through a bit faster okay so let's write
that down this demo 6 using the using
the manage blocker and I want to also do
one more 3 dump here if you know it
don't need to get some let's do that
again and
three dumped three done what you'll
notice now is at the beginning you're
going to have a whole bunch of other
threads thread names beside besides
naught to seven if what like common for
worker 31 of course you don't want to
have too much of this stuff going on
because constructing thread is a very
very very expensive operation
it takes like a couple of microseconds
to do which for a computer is a very
long time
for us it's a microseconds fast but
computer it's actually quite slow so um
but you see that that it's the Ford was
seven now it's actually up to 31 it's it
could be all sorts of numbers in total
there should be any seven threads really
working at a time maximum but you can
improve your your you use it your
utilization of your of your cause so
that's a little basically most of my
talk I've added one more slide just for
you guys and then homework for you all
right so you seen how you do this with
with them with with fork-join pool and
with Manish blocker you can do something
very similar with completable future the
two methods you need to use for that one
is then accept both async async is
important and complete and together with
those you can actually go and you can
implement the same algorithm that I've
done and it should perform quite
similarly to what what what we got here
there's one little catch with computer
future need to be aware of and that is
what happens if you don't have any call
any threads inside a common foreground
for that's that's one catch and and the
fork/join pool is very peculiar if I've
got I've got eight Hardware threads in
this machine so we're not say women out
we're not going to use we look at the
four point tool and it's a how many
threads you have it tells me I've got
seven threads inside there what do you
think happens if I've got two cores to
Hardware threads in my system how many
what would it say
one correct because two minus one is one
what would it say I only have a single
corn my machine no it will say one and
there will actually be a thread
constructed that will be running inside
the common folk gentle so this so by
default there's always at least one even
if they are there any things want anyone
caught it will have the main thread
running plus the thread inside the fork
gruntal and now when I talk about the
super say to me button who has single
core machines nowadays quite a few
because of all the virtualized machines
they have single cause maybe two cores
and if you turn off the common folk
jumper by saying parallelism equals zero
how many threads will be in the fork
turn four now zero but what will it say
it will say one okay and it true true
true true they will never tell you that
it's zero and the reason is and you will
not promote the leavers but it's true
they are so scared that we are so
idiotic that we're going to get division
by zero errors if they ever tell us a
zero so instead of telling us the truth
that tell us one so in case we make a
mistake now this actually has an effect
on completable future but I won't tell
you what it is you've got to discover
that yourself so here's some homework
for you to do and if you if you go to my
github I'm going this it's in the PDF on
the github or and once your thoughts
send it to me on the links a and we'll
see who gets the best answer first
thank you very much and we've got time
for one or two questions we've got two
minutes and 30 seconds left
it sort of tries to keep it at seven so
what I'll do is it'll if it if it blocks
a thread it will I think it stops and
once once the other if it sees them as
we has taken over so so you know kind of
all of a sudden 103 is running you're
going to have only seven but whilst is
blocked it will contract other threads
to keep it keep it happy if it ok so the
question is with could we just put the
recursive task into the cache yeah you
could do that I've done that I've done
that but um the the problem is that um
you would then have to do a managed
blocker on the join and that does get a
bit tricky
no the joining and so I I have done it a
full summer started with future tasks I
put in the future tasks but the
probability always run in two days is
that if if you want to prevent multiple
from working out the same one whether we
put a few tasks it but then you'd have
to work out gate you have to call gate
on the future tasks and if it's not done
yet it's has to wait for it to be
completed so you end up having to then
you know jump through hoops to try and
do that it's bit difficult there's
another question I'm sort questionably
yes sir
okay so the question is is there any way
to limit how many threads will be
constructed in total within the fork
joint Poland and I don't think there is
there is sort of for safety within
parallel streams but even that's not
completely failsafe because if you if
you've got a good splitter rater that
splits down the middle
always down the middle then it's not
it's not it's not going to construct
more threads at the same time then
number number three two times four
inside the fork drone cool but if you
have a very skewed splitter eight it
could be it could be more you can you
can enter pass out of my mirrors honest
with the managed blocker but you can
also in enough can also get out of
memory errors just with the normal fork
joint but if you don't if you fork too
many times before you joined that's why
I my algorithm and when I was paralyzing
the the the big integer I was I was
always joining before I did another fork
to to help for trunkful to keep the
numbers at seven if you don't do that
you'd end up with far more threads at
the same time one more question a
limiter is
with which remic oh no the questions
have a competitive Kotlin co-routines I
haven't but do you know how they work so
your homework is going to not be
computable future it's English with
cotton carotenes interagency to see the
result actually please be sympathy I'd
love to see it so thank you very much
I'll be here for the rest of today
tomorrow I'm gone so if you want to
speak to me more than welcome to thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>