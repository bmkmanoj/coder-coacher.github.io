<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>OpenShift   the power of Kubernetes for developers by Marek Jelen | Coder Coacher - Coaching Coders</title><meta content="OpenShift   the power of Kubernetes for developers by Marek Jelen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>OpenShift   the power of Kubernetes for developers by Marek Jelen</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7aAKeCfdrNI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning looks like this works re
already alive okay so good morning good
morning welcome how was the party
yesterday
was it good raise your hand we're still
asleep
everybody okay I will try to wake you up
so my name is Marek
this is Erika and we are going to tell
you something about OpenShift today but
before we start I would love to get some
basic idea who is in my audience so
first who is an engineer developer
depart the people who build cool stuff
raise your hand okay most of you who is
operations those are the people who run
the cool stuff and how many managers
those are two people who sew down the
other two groups almost no one okay good
so thanks for the information
the idea is to speak you speak to you
about open chip for developers engineers
so I have mostly engineers here so
that's that's fine let's move a bit and
let's like describe what is the common
problem let me let me face this is my
favorite slide it like describes what
open chip does on the left side you see
what it does for developers on the right
side you see what it tastes for
operations however I will just focus on
the left side where we have service
self-service so if I'm engineer I want
to have easy way to give myself an
environment to surround my application I
want to be able to do something like
push so I want automation I want to be
able to easily with an application in
Java run application in Python do
applications in Ruby that means I want
to be polyglot multi-language platform
and I want to have one platform for
everyone even better if I could have one
thing that will be the same for
production environments as well as
testing so I don't get into it work on
my laptop problem so if I have something
that resembles as much as possible in
the production environment
would be good so this is one of the
basic ideas that we are trying to build
and what we do for that and you see it
in the slender and in the in the title I
mentioned kubernetes and OpenShift so
what's the relation between these two
things open ship is actually kubernetes
it's a distribution of kubernetes that
we do for environments that are
demanding for enterprise customers even
for normal not normal people that's
wrong term but but for people and we
essentially take kubernetes we made it a
distribution we hired on it we do
testing we do verifications and on top
of that we build a developer experience
because who tried kubernetes already
okay so from 44 engineers who enjoyed
using kubernetes almost no because
kubernetes is a tool for operations it's
not - for engineers it helps you with
running containers it helps you to be in
production it helps you to make
applications wrestling and highly
available etcetera etcetera but not
let's not a problem for the engineers
this is the problem for the operations
so if you want to use kubernetes as a
developer you need some other - link you
want to build your container using the
platform you don't want to write the
code files you want to be able to easily
see how my application behaves in that
container I want to be easily accessible
to metrics I want to see what is the
amount of memory my application is using
do I have a memory leak can I see the
locks of my application or maybe if I
have micro services can I see a
application of locks between different
services etc etc so kubernetes itself is
great but it's for operations so that's
one of the things that we do in
OpenShift we build like edit things on
top of kubernetes that provide you the
developer experience for engineers but
before we move there we need to
understand what Linux containers are so
who tried docker ok good right rocket ok
almost no you it doesn't matter really
so dr. is the most popular nowadays but
the idea behind that is the same if I
have a VM I
actually have virtual hardware then I
run my operating system on that my
application is in that operating system
right so I have a kernel and in inside
each VM and each VM is completely
isolated from each other
easy I mean I understand that he has
been here for years but with containers
I have some hardware I hoped my
operating system and I am NOT
virtualizing the hardware to run
multiple operating system I am
virtualizing the operating system to run
multiple applications in isolated
environments inside the same operating
system that means I simply spin up an
application and I put some kernel
fingers around it to make it isolated
from each other so they cannot interfere
they cannot see each other I am in some
special environment so what is the
benefit spinning a container takes
milliseconds compared to seconds with
VMs because I don't have to boot the
whole virtual machine the only thing I
have to do is to create a process and
then isolate it with VMs I need to
create the hardware then I need to spin
up the operating system and I can spin
off my application so the boot time from
like starting to having the application
on it gets longer on the other hand
hardware still have slightly better
isolation especially in Newton
environments if we are providing
something like platform for customers
you don't trust then our virtual
machines may be slightly more secure but
still containers and docker and all the
stuff that we do is still very good and
you can use it for production
environments as well so now if we
understand the sorry now that we
understand what containers are so what
happens if you run openshift is you
deploy something called masters that's
where the brain is that's where all the
scheduling is doing happening and then
you have nodes and nodes is where your
containers run so it's easy you have
notes you run containers you have
masters that's where the scheduling
happens and then you have some edit
features around that that are important
so you have registry so registry cache
is your images when you build a new new
container image it will be not pushed to
doctor
or some other Public Registry it stays
in the platform so it's private so you
don't publish everything that you do
persistent storage who can do like 1250
applications and cloud native
applications who does that
like normal thing at work okay who has
to deal with legacy applications using
persistent storage stateful applications
etc okay most of you so by default
kubernetes has been conceived to run
stateless applications those flight
native Bell factor whatever you want to
call it that's essentially the same but
what we try to do is we try to provide
environment that would also go out to
run stateless stateful applications
using persistent storage running
databases and this kind of stuff inside
a platform an easy way
so that's other thing a service layer
allows you to somehow map things inside
inside the cluster for communication
between different containers we will get
to that in a slide I think the next
slide actually and then there is the
routing player this is the slide after
this next one so I won't get to that
right away so now I'm getting to how
engineers can actually benefit from
using using kubernetes from using
openshift I this is the basic things and
networking this is the thing like I'm
not working with that I am an engineer I
just developed my code and this is
operations problem well in most cases
yes but you can actually benefit from
things some things that the platform can
offer you and it's actually network
related so before we move to debt there
is a basic concept called port and
service so put it's a set of containers
that's just an abstraction of the
container you can think of a boat as a
container just to simplify things and
then you have a service service is a
load balancing proxy if you are
deploying a container inside kubernetes
you should never communicate from a body
to a pod unless you have like very
important reason to do that if you do
communicate between different pods you
should go to the service because the pot
whenever put is started
it is assigned a new IP address whenever
put they started it changes its identity
when container gracious
new container is started completely
identity complete new container so my
application if I'm communicating between
different containers I have to know what
is going to be the IP address of the
next container I have to do some
discovery I have to do something to
figure out where I should connect with
my my database failed and I need to
recollect I have to have the new new
identity of the new container so with
service I simply say I am always going
to this service and the service height
of this complexity for me it is a proxy
and all these reconfigures itself to
send the request to connections to the
correct port behind that so I always go
into service let's table its name it can
be either the IP address or you can use
DNS by discovery so essentially the
service name is always resolvable to the
IP address of the service so I can
simply deploy my SQL to call the service
MySQL and in my host name I will just
say host name MySQL and it's always
resolved to the correct IP address of
the port of the container running
somewhere in the platform and I don't
really get there how it is done the
platform hides all this complexity for
me so that's one of the things the other
thing is whatever you deploy inside the
platform is internal so if I spit up a
new container inside the platform it is
not going to be accessible from outside
I need to create some entry point to be
able to communicate with the service
running inside the platform and for that
there is a router in kubernetes it is
called ingress and the problem is we
needed something like ingress way before
kubernetes decided table to have ingress
so we had implemented routes inside
openshift then we now we are up
streaming everything into ingress with
the goal to actually move to ingress
eventually but like this was the
evolution right there are two different
concepts and so everything that run runs
Indy Indy inside the platform is
isolated from the outside world and you
have to create this kind of route or
ingress that will allow you to access it
this is just the basics that we need to
understand and the last thing is the SDM
so Sdn is the networking configuration
that says how my pots how my containers
inside the network and communicate with
each other I have different ways how to
configure that and I don't want to go
into the details but if I do the basic
one it says every project which is
essentially a namespace in kubernetes
has its own VX lab so every whatever I
deploy in one project is not accessible
from Project from other project from
from containers in other project so
everything is isolated inside that
project how I say as a developer can
benefit from that let's say I'm
developing an application and the
application needs to be sure that the
communication is always accessible only
through some specific points right and
if I'm deploying it on my local network
I can communicate from wherever I want
to wherever I want so I sometimes it
happens to me I don't figure out later
the communication was going through some
other route and I was expecting through
some entry point of my system right so
if I do that and I know that I always
can isolate my my services inside the
projects I know that every the only way
how to communicate between two different
projects is the entry point created
using the route and I know that I have
the I know that my service always sends
it to the correct place I have a very
easy way how to simulate an environment
where I have two services running in
completely isolated networks and I can
test that the communication actually
happens in the way I'm expecting okay
okay that has been a bit more technical
but it's fine what is coming in the in
the next version is the network policy
which will allow you to actually say
this specific container can communicate
with this specific container but any
other container can't do that right so I
can specifically say who can communicate
with whom and in which direction so this
is going to be cool but it's not yet
there
but it's coming so let's move to the
things that you will probably be more
interested in and it's building and
deploying applications so so what is
possible to do is to deploy applications
either from source code from a binary
file or from a container image if I am
using kubernetes I can do the last one I
can build my container I have a doctor
file about my my container I push it to
the doctor hub or somewhere some
registry and then I can deploy it that's
it
right but we add the other two features
so if you have already some pipeline you
have Jenkins teamcity
or something in place you can say you
can build your your voir file your ER
file something whatever I using using
that pipeline and then you can tell
OpenShift to build me a container that
is using this word file and it's
configured for running wildfly or
something like that so I can move the
build of the container inside the
platform and I can have something
produce my applied binary artifacts that
I will be just placing into the
containers using the platform however if
you want to take it one more step you
can actually say build me a container
from my source code and we have
something called as 2i which I will be
speaking about which allows you to say I
have my source code I use this image to
build me a new image essentially I have
my source code for java application use
this image for building java
applications using maven and i will get
a new container that will have multiply
or something
it was EAP last wish something it will
get the result of the process the build
process which will be devour your file
and it will all happen inside the
platform that's what your guys going to
show you in during his demo one more
step so the other thing is I can change
my my development a bit openshift can be
easily deployed
so I can have a local deployment running
on my machine using something called
mini shift if you have a minute mini
cube it's very similar it's a tool that
connects to your hypervisor it creates a
single VM on your machine and it places
the whole cluster inside that p.m. so
you have single node all in one cluster
running on your machine with Java you
need a bit more memory but if you're
doing something like Python or Ruby you
can easily do with 2 gigabytes VMs and
run the whole process with that it's
quite easy so what I can do is like I
can create I can think of my project
like a bootstrap my project and I start
developing and I can test locally using
containers using the platform directly
on my machine I can verify everything's
ok I can do the containers inside the
platform and then when I'm ok with that
I can get push and I can trigger a
pipeline in OpenShift or somewhere and I
can build my container inside the
platform that will can that can then go
through some validations testing as a
graph so I can actually have the very
similar or actually the same environment
running on my machine as will be Indian
in the production because the container
will be pretty much reproducible between
these different environments and just
based on the input of the of the source
code and and the Builder image so the
source to image how it works is I have a
developer he creates a code gets it puts
it into git repository and then I
trigger the build itself
so the s2i builder will figure out what
is the image the image is very easy it
requires you to have actually two shell
scripts or two executables inside a
container which is assemble at the build
process and there is a run which is the
startup process how to boot up the
application and then you can have
everything like a container for building
COBOL or something if you want to
so from image registry we pull one of
those containers and are configured for
building that particular technology and
then it runs the build process
when the build process finishes it
configures the container to be able to
boot up and the run script is set as a
entry point for that container so when I
spin up the container
I actually spin up the application using
the run script and this is pushed again
into the into the registry and when the
register vendor when I have a deployment
hook configured to monitor some kind of
namespace in registry I can
automatically trigger a deployment etc
but that's its other step I will end up
with image image registry so for for for
example VAT fly as 2i image what happens
is we pull the source code we run maven
build with the profile OpenShift
when the Warfel ER voucher file is
produced it's moved in to the
deployments directory of the of the
world fly and then we run multi
standalone to spin up the application
server itself if you use JBoss EAP which
is the container platform the product we
have integration with openshift so
essentially if you spin up one instance
of application like that it will be a
standalone JBoss however about SQL I
shall start scaling the application it
will start configuring cluster for you
so it will build something like a domain
if I understand it correctly and it will
automatically do everything for you so
you can start with container and then
scale up into the cluster just by
clicking buttons in the end of app
interface and now your guys going to
show you something how to do this in
practice thank you Mike
so I will do a very quick demo there are
three ideas behind them all first to
show you this process in practice so
basically what what I'm going to do and
it's not going to be all the steps are
not going to be clearly visible because
obviously stylize it so I will do a demo
with our fuse integration services as
integration platform so I'm going to
take some logic like integration logic
from from gate I'm going to build the
image which
because his Java is going to involve a
lot of Navin stuff right so this is
going to build the image which contains
Charles from maven it contains the
integration logic which is somewhere
which is the code which is the trilogy
itself and all the underlying stuff
including the things which are necessary
for run bits integration service and I'm
going to end up with a kind of like
service which expose the REST API and
this is going to be deployed in
openshift right so the idea is to little
bit actually demonstrate this one second
one introduce very quickly what kind of
integration platform we have and third
and it's quite nice I'm going to run
this entire stuff in the browser because
we have nice like learning interface
something which you can access without
registration without anything you can
actually spin up your own openshift and
do something in it right so it's just
URL I will show you at the end at the
end something you can use at home so
basically I will demonstrate something
you can run at home or run at your
laptop in a browser and just like
demonstrate how it works so let me
switch to this one I want to make sure
can you guys in the really back can you
see the letters in here raise the hand
if you can't raise their hand if you
can't ok the two at the very end so let
me try to it to better it's good right
so this is our learn think we just
introduced with open shift is as I said
it's a very simple thing so it all runs
in browser you just access the URL and
what you actually get is the console for
openshift and there is a kind of
assignment or actually kind of like
workshop you can go through contains a
couple of steps this one is particularly
for queues on views I will try to
refresh it because you have like 60
minutes when their environment is alive
because it just in browser session so
every time every 60 minutes it actually
does so have 60 minutes to complete this
this exercise looks like it works hopes
going to work
it worked yesterday in the bar so should
work to baseball
so so this is the fifth scenario so I
have my console from openshift as Marek
most probably mentioned you can access
or convey a console or evap interface so
this is the console with the openshift
so what I'm going to do I'm going to use
this command so basically I login as the
developer user I can create a new
project so I will basically create a new
project which is called fuse lab which
is going to happen hopefully right so
the project is created and I can create
new apps which are going to be part of
the project the project is kind of
namespace by the apps actually live so
let me continue to the next step okay
the second one so this is a bit longer
one something I'm going to use to create
a new app how do I create a new app I
basically define a URL of the git repo
with the Yahoo right so the Yamal
contains the template is a kind of
recipe how this actually should be built
so how should you know it creates all
the necessary artifacts and openshift
which are needed for being able to run
my service alright so I just click it so
oops your did it failed no it's fine
you did it already before so when you do
it again it authorizes clean it twice
right so I did it before
right here so what happened I created a
route that's the way how I'm going to
access the service I created the service
itself
I created definition which images are
going to be used and Bill config and the
problem and config these are the things
which are necessary which define how the
whole thing is going to be built and
deployed later on right ok so I'm good
and next next step I'm going to start
the build itself right so I click OSI
start build and it starts building the
actual service right I can actually lock
in my web interface just to have a look
what happens here I
so this is the very similar view my
project fuse lab I'm going to look into
it I see there is this bill happening
right I open it and let me know it's
just like okay I open it I see the build
is happening so that you spin up the
container where the whole thing is being
built right so as you see you can see
down here maybe I will just open the
locks in the console because that's kind
of like a good practice right so what's
happening now as you can see we are
running the internet because it runs
maven right so we need all the charts
which are which are which are needed for
my service this is going to take like
two minutes before this all these
dependencies get unloaded so let me use
this opportunity to explain what fuse
actually is right
who knows fuse it who knows camel camel
should be better right
so fuse of course fuses our integration
platform in case of open shift we call
it fuse integration services but
contains very much the same technologies
as the original fuse it's based on camel
so the actual the most important part
where you actually build the integration
logic is camel camel is it's kind of
like open the facto standard for
integration in the open source world I
would say it's a kind of framework where
you can define your integration patterns
you can define transformation so
basically what very simply explain what
camel does you say something like from
my rest service to a database with this
address right you use a DSL to define
something like this or you can use the
graphical editor what happens anytime
that actual there is a put on this rest
web server like this rest service a
record is going to be propagated or like
it's going to be store in the database
and you can define transformations and
all these kind of things so this is what
KML das right
we use of course the camel is a java
thing so it needs a container so we run
Kimmel in EAP or cutoff or spring boot
right and because if you run your
integration cluster you need kind of
messaging we use MQ for that so MQ is is
the messaging part so these are the
important things right
normally one if it's being run on plan
view scarf and fabric to actually manage
the deployments and stuff if this runs
in containers and runs on OpenShift
which is this case the case one we call
it fuse integration services then we
actually let open shift to manage the
whole thing so the continent the
OpenShift is responsible for actually
deploying the integration logic and
clustering it and make sure it's a H a
and cetera right so that's being done on
a container level which actually
simplifies the whole thing a lot so so
briefly about few about fuse integration
services let's look what happen here
right so what happens my image was
successfully built right so I got all
the dependencies the maven dependencies
I built the image which contains Java a
container
sure here is there's the container in
this case is spring boot it contains all
the necessary dependencies which are
related to my restful service it concept
the integration logic a camera route
which says from my rest service to a
different end different endpoint right
so the image is done and it's
successfully uploaded to the repository
and hopefully there should be a port
running as well because as I started to
build it actually creates the port as
well right so this is the part
containing the service and actually
where fuse is running I can open it
ICU is support it's running it is an IP
address right there is this image which
is built from it's actually has a kind
of readiness of liveness Pro
because I want to make sure I want to
define I want to define how do I make
sure that the container is running and
ready right so in this case I say my my
lightness probe is that there is a
service running on certain port right in
this case so okay so I went mostly
through all these steps so that already
happened that's good so what I do now I
will open the the console which is a
console fuse where I can actually see
all these in routes and the integration
ology so let's open it
as you see I'm going through the
tutorial at the same time because there
is a useful stuff you can do there so
it's opening the fuse console ok so once
it loads will see slower than yesterday
in bar they have obviously faster
connection than here so I will try to
open something like route diagram hopes
going to open yeah I did
so the route diagram defines just what I
said like now it's bigger so I cannot
see okay so this is what I said from the
rest if I get a get for user and there
is user ID I will execute this route
which means I will return
I had an identification of the user
right that's exactly what I'm going to
do so okay let me go back here right so
let's go to the terminal and I'm going
to curl this URL where the service is
actually running so let me do this so
okay so what I did I did a query where I
said give me service slash user slash
one two three which is the user
identification and it's returns okay
this is the user I can do a couple of
other stuff as well so by the way if I
go to my console and I open the console
again
I actually see that the certain route
was was actually used right so if I look
this user ID route was actually years
there was a certain time it took to
process it and if I look at the route
diagram I see that this one was actually
used and the the beam because actually
the user is actually being I mean like
the reply goes by a beam I see there was
a one query and I got a kind of Ripley
so I can get another users like Donald
Duck and these guys I can do also like
find all methods so actually it's a
classic micro service which returns JSON
which contains records right of course I
can do also something like a create a
actually user so I can do like put so I
can do okay let me create let's use of
Christine because Christine does her
demo so she should get her credit as
well and yeah and that's that's it so
this is kind of the very simple micro
service which I've created I've created
it so that they actually I used fuse to
define there is this restful service
which contains record user and I let the
fuse to wrap kind of been actually and
create this kind of restful service so
last an important thing usually even
comes to my like services what people
ask is a swagger so of course fuse
tonight something like the swagger
documentation for my service so what I
can do here is sorry I make it smaller
because okay so I can do here I can
actually list my swagger documentation
for my service and I can see is a
classic restful thing which contains a
certain structure there are methods and
everything is documented by swagger so
okay that's it's mainly it so that's how
the actual demo look like you can try it
yourself
just go to just a second I lost my
cursor oops
no switch okay now so you can actually
go to this URL and you can try it
yourself there are many other things you
can build your application I think you
can build application with the database
etc there's a couple of other things you
can try with OpenShift always is just
you open the browser it spins up the
console spins up the actual web
interface you go through a couple of
steps you execute commands you do
something you build your application
it's very nice to try very nice to play
with
before I hand this back to Marek let me
mention that what I've shown like the
way how the integration thing was built
the way how the I build is the service
this is very similar approach which we
use with the rest of the Chivas maneuver
so the same way as I build the
integration route kind of integration
logic I can for example build a business
rule business process right for
messaging if I have a messaging setup
it's very much the same same thing
alright so this is general the approach
way I can actually build a back-end for
mobile for mobile applications etc
alright so it is very much the same
approach we use with all the middleware
so this is the way how this how you can
actually very simply take your artifact
something you develop doesn't matter if
it's the integration route if it's a
business process or business rule give
it to openshift in a gate and say like
build me the entire thing for I mean
like build the entire thing for me right
so good I think I'm good so Marek okay
thank you thank you for demo it was
great
I think I can hear myself so that's good
so there is way more things that you can
deploy on point shift and it doesn't
have to be only Java you can deploy Ruby
Python petal whatever language you are
comfortable with and all of them do
follow pretty much the same workflow you
just say this is my git repo the
built-in your container and then deploy
me the container and
so the same workflow and all these
things can run for you and like this is
just a small subset right you can also
go to the car hub and essentially take
any docker image that's there and write
yourself the only problem is that on
docker hub most of the containers
require to run as root we by default
disable the ability to run as root
because it's not safe and so a sin so if
you are building your own container this
is like a good practice always try to
switch the effective user when you spin
up a container to some normal user and
them being a root and unfortunately if
you want to run most of the containers
on the crop you need to lower the
security settings we have in openshift
right in cube it's okay and open if we
put the security a bit higher so if you
want to do if you want to for example I
think around don't get from directly
from from the hub you would need to say
I am ok with this platform running
container let run as root that's
essentially it
I'm just just right right right there oh
ok ok good so on the other hand you can
deploy also many other things and we
separate these two things into two
different groups and it's what we
support and what we test and verify
right so if you want to run Springwood
if you want to write things from netflix
OSS just tested and verified so we made
sure it works actually but if you want
to run something that we will be
supporting you with as a as a company
then there are some other some other
technologies so for reactive stuff epics
black text there has been several dogs
here around it one fly support for micro
services JBoss etc and whatever you need
and as I mentioned micro services
already have you heard about Sto ok have
you heard about micro services ok so
there are some still is a framework that
should help you with doing like running
micro services and simplify things for
it it's a way it's something like
Netflix OSS
so what everybody's familiar with F is
OSS right no really it works
okay so Netflix has been one of the
biggest popularize eaters of of
microservices right so they built a lot
of stuff for running micro services in
the environment they open source these
projects there's a circuit breaker there
is a deployment tool there is a looking
to there's a monitoring tool there's a
lot of tools that you can utilize so
these things do a lot of things for you
but they're essentially they move the
problem into the user space so you as an
engineer you need to understand all
those tools you need to manage them you
need to configure them and they live as
part of your application
it still is trying to do it slightly
different way it tries to move all these
things that you have to do but put them
on the infrastructure level
so essentially sacred breaking like if I
am calling application application a
cause application because application
seekers application D which is
completely normal in micro services work
what if one of those calls fails all of
them has to fail and somebody has to
make sure that it's failing or do some
resurrection like say this application
is not healthy anymore a deployment a
container do all those those things so
this is something that can be that done
on the infrastructure level doesn't have
to be on the application user level so
this is the things that you usually have
to do or handle when you are doing micro
services you need to have the visibility
and reporting you have to see what's
failing to be able to keep the
applications healthy to keep the
ecosystem healthy you need to be
resilient fuller and you need to set up
parenting and control the traffic
because only some services should be
able to cause some other services you
need to make sure there is some
authorization there are identity of the
services you control who is calling who
what what data has been processed
between different different endpoints
and essentially all these things are
implementing using Sto so what is the
goal of the project is to essentially
implement all this and put it directly
into the platform so usually you would
have application calling the service
sending the data to some other
application and the application would be
responsible for checking its health side
checking that everything's fine reacting
to problems etc if you deploy deploy Sto
you essentially although the whole data
plane the whole communications thing is
put into the infrastructure so you don't
call a service of service a doesn't call
service B you call service a cause steel
which some house redirects the
communication to the service be based
identity security measure all the
profiles and routing so all of this is
handled by D by D by D platform and your
application can be pretty dumb in this
in this regard and the platform is
handling all these things for you and
you're just the operator of the platform
make sense so this is something that's
coming that will be available in
foreseeable future hopefully even in the
kubernetes level it's still open
something release so it's like very much
in development but it's something pretty
cool because with this theory odigo is
let people not to bother themselves is
so much with distributed system as they
have to when you are building micro
services architectures and the last part
is looking in metrics so by default or
usually what we see is that developers
don't have access to those information
so you build your application you give
it to operations and you have no insight
into what's happening in the in the in
the runtime right
so with openshift again we have some
integration with for logging and for
metrics algÃºn gives you on logging
that's what easy showed that was
directly in the in the platform but if
you want to put it on another level we
use fluent d to stream all the logs from
the nodes from the containers what what
is being produced there is another thing
if you're building containers
you should always default to using STD
out as the logging endpoint right
because it's very easy to scrape for for
all the other integration systems if you
are looking to files it's more difficult
to
extracted logs from the containers if
you are looking to STD out it's very
easy to scrape and send somewhere else
so that's what we that's what we do we
sent all those to elasticsearch and then
as part of the platform is Cabana which
you can use to curate all these all
these all these logs and essentially can
create all the projects that you have
access to so you can do correlations
between log messages between different
projects if you have access to those
projects right so you can do all of
analysis what's happening there and what
might be the potential problem of your
application on the metric side we use
hipster to scrape the information then
it's hard to hook your which is our
aggregation system all the information
is being stored in Cassandra and then we
exposed all the information in two
different different ways to the user and
all of these things essential exhale
Iran s containers on the platform so if
you deploy to logging
if you deploy the metrics it will be
running as a container on top of the
platform s easy used the entry point
there was a URL so this the router is
actually a container running H a proxy
directly on the platform so everything
that's possible we try to dogfood and
put direct on the platform so it's
managed by kubernetes by openshift and
it's highly available and resilient so
this is the metrics what it looks like
when you have it deployed you actually
see how much memory how much CPU and how
much network is being used in the pot
and then you have chance
what is the development so if you have a
problem with memory you should be able
to see that my memory is growing and
directly integrated in the platform so I
can easily identify there is a memory
leak or something like it in my
application and that's it thank you for
coming I know it was 9 a.m. in the
morning after the party so that's
challenging though if you have any
questions feel free to ask and we will
be if you are shy to ask over here we
will be here so feel free to come to us
and we will be super happy
to answer your questions as well and I
would like to thank two usually as well
for joining me today thank you
and the last thing I would like to add
try arcade or disappeared Friday they
learn that oppa she does come what it's
coming again oh yeah it's great
so try to learn that open shooters come
you can't write a lot of stuff just from
your browsers so I definitely recommend
to play with it thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>