<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How Google DeepMind conquered the game of Go by Roy van Rijn | Coder Coacher - Coaching Coders</title><meta content="How Google DeepMind conquered the game of Go by Roy van Rijn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How Google DeepMind conquered the game of Go by Roy van Rijn</b></h2><h5 class="post__date">2016-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/derC33ODrME" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello let's do the fan cut he's always
at the top of the rating so maybe this
is it we don't know we'll find out what
is this this is the logo of goda
programming language if you are here for
go-to programming language you can leave
because that's not what I'm talking
about what am I going to talk about so
list and go obviously we'll start with a
very simple game and using this simple
game I'm going to introduce you to three
search minimax and then we move on to a
more complex game knots and crosses and
we're going to talk about perfect
information and game theory then we move
up to a bit more complex game and then
we need to do forward and backwards
pruning and then finally we move to go
and then we can forget everything I
taught you
because all these techniques don't work
and go spoiler oh now I have to do the
voice I want to play okay so the game
we're starting with is a very simple
game we take a tree you can always start
and one with high score wins so oh
there's a jigsaw reference that's
chicks'll so we start do we go left or
right go left left because left is
higher than five higher than three so we
start do we go left or right
and suddenly it is a trivial anymore um
yeah
for us you can say well let's go towards
the nine but yeah there's also two there
but so how would you solve this turns
out there's a very simple algorithm you
can use and it's called minimax in
minimax you try to minimize the maximum
score if it's the opponent's turn and
you try to maximize the minimum score
when it's our turn and this is basically
perfect play so in this game um both me
and the other player we know the outcome
we know there's three to five or ninety
two to six eight four and one
so there's perfect information both
players know everything based on that
you can do a minimax search and we do
minimax you always start at the bottom
so the bottom is our turn and we can
just pick the highest because we want to
maximize our score obviously we want to
win then we move one layer up and we
move one layer up the opponent will
obviously pick the lower score and we
will pick a higher score so if you write
the minimax three out we'll end up with
five and that's the best we can do if
the opponent plays perfectly and we play
perfectly we'll always end up at five
if the opponent makes a mistake for
example if you go to five and your bonus
s9 yeah we'll go to nine obviously but
given perfect information you'll end up
at five today I actually wrote the code
so now I have Java code to show and how
does it work this is a recursive methods
minimax the node is the initial node of
the tree and you need to say if you're
minimizing or maximizing so we entered
methods and if the nodes in EndNote we
evaluate so we look at the score and we
can just return the number so we go down
we fight the five will return the five
if it's not an EndNote and first we
initialize a best score variable and we
start at both ends of infinity then we
loop over each child we calculate the
score by doing a recursive call and if
we are maximizing we call max if we're
minimizing we call min and we turn the
score so to solve the the simple three
game this is basically all you need this
is very simple you can just walk a tree
calculate min and Max and that's the
entire algorithm this is just an example
game we'll we'll go into more advanced
games so in our simple tree game there
are some statistics we've got a
branching factor of two because at each
point we split into two the entire depth
of this game is three we go 3d and we
have perfect information both players
know the outcome of the evaluation so if
you want to write code that can play a
game any game basically these are the
ingredients you need a way to generate
all the moves so in our three base gave
it simple we have the three that are all
the moves if you want to write a chess
engine you need the fuel try to chess AI
you'll need a chess engine that can
generate all that it mean for you and
from those moves you get a treat because
after each move you'll get new moves you
get new moves and eventually someone
will win or lose the same thing you need
is to be very wait a note if you
evaluate all the way down there's always
a winner or loser or a tie so that's
easy but if a game becomes too large
like for example chess you need to stop
halfway and you need to give a value to
the note who's ahead are we winning or
are we losing
first thing we need is yeah basically to
pick up off and that's the AI part so
that's it we're done like five minutes
in the top and we can stop here these
are all the ingredients so how do you
apply this to a more complex game for
example knots and crosses but knots and
crosses for some reason in Dutch it's
called butter cheese and eggs which
makes no sense at all because it's three
options butter cheese and eggs and it
has nothing to do with enough or across
but okay if we would draw the notes of
the three of butter cheese and eggs this
is what you end up with you start with
an empty board and then there are nine
choices so in this case the X cross
starts first and you can place it in
nine different positions and below that
there's an not being placed and there
are eight options for each note and yeah
basically I've ran out of space it's
impossible to draw the entire tree but a
computer can it's not hard for a
computer to generate this entire tree if
you're like really smart and you want to
shout stuff like oh but putting it in
that corner is the same as that corner
it's just a rotation and that's a mirror
we'll come to that so when we evaluate
all the way to the bottom what do we do
well we either win tie or lose we can
assign a value of 1 0 or minus 1 pretty
simple if we now apply minimax the game
is solved you can always perfectly play
this game and it's the same code I
showed before
that's minimax so some statistics
this game has a larger branch factor on
average it's 5 it's not entirely 5 but
at first node you have nine choices then
there are just ate dinner 76 on average
your branch out by 5
the game depth there's a maximum of nine
moves the board is filled at then I move
so that's when the game ends and if you
would remove all the symmetries I was
talking about
there are 138 terminal positions
interestingly and the one that starts
wins in 91 of those cases there are 44
times where the other player wins and
there are just three draws but what
happens if you apply minimax you'll end
up with the draw so if you play knots
and crosses perfectly you always get a
tie which is weird because it's like of
all the terminal positions just three
end up in a tile but moving on to a more
complex game the noble game of chess if
you draw the tree for chess it's already
a bit more complicated
um there's you start with an empty board
well not an ends board but all the
positions starting positions and there
are 1 2 3 4
I've got a table there are so adept 0
you have just one node it's the starting
position after one move there are 20
nodes so there in chess there are 20
initial move you can make at depth to
the other player also has 20 options so
you're instantly at 400 nodes you can
see after that 3 4 5 6
after just 6 moves the tree is getting
pretty large and this is going to be a
problem in chess because chess doesn't
normally stop after 6 move it's possible
because you can check mate someone in
four moves or actually in 3 moves that
before there are eight possible
checkmate
I didn't know that but the table says
these tables are super variable I wrote
a test engine once to write the chess AI
and the
tables are used for two ways the first
one is to generate all moves and when
you start writing a chess engine and you
run you can easily burn this just
generate all moves from those moves
generate all moves and if you're lucky
after six move you end up with 119
million 60,000 324 but when I did it I
ended up with 119 million 60,000 322
that sucks you know there's a bug
somewhere but but but it's perfect it's
a very good way to unit test into five
bucks in your in your engine if you and
also you can see the captures there's
there are ample some rules gosling and
promotions and checks it there are all
kinds of different initial starting
values for these kinds of births tables
they're called birthed because the
second way to use this is for
performance um if you write a chess
engine you want to write fast yes engine
mine wasn't because mine was kind of
crappy in in Java
um but people are bragging so at depth
six my chess engine did that in four
minutes and just generate old notes but
these are super valuable you can use
these tables as unit tests to verify if
you apply all the rules correctly you
find out the corner cases and just
basically to measure performance as well
so what's the problem with chess there's
no more perfect information it's
impossible to calculate all the
positions go to the ends see who's won
because the number of combinations is
mind blowing large but luckily so the
question is how do we evaluate a note
because now we can compute to the end we
have to stop halfway and evaluate but
luckily chess has
is a simple way to be very wet a note
you can for example just count the
pieces if you lost the Queen you're
probably not a head also and if you're
tight you can look at the peace
positions and the liberties your pieces
have so there are for example if your
chess pieces are in the center it's
probably better than if you're on the
corner so writing an evaluation function
for chess isn't that hard to make a
faster chess engine or a better chess AI
you need to do pruning Smulian for the
Dutch people so basically we need to cut
back to three so we need to ditch nodes
there are two kinds of pruning you have
forward pruning
I'll come back to that which is risky
and you have backwards pruning which is
a mathematical way to prune and it's
completely safe which I find is you get
it for free so what do we mean by
forward pruning if a move is too bad
just stop evaluating if you do a move
and the opponent captures your queen
early in the game it doesn't make sense
to look at everything that's below that
because you're not going to play that
move you're not the idiot the other way
around if a move is too good it's
probably not going to happen the
opponent isn't going to randomly
sacrifice his or her queen for example
so let's not calculate below that but
like I said pruning is risky
it's risky because there's always an
ERISA problem if you decide to stop
evaluating maybe sacrificing a queen
sounds stupid but maybe the next move is
a checkmate for you it happens but you
will never find it because you didn't
search any further so aggressive pruning
in chess is very important but don't be
too aggressive because you might miss
obvious things that are just behind the
horizon there's a different way to do
pruning and this is the mathematical
safe way of the to do pruning and you
don't have any problems with your
horizon problem for example we're
somewhere in a chess game and this is
the tree and we evaluate we have the min
and Max move and we end up with at 3 3
is just a random number higher is still
better so we continue and we find a 5 5
is better so we want to play that move
it gets promoted up now we go down and
we find a 9 9 is even better move but we
can stop here why can we stop because we
are they head of five and that's
minimizing move the opponent sees a nine
there he will never pick that 9 you
always go towards the 5 so what can
happen in the other nodes if it's higher
than a 9 the 9 will get promoted up
because you're maximizing but it will
never replace that 5 that 5 is stuck
there what happens if it's lower than a
9 if it's a 2
well we want to maximize our move so if
there's a 9 82 we won't pick the 2 we'll
pick the 9 so the 9 is stuck there
you'll never go lower than the 9 you
only get higher but because there's a 5
above it
so you can basically safely stop be very
waiting this because it doesn't matter
and it works the other way around as
well so for example now the min and Max
have been switched we are picking the
highest number and there's a 3 there and
it doesn't matter what happens if it
gets lower will still pick a 5 if it
gets higher it doesn't get picked
it doesn't override the 3 code yeah this
is the minimax and this is the same
minimax but I hid some stuff um and I
call it alphabet because yeah that's
what we're doing we do an offer better
search so what we need off I'm better
obviously so what we do we call methods
and we enter alpha and beta offer better
or infinity and negative infinity and we
evaluate the notes just like we're doing
in minimax
but next to we when we calculate score
we also update our alpha and beta alpha
our alpha is the series correctly the
you pick the max so alpha gets larger
alpha is the lowest lower threshold
better is the higher treasure it's bad
that it comes down off it goes up and
you can basically guess what's B this if
you cross a certain threshold you can
stop evaluating but basically we're
doing the same as we were doing before
we're doing this and it just takes three
lines of code to do this so now you can
write a chess engine and emit and well
if you have a chess engine that's pretty
hard but if you have a chess engine
writing a chess a is very simple it's
just this life of code this is a go
this is basically at si I and it's a
pretty good one and if your test engine
is fast enough it it will probably beat
me because I'm a bad chess player so
it's not hard to do game AI so back to
chess chess has an average branch factor
of 35 so on average when you take a
chess board you can do 35 different
moves which is already a lot more than
not two crosses both Kasana header also
um this game doesn't stop after nine
moves but usually 40 to 50 moves so the
game tree is much larger and we've
already seen it's too large to compute
because it's 35 35 times 45 death 50
times in a row the good thing is writing
an evaluation function for chess is
pretty easy just count pieces look at
some board positions even having it that
simple you can beat a professional chess
player it's that easy
and if you have a Radiothon chess ai you
can do 20-plus moves ahead with some
aggressive pruning and that's more than
enough to beat a professional so chess
has been solved computers are just
better so now we take the final leap to
the more complex game of Go and it looks
very similar for you for those who have
never played go there's a 19 by 90 board
there are black and white stones it's
very simple you take turns placing the
black and white stones and you try to
surround and capture areas that's it it
sounds easier than chess chess a lot of
different rules this is pretty simple so
why is go such a complex game well
when you start there's a 19 by 19 board
and you are free to place it anywhere on
the 19 by 90 matrix and obviously later
in the game the board gets filled and
there're less options but in general you
have like 250 different positions to
pick from each move so there's a lot to
be very wait an average go game has 300
moves so if you want to calculate you
can do 250 times 250 times to do that
300 times and see what you see what you
add up it that's the entire tree for an
average goal game
the final problem is an evaluation
function it's nearly impossible to to
write a good evaluation function because
of alphago I've seen a lot of go matches
and even the professional commentators
are saying well in that corner might be
one or two points for them and five or
six stones here and and I think he's
winning and that's all based on
intuition because even if you are
surrounding an area and you're like 90%
there it's not obvious you will make it
because that's just how the game works
these are the possible amount of both
positions that you can end up with in a
game of go and that number is larger
than the amount of atoms in the entire
universe I didn't count them but
Wikipedia sesor so how do we make a
program that plays go but the most
powerful method until this year was to
do a Monte Carlo t-shirts so this is
Monte Carlo what do we know Monte Carlo
off its casino so how does a Monte Carlo
three shirts work well basically it's
it's Bay
some chance we pick one of the notes we
play semi randomly or just randomly to
the end just all the way to the end to
your moves and we'll look did we win
did we lose what happened and we do that
as often as possible and this gives a
pretty strong indication of the strength
of of a certain move and that's it
that's like the entire I'll go a eyes
this is what they do just play randomly
see okay we want 200 times we lost 10
times it's probably good move we'll go
there and that's also why the experts
one year ago
said it will probably take between 10
and 15 years before a computer can beat
a professional go player forget that
because suddenly up wait suddenly
alphago appeared so what are they doing
differently alphago is based on neural
networks and the neural network is yeah
what it says neural network is a
computer model designed to simulate the
behavior of your biological brains so
how do your networks work well let's do
it short demo does this work I hope this
note does not obviously wait we'll just
switch if you go to the tensorflow
website if you go to wait once they're
back tensorflow
is a framework I think it's great by
Google but you can create neural
networks intensive flow mostly using
Python sorry but they have an online
playground and this playground is made
so you can kind of get an idea on how
neural net
work and I find it really interesting
just to play with it but um who here has
played with this almost nobody it's good
so what do we see um here's a data set
and here you can see the data set
they're just blue dots and orange dots
and the goal of the neural network is to
classify them into two parts so it needs
to detect the orange ones and the blue
ones we have inputs this is just a
vertical line if we remove the entire
neural network and we would run it
nothing would happen obviously what
happens if we add a neuron not to just
one you can see all right it has a
weight to it this neuron does some
program some this neuron does some
tweaking of the input so there's a
vertical line as input this neuron
changes it and it looks at the result if
we play this you can see the vertical
line moves and it moves to the side so
it avoids the blue dots and it finds
just some orange dots and it gets
rewarded for that so that's like the
most simple neural network it has one
neuron and one input so what would
happen if we have two neurons
well the input is connected to the two
neurons and they they get randomly
initialized so if I keep refreshing this
you'll see random values the ways the
weights get updated and well we can just
see the results if you have two vertical
lines it can do much better it can find
two yeah two parts but that's not enough
right that stopped going back to one
neuron
what happens if you have two inputs so
for example now we have a vertical line
and horizontal line if we would show
some random inputs you can see it can
now create the diagonal line by
combining the two inputs so if we run
this it tries to find as the as many
orange dots as possible but this is one
optimal solution found maybe we can find
another so now it fountain another local
optimum so what happens if we have two
neurons this is just just playing around
well because it has two neurons it can
combine the two diagonal lines to create
like a cup and the final thing we can do
is we add another neuron and this is
enough for the algorithm to create a
perfect solution because now it has all
the orange dots in orange and all the
blue dots in blue so it won so what
happens if we create like deepmind it
just takes longer a lot longer hold on
longer it takes too long
let's randomly initialize it again so
you can see bigger isn't always better
mr. Trump okay another example so for
example let's remove some layers and we
want to match this so it can do it our
weird neural network can do this but not
all neural networks have the same input
for example there's also this input what
happens if we add this input as well or
you can quickly see the weight of these
inputs are almost zero and it's almost
entirely working on this input so even
though people say a neural network is
like a black box you don't know what's
going on yeah basically by looking at
this you can see it's clearly not using
those two it's using this one and if you
would if you want to for example
compress a neural network well it's very
easy we don't need this we don't need
this oh this is also almost never used
let's remove that basically remove this
oh that's a bit too much so this is
enough for the neural network because
it's already a good match and sometimes
if you just have simple inputs but you
need to generate a complex pattern for
example this spiral let's add a lot of
neurons it can't really do this this is
too hard for given the inputs the inputs
don't match up with what it needs to do
it can create something but yeah it's
not really working
it also has sine inputs so sine waves if
we use those as well it works much
better you can see
kind of resembles to spiral we need to
match so enough playing around stop this
so if you want to learn more about how
there are networks yeah yeah yeah the
question is the algorithm that's being
used is is basically just sign well the
algorithm is taking some inputs in this
case one horizontal angle vertical line
assign an assign vertical horizontal and
it's being run against a couple of
neurons and those neurons yeah there's
just no neuro network code it you have
if you can easily find that online and
intensive flow is just as easy as define
seven neurons um and if you run that it
could generate search patterns and it
could this network now is able to find
that pattern so if you want to start
using this yeah not a question meter
oh yeah
yeah so so basically the question is
what's a neuron um in this case a neuron
isn't isn't a magic thing or anything
it's you can basically see it combines
the input weight away and let's create
something very simple this as well so we
have this input horizontal line we have
one vertical line you can see the weight
of the vertical line is in this case
it's negative weight so it gets flipped
around but it's a half which is a lot
and the weight of the horizontal line is
dot zero six so it's very minimal if you
would translate that you'll get
something that's very vertical it's a
little bit horizontal and that's it
that's the only thing that Iran is doing
it's combining those two inputs into an
output
and if you run it it would now update
the the weights so you can see the ways
have changed and this is now what it
generates so basically you take two
inputs that have a weight and it outputs
let's that's the only thing a neuron
does in code so it just combines two
inputs to one out but yeah the magic
happens when you have a lot of neurons
are connected to each other combine all
the weights you'll get something more
much much more interesting but play
around with this it's just a fun toy I
can do this for hours but we don't have
that time
so let's go back to the presentation so
very very simple debts neural network if
you want to learn more for example about
tensor flow go to the tensor flow a
website tensor flow is mostly Python the
problem is most neural network and
machine learning algorithm libraries and
frameworks are Python but there's deep
learning for J which is the other and
there are other still you get cafe
towards Dino most of them are Python if
you want to learn more about tensor flow
there are a couple of talks both of them
tomorrow there's Google skill they talk
about tensor flow and I was also
tensorflow in deep learning without a
PhD which I'm going to attend absolutely
because I don't have pity so by now
you're wrong you're probably wondering
how does alphago do this why is alpha
code different how can it play go while
the other algorithms are pretty useless
so basically google deepmind I'm not
from google deepmind they hardly release
any information but I've managed to find
some information and it turns out they
created a couple of neural networks the
first one is called the supervised
learning policy network they two
30 million amateur matches so not no
professional matches amateur matches
they put it into that large neural
network and they gave it a goal predict
the next move so given a certain board
what is the amateur going to play and
the result was a 57 percent correct
that's pretty good that's that's so it
it's most of the time it does the same
as an amateur player would then they
took that Network copy
they created the reinforced learning
policy network like I said it was a copy
but they gave this network a new goal so
instead of giving it a board looking at
the result and did it makes the result
we want to find the best move and to
find the best move the network just fade
itself
1.2 million times and it will base the
reward of the neurons so you're in a
neural network you always have a
feedback loop and it would base that
feedback loop on the outcome so which
version of the neural network did better
and then they took Pachi Pachi is not
the best go playing AI go playing I eyes
aren't that good but it could win 85% of
the time without doing any syrups just
give the current board position
run the network once and take the
outcome so that was already like ok
we're doing something good and they
created the third neural network because
they kind of ran into a problem
the network I mentioned before the
reinforced Network was slow in computer
terms three milliseconds is slow for
example if you want to do a Monte Carlo
tree search you play to the end as often
as possible you don't want to be waiting
three milliseconds every single step
so um to play to the end one time it
will already be 300 times three Billy
seconds which is ages so it took the
neural network and it made it smaller by
making it smaller they try to keep it
yeah as smart as possible but you
obviously lose information but there are
always cases where neurons aren't firing
anyway so you can just leave them out so
they try to compress that Network and it
made it much faster to microseconds
which is 15 I think hundred times faster
he created a fort neural network they
were all over the place they took the
same 30 million emerges but the goal
wasn't to predict the next move the goal
was given this board who's going to with
just just tell me who's winning is it
player 1 player 2 or is it a tie and
initially is there an error of point 3
point 37 where 0.5 is ever it's just a
random guess this network they did a
self play with it as well so then the
error came down to around point 23 still
it's a very simple neural network you
give you give the board predict the
winner and predict how much it will win
the the weight of the win so they
started to test this value network this
value network is like an evaluation
function right so for a given board
generate all the possible moves for all
these moves run the neural net or ones
evaluate and pick the one that's most
likely to win for you this neural
network using this method was able to
beat the strongest known AI Ingo still
without doing any research
so they were kind of on the right track
and then alphago decided to combine all
the pieces together so they use the
policy network the first network that
predicts the next move and they try to
select the best moves to play if play if
certain moves are like completely crap
don't evaluate that's the pruning part
for the good moves
check with the value network which of
the moves have the highest likely
outcome to win and then using the first
of all ad network do a multicolor search
as often as possible because that's
still a very powerful technique but
instead of doing random moves we can now
use the fast Network to do smart random
moves so pick the best moves at every
step so that's a much more realistic way
of doing multi card research that in
total is alphago and they were able to
beat some go players oh yeah yeah during
play it doesn't do any reinforce
learning um reinforce learning is during
training when it's playing itself you
basically have two versions and and the
the weights get updated after playing
itself if it won the that network would
get rewarded and the other won't
that's the reinforced learning part this
is at play yeah so this is combining all
the neural networks they've created into
one program called alphago that can play
go so they set a challenge and let's
lease it all he is considered to be the
best go player of this decade people say
is the Roger Federer of go I don't play
tennis but so it's a best-of-five and
just Solis it all really tries it's best
if you wins you get the million dollars
this is the Challenger it's a
distributed version of alphago it's
using 1200 and 2 CPUs I think those two
and it's using 176 GPUs and Google now
also owns tensorflow but deepmind wasn't
at the time using tensorflow so it's
still just using CPUs and GPUs and not
their own CPUs which our tensorflow
processing units so they were just using
CPUs and GPUs at mode I think they're
currently transitioning towards using
tensorflow but I'm not from Google and
they're not telling anyone so who knows
this is what the contest looked like
maybe you saw it maybe you did who sold
it okay okay
I was actually on a skiing holiday so in
the morning I would I would check this
life and my wife would be angry and okay
basically what you see here there's
alphago that's a computer screen and the
guy next to it is alphago's minion and
who just has to do the move so he's
basically a slave of the machine on the
other side of the table
obviously digital and game one was yeah
it wasn't very special it was just like
any other professional go match which is
surprising because no no other gay go AI
was playing like a human but this was
just like any other regular match so
that was surprising but Lisa dough for
it could easily win this because yeah
we've seen this light it will take 10 to
15 years before an AI will take who take
down a professional go player let alone
lease it oh he's a late but then came
move 102 loses the racism so alpha cos
mu yes
look at Lisa Dawson - he does it haha
it still dropped literally and he froze
for 30 seconds
lowly he's now thinking what the heck
and he started to realize I might not
win this and this is the moment not even
so gonna lose sin I change in
traditional he did lose that game this
so he's won one no behind in Game two
but yeah it wasn't a very special game
it was like any other go game Game two
was much more interesting because very
early on in the game here you can see
the two commentators the two
commentators are really good 9 then gold
players and they are analyzing the game
and you can see in the bottom corner and
alphago has played a black move and it's
this move but the commentators are still
analyzing all the possible combinations
that could be happening they haven't
seen this yet just what's their reaction
it changes the value of the area when
you have a strong group like this
because black doesn't have any point to
approach it because it's so strong and
this is what sorry from the Google team
was talking I'm going to move I was just
kind of about valuation know who value
said that's a very that's a very
surprising move I thought a total this
was a mistake
um what I thought it was a quick myth
but um click city free online Oh Oh a
flick oh yeah it's a very strange
something like this would be a more
normal yeah let's just let's just
analyze what we were doing I guess this
doesn't make sense
you can get the big emitters and black
wood white it would locally washer yeah
like the idea is this group is so strong
maybe white wouldn't okay
all right that's right because what you
were just saying that's just settled
because
if black does stuff like that yeah so
did they just disagree what else ago did
because it didn't make sense the
European champion fun goon said about
this move it's not a human move I've
never seen a human play this move it's
so beautiful
and it's actually for the first time
that a go AI was playing at a different
level than humans are playing and this
happened to chess as well the game of
chess in the last 20 years changed
tremendously it used to be very
traditional very very much the same
moves the same openings but in the last
20 years because of computers people
started analyzing different openings now
this sounds interesting and I'm now an
expert in this movement nobody is so and
people started branching out and doing a
lot of experimental stuff and the
prediction is this is also going to
happen to go um it's going to be a much
more interesting game in feature so Lee
SEDOL lost that obviously he also lost
Game three and then in Game four and in
Game four goo goo key it's leaves our
trifle he said this move was made with
the hand of God we all know then of God
but that's basically also the hand of
God but this wasn't the move from
alphago this was a move from Lisa doll
it was like a very tricky situation in
the middle and alphago didn't move her
alphago didn't know what to do and lee
sedol made a very risky move and
probably alphago ran into an arrival
problem there
it didn't analyze that situation at all
so it was taken by surprise and because
of that brilliant move from Lisa tall
and he kept playing like nine ten moves
after that brilliantly well decoe
alphago was in time trouble he managed
to to win this game
it wouldn't matter alphago 1 v meds so
in the end
alphago firstly said Oh turned into for
one so conclusively why is this
important
everybody's saying that 2006 it's a
horrible year and I kind of agree
especially since this morning but nobody
taught alphago what a good or a bad move
is
nobody programmed the evaluation
function for alphago alphago isn't an
expert system nobody puts go logic into
alphago alphago learned of this by
watching others and self play finding
out the rules for itself using general
machine learning techniques to figure
out for itself how to win and that is
like the biggest breakthrough in AI in
ever I think because even if you take
deep blue versus Kasparov which is also
something that people are still talking
about is a great thing for AI it isn't
it is just a database deep mind deep
deep blue was nothing more than the
database it was just Lou doing blue cups
of professional games and doing the
minimax 3 shirts we saw like in the
beginning of this talk alphago isn't
like this it doesn't have a table of
lookups it doesn't even know the rules
of the game it's all playing on a couple
of neural networks and it's playing on
intuition which is crazy and um the
people from alphago are now trying to
use this system not to play go but to
put this into medical research so for
example you could you can input a lot of
questions and the machine can can tell
by intuition
if your sacrum but your diseases are and
what your chances are of getting
diseases so that's what I've heard what
Google is currently doing with alphago
they made all they might be creating
Skynet who knows but they're not that
open nobody from deep mind is here to
talk about it but yeah not a question
wait they're confidential neural
networks and the question is what kind
of neural networks are using their
convolutional neural networks but I
didn't want to go into that because then
I had to explain what a compression
trishal neural network is and that would
take a lot of time so I and please find
someone from google deepmind that could
talk more about this I love the story I
love to learn more but there's almost no
information about these networks
available so that's the problem other
persons no questions well thanks
don't forget to vote</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>