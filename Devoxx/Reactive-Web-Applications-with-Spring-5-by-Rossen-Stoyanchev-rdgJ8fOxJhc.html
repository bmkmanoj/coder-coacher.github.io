<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Reactive Web Applications with Spring 5 by Rossen Stoyanchev | Coder Coacher - Coaching Coders</title><meta content="Reactive Web Applications with Spring 5 by Rossen Stoyanchev - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Reactive Web Applications with Spring 5 by Rossen Stoyanchev</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rdgJ8fOxJhc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello good morning welcome on this
Friday morning nice to see all of you
here we have a interesting topic for you
this morning hope you're enjoying the
conference we're gonna talk about
reactive web applications in spring five
spring five is coming up in March of
2017 we're currently in milestone three
working towards the last milestone at
the end of the year so this is a good
time to be talking about this and to
learn more about it whether reactive web
applications is something that's already
familiar to you whether it's something
you're already looking for is less
important than learning about it because
this is a big transition and it is a
good time to learn about it and to be
aware of what this is and why it's there
so that's the subject of this
presentation first of all a couple of
words about me
I am a committer a member of the Spring
Framework team so I'm involved with
spring five effort I've been on the
engineering side for about five years
so I've primarily been involved with
anything web related spring MVC
WebSockets and currently the spring web
reactive effort I want to kind of set a
broad expectation about this talk this
is we're not gonna go into the details
of reactive programming in the sense of
using a reactive library and showing the
mechanics taking you through that think
of this a little bit more of a kind of
making sense of the transition to
reactive programming it is going to be
very specific we're gonna talk about
very real things that we've been doing
over the past two years you can think of
it as joining a new member of a team
joining something that's been going on
for two years and my goal here is to
introduce you to what
beam up to to catch you up obviously in
this one hour I'm not going to take you
through the mechanics or the syntax of
doing things my purpose is to give you
the background to make you understand
what we've been up to why we're doing it
maybe sketch out a few things well not
literally obviously but basically take
you through that and get you to a point
of understanding so you can begin to
look at more details now having said
that there is a wonderful University
session that was done on Monday by
Sebastian Toulouse and Brian Kozel and I
have a link here and it's a three-hour
session where you can look at reactive
libraries you can look at specifically
the details of using reactive libraries
and then you can actually look at a web
application in action all of that is
with live demo so I highly recommend
that as in addition to this talk which
will provide you with more background
and the other things the other thing I
wanted to mention is that this this
slide deck is optimized for listening so
all of you are in the right place
but for anybody who is actually watching
this afterwards the slide deck is really
optimized for listening all right well
many of you may remember this book Java
concurrency in practice 10 or more years
ago at this point and one of the
memorable things that sticks out in my
mind from this book is the idea that
we're no longer getting a free lunch
from the hardware so the it's the end of
Moore's law was the prediction and from
now on we're gonna be governed by M
Dells law and basically that means that
the CPUs are not getting any faster
we're only getting more cores and our
applications will need to become smarter
and and better at doing concurrency and
that's how we're going to get better and
faster and scale and that was of course
the time when we got the major
improvements in the java.util
concurrency package in Java
and at least in my mind I wondered what
does this prophetic statement really
mean what's going to change you know we
already are doing things concurrently we
already have pretty good you know
threading model in Java and we can do
things asynchronously so what is really
fundamentally going to change I didn't
quite see the answer at the time and of
course as time went on then fast forward
to 2009 many of you will know that's
when nodejs was created ryan dow the
creator of nodejs did something that
seemed almost hard to imagine at the
time he took a a single-threaded
environment and platform language like
JavaScript and he created something
highly scalable that can run on the
server side with a single thread and
process massive amounts of traffic and
connections and and this was also very
very interesting I mean there is a talk
you can go back it's out there on
YouTube it's a good way of understanding
how something like this can be done I'm
sure many of you have seen that talk but
it's basically if you have a single
thread you can never block that thread
if that is your constraint from the
beginning this is what you have to do
and essentially when you have to block
which means that you have to make a
database call you have to do something
which requires waiting and which is
outside of your control how long it may
happen you really don't want to block
the entire server because your server is
running with a single thread so you're
going to make that asynchronous and
you're going to wait for a callback and
that's how you're going to do everything
and again I'm not going to go into all
the details of that I recommend seeing
that talk if you haven't and I remember
seeing that in 2009 and thinking wow
this is super interesting but this is
going to be difficult to replicate in
Java because we already have an
ecosystem and we already have
an established way of doing things where
a lot of the api's and a lot of the
libraries that we use are synchronous
and we write imperative style code and
that's the easiest way to write code and
we can scale pretty reasonably in Java
because we have a thread not just one
but we can have many threads but at the
end of the day to actually become
non-blocking I think there's a phrase
that the golden jail becoming
non-blocking is a really high high bar
high threshold it's because you're doing
so many things already synchronously
switching requires you to redo the
entire stack in order to get there so if
we talk about asynchronous and non
blocking and reactive a natural question
might be why and also you may wonder
aren't we already asynchronous this is a
very common point of confusion myself
included at some point just like trying
to explain it to myself and work through
the logic so let's take a moment and
talk about that we're using threads we
have thread pool so we are asynchronous
right to a degree we are asynchronous
there is such a thing as being a little
bit a synchronous or more asynchronous
it's much harder to become non-blocking
and that's a much more deterministic
thing you can say I'm a little bit
non-blocking you're either a
non-blocking or not and the if you think
about using threads for example the
serveth container we have a thread pool
and we allocate an individual thread for
each incoming request the question is
really how much time is that thread
spending being blocked so we can make
the thread asynchronous from the point
of view of the server because we're
putting it in its own thread but the
thread itself may block and each time
you block there's a cost associated with
doing that now you may already be
thinking well what's the problem really
with a single thread and it's true it's
you know it's perfectly X
we've been doing this for many many
years this is not to say that this is
doing it wrong but there is a cost
associated with blocking and when you
are trying to reach a certain level of
scale you will find that there is a
limit to how far you can go because
ultimately using a thread pool and and
many threads is a crude way of achieving
a synchronicity I don't mean that in a
negative way it's just a coarse-grained
way of achieving a synchronicity where
you're writing things imperative ly
you're making a call to the database and
then you're waiting for the result and
it's the easiest way to write code and
there's nothing wrong with that but
there is a cost associated with it and
there's only so much that you can scale
by doing things in this way and of
course nodejs was a great example of
demonstrating how much scale you can
achieve with a single thread so we
talked about horizontal versus vertical
scale with horizontal scale because you
know as we use more threads that
requires more memory because each thread
means you're deep in the stack and along
the way you're you're keeping state and
so there's memory associated with each
thread and then the more of those you
have the more memory you using so that
the more resources you're basically
consuming you've over over time as well
we're doing more and more things that
require latency ten or more years ago
things were a lot simpler you know we
had the servlet container with the
thread model and each thread can block a
little bit you know and we can still
scale but nowadays we make calls to
other services we make third-party
services on a server side we do scatter
gather micro services so things have
changed as well quite a bit to the point
where many many applications are now in
the category of requiring a kind of
scale which is difficult to achieve
otherwise so with vertical scale with
horizontal scale when we reach the limit
of the JVM we load balance and then we
have multiple instances of our servers
as
serving requests with vertical scale
it's kind of more than no j-style where
you're making the most of the resources
and that goes back to the concurrency in
practice and Amdahl's law where you're
doing something in a different way
because you can achieve a higher degree
of utilizing the resources that are that
are on that server that's really what
we're talking about here interestingly
if you start adopting the non-blocking
way and what that means is that you you
cannot block a thread you can do things
and for as long as the things that
you're doing don't require any blocking
and by that I mean latency that's
associated with waiting for something
not using the CPU if you're using the
CPU you know you have to use it but if
you're making a call to a database if
you're making a call to some external
service over HTTP anything of that kind
or writing to the response back on a
servlet container anything that's
associated with waiting that's that's
what we're talking about not blocking
there and instead making that
asynchronous and then receiving you have
to use an asynchronous library at that
point and receive a callback when the
result is ready and there are facilities
in the JDK the nao selectors that make
it possible again it's not my goal to
explain how to make things non blocking
but I think the concept should be pretty
clear so and and I didn't talk about
reactive yet reactive is essentially
when you start doing asynchronous and
non blocking things fundamentally you're
dealing with a lot of callbacks you're
receiving notifications when things are
ready you're no longer writing things in
the imperative style and reactive is
basically a kind of micro style of
programming where you receive events and
as you deal with these events there are
new kinds of problems that you run into
but hopefully in the course of the
presentation this will become more clear
so is this hyper reality do we really
need to be asynchronous and non blocking
and reactive and does my application
to change well reactive for sure is a
buzzword by now it's something that's
talked about quite a bit so you can
argue whether that's hype or not and how
much it's going to be used I can't
predict the future but I can tell you
that the benefits of being asynchronous
and non blocking are very real
and for those who are looking to reach a
kind of scale that probably isn't
typical for the average application you
might be reaching for the top shelf to
find something there and there's nothing
there so you're already trying to invent
new go out of the way and create new
mechanisms and new ways to scale if you
don't find yourself in that situation
then there's probably no need to change
in fact we do expect that a majority of
applications for a long time will
continue to do things the way they are
this is not about saying that we all
need to change now but this is about
talking of new ways of achieving scale
and when you need to do that that's when
you go in that direction and as you will
see this is very much the philosophy we
follow in the spring framework we're not
going to tell you this is the new way
that's the old way and now from spring
five you have to do things than you wait
instead it's very much the same way
we've always done things we try to make
sense of something new that we see we
try to provide options and then we
evolve with what you do and what you use
we think that there's a lot of benefit
in this but it by no means does it mean
that you have to drop what you're doing
now and change there's a really good
blog post that I'd like to point out the
recent announcement of the Zul to
upgrade from Netflix where they talked
about their journey of converting their
gateway where all Netflix traffic comes
through to be non-blocking
and asynchronous it's very much the
things that we're talking about here
it's very much the things that we've
been looking into for the past few years
and it's very interesting to see that
coming
from Netflix because they're probably
one of or maybe the most highly
trafficked website they used servlets
and they switched to be asynchronous and
non-blocking
at the gateway they still have many many
systems internally that they're not
necessarily rewriting and that's I think
the reality you don't need to make
changes everywhere because certainly
there's a there's a cost associated also
with becoming non-blocking and that is
in terms of the programming model which
changes significantly you know when you
start dealing with asynchronous code
it's not as easy as writing imperative
code it's not as easy to debug it you
know you don't have a single thread that
shows you everything so it's certainly
not easy and that's what I like about
this blog is this is very balanced and
it gives you kind of very experience and
there's also a kind of analysis there
they have variety of different gateway
services some of them are more CPU bound
some of them are more latency and i/o
bound and the actual of benefit that
they see from this transition is is much
higher in latency bound services which
is perfectly to be expected but it's
just interesting to read about that and
also the other thing that they share is
a kind of benefit for them going forward
is that they're able to deal with a lot
more connections just a much higher
number of connections and the reason for
that is because the cost of each
connection is now very very low when you
switch to the non-blocking way of doing
things you need a very small number of
threads it's kind of the event loop
style processing you don't need large
thread pools and now the cost of a
single connection is basically a
callback you know when something when
the connection is not blocked and you
can do something there's a callback in
the code continues so you don't require
so much memory so what that means is
that they can keep those connections
more of them and they can start to do
more things like long polling and
streaming and HTTP to it allows them to
scale better in the future and deal with
more clients
so we turn now to the spring reactive
journey what we've been doing over the
past two years so when we started
looking at this we were wondering about
finding different execution model for
running web applications and this came
from observing the experience of
companies like LinkedIn that you know
shared that by trying to scale to the
kinds of traffic that they have they
reach a point where dealing with threat
pools
everywhere it becomes unmanageable as a
way of dealing with a synchronicity and
that's again the things that I've been
talking about here so far and it becomes
unmanageable so they wanted to find out
if there's a different way to do things
and that's why they moved in this
direction and we wanted to explore that
route as well and we've been hearing
also questions going back to 2011 can
can we run spring MVC on Nettie
you know Nettie being an asynchronous
and non-locking runtime that's pretty
much the de-facto choice for doing
things of that nature and going down
that path in exploring the options is
really what we've been up to so in order
to so we're talking basically about
becoming non-blocking kind of
replicating a node.js experience using
event loop style processing a very small
number of threads obviously we knew that
this was going to be a very big road
because first of all at the very
foundation of what we all do for web
applications and have been for a long
time to the beginning of the server's
API almost 20 years ago now is we we've
been using a thread pool so if we're
going to stay with a very small number
of threads an event loop style then we
know the servlet API first of always
blocking because if you use the input or
output stream well those are blocking
API if you start reading from the inputs
Green you have to read you can't you can
get a callback if let's say that's a
slow client over flaky Wi-Fi and you're
not getting the data immediately you
have to wait until the input stream
gives you the data you block same thing
for the output stream now over the years
the servlet containers have evolved
tremendously their modern runtimes just
as well as nettie
but it's the servlet API on top which
basically underneath there's an event
loop but on top of that there's the
server the API and the way we consume
the application the input connections in
the output connections is effectively
through a blocking API now some of you
are probably immediately thinking well
we have the servlet 3 or a sync request
support and that's true in Spring and
Missy can return a deferred result and
again you can see here that a
synchronicity is being added on top of a
essentially fundamentally synchronous
model the servlet itself has a void
return value filters as well if you
think about what that means that means
that it assumes that what you do is
asynchronous and and the threading model
that goes along with that also assumes
some kind of blocking occurs inside of
that the async requests in server 3 it
does allow you to process the the to
handle the requests asynchronously
but at the end of the day you're still
blocking because when you when you read
and write to the response and the
request again that's the server the
input and output stream and then some of
you may also say well we have the server
3 1 non-blocking i/o don't we and it's
true we do and we've explored using that
on the Spring Framework team and spring
MVC for you know traditional server
applications but the fact is and this is
not just me saying that there's a great
talk here at devoxx I think two years
ago maybe by Greg Wilkins from jetty who
basically shares the same
experience in the same conclusion that
we arrived at that it's either/or
proposition when you start using the
survey 3-1 non-blocking i/o you really
can't combine that very well with the
rest of the sort of API because much of
it is blocking so you can do the i/o at
the lowest level in a non-blocking way
but then there are many things in the
server api which are blocking themselves
say something trivial as doing requests
that get parameters well this may cause
parsing the request body which will
block so in effect I don't want to go
into much detail there but if you you
you can use a servlet container through
the server the API in a non-blocking way
but you have to kind of leave behind the
rest of the servlet API we have to kind
of start a new that's really where that
points to so we knew that this was we
were in for a very big change because
spring MVC is based through and through
in its core contracts on the servlet API
and we could not use the server of API
but the problem actually goes even
deeper than that because when you decide
to become a synchronous a non-blocking
you're fundamentally dealing with async
callbacks imagine writing an
asynchronous application that's fully
non blocking you make a call to the
database now you have to wait for the
result if you imagine a real application
you're doing a lot of that so you're
doing dealing with a lot of callbacks
and pretty easily you can end up in what
some refer to as callback hell now it
doesn't mean that it has to be that way
for example in in Java we have the
completable future and that's a great
example of an api of a continuation
style api which allows you to compose
what should happen when that future
completes and then the code looks like
imperative code but it's broken out into
pieces it's it's readable you know
there's still callbacks underneath but
you're not dealing directly with the
callbacks it's it's a bit like using the
stream
gee I so in Java eight we have the
stream API we have all these operators
filter map flatmap those are the kinds
of facilities that we want to be using
to compose our logic asynchronously so
we need something to do that of course
many of you will know our H Java that's
kind of what I'm hinting at but we'll
get there in a moment
now these are the words from Doug Lee of
course the lead for the java.util
concurrency module in Java in Java 9
we're going to have the reactive streams
specification incorporated and this is
what he wrote when he when the decision
was made to do that he said there there
is no single best fluent API in Java for
push style operations on items as they
become available from a source so we're
talking about a hot source with the Java
eight stream API you have the ability to
pull items from a collection it's
primarily built for collections we have
the completable future which is a nice
continuation style API that you can set
the item on but the stream API is really
a pool style API what we want is
something that generically represents
async results that data can flow on that
can be pushed into when the data becomes
available we're talking about anything
latency related like an HTTP client or
database call sometimes there may be a
delay and when things become available
they can be pushed
instead of pulled if you're pulling you
have to block if you're pushing that can
be provided as a call back style
notification so this is why these
interfaces were included in the JDK this
is the reactive streams specification
which was an interesting effort
interesting in the sense that it was
created not as part of any
standardization process it's just a
number of different vendors including
light bends pivotal Netflix causing
Twitter that just came together and they
created a specification for
interoperability across asynchronous
non-blocking components and what you'll
see here is just four interfaces the I
see now the subscription gets off a
little bit but those are the two methods
so then never mind the formatting there
but those are the two methods of that
interface the there's nothing
fundamentally radical about defining a
publisher and a subscriber
publish/subscribe we've been doing for a
long time
what's novel here is that there is a
back pressure mechanism which instead of
the publisher pushing things to the
subscriber at any time or whenever the
subscriber has the ability to into
request items and then the publisher can
only push items if the subscriber is
asking for them this is very important
mechanism because whenever you deal with
asynchronous applications and you're
getting results say something is coming
from the database and then eventually
you have to write it to the response to
an HTTP client well if the HTTP client
is not ready for the right we have a
blocking right there non blocking right
then we wanted to communicate back to
the upstream source but the data is
coming from that we don't want to get
any more items right now wouldn't it be
nice if we had such a mechanism and
that's what really what this is about
it's about allowing different different
libraries different companies to create
components from Couchbase and Mongo to
web framework to a runtime HTTP runtime
that can communicate and pass data and
and construct entire pipelines where
data can flow and you can pause at any
time if if we're not ready to process
more of that data now it doesn't mean
that it works out that way everywhere
but we need that foundation we need that
mechanism sometimes sources will push
data no matter what that was one of my
first questions about reactive streams
what what if the data
keeps coming well that can happen too
but then you have to somehow deal with
that overflow here reactive streams is
just giving a mechanism to communicate
so if possible the upstream should slow
down so this is a typical example of
imperative blocking style code that we
write we have a user repository with
methods to find users or save and you'll
see in the usage what we mean by
imperative is we go top to bottom we
call the repository to find a user if
there is an exception we deal with the
exception if we get back a user we
continue this operation may block that's
the big difference that's the cost of
doing things the imperative way but it's
very simple and it's a single thread if
anything goes wrong we can see exactly
where it went wrong now to make it
asynchronous we using reactor streams
only we can make it asynchronous and non
blocking by returning a publisher of
users and you'll see that whether it's
one user or many users that's kind of a
common scenario kind of aggregated into
a single thing publisher so really here
you see an example of the save which
returns a publisher void which means
there will be no data coming on that
publisher only a notification when the
save is done or there's an error there's
a fine by ID which gives you a single
user or find all which gives you many
users I'm not yet saying this is what
you will do I'm just taking you one step
at a time so just bear with me
this can be asynchronous and non
blocking because the publisher will push
the data to whoever is calling defined
by ID method we it doesn't have to
happen in the same thread it can happen
later when the data is available so you
can see that this is a very fundamental
shift I mean you know up here you get
the user and then you move on to do
something with the user over here you
get back a publisher and now you have to
somehow compose what should happen next
you
don't have a user yet that user will
come when it's available which may be in
the same thread or may not be in the
same thread so it's a very fundamental
shift and the way way of doing things
you you no longer indicate exactly how
to do things you indicate what should be
done instead so you can imagine these
notifications as a sequence again back
to the contract here you can see on the
subscriber we have on next on error and
uncomplete so these will come 0 or many
on next notifications if we have any
users coming and then either an error or
on complete signal callback and the
reason I show that is because I want you
to see that we can take all of these
methods the void returning method the
user returning method or the list of
users and we can represent them as a
sequence of notifications to a publisher
so for the void method we get uncomplete
or on error and that's all we want to
know for the single user method find by
ID we get on next and then on complete
or on error and then if we have more
users that simply becomes multiple on
next notifications but of course if
you're dealing with with a publisher
that's a very basic API you are now
dealing with callbacks directly and
that's what I said we try to avoid so
this is where we talk about reactive
streams implementations we have our X
Java reactor ARCA streams these are all
libraries that implement reactive
streams and not only do they implement
these contracts but they actually give
you a composition API similar to the
Java 8 stream that allows you to compose
logic asynchronously to use operators
like filter like map and flatmap so
you're composing your logic but not
mm-hmm by dealing directly with
callbacks but rather on a higher level
more functional and more declarative so
it looks something like this now you can
be ace
Kronus non-blocking and functional and
you can see here that when we get all
the users then we can continue to
declare what should happen next and you
know hopefully that looks a little bit
familiar for many of you using Java 8
that's the kind of thing that we're
talking about here obviously we can't
just continue to write code imperative
ly we have to use something like that
again my my goal here is not to I
realized that I'm leaving out a lot of
details now you're probably curious you
know about the use of mono and flux
these are the two types in reactor flux
represents a stream of many items where
mono represents a single user and then
you have the mono void which means that
you get just get a completion
notification again for using these types
and for seeing how to write such code
and testing I again I recommend the the
talk that I pointed to in the beginning
of the session we're not going to slow
down here just keep in mind the concept
of what we're trying to do we're trying
to provide a composition API and that's
combined with reactive streams so let's
take a look at what we have in Spring
Framework five
hmm to begin with we have a very basic
HTTP handler contract maybe you will
notice that this is similar to a servlet
contract except the return value is not
void because void is synchronous
semantics and if you have to do
something that is actually asynchronous
then the void method does not allow you
to do that it means that you would have
to block to complete before you return
this is why again I'm said this earlier
the the servlet API is fundamentally
synchronous in semantics and origin and
here the HTTP handler is our lowest
level abstraction over a synchronous
non-locking run times and again the
method is very similar to serve it
except it returns mono void and also we
have a request and response
representation these are not the service
request and response because the request
body and the response body are
represented as publisher or since we are
using reactor as a core dependency
internally within Spring Framework 5 the
the request body and response body of
represented as a flux of data buffers
which means that we have the ability to
read and to write without blocking so we
may read a little bit from the client as
the data comes then we pause then we
read a little more this is not something
that was possible to do that is possible
to do in the servlet API unless he using
the non blocking i/o again but that's
hard to use with the rest of the servlet
API so we have that basic capability and
it's built on reactive streams so
effectively we're adapting any runtime
that we're building on to and from
reactive streams and we're using reactor
but that doesn't preclude us from
supporting the other
active libraries so if you happen to use
Couchbase with rxjava or another library
that's using or maybe your application
chooses which library to use like our
Java reactor as you will see we we have
a way to bridge or to adapt to that and
it's perfectly okay to use multiple
reactive libraries in a single pipeline
that's what reactive streams really
helps with and if you look at this
example here we're getting the body of
the request and we're writing it to the
response interestingly if you imagine
doing the same with the servlet API you
can't quite see that right because the
body is an input stream and the output
is an output stream if you're reading
from the input stream you can't just
take the input stream and pass it as the
output stream because that's a pool
style based your reading in a blocking
way but here the body is a publisher and
then the response expects a publisher to
write with to the response and then the
return value that you can deduce here
from the return value of the method is
mono void so the response write with is
actually taking a publisher and giving
us back a mono void that tells us when
the right is actually done incomplete
and we support all of this on the
following runtimes at the moment we're
running integration tests and examples
on top of all of these runtimes well you
will notice at the very top there Tomcat
and jetty so I said from the beginning
that Tomcat and jetty are have evolved
over the years
so the servlet API has largely remained
the same it's much more difficult to
change things like that because you
already have an ecosystem that's built
over time but the service underneath
that they're pretty capable of doing
things a non-blocking way they use event
loops and this is something that we're
doing unique we believe in the async
space where pretty much anybody doing
async
non-blocking and looking for runtime is
is using neti I mean if you look out
there that's what you'll find any
existing web framework or product or
project is based on Nettie and Nettie is
a perfectly fine and capable choice but
we come you know from the experience
with the Spring Framework and we know
that many of you are using Tomcat and
jetty and our natural inclination is to
provide choice and this is why we have
the HTTP handler abstraction and it
allows us to adapt it to all these
different runtimes just like in the
servlet container world the server the
API was a common denominator and you
could switch and run on different
runtimes here we're actually expanding
the footprint so now you can do things
like spring web on nettie on the toe is
another runtime that we support now for
Tomcat and jetty and I'll also say
server 3-1 containers what we're doing
there is we are building a bridge
between the server 3-1 non-blocking i/o
and reactive streams
we're basically adapting what server 3-1
provides as non-blocking i/o to reactive
streams publisher with back pressure so
that means that if we cannot write to
the response we communicate the back
pressure upstream and vice versa when
we're reading from the request body if
the client is too slow we were told by
the implementation publisher that about
that and then we can adapt further
upstream so so we we have that for
Tomcat were separately actually building
extra facilities for for doing this and
in server 3 any server 3-1 container in
theory can work as well and I say in
theory because the server 3 one
non-blocking i/o is not something that's
commonly used most applications don't
use that so we find and we found and
reported many issues
so with Tomcat and jetty we have a fair
amount of confidence we've actually
tried this on WebSphere Liberty
profile in theory it should work with
WebLogic as well any server 3-1
container should work with this with
with the bridge that we provide now on
top of that as you're reading bytes from
the request and response what you also
want is actually to be able to convert
to and from objects because that's what
we do in web applications so you'll know
the HTTP message converters that we have
in spring MVC well we have similar
facilities for taking a flux of data
buffers and turning that into a flux of
objects and we do that with for JSON and
XML with JSON we at the moment we use
jackson is where we've started because
that's what's used most widely we did
have to jump through some hoops because
jackson itself works with an input
stream in an output stream so on the
input side we built we are actually
parsing the input stream and if that's a
JSON array we're parsing out the
individual objects and then feeding that
into Jack's own to do the data binding
on top so we have to do extra work to
work around the fact that Jack stone is
not does not have an asynchronous option
but they are working for hopefully for
Jackson 2.9 on having such an
asynchronous option and if it's not to
nine I'm sure that's coming we have
something in the meantime but we would
be very happy to get rid of that code
because it's very low-level parsing the
JSON and there are all kinds of
scenarios and issues that arise when you
are in that level interestingly enough
Alto XML is a asynchronous parser from
the same team that's building Jackson so
there is an example already and we're
using the asynchronous XML parsing
mechanism to then feed into Jax P and
turn into objects in a fully non
blocking way
we have others for server-sent events
that's obviously a really good case use
case for streaming and for non blocking
things zero copy transfer there's a lot
of goodies there you know for more
advanced scalable web applications and
then this is the most interesting part
when you look at a controller at the
controller level it looks very much like
what you've been looking at and using
with spring MVC except it's not spring
MVC I mean I said earlier that with
spring MVC the contracts the very
contract of spring MVC the handler
mapping the hell're adapter are built on
a servlet API and we can't use the
servlet API we wear now adapting to
react with streams an HTTP adaptation
layer so but there's no reason why we
can't build the same model on top of
that in fact we've taken many of the
spring MVC mechanisms and we're
translating them to new contracts very
similar but non blocking so we can't
physically share any of the code with
spring MVC but we are sharing many of
the algorithms and we're simply in many
cases taking existing code and simply
porting it over to asynchronous
non-blocking semantics we're not
changing necessarily well in some cases
we're taking an opportunity to see where
it makes sense to make changes but by
and large we're looking to provide the
same programming model and kind of a
consistent approach so that if you want
to use spring MVC or if you want to use
spring web reactive both of these are
there and you can report issues on
either side they'll make requests and
both sides will benefit from from that
here you will see for example methods
like returning a mono of user or flux of
users and of course if you're calling a
repository and that's giving you back
these kinds of types you naturally want
to return them from the controller
methods and that should all work it
looks the same but it's very different
underneath in the sense that
we could not really truly support a flux
of users underneath with spring in
bussiness already I just think about it
for a second we're giving spring MVC a
flux of users and that's push style API
the items may come immediately or they
may come later they may be latency
associated with where the user
information is coming from we don't want
to block the current thread because with
spring web reactive and using Nettie and
Tomcat and jetty any of the runtimes we
support we're actually constrained to a
very small number of threads again this
is the event loop style processing and
just like with nodejs you don't want to
block these threads the Assumption here
is reverse with spring MVC the
assumption is that you can block if you
need to do something in synchronous and
if you want to be asynchronous you
return a deferred result you have to do
something explicit here the assumption
out of the box is that your asynchronous
you will not block because then the
runtime model underneath will not deal
with that so for the flux of users that
means that underneath the framework and
the runtime is prepared to wait for each
item as it becomes available and write
it to the response and this is all taken
care of you don't need to do anything
extra and just wanted to point out that
we support our X Java just as well the
the annotation based programming model
is well suited for doing things like
that where we look at how is the
controller written what library is it
using and then we basically adapt to to
that I just wanted to point out a
non-blocking HTTP GET that you don't
necessarily have to use asynchronous
semantics like you can see in the bottom
we return a mano of user but if your
method is synchronous and non blocking
to begin with there's nothing wrong with
returning a user that implies
synchronous semantics right if you have
to get the user and block you would have
to block but if what you're doing is is
just say for example instantiate the
user or
doing something that's not walking
there's no need to return a mono you can
just return a user and then we deal with
that as well same thing on the HTTP POST
site and this is where it might be a
little bit more interesting because if
you can think about spring MVC giving
you the request body as an asynchronous
type that means that it has to fully
process and convert before it invokes
the method and that's not something you
do easily with a single pass through in
a thread like we do in servlet model
where a bunch of filters and then a
servlet and then servlet calls the
dispatch of servlet calls the controller
method all of that happens in a single
pass here we can actually do this in a
completely non blocking way and call the
controller method when the user is fully
instantiated we do have a web client as
well this is a very integral part of a
non-blocking story because you're
probably likely to use something like
this say for micro services or
distributed applications that are making
calls to other other instances and using
the the web client allows you to do that
in a non-blocking way maybe you can make
multiple calls and then you can
aggregate and send this all back this is
all very natural and very very well I
don't want to say straightforward if
you're looking at this for the first
time nothing about this is
straightforward but once you begin to
get into it you you appreciate those
facilities the way to declare the logic
is quite powerful and if you have to
replicate the same with present-day
capabilities dealing with all the
asynchronous callbacks you then you
begin to appreciate what this does and
how powerful it is so this is kind of
the big picture I want to leave in your
mind to get oriented on the left hand
side we have the spring MVC stack
with traditional servant container then
server the API on top and then spring
MVC this is what we're using today and
this is by no means going away in fact
this is very much an expectation on our
behalf on our side that a vast majority
of applications will continue to use
that and we have no intentions to slow
down or to phase it out
in fact we're providing a parallel model
on the spring web reactive side where
you'll see that we're expanding the
number of runtimes so it's not only
servlet containers but it's also nettie
undertow then we have this reactive HTTP
adaptation layer where whatever the
runtime exposes we're adapting that to
reactive streams a kind of a common API
and then on top of that we have
different programming models we have
spring web reactive that's a new module
next to spring web MVC which has many of
the same facilities but again in a fully
asynchronous non blocking way and of
course the most natural starting point
for us was to provide the same
annotation based programming model
because that's what's with everyone
knows and there was no reason not to do
that because it's not blocking
fundamentally and you know you have
flexible method signatures it's okay to
use that in a non blocking world as well
but beyond that especially since its
spring 5 where Java 8 plus as a baseline
we began to receive questions well could
we imagine a more functional way of
mapping or routing requests to handlers
may be going or looking beyond
annotations so we're beginning to
explore that route as well again we're
providing choice and this is something
that makes sense this is an example of
functional style web routing so this is
an alternative to the annotation based
approach it is very transparent by
comparison and very very lightweight
because when I say lightweight I mean
there are very few classes behind all
this
on the spring MVC side in order to
support the flexible programming model
we have to do quite a bit we have to
introspect the methods we have to
discover the annotations then we have to
look at the method signatures we have to
decide how to convert and you know the
different Manos observables different
things that we have to deal with there
here you see constructing a route and
your fully in control this kind of flips
the model from an inversion of control
to explicit control with functional
style delegation and there's a kind of
DSL here for defining routes and at the
core of this are our functional
interfaces there's a handler function
there's a routing function and these are
all single input single output requests
and response and then the request gives
you a bunch of facilities to deal with
extracting the body but everything is in
your hands
it may take a little time to digest but
here I'm just presenting it so that you
know that that's something we're working
on and this is a complete application
here you can put this in a main method
and run it I mean that that's how
powerful this is also from the point of
view of writing a few lines of code
we're creating a router function and
then turning it into an HTTP handler and
then installing it on reactor nattie
server and if you want to get started
with this probably the quickest way to
try it is of course with start spring
i/o just make sure you select the
version two snapshot and then type
reactive and you'll find it and if you
want to find out more about the reactive
starter there's helpful information at
the repository where it's at at the
moment it's still experimental so you
can take a look there and see
instructions on how to switch to
different runtimes etc and there's also
a manual bootstrap which is also not
many lines of code so you can take a
look at that in the Spring Framework
reference and that's all
I wanted to talk about before we close
we I see we have five minutes any
questions yes okay question about how to
deal with security context and other
kinds of context yeah so there there are
some things that don't have a good
equivalent in a functional world you you
tend to pass everything where it needs
to be available so we're still looking
at how to do some of this spring
security at the moment there is an
effort to in parallel provide facilities
so that's that's ongoing but this is a
known challenge we're fundamentally
switching from a single thread model and
it was very convenient to put something
in thread local context and then use it
but now we're switching threads were not
in a single thread and it's not as easy
and it's even dangerous and maybe not
even a good idea to do that so we have
to find new ways to do things like that
question okay question about JDBC that's
a good question
in fact one of the natural ways of kind
of narrowing down who is this for even
is to look at your stack what are the
kinds of things you need to do in your
application if you need to use JDBC at
the moment mmm this is probably not the
best choice because there isn't an
asynchronous driver for JDBC it does
it's not to say that you can't do it but
it's just not the best fit because you
can't make the most you still have to
fall back to using threads there is an
effort underway so we heard at JavaOne
about a month ago for creating an
asynchronous JDBC driver I think
probably something along the lines of
Java 10 or maybe before that in the form
of drivers for specific databases so
that that's coming I know there is some
code out there already to look at but
it's still not there yet
all right well thanks
oh one more okay so what about exception
handling in the controller you can still
define an exception handler method just
like you can in spring MVC and we will
do the right thing it's a little bit
more involved in with spring MVC because
we're not in a synchronous invocation
model in fact when you return a mono of
something that means that most likely
your controller method is not directly
throwing an exception when we return
it's gonna happen later when the user
comes through on the mono but we deal
with that there are operators that
reactor and our Java provide and you can
catch those error signals they're no
longer flying through a stack because
it's not a single thread call stack but
we deal with that and we route them into
the exception handler method well thanks
very much for coming to the session and
I'll be around in case anybody has
questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>