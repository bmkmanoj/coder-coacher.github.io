<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>From 0 $100 billion: Inside lessons on how to scale your dev workflow by Michiel Michiel Toneman | Coder Coacher - Coaching Coders</title><meta content="From 0 $100 billion: Inside lessons on how to scale your dev workflow by Michiel Michiel Toneman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>From 0 $100 billion: Inside lessons on how to scale your dev workflow by Michiel Michiel Toneman</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OMrASg7dx-E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay hello welcome this is my first time
at devoxx so please be gentle and this
screen is awesome big my name is Nikhil
tournament I'm I'm from EDM at the end
as a payments processing company and
today we'll be talking a little bit
about fish move that's much better
how we scale our company from zero when
we just had four engineers on board to
being able to process a hundred billion
dollars on a yearly basis and that's
quite a large amount and we're giving
this talk the we talked about what could
we give this about so we could do deep
dives about all of our technical
integrations some of the frameworks
we're using or from the frameworks we
developed but we didn't been doing this
for ten years so I think it's sometimes
also good to look back at after 10 years
what what works what didn't work and for
somebody who might be starting or it
might be two years into their project or
four years into the projects give some
helpful advice on things that works and
things that didn't work so I'm hoping
this will be useful for you
so first quickly what do we do otherwise
I think this is going to be a rican
fusing talk so either there's a payment
processing company and we really sit
between the merchants who's trying to
sell something whether that's in a
physical store using a pin terminal or
AV terminal or an e-commerce transaction
happening on the web somewhere or a
mobile transaction so whenever these
transactions happen IDM sits between the
merchants and all the payment networks
whether that's MasterCard Visa or
something very specialized to region so
that could be mr. cash in bond contact
mr. cash in Belgium there could be ideal
in the Netherlands but it could also be
a lipe in China or something like
boleros in Brazil
and what we're really trying to achieve
is to make purchasing as smooth and as
seamless as possible we try to remove
ourselves completely from the flow so
that's probably a reason you've never
heard of Aegean or you might not have
heard about Yemen before the regardless
of where the purchase takes place or how
the purchase takes place we want to make
sure that it's it's as seamless as it
can be and I think the reason why we're
so successful at this is because we are
using IT to solve today's problems for
merchants we're not looking ahead and
what's happening in ten years because
the world will have changed in ten years
who knows what's what the payment
landscape will look like then but there
are many many problems for merchants
especially when they transact worldwide
not only in their single country but
they're trying to sell stuff in Asia or
trying to sell stuff in Latin America
and it's quite quite difficult for them
so who do we do this for well we love
our customers we're really proud to have
all these great companies on board and I
think you'll recognize that probably all
of you in this room were of some time at
some point used at the end maybe for a
lot of things to whether that you are
writing an uber whether you have a
Spotify account or Netflix account if
you're in the Netherlands you will
probably have purchased at the back
Wharf at some point or your purchases
gone from Etsy so at some point you will
undoubtedly have used a DM and our
merchants love us in the same way
because we enable them to to grow and
expand their business and give their
give himself a competitive edge over
their over their rivals because they're
using our technology essentially so what
does that look like well I think any
company that has a high degree of growth
will show exactly the same graph a basic
exponential graph and to put that into
perspective so we've processed for all
of our merchants
about a hundred billion dollars this
year give a little bit of context around
that if if you're on the platform if you
joined as a developer in 2010 a day's
worth of processing so we did all our
terms actually bundles them up into a
day today we will be doing those same
management actions in five seconds
so that grows really really quickly
so this is a nice glossy part but what
you're actually trying to do most of the
time is this you have as platform which
has a requirement for zero downtime its
financial transactions you cannot afford
to mess up anywhere and you have to keep
your systems running and and it's like
you're changing the wheels of a car with
that stopping it these guys are much
braver than I am I don't think I would
actually physically try to do this but
sometimes operating and and changing
stuff on the platform feels a little bit
like this and with various degrees of
success how we do things sometimes they
work out sometimes they don't work out
really well and as you grow everybody
makes a lot of mistakes we've made
failed so many times at things but we've
also succeeded many times at things and
I think what I want to do today is to
share some of the stories of things
we've learned along the way things we've
learned as we grow things we've learned
as we failed so who knows about maturity
versus complexity
it's a idea from Pinterest good I don't
see many hands it's not my idea it's an
idea that's put forward by Pinterest I
think it's really interesting because
I've always intuitively felt this way
but I've never been able to put it into
words so Pinterest was very effective at
as showing us what the maturity versus
complexity graph looks like
and they basically define maturity as
the blood sweat and tears you put into a
piece of software divided by the
complexity of the software
now anyone who's on doing on-call DevOps
work intuitively knows knows what that
means because there's nothing really
worse than looking at atticus all at
3:00 3:00 a.m. in the morning everything
is on fire customers are angry you feel
just lost the massive amount of data and
all you see is this obscure error
message you've never seen before
so the what's what's Pinterest defined
is to say look every every product
you're going to deploy has a certain
inherent complexity and it has an
inherent maturity and if you get it
wrong if you are on the red side there
with a really complex piece of software
you're deploying into production with a
very low maturity your your life is
going to be a living hell everything is
going to be on fire
and putting stuff into production is
really really hard because something
works well in your dev machine but in
order to get it into production you have
to you have to deal with deployment you
have to think about availability and
probably multiple regions you have to do
the provisioning of the the required
computing power and storage yes we think
about updates data migrations for for
upgrades you have to know about its
failure modes back up backing up to the
data recovery and you actually have to
go all the way down to hiring and
training so it's important these
decisions need to be made properly and
just to give some examples for instance
a relational database if I was deploying
Postgres it'll probably be around here
in the quadrant but you could also
deploy something like Hadoop and I'm not
saying Hadoop is a bad product I'm just
saying it is a relatively complex
products with a relatively low degree of
maturity so you have to invest very very
hard in deploying that into production
if you don't want to have massive
failures you could also be looking at
something like subversion so this is why
this bit Azure
if you were today the plot is deploying
your source code repository with
subversion you're probably on a slightly
too conservative part of the scale
you're using an overly mature products
with a low degree of complexity and you
probably get more benefit from something
like it these are these are fairly
obvious em for ancient tool for for
templating again something like mustache
would be better so if you experiment
with a new piece of technology you're
adding to your stack make sure you do
your homework if it's a a simple piece
of technology like you just swap out a
jsonparser probably having a deploying a
low maturity product isn't really gonna
break anything terribly for you but if
you if you change your a database for a
no sequel solution for instance you have
to be very aware of what the failure
modes are and how maturity from the
development communities around it so
boils down being hyper-rational with
your stack so there's an what an F
Formula one steering wheel looks like
and as you can tell it's hugely complex
so a Formula One car is insanely
specialized for doing one thing really
really well and that's driving Formula
One races at everything else it sucks if
you were to get a car which do you want
to sometimes drive fasting but you also
want to be able to do the school run
with your family you're probably better
off just getting a BMW and for many of
the choices you make around technology
that same sexy formula one very
specialized with with something that's
on the one one hands always enticing on
the other hand you have your proven
technology which is almost boring by
comparison but it's probably going to
get the job done better and I think the
golden rule here is that if a tech giant
is putting out a piece of open-source
technology which is helping them solve a
particular
use case you can be very very short
insanely specialized for that use case
so LinkedIn uses Kafka
for for their analytics because they
have a insane amount of analytics data
they need to process Amazon has
developed a dynamo later Cassandra and
the Cassandra use case is very specific
to Amazon but Amazon wanted to do is
make sure that when somebody purchases
something and it put it into their cards
that that write of putting something
into that card always succeeds because
Amazon is all about selling stuff and if
you fail at putting stuff into your cart
you're losing business so the right
availability is the specific use case
for always being able to write it's a
specific usage for Cassandra now
whenever you think of Cassandra looks
like a nice fit for my use case you have
to think does it actually match your
exact use case and Pinterest defined it
in an article which are recommended to
read which says stop using shiny new
things start using my sequel now I'm not
a big fan of my sequel myself and more
Postgres guy but but I think it makes
that really valid point another what
article very similar is you are not
Google by ozone on a I'm not sure if I'm
pronouncing that right and he put a term
into how she'd rationalize looking at
you deploying your stack and choosing
your technology and he called it Sun fat
also well worth a read and you'll find
that this established technology stuff
which is really boring is surprisingly
effective if you use it well some of the
use cases are for instance with a
company like Google putting out a piece
of software if they put it out five or
six years ago into the community chances
are that the computing landscape now is
completely different do you know that
you can buy for instance one terabyte of
RAM for about three thousand dollars so
why not just fit your entire data set in
rather than looking at some fancy way of
optimizing your i/o in the same way
someone like a Postgres database has
performance constraints why are these
performance constrains there because it
has a very high level of transaction
integrity and durability if you don't
need to elect you durability you can
simply set a flag that synchronous
commits to off and you get a transaction
durability goes out the window but you
get a massive performance boost for it
and Marty Weiner from pintura said
basically the same thing that after a
year of just putting out new technology
for every single problem they they face
and scaling that everything was on fire
and they were basically had their ops
teams running day and night and just to
put out all the fires and everything was
breaking in their own special ways so
enough of that talk a little bit about
something we encounter called merge hell
this by the way is the worst traffic jam
in history it's in China you see 50
lanes of traffic I didn't even know
there were highways with 50 lanes of
traffic and took 12 days to resolve so
that's a really bad traffic jam I think
I thought Antwerp was bad and so when
everybody wants to commit at once you
get into marriage hell if you're in
scrum teams and you're at the end of the
Sprint you know exactly what that looks
like and we over the years we've seen a
pattern emerge that whenever projects
failed that a large proportion of those
projects had two things in common first
thing is they were developed by a
developer without who's keeping it to
themselves so basically keeping the the
code outside of the main line for a long
time basically going over the code
not not consulting with colleagues and
finding out after a while that they were
getting digging themselves in deeper and
deeper and when they are finally
pressured to release because of because
because the project needed to be done
there was a promise made or a
contractual obligation with her with a
customer and when they tried to commit
it they committed just before the
release so they're pushing a huge body
of change of which nobody had seen
before which nobody knew about onto the
main line just before a release moment
now that is when you get into marriage
hell so a full of ways of how can we
make it possible that all the developers
get early access to each other's changes
because you see somebody else's changes
come in you can do something about it at
that point and you can you can optimize
their so just to quickly show you what
our release procedure looks like
everybody develops on our main line so
no exceptions you don't get to run a
project branch for six months what you
do is you just develop on the trunk and
whenever we want to prove something into
production we branch off from the main
line stabilize that branch with patches
and then once it's gone through all the
testing regression testing it gets
deployed to our integration environment
and we're merchants get early access
there they can spot anything we might
have missed and if we were happy we push
it into production now any change we do
we first create a due to change on the
main line as I said but if we need to
fix something on a production branch the
change is first applied to the main line
and later ported to the production
branch at a certain stage with us
production branch is in production we
want to start with a new production
branch so we fork off again from the
main line start stabilizing that branch
at that point we
two production branches which are active
once that stabilizes and that gets
pushed to production we terminate the
old production branch and the new branch
takes over so that's where we what we
call installing a release and as you
guess if there's at any one time to
production branch is active that means
that any bug fix you do on the
production branch needs to be ported as
well to you your new production branch
or your pre-production branch as well
and what we're trying to do is get
everybody to commit early commit often
so commit early commit often means that
all developers get to see each other's
changes at the absolute earliest
convenience which means that if you find
that your you get a commit a conflict on
commit or you see code coming in in the
project you're working on the idea is
that you need to communicate with the
other developer or the other project
group and try to resolve how you're
going to put these changes into
production or you're going to find a
common set of changes which will satisfy
both projects now the thing to enable
this commit early and we need to be to
allow our developers to commit partial
projects I know that's a big no-no in
certain development communities but you
have to be you shouldn't be afraid of
committing unused code so if somebody is
working on a larger piece of software if
they have part of its completed get them
to check it in early that means that you
might actually have a release where a
piece of code is in the release although
that code path has not yet used that's
something you just have to take for
granted and you might want to make sure
that everybody commits often so don't
sit on your changes too long we can
incentivize that quite easily by having
everybody commit on the main line why is
that well if you get a check-in
first and the other guy gets to check in
later
then he has to deal with the conflict so
that's the easiest way of incentivizing
this because everybody works on the main
line if there's a conflicts the guy who
commits omits last gets to solve it and
in the end what we're trying to do this
for is encourage communication no amount
of tooling can is a substitute for good
communication between developers and
between development teams the there is a
trade-off here we accept a certain
amount of pain from everybody getting
early access to to each other's changes
that stuff will break stuff sometimes
it's really frustrating if you're trying
to work on something you integrate
everybody everybody else has changes
this stuff breaks for you but the net
result for us is positive now we are
starting to find that that our team is
growing I think we have a tech team of
about 150 the vet or about 110
developers and another 40 tech staff
that are this trying starting to reach
the limit of our feasibility and we're
looking at other ways to improve that
process because the amount of pain
you're starting to suffer with that
amount of developers all committing on
to the same main line so even for us
starting to become a problem so my next
favorite thing
zombie bugs in a previous life as a
developer in a previous company there
was a lot of patching going on but all
the patching was manual so developers
would write would create defiles and
these diff files would be applied over
the current the current branch on the
main line and a cause basically caused
hell people would forget to include
certain certain patches developers would
get a conflict and try to resolve it
poorly
what we found is that badly resolve
conflicts and forgotten patches started
to reject old bugs so things that have
been fixed before got unfixed in later
patch releases and also when everything
when something is on fire everybody
concentrates on putting out the fire
that means everybody's looking at an
easy way to patch something put a patch
out put it into production and then when
everybody relaxes because the thing is
is fixed then the developer would commit
to the main line now if multiple things
happen right after each other and you
have multiple fires everybody's always
just trying to put out fires and in such
a scenario people forget to commit to
the main line now if you commit forget
to commit to the main line at next
release you're just going to run into
the same problem so you're always trying
to get to to work to avoid these omni
bugs from occurring and actually a nice
thing if you set up your release process
like this is there's no good reason for
a zombie bug whoever exists and we
actually don't really ever have them and
the reason is every fix is first applied
on the main line and then ported over to
to the production branch that porting
over is it's enforced with a commit oak
so there's just simply commit look in
the source code repository that says if
you have a certain change you want to
put onto the production branch you need
a four eyes policy you need a reviewer
and B you need a revision number on the
main production on the main main line
before you're allowed to commit that
doesn't mean those two changes have to
be exactly the same you don't have to
have a like a perfect one on one patch
on to production because what you're
looking for is always to minimize the
risk on production so you might have
something which is just a simple guard
against a certain edge case and on the
main line you might want to actually
change change the framework to avoid
that situation from occurring at all but
important thing is that you don't have
you always make sure it's fixed on
mainline first it's a little bit of a
change the reason we can be successful
as a business is because we have a lot
of change on the system a lot of changes
means a lot of new functionality for
emergence the platform moves moves
forward really quickly and releasing it
is simply a process of pushing
improvements of existing code as well as
new and cool software features into
production now as your as you grow and
you have more more developers the rate
of change increases and the monitoring
of your production your fe of your
software going life it becomes more
complicated because what you're checking
basically if your software is going in
life is is that software behaving as it
was before so are no regressions
happening and also for these changes
which are happening do these are these
changes these features or these this new
new new pieces of functionality
are they having the Intel are they
working as intended so that's just kind
of a split role for somebody monitoring
a release it's it's on one hand it's
making sure that everything operates as
it was but also checking is this new
piece of software doing exactly what
it's supposed to be doing and to
symbolize that with a BB has a very
useful low low critter but yeah if you
annoy it it stings you and what was
starting to happen is the ops teams
monitoring the installation of the
release we're getting overrun by the
amount of change so before you know it
you start missing things that are subtle
things that are going wrong they might
not throw big error messages it might be
quite subtle but the amount of changes
people were just really happy we're
monitoring the system if everything kind
of seemed to be okay
but if a certain piece of functionality
was not having the intended effect or
was misbehaving it was quite it started
to be missed and I think anybody who has
a significant codebase will have at some
point created a little toggle that says
okay this is the old code path this new
code path or I don't want to activate
this just yet I want to be there and
monitor it closely when I activate a
piece of code I think if you're from
booking you called experiments everybody
has their own lingo my recommendation
would be centralize this because before
you know it everybody is creating their
own unique and special ways of creating
these little software toggles software
toggles have a couple of real benefits
is that you don't need to you can
separate out the deployment of your or
the activation of your change from the
deployment of your change but the
disadvantage they have is that they
leave old code paths in your car in your
code because you need to have both code
pads with paths available when you
activate the software toggle and there
is no incentive to clean up your old
code path that makes for messy software
but worse is that if you have an old
code path which is already being which
was never cleaned up you run the risk at
some point maybe because your toggle
framework is misbehaving or maybe
through a refactor which and a wrong
assumption and you can accidentally
start reactivating old code a code path
with your pretty bad consequences
sometimes so what you want to do is make
sure that every we call of features they
drive to the enablement of these code
paths but every feature you put in there
is is goes through central framework and
that central framework knows who the
developer is and also when that feature
should be removed from the platform so
you need to expiry
of that feature as well so by having
ownership and having expiry you can then
automate the process of alerting your
developers of hey wait a second you
still have a dead code path it's your
code path you need to clean it up if you
haven't activated the feature don't
forget to activate it or get rid of it
and and what we do is with these
features if we expose these these
features by default to everybody on the
development system
so regardless of of what feature is it's
always on for everybody who runs on the
integration platforms and on the
development systems that that reduces
the risk of these features being dormant
until they get activated on production
and then the first the first thing we
know about and that goes wrong is when
we see it on production so these
features are really well tested during
the integration and during the
development phase and only when but
there are still dormant on the
production system and them on the
production system we can toggle these
features one by one we could canary on a
single server so we have a through J mix
we expose tooling to activate these
features on all these code paths on all
servers at once but we can also just
toggle them on one so we can canary and
we can even do a percentage based canary
so say only one out of every ten
requests gets guests who see this new
code path the J mix part of the
framework also manages persistence so
that we restart an application it simply
picks up the D features as in the state
they were before I think lastly if
there's one thing we've learned over the
last 10 years is that it's a really good
idea to avoid making early choices so if
you have the if you're looking at
solving a particular problem or you
anticipate something becoming a problem
in the future it's a really good idea to
about us maybe to plan ahead a little
bit but please don't make any choices
for problems you don't have at this
point there's a couple of acronyms which
deal with this you might know them you
ain't gonna need it is one of them but
making an early choice or making a
choice too early locks you into a
certain direction that means that you're
deploying a certain solution to a
problem you think you might have at some
point in the future that if you don't
know what the future is going to hold
the future might take a completely
different direction your product might
take a different direction and your
finds inevitably that you've invested in
a piece of technology or you've invested
in a change which the moments you get to
the point where you thought you needed
it you either don't need it anymore or
that the world has changed sufficiently
that it's completely inappropriate for
what it does and then you have to deal
with getting rid of that choice you've
made and making a choice another way so
some examples of that is when we started
10 years ago we decided to use Postgres
for a big financial system ten years ago
that was almost unheard of today that's
not unheard of but some of the things we
factored in was once this scales up we
are going to have to be we're gonna need
some enterprise database features for
doing things like streaming replication
for data distribution for battle for
more sophisticated backups there will
need certain features which are probably
only available at this time with oracle
sybase but we can we can get by with
Postgres for the first couple of years
and by the time we got to the point
where we actually started needing those
features and it became infeasible to do
a full database backup the normal way
because the database was just too big I
think our databases now runs that
primary database runs at over 50
terabytes so you know you can't just
dump a low to a database like that by
the time we actually started meeting
there
Postgres had evolved to the point where
it natively had all those features
already and actually one or two of those
features have been sponsored by again
specifically with the development
community of getting the features in
because it's much cheaper to sponsor a
project with a couple of Regas
developers then to actually pay
commercial licenses on a large
commercial database
another example is charting so as I said
our main database runs at about a
hundred and twenty billion rows for the
largest table
it's the database is about 50 terabytes
in size and we saw a long time coming
that we needed to shard this data so
it's a big accounting system and it's
one of the primary features of an
accounting system is that you can always
have one single source of truth so
shorting is difficult and we explored
many many scenarios and we prototyped
out about three potential candidates
three did three feasibility prototypes
which we all dropped and only last year
when we really thought down now we have
to make it make an actual decision we
invested in what's currently our
solution which is looks completely
different in how we envision viciousness
about seven years ago when we already
we're looking at the problem of how are
we going to shortlist data and what we
actually did was create a streaming
framework and just have multiple copies
of of the same database or is it the
same schema so we just clustered the
amount of accounting systems we have new
separate accounting systems and they all
provide they're they're the output of
their data so every record they write
out they provide that into a streaming
framework and then we have consumers
reading from those streams and creating
things like
reports and everything where we need
that single source of truth so that's a
pretty big engineering effort but I'm
confident that if we've made that choice
say five years ago we would have come up
with another solution which would have
been probably pretty inappropriate now
and would have probably been a big
headache to to solve
so keep it simple as well having complex
technology means that you need to invest
a lot in understanding the failure modes
of that technology understanding how it
works in detail hiring again and these
are things I've I've already tackled and
one good example is low balancing so the
nice way of doing low balancing across
multiple data centers is to have
something called a hardware global load
balancer which is a really complicated
piece of machinery it's very expensive
and it does very complicated tasks we
designed all our API is to be stateless
so what is actually easier than just
saying I'm going to load balance over to
data centers with round robin DNS it's
it's you know it's it's stupidly simple
you just have DNS and you just round
robin DNS just means you're rotating the
IP addresses you gave back which means
that about 50 percent of the
transactions go to one data center and
fifty percent of the taxes go to another
data center something happens in one of
our data centers could be our fault
could be one of our applications which
is dying it could also be a power
failure or the incoming network might be
having a routing problem something we
can do nothing about but we just have
our DNS set to to a sixty seconds time
to live which means that the moment we
reactivate a change in DNS it takes
about 30 seconds for most of the traffic
to disappear from that data center so
again super simple solution which is
very very robust very easy to understand
we thought when we started 10 years ago
that betters a choice we're definitely
gonna have to revisit because your life
is never that it couldn't be that simple
but in fact when we look at it now is
we're just so glad we never chose
another solution for it because it just
works that exceptionally well and it's
that'd be so easy to understand and
maintain so that brings me kind of to to
the end of my talk I'm I think the whole
spirit of this is that's
I want to share knowledge about what
we've learned in the last 10 years so
I'm definitely looking for questions
from the audience before I start taking
questions we are always on the lookout
for a new engineering talent so if you
if you feel we're doing interesting
stuff please visit our booth we are
right at the entrance it would be happy
to to share some ideas over coffee there
but are there any questions go ahead
sorry yeah so we are here yeah
yep yep so I think is summary your
question is if you have stuff which is
not all being finalized at the same time
so at different times in the time
periods and you are cutting a production
branch somewhere halfway and we don't
run formalized sprints so we don't all
kind of converge on the same at the same
moment then you are gonna have semi
completed projects in your next release
I've never seen the problem with that I
know a lot of development organizations
see their major problems with putting
code into production which is not used
yet I think it's something that is quite
logical we release not as often probably
as some of you before a financial
institution we release about every three
weeks do a full system release that
scares the hell out of our regulators
they don't like give people and they
don't seem to really understand that
it's like walking if you just woke every
day you're not gonna fall over but if
you stand still for six months you try
to take a step you're probably gonna
fall they don't really see that
something you do often it gets D risks
by doing it often and specifically here
we just accept that incomplete projects
are being pushed to production if
they're not they shouldn't disturb the
total they should they should be
encapsulated to providing the building
blocks for creating finishing the
project but they shouldn't be incomplete
in the sense that they don't work or
they are going to cause operational
problems but if it's something we accept
another question go ahead
I am at be interested if you have any
compliance requirements as your
financial provider sources provider and
how do you handle your future flipping
houses in a compliant way yeah yeah so
good question
again we're a financial company we're an
IT company but also you know pretty
heavy on the finance stuff and that
means that we do get regulated in facts
too we become so big that it became
natural for us this year to apply for a
banking license we're now under the
European you mean a European bank and of
course that does mean your compliance
aspect of writing your software changes
you have things like PCI compliance of
course because we're handling credit
card data you have your auditory
compliance on the financial side these
things are all important and they they
having an agile workflow does not
conflict with your compliance
requirements I think that's that's for
first and foremost but it does mean you
have to be quite strict about certain
things so what we need to be able to do
is to show that we are in control of our
software development process because it
doesn't really matter where you're if
you're releasing every six months
you're dumping essentially a huge amount
of change at a very infrequent pace and
onto the system we can show that that we
have good code review that every every
single code change is actually checked
before it goes into production and
that's that's actually physical printout
where somebody just has a tick list of
every SVN commit and it's I mean it's
for every release it's about that much
paper but just being able to provide
that evidencing and proof is enough for
a regulators to to see that we are
actually doing the right things
yeah good also a good question um do we
have one single massive application is
the monolithic application so no it
isn't it's a I think it's it's float
somewhere between a service-oriented
architecture and micro services but they
all why they don't fit micro services is
that all of our software which runs on
our production system is tagged and
branched at the same time so they all
live in a single code repository and
there's with single branching a strand
and patching strategy and the version
versioning is all unified across the the
software but each service is
independently deployable it's completely
separate in its in its resources from
other services so there's no individual
work work streams which have individual
release cycles also a little bit of bad
experience
we've been bitten before by in previous
previous jobs by having having a lot of
complexity about version matching saying
oh this version needs to be deployed
with this version it doesn't actually
work with that version and I think these
are all solvable problems I'm not saying
we're not inventing - we don't want to
reinvent the wheel but we're not also
doing I think one of the keynotes said
every problem in software engineering
has already been solved it's just a
matter of you know applying those that
knowledge but for us dealing with just a
simple versioning and a simple
tagging structure across your entire
code base means that integration testing
is just that much simpler really and
regression testing but it's an arbitrary
an arbitrary choice I actually admit it
yeah so the codebase is getting too big
I've I've forgotten exactly how much but
it's it's it runs into millions of lines
of code so what we've done recently is I
also mentioned that the code base is
getting too big for everybody to work on
the mainline the way we've always done
that so one thing we've done recently is
implemented Gradle and just separated
out all of the the software basically
into a small Gradle sub projects and
that becomes much easier to manage we
haven't gotten the full benefit of it
yet but it's it's getting there
definitely any other questions yep yeah
okay that's also a really good question
so I talked a little bit about just
briefly talked about streaming and
actually did talk about this on the
lease web conference about how our
streaming technology works so the
problem we have is we used to have we
have we have all these front ends who
are taking payment transactions they
store these locally I mean one of the
nice things about using an open source
database is because you're not talking
you don't have licensing costs for your
database you can afford to put a
database on every front end and that
works out really nicely so there's a
little bit of local storage on each each
front end they store the transaction and
then pour that over back to the central
back office that means we can decouple
the front end completely in terms of
availability from the back end the back
end is used to be a single a single
counting database and we would basically
go into the database with queries and
just pull reports pull things like
what's called capture file stuff we send
off to MasterCard Visa and do our
reconciliation based on files we get
back from MasterCard Visa and banks etc
so there's a lot of this single source
of truth and fetching data from the
database at the moment you say okay I'm
gonna have a second accounting system
that all goes out the window
the moment you you split
you can no longer I mean technically you
could run the query here and run a query
there and then combine the results but
you're not really getting any benefit
from your charting at that point because
you're just multiplying the amount of
queries so what we did instead of that
is just pull a stream of data from from
from each each transaction and after an
action data is quite big it's completely
denormalized
so we face two challenges there one is
the size because it's it becomes every
transaction becomes quite big because
it's just the normalized version of of
of a highly normalized schema in the
accounting system so one thing we did
there is used set standard with a
dictionary based compression it's quite
nice I'm gonna recommend that and we use
alibaba's fast jason-2 to serialize
because we did want to have human
readable scheme Alice data
representation now those that streaming
data goes into so we investigators Kafka
because I mean that's the obvious the
obvious candidate there Kafka is amazing
I mean I think it's it's an amazing
product
it's brilliant of what it does one thing
it doesn't really do well is guaranteed
consistency and again finance
consistency it's kind of a thing so we
need to be very very sure if we have an
exactly once scenario and then when we
are processing data as well that when we
commit the results that we commit the
the point we are in the stream together
in a single transaction with the work we
are committing as well so that way
there's no chance that if something
crashes in the job or whatever at a
certain point that we can exactly
rollback and guarantee we are at that
point in the stream and this is the the
work done for to get to that point and
that there's never a mismatch between
those so I think Kafka and the latest
release is actually getting something
pretty similar to that but before when
we were when we started running this
definitely not so we built our own
cough-cough ask solution that sounds
really weird calf care solution on on
Postgres because Postgres we understand
really really well Postgres does all the
the you know durability of transactions
like purely ask the database it's it's
it's awesome what what it does and it
was performant enough for the use case
we we threw at it so we just build a
relatively lightweight structure based
on this serialized normalized data
structure denormalized data structure
and then just build is this whole
concept of of streaming so have
producers and consumers on top of
Postgres and it's working marvelously
actually last question i have one minute
left
what are the big challenges for the
future it's a very good question so we
jokingly say we want to get 10 times as
big
well it's not that joking because when
we were 10 times as small as we are now
we already said we wanted to get
probably a hundred times as big so you
we want to get ten times as big at least
and that will mean we are currently
almost doubling every year so that means
that's you know we have about three to
four years to achieve that I think we
need to grow out our development
organization we need to grow out our ops
that's going to have his own challenges
the amount of volume we're going to get
on the platform is going to be the
challenging I think we've laid a
foundation with things like doing the
streaming exercising the clustering to
to grow D the core of the application
quite quite effectively but I think
mostly it's going to be about how do you
keep an agile organization going and how
do you how do you grow your teams
effectively so that's all I have time
for thank you very much
visit us at our booth</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>