<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Going global with Nomad and Google Cloud Platform by Bastiaan Bakker | Coder Coacher - Coaching Coders</title><meta content="Going global with Nomad and Google Cloud Platform by Bastiaan Bakker - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Going global with Nomad and Google Cloud Platform by Bastiaan Bakker</b></h2><h5 class="post__date">2016-11-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cZY6kLyoI7I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">ok welcome everybody yeah talking about
going global with Nomad and Google cloud
platform first of all little disclaimer
I'm neither affiliated with Google nor
with Hoshi Corp I'm a consultant at sexy
BIA specializing and continues delivery
and data center automation and as such
we encounter these products and actually
i'm quite a fan of the hershey corp
tooling such as nomads and console which
will explore this talk so going global
why border why not just have everything
in your your data center your own data
center or one of Google or Amazon and
surf everyone from there just pick any
one this is the the current list of
google data center locations and it will
be expounded so plenty to choose from so
for this talk i will focus on two of
them to benefits of having a globalized
experience and the first one is latency
latency costs and in a in an experiment
that's already conducted ten years ago
by google it turned out that half a
second extra latency could reduce the
amount of traffic and revenue by twenty
percent so that's quite significant and
actually the latency between Europe and
Asia is around half a second at least so
that's something to am yeah 22 bill to
be able to improve so the other thing
we're focusing on is failures because
even if you're surfing slow word might
not be that bad but
if your data center a local data center
is down or just well first of all the
process the server availability zone or
leaving the whole region yeah then your
users cannot reach your side so what are
we going to use today are to test
consists of the Google cloud platform
and nomads by hasha core console also by
has europe and we'll use an HTTP router
from ebay which is called Fabio which
also makes it a bit difficult to find it
and not getting some large Hank as a as
an image so why Google cloud platform
well I could have used amazon or azure
but we use google cloud platform a lot
for example in training and farmers
because it's really fast you get a vm in
30 seconds so that's nice for a tools in
action talk the the concepts are are
clear and and simple so they're easy to
to convey and to understand and also
since it's not around as long as amazon
there's just a smaller simpler website
instead of 200 different features what I
also like is easy networking because we
want to stretch a global data center
with connected networks and machines and
Google takes care of that so you have
just a flat networking in 10 range which
you can reach from all your machines and
one part that's also very nice it has a
global load balancer which will use
today to automatically get our traffic
routed to the nearest data center
so the other component is nomad is
anyone actually already using or trying
out nomad no F for everyone it's new
well nomad you heard a lot about cuban
EDC today so I'd like to compare it with
that except that it's much simpler and
as some other nice features because it's
just a single binary which is in written
in go which you can just download and
install and it does a lot of things it's
a cluster manager for your local data
center it does scheduling of your
workload on it it's also a task executor
so if you compare it with for example
mrs. marathon setup it's all these
different components like mesas master
in a maze of slave and marathon all in
one it can do service registration so
that its discovery of your services and
what I really like is that it's very
scalable and has high availability
building because it builds a cluster
which is consistent you can build it
with three servers or five service for
redundancy and all these surface will
make sure they have the same state about
the cluster based on a mechanism that's
called raft and actually that's now used
in in this war mode of docker as well
and one of the nice things of the global
state is that the nomads can do
concurrent scheduling decisions so it's
actually the only open source
optimistically concurrent scheduler
which means that if you have a lot of
course on your no med service you can do
a lot of scheduling
sessions at the same time and since it's
optimistic it will do the concurrently
without locking and in some cases that
will get a scheduling conflict and then
it will need to retry it further but
it's much faster than the other
mechanisms and in fact the the folks at
Hershey Corp which have written no
matter have done a 1 million container
challenge together with google and the
graph is here so within five minutes all
these million containers who were
scheduled and and started which is
pretty amazing and in fact they actually
run into some bugs in docker that's why
they actually start a little bit more
than 1 million containers so before we
go into the hands on stuff the tool in
action I'll show a little picture about
the setup so like I said there are three
servers and they replicate and forward
the state of the cluster and then the
clients connect to either one of these
servers to get information on there yeah
what they should run and what their
state is how many resources they have so
this is what we're going to build right
now to start with to get stuff be able
to deploy stuff on our on a cluster so
our girls are this setting up the server
cluster setting up the client cluster
and start our first job which would be a
UI for no map because it doesn't help on
building so it I think it's cool to
provision your own user interface by
yourself so let's move to the comment
line
since I'm a lousy typer I wrote some
script small scripts that will do the
most of the stuff for me but a bit a bit
manually their life done the bash output
so we can see everything that's going on
let's decide while it does it so this
creates three machines one in zone
westby one in c and one in d well it
gives a warning about the disk size
doesn't really matter we are using
Korres because that's our minimal OS and
we just want to run docker and it's
already created so let's watch it are
they already running so that's cool so
we now have three machines running with
core OS on them there are small machines
because we don't need anything larger
for a small cluster and usually actually
I do the micro machines but well I
didn't want to turn to demo gods and
have something gone wrong right here so
we can now login to our server which
also i'm too lazy to type out so ssh to
see if an i dot slash is too difficult
for me SSH nomad so this uses GG cloud
compute to SS a to the server I've done
some port forwarding I'm going to need
later on but you can ignore them for now
so now we're on one of the first of the
server nodes so we can see now matt has
been installed here and that's because
we installed a startup script where we
he created the Machine server script and
basically the service cribs we have here
are we serve script so this is basically
a shell script which downloads the
binaries we need here download Nomad
then it performs some configuration on
it and runs it as a surface so that's
what we have right now and if we ask no
Matt it status it will take a while
because it's not connected yet with test
not form tie a cluster yet so it's it's
still lonely so now we need to join the
three service together as a bootstrap so
they know about each other I could have
automated this by including it in the in
the service script but I thought it
would be nice to do with life here so we
would say server join and then the other
ones are cold let's do all three
together so now we have three service
together so if you now after cluster we
have a full cluster and we see that we
have a leader which is making all the
decisions so in any case when when a
task is scheduled the leader is the one
who decides which scheduling plan will
proceed and which one won't in case of
conflicts and the nice thing is if this
one crashes we have two left and I can
continue doing scheduling there are some
other interesting things to see like
they you can see the data centers and
I've put them in the EU
by default the region is global too yeah
to have everything in one same same
region so now we can look also at the
client side because I've configured
these service to also act as a nomad
client which means that we can actually
schedule jobs on these nodes typically
you would use the Nomad service just to
perform no matter to run the Nomad
server but for the demo it's nice to
also run the UI into later on do the
surface registry also I'm here so Nomad
melt really loves you typing notes itÃ­s
we see that there are three notes ready
and we can schedule our first job so we
go two jabs and no Matt you I will be
our first job as you can see this is a
knob gamal but actually hoshi curbs own
configuration language which is yeah
like Jason but a bit easier and it
allows comments and stuff like that so
it's quite a nice language to to do
configuration so we want to define a job
nomads in the EU region we need to
specify a list of data centers it can
run in so we want all the European ones
and for convenience one for convenience
I've also added to the data centers and
other regions so that might be handy
later then we need to specify the type
of the job in this case a system job a
system job is one that will run
all notes that are eligible this is
another option is to have a surface drop
and then you can as explicitly specify
like I want to have three instances or
five instances and this one just takes
it does it all rolling updates is
supported that's not what we're going to
look into now here is the group so now
matt has a hierarchy where a job
consists of different groups groups are
the units that are scheduled on a
particular note so and within a group
you can have multiple tasks that will be
run together on this same machine in
this case we just have one task which is
to you I and we have a constraint we
want to run it on a linux server and one
nice feature of no matt is that it runs
not only docker job but also native jobs
and it provides its own isolation with a
change route and and limited
capabilities so we can simply supply a
static binary in this case one built in
Ingo so it doesn't have any operating
system dependencies and directly obtain
it in this case from from github
configure it with environment variables
we specify how many resources hit once
including a a port for its communication
and we can also register it in the
service registry which will do later so
let's run the job no Matt well let's
first see what it will do now Matt plan
this says it will create three instance
because we have three server nodes so if
we actually run it will see that it has
completed so we can look at the status
you see you'd run in nomad you why and
we see it has created three allocations
it has allocated this this task on 33
servers and if we look at the allocation
for six we'll see it has been started
and it has used this HTTP port which I
conveniently forwarded to my local hosts
earlier somewhere here so if we now go
to localhost 3000 yes we have a nice UI
and we can see we scheduled out come on
we can see we scheduled our out drop and
we can zoom into the actual allocation
and see the logging like standard error
will show everything so that's nice but
now we just have server nodes we want to
run an actual cluster so we also gonna
install the client notes and for this we
use an and managed instance group
because we can easily auto scale this
one so we do reinstall clients and it
will also show what's what it's doing
first it will create a template which is
like the actual commands or the
parameters we gave to the instance
create but now this is a template which
say instance manager can use to create
more identical notes which are worker
nodes so again we're going to watch it
creating the notes
the client script is basically like the
service crypt except that no matt is
configured in a different role so
they're almost all running so if we look
at the Aquaman where r at the you i will
now see the cluster become life because
now we have notes also at the their
client notes so now we can run a an
actual job or below fatel a world job in
this case and inclination also in Ingo
and it will serve in a /hello endpoint
so we're going to know Matt run hello
world and we see it has been scheduled
three times because we have specified
this is a surface job we wanted to just
run on the far notes through another
constraint so we should see it here at
the jobs hello world is running and if
you look at the allocations it's on all
the farm notes and now we need to know
actually what the the end point is so
we're going to look up the the
allocation again
nomad oh I'm running out of time um and
nomads status hello world and now Matt
statist 267 and we see it's over here so
if we now do I curl to http 1320 to the
848 180 / hello f let's do our topping
properly port number where was my port
number 4 h 190 what
48 I can't type something like that ok I
see I've seven minutes left I'll simply
move form to the service discovery
because the next step is to not have to
look up in allocations to do service
discovery there to find out where your
services live so we're going to use
console which is a very nice service
registry also by Russia Corp and nomad
integrase integrates very nicely with it
so once you start a console cluster and
here is complaining because it's not
having any actual surface in these data
centers but if we look at console where
we see that we now have a console
cluster and then we should also have a
console you I 85 and now we see that it
has registered itself and no Mattie no
Mattie why and also hello world so it's
there after all and for some reason I
cannot access it so I'm now going to ask
the service registry where it lives so
we can do that to an HTTP IP I but also
through DNS which is pretty convenient
so we're going to use dig we want to
know about hello world world service
console we need to ask it on the console
port with the dns mask you could also
make it available through regular dns
port and combine it with your regular
dns localhost another
other type oh hello world so now we see
the right locations and then if we want
to know the port we need to ask a
service records so here we see that it
has the four different ports on
different nodes so if we want to put a
load balancer in front of this to make
this accessible to the public then
that's not going to work because the
Google load balancer expects a fixed
port so that's why we're going to want
to use a HTTP router and actually one
that knows about a console and service
registry so I'm going to know Matt run
Fabio and this is also one of the ports
that i forwarded earlier so we can go to
the admin port of Fabio and it will have
discovered the let's go down here where
it's my right at the bottom you can
still see hello world and I've created
Fabio to Rachel itself as well so this
will listen to a fixed port and based on
the hostname which has been configured
in the job it will forward it to the
right service so now we can use this in
together with a global load balancer so
let's configure that right now and we do
that in compute engine and then we
should be just in time here are running
services I've also created already
created some in Asia which will hook up
as well
we are going to the networking load
balancing and we want a new load
balancer HTTPS and we want folks we need
a back-end configuration to define where
our services should go that's nice that
we cannot actually see it here so we
want to have the UVU farm in there on
port 9999 we want also I'll add the Asia
one as well also well 99 09 oh sorry
wrong one and this one is 80 and we also
need a health check so the load balancer
will know when it's available so we want
to check health for Fabio and then we
have a back-end and we need to configure
a front-end our host path and rules to
be simply move forward everything to the
back-end service front-end configuration
we already have a static IP available
and we want to create this one review
yeah everything fine so what's wrong
come on what's wrong yeah review it's
optional
back end it's not happy yet so come on
oh it has not created did at all that's
nice new back-end service yeah wait come
on la la farm Asia you yeah are you
happy now create yay okay so it
meanwhile we're gonna add some traffic
to 2 d's so I'm gonna yeah time's up
sorry so we now have for a global load
balancer which is probably not healthy
yet no but if it would then we could see
our traffic to a back-end move from the
different locations to the local data
centers because Google does any cost IP
routing to the local data center cell
doesn't need D&amp;amp;S to switch to a local
region which is pretty cool and then if
you're the local data centers not
available it will switch to the most
nearest one which I had hoped to
demonstrate right now but my times up so
yeah I have to keep it like this I can
show you probably in five minutes in the
in the hole but I need to make room for
the next speaker i guess or i cannot
continue until he shows up
hmm oh you're ready there yeah okay
sorry okay it was too it's still not
healthy yet it takes a little bit ok
I'll show you all in the hallway if
you're interested later all know just
ask me everything is on let's move to
the end yep everything is on github so
the whole it's not showing come on okay
Oh slideshow come on current slide there
it is so we we can recreate it any time
with the scripts on github and all the
other links are there as well and i'll
add a i'll put up the presentation as
well on the github okay well that
concludes the talk then thanks for your
patience</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>