<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Extreme Devops using Kubernetes by Dennis Lauwers | Coder Coacher - Coaching Coders</title><meta content="Extreme Devops using Kubernetes by Dennis Lauwers - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Extreme Devops using Kubernetes by Dennis Lauwers</b></h2><h5 class="post__date">2017-11-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/g2ud-xemQ2o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everybody
so welcome to this session about extreme
DevOps using kubernetes this is of
course a sponsored talk by IBM and we
will be talking about most of the time
the IBM distribution of kubernetes so
that's why you will see ICP so ICP that
stands for the strange name IBM cloud
private and this is our implementation
of a private clouds hosting a multitude
of cloud types including the kubernetes
environment so we will be doing a dual
session so I'm going to do more of the
talking about the positioning what is
this part of kubernetes how do we
introduce that in devops what can we do
with integration into the pipeline and
then we go into a demonstration part
which will be led by Erica park and we
will go through the tool sets and see
the deployments so first of all what is
IBM private and yes I need to stand in
front of the camera
IBM cloud private is a set of cloud
types and these clouds the kubernetes
part Cloud Foundry part but also we have
a cloud automation manager helping you
with even old VM deployments in a cloud
strategy so we bundled everything
together we made sure that everything
can be deployed with a single installer
we have ansible automation scripts
already made for you you can deploy
whatever you like single cluster double
clustered Federation whatever you want
and we pre integrate it everything what
is needed to do DevOps meaning we will
have an LX stack we will have graph on
now we will have from Matias for the
monitoring so that whatever we do from a
deployment point of view you also are
able to get the operational side see
what's happening or the performance
problems are there issues
that we can have a very fast feedback
loop into that development cycle so the
whole bundling is done by us pre-tested
delivered and every sixty days we are
going to deliver a new drop of the full
platform including some of the content
the third item that you see it's all
about content the platform is as good as
the content on that platform so we will
be publishing through a public github
our middleware
but there are also all of repositories
like the Google one which you can just
enter into the platform you sync it up
and you all have a bunch of very nice
open-source tooling and middleware
available in your catalog and of course
we are also adding now the Cloud Foundry
part so that you can create also another
style of cloud services which you can
interlink with the public cloud of IBM
so that you can have access to the
Watson API or the IOT api's so the
deployment is a standard deployment so
we are not altering the distribution
from open-source it's going to be
completely as it is we just are going to
follow the releases very very rapidly so
we added a bhoot note and this is very
specifically to make sure that we can do
maintenance on the platform it's very
nice that it is there and we can do
development and we can deploy stuff but
once we are in an operational phase we
need to do an upgrade of the platform we
need to add new components maybe we want
to switch the plug-in for the overlay
networking this is going to be done
through that boot node and we are also
going to deliver a mechanism once you
have things in production that you can
do that while running the whole upgrade
so we have master nodes there you can
have multiple master nodes if you want
to have high availability part you can
have as many proxy nodes as you want if
you want to segregate proxy nodes
because you have multiple divisions or
whatever we allow you to split them up
and then you have a bunch of work
notes worker notes all the containers
are going in there and you can deploy
all your very knife applications or
through a push of the docker images
manually or you can use Helens chart
automation to orchestrate maybe a full
set of containers at the same time now
we support multiple infrastructure types
so we have x86 where we have OpenStack
and where we have VMware as an
infrastructure as a service port by
nature this is what we support we also
have the IBM power environment which you
also can have as a full implementation
and then we had a request especially
from the bank's can you also put it on a
mainframe so I can do full encryption
and to end into my worker nodes and I
can run then my container workload
inside the mainframe you can have all of
these in the same implementation meaning
I have one cluster multiple worker nodes
with multiple or different technologies
behind it and then of course you need to
make sure that you're going to do node
selector tags because you don't want to
push an image which is bound for power
to go to x86 or to set Linux it will not
happen make sure you have the tagging
and that the Helen charts are using
these tags so besides the normal stuff
that we have from kubernetes IBM is
adding a lot of stuff one of the things
that we are adding is the cluster
management so we have also a specific
and we call it the bluemix interface
where you can manage your clusters where
you can also go and have a very quick
look at certain specifications but we
also help you in deploying very fast a
kubernetes cluster so once you do a
little bit of automation you can deploy
a full cluster with multiple nodes in
under 40 minutes and that's fully
installed everything prepares
integration for the monitoring
everything is in there we will have the
in there the isolation levels why did we
do that we removed the standard overlay
Network and we plugged in calico and
with calico we can have Network policies
so that you can do segmentation for your
development pipeline or for multiple
divisions in your production so you are
able to design and create your own
clusters and then automate that
deployment so that it's immediately
deployed for your liking how are we
going to deliver it so every 60 days we
are going to do updates updates can be a
on the platform itself for instance in
December we are going to release and you
drop and there we are going to move from
one dot 7.3 kubernetes to 1.8 so we will
be pushing that as new code so on the
community edition which is free of
charge which you all can use it's just
going to the docker hub get the
Installer in there download it and then
you can start downloading and installing
your cluster from a Content perspective
we will be updating our github with all
the content all the containers
everything which is there you just need
to push the sync button from now and
then and then you will have everything
into the catalog so as I said it is a
specific implementation from IBM on
kubernetes but we leave given it is
completely open standard api's so if you
like to use cube CTL or hellim CLI you
can do that we will not work that for
any reason especially for automation
reasons if you want to integrate that
into a CI CD or into an integrated
pipeline all our uise which are built or
anyway goes to the API so we are not
doing anything special on that specific
part so you choose I can deploy it on a
single image or I will deploy a full
cluster it's just into a config file
where you say this is what I want and
then he will deploy that for you content
will be delivered through a number of
catalogs you have the get up from IBM
then you have the open source get ups
and the most
popular one is a Google one that I saw
that's always pasted in you'd sync it up
and you have it and then you can create
your own catalogue there is a image
catalog an era and a repository for your
hallam charts so that you can create
your own stuff deploy it test it etc so
enterprise-ready
we have to make sure that we can isolate
we can scan our containers it's not only
scanning the containers before they go
into a depository but also once we are
running I need to make sure that my
stack stays secure and not vulnerable
so the scanning is also going to be
implemented there we have some access
based controls but we also are doing
auditing and eventing through the alux
stack and then from an Operations point
of view full integration with helm full
integration which for instance Jenkins
so that you can start deploying your
applications just by pushing code
picking it up building the container
then creating the Helen short and then
we push it out to the environment and we
will help you also from an Operations
point of view to really see what's
happening what are my events is
everything going ok what is in the
logging etc so this is the release this
is everything that you get with a new
release here you see also the Cloud
Foundry you see the kubernetes port and
we can bind everything together in one
single catalog so from a DevOps point of
view I will now describe a little bit
how we integrate what we do and how we
push this and what IBM is also
delivering as a tool to get an
integrated devops pipeline and there we
also chose to use open technologies our
belief today is that we need to respect
the open technologies also that's the
reason why we kept the api's opened from
kubernetes and here also for the
deployment part we will be using helm
helm is one of the most popular parts to
get orchestration of containers or
container application
so we will be packaging we will be
creating the hell on shorts you will be
able to push the alum shorts into your
repository and from there on you can
start using them in a self-service and
later on we will push that to operations
so that they can also use the same
elements to deploy the applications to
production so first of all why you can
do and this is how everything started in
the beginning it is a manual push of
your Dockers in their images you deploy
that and then you need to go and create
your services on your own because once
you have a image deployed in kubernetes
by definition it's not accessible you
need to get it as a service so that you
have a ingress port and that you can
reach it so you have to do everything
manually now we automate it further by
using the element vitamins so that you
can create the hell on shorts a hell on
short can create a full environment
completely and that's not only the
docker image with your application in it
we can orchestrate how secrets are
deployed we can orchestrate our
persistent volumes are deployed we can
orchestrate how we need to interact
etcetera and also exposing these
services so everything can be created as
code sort a bunch of EML files in a
Helen short and that's what we are going
to push automatically of course once you
start doing production you need to
certify you need to make sure that these
repositories are secured and that in the
end we are going to be able to scan them
make sure that we are doing the proper
versioning etc and then once we go
further what we see especially in the
regulated environments we need to
segregate these environments so that we
have a very defined environment for
testing QA etc and a separate
environment for our production we have
the ability to federate them from a
single management point of view so that
we can orchestrate also the end-to-end
deployment going from the codes up to
the production environment
and then of course scanning as I said
not only the repositories but also
scanning everything which is inside and
running because today I have a stack
which is optimal but maybe in three
months time we find a vulnerability we
need to scan that and flag hey we have a
problem so that we can start building
the new stack push it through and then
have a new deployment or a replacement
and then we can extend the whole thing
if you want to deploy it and not only
on-premise but also use kubernetes
outside for instance in AWS or in IBM
cloud we can extend the whole thing so
that we can deploy and make sure that we
have this kind of flow between on and
off premise so how do we do that
natively with the product we have Micro
Service builded in there it is a
construct based on Jenkins
that's the pipeline there we alter the
Jenkins we made a lot of processes in
there so that once it is hooked up into
get you just push the code the Jenkins
will then take your code
built a container built the application
create a Helen short and then publish it
automatically to your environment of
course you can build your own you don't
need to use this for me this is a very
well and good example on how to
integrate into existing environments and
then of course we have also a fabric
which is automatically picking up your
deployments and then all your logging
all your information can be sent to an
Alex stack and we are also using Zipkin
if you want to do debugging on micro
service applications so this is the
pipeline Eric is going to go a little
bit more deeper into that and that's the
micro service fabric where the alex
stack is for the logging the events and
if your the middleware or your
application is able to send FDCs or
whatever to a alex stack we can pick
that up immediately you have one
dashboard to look at so that you can
investigate what's really going on if
there are
problems and you can do your debugging
from there on that is the linking that
we have if you are interested to see
what we can do and then now it's time
for a demonstration
okay so demonstration first of all I
will explain a little bit what we're
gonna do and then I will show the
various kind of aspects so how does it
typically work so the first thing you
will have to do as a developer is build
your micro services and then bring them
together in an in an application and we
will see that the micro service fabric
has a number of command line tools that
can help you in doing that and already
defining a lot of things like the belt
files the hound charts etc that you will
need later on of course you will still
need to modify it afterwards but it
already gives you a head start and and
and you can also you have the options we
will show you you can you have the
choice between various technologies so
you can do that for Java web spring or
for Java with the micro service profile
or you can do the node.js route etc and
we offer you also the possibility to
modify those templates so if you want
those templates they are just in github
and you can start from there and you can
modify them and do your own thing based
on whatever you want
next step will then be okay you push
this code in to get up and that will be
your starting point and and then we will
configure the microservices fabric to
pick up the code from there it will then
be able to do the belt of course we need
to code whatever the the business logic
over microservices and that will
immediately the build well push it to
the default in this case you can also
again change that it will push it to the
default namespace in
this kubernetes cluster that we will use
so as a developer you can just quickly
without any constraints push your code
then and try it out on on the on the
cluster afterwards we will combine with
one tool which then is also had on the
slides which is our urban code deploy
tool which will use basically exactly
the same ham charts the same approach to
push this whatever the developer
produced to the other environment so you
can then also push it to a test where
testers can validate that everything is
okay and then finally push it through to
Rudy to the production eventually with
some approval gates etc to ensure that
nobody just by accident pushes code into
into the production and so so that's
kind of the set up again it's all
customizable in many cases you will have
more stages that's all possible possible
it's just a question of configuring
things
so let's now switch to the demo view so
and yeah let me first show you a bit
that the cluster we gonna use that may
be the good thing to start with so this
is typically what you get when you log
on to this IBM cloud private use user
interface so it gives you immediately if
you is my cluster in good shape and it
gives you a few metrics about memory
consumption overall CPU consumption so
you get the first view our things and in
good shape you also see how many nodes
there are and if we look in fact we can
show you this is a demo setup where we
have one master node and to work or node
so it's quite simple basic setup but
already with multiple worker nodes so
that you can do some failover at least
but again this is completely
configurable as Danny said we
can add worker nodes you can do
high-availability setups with multiple
master nodes and and all those kind of
things but for the damn movie of course
they didn't need that the other thing
which is which Dennis was mentioning was
this catalog which is quite nice so here
you see all the ham charts that are
available in the repositories that you
added so if you add the Google
repository you will also start to see
the hunters that are available there
well you can deploy lots of open source
code by default it will be configured
with a stack with a number of IBM
capabilities and our recommendation is
also that you use the ham chart approach
to do your own de Ville deployment and
as such you could also set up your own
repository parameters which you then can
use to deploy and if you do that then
your your applications will also show up
as this kind of icons just to give you
an example if I want to use for my and
we later gonna use that also in the
application I want to use a cloud and
database for my development what do I
need to do I can basically instantiate
this I get some explanations basically I
get the command that sits behind this
chart so it will just do a ham install
of this particular chart we can click on
this configure and that would launch the
ham process it allows me to fill out the
the various parameters I'm not going to
do it here we will immediately see it
being done through the micro service
fabric as part of our application the
hunter parameters you would for example
need to specify persistent volumes where
the database will go and all those kind
of things and
that's also things that you could
configure either through the user
interface or just through the usage of
cube CTL commands because it's just our
key brain it has kind of concept so that
is the environment where our where our
code is gonna run let's now start the
journey and we gonna play the role of a
developer and let me to many commands
already
okay so I'm first gonna log in to this
to this tool so that will give me the
possibilities so I'm looking into the
IBM cloud and then I can basically
create a new project and this this is
now gonna ask me a number of questions
what do I want to really do in this case
I want to build a micro service you see
there is also possibilities to generate
skeletons for a web application for a
mobile application etc so and and as
already said these patterns they are
just available for you you can also add
your own and modify as such what is
happening here so I take the micro
service option and now you see if I
select micro services I have multiple
technologies choices I'm here now going
to take the first one the Java micro
profile option from eclipse but as you
can see the results of possibilities to
do a node or a Python or a spring
framework based selection and again
these templates are just coming out of a
get up so you can also do your own stuff
there
Oh
okay this option as you can also
generate them for usage in our IBM cloud
and then you can also make use of for
example Watson services etc and add them
to your microservice project I'm not
going to do that for now and so and this
is now going to generate my okay that's
already not too good for demo do I have
I will take the one which I already
generated before okay I'm not going to
do this I will show you an example true
to our github repository so but normally
it should generate you already all the
the pieces that in this case with the
micro-service profile it generates a
maven file for your belt it generates a
Jenkins file it generates the hound
charts etc so I'm going to show you an
example of such a project and of the
code which we're gonna use for the
application
ok so I have here a number of these
repositories which contain the code so
the the micro-service profile sample
that we are using for this example is a
kind of is quite known micro-service
example which gives you an application
for managing the sessions at the
conference where then you can manage the
comfort that the talks the people that
the speakers you can also manage then
the voting so people can vote etc and
this is the in fact the micro service
which is being used for the vote so a
few things that I want to show so and
and these are the things that are being
generated by this command-line tool
so first of all it will generate Jenkins
file which will then be used by the
micro service fabric it generates a
docker file and let me open it in this
case as it's a microp so this docker
file will also change depending on the
technologies choice so in this case it
uses the Liberty micro profile as the
base image to add then the code and of
course all these files are just the
basis you can yourself added what you
want but this will allow you already to
do so the rest the the files necessary
for doing the make the dependencies for
the maven there is the docker file which
allows you to generate the the image and
then there is also this folder with the
hound chart so it already generates
basically also a basic hound chart which
I can show you so in this case it's very
simple it and it makes use of a number
of the Tam
ladies in the in the template directory
of course this is again just the basis
so if we look it basically has the
template where for example there is a
deployment file etc so this is where we
we start from this whole combination
will generate the basic harm chart to
perform a deployment and you will see
for example it has already all variables
in there to replace the name etc so
these templates help you in keeping
things consistent and and generating the
right code again they they come out of
of there just publicly available in in
github so you can do your own stuff if
you don't like them and of course in
many projects you will start to edit
them for example here we have also added
a cloud and deployment because this
micro services using a cloud in database
so if I look here there is also a home
chart in which which will in fact deploy
the cloud and database based on a cloud
and docker image and here you can see
the commands that does there is some
stuff in there to generate the secrets
to access the database there is also the
the volume and to monitor storage
etcetera so all that this is isn't there
and comes out of this out of this
generator
so let's now so it this application in
fact has multiple of this of these
services so there is one for the voting
which we just seen there is one to where
you manage the sessions there is one
micro service to manage the speaker's
the schedule and then there is also a
web application which is the user
interface for this for this application
now what you
to notices that we deployed we put this
all in one organization and that will
also be the basis for what we're going
to do with this micro service builder
fabric
so let's now switch to that fabric guess
there are some network
and that's probably also why my comment
line field okay
back and back in so in fact the this
microservice builder fabric is also
something which you can deploy through
the through the ham charts so what it
will do it will basically deploy a
Jenkins with some pre-configured content
in it and if we want to go there I can
just see okay this is the HTTP port
where it was deployed and here is my
Jenkins and what we see is that here in
fact we specified and that it needs to
check all the projects within this IBM
Cemil whole organization and if I click
on it we will see that it found in there
those five projects the one which we've
already seen the micro service builder
vote piece and then there's also all the
others here that are being picked up and
for which there is a built pipeline
being generated so if we look now here
is actually a belt that we've been
running and I will show you a little bit
when I'm not gonna run it but I will
show you a bit what is happening in this
belt so first of all it will basically
first do the regular maven belt so you
see that it did a lot of picking up of
all the dependencies etc
and which better needed which came out
of the palm file okay so once it did
that then in fact it's basically doing
the docker belt based on on the on the
the the docker file that was also part
of the project also the generated file
so it's basically doing the docker belt
and as a result I have an image that's
being created and then the next step is
it will do some validation whether this
whether this deployment will
successfully happen so what what it's
doing for that is it actually creates a
temporary name space in the kubernetes
where it will where it will deploy so it
does a docker push to put the image and
then it will basically deployed the
micro service and then it can execute
some test code etc and if all those
tests succeed then it will again use the
ham cart to do the same deployment into
the default namespace so that is
basically what this micro service belter
factory is doing and so at the end you
see it has deployed the micro service
vote and it it was not yet available
here in this case and it did also do it
and that's the the thing which Dennis
was mentioning the armature will also do
things like expose the surface and all
those kind of things so if we so that's
basically what what the micro service
belltower does and it can do that for
all the project so if you now add the
new micro service into that same github
organization it will pick that up and it
will also
automatically each time you check in new
code it will launch the belts and it
will deploy them into the cluster one of
the nice things with that setup is what
we see more and more happening is that
instead of companies making just one
developed set up for the whole
organization is that it becomes now very
easy to setup your own pipelines for
every department which you can then
tweak you can add whatever tools you
really like and that gets you out of
those discussions where people say no we
don't want to use your pipeline because
we need this other tool or we don't like
the tool you are putting their etc so it
gives you the possibility to do some
standardization but still give the
people from from from freedom and that's
then the nice thing about it now let's
look what these deployments then have
done so as a result of the if I if I
switch of this filter and I add so in
fact as you can see now the ratio
disappointment and the fact that they
have been done a true home chart is
that's why they appear up here so we
have if we if I go back to this vault
service I can see that there is a pot
running here with with this kind of
service and we can see for example log
files etc so I can just see that the
thing has been deployed and is up and
running and now I can test the
application and just to show it's also
you can just use the cube CTL commands
- towards the cluster so for example if
I want to know okay so they definitely
got the network issue here now let me
set my cube signal context so this is
just an example of accessing the same
cluster using cube CTL I now see that
these micro services have been exposed
through ingresses and then also my web
application has been exposed and if I
now take this one
so the application is running and I can
see here the the speakers and I can
click on it I can look at the various
sessions and then I can add some food
and then see the result of those votes
which are all being stored in the
Cloudant database which was deployed
with the hum turret etcetera so this is
kind of the the journey which the
developer would see so it would do this
command-line generation of the skeleton
then check that then in to get up and
work with a team on the code etc then
once the code is already set up the the
micro-service build the pipeline and
that allows you to deploy this
application again there now it's
deploying it in the default namespace
you could make options you could create
the def namespace or whatever to do so
and as such have your cycle and and as
this is just all based on the open
source you can do anything you can do
normally in Jenkins you can add whatever
code validations and all those kind of
things you want
so let's now have a quick look still at
the the rest of the journey which was in
this light so now I've been doing this
development I'm happy about this so how
am I gonna push this into other
environment and therefore I have here
this tool called urban code deploy and
this will help me what what is the
advantage is what I've been doing now
I've just pushed the the images and I
have no really trace what version is
there in that namespace etc with the
with the urbancode deploy we will be
able to define an application so in this
case we have been defining this
application with the name micro profile
and then I've defined multiple
environment so I have for example a test
and a production environment it has not
yet been deployed on the production
environment it has been pushed already
to the test environment and I can here
it also keeps track of all the version
numbers etc so I can do roll backs and
and all all those kind of things if we
look what sits behind that so if I click
on this micro surface profile for the
Vote surface again I can see that what
the date is a number of steps to deploy
the the home chart at a terrazzo it's
basing itself exactly on the same help
charts that you have been putting into
the repository and that's important
because in that way we know that because
it was working in the in the dev
environment that it also will be working
in the other environment if we look in
this urban code we can see what is the
process setting behind that so and and
that will show you that it and this is a
bit of an eye chart but luckily we can
zoom in so what what will it do it will
first create working directory it will
download the artifacts out of the get up
repository so it will download the home
charts out of the the github repository
it will do some substitutions because of
course now we might need to go to a
different cloud and database etc for the
other environment so it's going to do
that and then it well basically the
resin step here
so it's creating the environment setting
the contexts and then it does the helm
initialization and then it will check
whether the application already exists
because then you have to do a helm
update or if the application is not yet
there it will do a helm in store so
that's the process that sits behind just
to show you it it's doing nothing
special it's just using the same help
chart to perform the deployment to other
environments and this allows us to
deploy the same application to the to
our own cluster but maybe in a different
namespace so you could create separate
namespaces for a test production etc and
a search keep the environments neatly
separated but it would also allow you to
use the same ham chart to deploy to our
bluemix cloud where you have a queue
bonitas environment or to any other cube
or native environment that is available
for that for that matter so and that is
more or less what I wanted to show and
wait we can still see it Dennis
mentioned that there is also the the
logging information to a set the
environment contains also capabilities
to do to keep centralized log
information of all the applications so
we can access this and again this is
just an Alex tack which is also deployed
within the cluster as as as part of the
so as as part of the deployment there is
this Alex pack
you can it will log all the information
of your containers through just on file
loggers so anything that goes to
standard out standard error etc can pop
up in this in this kind of log files but
also if your application uses the log
stash you can just push your log
information and then you have all the
capabilities what that you you have an
inky banner you can create your own
dashboards you can do whatever you want
and then you can search a net half graph
etc and keep a centralized view on all
what is happening in your applications
so that is basically the demonstration
we wanted to show you we are also
available we have an IBM booth here so
we are if you want more information
about this queue brain it is
implementation on whatever kind of
aspect we are there so if you want you
can still come there for questions if
there is questions here there is just a
few minutes left so I don't know if
anybody has a question on this No ok
then I thank you for your attention and
maybe see you on the boot
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>