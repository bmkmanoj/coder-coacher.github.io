<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Edge Performance with In memory NoSQL by Liviu Costea | Coder Coacher - Coaching Coders</title><meta content="Edge Performance with In memory NoSQL by Liviu Costea - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Edge Performance with In memory NoSQL by Liviu Costea</b></h2><h5 class="post__date">2017-08-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JgZHbKMlSQ0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello adjusting okay I was looking and
this is one of the nicest screen that
I've gave presentation on it really
looks amazing not like a regular
conference room really nice and it's not
a movie today but we still have three
main characters memcache Redis and
aerospike and I'm going to say a few
words about each of them how you can add
them to your stack so are you using some
sort of in-memory no sequel great thank
you so just a few words about myself
technical guy it's nicer to sit than
saying the time a geek and my Stack
Overflow user and now I don't expect you
to remember it but it has some meaning
in all this presentation context because
it's actually a redis handle Stack
Overflow is a big user of Redis there
are lots of things saved in a Redis
database and I'm working in the travel
industry we're doing software for b2b
travel agencies so we're not so well
known in the b2c space but if you I
don't know if you have some friends that
do own or like a travel agencies or you
if you want to open one we have the
software for you we have clients like
from Central America to solve East of
Asia or all over the world and a lot in
Europe so this is a what we are doing
this is what we are building at plugging
travel okay so the first thing that
comes to mind when talking about
in-memory no sequel it's the performance
I mean it's clear that accessing data
from ROM is much faster than accessing
it from the disk it's much smaller
latency and get it much faster not to
mention if everything goes through a
network but there is another big
advantage in using in-memory no sequel
and that is scalability maybe you don't
see it but all the big applications on
the market today are using some form of
in-memory in memory solution Facebook
for example is using memcached a lot
like probably all the things are stored
in some memcache server for sure more
memcache that were not ingesting what
and Twitter for example stores all the
time line in Redis they have their own
Redis fork from some point but hopefully
they will merge it into into the main
one Stack Overflow also a big big user
of Freddie's so just think that if they
would stop this in-memory solutions for
sure there their applications will not
be that scalable so they will not answer
our requests that fast if they will
answer so this is how we started at
plugging travel thinking about some
in-memory solution
oh you first build like a small
application put it like like on a server
you don't care about things like
performance scalability it works but
then if the business is doing great
which of course is a good thing now you
need to scale your application so you
need to move from one machine to more
and you're doing this by adding a load
balancer
now when you put two machines at least
two machines under a load balancer you
start having some problems that you need
to figure out how to solve them you need
to think about where is now the best
place for your session because if the
session is again in the in memory in the
application memory it will not work
because it's either on one server or on
the other cannot go to any of them then
you might have something like search
results like taken from the database or
maybe from an external endpoint stuff
like this so those might not go into
session but you still need to save them
in in the application memory and the
static items I'm referring like things
like you are loading when your
application starts so you probably have
some static things that you want to load
the not true ask them every time from
your application so it will go faster
now when you have only one server and
it's loading it from the database it
seems like a good solution good idea but
when you have like four servers and
they're always loading it from the
database things might not look so nice
no if you were like maybe 10 years ago
you'd solve all this by using sticky
sessions so you put like the cookie on
the load balancer and this way the load
balancer knows that you end up ended up
on server number 1 and it will keep
redirecting you to server number 1 so
problem solved but being 2017 you want
your request the client requests to be
able to go to any of the machines under
the load balancer to be able to scale
because the load balancer can find out
how how much load is on any of these
machines usually there there know how
many connections they have to any of the
machine on the under the load balancer
so it can really balance the load so
sticky session is working but probably
it's not the best solution
and it also if you're using sticky
session you'll not be able to auto scale
and if you're using some kind of cloud
platform I think your destination should
be Auto scale I believe you're this
nation should be auto scaling in our
case for example because we're working
with b2b travel agencies they usually
are closed during the weekend so we get
many less searches we don't get so many
requests while during the weekdays when
they're working and they have clients
doing reservation get many more requests
so there is an advantage on on auto
scaling which can be really explained to
the managers but there will be a cut of
cost if you don't need the same number
of machines running every time sorry
now probably the majority of us are
doing some kind of web application some
kind of MVC application like you show
data from the database you display to
the user edit something save it back and
this kind of this kind of developing
these kind of things also in our case
might make you consider the database is
a solution for everything you think the
database like okay the best place to
store your session and your search
results or stuff like this but they were
not really meant they were not created
for for this for to solve such a problem
because you don't need on the session
you don't need the DS persistence don't
know don't need all the hayseed stuff
you don't need to be like all the things
atomic and because it's a little too
much you need your session to be fast
you need to load it because it's loaded
on every request you need it to be fast
needed to be responsive well the
database is more they are more created
with like AC transactions in my hand and
stuff like this so database is a
solution and there are many session
providers which are working with sequel
server oracle my sequel and stuff like
this but it's not the for sure it's not
the best solution and then you find out
about some in in-memory key value stores
and stuff like you read about memcache
which is like probably the first one
then find out that there are more of
them and I think that this could be a
good solution for your scaling problem
and now you're going to you're going to
talk to your I don't know team leader
architects senior management and trying
to convince them that you should adopt
such a solution you should go for some
in-memory no sequel and if you are going
to do that you need to have some things
in mind I need to consider some some of
things so if you're going to talk to the
management they're going to ask you how
much it will cost how many machines do
we need and you need to be able to do
your calculation so I just brought some
numbers from a AWS and Asia and you can
see how much what is the cost per an
average cost per gigabyte round per hour
so it's easy to calculate how many
gigabytes you need and then you can see
exactly what kind of machine and you can
make the calculations and you can come
up with some really hard numbers to your
management which can approve it or not
okay now talking to your fellow
developers the first thing which it will
come to their mind is that if you stop
that machine where I don't know read
this is installed or memcache all the
data will be lost
so because it's volatile it's not saved
on the disk being in memory everything
you'll lose everything so you're
probably going to be scared of this
situation when everything can disappear
and in the case of for example in case
of Redis you can do backup the same with
aerospike and backup even if all these
like new solutions have things like
rapid cassettes like replication factor
in the cluster backups are really
essential because it will save you when
something goes when some developer does
something really really stupid or some
mistake and deletes all the data in
staging or even production so even if
you have like this persistence so like
everything which goes to memory it's
also saved on the disk
it still is still good to do backups
from time to time
so besides memcache which is a little
bit different radius and aerospike do
support it so you can think of the next
step
which is now if your business will will
keep growing you need to be able to
scale also such a solution also your
memcache your Reddy's and they do
support server-side cluster both Redis
and a respite which means that you can
add machines on the fly and all the
cluster will rebalance itself it will do
all the migration is automatically
behind and you will not have to take
care of anything besides memcache which
is like more like a client-side cluster
and that will mean some data loss but it
can still scale with some data loss
now if you start reading about this
product you see that there they're not
the same they were not created like to
solve the same only one problem in mine
so now we're going to see about some
details of each one of them and we're
going to see how they were created what
they are trying to solve and this way
you can see which one fits best to your
own stack I'm interested is the veteran
here it's probably the most used one
they are if Facebook is still using it
and is doing a great job then I think
it's a good solution for each each of us
and it's a very simple it has a very
simple API which allows you only two to
work with key and the value the value is
at just a simple value you don't have
like something like a list or a hash
there you only have like the immutable
API like delete key update key expire
key and stuff like this it's got some
limitations which can be a little
annoying for 2017 especially that the
value cannot be more than one megabyte
and you'll probably end up with key
underscore one key underscore two so you
will separate a bigger B key into
many smaller keys and keep track of
their number and stuff like this oh okay
you you can go over that that issue it's
a this is created like to be a simple
out of processed caching solution so it
doesn't have any of the scaling features
on server side it's just a simple cache
so you need to always to take in
consideration that your data might not
might not be there in your memcache
so you need to be prepared to fetch it
like I don't know from an external
endpoint to fetch it from your database
again because it might not be in there
and if you think of that in mind you
don't have a problem that it doesn't
have servers I cluster it's okay to have
only client-side because you can still
add and remove machines from your
cluster okay moving on with we've read
is it's a very popular tool it's you can
have it on both AWS and Asia as a
platform so you don't need to start any
infrastructure any VM and install it you
just click some buttons or some API
calls and you have a cluster of
freddie's if you go on AWS it really
supports clusters right now so you're
ready to start in just a few seconds
probably there are big companies using
it there's a very big community behind
it and it's really open source it
doesn't have the you know community and
Enterprise Edition like you'll have to
pay for some extra features or stuff
like this everything is available to you
that's why it's it's a really popular
really popular tool now moving along and
if you start reading more about it you
find out that it's a it has only one
thread to serve all the clients requests
so all the requests that goes to it are
so
by this thread that you need to so you
need to pay attention if you have a
longer running process if one of a
client of the clients will ask for some
big big data or some kind of big
processing it will affect all the other
ones so they all the other requests will
be killed so you need to pay attention
to this this was created more with
solving some live data analytics in mind
so this guy that created it went into
salt I am small one wanted to do some
small updates to the database but really
fast it was a really fast fast update
sending so it's not sending like a lot
of data but just small increments and
the way he wanted like very fast
performance so it ended up creating a
lot of data structures on the server
side and once you understand these data
structures and you use them correctly
you're going to benefit of all the Redis
power you're going to use it probably
its maximum it has some server-side
procedures so it can write some nice
code in Lua and put it on the server
side and you can execute it there like
you don't need to get on the client or
all kinds of keys you can make some
calculations there but again you need to
be aware of the long running processes
that will affect the other clients
initially it was created with just a
replica set so like a claw like classic
master-slave replication now it also
supports cluster so you can have
partition of datas and two different
replica sets in in your stack in your
solution does support persistence so all
the data that go all the rights that
will go to ROM will also be saved on on
disk on some append-only file you can
read it very easily it's very clear and
you can take backups from time
time of your data now we're going to see
about these data structures and I do
have like small demo about it
I have an application that it's a small
application that uses the Redis as the
only database behind so I'm trying to
see how we can how we can do things that
things that you do in a web application
and - and - and you don't need some like
my sequel or some other database behind
it and I will put here we'll see exactly
what the application we'll be sending to
Redis
so I have like a like a user's page and
we can see here we have a last
registered users section and normally
for such a thing you'd use like a list
right to save your users so we're going
to see exactly what was sent behind and
you can see here hope it's clear so you
have a I'll try to translate it you have
a left range so on the list called
last registered users starting from
index 0 until the end minus 1 will mean
the end so you're asking give me the
list
starting from left index 0 until the end
and this is the key of the list so in
this case the value it's a list so you
have a key which the value is a list and
you can add to the two lists to this
list you can ask to make recursion on it
from the left or from the right
depending on what you are trying to sort
to solve so I'm going to create a new
user
and you can see we can see what happened
behind in this one okay so we have the
after left range we have a set on a hash
so one another type in Redis we have a
hair set which has like you can think of
it like an object like a dictionary it
only has like one one one level so you
don't have nested levels inside and you
can see first is the the key of the hash
its users and my email and then we have
the like you can think like the fields
the name of the field and the value and
so on so this is this is exactly what
gets sent to get sent to Redis then I'm
saving something in in the list in the
list that we will send at the beginning
last registered users
I'm putting their my email which will
act like key to this to this hash set
and then I'm asking again give me the
this list from the left from 0 to minus
1 and here is the last registered users
and now I'm going to the user details
and I'm seeing the one of the question
that I held I held like Redis were show
up in some database group and the main
question is how do you do select
everybody was trying to skip - I don't
care lower left range or how do you do
the Select and the question is we've
read this it's always on every question
is the answer we fred is on every
question is you build another structure
it's a geek jokes so you need to
understand the structures behind it and
once you understand them you can also do
select
which is not easy you need to create
like a lot of structures but it it has
additional to what I showed it has some
sets and on the set you can do
mathematical operations like Union and
intersection difference so these things
you can do to do the to do the Select
and the predicate on the where okay now
back to where we left with Freddy's well
once we went live with this we found out
that we started having timeout but at
some point and it's not necessarily
because the Fred is I mean usually when
you add read this to your stock like to
save your session or or stuff like
cached results or some other things that
you want to put like you know in memory
solution you make calculation of how
much RAM do you need you probably you
are doubling it just to be on the safe
side and then if you are in on AWS or if
you're on Asia or some other cloud where
you're putting like some VM with read
this it's not necessarily you you look
up for a quite cheap machine and for
example on on AWS there are the t2
machines the burstable ones if you know
which can give you a lot of wrong
doesn't it doesn't give you a consistent
cpu but you actually don't need it so
much in case of raddest but it also
gives you a very poor networking so
those timeouts might not be because a
thread is but because you're asking a
lot of data from that Redis instance and
the network can can't even handle all
all the traffic so you need to be pay
attention to also going to make the
calculation pay attention also to the
network how much data you can transfer
and which is not really simple to find
out when you are on AWS because they
don't give you any hard numbers they
just tell you that network is low or
later it is moderate they just give some
attribute you need to pay attention to
this long-running processes because
being a single-threaded
you can only serve on one request at a
time so just a simple command like keys
which returns all the keys on the server
or flush which goes and deletes all the
keys can bring your replica your master
from the replica set down inside the
replica set there is a ready Sentinel
that you need to set up which will
queries from time to time I mean default
is like every forty second queries the
master and that query also needs to get
answered from the single thread so the
if the thread is busy doing something
else it will not answer to the Sentinel
which will promote some other slave
another slave will be promoted as a
master so it can and this can happen
quite frequently during the day it's
really not something that you would want
moving along to aerospike era spike was
created to solve the let's say our
today's problems scalability and
performance if you want a tool that
doesn't have so many things on the
server-side so many dot structures but
you want it to be fast and you want it
to be able to scale like to have like a
cluster which you can really easily add
machine and remove them a respite is a
good choice it has here we can find the
Enterprise Edition which has some extra
features that you will need to pay for
and still it's gaining a lot of
popularity kayak I don't know if you're
aware but it's a big brand in the travel
industry it's also used in the
advertising industry like in if you need
to serve fast ads to your customers it
would be
a great choice and it's easy to start
you can find it configure it and
available like a vagrant box if you want
to start developing and playing with it
and you on AWS in Asia in the market you
can find VMs already set up with error
spikes so bringing one up nicely
configured so bringing one up it's just
a matter of minutes and you can start
playing with it and do tests and
everything that you need Oh
once you go we Faro spike and you start
finding more things about it you see
some similarities we've read this it
does have some data structures but not
that many as as a Redis again you find
some support for Lua a nice C like
language you can do some store
procedures but probably its main power
stays in the storage models so you can
configure like one cluster to have
different storage models inside and
we're going to see exactly which one
will fit your description better the
inside the cluster the replication is
synchronously which can be a little
problematic for example on Redis the
replication are synchronously which has
of course some other problems like
consistency of data you can find out
then it has something like namespaces
and initially you read that they are
similar to databases in a classic sequel
solution but if you go deeper you'll
find that they're totally different
because once you configure the
namespaces on a cluster you need to
restart the whole cluster for example
for adding more and the namespaces are
just like container to put the storage
model so one namespace one storage model
so for example on a cluster you should
have like maximum free namespaces
because that's how men
storage models it has so you don't need
to like one a space per client if you're
having multiple clients you'll not be
able to separate the data based on
namespaces then it has something like
set which are very similar to databases
and the beans are the columns inside the
databases and you have a the primary key
and on the beans on the columns of your
set you can have secondary indexes and
you cannot make queries on these bins
and unless you create a secondary
indexes X on it and just a few words
about the storage models because I think
this is its main power you can have
everything only in ROM with no
persistence on disk and this will be the
fastest solution if you want some
persistence you can be on every right
and every right operation that I will
also be saved on the disk and the most
interesting one it it has a special
storage model for SSDs I'm saying it's
special because it uses something like
which is really trendy today like they
append only database so every write that
goes to the database it doesn't
overwrite an existing value it's it
always it's always put on an empty space
because that's what makes the SSD faster
overwriting some existing data it's much
slower on an SSD than writing on a on a
space that is zeroed out from the
beginning and it takes it takes
advantage of this feature of the SSD and
but because of this when you're putting
a disk when you're attaching the disk to
your VM you need to be careful not to
mount it so it didn't you know it must
not have a file system on it because the
file system will will act on its own and
will overwrite some data that aerospike
we write and you
have conflicts already startin it will
stop working so no don't put a file
system on it because aerospike handles
its own system inside there and also if
you're starting you're attaching the SSD
to your HR instance to a WC instance it
needs to be completely zeroed out before
you start working with it with the disk
in order to get the best performance and
now I have a small demo about aerospike
we'll add some data to it and we'll just
make a simple query which initially will
fail because there's no index and after
that it will work because we will create
the index and we'll see the nice
interface to create the index so I think
the code can be seen here so I have
three users which I'm saving and then
I'm trying to do a query on the city
this one I have to users on yash and one
on a different city so I'm trying to get
the users which are from yash and
initially it will fail just because I
don't have any index so here I have a VM
started with vagrant
we're aerospike is running and then
let's see which one
well crash and if you see here it tells
me index not found so it did save the
data but the index is not there so you
cannot do any select and there we can go
here this is the console of aerospike
and we see that we don't have any index
and I'm going to add one and the beam is
called CT you can pick up if it's a
numerical string even for example in my
case that I have string values if I will
put numeric it will not take into cos
delusion the string one so it will not
index the string ones it will just try
to find if I have like numeric values
inside the beam and the same with string
if I take the and do a string index it
or not if I have that been using also
some numeric values it will not tonight
take them into consideration okay so I
did create them I create the index you
can see it here it appeared all the
details and then running again the query
it will give me the two emails that were
from the city that I queried and we can
look at the so this is how I'm saving
stuff and this is how I'm querying stuff
so you can see here a query I'm setting
the name space the set name the dot
which is the table like the column that
I want to retrieve and the filter which
is on the city column it's it's pretty
easy to start with and it's it's
actually interesting to do something
right
sure
I think you can also add an index on to
be honest I didn't try this in our use
case we only have the index only one
column but I think you need to add more
indexes I mean like an index for every
column that's that's what I think yes I
wasn't prepared for the live demo yeah I
can find out and I will tell you after
so once you go live with aerospike in
our case there were some things that we
found out on the hard way I was
mentioning that replication you start
the cluster in you know aerospike is
synchronously which means it wants to
have a really good and reliable Network
because otherwise you will have like
partitions brain splits stuff like this
will happen one node will not see the
other the other ones and they don't
recommend putting different nodes on
like different availability zones on AWS
which is against a SS recommendations
which that if you want have the high
availability put different nodes in
different availability zones because
there are different physical locations
separated tens of kilometers apart so if
the hurricane hits one it's very likely
unlikely to hit another one so they
don't recommend this but I I have like
believed that a lot of people that are
on AWS using aerospike are using it like
this so different nodes on different
availability zones you can play with the
settings and put like a bigger timeout
on the on the cluster so you'll you'll
not have you you will not have all the
brain splits
for example the one of the problems when
putting that on SSD is that all the
secondary indexes all the indexes that
are created are kept in memory so
they're not kept on the disk at all only
in memory this makes it fast but on a
restart if you have a lot of data and
many indexes it needs to recreate them
in memory which can take a lot of time
and in our case the cluster that we're
using right now it takes between 6 &amp;amp; 7
hours so if we have like a brain split
and we're going to need a restart on the
node to rejoin the cluster we know that
it takes 6 7 hours
now usually when you deploy such a
cluster you do take in consideration
that you will be you might be able to
run with minus 1 note oh but you are not
sure that you'll take in consideration
that you might need to run with minus 2
nodes because you have a period of 6
hours when you were exposed if something
bad happens it's nobody will like it
you'll like it there is the option of
fast restart unfortunately only
available in the Enterprise Edition so
you need to pay for the license what it
does it saves a copy of the indexes in
the memory of the operating system so it
still it has a copy in ROM of all the
indexes and this allows you to restart
in a couple of seconds now I'm just
guessing if they would have this feature
from the enterprise available in the
community for sure it will have much
more popularity and probably it will be
interested to to many more developers of
there to start using it like just a
message for them
there is a limit he also here the row
size cannot be so the sum of all the
bins cannot be more than one megabyte
but this is mainly only when you're
using SSD but this is mainly because how
they are querying the data to make it
faster so and because they're using
their own system on the disk so you need
to be attention you need to pay
attention even if you're running go on
SSD and you can easily put like a couple
of DS of 500 gigabytes in AWS in Azure
you still are bounded by the amount of
RAM you put on the machine because if
you put a lot of indexes and they get
filled it will simply that note that you
got filled it will simply stop so if you
need to restart it you need to add one
more node to migrate the data and to
make room for such some some space in in
the ROM okay I made a separate slide for
this because I find it really important
what we found out is network is really
important after running for a aerospike
we have it for around one year and
readies for maybe three years not sure
exactly we found out that at the
beginning we didn't take it into
consideration and for example we tried
running clusters like I said with the
burst of all machines on AWS the tea
machines which do provide the ROM you
need and it has good CPU but they are
really bad on the network and every time
that we try to have a cluster on the tea
machines every time we got a partition a
brain split one of the nodes
separated from the each other so you
need to I probably need to run at least
with some m4 machine
if you are familiar so look for the
network transfer make some calculation
maybe put some alert you'll only you
you'll have to make your own test
because like I said AWS for example
dozens doesn't give you some hard
numbers on the transfer but with careful
monitoring and some alerting you might
take advantage of even smaller smaller
machines ok Oh a small review of what we
covered the in-memory solution
besides performance will give you a
scalability which probably at some point
if your business goes well you're going
to need it and if you are also on using
some cloud environments on cloud
solution it's also the path to auto
scaling and probably this is should be
your destination memcached is a simple
machine which allows you to to put that
I like to use like a secondary cache and
from time to time you might you need
take in consideration that the data
might not be there so you need to reload
it from the disk from from the sequel or
from the external endpoint whatever you
have it now read this it's more advanced
stands for this is the macro name
readies for a remote dictionary server
so again think about the data structure
that it has on the server side and once
you understand them you have it at its
biggest power moving going to aerospike
it was created with cluster from day one
using stuff like replication factor
similar to Cassandra for example and
it's nice that you have this hybrid
approaches and inside the cluster you
can have a namespace which is ROM only
you can then have a namespace which is
round + persistence and then you can
also
everyone which saves data on the disk so
then you have the option from your
application to save data wherever you
think it's necessary and even moving it
and most important do make the
calculation also for the network that's
it so if there are</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>