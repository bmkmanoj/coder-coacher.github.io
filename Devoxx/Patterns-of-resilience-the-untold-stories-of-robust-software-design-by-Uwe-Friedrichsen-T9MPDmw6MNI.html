<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Patterns of resilience - the untold stories of robust software design by Uwe Friedrichsen | Coder Coacher - Coaching Coders</title><meta content="Patterns of resilience - the untold stories of robust software design by Uwe Friedrichsen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Patterns of resilience - the untold stories of robust software design by Uwe Friedrichsen</b></h2><h5 class="post__date">2015-11-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/T9MPDmw6MNI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the second last talk of today
I guess you already had a lot of input
today and I'm sorry to add another pile
on top of that right now so what okay I
try to make that bearable I'm not sure
if I succeed anyway my name is Alexson
and I work for a quiet cool company
named quad centric that cool should be
enough of advertisement for the company
so let's leave that aside my history
yeah work in computer science I team
meanwhile more than 30 years did a lot
of nice things did a lot of not so nice
things did some ugly things so basically
same experience that probably you have
maybe some other details but let's skip
that because usually that's ninety
minutes talk and I have 60 minutes so
again sorry about that I therefore I
have to leave out a few bits and pieces
but anyway let's start up resilience I
mean I'm around quite for quite a while
and talking about resilience as I am
quite heavily involved with distributed
scalable systems and resilience is an
very important topic in there but at
least when I started up and also
sometimes right now I still get
reactions like that so like hey what's
that and then every reasonable person
looks it up then and okay we look into a
dictionary and yeah it's a bit odd I
didn't take Wikipedia sorry for for that
but anyway so I took a real dictionary
and so resilience definition here is so
that I can return to the original form
from being bent or something like a
spring that you bend around and let
loose and then the bowing it goes back
to the original position or recover
readily from illness and so on and yes
it sounds nice but again huh I mean we
we're 90 don't aren't we I'm so what
Scott has I've got to do with I di t so
what's it all about
and then I say okay I try a little bit
better explanation and then I usually
start up if if I talk about resilience
first thing you have to know it it's all
about production and before you go to
the third yeah give me a second to
explain that so what I mean with it's
all about production is we're building
software to create some kind of business
value so making money satisfying
customers best both of it and we only
create that business value so with
software if we're software involved in
production therefore it's all about
production and having software and
production isn't enough either because
software needs to be your sister needs
to be up and running available is the
official term for that availability is
important because as long as your
software isn't doing what is intended to
do though it's down or doing the wrong
things it doesn't live any business
value and that's why you wrote the
software in the first place so it's all
about production it's all about
availability so let's have a little bit
deeper look into that availability thing
here's the formula for availability
I picked the quite easy one so even for
the fourth day in the afternoon that's
almost understandable so it takes me
five minutes so you're probably faster
the definition that several definitions
around for availability I like that one
most actually I took that from robot
Hannah's book patterns force for
tolerance software design so it's
defined on top you have mean time to
failure which is the average time from a
system coming up until the first failure
is seen from the outside and on the
bottom lines on the denominator you have
the sum of mean time to failure plus
mean time to recovery so that average
time from when you see a failure until
the system's back up so in the
denominator you have all the time and
the fraction of time where
everything works as designed you have an
enumerator so quite straightforward and
you try to maximize that towards one so
becoming as close to one as possible or
if you like percentages more you
multiply all that stuff with 100 and
then you have your 99 percent
availability 99.9 percent and all that
stuff
and last thing to note here is if we
talk about failure there are several
kinds of failures it's not only crash
failure what most people think about
when they talk about failure or think
about failure so systems up and boom
it's down and it's gone that's the
easiest way we also have a mission
failures when systems become brittle
sort of so yeah sometimes responds
something does not and so on and then we
have the timing failures which is that
system response but too late so I can't
wait for that or for that long or
response failure so it responds but
unfortunately the wrong thing and
especially in distributed system that
happens quite often so if we think about
replication eventual consistency and all
that stuff these are response failures
also it's not only itself web box and
then we have the very mean ones that
we're not going to talk about today is
the basanta and failure so when the
system goes berserk basically so it does
whatever it whatever it wants to do and
you have no clue what's the heck's going
on there so these are all kinds of
failures and we have to deal with all of
them so that's when we talk about
availability whenever something goes
wrong it becomes slow it becomes brittle
it crashes it gives it wrong answers all
failures that's important to understand
so it doesn't help to have a system
which is up all the time and always
gives you the wrong answers that's not
availability so core question is how can
I maximize that because we want to
generate business value and for the guys
in here who are quicker than I am with
math you immediately see okay the secret
here is to make mean time to failure a
lot bigger than Minton
recovery so that mean time to recovery
becomes irrelevant relative to
relatively to mean time to failure and
then you're getting closer to one okay
and of course there are two approaches
for that the traditional one is I try to
maximum mean time to failure so I try to
maximize the time until a failure
becomes visible or happens at all it was
quite a good idea in the past and most
of failure engineering we see around
there in the in the past goes for
maximizing mean time to failure so we
take big high-availability solutions
cluster solutions redundancy is a
redundant network and mostly
infrastructure and redundant
infrastructure because that was the
biggest source of failures we had on
these systems and then a lot of
extensive tests and additionally so
because mostly the systems were running
in isolation mostly and so not a lot of
interconnection and so on and there was
a perfect approach for that this kind of
trying to think about what can go wrong
and then already take measures and it
wants to prevent that so if that was
perfectly fine so what's the problem
right now in simple words today
basically every system is a distributed
system so even if you set is it in
normal telecommunication company and you
have a CRM system it usually talks to
about 50 or 100 different systems online
or if you have a claim system in an
insurance company it also talks to 30
other systems and so on and all these
systems talk to each other and online
and if one system goes down the Alice
quite often have a problem so world
today is distributed basically and if
you talk about distributed systems you
can also have a quick look at the eight
fallacies of distributive computing by
Peter Deutsch terms like the network is
reliable not latency is zero
bandwidth is infinite is all fallacies
so they
many many sources alone in the network
which can give you failures and we
haven't talked about application level
yet and this leads Leslie Lamport one of
the Guru's of distributed systems to his
quite sloppy definition distributed
system is one with failure of a computer
you didn't even know existed can render
your own computer unusable so what can
we learn from that failures in today's
complex distributed and highly
interconnected systems are not the
exception anymore they are a normal case
and they are not predictable up front
and sorry about that it's even getting
worse so if we talk about cloud based
systems I mean the cloud provisioning
resource provisioning model is so much
superior to the traditional provisioning
model that it will eventually blast away
the traditional resource provisioning
model I mean I want to have resource I
do it by ourselves service API here it
is so no more no longer waiting for
three months for tests or or anything
like that or scaling up and down in
production all that stuff but to the
price of a lower availability of the
resources then you usually have in a
high availability solution or you talk
about micro services dis through the
battery fall even more moving parts on
and at the same time we get
ever-increasing availability
requirements so zero downtime is the
word du jour at the moment and so and
you have to solve that problem while
your system becomes more and more
distributed and gets more and more
moving parts and then also IOT and
mobile it comes into place or you have
even more not so reliable plan peers in
your system talking our over quite
unreliable network connections or social
media so completely unpredictable load
patterns at the moment your server is
idle the next moment it gets just
flooded with requests
and you have no idea where the heck
they're coming from and so on so we
moral of the story is we are not going
to go back to the good old times so we
are facing an ever increasing complexity
and connectivity in our system
landscapes which leads to the mantra of
resilient software design do not try to
avoid failures embrace them accept that
they will happen all the time and deal
with that what brings us to resilience
approach for maximizing availability if
I accept that I cannot really maximize
mean time to failure that there are way
too many sources of things that can go
wrong my only chance to maximize
availability is to minimize mean time to
recovery so to take measures that if
something goes wrong I can recover very
quickly from that or at least that I can
mitigate the problem in a way that the
user isn't experience it or gets at
least that degraded a service which he
still can lives with which user still
can live with which leads to a quite
different definition that I usually use
if I define resilient software design or
resilience for in terms of a T so for me
resilience in at he challenges the
ability of system to handle handle
unexpected situations without the user
noticing it in the best case and with
the graceful degradation of service in
the worst case okay now we've seen what
resilient software design is why we need
it and what's the difference to
traditional stability approaches but
we're all developers engineer so our
main question is not what and why our
main question is how so how can we build
that and that's quite a broad topic
actually so I'm currently developing
sort of a pattern language for resilient
software design and actually doing that
for 1/2 years in my non existing spare
time and it's getting broader and
broader and broader and I figure out
there's quite a lot to learn and
way much more than we could do in the
remaining 40 minutes that we have here
so what I decided to do is I give you a
starting point in here in the remaining
minutes that's a small pattern language
it's still 20 patterns but I have to
skip some because as I said before
usually 90 minutes talk and I'm probably
quite sure that the next speaker will be
quite upset if I'm going to talk 90
minutes here and we're reckoning out
somehow so we're not trying to do that
and so I have to skip a few patterns in
here and amazingly stay at the design
level I have some code examples in some
places but I won't be able to go down to
every detail and I picked isolation as a
starting point because usually when you
think about resilient software design
they usually start to design your
solution is that you think about
isolation and then you start to add the
other parts and that's what I'm going to
do here so I start with isolation which
is more like a principle here in the
terms of that presentation principle is
higher-level topic where the patterns
are organized around what's isolation I
mean the idea is that the system must
not fail as a whole so what you're doing
is then you try to split up your system
in several parts and try to isolate them
against each other
so if one part of the system fails the
other system parts of system must not be
affected by that so we try to avoid
so-called cascading failure something
goes wrong here and this drags that one
down and that one down and that one down
and now we have a perfect test or a
catastrophe and we don't want to have
that the system as a whole must stay
available and there are several patterns
around I've got two here first one is
black hats probably quite a well-known
one so it's it's actually the core
isolation pattern and it's usually where
all efforts to build resilient systems
start you try to figure out these bike
heads off
units or units of mitigation there are
several terms for that and because they
are the basis for redundancy and for all
other approaches to build resilience
into your system and also how to build
scalability in your system which is more
or less scalability is nothing but sort
of success resilience because if your
system becomes successful more customers
come to that you have to cope with that
it's also can be an unexpected situation
so that part of the story is it's a pure
design issue so for all these of you who
like these flats here I'm an architect
if there's still anyone around here who
likes being an architect
you're quite often talking about
separation of concerns and this is
another concern so this is another
aspect that we have to have in mind when
we think about how to split our system
best and our system at runtime here so
if you're talking about micro services
Microsoft's a perfect candidate for
being a bulkhead not necessarily all the
time but quite often you have if you
think about resilience and micro servers
you think about how to slice them in
some way that they also become resilient
or that you can't isolate them quite
well against the rest of the world and
that it still makes sense in soft design
in terms of design again pure brain
power
no frameworks you're anything that
really gives us out of the box I mean
even if you go for a cow or something
like some great framework that are out
there they say here's an egg door but
this thing isn't resilient in itself and
I never tell you what needs to go in
there you have to think on your own
which part of the functionality goes in
there okay the next one complete
parameter checking I mean you might
think most orienteer
the problem is we all know that and I'm
not sure about you but I've hardly seen
ever a system which really implemented
that we all know we should check all the
parameters on our boundaries and hardly
anybody does so yeah we have to do that
if we want to have resilience we have to
protect ourselves from broken or
malicious calls which come in and also
from broken or malicious return values
which come back up from downstream calls
so I've seen so many null pointer
exceptions from people just blindly
using results from their query to the
database that I can't count them anymore
and I never understood that actually
because for me the definition of a
production database is that it's broken
in some way that it has inconsistent
records in there every database that
only has consistent records in there is
a test database usually I've never seen
a production database which was
perfectly consistent it's it happens
it's it's real life and so I have these
tonnes of null pointer exceptions and
even more and also having too many
having broken calls coming in still pay
attention to passports law in there so
don't become a interface nazi in a way
so the idea from Jon Postel he is an
Internet pioneer he wrote the original
RFC 40c and what he what became famous
as Possible's law was his idea that what
he said be conservative and what you do
be liberal in what you accept from
others so if I talk to someone else I
try to stick to the specification but if
somebody else talks to me if it still
makes sense I'm going to accept that
that's an extra parameter so what I'm
going to ignore that it's not exactly
the format but I understand that it's
okay enough and so on as long as it
makes sense to me I accept it and try to
process it if it doesn't make any sense
I reject it
and that gives us a lot more robust
systems in the end I will skip the part
about the specific data types so let's
move on to loose coupling loose coupling
is not a principle which complements
isolation by trying to reduce the
coupling between failure units again
what reducing the risk of cascading
failures so less coupling between the
pieces fewer chances that one system or
one piece is going to tear down another
one quite well-known in this area is you
know the idea of the synchronous
communication which decoupled the sender
from the receiver I mean the problem
that usually if a synchronous
communication is the moment you do the
synchronous call and the other part and
the resource you call doesn't respond
just stand still and you can't you don't
have to control because you're waiting
for the response so you're out of course
you don't have to control anymore so you
can't take any alternative actions and
anything like that and a synchronous
communication relieves you from that
problem because I sent out the request
and I get back the control so I can
still react to timeouts and other
problems and so on or to crash'd
machines on the other side I can still
respond to all of that and therefore
it's quite useful to break these
cascading failure changes that you quite
often get with a synchronous
communication and problem in here is
that quite often here then that's so
hard this synchronous communication
stuff is so much harder than synchronous
communication do we really have to do
that and my answer is you're only half
way right because yes it breaks the call
stack paradigm the call stack paradigm
is nice in the way that it works the
same way as our brain
so in a linear fashion so a Cosby
because he is he comes back seeker
because D and so on it's perfect the way
like our brains were not internally
about the way we think a synchronous
communication is actually how the brain
is wired internally but we can't
understand how our brain is wired with a
conscious part of our brain it's it's
quite interesting if you think about
that for a while but that's a different
story
and so we quite often have quite a hard
time to reason about these communication
networks is a synchronous once that's
that's true on the other hand from the
technical point of view if you go for
synchronous communication and you want
to get resilient you have to build in
some kind of timeout management which
I'm going to show later and then you
have the problem I do a call you know
wait till the timeout happens so the
timer doesn't happen so ever get the
answer back before time what happens
everything's nice but once in a while it
will strike and now I've got the problem
I have no idea what's going on because
didn't the call reach my downstream
results or did it reach the downstream
resource but broke while being processed
or did it reach the downstream resource
and is still processing and but actually
everything's fine it will just
eventually complete in a second later or
a second later or something or the just
return message doesn't come back so what
the heck am I supposed to do can I call
it again or doesn't it make any sense to
call it again and then and what's my
measure and so on and just after a
moment synchronous calls are as
complicated as a synchronous cause the
only difference is that in essence
communication it can happen to you that
it B might become harder for you to
reason about the whole network that's
everything so the difference is not is
it more complicated or less complicated
I basically am again for the architects
and designers in here and it gives you
quite different designs because
synchronous call calls usually give you
a top-down slicing of a system and as
soon as calls usually give you a left
- right slicing of the system you end up
with quite different designs which is
way more interesting point that if it's
one thing more complicated than the
other one by the way
okay long enough so let's keep the
location transparency as a pattern short
I mean yeah if I only have to deal with
a logical name and don't eat to know
exactly where in the system this other
resource lives yeah makes things easier
if I think about redundancy failover
scalability and so on so let's keep that
short and move on to event-driven
communication so event-driven is one
flavor of a synchronous communication
the other big flavor is usually the
message driven communication so message
driven is a calls be event-driven is
basically I do something I send out an
event and I don't care anymore so who I
ever wants to know about that and it's
interesting that can subscribe to me so
basically it's reverses the dependency
so the record location dependency
because sender does not know it does no
longer need to know where the receiver
is but the other way around which is
quite interesting in some places when
you set up your designs and if you've
got a broker in the mid in the middle
you can achieve full location
transparency again as I said before a
very different approach to normal
request response paradigm just to
further in a picture so sender receiver
with request response you have the
typical of dependencies sender needs to
know where the receiver is event-driven
without a broker it turns the dependency
the other way around
receiver has to know where the sender is
and the last one with a broker it's
completely decoupled again design issue
and as with all things in design no
solution is better than the other they
just have different trade-offs so like
in Indiana Jones 3 choose wisely
another pattern in here is and I want to
mention it's from different domain but
it blends in quite nicely it's
statelessness because it's quite
important in the domain of resilient
software design so it's supports
location transparency but it also
supports a lot of other things like
scalability like failover and so on
because it's quite hard to relocate a
service from a broken node to other node
if their state because first of all you
have to move the state when also a
failover is quite hard because you have
to replicate the state in some way and
scalability is hard because you have to
replicate the city across all the nodes
and it gives you a hard time if you ever
tried to replicate not in an eventual
consist even in an eventual consistent
way if you try to replicate a state and
if you ever tried that before where it's
more than five nodes or something you
know what I'm talking about
so it's a very important pattern and
usually the rule of thumb is avoid state
in your services and in your unit try to
move the state either to the top so to
the client-side or to the bottom sort of
the persistent layer and try to keep the
middle part stateless as much as
possible oh yeah
my perfect enemy relaxed temporal
constraints problem is that I could talk
about that one for ninety minutes alone
and I actually talks about that one for
ninety minutes alone so I try to keep
that one short problem is that strict
consistency requires a really tight
coupling of the involved nodes what do I
mean with that strict consistency
meetings that whenever you ask for every
ask request from the outside and no
matter which
note your asking you always get the same
answer so that means these kind of asset
transactions
so these asset properties that you have
this atomic updates things and so on and
this serializability or even linearize
ability and so on all these properties
that you need and problem is then you
have really we have to implement a
really tight coupling between the
involve nodes which replicate their
state in that you're talking about and
so if one node goes down usually all the
availability of the other nodes are
compromised and all that stuff gives you
a lot of headaches and if anybody of you
ever try to implicate protocol so with
these two-phase commit protocols you
know what I'm talking about they are
just a pain in the neck and so basically
if you want to build highly available
systems which are distributors then you
usually get to losing the consistency
levels so to lower the consistency level
to get better availability it's also
what the caps here basically tells you
so partition tolerance isn't an option
so you have to be able to deal with
partitioning of your system and which
require and you must be able to do
reconciliation if it comes back up and
all that stuff because otherwise you're
a pair default inconsistent which isn't
an option and so you have to get these
trade-offs between
availability and consistency so see ap
that's beta in here and a lot of
discussion around yeah we need that
asset transactions in here and our
systems that's so important it's a
business requirement that all our
transactions are asset all the time and
eventual consistency isn't an option at
all and that's where I usually
contradict because I say there isn't any
single business requirement for asset
rent actions because the real world
an asset in the real world out here a
concept like acid doesn't exist in the
best case the real world is eventually
consistent in the normal case it's
simply inconsistent so there can't be a
business requirement for that and then
the people usually come out and say yeah
but if you have this bank account
example so I transfer so here money
transfer from one account to the other
one I need an asset rent checks and say
why I mean I tell you how money transfer
in the real world works I transfer some
money from my account for your card
what's going to happen the real world
money from one account is gone when your
account nothing happens and then
depending on the banks involved so day
later or two days later eventually the
money shows up so where is the real
world requirement for s transactions so
don't get me wrong there's there's a big
case for asset transaction but it's a
programming model it's not the business
requirement the programming model is so
much easier because you don't have to
deal with all these intermediate
temporarily inconsistent states that it
gives you a big relief when you have to
reason about those systems so
programming and eventually consistent
environments is really really hard so if
you have a chance to go for asset
transaction do it for your own sake not
for business requirements that's the
part of the story yeah let's briefly
mention idempotency because also very
fundamental pattern in here idempotency
the basic idea of idempotency is that
you can do call several times without
getting different results or different
side effects so it's very simple example
you have a counter and you have a
function or an operation like increase
calling increase several times is not as
increase is not idempotent because it
makes a difference if you call increase
one time or two times or three times if
you have another action
so not another operation like set you
can call set to five one time two times
three times 100 times the result will
always be the same so set is idempotent
increase is not unimportant and and
distributed scalable system so if you
want to be a resilient system it's very
hard to deal with non-id important cause
because as I said before you call
something it doesn't respond and now you
have to figure out what's going on
can I call pinners sent this right
request again or is it's just still
processing or is something else broken
here or do I just have a network
partition and all at once I have to get
a tight coupling with this other peer
the resource I just want to call and I
want to have a loose coupling with but I
need a tight coupling because I have to
figure out the internal state of that
no-fun doesn't so no good idea and so
usually what I'm going to do is I try to
implement these action this right
request in an idempotent fashion so if
it goes wrong it's quite easy to solve
that problem I just go on and we I just
wait for a moment and then I retry and
maybe I call some supervisor or
something and then I retry again and
yeah it's it's a lot easier and I still
keep my loose coupling therefore
importancy makes it quite easy right
importance he also makes it easy for me
to get exactly one semantics implemented
because what I usually do in these rural
systems to implement exactly one
semantics which are quite often want to
achieve is I had taken at least once
communication channel which gives me at
least once semantics so it delivers
messages one or more times but at least
once and then I implement I'd important
actions on top of that because if it's
delivered more than one time it doesn't
matter so in the end I end up with
exactly one semantics also very
important pattern here I also had I have
a slide in here which I want to skip how
I
get a unique request token you can look
at that up in the slides later on the
idea basically is I have a no night
important : want to make it idempotent I
decorate that with a unique request
token which I evaluate on the server
side and so on the resource side if I've
seen that token again already and I'm
not going to process it and otherwise
I'm going to process this request and so
you can more or less with a little bit
of wrapping of your resource and your
calls you can turn on item protocols I'd
important calls into unimportant cords
basically okay let's move so where are
we yes here skip that one and move on to
latency control so latency control
another principle which complements
isolation and it helps you to detect no
timely responses basically and also so
in this way to avoid a special class of
aliased timing failures or temporal
failures and the most best-known pattern
here probably timeouts which is quite
straight forward from the basic idea I
mean as I said before we want to
preserve our responsiveness and if I do
a synchronous call what I have to do it
then I have to spawn that call in a
different thread or however and then to
keep an eye on the response time and if
it takes too long
when timeout happens I stop waiting i
discard the call and take an alternative
action that's basically the call the
idea in here and this alternative action
is also known as fallback minutes
basically where all these correction and
mitigation patterns and all that stuff
blends in then usually and quite often
people think oh well that's quite hard
to implement but basically it's very
straightforward especially in Java to
implement
mods were standard library means so it's
just three more lines of code even
without taking big new libraries or
anything like that I've got that example
over here so not sure if this mouse
works somewhere yeah it also seen here
yeah cool so I have to look over here so
basically what I'm going to do is I'm
wrapping my action which is blocking in
a callable and then I just create a
single stretch executor it seems an
executor and I submit that and then we
call and that's basically all because
what I've got done is I get back a
future verse template parameter of a
return value and down here and future
has two methods in there it has a
blocking gate
don't use that one and it has a 1 which
is also blocking but with a timeout that
I can add to that and after the time out
so if everything works fine I end up
here and the next line and I can simply
process the result of the request and
otherwise I get a timeout exception and
then I can take my fallback my
alternative actions in here the rest is
standard stuff so a little bit of Java
fancy around and button questioning why
aren't we always using that one and the
answer is not because we are too lazy
but because we have no freaking clue
what to implement in this piece of code
so what the heck do I have to implement
here at this place because usually you
get your requirements and you will try
the best to implement your stuff and
nobody told you or give at least has
even no strategy no nothing what to do
if I have a technical problem so you go
back to your proper to your product
order and ask hey managed to do here and
you know you have to make sure that it's
not it must not happen it's your job to
make sure that it's not going to happen
and
and you'll say okay I just put a comment
in here this is not going to happen set
and so on and then we're waiting until
it happens the first time because it
will happen it can happen so it will
happen and when the call centers floated
by angry customers because the system
not responding anymore we are going to
discuss is then later and okay be a
little bit more diplomatic basically but
quite often these folks then realize
it's important to think about that so no
matter if they're if they're architects
or project owners or a project product
owners or if they're requirements
engineers and so on you have to have an
answer how to respond to technical
failures and it's a business answer
because it's a difference if it's just
okay to show a website to just show
webpage come back later or if this
action is so critical that you want to
implement for instance if your database
is down a secondary cueing system where
your cure you cue your requests and
process them later on when the database
is back because you're losing sales for
instance or anything like that so you
can't decide that on your own it's very
important and very fundamental that it's
answered these are these kind of
questions are discussed with somebody
who knows about the business demands and
requirements okay the big brother of the
timeout is a circuit breaker probably
the most or the best-known pattern in
resilient software design Michael
Nygaard
Road required a brilliant book release
it in 2007 still very very important to
read right now and he also mentions the
circuit breaker the core idea here is if
you know you're going to fail you better
fail fast which is some basic principle
of resilience of a design and fault one
software design so if you know that you
have hit a time or bicorn resource
several time
you don't need to do that more over and
over and over again so you put some kind
of God or some kind of gatekeeper in
front of the caller so that's the
circuit breaker actually and if it it
always watches the requests and
responses and if you have problems with
that resource or it doesn't answer or it
slow all the timelines and so after a
while the time or the circuit breaker
simply trips and all subsequent calls
they get the response don't try it at
the moment that's a problem over here so
come back later and it's still and then
after a little while it lets one
additional request going through and see
observe that still too slow okay we're
waiting for another while coming back
later and then now it responds nicely
again so let's open the connection up
again that's basically the concept of a
circuit breaker you can also use that
for different kinds of failures but most
often is used for crash failures and
timeout failures you can also implement
that on your own it's not too hard but
it's a little bit more fair for than the
time or I've shown before usually what I
recommend in here that you use something
like hystrix it's a quiet mmm it's a
very well tested and battle-tested
library from Netflix they're using that
in their resilience engineering and it
basically revolves so it gives you some
features and it builds all around a kind
of a circuit breaker also had bounded
queues and there are a lot sort of load
shadows they also provide you with time
of management and several other patterns
but basically it all works around or
builds up on a quiet sophisticated
circuit breaker implementation screen
and just to give you an idea how that
feels very rough idea here's a little
example I have to find my cross over
again here is okay
historic builds on the command pattern
so everything you implement in history
derives from the hysterics command so
all your calls that you want to protect
or to God with a circuit breaker you
have then to write your own command
which is yeah it's derived from the
history command the the template
parameters return value basically and
then when you want to pass in some
parameter some request parameters which
you what you usually want to do you do
that as a constructor parameter so one
request call is one instance of the
command so low reuse or something like
that intended in here so they hope for a
good garbage collector basically and you
save that and then you have to overwrite
the run method that's basically it and
usually in here would be the real call
to your downstream resource that you
want to god I simply put a hello world
in here so that's all and return that
and that's that's basically it there's
another function that your method that
you can override that's the get fallback
method this is always called whenever
this run method takes too long or fails
in some other ways and get fallback
method it's called and then you can put
all this advanced error handling in
there and usage on the other hand is
also quite straightforward you
instantiate that put in your parameters
as constructor parameter and then you
simply call execute that's the
synchronous way and then it runs and
after or if it hits timeout it comes
back and tries to call or get call it
and so so it's it's quite
straightforward also gives you a
synchronous variation it gives you an Rx
Java implementation on that basically
internally it's very much implemented on
the reactive pattern and but it's quite
straightforward to use the first time so
it it's no magic it's still a kind of a
learning curve especially if you want to
fine-tune that in production but from a
developer's point of view it's quite
straightforward to use that and that's
what I would try to encourage you if you
never thought about building things like
a circuit breaker in your design have a
look into that one I mean it gives you a
lot more than just what you see in here
because it gives you a full-blown
circuit breaker implementation where it
also checks for back for cues it can
implement decorator and all that stuff
it's all in there so I'm not going to
get into any details of that picture
which I have taken from the
documentation from history so if you
want to dive into resilience have a look
at that let's skip the fail fast well I
mean the basic at yes I talked about
already and let's talk for a second
about fan-out and quickest one wins
because more quickest reply because
that's a very different way to deal with
latency management and I won't just want
to show that one because to give you an
idea at that very very different ways
that usually don't think about in the
first moment so you want to keep latency
low and the idea is then that you say
I'm not calling one downstream resource
I'm calling several of them so I have
multiple resources now I send out my
request to all of them and wait just for
the quickest response because one
service one resource sometimes get slow
garbage collection whatever network
hiccup anything like that
several the probability is way it's it
is a way lot smaller that this is going
to happen and therefore it's it's a very
nice tactic to deal with those issues
because one thing needs to be clear if
we talk about distributed systems we
only talk about probabilities so all
this determinism that we used from in
process and programming is gone
so we'll just lower the probability that
we get latency we don't have any
guarantees about that and that's all of
that stuff
it's about probabilities and what's
quite interesting in here is so you have
a trade-off between waste of waste of
resources and latency so you trade
resources at edit resources for lower
latency and that's typical design
decision that you have to make and so
some guys from Google Dean and Barroso
wrote quite famous at article tailored
scale where they played with all that
and by implementing something what you
call backup requests so sending the
second request a little bit later so not
immediately sending out the request to
several resources but just sending it
out to one resource and then a little
bit later to the other one they were
able to get the overhead so these
additional resource consumption down to
an overhead for 5% by giving up a little
bit of optimized response time because
of that delayed call so that's very
different way to deal with latency let's
skip the bounded queues or just just a
very short word about bounded queues
quite often we're used to thinking in
unbounded queues we must not lose any
requests but unbounded queues are the
enemy of latency so because the longer
your queue gets the longer it takes
until your request gets processed
especially if the resource is already
heavily loaded so you better go for
bounded queues and watch them tightly
and if the queue is full you simply do
not accept any requests any more from
your senders and so that's what's called
back fresher so it has to wait until the
resource available again that's very
much better than letting the queue grow
and grow and grow and because then your
timing problems are going to
row and row and row have a example in
here to implement that into on front of
the illness on top on front of a
executor service but I'm not going to
into it into the only thing you need to
know is whenever you try to instantiate
an executor service from the executor
the static class you always get
unbounded queue so if you want to have a
bounded queue in front of that you
always have to instantiate that stuff
explicitly and then you can also even
implement your back pressure strategy
and all that stuff all that stuff's
built into the standard library you just
have to use it let's skip the low
chatter and go to the last principle
which is supervision while supervision
important here what we've seen up to now
loose can isolate in complemented by
loose coupling and latency control helps
us to build bike heads or you failure
units let's call them building blocks
which are quite wire isolated against
cascading failures from the outside but
my goal is that the service as a whole
stays alive and will keep on running so
just protecting me from other services
or other units of failure units having
problems isn't sufficient because in the
worst case what's going to happen is hey
I run perfectly and then you see growing
the lights out one by one until you're
the last survivor and but the service
doesn't work any more than so you need
some other kind of level which
supervises the service as a whole and if
one service has a problem yes the other
ones are not affected by that but this
must be repaired
so this self-healing properties of the
system and therefore you you need that
I'm supervision part so
detecting failure units and also
providing a means to send redirect
problems to what I mean with that show
you next slides so typical pattern is
monitor all quite well-known the only
thing which is very important to
understand and here is it's no longer
sufficient to send out an email to the
administrator whenever I call see a
failure or problem in your system
because there are always problems in
your systems so don't drive your admins
to a burn out build in self-healing
properties into your system which is
very important the rest is up to you and
let's skip that one and go to the last
one which is escalation which I want
that's where come back the thing I
mentioned before quite often inside a
unit we don't have enough information or
time or both to handle a problem that we
just observed so we either need more
time or more information and as we can't
hand handle that problem locally we need
an escalation peer so say I've got a
problem please help me and so we quite
often end up in multi-level hierarchies
which has basically design issues so if
you have your control and data flow here
on the lower level you get another
organelle flow for control and error
handling quite important for all those
people who are used to working with
single process systems because what
we're usually doing there also with
request request response pattern I've
got a problem down here so I just draw
an exception and it goes back up up up
up okay and it's locked and we forget
about that now where we're doing some
proper ik exception handling but it's
not an option in a distributed system to
tell your caller what your problem is so
let's it's definitely no problem no
option for you because your caller will
just he'll tell you and what should I do
about that I have no clue about that
what's inside of you I just wanted to
know I just had this request and I want
an answer so just tell me do I get the
answer won't I get the answer or does it
make sense to come back later whatever
but I don't want to know anything about
your stacktrace and all this additional
error information so so you need
something else where you put that and
this part the supervisor is going to
handle it was meant to handle these
kinds of problems your caller should get
back the response or simply information
you won't get any response here at the
moment so the 503 in HTTP come back
later or don't come back I'm going to
die because my supervisors go to take
care about that so that's this language
built around isolation and a bit of
supervision as I said before there's a
lot more but I unfortunately don't have
the time to talk about there are all
these recovery and mitigation error
patterns what options do I have if I
encounter a problem no matter if I
handle it myself or on a supervisor
level there are more ways to supervise
your system than just this one strategy
a lot of architectural patterns around
there are antifragility patterns around
which makes helps to make system even
more robust against problems so
antifragility isn't is nothing new and
their resilience domain that's 20 years
old this idea and then of course fault
treatments and fall prevention patterns
so some kind of upfront nourishing of
the system to reduce the likelihood that
something bad is going to happen
not get rid of it so as I said it's it's
rich parent family and quite a lot that
you can do dive into yet I think with
this starting point isolation you have a
good foundation to spread out into the
domain of resilience of a design so
let's wrap up as we've seen in the
beginning today's system landscapes are
distributed and it's getting worse
so failures in today's system landscape
at a normal case and they're not
predictable and they're not avoidable
avoidable at all so what we need is we
need some kind of resilient software
design from scratch we have to think
about how to make our systems to design
our systems in a way that they become
robust it's a very rich pattern language
and you can spend a lot of time in there
but still isolation as I showed you with
all these concepts around here is a very
good starting point and then you blend
the rest of it into it basically and if
all of that has been way too much as
again I said sorry that it's social time
for so much information and you just
gave up somewhere in the middle and just
want to take away one sentence from the
whole talk then take away this one
sentence do not try to avoid failures
embrace them that's what I had for you
so first of all things a lot for your
time for your patience and have a great
conference Thanks
I would suggest if there any questions
just come along ask me or they were
later because next one is probably
waiting to get on stage here Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>