<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Container Orchestration Considerations by Patrick van der Bleek | Coder Coacher - Coaching Coders</title><meta content="Container Orchestration Considerations by Patrick van der Bleek - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Container Orchestration Considerations by Patrick van der Bleek</b></h2><h5 class="post__date">2017-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iPnld2lizd4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so good afternoon people welcome my name
is Patrick
I'm from darker I'm going to have a chat
with you about our orchestration of
containers before we kick off who's
familiar with docker already good good
so this is not going to be a darker
introduction talk who is familiar with
orchestration already not less who is
using swarm in production who is using
humanities in production good so on
average we should be good to go
and this is more a talk on what are the
things you keep in need to keep in mind
when moving containers towards
production environments so it's not
going to be a deep dive on orchestration
it's more of considerations on what kind
of choices do you have to make in
regards to container orchestration a bit
about myself I've been playing around
with Linux since 1997 first box I broke
really good fortunately I got a lot
better at it right now turn to Linux in
my professional career since 2003
started off at the Dutch police doing
all kinds of Linux stuff and after about
eight years of the Dutch police I moved
to a large open source vendor famous for
its Linux distribution I joined darker
back in January of this year as one of
the first guys in Europe we started off
with a real small team this year and the
biggest challenge I have is I'm really
bad at saying no because when we started
out basically pointing Europe into
regions they asked me Patrick would you
be ok by doing Northern Europe and I say
yes which results in fact that I now get
to travel to all of the cold countries
luckily right now Belgium and
Netherlands are not that different from
the Nordic countries so it gets used to
the to the actual cold over there if we
look at container adoption
container technology is has been around
for a while
dr. technology has been around for
roughly four years right now and we
still haven't seen the end of the growth
of the usage of containers the numbers
you hear Syria right now 21 million
docker host those are the ones that are
known to us so not behind the corporate
firewall and regularly checking in with
the docker hub 24 billion image
downloads from docker hub as we speak I
think the most impressive number is the
one we've done for 2017 which is 12
billion so only half of this number is
actually the image pools from docker hub
in this year alone and final number 77
thousand percent growth in darker job
listings no this is not jobs open at
docker to company and we're small
companies fill 400 people globally this
is the number of job listings that are
out in the IT community for companies
actually looking for darker skills so if
you you want to put something on your
resume start with docker and the
recruiters will actually start following
you everywhere you go with the growth of
container use cases also the container
adoption also the number of use cases
that we see for containers is growing
quite rapidly where containers
originally were more meant for modern
type applications like Microsoft Azure
key textures etc what we see nowadays is
that the use case is slowly shifting
towards traditional applications as well
to give you an example we were talking
to a customer when we first introduced
docker for Windows talking about Windows
Server and and one of the questions they
asked is can I pick up this old
fashioned dotnet application I'm still
running on Windows Server 2003 and put
it in a container running on a 2016
version of Windows Server
well yeah the answer of course was as
always yeah technically you can but why
should you the answered occurred the
customer gave us was pretty surprising
and which I will still have 100 Windows
Server 2000 or three instances running
old-fashioned style Net Applications and
I'm paying a lot for support on that for
just a couple of security fixes on the
platform itself per year if I can
containerize that application move all
its dependencies in the container and I
can move it around I can just pick up
the container deployed on a new version
of Windows and I can get rid of those
old-fashioned operating systems yeah so
yeah pretty good use case so we started
working with this customer after a while
after deploying a couple of applications
on Server 2016 they started looking at
the applications again hey wait a minute
now we've made this application actually
portable so we don't need to deploy this
on premise in our own data centers we
can actually move it towards the public
cloud if we want to and then it came to
the consideration they want that all
2003 server was always the fact that
they didn't realize their public cloud
strategy yet because they could just
couldn't move those old-fashioned
operating systems and their applications
towards a public cloud environment and
container rising those applications made
it really really easy you know for the
traditional applications just for to the
point out this is one of the fastest
growing use cases we see out there in
the market today but of course other
typical use case is to speed up your
application development the deploy micro
service and scale out architecture those
are still really fellow use cases for a
doctor as well
orchestration why should I care about
orchestration if you're doing docker on
your local system as a developer you
probably are very happy with the fact
that you don't have to worry about the
underlying infrastructure anymore
whenever you put your container into a
production environment then suddenly dad
on
my infrastructure does become relevant
so let's say we have a platform that
runs 100 docker hosts where we have to
deploy your application on who knows
where this container is actually running
where we're going to deploy this
how are we going to expose this to the
outside world how do we make sure that
our application is highly available so
if one of our darker hosts goes down
that the application is absolutely
rescheduled on a other house how do we
do networking making sure the content
containers can actually interact without
on one another and how do we handle
persistent storage sure we can have a
docker volume on our laptops connect
that to a running container and we've
got our persistent storage we have to
have those storage options in a
large-scale environment as well so
basically what orchestration is going to
bring you is boils down to roughly four
things automatic scheduling of your
applications high availability scaling
etc things like that service discovery
where are my containers actually running
because container life-cycle can go down
to seconds or minutes so appertaining
can be living on a host one the one
single moment but half an hour later it
can be running on a completely different
host the other two networking and
volumes so networking connecting
containers towards each other so they
can actually communicate no typical
application exists of only one
application instance there's always a
couple of components that need to
communicate with each other and that is
actually one of the tasks that a
container scheduler actually has choices
there's a lot of choices out there I
name five in this slide there's actually
a lot more choices to make in regards to
container orchestration there's the
famous ones humanity's really popular at
this point in time swarm also very
popular may sauce DCOs
popular but not really a container
Orchestrator
from origin it started out as a platform
for compute resource scheduling and
management later on they added Marathon
which gave it container orchestration
capabilities rancher they had their own
illustrator and kettle I'm not sure if
you've seen the reason to the outputs
from from Rancher you're making the
switch to Cuban it is so they're still
on there but they're going to make a
change
so Cuban II this is going to be more the
one that Rancher is going to be
following on new kid on the block nomads
from Hershey Corp doesn't have a large
footprint yet but might be interesting
to look at if we could look at the
landscape currently to stand out which
is form and Cuban ET's humanities is by
far at this point leading Orchestrator
tool most popular between especially in
the developer community because of its
capabilities one thing that stands out
to me is the top one homebrew solutions
these are the early adopters in
container landscapes the ones that
started to schedule their own containers
well there wasn't any Orchestrator
available just yet that they could
actually use 20% I've come across a few
of them while talking to customers and
but I don't expect this number to to
grow very much it's near near future so
I'm going to focus a bit on the two
major ones which is swarm and Cuban
Eddie's starting over Cuban 80s and it
was announced via 2014 by Google right
around the same time that docker
released their first version of the
container platform as an open source
solution and it's based heavily on
Google's borg borg was an internal
project within Google which they used to
orchestrate containers and to give you a
bit of an idea in 2014 Google already
scheduled about two billion containers
per week that's two billion
so that's a couple of thousands per
second every single search you did on
Google was running inside a container
that's what they're one of the reasons
they started with Google board and they
needed a scheduling solution to schedule
all of those containers across the
environment they released it as an
open-source version as fee one in 2015
and put it on the cloud native compute
foundation as an open source project
called kubernetes
largest contributors to date Google and
Red Hat the famous open source company I
just mentioned already and these are the
biggest contributors but you'll see a
lot of different vendors contributing to
the cuban Eadie's project as well
interesting to see is that Cuban II this
is a real open source project on an open
source governance so the amount of
commits you will actually see will be a
large part for Google a large firm from
Red Hat but a fairly big chunk of all of
the commits going into Cuba knew this
project is actually in the bed net
software developers not working on Cuban
Edy's for their their employer for
example the other one swarmed originally
released by doctor in 2015 and that is
nothing compared to the swarm we see
nowadays so the first version of swarm
was external to the docker engine you
had to build up a server which then
could talk to a lot of separate docker
engines to schedule your containers on
top of it we integrated it into the
darker engine which we now call swarm
mode since version 112 so since that
version every single docker engine you
install whether it's on your macbook
whether it's on a linux box is capable
of becoming a swarm enabled engine and
capable of having those scheduling
capabilities it's fully open source as
part of the mobi project its component
we call swarm kit which is basically
added on top of the detailer engine
it is an open-source project but the
main contributor contributions to the
project still come from us so and we are
basically a driving force behind the
project so how do you choose the best
fit for your organization there's a
couple of considerations to be made
first of all what are you using
what are your developers using right now
a lot of times there's basically two
scenarios for an Orchestrator to come
into your environment
first of all is the developers have been
developing applications in-house need to
bring that to production and they've
been testing it on our local systems or
development systems environments using
Cuban ETS or swarm as their Orchestrator
of choice in that regard to the choice
that is being made is being driven by
the development organization the other
way around is possible as well what you
see happening is idea operations is
basically trying to build a platform to
provide to the developers so that they
can land their applications on top of
that from that perspective its IT
operations making the choice for the
orchestrator there can be a good thing
that can also be a really bad thing
because if you make the right choice the
wrong choice you're going to force your
developers to learn a complete new way
of deploying their application if
they're Bill they've been used to using
Cuban Edy's in our development
environment you're going to be forced
and to use swarm you're going to force
them to change the way they deploy their
applications so the other way around
yeah it is something that you really
need to consider and work together to
make the best choice for your
organization there are a couple of
fundamental difference between the two
one of them is the cluster management
capabilities of both if you look at Cuba
metis Cuba Nevis has clustering that
requires some external components so for
example for the configuration to be able
to share it between all of the hosts in
your environment
you'll need to set up an external kV
store in most cases @cd is used but you
have to set that up manually it takes a
lot of work it takes a considerable
amount of knowledge to set up and to
keep it up and running if you look at
swarm on the other hand it has all of
those features built into the engine so
it's relatively easy to set up setting
up a swarm cluster is basically two
commands running Dockers form in it on
one engine
Dockers form join on the other there's
differences in the CLI so swarm uses the
docker command-line interface so every
command you're used to used to do from
the local system is relatively close to
what it's going to be like when running
inside a docker swarm queue Benitez has
its own command-line interface not that
difficult as well but it's something you
have to take him to consideration when
looking at orchestration the other
fundamental difference is how networking
and storage are handled if you look at
swarm for example that relies on the
underlying engine to handle networking
and storage for you so if you do a
docking network create on a swarm
cluster it's the underlying engine
actually creating the network for you
which either has a local scope to the
engine or a global scope across all of
the notes in your swarm if you look at
cuba Metis Hugh Benitez takes a more
open approach they've got an API for
networking which you could just plug in
any con type of network infrastructure
of your choosing and in that case cuban
e t--'s is handling all of the
networking towards your containers so
mayor doing a docker network created on
a cuban V's cluster will make absolutely
no sense there's a lot to say for both
on the Cuban Navy side it's much more
open much easier to integrate with other
solutions other networks if you look at
the swarm side networking is something
that comes out of the box you don't have
to think about it on the other end one
of the models that darker is batteries
replaceable batteries included but
replaceable
so if you want to integrate with your
underlying network it is capable by
using docker plugins for that if you
look at one of the biggest changes
between the two and we're talking about
application developed their deployment
you Benitez uses something they call
pods swarm uses something we call
services they are quite different from
one another and to make it more even
more complexity Benitez also has a note
notion of what they call services which
is completely different from what swarm
uses as a service I think one of the
biggest advantages r-cubed me these
paths is that a part can have actually
multiple types of containers running as
link applications towards each other so
you can have one part with a web server
for front-end or a reverse proxy with an
application server back-end running
inside the same part allowing you not to
create complex network configurations
for those two to work together one of
the advantages as well is you can run a
pod and deploy it on one specific node
you don't have to worry about where is
application one contain one in that pod
running where it's contain or two in a
part running difficult part is oK we've
got the pod now we have to expose that
to the outside world how are we going to
do that then it becomes a bit more
difficult because then you need a Cuban
et servers in front which is basically
exposing your application on the
physical network and then load balancing
all of the traffic towards your
container pods services in swarm easier
to manage easier to create but they have
a limitation regard to parts that they
run exact replicas of each single
container so a service in swarm is
basically a set of containers which all
run the same image same functionality
which we automatically low balance
across when you attack connect to that
service exposing that service to the
outside world is actually really easy
is built into the service command it's
just adding a parameter expose this
service to this port or the outside
world and you're done you get service
discovery you get DMS you get load
balancing so it's making that choice do
I want to be able to set up a complex
application topologies or do I want to
go for a easier way to deploy my
applications without having to worry
about how does load balancing work how
do I set up a service in front of those
applications that's it
as I mentioned choosing Orchestrator is
something you do both as a developer and
as an IT operations a couple of
considerations to make when you're
actually a developer if you want to use
an application that's capable of out of
scaling that is something that Kuban
et's can do out of the box swarm on the
other hand doesn't have auto scaling
capabilities just yet it will be coming
somewhere in the near future but this is
something that isn't hasn't been high on
our priority list just right now one
additional thing I want to mention about
auto scaling um most of the auto scaling
solutions right now look at it from an
infrastructure perspective which means
you're going to bear base auto scaling
decisions on metrics from the underlying
operating system in the case of Cuba
needies team if I'm correct right now
the only implemented version is CPU so
you're going to base your auto scaling
decision on the amount of CPU that is
being used by the application if your
application is doing something drooly
wrong and is consuming a lot of CPU
because of that and you make a decision
to auto scale right down then you're
just replicating your problems making
them even bigger than they actually are
so be careful when using auto scaling
I've seen in the cube project that
they're actually working on something
they call custom metrics so you actually
can start interrogating the application
on actual application statistics where
is the
q sighs how busy are you how many
requests are you handling right now and
do you need actual help then we can
start scaling in my regards
what safe way of scaling up Bluegreen
deployments familiar with that yep
so Bluegreen deployments basically I'm
deploying a service I have 10 replicas
of that specific service and I'm going
to do a new version and I'll test it out
on three of the 10 and I want to
redirect a small bit of the traffic to
the new version of my application before
I start rolling it out on a larger scale
that is something that Cuba needies can
do today swarm on the other hand doesn't
have that notion yet you can do it but
you have to work with a lot of
workarounds they have to consider the
actual workload you come to deploy is it
mostly going to be really modern type
applications with complex application
landscapes Cuban ETS might be the better
fit if you're going to deploy
traditional applications databases
WebLogic WebSphere those kind of
applications running in a rather
traditional way then swarm like MIDI
backs ready actually to be a might be
the better fit much easier to bring a
traditional application to a
orchestration environment in swarm than
it is in on a Cuban ideas cluster the
learning curve for developers it's okay
Cuba need is you need to learn how to
Cuba Cuba needies command-line interface
where it works and how you deploy
applications in Cuban it is a couple of
the concepts like services and positive
points that's something you need to
learn but it is achievable and sworn on
the other end is relatively easy because
most of it what you see in swarm you've
already played around with with well
using docker compose a lot of that
technology using compose come back since
in a swarm environment are you going to
run old-fashioned Windows application
dotnet I is a speed-up net
then swarm at this point in time is your
choice that is the one that is capable
of having hybrid clusters consisting of
Windows and Linux nodes in one in the
same cluster it is coming for a cuban
et's but that's still in in early stages
and as I mentioned the application
constructs and swarm uses Gemma files
basically a composer is also a llamo
foul but composes a format that is known
to a lot of people because they've been
using compose on their local systems so
when using cuban it is you need to learn
how to code your application layout your
topology in a cuban additional file
looking at it from an ops perspective
however things changed a little bit when
we look at the learning curve building a
cuban ITA's cluster managing a Cuba the
Cuban ETS cluster the word breaks my
mouth every time is pretty hard it means
a lot of skills it means a lot of
learning before you can actually start
deploying a communities cluster into
production and and manage that weird
yeah with some confidence as I said the
installation is pretty difficult it's
it's relative easy you deploy a kV store
at CD you may have to make that high
available you deploy your cuban et's
masters also relatively easy then it
comes from networking basic out of box
you get one big flat network to deploy
your applications in and then you want
to start using
software-defined network so you got to
integrate things like open V switch or
ro networking solutions making that all
that highly available can be pretty
difficult the other thing is close to
communications um normally you would be
want to encrypt all of the traffic
between your notes this is something you
could do within cuban e this but it
doesn't do that out of the box you have
to set that up
integrated with your own PKI
infrastructure looking at swarm as I
said it is relatively easy it's to come
also set up a two node cluster learning
curve is pretty easy as well as I
mentioned it's the same darker command
line interface you've been using on your
local system for a quite a while and
security is something we take pride in a
docker
we'd have done a lot of security
configuration by default out of the box
so if you deploy a swarm all of them
nodes communicate with mutual TLS
between each other certificates are
auto-generated between the notes are
recycled every now and then you can
interface with an existing PKI but only
through a couple of protocols looking at
networking in a swarm you'll get overlay
networking out of the box overlay
networking is basically a
software-defined network which stretches
the nodes in your cluster wherever your
application is being deployed if you
want to go and build external networks
you want to interface with your physical
networks for example that's where it's
going to be a bit tougher when you're
using swarm application deployment as I
mentioned cube Aneta GMO file is
extremely flexible and I'm not thinking
you're actually going to read this and
be able to read this I just want to
point it out as an example this is an
example yellow file is deploying a
wordpress instance where m is equal
back-end and because if I didn't have
room on this slide I stopped at the
WordPress service so it doesn't this
doesn't include in my sequel services
this hopefully gives you an idea of how
much possibilities you get when
deploying an application landscape using
cuban et's there is so much you can
actually tweak and chew and at the same
time it can make deploying your
application a bit complex if you're not
really comfortable with this kind of
setup however it is
really flexible you can create extremely
complex application setups and tweak it
to your career findings as as much as
possible on the other end this is the
version you would use in Dockers form
it's almost identical to your one I just
show you but this does introduce my
sequel in the same page advantages of
this it's relatively easy easy to use
and for the ones that have used darker
compounds whereas do you stock up to
compose a lot of hands this should look
rather familiar downside it's not as
flexible as the example I just showed
you in the beginning of the slide so if
you want to choose M is going to be a
journey on ok um typically journey on
should I choose the red pill should I
choose the blue pill most important
considerations what type of applications
am I going to run is it more traditional
slightly towards micro-services
architectures then swarm might be the
best fit for you if you look at more
modern type applications 12 factor web
apps modern micro services architectures
will complete complex structures then
cuban ETS might be the best fit for you
scaling requirements um there's two
scaling requirements you have to look
into as swarm can scale up to thousands
of nodes Cuban ETS was built to scale
even further than that so depending on
your cluster size you'd have to look
into either one of those on the other
hand auto scaling if that is an
important feature for you thank you
Benitez might be a better fit are you
going to do multi-platform is it the
only Linux in your data centers you can
choose either either one if you want to
go towards Windows then Cuba Nevis is
not probably not the right one for you
to choose at this point in time it will
be in the future but at this point in
time windows supporting humanities
is just not there yet if you look at
swarm on the other hand we do Linux we
do Windows we just announced the
capability of actually running Linux on
the mainframe from IBM so you can
actually start adding your mainframe
instances into a existing swarm
environment and run your applications on
there another consideration is what is
your skill level I think the skill for a
developer is something that is
relatively easy to gain it's it's not as
steep as a learning curve for developer
as it is for a infrastructure IT
operations person that is where the real
difficulty is going to be so if you have
a lot of skills in-house you're used to
manage complex infrastructures the Kuban
et's is absolutely a viable option if
you don't want to build that skill and
you want something that is easy to use
easy to maintain
then swamp swarm but would be probably
be the word a better they're better one
consider your cloud strategy so ok
containers helps you make your
applications more portable so you can
actually move them around between cloud
providers there's one thing you have to
keep in mind with both types of
orchestrators most of them bring you a
lot out-of-the-box Software Defined
Networking that fully abstracts away the
underlying network infrastructure for
you and the same goes with storage you
can provide storage volumes towards your
application without actually knowing
what kind of physical storage is
underneath your platform if you're going
to go for complex setups and you tend to
go way down into the underlying
infrastructure and that's going to limit
you on where you can actually start you
deploying your applications so if you go
for orchestration as well take into
account how much freedom do I want to
have moving around between on-premise
physical virtual or public cloud and I
cannot stress enough orchestration
impacts both the developer and the
operations so developers might be the
ones that love using
humanities but if you start pushing that
to ID operations and they don't have the
capabilities of managing such a platform
for you
you might get into big trouble on the
other way if the IT operations team is
already building a cube platform for our
developers to run on well 80% of the
developer community in your company is
already using swarm you're forcing them
to move away from something that might
give them just the amount of tools that
need to actually deploy their
applications the way that they want to
deploy their application so it's always
a tough challenge but you need to figure
out a way that both parties can actually
cater each other
so I'm who's been in this morning
session with my colleague fatique or
Patrick would surely say so and he did a
demo on Cuba Nevis integration in docker
I thought it was only fair to do a quick
demo and give swarm some exposure as
well so what I want to do is deploy a
fairly basic application which is a web
application which has two components
going back to the first slide with the
introduction slide I have an
infrastructure background so one big
warning I'm not a software developer and
I will probably never will be as you
will probably see during this demo I'm
not good at it I will probably never be
good at it but I I like doing demos
application what it does is I've got
from an application and it's a Python
application that basically serves up a
web page and it pulls an image from a
image server that runs in the backend
sounds really easy I want to basically
separate the image server from the
front-end so I'm going to deploy the
image server in a separate the backend
network so that it is not reachable from
the outside world and the only thing I
want to expose to the outside world is
the actual image front-end
so I've built a composed file for that
relatively easy setup I'm going to
deploy two surfaces to my swarm one is
the front-end server I'm explaining to
the front end service which image it
should use it comes from my private
registry I'm going to expose that
internally to the network on port 5000
and delivered me not exposing the port
on the outside Network I'm known to
connect it to two software-defined
networks to overlay networks as we call
that in swarm one is the UCP HRM network
and the other is a back-end Network when
I deploy that I want swarm to create six
replicas of the application for me so
I've got a service which is running six
containers doing exactly the same thing
and I'm going to load balanced across
them in the final thing you'll see is a
label that I attached to it this is a
nifty little feature in docker EE which
basically allows me not to just publish
a port but publish my application based
on a hostname so I don't have to know
which port my application runs on I just
deploy it it listens to all HTTP
requests coming in looks at the HTTP
header decides okay this is for this
application and it routes it into my
container platform Bekins is my image
server basically just an engine iyx
running a couple of animated gif
pictures I want that connected only to
the back-end network so I'm not going to
expose that to the outside world and in
this case I want three replicas behind a
load balancer running there the final
few lines is basically me declaring all
of the networks I use so if you see if
you look closely you'll see that the H
UCP HRM is defined as a external network
which is basically telling my swarm
don't create this when I deployed the
stack it's an already available network
in my environment the backend network
and however is specifically built for
this back
so I hope that a swarm will actually
deploy that for me pretty simple example
right don't see people finger only good
let's see what happens when we deploy
this to a swarm don't tell docker to do
a stack deploy use this compose he'll
give the stack a name and to make it a
bit more visual I'm using a tool which
one of my colleagues created to
visualize my cloud nice warm environment
and you can see seven nodes in here six
linux nodes in the number seven is
actually a Windows worker notes and so
I'm really hoping that swarm isn't going
to schedule any of our Linux very close
on node seven during the demo let's see
what happens um it should create the
mapper back-end first then it should
create the surface to front-end then it
should create an image server it should
pull all of the container images from
the private registry I built deploy them
create networks low balancing rules for
all of those containers and it should
have published it on a URL that I gave
as a label on the compose file you see
it actually works
you also see my incredibly devastating
programming skills the only thing I want
to point out is you'll see the container
ID this is actually one of those six
front-end containers that's been serving
this webpage the actual image itself
comes from that back-end which is not
available to the outside world if I love
barrel refresh our page right now you'll
see the container ID change now if for
some strange reason people actually like
this work and start visiting my site
quite frequently I want to scale this
out
any suggestions how many containers do I
need I did 100 yesterday it worked but
it almost killed my cluster so I'll
stick to 50 reason why it's killing my
cluster is I'm running this on Amazon
Amazon is pretty expensive so to save my
company a bit of money I'm running
rubbish small instances of the
environment let's go back to my
visualizer if I can find my mouse and
you should see it spinning up an
additional load of front-end containers
and move it towards 50 this is what
basically how easy it is to deploy an
application if you've used if you've
been using compose then it's not going
to be a lot different than using swarm
on the other hand why choose it all
who's seen the announcements from dock
icon a couple of hands go up good one of
the things that the survey I used in one
of the first slides which told you how
much usage we see in the market right
now of orchestration platforms tells us
is that a third of the kubernetes users
is actually reporting that they're also
using swarm why is that there's two
reasons their customers can actually do
that one is they haven't made a final
decision yet and they're still trying to
discover both which fits our
organization best the other one is that
it's a thing that's been grieving been
driven from the development teams part
of the teams are used to working with
swarm and compose other parts have been
using cuban et's for a while and
companies don't want to force either one
of those teams to start moving in a
different direction and start working in
a different way so that's why we decided
to integrate
Kuban needies as an Orchestrator into
our Dockery platform as well so now we
can actually provide our customers with
choice on which orchestration to get to
use one of the main goals we have for
that is make make it simple because we
realize that a managing room could be
read as environment and deploying a cue
bonitas environment is relatively
complex and we want to take that
complexity out of the equation for that
the other consideration we had in mind
is we need to make stay focused on the
developer experience so a developer
should be able to use the same commands
to deploy his applications in the same
way on his local system as he would do
in a large-scale production environment
one of the reasons we've been getting
this request I mentioned it already
a lot of customers actually have
multiple teams from making different
choices so we see quite some customers
that actually have two types of
orchestration going on in their
development teams and when the developer
teams start pushing for containers in
production IT operations is standing
with the back to the wall okay what kind
of choices do we need to make here
typically they don't want to make that
choice I want to provide both options
customers also helped us make human need
help us make Cuban ET's more easy to use
because that is one of the biggest
challenge when using an open source
community version of cuban et's you've
probably got a lot of skill in-house
large enterprises rely on large IT
operations teams and if only one or two
people of those have actually actually
the skills to man maintain and manage
such an environment you're pretty
screwed so looking at the darker
Enterprise Edition platform and don't
want to make it a too commercial talk
but there's more to it than just
orchestration the thing that I've been
talking about for the past half hour
forty minutes it's basically where the
arrow is pointing at it's only a small
part of running containers in production
at skill and what we're doing right now
with the introduction of cuban et's is
making that part something you can
choose as a user without having to think
about how to install it and how to
maintain it what does it look like
technically simply we already have
swarmed we looked at the complex part of
running a cluster management solution
for kubernetes which is basically all of
these security encrypting the network
communication between hosts storing the
configuration in an external key value
store those are the things that swarm
already does out of the box so why not
integrate swarms cluster management
capabilities with cubanÃ­a so you don't
have to worry about that anymore
why manage to clusters was one of the
things we were had in mind as well why
not have one big cluster that is capable
of deploying cubanÃ­a these applications
and swarm applications at the same time
so every node in your cluster is
actually capable of receiving a queue
bonitas environment application or a
swarm application at the same time they
both listened to the both api's and on
the front you just decide do I want to
push a cuban EDM or file to this
environment or do i want to push a
compose file to this environment when
you add a node to the cluster it's going
to be as simple as docker sworn join and
then the magic starts happening that
note you just added to that swarm is
automatically configured to be part of
the same cuban Edy's cluster as well
making sure that all the connectivity is
set up then it has to place to store its
shared configuration etc etc as I
mentioned one of the other important
things we have in mind is that user
experience all the way from development
towards production we want to make sure
that when you move an application
through these Selfridge supply chain you
shouldn't be introducing developers to
new things because then you're making
their work a lot more complex so for
that reason we're going to integrate
cuban et's into the darker foam
and dr. for Windows clients as well and
what you'll get out of the box when you
download and install doc for MEC you'll
get the look and feel you're used to
command-line interface but we add
something under the hood you'll get a
really small cube anita's environment
running right next to your document
environment without you knowing it and
Wiggins will introduce the cube CTL
command-line interface for your users on
there so you can actually deploy a full
cube anita's application on your local
local netbook or your Windows desktop or
whatever and deploy it in exactly the
same fashion as you would do in your
large-scale production environment and
we're adding all of the features that
Dockery brings on top of orchestration
as I mentioned orchestration is only a
really small part of the puzzle so
there's a lot of security features that
we bring to the table role based access
control if you're going to have multiple
development teams use the same
environment all those tools are already
in the Dockery platform we're integrated
tightly with swarm and we're going to
integrate those with kubernetes as well
and if you want to play around with it
and we're all going to open up a beta
program probably in the fourth quarter
so hopefully before the end of the year
so we actually make fourth quarter if
you're interested go to doctor.com Kuban
v's sign up and we'll send you
information on the beta program later on
and the idea is that we have this
available for our customers to start
using it in production enterprise-grade
in q1 of 2018 so it's going to be
available for Dockery East and for Linux
reason for that as I mentioned earlier
in a couple of slides ago Windows
capability is not yet available in Cuba
ladies but will fall out later on in the
row so that's what I wanted to explain
you if you have any questions feel free
to find them fire up and otherwise I
want to thank you for your attention and
have a great day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>