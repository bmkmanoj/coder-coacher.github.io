<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microsoft, Canonical, Docker and Chef - Cooking up a Swarm by Justin Davies | Coder Coacher - Coaching Coders</title><meta content="Microsoft, Canonical, Docker and Chef - Cooking up a Swarm by Justin Davies - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Microsoft, Canonical, Docker and Chef - Cooking up a Swarm by Justin Davies</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iC7oyQ50i0I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">forgive you play kid do it make sure
good morning everyone thank you very
much for coming along to the Microsoft
presentation I know it's a Java a Java
conference so coming on to a Microsoft
presentation thank you very much when I
was taking the time my name is Justin
Davis I'm the open source technical lead
at Microsoft
so looking after linux jabber on linux
java on windows and looking up there are
ISPs as well so the likes of docker chef
and canonical as well he's going to be
coming on stage with meteor shortly I
think historically people don't
associate anything non-microsoft with
Microsoft especially even when it comes
to the cloud as well and we're here
really to be able to dispel that myth
Satya Nadella our CEO 2014 really
internally at Microsoft said that he
wants everyone to work with openness in
mind so we know developing in the open
so that other development teams can see
what other development teams are doing
and everyone to be able to work
underneath the source of open source
being the driving force behind what we
do internally at the company and look at
that that's not a world-changing or
dramatic in terms of that since it's
just changing the internal way that we
work at the company
it wasn't until later then that Satya
get up on stage and we have this slide
here Microsoft loves Linux not gonna
bang on about Linux and of what we're
doing with regards to it but really what
I want to highlight is the fact that I
think a lot of people historically
wouldn't have assumed that this type of
messaging would have come from Microsoft
we want to make sure that as a company
anything can work within our cloud
doesn't have to be Microsoft it doesn't
have to be sequel server we want to make
sure that if you have a workload to be
able to come to Azure as a cloud
provider it will work and it will work
in the best way possible the way that
Microsoft does this is that we initially
enabled the platform itself to be able
to run non Microsoft products so
initially the first one being Linux we
contributed a huge amount at the Linux
kernel to be able to make sure that the
operating system ran as well as possible
under height of II which is our
devisor be able to work very close with
the likes of docker as well in terms of
making sure that as your container
service which is essentially an
infrastructure orchestration layer with
energy to be able to run docker swarm
kubernetes and d cos or mesosphere and
be totally automated and and since he
looked after for you don't have to worry
about the underlying infrastructure a
couple of steps further is that we've
actually taken open source projects that
we consider best in breed to be able to
provide good solid functionality to our
customers and actually provided a
service around those as well so the
likes of Reedus key value store and
distributed caching system said docker
being part of azure container service as
well and the likes of our big data as a
service hdinsight is actually based on
one of one of the largest providers was
I've just forgotten actually hdinsight
oh yeah it'll come to me I will say in a
second I'll come back to that in a
second
the other thing that we've done as well
as that we've actually open source our
our own pieces of software which were
considered to be core company
intellectual property so the likes of
PowerShell the.net foundation is well
we've open source that and we've
developed that in the open so that
allows our customers to be able to be
involved in the development of those
those pieces of software and allows them
to be able to see what we're doing in
terms of fixing bugs and moving that the
software forward and we also contribute
back to to open source software so the
likes of Linux docker as well are then
contributing back to the likes of Python
as a programming language and taking the
learnings that we've had from running a
hyper scale cloud environment globally
and leading that back into open source
projects so finally before I hand over
to canonical to be able to go through
their demonstration as you're is an open
cloud that we we provide a kind of home
for not just the operating systems but
also the likes of a big data cloud era
my sequel postgresql being hosted and
being managed within as your for you all
of these people and all of the logos
that you see on here we have
relationships with them and we would
have both strategic soak and commercial
relationship
with them but also engineering
relationships as well our cast our
engineering teams and their engineering
teams working together to be able to
make sure that again those pieces of
software are best in breed running on
Azure as a platform so that's kind of
the Microsoft story where we are really
in terms of Azure and it being open is
not just Microsoft and I think the
demonstration in terms about our
partners being here to be able to show
what they're doing with adjourn with
Microsoft is testament to that as well
so with that in mind I'll hand over to
Nikolas from canonical to be able to go
through Gigi thank you
thanks Justin hi everyone I'm Nikolas in
otakus I'm from canonical so in case you
haven't heard of us we are open to we
are the company behind Ubuntu so I'm
sure you're aware that Ubuntu is
effectively the developers choice for
the desktop and I'm pretty sure many of
you might have already used and are
using Ubuntu but one thing that maybe
you're not as aware is that Ubuntu is
the developer choice for the cloud in
fact all the big the big companies the
big successes right now that are using
cloud technologies to to operate you can
see all there are all running on a boon
to everything that is scale out and
cloud effectively runs on Ubuntu 75% is
a magic number that that we tend to to
mention in general so effectively 75%
apologies of overtures Linux so of
course as your runs a lot of Windows
virtual machines but anything that's
Linux about 75% of it is a boon to 75%
of all the open source projects there
are also boon to same thing for the arm
templates HD insights in fact runs on
Ubuntu
the default doctor images are again
Ubuntu if you get kubernetes owners your
are the default kubernetes again that
runs on Ubuntu and a number of other key
services effectively so a bundle has
been the platform of choice for for
developers so this is the reason why as
development started moving to the cloud
Ubuntu came with it and that's why it
became again the platform of choice just
a little bit about how we see the world
at canonical so we see the world on two
sides one is the elastic hybrid cloud so
effectively is a number of machines in
the private and public cloud it's the
ability to to scale out either as your
private cloud or scale out elastically
into the public cloud as well it gives
you it you need to have the capability
effectively to have machines everywhere
right have running machines and services
everywhere scale as you need have the
high availability exactly as you need it
and be flexible so this is one side of
the story where effectively you stop
caring about individual machines you
care about your applications if a
machine dies in the cloud on Azur you
guys don't care you're still going to
get your service you're never going to
experience that the machine died right
so cloud is building in in this way on
the other side though when we talk about
the transactional edge we're talking
about individual devices robots
drones cars you know self-driving cars
so
all of these devices effectively are on
the edge they have importance on by
themselves so they're not they're not as
redundant as you have within a data
center or a specific machine if a drone
dies this is a problem right if a is a
base station that provides a 4G service
somewhere in a in a telephone pole or
somewhere in an electricity pole dies
somebody needs to roll a truck and go
and replace that so the importance of
the transactional edge is quite
different from a from a device
perspective than what is in the elastic
cloud Ubuntu effect will plays on both
sides of the spectrum and deals with
both sides of the spectrum quite
differently over here we build tools
such as math and juju to handle machines
at a very large scale and to provide
that elasticity at a very large scale on
the other side we have a bun - which
works with snaps and snaps enable you to
secure your device to provide updates to
it without endangering a corrupt device
which again will require you to roll in
the track or to do a complete firmware
upgrade so we're always thinking of what
is the importance of each type of device
on on one side or the other one thing
that I'm sure you're aware of is that
software is becoming cheaper and cheaper
to the level of being free right this is
the whole point of open source so
license costs have been going down I'm
pretty sure you've experienced this with
Microsoft as well and would pretty much
everything else that you use as
developers you tend not to buy licenses
anymore however what has increased is
the cost of operations
quite significantly why because you have
a very large number of new pieces of
software that all need to work to
gather to provide the service that you
need in the old world
you bought a license from one vendor you
have your whole piece of software
everything was working
you had one maintenance contract you had
some experts in it and that was fine
right now when you go to anything that
requires five six seven pieces of open
source open-source software you need to
have the people that have the expertise
to operate that software I'm not just
talking about using the software I'm
actually talking about operating it and
so the big challenge is how do I operate
efficiently and economically and this is
what canonical has come in to try and
solve so let's talk about deploying and
operating how can i deploy swarm for
example or Zeppelin or Hadoop or
kubernetes and how can I operate that in
Azure cloud for example in minutes or in
my local machine because I want to
develop something very quickly well it
needs to be done in exactly the same way
right so effectively you need to have
the ability to deploy any bundle of
open-source software or even licensed
software in an easy way and you need to
be able to operate it in exactly the
same easy way and when I say operate I
mean you need to be able to scale it out
I'm running a swarm and I'm running
three workers of swarm within my bundle
and I need to increase that to five
because my workloads have really
increased well I need to do that in two
minutes I need to just click on
something and say allow me to do allow
me to expand my swarm into files I need
to be able to upgrade it right now we
don't have the capability to take things
down anymore things are running in
production and we need to be able to do
upgrades live in production and I need
to have that capability but I don't want
to have to hire the people to have all
this knowledge this operational
knowledge I don't care about that I want
to use the software I don't want to
spend a lot of money operating it
so effectively what canonical has come
up with is juju juju is an application
modeling tool which focuses on
economically and effectively operating
big software as we call it
each circle that you see there is one
piece of software that you can bring in
from our store
it's circle is called the charm a charm
effectively is the operations code and
deployment code for each piece of
software so if you see for example there
at the top over here we have a docker
swarm and we have other pieces of
software like console we have file bit
top bit and of course we have Cabana for
monitoring purposes and I want to be
able to deploy that without having to
think oh I need to bring all these
different pieces I need to write some
sort of script to bring them in together
now I want that code to exist somewhere
I want it to be able to deploy these
things very very easily and then I want
to be able to operate them very easily
let me show you apologies let me show
you what I mean in there it is so here
is here is Zhu Zhu sorry oh how do i ah
yes sorry
okay
said okay perfect so here is a model
that I started to spin up a little bit
earlier this is the the canvas I
basically I basically went in I created
a new model in Zhu Zhu and I said I
would like to install swarm so I
searched in the store I find either the
individual charm for swarm or I find the
whole bundle which includes a number of
other pieces of software
I added through the model and as you can
see now it's starting to bring from from
the juju store the different pieces that
make up my bundle so let's say I want to
deploy that to a shore so I would like
to deploy the changes you can do this by
the way with CLI it's juju runs
completely on CLI I click on Microsoft
Azure let's say I choose the region West
Europe let me put the SSH key here
that is justin's ssh key if you can
remember it as if that makes any
difference okay
it basically says the machines to be
deployed are nine so i need nine
machines to deploy this bundle and then
i click deploy sorry
ah i need to change the model because i
already did one of those apologies let's
just call this dr swarm okay i click
deploy and then if i go over here you
can see that it's starting the
deployment and you can see exactly the
status of each one of the pieces of
software so if i refresh now there
should be a new resource group there it
is
juju docker swarm so as you can see
what's happening is automatically juju
is requesting machines from azure and
it's saying I would like nine machines I
would like those machines to be of XYZ
specification and then I would like you
to deploy for example boom - on those
machines and then I would like it to
download the software and install that
create the relations between those
pieces of software and then expose it so
I can use it and exactly this is what's
happening so effectively you end up with
your complete bundle that runs docker
swarm and I'm now going to pass it over
to docker who will talk a little bit
more about docker storm
thanks very much
my commentary all right hi everyone my
name is Steve Heights and I work in
London before docker if you're looking
for us or one slide for what book has
been up to or we're trying to do it's
really here we're trying to get all the
tooling that spend across development
and operations across multiple different
platforms for working with containers so
we're not really opinionated about where
where you want to run your workload or
way what word code you want to run on on
the platform but all the tool that spans
all of that hopefully everyone is a kind
of had the 101 talk on docker before a
procedure cool so just a few things that
you might be unaware of some some of the
more recent stuff that's happened in
docker very focused obviously started
life as about four years ago now as a
just as just as a container engine and
obviously over time tons of new
technologies been piled in there things
that handle orchestrations networking
service discovery storage all that kind
of things at them as well and now we
have the mobi project this was recently
announced at docker Khan and this is
actually a an upstream of da canal that
has all of the components that make
docker what it is separated into
separate projects which are more generic
and that can be assembled into an other
as a component of other platforms so
this is kind of given a lot of what they
were looking for because dr. got quite
big over time
and it's also net now part of the
universe a set of upstream so I guess in
an analogy would be sort of a fedora
into realm for example and another one
is around container D so this is the
container supervisor which runs and
looks after every container that's
running and that's been recently given
over to the CNCs the cloud native
computing foundation also the circus
custodians of the cubed IT project and
also all of that we're now distributing
our assembly of those components docker
as c e and e e so c e is pre bit free
for developers and develop a sort of
platforms for your prating systems and
then EE Enterprise Edition is for
production and sort of production-grade
os's the we're always working to broaden
OS and platform supports so we used to
be just linux x86 but now of course you
know Windows is coming into play arm
devices of course working with
integrations on different clouds as well
and this is really where some of our
work with Microsoft has been come to
fruition we've had an engineering
relationship with Microsoft since 2014
and that's now sort of yielding results
all across the tool chain so the manager
of docker is build ship run so I figured
in the time that I've got I might turn
just go through these things in turn so
on the build side for developers there
is dr. C if your development work
station so if you're running Windows 10
Pro or if you're running Mac OS 10 you
can just download Doc's EE and it's just
a very very nice integrated experience
so some of those upstream projects like
hyper kits and VPN kit are put to use
here to expose the hypervisor framework
in Mac OS 10 and we use of course
hyper-v built into Windows 10 to give a
embedded Linux virtual machine so you
could get to work for creating those
containers but in a very kind of
seamless manner and you might be able to
see at the top there we're actually
switching between working with Linux
containers and windows containers on the
windows Edition because we also have the
ability to run the doctor engine now on
windows huge plug in support across the
whole sort of much of the tool chain so
plugins of course for your IDE including
visual studio MDS code the build tools
like maven and Gradle or have you know
very strong and mature docker support
now if you're working with doctor
machine for creating development
machines as well these your plugins
allows you to go and spin up new engines
on demand and of course Microsoft is now
contributing images to the public docker
registries so the docker hub in the
docker store are examples of that and
that's where Microsoft are now
publishing a lot of their sort of core
technologies on which you can build your
work so that could be Windows nano
server images to provide you that base
image that
used as that base user space where you
add all your software but also you know
their middleware as well things like you
know net IAS etc ready just if you to
add your own content and then
immediately deploy and that's you know
those just examples some of the official
mineral middleware images that we have
available so lots of the products have
official images if you like from the
products themselves so that would
include like Tomcat also the Enterprise
Java and middleware as well from Oracle
IBM and others now have official support
now on the school on the ship side so do
you and docker if you're on this if
you're on the sea release you can
actually subscribe to a edge channel so
there are stable and edge channels
available they will come it quarterly
Abel Teran really have all of the baked
features and edge comes every month with
whatever's coming out in is new features
speed to test one of the new things
there is how multistage building docker
which is really nice that means you can
sort of having to put all of your sort
of build software into the actual final
image you can run your build process and
that will actually use a particular base
image with the software you need to
build your artifacts and then continue
that build with potentially another
different base image that's used for
deployment
which is long been asked for and it's
now fine again integrations of course
with jenkins bsts
team foundation server team city all of
the CIT we now have pretty strong doctor
support as well and on the registry side
registries being of course where we've
where we keep our doctor content in
images we have of course the the public
docker hub which has now had something
like 12 billion downloads now we're
having like a billion downloads every
five weeks it's crazy and of course the
usual container registry which is
offered directly on a jewel from
Microsoft for the enterprises well we
have doc a trusted registry and this can
be deployed you know on Prem or a
furniture if you like which would give
you a few extra kind of enterprising
features surrounding your registry
things like access control of course so
you can control who does what and who
can do what within your repositories but
also features like image scanning which
will actually
inside your image I think I can quickly
show you some of that a second image
signing as well so you can actually add
a digital signature to content that you
can verify on deployment and things like
web hooks as well so you can tap these
events happening in the registry and
then kick off your own automation yeah
so lots of the all of the open API open
source API supply of course in in
Enterprise Edition but these extra web
hooks and things give the ability to tie
this and integrate this one into
whatever your pipeline is and of course
run so on the run side this is really
where as your becomes a target for us as
a place to actually create
infrastructure to run containers and
then and actually start our containers
there so from that familiar a user
experience perspective Dockers you know
it's very much a strong point is that
it's actually very very similar all the
way across different platforms you're
effectively operating when you're using
your your CLI a an API client using the
docker Klein you can point out something
local when you're doing development and
you can just change that's pointing and
then point to a server in your
datacenter or indeed servers out in the
cloud and so we can deploy a swarm as
been done already and that will give us
a bunch of features that we're going to
want to use in running containers so now
includes built-in orchestration in swarm
this gives us you know very very secure
orchestration framework it has load
balancing and high availability features
so built-in you can just deploy multiple
replicas of one component of your
application and they all you know
service discovery dns resolution and
load balancing is all kind of built into
that and that gives us the ability to
handle rolling upgrades which is often
something of an achievement to to
actually
hand-cranked can make happen yourself
but now it's just part of how this stuff
works most recently as well secrets
management is now part of this as well
which is really nice this means we can
we can we can have someone deposit a
secret in the swarm and it's encrypted
on disk it's encrypted in flight on its
way to the point of workload and this
and then someone I don't need to
actually need to know what that secret
is or have access to it and I can just
reuse it in my specification so I can
say this application needs to be able to
see for example a connection straight
as password and it will be encrypted and
flights decrypted on the fly and exposed
to the container so you can use it in
your application and as your integration
so this is what ambien there's loads of
scope for this of course we're building
a container infrastructures there's lots
of things we can reuse from Asia so if
one example is when you're persisting
storage outside of containers you want
to want to do that to symptoms of disks
that survives after the container is
upgraded or is destroyed and we can use
it as you can set a storage plugin for
that
so this trivializes you know setting up
external volumes for your containers OMS
so we can actually gather we have an OS
image for docker as well so we can
actually run that on our engines and
then collect all the data bits for
what's happening on the engine itself
and inside your containers and actually
send that straight out to edge if you're
in analysis as your extensions the
docker so if you want to just go pure
infrastructure as a service and then and
make this happen through that way then
you can have to use the extensions to
set up docker inside your containers
sorry inside your instances and then on
templates so if you if you know that you
know what you want is going to be pretty
generic or if you want to say something
right well very quickly for development
we do have an templates available it
like you just settle this up and click
and there's image there on the right
which kind of shows sort of that we're
making full use of V Nets the load
balancing etc and Azure as well and as
of last year the support for Windows
Server was editing docker so that means
so you know it's no secret in lyrics
we've been reusing Linux kernel
components it's you know it's just a
very nice interface for setting up all
the settings in the kernel for running a
process in isolation and we can do the
same now in Windows part of what we've
been doing through engineering with with
Microsoft is arriving at a set of
analogs in the Windows kernel that allow
us to code to present the same interface
to users so dr. Paul docker run docker
build all look and feel the same even
though the implementation is underneath
and the result is the same so we had
that engine release happen around the
time of Windows Server 2016 release at
the end of last year and now we're about
to add
warm as well two windows and the so it
be coming very soon and the result will
effectively be you can have a mixed-mode
swarm at that point so you can have
different components of your application
running on different operating systems
and you still using overlay networking
and a unified experience across both
platforms so expeller to be a big deal
in that land a quick demo we go cool
okay fantastic
so I've deployed my swarm into the
calabash it using EE here just because
you don't watch me type I don't watch
but much time but the you know that the
process is effectively the same you know
with with EE you have you know we
develop API first so everything we're
doing here through the GUI we're a we'll
say we're able to do to the CLI as well
I'm actually using this example
application and posting links to all
this stuff at the end as well the
example application has multiple
containers expressed as a compose file
and a stack farm so docker compose is an
is a yeah Mel expression of all of your
containers and deploy together on your
on your development system so that you
can you know you can build and you can
actually get a full multi container
application stood up together and then
we also have what's called a stack file
which is very similar lots of shared
syntax but we're more concerned with the
actual deployment onto a swarm at this
point this gives us a few extra a few
extra settings we can work with so how
many replicas of each service we're
going to have or if we're performing an
update what is the parallelism of that
like am I going to do one replica at a
time 15 seconds apart and and you know
how do I handle failures etc these are
all things that we're able to handle
through this and then use the dock user
doctor client it's just the command
docker stack deploy and then passing as
file I've already done that here so here
in my people see this alright good
bigger
- probably business I love it okay so
I've got this voting up the point here
and you can see it's actually composed
of multiple services all running
together some of them I have multiple
replicas and they're being low balanced
and some are just single instances so
this was deployed using stacker pulley
command you can see here that we're
using a particular images at each for
each one of these are basically a
services one or more replicas of a
particular image and their associated
settings and here I have this voting app
okay so you can see here we've got this
voting out cats versus dogs so people
can vote for cats or dogs
anyone for cats or dogs
okay thank you no I'm going to take the
first answer take the first answer sorry
guys so that looks like it's working
right so the register cash is doing its
Java and cats win okay but and so that's
one version of my app I also have you
know I actually have deployed but not
logged in - yeah let's try this again
shall we I told you didn't want to see
me typing
Piaui
I believe my URL for my tiara
nevermind I'll have to come back into
that I have a registry and my registry
basically contains these images but I
don't have the URL up in the tab down
but basically when those are all been
built on my develop machine push to that
registry where they have been to the
security scan as well so you can
actually have a full report and whether
or not you know what your exposure to
risk is in terms of these components are
found inside their image they might have
certain tve etc and you can you can
browse all of that but really what we're
trying to do here is a in place upgrade
so we're using we're leveraging all the
load balancing here one thing is really
nice about deploying on on swarm on our
measure is that we actually do hooks
into the platform it's not just it's not
just a case of just having some
instances and then deploying docker as
normal we have some extra hooks in there
for example when I start my containers
and I'm publishing the service on a
particular port number in this case
5,000 I don't need to go into Azure and
open up port numbers on low balances or
elsewhere this is something which is
happening seamlessly as we do a
deployment really neat so my building up
let's just take the right hand so I
wanna do a you haven't said currently
using the tag before I'm going to switch
that out okay that's scroll under yeah
come on thank you so that's the char
hash that work for the to the image that
we're using I'm just going to refer to a
different tag and choose after I'm not
going to right-click let's do that one
more time
okay I'm going to commit that and save
that and that's kicking off that
background orchestration process if I
wanted to just modify my stack file to
refer to a different image or specific
tag or hash
I could I could redeploy using the CLI
in exactly the same way and thus it
would have the same effect a comparison
would be made against the current setup
and the desired one in it reconcile so I
do that for that for the voting and also
for this one so we have the two the two
different apps actually you written in
different languages this is all I got up
on github and it's performing this
running upgrade for me so in a few
moments that should be committed and
then we so basically what's happening
now is it's actually one by one
taking these containers down and then
restarting them in the other versions
that would be pulling to the others in
the background okay how we looking
coming up stop dating stop pulling
okay we should be in good shape so now
let me do a refresh on this back there
okay so this is our new version can do
votes between jar and done there okay
that's actually been complete use how
about guys good stuff okay and now a
little operate and I'll update in just a
second we just go to show you know weird
would be with the tooling with the
experience that you have
it's a refresher second ah it's a fix
it's a fix on behind the kern how you
get the idea we're now in a you state
okay well that's one old demo there's a
bunch of links here as well that will
make sure this is available but there's
a bunch of things that you might want to
see they're relevant to the other talks
as well from today one of them is i
really want to call out as well from
this list is image to docker this is
something that we've been working on for
a while it's it's open sources on github
go and check it out because what it does
effectively is innately or inspect your
existing virtual machine and then do
some dis inspection of that and unknown
workloads basically suggests a docker
file to recreate that and provide your
artifacts back to going right rerun that
so the one which is furthest ahead right
now is the dotnet one for windows so
that well actually it's a powershell
script it goes and looks at what roles
and features you have installed it
cetera looks at your is and on there
configuration and goes and gets your
artifacts and gives you back a folder
full of all of the things you need or a
suggestion to get you most of the way
there and then the new one we now have
as well on linux will do the same for
ibelieve tomcat today as well on linux
as well and there's links to sample
applications in more that's me thanks
hi everyone and my name's Russell
Seymour from chef I work on the partner
team at chef primarily focused at the
moment on working with Microsoft Azure
so thank you see the new vehicle and
liqueurs for the infrastructure so what
I'm going to talk about is Chef
compliance and I just have a quick show
of hands everyone hurdle you chef yeah
none of those people have you heard or
values compliance okay so that's what
waterful come what is chef compliance
well chef compliance is a policy driven
system the checks to see if your
machines are in or out of compliance the
policies are written in spec which is
based on service pack and this is an
open source tool that allows policies to
be run very easily and you can create
your own policies there are lots of
contributors to the policies we we
contribute the CIS which is a Center for
Internet Security they create policy
policies and what it allows you to do is
run policies that could be governmental
so so I'll bind oxygen America or PC
idea pti here you might have industry
policies so if you're in the retail you
need to make sure that your for example
credit cards that saved our thing is
securely encrypted you might have
internal company policies that for
example you're only going to support TLS
in your web server or but you make sure
that you're only supporting SSH version
2 and you could have design and
development policies that you have
within your architecture team and you
can do lots of other tests for example
you can see if your windows and linux
patches at the right level you can check
that your ssh as I said before it's
correctly right and configured and and
so there are lots of policies but you
can write your own now oops and what
I've got here as
the intro to the demo is to environments
now these environments have both been
set up using arm templates they could
have been set up using juju from mock
nickel suggested earlier but to get this
going
I've used arm templates now what we've
got in the chef automate is our chef
server which is our server that contains
all our cookbooks and recipes for
maintaining configuration management
we've got our compliance server which
holds all our policies that are going to
check against our modes and we have our
all to make server which gives us our
visibility and dashboard of what's
happening to our modes in that
environment that has been built by an
arm template that it's in github and
links I can give you later
and then the docker swarm environment
here has been generated there not again
off an arm template using the Gherkin
st. container services engine which is a
product you can download or a script you
can download from Microsoft github and
you can run on Linux and Windows and it
will generate your container system with
whatever Orchestrator you want I then
modified it so that our chef extension
which installs the chef client on each
machine was installed on each of those
machines and all the agents and the
agents are deployed in a scale set so
that you can wax and wane them depending
on your needs all machines in these both
environments are running a Bundy so I'm
quick prey to the demo gods to make sure
this is working and I've got a demo for
you and hopefully we are logged in yeah
okay so so this is chef automate and in
here you can see we have four nodes
running in this in this environment and
if I go to these nodes you can see that
they're checking in and every so often
now normally chef client will check into
the chef server see if any cookbooks are
to be run every half an hour but for
demo purposes I've made it so that the
No
checking in every three minutes okay now
what I've got these the run lists doing
on here
I'm run list adjust the list of recipes
that you want to run on that node for
your configuration and what I've got it
doing is running the compliance test for
the docker engine now this is using a
CIS benchmark which is the profile is on
github and I'll show you how this gets
pulled down now at the moment this this
node which is the swarm master has 25
critical issues and they range from the
content trust don't enable swarm mode
your certificates and all the control
files that docker needs now what you can
do here is these policies are open and
you can say right yeah I'm really happy
with that but I'm not too worried about
the trust for the content so I can tell
it to skip that policy I'm going to show
you that now but you can skip certain
things so what we're going to do now is
fix a couple of eating's using chef in
chef to remediate them and we're going
to say check that the that's where is it
there's the permissions for the set the
daemon JSON file ownership is set to
root and the daemon JSON file are set to
6 or 4 or more restrictive so to do that
I have my cookbook here and in true demo
style it is all commented so that I can
uncomment it and you don't have to watch
me type although I can't use your
keyboard anyway and yep
so better okay oops too much now so
we're setting this and we're now setting
that we've got a li the file we want to
create using template work that source
of that file is from within the template
of the cookbook and what mode and the
owners we want so we now need to upload
this to the chef server so I can use the
integrated terminal of the S code and if
we go into cookbooks
that looks what I need to do because
this is an update and ideally your flow
would be I need to make sure that I've
updated my resident role my version of
my cookbook and you would check that
into source control new go through a CR
CD pipeline and then it will go through
that but for and so we have to update
and to make it pick up many changes and
we're using self-signed certificates on
here which is what I've got
no what's wrong one
run command I need you on the next one
and so we have to tell that to update
and Matt goes through and it checks all
the dependencies for the cookbook good
dump them and we've seen that we've got
our new version of The Devil's club a 0
1 2 so then we do an upload alright and
this is where now one of the things we
do have to do is we need to make sure
that recipe is reading one on that box
now the recipe is controlled by this
base roll and so what we need to do is
just say ok fine what we do is we add
that in
and we upload the recipe about the role
sorry and we upload that now what will
happen it's because our servers are
checked to run every three minutes then
and hopefully we're going to find that
the nodes are due to run fairly soon so
we've got this one here this one ran two
minutes ago so in about a minute it's
going to run the policy now while that's
waiting to run and you might be asking
well why why is this useful as me as a
developer
well the inspect tooling can be run at
any stage you can run it on your
workstation while you developing to make
sure you're managing your policies and
that your rhenium policies the policies
can be pulled down from your central a
compliant server or from github and they
can also be part of your and CR C D
pipeline so that you're checking at
every stage if you're compliant with
your policies one thing I'm not showing
here is how you would check your
compliance for your containers now this
is because we're testing the
infrastructure and if cest client was
running on each node it wouldn't know
what contain that it would find a
container but wouldn't know what rules
to run against that complain because
there's nothing linking that C so what
you would do is you would put that in
part of your pipeline and then you would
say okay fine thank you and I will check
my build of my container that we're
going to your registry and then you know
that's already compliant and then you
just run it so that's that
so I'm crunch very conscious of time
here so this one has run and what we
should find is that you saw we had 24
problems or 25 problems if I go into
compliance now we have 36 so it's made
it worse
okay I'm not quite what I was hoping and
it might be to do with the way that I
set the file up or whatever but you can
see it maybe change in the wrong
direction so I apologize for that but
the the idea is that you can build up
your recipes
and you can remediate these things and
have them as a central system in your
cookbook control so in that point come
on come on parcel not part of haplin and
so in summary all the docker swarm
agents are managed in chef you go Peter
Lee scan the servers for compliance they
run on every every the Alliance runs
every time chef client runs and you can
report on non-compliance which means
that you could maybe report into docker
swarm from some self-healing or whatever
needs to happen there there's some link
to be there I can publish them later or
beyond the the Microsoft stand today if
you have any questions at all thank you
so we got the song here thank you so we
got one minute left
we were hoping for Q&amp;amp;A but I think what
would probably do actually is ask people
to just come down from Microsoft stand
all the guys will be down there to be
able to answer any of your questions
this was a kind of like a punt for us
really in terms of would we be able to
fit this many demos into this amount of
time I think it went better to be well
and bearing in mind that we were running
on a 4G connection as well because the
Wi-Fi wasn't that great I think we did
all right so thank you very much
everyone for coming along and then
please do come down we've got loads of
swag on the Microsoft stand as well
t-shirts squeezy penguins depends if you
want with it as well so come down have a
chat to us
Gorillaz if you want to as well and we
look forward to talking to you later
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>