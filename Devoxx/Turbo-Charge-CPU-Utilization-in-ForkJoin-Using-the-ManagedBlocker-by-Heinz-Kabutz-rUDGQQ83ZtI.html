<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Turbo Charge CPU Utilization in Fork/Join Using the ManagedBlocker by Heinz Kabutz | Coder Coacher - Coaching Coders</title><meta content="Turbo Charge CPU Utilization in Fork/Join Using the ManagedBlocker by Heinz Kabutz - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Turbo Charge CPU Utilization in Fork/Join Using the ManagedBlocker by Heinz Kabutz</b></h2><h5 class="post__date">2017-03-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rUDGQQ83ZtI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">next up is science is good to talk a
little bit about term parallelization
and explain it's cool of course of
course not
so thanks very much for coming I have
spoken at lots of different conferences
but I've never been as intimidated as
this place especially after Derek's
introduction this morning I mean you
guys invented the internet all right I
mean after that what am I gonna say all
right so we're gonna look at how to
improve CPU utilization using fork/join
and also the manage blocker and this is
what the CPUs look like come out of the
machine here before I use the manage
blocker and after user manage blocker it
looked like this now there's some
differences first of all at the
beginning the the real cause it's a four
core machine with hyper-threading so
it's for real cause the four cores and
it has a fair amount of black at the
beginning of the run right so it's not
fully utilized in CPU and once a few is
the manage blocker the black goes mostly
away so it's mostly green at the
beginning and this gives you a about an
eight percent improvement in the
performance of this particular
calculation and what I'm going to do
today is to show you how to do this no
there's a lot of coding that I'm going
to be doing and I tend to make mistakes
when I do coding in front of live
audience and also without live audience
but then they don't know about that so I
get away with the different of these
watching so please pay attention and if
you see me make a mistake please help me
to correct it because otherwise the
experiments not going to work at all and
what I'm also going to do after each
step I'm going to commit the change so
that you can at the end of the of the
talk look at all of the changes and go
through it again because we will go
through this quite quickly it's not that
much time to code all the stuff we're
going to look at a very famous from
number series by Leonardo of Pisa called
Fibonacci the most commonly and it works
like
if naught is naught if F 1 is 1 and if
of illness the two previous numbers
added together and so the next number is
always a previous numbers and the
numbers get large very quickly as you
can see in Australia when they had this
big problem with the rabbits breeding
uncontrollably now if you take an even
fermentation if if norton's naught if 1
is 1 and then so if an in is less or
equal to 1 we return in otherwise you
return FN minus 1 plus FN minus 2 it's a
very bad algorithm all right it's
basically the complexity is in itself a
Fibonacci series so it gets slow and
creatively quickly and I try to do an
estimate of how long would it take to
work after Archie 1000 and sort of the
closest I could get to us not 14 billion
years but came to the path 200 years all
right that's a spinachy-- 1000 with this
algorithm so basically it's intractable
you can't actually solve it and
interestingly you will find this
algorithm exactly like this in the JDK
and you'll find it written just like
this in a performance book that I won't
name Java formitz book it's not cool
drug for suing it's not so and we could
use iteration which goes like this in
order to in work out the next value
based only on the previous two values
and with this you could work out for
issue 1 billion in a much shorter time
but the number of a flaw is pretty
quickly run about 4 not she's 70 or so
so ever flown and so even though the
complexity is is good you'd have to use
big integer and beginners the add is
also linear in up with quadratic
complexity and so if you actually one
billion will take again a very very long
time to solve so the third one is a
slightly better approach where we are
first of all improving the algorithm to
use a more intelligent algorithm and in
this case we're using dates for sum of
squares and it's got logarithmic time
complexity so that's of course much
better and the multiply in Java AIDS has
also improved a lot from previous
versions in previous versions multiplier
was quadratic
whereas now it's got either into the
power of one point five eight five or
into five 1.46 five which makes a huge
difference we see the graphs you'll see
that it's much much faster and the
numbers that we only care about are the
big numbers and so the only one that we
really care about is the tomb cook
optimizer to concoct calculation at the
moment it's still single-threaded but we
will make it multi-threaded and do it
parallel as well so this is the first
experiment we're going to take the
algorithm it as it stands at the moment
which is the very old the very basic
implementation and we had to rewrite it
using takes a sum of squares so it's
basically if innocent odd number then
it's the half of N squared plus n minus
one half of in ones ones minus one
squared and if it's even it's this other
calculation so let's do this quickly
let's go to IntelliJ which I also use
using for a long time and it's a
Fibonacci this is the old code and now
I'm gonna say the half of in is going to
be n plus one there are about two and
then we're gonna say big integer if not
equals F of 1/2 minus 1 and F of 1 will
be 1/2 and then we're going to say if in
percentage 2 is 1 I know you could use
bit masking but it's actually exactly
the same code because it's power of 2 so
it doesn't matter we're gonna say return
if I've not multiplied if of not that
say fulfilled not swayed there is
actually a slave function inside begins
it about its private so we can't call it
from outside you will see that in a
moment and then we say dot add F of 1
that multiplied of F of 1 m else we're
going to say return F of note we want to
multiply about two this time we will use
a bit shift by one dot add of F of 1 and
multiply that with F of 1 and that
should give us the correct answer have
done this correctly witches
unlikely but we'll try it anyway so
let's run this and I'm not using CMS I'm
using parallel GC sorry I know it was a
stupid joke so it's running for a while
and we want to get some figures as to
how long it takes to calculate this this
number and I'm working out Fibonacci 100
million so it's a it's a sizable number
it's like in the tens of megabytes of
one single number and once we finish
that we're going to see if we can make
it run faster so it's happily chugging
along and and and and and and and and
and soon soon to be finished hopefully
44 seconds forty three point nine four
five seconds safe forty four seconds and
this is a CPU graph and you can see that
we actually were running basically
single threaded I'm not completely
single threader because sometimes the GC
was running and the GC is running on all
eight cores but besides the GC is
running single threaded so um what we
can do before do anything let me just
quickly commit that so we can get a one
now I'll keep on doing this and then you
can see the whole history of what I've
coded now and what we've done is we've
included this algorithm and we could
actually solve very large numbers so it
took a while and we didn't use all the
available CPU but we could work out big
numbers
let's take demo 2 we're going to
paralyze the algorithm itself and we do
this with a very useful framework called
fork/join gives us recursive
decomposition or divide and conquer and
what i'm doing here is i'm constructing
a recursive toss which is a wrapper for
the code that must be run in parallel
and then i'm forking that and after that
i'm i'm working out if a half and after
that i'm joining the first calculation
again so i'm just basically doing them
in parallel or potentially in parallel
they don't need to Sony have to run in
parallel but potentially they can run in
parallel let's try that out
MC here we're going to say we're going
to make a recursive task of if not so
it's going to be a fork/join task
returning a big integer so it's going to
be if not task equals a new recursive
task and all we do is we take the code
that's down here then we're going to
copy and paste it into them we then say
if not task dot fork I often forget that
and hit it doesn't work and after we've
worked out F of 1 we can then say if of
if one so if not task dot join so this
way we can use all eight cores to work
out the number now before we did it in
44 seconds I've got four real Hardware
calls on him how fast do you think I can
calculate it none from 44 down to a bit
on a guess 130 you're a pessimist
I guess I'm overhead right do I run
number of cores per smile heap so any
guesses 12 13 okay we got the optimist
12 down to the pessimist 30 let's try it
out and run it and we get it to this
time from the beginning look at what the
CPU is doing and you can see that CPU is
much more business today we are using
all the CPUs this is much better yeah oh
not anymore
hmm so we start off great we start off
with the optimist and we end up with the
pessimist right and the real answer is
somewhere in between the pessimist of
the pessimist and optimist yeah so we
can see that we actually ran it in 22
seconds so the first one was 44 seconds
22 seconds it's actually normally a bit
worse than twice as fast so it's it's
it's sort of closer to your your answer
normally then then you
and he can see that in the beginning
it's really busy and then it's the CPUs
slow down they become less active
alright so and if you do a profile on
that you'll see that the reason why is
because once we start calculating we we
start having to multiply very large
numbers and the multiplier is single
threaded so the final few that the final
few numbers are going to only use a very
few number of cores and here that's why
we're not getting the the full-time
speed-up that we were hoping to get all
right so before we do anything we
quickly come etherion demo2 and and now
but besides that but by the way if you
want ask questions you can at any time
ask questions so please don't just
really did mislead to stop you and what
i'm going to do is really just comment
on some of the taste because i don't
want to get distracted by any of them
anyone a cave artist tastes 100 million
and the other ones don't matter so let's
go and and do something else which is we
can go and what I've done is I've got
another version of the big integer I
just basically copied and pasted the
whole math package into my own package
and I'm going to paralyze this as well
it's a way to basically take fork/join
and stick it in there
it's a different license actually that's
why it's in two different modules this
one is is the normal new license so and
what we're looking for a scape tomb cook
and multiplier tomb cook and within
square tomb cook what they do is they're
take the number they're break it up into
five equal chunks then there is some
maths wizardry which I don't understand
and then the name they they join it
together and they have the number square
and so what we need to do is we're going
to basically fork this one and then join
it over there so in other words fork
fork the first square do some
calculations and then join after we
finished with the second square and then
we're gonna fork this one and to do the
other calculations and then join again I
wouldn't want to have too many Forks
happening at the same time so that's why
I'm forking and then I'm joining in
before do the next fork otherwise you
can have a very large number of threads
being constructed within the fork to run
for right now to do this I need a
recursive task and I'm gonna later this
time be a bit more studious I'm going to
construct a private static class square
square task M extends recursive tasks of
big integer and in the compute function
I'm going to I'm going to I love to pass
in private final static no final big
integer a that's what we are squaring
return a dot square but as I told you
this way is a private function that you
can find within being integer so this is
my square task I'm going to have a very
similar tasks for multiply multiply a
task except it's going to be a and B and
again we're going to have a constructor
with a and B and we're going to set a
dot multiplied with B all right so these
are my square tasks and multiply task
and inside my square function squeak I
mean how many dings great too because
that's for the very large numbers and
that's what I really care about I don't
care about small numbers and now over
here where I said Fork I'm going to say
my square task V naught task equals nu
square task a naught and then we're
going to say V naught task dot fork and
later on we are said join I'm going to
join that back against whether it's me
be here V naught task dot try
it's important that you always fork and
then join of course and often forget
that that's why I keep on reminding
myself Square task v1 task equals nu
square task of the summit's da one have
no idea what those things mean I don't
understand this algorithm but a tiny tip
because I'm just paralyzing it and then
again v1 task fork and later on I'm
going to join that again it's going to
be v1 task dot join okay so this is the
this is a square done and that's all I
need to do to paralyse the square
calculation that's pretty neat we're
going to do the same for multiplier to
cook consult apply to cook so here again
got five different slices the multiplier
so we're going to say multiply task V
naught task equals B multiplied task of
a naught comma B naught and V naught
task dot folk to make sure that that's
also formed and then after I've done the
other multiply which is over here and I
let it do some more calculations then I
drew the joint hopefully it's going to
be done by then that should be done with
it so that's going to be V naught equals
V naught task dot join okay now we're
gonna do the same thing for V 1 produced
do a copy and paste here so V 1 task is
da 1 and DB 1 again don't forget to fork
otherwise it's not going to work and
then I'm going to actually do two
multipliers and then I'm going to do V 1
task dot try know if I did that
correctly which is extremely unlikely
then it's going to run faster maybe
perhaps but of course you won't agree
with that one
maybe it'll run faster if I did it
correctly if it runs at all okay so the
test pass which is a good sign and we
can see that our CPU is also more
engaged well not actually because I
didn't use that my doctored big integer
I use Java math big integer so this is
one thing what you need to still do I
need to go back and change it to use my
own version of big integer so let's do
that let's go back not here go to
Fibonacci and here we've got Java
mathematical automation state use import
class the EU Java specialists
performance math big integer which is
the one which is paralyzed okay so let's
try that again
we're healthy now we'll see that the CPU
is keep engaged until the end ok so
that's 32 say but it does look promising
that the CPUs are not fully utilized so
that's that's great so is we are we on
the right track we now at 17 seconds we
were at we started at 44 seconds we got
down to 22 seconds now we're at 17
seconds so that's we on the right track
and the next step is to have a look
quickly before we go into the next demo
way we are wasting our time on these
calculations and that will give us a
hint as to where as to what we can look
at next
so let's go to Fibonacci game and what
I'll do is just around here I'm going to
just do a time I need to be careful
cause I can't system tom has some
current time it is a very expensive call
II okay I'll do that I don't really want
to because I wanted to okay I'll do demo
three and I'll do another commit for the
time and information Thanks
so time equals now
at a concours current time it is every
single time because it's the rectum it's
of cool I'm only going to do it if in is
bigger than a thousand if it's bigger
than a thousand I'm going to use system
current time minis otherwise I'll just
use naught okay
and then we'll say here try finally and
in the finally I'm gonna say time equals
and again in it's bigger than a thousand
we take system current term minis
otherwise just use not - time otherwise
just use naught and then if time is
bigger than let's say 20 milliseconds
I'm going to print out if off in equals
and the time obviously not the real
number because it'll take too long but
this will show us where we've got where
we spending our time okay you might have
already picked up something here for
looking at the numbers flying past
anybody's spot anything with the numbers
this is true that this is a very good
observation that one of them is longer
than the other one and remember that
we've got two different calculations but
there's something else that you might
observe here
yes exactly
we're doing the same work over and over
again alright so this is another good
observation you can see here this takes
three hundred and forty milliseconds but
you're doing like one two three four
times so yeah we're very busy but we're
busy doing the same thing over and over
again so that's kind of silly right the
the even and odd is another very
interesting observation which you can
see right at the end quite well quite
strongly in fact it's the opposite to
what you said the odd ones are faster
than the even ones right and the the
reason that they're supposed to be found
the hint Vecchia right but nobody wrong
the reason is that squares the square
algorithm is faster than the multiplier
algorithm so it should be faster on e on
odd numbers and even numbers but okay
anyway we got down to we we had 17
seconds before that's no different
mm and what we want to do next I'm gonna
just commit this demo three with timing
next we want to to try and address that
particular problem
all right so skip there were some things
here by the way I'll show you this link
again late if you want get lots of spam
subscribe to a newsletter you'll get one
email a month from me and also I'll send
you if you want information about these
this source code here so we did this
part cache result so that's the third
that's the fourth thing we want to do is
to cache the results and and the idea is
that we we don't work out the numbers
over and over again we rather just have
a cache maybe put the value so we don't
have to do the work over and over but we
also to be careful of a memory leak so
we don't want to have a static mesh it's
a static cache so we're going to
construct the cache fill it with data
and then throw it away at the end of the
run
let's try to that so we go back to our
code and I'm greater than a second
method and this myth is going to be I'm
gonna pass on a map from integer to big
integer cache and here we're gonna we're
going to set up the cache map from
integer to big integer cache equals new
will have to use concurrent hash but
because we've got multiple threads using
the map at the same time how many of you
have heard of the new method and Java 8
called computer absent very good at five
how many of you have used or are using
computer absent you might want to change
your code
and you know why that he knows why he
that told me about the very interesting
it's it's got two problems two big
problems one is a infinite loop possibly
and the other one is contention very bad
contention so keep your eyes open for
the cash not put naught comma begin to
zero and begin to the one and then we're
going to say return f of income a cash
I'm going to cheat a bit because I'm but
stupid and I can't find all the right
places in the code so I want to find all
the FS that that will called F before
and I'm gonna put in the cash so I'm
just kind of like change the name and
that shows me down here way I forgot to
put in the cash right so that's Frances
easy cheating way of finding out way to
put the right numbers and then I can put
it back to F so I am now I'm using the
cash of course I'm creating so I'm just
using a debt I'll use it not a second in
here I'm going to say where do the
actual a remedy that we know okay so we
don't need this anymore because it'll
never be I can say I can say big integer
results equals cash get off in and if
results is no then I can calculate it I
can say results equals and results
equals and at the end of this this block
here I can say I need to say cash put in
comma the results are put it in and then
I'm going to say return the result so
now we're not going to work it out over
and over again we're just going to work
out at once and off that get it from the
cash
ah very good observation thank you well
that's the next step yeah we might see
some improvement but you're absolutely
right
we're not going to see a full
improvement because we still will will
have sometimes work not the same number
not as much and we've gone down to sort
of almost 12 seconds I understand were
12 seconds so it has had some benefit
but you're absolutely right we still are
doing it sometimes and we're still doing
here for example what's the 25 million
twice and two for none and twice and so
on so they are it's happening still that
we're doing most multiple times but not
as much and we did actually bring the
time done so this is again another
opportunity to commit that that's dimmer
four and next one is to what we going to
do is we I made to put a spatial value
into the map and the spatial value is
going to say that I'm busy working on it
so instead of sort of instead of just
you know have anybody work at the same
thing whoever gets there first is the
one is going to do the calculation and
everything else is going to wait until
the first one is finished and I call
this the reserve caching scheme it was a
it's a funny name it's an elaborate
practical joke that I started a long
time ago never mind the name does
actually make sense I think when you see
what I'm going to code here okay so next
step is to what we're going to do is
we're going to make a reserved object so
it's going to be private final big
integer reserved equals new bigot and I
always get this wrong big integer value
of minus a thousand so I have one
instance for each Fibonacci object and
then when I when I run this code I'm
going to instead of saying get away to
use another method called put if absent
in comma
like that okay
income reserved so if result is now then
we were the first so the you would get
back what was there and if if you were
the first to put it in then you're going
to get back now that's what put of
absent does and otherwise we're going to
it can it grow so B if results is equal
to reserved that's another option and
and if it's equal to reserved I'm going
to say return that we're going to now
wait until it's done so we're going to
say over here synchronized reserved
while results equals cash get in is not
equal to reserved I'm going to say
reserved dot weight which going to
suspend the thread and wait until it's
done and if this causes an exceptionally
to throw a new cancellation exception
interrupted like that
now also need to to notify so I'm going
to do that wrapped around here I'm gonna
say that's right synchronize reserved
and I'm gonna put it in in the NSA
Reserve dot notify or anybody who waits
gets woken up now this not going to be a
lot of contention on this object is easy
they're not that many cases where we're
going to have contention we just want to
prevent having multiple multiple threads
running on this at the same time working
on the same number at the same time so
if you run this again it doesn't work
which is interesting ha you guys are
amazing thank you by the way if you if
you want to speak was basically press
the button so we can also record your
your comments thanks for that help
and now we can see that it runs
correctly and should waste my task
manager from the task manager again but
it is I've got it was open this again so
I can see it CPU okay so so Mario is
asking the question of what happens
somes repeating because of micro Roslyn
what happens if I've got two threads
which are both waiting for different
numbers and it can happen but it's not a
highly contentious problem so they're so
they'll both wake up and one will say oh
no it's still not equal to the number
and I'll just go back to sleep so it's
it's it's not a correctness problem and
it's you're also not going to get a big
performance improvement by fixing that
so you can if you can address it you
can't change it but it's not gonna
really pay you to change it okay it's a
really good question thanks and for the
same reason you could also say that if
you could have lots of different
reserved objects you could say anything
which is negative as a reserved object
and I've tried that out to see whether
it makes an impact then it really
doesn't because that's not a bottleneck
do the question let's try that out so we
know so what we've done is we've done a
whole bunch of different tests and
different provements and the question is
which one is actually making the big
difference here because we are down to
oh wow that's a good that's good number
under nine seconds right so we've gotten
down to under nine seconds which is
phenomenally good
mm yeah we wasting less CPU cycles right
so it's under nine seconds now I will
answer your question in a moment but our
first one and run this again so we can
see the CPU usage and you can see that
at the beginning there's still a time
not very much but there is a time at the
beginning where there's some black when
it's ramping up at the beginning of the
algorithm a going to be in more cases
where you're going to be waiting for
others and then once once you once a
numbers get bigger then it's more going
to be a case of the the big integer
parallelization is going to start keying
in and helping you so remember we are at
nine seconds in fact it's now just under
nine seconds eight point eight seconds
which is very good and the last step
which we'll do after I've done a demo
for you is to try and address this loss
of a bit of black which in this graph is
not that much but in the graph I showed
you at the beginning of the of the talk
was a bigger number Nate was more
significant than we actually got an
eight percent improvement in performance
no and before do anything I'm going to
do a quick commit this was demo five and
then we're going to go back and change
it to the the standard big integer so
let's comment out the math and we'll use
the Java math begin to jam and we'll run
this again and I've got no idea what the
output will be but I have a suspicion of
what we'll see
so you can see that it's basically
running single threaded
it's not much CPU going on here oh it's
still faster because we're not doing the
same number twice but this we're not
utilized into the available hardware so
so it's like all these steps together
that give you the the final results
where we are getting a performance
improvement okay so you can see in the
graph here that that at the beginning it
was still okay because we did we were
doing the fork/join and that was making
a difference but towards the end the the
real difference comes from paralyzing
the big integer okay let me just undo
that change alright and now comes the
last one and the last one is a very it's
a little thing that was added in Java 7
which not many people have realized
though realized when they put it in
there's a class called phaser in Java 7
who's head of the class phaser
it's like count on latch or you've
probably written it but phaser right now
phaser it's it's a replacement for count
on latch and and what's other one like
count on that we have threads
coming regularly doing something not the
semaphore another one like that I've
never I never use it so that's why I
called over the name anyway
so phaser is the only class in Java
which which is actually compatible with
the fork/join you see when you really
start a fork to when you start a fork to
an job it actually runs with with as
many threads as you've got hardware is
your system by default and if you have
one thread which gets blocked up because
it's waiting for something like what
we're doing now then then then in the
meantime we've got we've got lace
threads which are working in the system
actively doing something now what the
man is blocked
is it tries to keep the the fork/join
pool at the desired parallelism when you
construct the romper you specify
how many threads you want to be running
at the same time you don't specify the
maximum number of threads you can't your
any space for how many threads you want
to have active at once you desired
parallelism and so what the managed
blocker does is it automatically starts
new threads as you need them and what we
will do is we'll run this again with the
Sun we'll do a straight up and we'll see
that there will be some threads which
are which are blocked up whilst we're
doing our test and then we'll run it
with with managed blocker and you'll see
that new threads are constructed to take
the work of to keep the the parallelism
high so let's run this test once more
and the Sun will do a thread downpours
for doing it
in fact I'll do a few three times so
it's got this lovely camera icon click
another three dump I've got to be quick
now because it's so fast
alright so I've got a few three dumps
let's put this into a an editor surprise
I didn't mention VI on you and your
slides okay and what we're looking for
now is workers and here's a worker for
example and the common pool worker
actually the main three it's also going
to be a worker doing work and you can
see here now this runnable there's also
here this object way through I'd say
they've got three eight five is waiting
thread three is writing to and one is
waiting so they're all waiting and
you've got eight threads including the
main thread but the worker thread some
of them actually doing work or the one
or other ones are just waiting towards
the end I don't think it's such a
problem like the last one the last
thread Dam you've got Randall runnable
runnable runnable run of a run of
so this is a problem in this algorithm
at the beginning of organ waste some are
waiting for other results to be
completed before they can continue
towards end you're doing just number
crunching and it's over and so what I
want to do is to address that you get to
squeeze the last bit of performance out
is to is to solve this problem so the
way that you do it is you construct a
class called a managed blocker so this
is our private class called this court
of the reserved blocker reserved blocker
extends implements sorry the managed
blocker and I'll say the only one any
class that actually does that at the
moment this phaser the word talks are
fusing of also making the abstract cued
synchronizer implement managed blocker
but they never did that
what I did in one of my newsletters I
made the reentrant clock implement
managed blocker and then I hacked
there's those modified reentrant locks
into into blocking into area blocked and
humic blocking queue and that way they
also became compatible with with the
fork toe and framework so here I'm going
to implement two methods it's the block
method and is releasable now in the code
down here we are waiting I've got three
components and to this to this code the
first component is the condition
predicate the condition predicate tells
me how long I need to wait before I can
exit from this loop the second component
is the actual lock that I'm locking on
and the third component is the condition
Q now because I'm using synchronized
condition Q and the lock are the same
thing but the condition predicate is
something separate and this over here is
basically your production predicate so
I'm going to take this I'm going to copy
that into my condition predicate which
is that is a method called is releasable
so I'll make a comment here this is
basically your condition predicate and
we're going to say return that it's not
equal to reserved
so we want to return whether or not we
need to block so if it returns true we
don't need to block it's releasable if
it's not true we need to block and wait
until until it's it's available now I
need to create fields for this so result
I need a field full and that's going to
be a big integer result before doing it
yeah okay let's just check them using
the right big integer and then cash I
need a field map integer comma big
integer and then in the need of field as
well and that's gonna be an int and
we'll mark these final these two and
insert a constructor for those two and
sonar pod a reserve blocker that takes
an inn and a cache and it returns we're
going to use we're going to make two to
return resolve later on so our make this
volatile I'm not sure another thing I
need it but there's no big harm and
doing it in this case is releasable it's
finished predicates and then blockers
going to be very similar to the code
that I've got down here and it's going
to basically say while not is releasable
reserved dot wait and then return true
means I did gate I did do what I wanted
to do and we can exit from here now all
right we need to return true otherwise
you'll keep on then thing it's going to
to return from the from the block okay
any questions so far
they must be blocking because they're
both collapsing on the same number too
often you do you see parts and see you
graph
playing is to white you add the tracer
jumping around so they are accumulating
information but you're not the same
things with fine morality enough so you
I expect your calculations actually on
the order three maybe okay can you just
repeat what the question was because I
missed it from the beginning right so so
so we actually saw you could measure
like the whole run and see how many
threads are running or waiting at one
point we did see at the beginning that
there were like three or four which were
waiting but don't forget that I've got
eight threads running and I've only got
four real cores running on four hard
weeks for hard recalls so so having four
waiting is not not a train smash but the
problem gets an S that's the number that
we calculated it's bigger you've got
before a higher number of threads in
proportion to the available hardware
that are waiting at the beginning then a
we do have time for questions so please
if I don't answer that
okay so let's continue with the code
this is this is probably do reserve
blocker m and I would apply it in here
we have got the synchronize reserved I
would take this out doesn't take too
much out and I would say mana
reserve blocker equals new reserve
blocker passing in the parameters in and
the cache and they not say fork/join
full dot managed block the blocker
thus await until it's finished before
returning and then I'm going to say
results equals blocker dot I get the
result from there
it's last step but often forgets and
then it doesn't work but this list
should not work correctly so now the
manage blocker the Manish block will
sometimes create more threats to keep
the parallelism at the same level
let's run the suit now and with this
small number you don't actually see such
a big done done done oh right I have
some way waited without synchronizing
them again to synchronize aim preserved
let's try that again
and we'll have a look at the CPUs in a
moment at the threads what the CPC
presiding it is it was a little bit
faster you see that was an eight point
five seconds not a lot mm and the reason
is the the part which we were trying to
save we we need to look at the real
cause here it's this one this one this
one in this one so the zero two four and
six the ones in between that's your
hyper threaded we don't really care too
much about this if there is one hundred
percent or not it's not so important but
these ones you can see that they are
pretty much at the top all along so so
that little bit that we saved here with
this with this big calculation does work
out to much bigger percentage of course
when you have a bigger number and we we
actually also did run a bit bit faster
it wasn't a huge difference but it does
make a small difference of course the
biggest difference we had was from the
algorithm change and we always have that
with all our systems that the biggest
winners that now let me quickly and
commit that they still get some trouble
let's do this this is in the present
branch so that you get thing and let's
go back to the presentation so I want to
show one more thing before I put up the
final expression slide and that is I
want to do some three dumps while
running this this new code so one two
three four yes I've got four three dumps
that should be enough and if I now open
these grab the output and our search for
worker thread you'll see that all of a
sudden got a worker a 14 and the first
bit so I've got worker 14 who's runnable
and I've got a few workers which are
which are waiting and worker 14 is still
around still around and so it's it will
try and have seven workers plus the main
thread that do the actual calculations
if you're on the few times you'll find
more workers or less workers but they
are all of a sudden new threads which
are arriving to keep the parallelism at
the same level within the forked
rainfall so I've had a whole bunch of
questions during the talk we've come to
the end I am or any further questions
and this is the link if you want to get
the source code for the project and also
subscribe to a newsletter and if you
want other stuff it's all they lots of
spam every day in your email once a
month actually any questions please put
the microphone on so we can record it
it's a button that you press
right wait you mean you mean like future
tasks so that we don't use knives on the
pool no that you are waiting on tasks of
the pool on it can so so they they're a
bunch of different ways you can do it
the you could the the thing is that if
you I haven't really thought about doing
the four point into the map like that I
don't think that's going to help you
because I've redone the fork turn before
I get there and what I'm trying to avoid
is to avoid having duplicate work being
done that's what I'm trying to avoid
here so what one could experiment and
see if that's going to help or not but
that's not the bottleneck so we mean
when we you know the the next big change
is to you can improve the algorithm and
then that's going to help you more than
then do that at that level algorithm
improvements always hop more then
paralyzation you know hard way is one
only one way to solve a problem
cleaver brains helps more which one for
the neck for example when you select
surreal lights and then you have this
context menu to wrap oh yeah I right so
so IntelliJ I'm actually to do a course
on IntelliJ basically there's like some
some shortcuts you can press to to
select more more code it's the thing I
would probably use the most is a fun
little thing here called the
productivity guide help
and that shows you what you've done the
most right we've actually spent the most
retirement and this this one thing where
I'm selecting code I do
incredible amount of times use number of
times like subjects away selection are
fused like sixty thousand times it's
really often so if you just know that
and in a smart auto-completion smart too
smart type completion actually basic
code completion if you know those things
you don't have to really code anymore
just eight the ID do the work for you so
um again thanks very much for having me
and listening to me so well and thanks
for participation the great great
questions enjoy the rest of the
conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>