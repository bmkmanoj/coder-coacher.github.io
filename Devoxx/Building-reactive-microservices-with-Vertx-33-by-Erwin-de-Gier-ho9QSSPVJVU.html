<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building reactive microservices with Vert.x 3.3 by Erwin de Gier | Coder Coacher - Coaching Coders</title><meta content="Building reactive microservices with Vert.x 3.3 by Erwin de Gier - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building reactive microservices with Vert.x 3.3 by Erwin de Gier</b></h2><h5 class="post__date">2017-04-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ho9QSSPVJVU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay let's start my name is Aaron de
kere I'm from Amsterdam
I work in Sochi Netherlands as a
developer and one of the things that I
like working with the most and I also
like my my free time is open source
project called vertex and before we
start I think I need to know how far you
are with vertex so does anyone know
vertex I've worked with it uses it in a
project ok now we know the level of
detail to go into so first of all if you
go to the website it says something
vertex is a toolkit for developing
reactive applications on the JVM and
what do you mean by this is that it is a
complete environment for building
lightweight
reactive applications so you can use it
together with Java Enterprise or with
Spring Framework but the intention is
that you use it separately separately
from other big frameworks that dictate
how your architecture looks so basically
if you build a vertex application you're
building a runnable jar with all the
dependencies in it and one of the
driving forces behind the development of
the vertex vertex project was the
reactive manifesto so do you how many of
you know the reactive manifesto - okay
so let's go over it if you go to the
reactive manifesto website reactive
manifesto dot walls they say that
directive manifesto is an answer to the
requirements we see for our software so
requirements around a lot of data you
always want to be able to access their
information distributed systems and they
say basically there are four traits that
you need to have in your application in
your architecture to be able to call it
a reactive system
those are elasticity so it has to be
elastic so you should be able to scale
up and down modules in your system it
has to be responsive so you should
always get feedback even if there are
failures so it should also be resilient
so if certain modules fail you should
still be able to use part of the
application and it should be message
driven so asynchronous messages are used
for communication so if you look into
our vertex is built and how you build
applications with vertex then you
recognize all these traits another
interesting thing about vertex is that
it uses multiple languages so they have
an API to use the utilities inside
vertex and they basically start with a
Java implementation and based on the
Java implementation they generate ap is
for other languages so you can use a
groovy Ruby Java Script
Ceylon scarlet Oakland and this makes it
really versatile if you have a
development environment and people are
not a Java person by default or they
want to use another language to develop
their functionality and finally the last
one is distributed and I will go into
detail a little bit more with that one
so the intention is to use it separately
as a complete solution for your
application and it also means that the
technology stack includes all kinds of
functionality so you can build rest
services there are adapters to use
different data sources like MongoDB or
Redis but also legacy JDBC drivers there
is also a lot of integration stuff a lot
of protocol supported their solution for
metrics actually they use the dropper
widget metrics and their integrations
with stuff like zookeeper hazel caste
and Google meters and what I also like
is if you think about asynchronous
applications they should always be
asynchronous front to back so from the
click in the browser all the way to your
data store or your file system
everything should be
- so within the 30x project you will
find a synchronous GBC drivers that
means you can fire a query do something
else in the meantime
and when the research comes back its
processed so your threat doesn't block
on the query but it's free to do other
stuff same goes for MongoDB but that
already has a asynchronous kappa dr ER
but also for calling or the web services
for writing files to the file system
everything is asynchronous so this model
of asynchronous behavior it's
photoreactive pattern and also the same
which is implemented in node.js so if
you know nodejs actually there is one
thread processing or your application
logic and for what that one thread your
application is optimized to when there's
any long-running work the threat is not
blocked but it's either running on a
separate thread or it's an external
system doing its processing and you use
callbacks to further process your
information so although application
logic you write is asynchronous and this
is an optimization with vertex you can
use your processing power efficiently
and because of the asynchronous model of
course when you start developing your
software you always run into cases where
you cannot do asynchronous processing so
there's also utilities for using
separate threads for instance everything
in vertex that does something is called
a vertical so if you have maybe a small
rest service you'll write paper the code
that implements this functionality and
if you need to do any stuff on another
thread its go to work a vertical so
maybe you have to call a legacy database
and with a legacy JDBC driver and this
is synchronous communication you can
upload it to a separate trip there's a
also more interesting stuff like
automatically the amount of instances of
each vertical is scaled to the amount of
creds available so if you have a eight
core CPU you get eight instances of your
vertical automatically so that's the
asynchronous model
another unique trait I think is in the
distributed nature of vertex basically
if you deploy your verticals in the
communicate between verticals you use
messages and by default these are Jason
messages over TCP B and the mechanism
that you use to send the messages is
called an event bus and if you deploy in
one JVM it's just an in-memory thing so
you your send your messages
in memory but if you deploy on multiple
JVMs it automatically creates a network
cluster of notes and the a the event
this becomes distributed so if you have
an ideal network where multicast is
allowed so say for instance your laptop
is on the same network as my laptop I
will new vertical here you run a
different vertical the same vertical
they will automatically find each other
using multicast join which is a Hazel
cross function and we are able to send
messages so without any configuration if
your network allows for it you already
get this distributed nature and you are
able to send messages you can even
extend the event bus to the browser so
you can connect to JavaScript clients
and you can do push push to the browser
and it uses WebSockets or reduce a
fallback method if you browser doesn't
support red circles so this is the basic
functionality of vertex so bubbly
clothes reactive and distribution and if
you look further down on the website it
says vertex is ideally for creating
lightweight web services or micro
services and this was interesting
because last year end of last year in
the folder was a vertex core developer
day in Amsterdam and all the
contributors and the core developers of
vertex code together two days at a red
head office and they invited some users
and people from the community so they
invited me as well and we talked about
if you build micro surface solutions and
you use vertex how do you use it because
if you think about micro services we
think about breast base
and underlying communication in vertex
is Jason over tcp/ip this is a bit
different from the regular micro
services so we listed all the stuff
that's inside the vertex stack that make
people use vertex as micro surfaces
because if you look at how it's used in
different companies they use it for
Microsoft architecture so there's
basically there's a lot of integration
so if you have to do integration with
rest or other protocols it's really easy
because it's all supplied in Seoul's
asynchronous you'd get the messaging out
of the box it has distributed data data
structures so for instance if you have
to share your session data or from
multiple nodes you can use the same
mechanism that's used for the messaging
so underneath it uses hazel costs which
is like a distributed key-value store
and if you use it in an environment
where you need to store your share your
session data you can deploy it on
different nodes and you can share that
session via one big distributed map so
you don't need sticky sessions or stuff
like that but it also has load balancing
features so you can deploy different
kind of configurations on different
nodes so say for instance if you have a
webshop
and you need to serve instances of your
product service but only one of your
order servers
it's really easy to do this with vertex
and you can even do it on different
machines and applications don't have the
same and they also have stuff like
failover so if one node is running on
one instance is running on one machine
but the machine dies even if it's not
running on the other machine vertex can
spin it up for you so you can have
different applications on different
machines and even in our availability
environments vertices can ensure that
your nodes stay up or at least one into
stable you ever question ok I thought
you were racing around and also they
have a lot of tools around monitoring
and metrics and deployment
today's Tuesday's elastic exactly one
week ago version 3.4 came out I've one
slide with a little little explanation
about what's in version 3.4 the stock
was based around three point three and
in three point three they added more
microservice related features and the
first one is the supportive circuit
baker better neither who knows the
circuit breaker pattern it was described
in the book releases by michael my Girt
i think is it correct I see you nodding
things okay so at one of my clients a
bank they said we have people working on
front ends on on the website and they
use JavaScript and they don't know any
Java and every time they have to build a
web application they need to pull some
some api's but to cut the correct
information that sometimes needed three
or four api's to call from their clients
code because there's back-end API so for
instance just an overview of your
account or all the transactions of the
past week but in the front end they
needed all the transactions over all the
accounts over all your cards and they
need them ordered by different like date
or amounts so that there was a big gap
between the backend API and the
front-end LPRs so they said can you give
a little introduction about vertex
because what we want to do is we want to
enable the front-end developers to use
JavaScript to create a mapping from the
front end API to the back end APs and
because vertex supports a development in
JavaScript that you can run it in a Java
JVM environment this gave them the
ability to let front-end people develop
their own mini micro api's support the
backend API so that was really for them
a case where vertex suits really well
and also because it's asynchronous they
can call multiple api's at the same time
and then great
get results back the project processes
transform it and order it but if you
pull back and api's and of course that
can be failures you can have a failure
that you don't get the result you want
or you get a timeout because the
services are not available and if you
have these distributed systems what can
happen is a failure in one API or
failure in one nodes can cause failure
in the other nodes because they are
waiting for it or their exception
handling doesn't allow for timeouts so
this is where the circuit breaker
pattern comes in so what it actually
does is it lates a circuit and when the
circuit is closed then everything is
fine from surface a I call surface B and
I get a response and the circuit is
closed with what happens when I don't
get a response you don't want to keep
retrying because you can overload the
surface you pole so what happens is you
can set an amount for instance five and
after five tries the circuit opens and
the back end search is not cold anymore
to get it room to recover for instance
maybe it was an overload of requests
afterwards it opens it doesn't call back
and serves until a certain time out and
then it all tries only once and if it's
still not reacting it it stays open but
if it reacts it becomes closed again so
this mechanism allows to prevent failure
and one service in the other service so
how does this look in code basically
it's just readable by the way yeah in
the back of it so basically you can
create with use of a vertex API you
create a circuit circuit breaker you can
set the max failures so if you have five
failures in the in this instance since
the circuit opens
the timeout says okay after two seconds
I want to try again I want to want to
allow a retry and you can call error
handling codes
maybe instead of having a real result
you have a different result or aesthetic
results and a timeout for when the
circuit is reset and then you do your
back end goal
inside the breaker both execute function
so I have a demo of this
okay so if you haven't seen any vertex
codes this might look a bit different
from what you're used to but basically
what we're doing is we create a web
server and when the web server is called
it pulls a back-end service and returns
it results so if everything is okay and
you call the results it will give me
Earth's bones it doesn't tell it's oops
so this is in ideal situation so if we
call the first therapist of course the
second service secretary returns the
result the first service in terms the
same result so now when the backend
server goes down so we stop the backend
servers
I think I have to call it three times
because that's the failure rate
so after three failures yeah one two
three the first two were correct
it says circuit opens and it doesn't
call the back end service anymore so it
will call it after a certain time out
and then if it still doesn't response it
stays open and if it all responds it is
closed to come so if you restart the
backend service and we run it again it
really immediately give me a result so
this is a mechanism and it's a pattern
which is widely used if you do this
integration scenarios and now with
inferred X you get it out of the box
that makes it really easy to implement
this pattern
okay next thing which is added in 3.32
microphones it's service discovery so if
you have a micro service environment and
you frequently need to call one service
from another surface what a course you
can do is you put serve the URL of
service be inside the configuration of
service a but what happens when you swap
out the serve from a different surface
or it gets deployed in another
environment so basically how will you
solve this instead of having hard links
between services you use the service
registry and inside the service registry
every service provider registers itself
and you can do this by name or by URL
and they say this is what I provide as
my surface this is how you can find me
and this is my name and if you need to
clear that servers you can query the
registry and the easiest thing of course
would do to do it by name if you have a
naming convention you just supply the
name but there are different methods of
growing as well a registry also allows
you to handle scenarios where servers
are unavailable so you can publish an EM
publish so you can have a dynamic
landscape of services and the registry
the registry make sure that you can find
the services wherever they are deployed
and if you think back about the services
being able to find each other that works
in ideal scenarios so if you have
Nauticus allowed on your network your
different verticals can find each other
but in a lot of cases this is not
possible this is not possible for
instance if you run your services in
docker they are already in a network
environment where they cannot find each
other or when you run it on a cluster
like on a kubernetes environment you
need to have a different method of
discovery that's why the service
discovery in the search registry
it's extended by a bridge and you can
use an external registry an external
registry can be the Cuba needs registry
or it can be the zookeeper for instance
so
you use an external method and one more
thing you can do is you can mix with non
vertex services so say for instance you
have a rest servers and it's built in
node.js or it's built in another Java
language they can register themselves in
zookeeper or in the kubernetes registry
and which uses the bridge from your
vertex verticals you can find these rest
services so you can import and export
services with other registries
so if you look at the example this would
be a service client so this vertical
wants to pull another rest service and
what they do is inside the service
discovery API they look for a record by
name so in this instance it's example
REST API and if the surface is
registered in registry it will actually
get back a reference to the surface and
because we know it's a rest service in
vertex you can create HTTP clients out
of it and directly on the HTTP client
you can make all your requests so on
this client you can do a get request in
the post request and so without knowing
the URL or the IP address of the
external surface the surface registry
provides me with an instance of HTTP
client that I can use to call the other
surface so if I run this it should
actually fail because I only have the
client running
so the result was not successful so I
print out no service fund so if I start
up the surface vertical and let's have a
look at it first
so the same vertical is a plane rest
service it also gets an instance of the
service discovery API and then it
publishes itself by name so the
combination of the name and the URL and
the port it's a service itself in the
registry
so now when I run those together it will
find the surface it will make an HTTP
request and you get status code 200 so
this is a way of dynamically discovering
services without hard linking them
together
okay so I just discussed or explained
the scenario where you can use motor
costs to find the different modules in a
vertex cluster if that's not available
you could use IP addresses so it uses
hazel cross hazel cast as an XML file
called cluster XML and inside that XML
files you can just put an IP address and
say the other service is running at this
IP address but then when you have a
micro service environment where you just
dynamically deploy and even if you use
docker you don't even know their IP
addresses they just get assigned
randomly so this scenario is not a
feasible scenario you probably want then
you can use static IP addresses to do
the service discovery so again we can
use the service registry but instead of
using a vertex registry you can use
something like zookeeper is does someone
have experience with zookeeper yeah a
lot of soup keeper experts so the
mechanism is the same but instead of the
vertex API the verticals publish
themselves inside the zookeeper registry
and if you want to find the other
verticals you have to call this the
zookeeper registry and you will get the
references back but you don't have to do
this by hand it's all handled
automatically for you
so if you look at the configuration it
does look like a lot but it's actually
only two things that are important first
of all you have to tell a subclass that
you want to use zookeeper and second of
all you have to specify where zookeeper
runs well in this demo I use zookeeper
inside docker without any configuration
but normally this would be a URL and
your dns would handle the translation to
the IP address so all your verticals or
all your application notes only need to
know where zookeeper lives
I just use a plain zookeeper docker
image because I'm actually not really
experienced with zookeeper so I did
nothing I just started the plain
zookeeper image no configuration
and I start my fake product surface and
what you see is it deploys the vertical
it creates a cluster and the cluster now
has one number and that member is
published in the super duper registry so
if we add another member
for instance the webshop from tens what
if we our group is it will try to
connect to the zookeeper registry and
now the cluster is extended to two nodes
and the two nodes are able to find each
other and this one it sends periodically
it sends a message and the other one
should receive the message so it sends
hello and the other one receives it
so both instances of the vertical only
have the address of the zookeeper
instance but you're still you're still
able to automatically create a cluster
of notes so normally this works without
any super on your local machine or your
local network but even on our company
network this doesn't work because you
are not allowed to do multicast so you
need a mechanism like this to be able to
find these services
okay so this is just local butter on my
local machine but if you're running a
Microsoft architecture you probably use
a docker Orchestrator to create your
cluster and to deploy in your cluster so
say for instance we have multiple
services and each service has its own
amount of instances because users use
the product servers way more than they
use the order servers we need more
instances of the product servers and of
the order servers so we have this
landscape with different amounts of
instances of our different services and
in my example I use up shifts openshift
is the reddit stamp version of Cuban
leaders and kubernetes also has a
register registry and in the same way as
with zookeeper we can use kubernetes to
do our service discovery so you can
actually do this at home if you want to
do anything with a cluster you can run
it completely on your own machine and if
you look at the documentation it should
be really easy you in you install
openshift terminal clients and then when
you say oc+ drop it creates a complete
openshift
cluster for you and paper that I
actually tried to run this demo Thursday
I was leaving on Friday morning really
early to fly here so I thought let's go
over the demo once more I updated my
daugher last week or two weeks ago
docker native app 1.17 came out so it
gave me a lot of errors when I try to
run this command and a lot of stress on
the Thursday before flying out so I had
to figure out a lot of stuff and
apparently if you have to write
configuration of versions it works so
basically I have to downgrade the docker
app to 1.13 which is pretty hard to find
because they don't have a release with
all the old versions but it was
somewhere in get up issue you need OC
client 1.5
let's think I think the latest if you
install it and we are going to install
open shave three point four point one
point five and this is the command you
use it's possible to do it during a
presentation but it depends on the
internet connection how fast it is so I
ran this this morning because I didn't
want to run in the situation where we're
just waiting minutes for this to come up
but basically if you use a Mac if you
use brew and you can install open shifts
you lie when you run this command it
will create an open shift environment
for you and the next thing you want to
do is log in this is big enogh okay so
it's running because I can log in and it
shows the projects you have inside
community so I don't know if you're
familiar with either kubernetes or
publish it no hands one hand not okay so
this could look familiar
so basically when you look into the web
I chose you project projects I only have
one which is for decks and what I did is
I deployed one surface and it's
currently running one instance of that
surface and let's have a quick look at
the surface because it's really simple
so basically I create a API which just
says hello and I have a bridge I reach
my event bus to the browser so I can get
push updates in the browser and what I
actually want to show is just I'm going
to this deeper the service several times
and it publishes in a low message and
the IP address and it pushes this to the
browser using the event bus so if you
have one instance the way to deploy it
is if you if you have used OpenShift you
may recognize this the basically inside
openshift
there's a build called source to image
it takes a docker file and a github
repository and it puts a quote from the
Kitab repository it merges it with the
docker file and it creates a container
for you so the doctor power I use it's
made by code centric and they basically
do a maven build and then they run all
the jars resulting from the build so
that's really easy if you want to
quickly deploy something on OpenShift
I don't want to do any configuration
with templating otherwise you can use
this image it was created for spring
boots because screaming boot is of
course a runnable jar but it works with
any other renewable jar so we can use
for vertex you can use it for drop
wizard and the second thing it needs a
native repository that's my github
repository where we're looking at now
and you can give it a name so once
you've run that command which I already
did it will create a surface you can
expose it in a URL this is really small
and basically we have one surface one
instance and it just services one IP
address so within openshift of course
you can scale
so if you have multiple instances
running eventually we should see in our
IP ID so now we have got two and dot
three so that's two instances of one
vertical the verticals use phaser past
and Zuki kubernetes registry to find
each other so if you look at other
configuration loops it's similar to the
zookeeper configuration but now we're
using a communities discovery strategy
and we don't even have to specify where
the kubernetes registry lives because
there's a an environment variable
it's called completes namespace I think
a namespace is basically coupled to your
project so within a project all the
services can access that namespace and
they're privileged under that namespace
so by default everything you deploy in
the same project is able to find each
other if you have services in different
projects you need to complete a
different namespaces so you need to do
some custom configuration if you just
want to run the cluster for PLC or
something else if you have one project
and openshift
everything you deployed there it can be
found using the kubernetes api so what I
start to if you want to try this of
course this isn't it up so you can have
a look but it took some figuring out
apparently you have to give the services
access to the Kuban aids
API and it's comments like this so this
command says this namespace is
accessible for all the services inside
this namespace so this really doesn't
tell us anything because I just heard in
the previous session you need at least
three instances to test most integration
scenario scenarios
so let's deploy another one
so basically we already use the docker
file once so we can just specify the
name of the docker file inside OpenShift
something called an image stream is
created and that's actually a built of a
docker file so if we run this it will
actually start a new build for us inside
openshift so these are second surface
and now it's currently doing the maven
build and then it will do the deployment
and then we have another container with
a another instance running inside oh
it's pretty constant that's good so
currently we have those just strong
currently we still have those two IP
addresses this might be too small or not
and eventually when the bill finishes it
should show a third IP address which is
the new service I deployed and then we
are at three I think that should be
enough yeah
so now there's a three two and four so
if you go back to open shift we see we
have two services one has two instances
one has one instance and they don't know
each other your IP addresses they
publish themselves in the communities
registry and hazel costs make sure that
they form a cluster together so no hard
links and now you have a dynamic
environment to be able to dynamically
deploy new services so this is really
really really basic but if you think
about it this allows you to create new
services dynamically scale dynamically
bring down the services dynamically
without having to change the
configuration of all the other services
so we're in the vertex environment is
really powerful but also remember if you
have any other rest services you can
deploy them inside kubernetes
communities as well and they will also
be imported by vertex and from vertex
you can call them and it also works the
other way around okay a full demo or
full source code is in my github
repository
any questions yeah
yes sir the question is can you pass
other informations via the registry
between services but yeah it's yet that
actually the concept that is used inside
vertex is called a record for this and
you can put more information in the
record and you can also query more
information in the record so you have
some more freedom there I don't know if
I had exactly what you can put in there
but so if you don't know if it's a rest
instance you just get the record and
based on the record you can do more
stuff here so you can look inside the
record to service record and you can put
more information there so you have some
freedom and there might be just a field
to position
okay so yeah so your question is besides
the metadata can you put more
information that also allows you to
create okay yeah it's actually a really
good question I don't know that by hat I
haven't seen it in a documentation but
we can have another look afterwards to
see if it's there because that sounds
like a really good key space so that's
basically you want to professional
surfers or explain the usage to this
through the registry yeah okay yeah one
more and kubernetes allows this yeah
okay okay good question but I don't have
the answer sorry okay next up is HTTP
too and I realized that those are not
the best colors for readability but
basically if you look at HTTP 2 versus
HTTP 1 it allows the requests to be
processed asynchronously and out of
order and it also allows multiplexing of
different requests so if you work with a
computer a synchronous system what you
notice is that HTTP is really
restrictive because it's completely
synchronous request response model and
you can for instance use something like
web sockets which allows you to do more
like an event based communication but
the thing about web sockets is it's
really basic it doesn't give you
anything it just gives
you a similar similar tcp/ip connection
and you can send stuff so HTTP tool is
what we were waiting for it allows you
to do more stuff like HTTP 1 with
headers and antibody but it allows you
to have more asynchronous communication
with messages so in a 3.3 version of
vertex you can create an HTTP 2 server
and you can create an HTTP 2 client and
it allows you to do stuff like server
push so you can actually just push stuff
to the client without getting a request
first you can do requests by blinding
and multiplexing which means you have
full duplex asynchronous communication
so you can implement the messaging model
or an event based system and it also
allows you to send and receive custom
frames so HTTP 1.1 it's quite the messy
are quite big if you have a lot of
requests and responses going back and
forward you will notice that the HTTP
message are quite big and with custom
frames you can just describe your own
frame and send it in a binary format so
if you do more like a real-time system
or for gaming or there's a lot of
communication between client and server
it allows you to just send basically by
uniform yeah yeah
you can that's actually a really good
question queso the question is dusting
event this verse uses HTTP - if you were
looking at server-side then the answer
is no because it uses a so fast and
tcp/ip if you look at the bridge to the
browser
it uses WebSockets and I don't think
they use HTTP - but I expect if you look
at the way they are working they will
just include that as an option for the
bridge so they will check out the
browser do you support HTTP - yeah I use
HP - fusible web sockets no HP - web
sockets and then fall back all the way
to long fall in but I don't think that's
there yet that's really good really good
question um so it should be - in
practice
so if you create a HTTP server in vertex
there's not a an option set hb2 through
its goldset use a LPN currently it's
full so if I start a server then we're
using HTTP 1.1
so I have a HTTP server and if I go to
the slash version URL it will give me
back the HTTP version so now I know I
have HTTP 1.1 and actually what the
server implementation does and this
might be a demo you have seen before if
you have seen other HTTP 2 demos it
actually builds up an image based on
small images so it will call an array of
XY coordinates and it builds up a
complete image so each part of the image
is a HTTP request and this is actually a
really good demonstration of how HTTP 2
works so if you have each image is a
separate HTTP request and you use HTTP
1.1 it takes about 8 seconds to build up
the image that's because it's completely
synchronous the request response request
response request assumes until we have
the complete image so if you enable HTTP
2 and we restart
so first check the version is aged to be
good so now we know it's going to work
and what will actually happen is that it
will combine the request responses and
they can do it out of order and the
performance increase you get is what
this was about I think one one or two
seconds so this is the big difference
what you can do with HTTP 1.1 and HTTP -
of course you want building up an image
like that but imagine that it's a lot of
data maybe data on a map amount of
hotels or the prices of hotels on a map
then you're able to to send more data a
lot quicker
so that's one thing you can do with
http/2 another thing is server push and
if you look at the API
it's called push and it enables you to
send stuff to the client without the
request so if you have a website with
real-time information you don't need
website circuits anymore to update that
information you can use HTTP and in the
client I have to register a push Handler
and currently I just love the stuff I
get pushed but of course this is not a
browser this is just HTTP client so it
will use it will work with HCP services
back-end HTTP services as well so if I
deploy those two together it will start
a server it will send the data and on
the client side the data is received and
I lost the version so actually when you
think of it if you're building a
asynchronous system if you do it now
you're constantly running to browser
communication rest communication still
synchronous with HTTP two it allows us
to do more like an event based system so
we can actually push information to
other services as long as the they are
registered over HTTP and the final thing
is we can send custom frames so here
it's yeah just a buffer that says ping
and this is the server side the server
side we define a custom frame and once
we receive the custom frame from the
client we send it back to the client and
now we have like a ping pong implemented
so if we start out to verticals together
then the client sends a ping and the
server sensible so now we have custom
data over HTTP to send between two
services those two words are verticals
but of course there can be any other
Java service already order known Java
services because it uses just HTTP to
now event there's no a so cost to say
HTTP to so we also already get this
support inside vertex so last week we
already get got three point four I was
actually hoping that it will be released
a little bit earlier so I could
incorporate some three point four stuff
inside my talk but that was not case so
I'll take all of you for the first time
we create Scala and Copeland
so next to JavaScript Ruby Cylon we also
have Scotland got line now as supported
there's a nice new web client it was
kind of cumbersome to do HTTP client
requests inside vertex but I we worked
the whole API and now it's much more
easy you can easily send JSON or receive
the digestion and automatically get an
object out of it instead of having to
send low-level HTTP requests MQTT it's
an IOT protocol which is pretty
elaborate it's for small messaging
between devices because you can use it
on low power devices and it actually has
a different service levels so you can
say that messages should be sent only
once or at least once or you want to
have a confirmation that your message is
received but you can also just publish
and forget messages depending on what
kind of service level you want and the
person who preserves project vertex mqtt
and actually incorporated that and now
in the new version of vertex we get an
MQ
t.server and what's nice about this is
that you can deploy this and it will
actually translate MQTT protocol
messages to your vendors so you can have
a vertical handling some kind of logic
and it just receives Jason and
accentuation and with the mqtt broker
you can connect your devices and the
devices will be able to connect over the
eventbus with vertex verticals so you
don't need any other mechanism to do the
mqtt you can just use it as part of your
vertex deployments more integration for
instance with Kafka so if you look at it
I think the amount of integration
possibilities with vertex that you get
out of the box makes it something that
that that makes it really stand out
among other projects you can really get
a lot of asynchronous integration and
they're still expanding those
integrations what I saw what clients is
the case I describe they want to have
JavaScript developers doing a little API
stuff on the on the backend which which
is easy because you can go in JavaScript
or other languages service discovery it
was something that was much needed
because you don't want to have the hard
links between your services and one of
the first I think HTTP 2 implementations
in a bigger framework so if you're
interested in vertex there will be 3
other talks in this devoxx instance
tomorrow even terrific Microsoft's with
vertex and good Benitez and Thursday I
think that's a handstand zone lab one of
these two is a lab and the other one is
a presentation so a lot more vertex
goodness if I trick at your interest
into vertex a bit any questions
yes yeah the question was can I talk a
little bit about how long this vertex
around about the maturity level if I
remember it correctly it was started by
Tim folks three or four years ago it was
called note X because it was an answer
to no Jess so Tim looked at the
functionality and the reactor pattern
how it was implemented in OGS and he
said this is a really really good idea
that we want to run it on the JVM
because our operations they don't want
to run JavaScript on the backends it was
a couple of years ago of course we've
moved on but we want to have stuff
running on the JVM because we know how
to operate it we know how to locate so I
want to have a similar project written
in Java along the way it's got there was
a little fight I think between VMware
and reddit they both want to have the
project and write a credit score it so
it's now a reddit sponsored project so
there are some core developers from Red
Hat's actively working on vertex Tim has
left the project is now user so it was
really funny because he was also at that
meeting and the fall which they said
yeah now you're a user so that's a
completely different view on the on the
project what I think of is is if you
look at a technology it's really sound
it's well thought they have some
principles like they want to be an
opinionated so they provide the full
stack and give you the possibility to do
implementation but there's not a lot of
marketing around it you I know some
companies in the Netherlands and some
companies and outside Netherlands who
use it but it's not frequently heard at
effective power to similar solutions I
think we have no js'
could be a candidate spring reactor
might be a candidate a car
if you want to do Scala but it's a
little bit more low-level and that's
about it I currently use it in and now
in one project for one of our clients
and we can use we are going to use that
software at different clients version 3
was a little bit different from version
to version to data all own clouds
floating model and became kind of
complicated in the first three days yet
we are just going to use Navy dependency
flat glass parts at ER so that also
means if you run a vertex environment
you can use a maven repository to deploy
your verticals so you don't have to
manage all the code by hand or put it on
different surfaces servers you can
actually do new instances or new
versions from a maven repository so you
deported a repository and with the
command line or on automatic scripts you
say ok there's a new version or I want
to four different rates so that answer
okay any other stuff now thank you very
much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>