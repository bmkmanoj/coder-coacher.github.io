<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What monolith can learn from microservices? by Alex Soto | Coder Coacher - Coaching Coders</title><meta content="What monolith can learn from microservices? by Alex Soto - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What monolith can learn from microservices? by Alex Soto</b></h2><h5 class="post__date">2018-03-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KnEf0e3NHS4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good moring thank you very much for
coming to this session thank you very
much for coming to a session about
monolith right because it seems that
it's not so hype nowadays monolith so
thank you and what I'm going to explain
you is how I would develop monolith
application nowadays with all the
knowledge that I have about
micro-services I know that most of the
things that I'm going to say you will
say it's common sense I already know
this sure that you already know but what
I wouldn't did you get it from this
session is that there is more people
that thinks that you can or you can
still enjoy developing monolith
application so I know it's common sense
but it's worth to you know remind every
time I'm Alex Otte oh I'm a Red Hat
engineer I'm the creator of a lot of the
charts calm and you can follow me on
Twitter you have any question just feel
free to ping me there and I will try to
answer and also this is the irony right
that I'm the co-author of testing Java
micro services I know it is an irony but
if you it's today and tomorrow you can
use this discount code so you get like
40% of this kind of the price of the
book so if you are also into micro
services then you can just bar it and
see how to test a micro services then I
will share the slides so if you check my
Twitter you will see the links finally
if you have any question please raise
your hand and I will try to answer
because it's a long journey today I'm
going to talk about several part so if
you do the question just a time then we
have all the contacts and the reason of
this talk is about this discussion
between a Kelly and my mate bar which
basically they start discussing and they
may be said that maybe we are currently
into the through of this release it
listen this aloose anuman sorry face
that basically it's the phrase that
happens after everyone is you know
adopting microservices and basically
these phases where you are implementing
microsoft's architecture you'll get it
to production and then you see that
there are some problems and your start
failing and you are not really happy
with the result right and this is normal
it's defined in the hype cycle graph but
even if you have felt i think that it's
important to learn things and this is
the reason of this talk it's learning
what offers micro services that can be
also adapt to monolith and this is
basically let's say a really simplified
micro service architecture where you we
have a front end usually you can even
split the front in between services but
for simplification i put it just one
layer of front-end then you have the
security context you have an AP gateway
and then you have several services all
of them interconnected by network each
of the service usually it's it's a map
to a bounded contacts in the ddd
methodology and usually do these
different technologies in all the
services and different teams developing
it right this is in summary i'm mike
Receptus architecture but what i'm
saying here is that maybe instead of
this we can have this other thing where
you have a front-end and then we have
all the services inside the JVM so there
are no more network connection but just
local cold of course all the language
are jvm languages and there are several
teams and maybe the front-end you
connect with the front-end even by using
an HTTP connection or maybe you just use
some kind of this template language is
like a teamily for free market velocity
so you get it on your server side you
render the HTML and you send it back to
the to the client so let's see how we
can apply some of the advantages of
micro services inside this way of of
these architecture
one of the best things of micro-services
is the isolation between services right
it gives you a common API to communicate
between them and the good things about
micro services is that there is a
physical wire which is the network so
it's like you know you have several
services inside they have some code but
any service needs to use this cone API
it's there is no way to that one service
uses an internal class of another
services this is something that usually
happens with monolith right that you
have several models and then one model
uses one internal class from another
module because we are in hurry and then
what we are end up is by having some
kind of a spaghetti call right across
all the monolith so the thing is that
can we select our code in the monolith
as it happens with microservices and the
answer is yes and there are several ways
of doing it but in my experience the
best way it's just using the modules
that offers you the the belt alright you
I mean that with maven you can define
modules will be there as well so one way
of spreading the code is using modules
and basically what I like is this kind
of a structure where you have the root
folder and then you have when you will
have one micro-services called game then
I have a module called game and this
game it has two more modules one we
would just called API another aim empl
the same for review and the same for the
talents one so far is you've got this
layered structure where you have all the
services let's call it although they are
not services in the sense that they
communicate by network and the API NPL
so it's happened with the with the API
the API is the public interface right it
it exposes in a small well define it
stable API so it's just and in mmm Java
interface and it expose only what is
required and it favors lot coupling
because as I said if everyone uses this
API
I interfaces then will never use the
internal classes so you get it out of
having a spaghetti code and then there
is this MPL folder which is like all the
classes are private or packaged or I
mean that it doesn't matter the scope
but they are not public it's highly
coercive in the sense that all the
classes just communicate inside this
model there is no outbound
communications and finally this really
important is that reduces or memory
footprint right because now if you have
not implemented this module but you want
to know what this model is doing you
just need to go to the API layer check
the Javadoc and interface and said ok
this service is doing this kind of
oppression and and behave like this you
need to go inside the code and check
who's calling what and so on so far so
it's a really good way of just spreading
each of the modules the problem with
this I'm sorry then also even you can
define teams for modules since usually
these models are just connected by the
API probably you can still use the same
approach that you are using with
microservices you have several teams all
of them working the same codebase
but in different folders so probably
it's like unlikely that there will there
going to be some kind of merge conflicts
and yeah the problem with this is that
of course nobody for I mean that
everyone can just go to the
implementation folder and sit and
discuss is public right so for this
reason you need to enforce your code
reviews so you need to talk of rebels
and say hey look this is an MPI and it's
public so please don't do this
also you can use tools like P and D
called assert a checker style or maven
enforcer to just have some automatic
ways of detecting these violations or
even and this is quite a hacky is that
if someone is a smart enough to say and
I know that this class is private but
I'm going to use reflection nobody can
avoid you to do that
the reason in the quarry we need to also
pay attention on the reflection calls
right but if you do this you see that
you get it exactly the same that in
micro-services see different different
code bases separated isolated and with
just one common point to access the
think that happens with microservice is
the isolation of data right so each of
the microservice has its own data its
database so you cannot do some kind of
join between service a and service B
right you need to do a call to service B
again we can do this with monolith it's
not a problem there are several
approaches but this is the one that
works better and basically is that you
have all the services and each of the
services is mapped in a schema so one
service or one module it's one schema
you have the game schema review schema
and the tailore schema
this is important the second thing is
that the joint might only be happen
inside the module so you have a game
with several tables inside the schema
then you need to do the joint between
these a schema but not joint with tables
of another schema and this is important
this means that the coverable you need
to pay attention on the core review and
also take care of JPA
and lazy collections because maybe in
the in the in the GPM model you just put
there a class which is from another
module and then when you do the get
you're doing a join so take care about
this but of course I mean that we don't
need to get crazy about trying trying to
replicate what is in microservices in
the monolith
we have referential integrity across the
schemas so just use it something that
you don't have with micro-services this
is in the integrity of data across all
the services with this with models you
can do it so just add foreign keys when
it's necessary even if there is are
between schemas yeah
yeah exactly like it happens with my
cursors yeah but it's like microservices
writing microservices is one thing that
you need to happen and it's not
efficient at all let's say and this way
yes it's true that you are paying some
kind of performance in this way but you
will see now that you can fix it in in
some ways but yeah it's true that it's
like you get it this kind of thing but I
think that well yeah this is just
performing thing that you need to see if
you want to pay off of this or not and
you will see why it's important to do it
in that way and in the final of the
presentation but at the end it's like
what you want right and you choose and
yeah but yeah that's true and and
finally remember that with micro
services you have an event or
consistency so you don't see the real
wall you see something that might be now
but maybe not and with now you can have
global transactions so it doesn't matter
if you are using different schemas just
use the global transactions you get it
all the time you can see the real wall
in your system yeah there are tools like
lightweight on leaky ways for populating
all these schemas and tables and so on
so far and in case of you said I don't
know this how must be done then think
that if you are implementing a micro
service architecture and then said how I
will do this and then just implement it
in that way although it is a monolith
this is the safest way this is about the
isolation we see how to select your code
how do you select your database another
thing that it's used in micro services
is the reactive approach right basically
what's happen with micro services is
that each service uses network to
communicate to another services and of
course they are slower than my local
call so what happen is that what we want
to do is execute all these things in
parallel and I think that one of the
best tool in Java
Eric's Java which is a library for
composing a synchronous programs and it
looks like something like this notice
that and now he
have this operation with this a combiner
which is a snip tip it means that I'm
going to execute some operations and
then join the result of all of them then
I have these three calls get game get
details and get reviews which is the
three operations from three different
modules each of them will do a DB call
then you need to set where to run them
and you said that it's you can think
about this scheduler as a thread pool if
you set here for example that this pool
is just one thread then all the methods
will be ticketed sequentially but if you
do a thread pool of ten threads then it
will execute all of them in parallel
finally it's like okay now when I have
all the data get it from each of the
services how I join and it put a tag
aiming for with all the games at the
tails and reviews I'm finally what I do
is just okay and when I have everything
join it what I want to do and it's just
send the game info notice that in this
case gate game is just a local call get
details is a local call and get reviews
is a local call there's no network all I
know that this in micro services
architecture will be a network call and
in this case is just a local call so
it's pretty much faster but at the same
time you can paralyze doesn't matter is
it faster that you cannot paralyze so
this is something that you can import in
your monolith from the micro services
architecture another thing that happens
with micro services is network and there
are a lot of network calls right because
you have one service you need to
communicate with other services to get
it and post data and usually what happen
is that the network fails and when it
fails you need to see how you recover
from this network fail you need to make
your services resilient so if the
problem so if there is a network failure
and the problem fails it does not just
you know blow all the service but and
you said yeah but in monolith there is
no network calls right everything is
local and that's true in the sense of
services monotonous
of databases GMS skills mail service all
these services are also running in the
network all so we can use what we can
what we have learned from micro services
and this is basically the well-known
secret Brigade pattern
everyone knows the secret bracket
pattern yeah nope well basically the
circuit breaker pattern is a a way to
wrap a function inside a circuit breaker
and then if there's some result error is
rich the security strip so any further
call instead of being called it just
automatically returns the R or in this
way since the expensive operations like
creating a socket creating a thread and
so on so far that it's really expensive
for the operative system arm not done
because you already know that it's going
to fail because it failed previously so
instead of days it just returns zero and
after sometime when you get it a new
request then it will try it again and
said okay I know that it has passed like
five seconds failing
let me try now if it works or not and
then if it works then the circuit is
closed and then all the communications
continuous as usually but if not then
the circuit is open and it's
automatically returned error without
executing the real code and there are
several implementations I think that
with resilience for J and districts
probably most of you are using hystrix
if you are using circuit breaker but I
prefer Brazilian for J and the reason is
that it just has one dependency with
this Babar for functional programming
that's all you will check history you
will see that you are populating your
class path with a lot a lot of
dependencies and then you maybe you get
run on this dependency hell problem with
Java and to just use reason for J just
you defined the circuit breaker with the
name here you grab the function in this
case I'm doing entity managers that find
so this is the communication to the
database using JPA
I'm finding what I say is like you and
when there is an error then just return
me an empty result so if there is an
error it will return an empty result and
all the success all the next
communication through this database it
will return always an empty until some
time has elapsed let me show you a demo
so it helps you see all these things
with with code okay this is application
this is what we've seen that we have the
Tales game page and reviews and
basically we can change for example game
page it have the API a MPL and the tales
as well the a pair of details it just
contains the interface which is public
which it's have a metal it's called find
the tail byte game ID which you pass
along and then it returns an optional to
say because maybe there is no detail and
then there is the detail model and if
you check the the MPL it's pretty much
the same but it just a class which is
package scope and it contains the
implementation of the test service and
all the I mean that in this case the
secret breaker and all the
implementation and if you check how to
consume this the same service you can go
here I'm just using I'm just injecting
the detail service and then choosing CDI
it will automatically resolve that the
tale service in PL to this detail
service so notice that now here and I
don't have any import about the MPR
modules now I need your help this is
okay this is the games that I have in
the database I have the first one is the
secret of monkeys lon everyone played
the secure the monkeys lon yeah okay
with I put it here if I remember
correctly four stars
it's what it's one two zero two five
four studies okay maybe five three what
five okay five next one monkeys on to I
put it a five
I like it more monkeys on to that one
but what I put five four five as well
okay next one Indian nations on the fate
of Atlantis this is yeah
less famous but I put it up for I
enjoyed this that you can played several
characters at the same time and several
pass five as well sure
let's put in a five next one doom that
the first or one of the first you know
first person shooter I put it a three I
mean the title I prefer doom two but
three is okay four one three five as
well okay five as well
next one day of the tentacle I put it a
five I enjoyed so much this five five as
well okay and then the other one is the
dimwit part which is one from Ron
Gilbert that was release it like one
year ago or so I put it as 0 because I
have not played anyone played this game
5 now if you have not tried you're gonna
say 5 right so I will have it at 0 right
so I mean to have something different
not okay now we I'm going to just to
show you that it works I'm going to
package
okay
I mean that this deploys application so
you can see that it works so the number
five let's see okay number five was day
of the tentacle you said five you have
here the five the number one it here the
monkeys and we also said five so you
have here the five estar and all the
information and that is that here what
I'm doing it just squaring the game
details the game and and the rate and
the rate and the reviews with the
ratings and put it everything together
right I mean everything locally and just
to see that the five it's five sorry in
the six it's zero as we said right so it
works maybe you are asking now okay how
I can ensure that there is no
communication between API and empl and
basically you need you just need to do
one thing which is like using Kota cert
which is this tool and the important is
like this one dependency right this test
it's a J unit test with its I mean I
know that now you said but it's this
inner class here it sounds really
strange yeah it's real easy
notice that the the class is called orgy
lot of the jars games right if you check
my package you see that there is an orgy
lot of the jars games so it's a way to
check this class is about having rules
for this package and then we have game
gaming then we have fields this face
which called game game API gaming PL
details API and reviews APA which
basically says that our G dot lot of the
jars dot games dot game right this is
the package origin lot of the chance dot
games dot game dot API so it also played
the camel case from the fields as well
so you can set all the packages right
this is a way of checking or setting the
packages and then you said just this
defined rules we say game so orgy lot of
the jars dot games dot game
must use game dot API details dot API
and reviews dot API and game in P I may
use game and game API so I'm defining
the rules and of any other communication
it just it's a failure it's a test
failure and then I'm saying I want to
check these dependencies but just thing
about that their dependency dependency
is like Java dot star Java X free marker
and he ordered reactive X which comes
from Eric's Java ru no external
dependencies don't take it into
dependency analysis so now if I run it
here the test when I deploy it here this
test has run and check that everything
is is perfect if I will use some for
example details dot MPL in the code so
here I have an import here for example I
had an import of details dot MP L then
this test will fail we said you are
using a forbidden package so this is the
way how you can automatically set this
isolation between modules so let's
continue in the journey front ends well
I'm not a super expert front ends but I
mean the microservices group on in Red
Hat and all of them are talking about
web components and custom elements
because it allows you to split the work
between front ends so each of the
microservices can contain the front end
as well inside the repo so the final
page is like a composition of custom
elements as I said I'm not super expert
but this is JavaScript code basically
define a class that extends from HTML
element then you have a connected
callback method where you put the HTML
code that should be injected inside the
HTML page and of course here you can use
angular viewer any JavaScript framework
then you need to register so you say
that checkout basket which is the tag
it's going to be checkout basket class
and then you just need to do this
put it in your HTML code check out
basket and then at runtime this check
out basket track is going to be replaced
by the HD near HTML define it in the
connection callback as I said I'm not a
super expert about this but you can read
a lot in the developer's Google site and
also in the micro front-ends dot org I'd
really recommend that if you are in the
micro services bandwagon and you have
problems with the front end you check
these links to learn how to split the
war between the front and steam another
thing that you should do is embrace the
Bob's right one of the important things
about micro services is that they reduce
the time between committing a change to
the system and chain and the change
being placed into normal production and
Biermann and what do you insure in the
high quality right this is the with Deb
ops tasks so DevOps tries to avoid that
used takes like month to release
something but just release several times
every day and from in my opinion one of
the best technologies that help on
developing and releasing faster is
docker
and it was really popular in because of
micro services and I mean that it's
awesome because allows you to define
your stack so you set your docker file a
set of practices to run your application
like the JDBC drivers the application
server that you want to use the Java
version which is really important I
remember working in a company that the
software works on pre-production were
not on production at goods because the
minor version of JVM because of the
corrector libraries
so this minor changes are also important
and it's really important to have the
same versions in pre-production
production so and so far so docker helps
you a lot and the good thing is that
this standardized the way how we can
deploy because in the past what I had it
was like hey man I've created this war
file that it's place it here I sent an
email to the Ops guys and said look take
this war file copy to the you know why
fly deployment folder and then you have
to boot up a Postgres ik well
copy these files confusion fuss here and
there and so on so far and be aware that
everything is done perfectly right this
how we work some time ago and then I
move to another company and I said hey
and I said I need to send an email for
deploying and they said oh now we are
really a smart we are using a wiki page
and it was like okay it's exactly the
same right because the wiki page becomes
updated then you are always have
problems on Friday night trying to apply
something so we could page it's exactly
the same problem and I think that darker
simplified a lot because you just create
your darker file and you go to the UPS
guy inside just run run docker built and
put it this and this is what it works so
basically this is my ass and a scheme of
my of the application that I've
developed using the monolith approach
which basically is a load balancer with
two Hardware servers with the drying my
application and then I had three
databases one database for each service
and one for backup and yeah I mean that
in case of fail at one node then they
will there were there an operation
guided set out this this know has fail
at I'm going to boot up again or just
trying to find what's happening and and
reboot the system and so on so far so it
was like a manual thing of course yeah
this is not the right way to do it but
I'm sure that everyone here has suffered
this and I said that darker is a really
good way to adopt in the monolith so how
do you do this right you start doing doc
around service one doctor run service
one mirror it doctor run post grade okay
run blah blah blah blah right so you you
can just start doing doc around the
Quran the Quran notice that in this way
you didn't you didn't a scale with the
traffic you have two services in that
zone and if you punish down then you
need someone there to set docker run and
run it again the container that has
crashed so the thing is that why you
don't start deploying in a cluster in a
queue Benares cluster up and shift
cluster again mean the cop up and shift
is
it's the Cuban a dispersion of Red Hat
which is open source so nothing blocks
you to create a cluster maybe it's a
small cluster with just four machines or
six machines but it's okay because the
the good thing about Cuban ideas is that
everything is managed automatically you
just deploy yourself is there in case of
failures automatically the cluster will
boot up a new service for you or it will
find a machine that fits your
requirement and will put the service or
if you get it high hike level traffic
then you gets a Cuban s can set all look
you are increasing your traffic's I'm
going to find another machine on my
cluster and create a mirror of your
service there and everything is
automatically so why we need to do
things manually when we can do it
automatically and that is that it's
really easy you just said this is my
service I want two replicas of the
service and they much that I want to run
is this one game dot 1.00 and I really
enjoyed doing this because and now that
I'm using I'm developing micro services
there are really huge Cuban areas files
right to deploy the micro services and
so on so far in this case it was really
simple and finally the port and this
looks like this right you have this up
and ship which is a kubernetes as I said
and you have the game service with two
pots so you have these two services and
then the cockroach DB with three pots
this is a database a sequel database
that works really really well for
distributed system so I recommend you
that instead of going to my sequel or
possible sequel give an opportunity to
cockroach DB for this distributed
systems and here this is the sorry the
reverse pour the reverse proxy router so
this load balance which done
automatically by openshift hundreds of
instances
another thing is like micro services
must be cloud native applications
basically because by definition of micro
service must be able to scale up and
down and a rapid the
be great and automatically and recover
automatically from errors how I work
with my monolith again I did have some
this kind of infrastructure with I have
the load balancer and so on so far and
then I have a request and then this load
balancer created a sticky session which
basically is a pair between my computer
and the server that's going to serve my
request then suppose that I want to buy
something - I add and product into the
cart and for any reason load balancer
decide that I have to go to this node so
I put it the shopping cart and in the
user I here
this is the session right this is the
HTTP session which is stored in the
server and then with the sticky session
all my success or my next communication
will be redirected to this server as
well but what's happen if this service
goes down I lost the shopping cart right
so in things like that you need to
reload the lock again and so on so far
this is how it worked or how I work in
the past I'm not saying that everyone
here is using this but probably most of
you has suffered the sticky session
problems and basically what how
micro-services fix this is using an
in-memory data grid which basically is a
data structure that resides entirely in
the RAM and it's distributed among
multiple servers so what's happened that
if for example I have here a request it
doesn't matter if it goes to note a or
not B but then the shopping cart is
shirt across all the nodes automatically
and they're in in RAM so it's really
fast to get it get access from the data
if this goes down it doesn't matter load
balancer will say ok I mean while the
new node is not up and running I will
redirect all the traffic to the other
node and it doesn't matter if you if
your session was in the service a or
service B because this in memory degree
it maintains the state across all the
cluster and yeah anything that one of
the best in memory data creates Infini
span which integrates very well with
kubernetes
well another thing that is really
important is like with microservices
we're starting releasing as unicorns it
means that we are releasing like four
times per day instead of one time every
six month so how they release the
unicorns basically thinks of the
continuous is really easy just just
built a docker file with all your stuff
you build a container right you have you
do this darker build and you put it in
the docker registry then you deploy this
to the cluster to the communities
cluster so you have up in this case in
case of cube unless you have a pot there
on production but you are not receiving
traffic so it's deployed but not
released and then it's when it happens
that okay and now what and one of the
things that are coming with a micro
services is them is that I'm testing in
productions so you put something inside
the cluster a new version and then you
check what's happening with real traffic
and this is really important to do it in
that way because production is always
different right there is different DNS
different Hardware different network
layers network topology sorry
and also the Regal traffic is always
different from the test traffic maybe
you get it you know people with strange
browsers and so on so far so it's really
interesting to have this testing and
production strategy and there are
basically three ways of testing in
production the first one is that
Bluegreen deployment basically you have
the blue deployment which is one that
it's running and then you deployed this
new docker container and then you switch
from blue to green then all the traffic
goes to green then you start monitoring
the monitoring that your responses and
if you see that there is a high error
rate then you switch back to the blue so
in this way yeah at least you have the
bottom bjurman then you can switch back
and forward to check if it works or not
notice that this has a really big
problem is that all your if there is an
error all your traffic will receive the
error so toroid is we have canary
releases
that instead of switching all traffic to
the new version your star just switching
just for example one person of the
traffic so although one percent of your
users will start reaching the new
service if it goes ok then you increase
to five goes okay ten twenty fifty
ninety percent ten percent and then you
can switch off the other service if
there is a failure just then just one
percent of the users will receive this
failure so it's not it's better than
Bluegreen and the third one is like dark
launchers or shadowing traffic which
basically is like I have a user that has
a request and then what I do is just
send this request to the alt service and
the new service the rivers to the all
service is going to be the answer that
is going to be sent but the new one is
going to be at like a fire-and-forget so
I'm going to send the request to the new
service and I will not and the user will
never notice that here the skis request
has also reached the new service and
then in the other side I have a
monitoring system which check if
everything is behaving as expected when
I see that yes it seems that all the
requests that are just with shallow wood
or shadow mirror that it's mirrored it
working then I would say okay it's
working let's try to start the canary
release process sending the one person
of the real traffic there and so on so
far so there are these three techniques
and in each case you must decide which
is the best one that fits in your use
case and finally when you have tests and
you have all the users to the new
service you have released your new
service and this is something really
typical for micro services but I
recommend you that you also do this for
your monolith because it's really easier
or easier than in micro services and you
will get it you know in touch of what
means testing in production yeah some
tools for testing upward automate all
these processes like source to image
tool openshift or fabricate it automates
all these steps
than if you want to get into testing in
production I recommend you Tate and
division for dealing with the big
problem of state or the persistence
problem right because you are testing in
production but you're inserting data
inside your databases as well and maybe
there is failure so you're you know
adding some noise on your DB so these
tools can help you with this so let's
mean down advantages of monolith now is
it seems that more like this is a
and if you arm only is you're writing
money you're not so cool but you see
that you can use so cool technologies
for monolith and you get it some
advantages like local codes there is no
network just memory call all parts are
always up you don't need to feel rad it
what's happen if the other service is
down and so on so far I'm here it's like
everything is up or everything is done
because everything is running the same
JVM it's easy to the back if you think
about how you will the back micro
service architecture is really hard
because everything is a synchronous
itself was a network so you need to
start configuring the debauch in remote
mode and so on so far so it's hard it's
easy to the back Romano it I guess it's
also easy to test right everything runs
on your machine doesn't need to boot up
and start doing some kind of built to
service utilization it's really easy to
refactor I'd recommend you the
experience of refactor of micro service
architecture because you know you like
you change one service and then you need
to said ok I've changed the parameter so
now I'm sending I changed the parameter
from name to full name I need to get it
who calls my service and notify them
that now it's the name but it's full
name right and because it is and they
need to change if you're sending JSON
how they parse the JSON in the sense of
course you can use contract testing but
then you need to write contract test for
that you see the real wall every time
because I mean you have transactions
level transactions so there is no
eventual consistency it's easy to deploy
I mean that in theory micro services
should be deployed in an isolated way so
you can deploy any service independently
but this happens when you
have a product like after two years but
at the beginning this usually it's not
that case so you need to coordinate
deploying a bunch of new services and
this one is just one service you
deployed the war and you're fine
and remember that nobody's about you to
use polyglot languages of course is jbm
languages but you can create a model
with Co clean another model with groovy
another one with Scala another one with
Java you can do that because then
everything is compiled and run in the
JVM and also you can just polyglot DB's
I mean I show here sequel but you can
use sequel plus MongoDB or sequel plus
new 4j or whatever so you can use no
sequel databases or polyglot databases
and your monolith as well finally one
thing that my College Board says or
shows is kind and name of digital
Darwinism and let me tell you something
that it is not ready with technologies
like okay we we are in the B parallelism
way so when we start you know working
with two legs we had two hands-free so
we can manipulate things right but it
has been discovered that we can
manipulate things not because we are
bipedal ISM but because the brain before
we walk into legs start changing
something in the brain so we when we
became people ISM we can move the hands
and you know take things and carry
things so there was a preparation before
the pedal ism for so you acute and
manage things and this is exactly the
same you cannot go said yeah I'm going
to do micro services and that's all now
that's not happening that way this is a
path for this the first one that you
need to this reorganization to the pub
so you need to be able to develop and
deploy and release quickly seven several
times per day or several times per week
but not every six month because if you
release every six month in with
microservices your continued releasing
every six months so you need to arrange
the ropes
then you need also to move to a
self-service on the man elastic
infrastructure which basically means
like I remember in one company that they
said I need a post great sequel server
for running some tests and said yeah you
will have it in one week so this is not
how it worked I mean that I want to post
great sequel machine to run my test so
I'm going to page and say I wanna pause
great and with five seconds I have my
server running there this the next step
you need to automate everything just in
puppet Jeff uncivil or cubanelles
whatever but you need to have your
deployment process automated move to see
HDD deployment pipelines you need to
define a poram pipeline which automates
everything and then you have your
application you said this is application
that I want to deploy I'm going to run
the test run the exception test someone
decided go to production
I pushed the okay Baba tonight go to
production next thing is this advancing
deployment techniques that I'll show you
after that when you have everything
automated and it's deployed to your
cluster then you said I'm going to try
Bluegreen deployments cannery releases
or there are crunches and you get some
knowledge about that and finally you're
gonna start micro services when you have
all this thing you can start deploying
micro services doing micro services and
you it will be a success if you don't do
it in that way it's you in your in the
near future right all the containers
that are blowing you know you don't know
what's exactly what is happening and
trying to you know fight it of doing
that firefighter thing lasting important
thing you know a stack overflow
yeah I think that this stopper a stack
overflow is down down it's time for a
coffee right and this is the page and
maybe you said yeah it's pretty cool you
have like a stat service you have the
user service you have the hour service
the question service with the thing and
then you have the advertised service for
that right it seems that for the amount
of traffic that Stack Overflow is
receiving and this layout it seems that
it's like perfect for a micro service
architecture right the trees that no
it's a monolith all stack overflow its
monolith application with ten servers
load balancers and so on so far but it's
a monolith there is no micro service
architecture
and they are serving all all requests
all our answers all our questions were
everything with a monolith so it's not
necessary to move to a microservices
because we want it just because we need
and one of the important thing is that
please one day go to the bottom of the
page of a Stack Overflow and you will
see this number and you see that maybe
every hour it changes like three or four
times so they are deploying 10 15 20
times every day I don't know how many
times but they it's a monolith so you
can deploy several times using monolith
finally I take this quote from Spock
that is like long live and prosper to
tunnel it because as you said it works
and that's all if you have any question
you can send me an email or just tweet
me thank you very much well if we have
two minutes if there is any question
pocket right thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>