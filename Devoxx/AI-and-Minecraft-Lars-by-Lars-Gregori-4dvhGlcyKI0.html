<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AI and Minecraft Lars by Lars Gregori | Coder Coacher - Coaching Coders</title><meta content="AI and Minecraft Lars by Lars Gregori - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AI and Minecraft Lars by Lars Gregori</b></h2><h5 class="post__date">2017-11-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4dvhGlcyKI0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay now welcome to my talk
AI and minecraft my name is my name is
sorry my name is Lhasa I'm working at
sapa high press at the hyperlapse team
and what we are doing we taking sa p
hyper software taking new technology
around it and building prototypes so
most of the time we're building
prototypes and also thinking about some
gamification how we can do something
like someone have to find something in a
shop in a retail store or something like
that or using batteries and coupons are
also something like going to the
gamification on the other side games are
getting more serious now with all the
eSports stuff yeah people can live on on
the money day or running with eSports
and I also try to do some serious stuff
with Minecraft and so I can do it in in
the office also not at home just playing
around also in the office so two years
ago I visualized IOT data like
temperature light on Minecraft and also
build up a shop inside of Minecraft
which communicates with our Year
microservice platforms with rest calls
and today AI and minecraft which also
looks serious so how do we get there
first of all I will explain what
minecraft and talk about the project
Mountain
next one will be reinforcement learning
and introduction about this and at the
end I combined both together so AI at
minecraft together
minecraft itself was created by Markus
notch Persson he founded mowing yep
with one of the or it's the best-selling
PC game of all over time 226 million
copies have been sold and three years
ago Microsoft bought it for 2.5 billion
the company not when
Beverly Hills and bought a villa for 70
million and then recreated all the house
in Minecraft so he's still with
Minecraft but now has a real house and
one in Minecraft it's a sandbox
construction game so it's about
creativity and building aspects and you
have the three-dimensional blocks where
you set up all the world you have to do
some exploration like finding a village
or finding some iron diamond and with
all these resources you craft together
in new tools and there are also some
combats about it so the best thing is
for those who have never saw minecraft
before I show a demo about minecraft so
minecraft itself have a single player
and also multiplayer mode and therefore
you can also have create new world you
are you have in survival mode and also
creative mode the survival mode yeah you
have to survive so there are zombies
there are skeletons and creepers running
around in creative mode you can fly
around also and build nice houses and
everything so there are lots of things
in the internet I will do a survival
mode call it their works and have few
more options and I figured out when I'm
using their works here as a seat code
the minecraft takes the seat code for
the random generation stuff and
everything and now it's creating the
world and we will spawn nearby a village
so normally you have to run around and
find the village and everything but now
we're spawning well on a tree that's
cool how do I survive you know ok didn't
expect this yes still alive ok yeah
here's the village so everything fine
survived ok and the idea is
you top down first a tree by hand like a
ninja or something
this makes on this case it doesn't
really make sense but yeah at some point
you have to start and then out of this
you take you build some planks and with
these planks you can do for example a
crafting table and drop this table here
somewhere
and now we have more possibilities so
high current can create some sticks I
need some sticks for this and with this
sticks I can build and UX and luckily
with this new eggs
it makes no more sense now I can chop
down the tree a little bit faster later
on you find some stone and some iron and
with the diamond you're super fast then
okay so that's Minecraft now the protect
mount so project Mountain is an
open-source project it's for microsoft
research lab in Cambridge and yeah
minecraft itself it's not open source so
this is this is still you have to buy
pay for it and but my memory is
open-source and minecraft forge is in
community project which is doing modding
stuff for Minecraft so it's one of the
greater modding frameworks where you can
change the behavior and malmo for
example is doing this for you have some
mission xml file will create the world
easily and get the world state this
means you know where your agent is and
also can send commands like move forward
attack something jump
we will see some later on summit
example and the agent itself can be
written in patent
yeah it's machine learning so everything
has to be written in Python
I have the feeling if you write some
hello world program it's already a
machine learning like because you're
using it with Python yeah then it's also
possible in Lua C++ C sharp at Microsoft
a UC sharp Java also because minecraft
itself it's written in Java so the
modding framework itself it's not
allowed to distribute minecraft itself
it downloads the charm file unpacks it
and just put some hoops inside of it and
there's where among we are also adding
some hooks inside of it then it's also a
torch which is like machine learning
framework like tensorflow but it's
written in in lua so you write that code
in Lua and our card learning environment
I have lighter one and bigger about this
ok let's take a look at some example so
this is Python file here you can see it
your import simple import no strange
stars or something in inside of the pipe
file you can define XML with the mission
if it name for example and here is some
generate generate a string for all the
layers you setting up so in this example
it will be nice colorful layers and then
we draw a sphere inside of this so you
see all the layers and also there will
be some lava which shouldn't fall in
obsidian and the diamond block damn
block is the gold weather agent have to
run through the agent itself can get a
name position and it also gets in
pickaxe as inventory what else
oh yeah the game itself or the mission
it ends when it reaches the time will
block
so let's run this I think it's this one
year tutorial and now in the background
was this yeah
starts grunts dicks and again and now it
terms and founds the diamond block at
this point this is not had nothing to do
with with machine learning this is trust
I'm sending commands to to the agent so
this part is here so first of all it
takes the pickaxe from the inventory
looks down and I have put here up sorry
then adheres for a second so you can
enjoy the view and then just moves and
attacks and there's also some obvious
observation here so when it takes lava
it jumps when snow not lava anymore it's
ops stops jumping so one more to see it
again so it looks down four seconds so
you can see the nice colors and now it
takes and digs find lava charms done but
there's no no intelligence about this is
the intelligence is how to write this
and this is some part of yessum tutorial
but they are already solved problem
exists so for yeah for machine learning
there's some part with reinforcement
learning
so what's reinforcement learning so we
have on one side the suppose supervised
supervised learning yeah right so this
is the part where we have some
classification with our cats and dogs
our pictures we run this this all day
and try to figure out what's a cat
what's a dark and then we go home and
then we know okay we have a dog at home
big profit we learned this supervised
learn unsupervised learning self use
unstructured data so there and inside of
this data you try to do some
classification and clustering and try to
get some prediction out of this data and
third part is reinforcement learning the
reinforcement learning we have an agent
and some environment an agent sends an
action to the environment and the
environment sent back in reward and the
observation and depending on the new
state the agents getting out of this
from previous action it will try to find
a better action for the next step and
then it gets it again a reward and
observation and that's where it learns
it so reinforcement learning is like
trial and error learning it's like when
you learn a new programming language to
compiler or interpreter will tell you no
that's not the way you miss something
yeah and yeah so right that's where I
learn programming languages there's a
book from 1998 from Richard Sutton and
Andrew Barton and they have an example
inside of it the cliff cliff climbing
cliff-hanging cliff something with cliff
I would know it moment and there's also
some formula for you learning um I have
patent code for this so I think it will
be more readable than this one let's
take a look first take a look at first
let I just run it wait I need to know
what's what's the thing
cliff walking is it so it's a cliff
walking example and we have it here with
six and now it starts here
building up the world
hopefully not crashes okay so in this
scenario we have some lava which is not
good because our agent is dying on this
so sorry for this maybe I should put on
some warning on it and and this inherits
it's just random walking so it doesn't
learn something it's just falling most
of the time into lava but yeah so this
just makes no sense to run here in the
next step it will get some reward out of
this it's a little bit more intelligent
but it's only getting a reward so for
each step it's taking getting one mine
and one minus one as a reward falling
into lava will be minus 100 and one of
them reaches the blue box in the in the
end it would get 100 but now it just
figures out you can see it here on the
left side where the lava is but it's
also it wolf at one point it will find
the blue box but that's it doesn't have
to learn something out of it so now we
take step four no three
and at this point is yeah doing Q
learning yeah oops we are just running
around a little bit so in the beginning
it also tries to figure out where the
lava is so it this agent has no idea
what's lava is about it also doesn't
have some idea what north south west and
east is so it falls for example in the
lava when it moves north in the same
situation the same lava block it falls
into when it goes east and now it learns
and learns and at repeat 21 it will find
the blue block yeah we have to wait a
little bit so as I told the report for
each step will be minus one falling into
lava minus 100 and the blue block will
be 100 the golden block it will never
reach the golden block will be 500 so
this that's one of the problems here you
can play around with alpha and gamma
with the formula I will showing later
next on so now it got the blue block and
now you can see yes sir
yeah green dot will move further and
further to the beginning so now it falls
into lava once again there's one block
I'm also missing this one yeah okay
and now it learns the way back okay now
it knows three blocks four blocks a lot
of look no it takes the middle block one
point no 35 it should know most of the
way back and wait it's doing this it's
learning so now it got way out learns
how to how to find this block here you
can also see the numbers so the block
before the blue block is 99 then 78 61
and so on so now it gots the way the
best way to figure out this in an
unknown territory let's take a look at
the code so what we want to do is to
fill a cute table with the previous
state and I'm in the previous action so
when we standing in front of the blue
block and moving east or you view on
this side
I will get in reward of 100 for this and
I want to know
to calculate the block where I'm
standing in front of the blue block so
this is the previous state and therefore
I'm getting a new cue in the previous
example it was just the old value so it
doesn't learn something or only the
reward but with this year I take the old
value and the reward which will be in
this situation 100 for the blue block
then a maximum Q which will be the
current state so the blue block has no
value at the moment because it's new and
at this point it also stops so it will
be 0 then minus the old value which was
minus 1 and also with this and with some
alpha and everything so we're getting 99
at this point and now we are running a
starting from the beginning and in front
of the yeah yes here's the blue block
I'm here for the blue block and I want
to calculate this block here so I can
show it if it still runs yeah this block
here so the old value is still minus 1
or some some value around minus 1 I will
get in reward only for minus 1 because
I'm moving one up I have some reward of
minus 1 but the maximum Q value of this
the current state so this is the block
I'm standing in front of yeah if the
blue block and there's the maximum value
is 99 and this one is multiplied by
gamma I just choose 0.8 so getting a h %
reward out of this maximum and then I
subtract minus 1 and everything and so
this is the value of 78 and with this
the value is back propagated to the
beginning so you start with 99 78 and
everything
still running yeah can stop it so here
we have ninety nine seventy eight and so
on and that's the way it learns to find
the blue block but one problem is here
if this one year so it never reaches the
golden block which is five hundred
because it's too complicated to find it
out there's some random movement inside
of it but it I tried it I didn't get a
curve around it so this one problem and
also everything we learned here is only
possible for this ya map and it's not
I couldn't take this one and and create
a new map it wouldn't work because it
doesn't really learned what slava is and
it doesn't really know what what's the
golden block and the blue block is
standing for so in this case we need
something different and this is called
deep reinforcement learning so we are
trying to learn with images so now we
are having the yellow part here so it's
reinforcement learning and supervised
learning with supervised learning we can
take its with the classification with
the dogs and cats so we take some images
and we know we just start everything to
learn so it at one point it learns it
will be getting 500 points out of the
yellow block so we have different Maps
different scenarios and we'll learn with
the golden block it will be 500 blue
block will be 100 and also am stores the
video out of every run and the reward
and a movement and then we take this
information and do some yeah
normal machine learning like on on
images so we get the classification and
the images and out of this it will learn
that a a golden block will be more worth
than a blue one
and when we started to run it will did
look for the golden one and find this
one so that's the way deep reinforcement
learning is working and yet deep
reinforcement learning is best known by
a deep mind with alphago but they also
started with their what's it le are tied
here are cut not Atari I always have
Atari which is nearly the same but
arcade learning environment so here's an
example for breakout which runs on on an
arcade machine and the only information
they have about this is the points the
scoring points and here the lives which
are five at the moment so this is just
some memory value inside of the RAM so
you put in an coverage this were loaded
to the RAM and inside of the RAM you
have two points the lives and also the
video data and then they took this out
and have the movement left right and
idle for example and out of this they
train the machine and here I haven't
video so this about 100 trainings still
a bit stupid but hits the ball doesn't
move twenty trainings a little bit
better yeah and 400 is getting more
better
so in this case they just move left
right and try to figure out yet the
reward will be on if if its goal yeah
lose at 600 it learnt that it build up
in tunnel and then you can throw in the
ball here and based out of this idea
alphago was also created and now they're
playing around with Starcraft 2
they've open API for this and I just saw
that Starcraft 2 will be a free play
game free to play game next week so
could be interesting to play around with
this okay yeah in at the end I thought
okay we have this with the deep
reinforcement learning we just run
around have no idea of where where the
thing is running around so my idea was
what happens if I just take the yeah
from the beginning this example where
chop down a tree and yeah let it just
run and it chops it just down it's just
some some idea so now it would the next
step would be it tries to learn
depending on on it hasn't three now and
do some yeah building some tools out of
this creating new new environment and
everything creating a house or something
and it would be interesting to see such
thing to develop this and you only need
to tell out yet like a stone axe is more
worth than a wooden axe so you have to
dig around and find some stone therefore
you need to pick ax or something and it
just have to learn it like our pickaxe
is more worth at a stone pickaxe moveth
and wooden pickaxe and everything and
the interesting part would be if you
just yeah set up everything and would
run this half a year and then take a
look what yeah what has this agent built
out of this for example you have it
built maybe in neuschwanstein or how do
it survive against the monsters and and
you also need to do some farming and and
you have with animals and everything so
yeah this would be interesting to see
and go further with this and the same
idea is also with a stark of two but
that's not the topic yeah so that's it
thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>