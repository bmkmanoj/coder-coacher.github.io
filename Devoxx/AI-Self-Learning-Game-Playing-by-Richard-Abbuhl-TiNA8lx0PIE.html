<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AI Self - Learning Game Playing by Richard Abbuhl | Coder Coacher - Coaching Coders</title><meta content="AI Self - Learning Game Playing by Richard Abbuhl - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AI Self - Learning Game Playing by Richard Abbuhl</b></h2><h5 class="post__date">2017-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TiNA8lx0PIE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I think welcome to everybody thanks for
coming and enjoy your lunch
it's McCulloch I'm going to talk about
self learning game playing today and
basically gonna go over some what's
machine learning and why it's important
game playing is important a bit of the
history of machine learning and some of
the games and machine learning that that
are being have been a machine learnings
been used and also going to talk about
alphago because that's one of the most
more important things that's going on
right now with machine learning talk a
little bit about myself I'm from San
Diego originally I studied there I did
my thesis back in the 90s and I studied
back propagation I ran into this
professor at the University and he gave
a talk on machine learning his name's
Robert heck Nielsen and he started a
company called HNC software and I ended
up working there and we created a
product called database mining marksmen
it was written in C C++ and it had a
board in it and basically we sold it for
$50,000 so it gave you the power of a
Cray in a in the computer that time was
just 386 or 46 they snap processor when
to Gordon Bell award because it because
it performs so well in that
configuration I live in the Netherlands
I'm a C++ Java guy more Java and also
angular and doing stuff with polymer so
I'm not a data scientist more of a
computer scientist I like this stuff
married with five kids and four cats one
just unfortunately passed away and they
also play a bit of music so before we
start let's talk about what's machine
learning and what it means to you you
hear these days like the last talk about
driving a car use machine learning you
can use it for playing games like
alphago some of the people who are
critics of machine learning and AI say
well okay make a machine learning an
algorithm that can tell a joke or tell
the story so there's people that think
machine learning is really far along and
some people think that it really hasn't
gone anywhere at all I tend to think
about machine learning as making a
prediction
and I got into a game playing because in
the 90s I finished my thesis and I had
back propagation and I bought a laptop
and then I don't have any data I had the
small laptop 10 gigabytes so I started
playing around with games and I could
generate like 4 tic-tac-toe and let it
play for three or four days and to see
what I could come up with for the
results and if you are into machine
learning the thing you'll learn right
away and you can see if you've gone to
other presentations is machine learning
loves lots of data and the more the
better excuse me I want to go back and
talk a little bit about the history of
machine learning because I think that's
important to look where we're going and
and what the developments are so back in
the 50s one of the first people people
who did something with machine learning
and game playing was Samuels and he
invented alpha-beta pruning so it
basically made a tree and he figured out
I can prune off some parts of the tree
and make the algorithm faster and
another guy was Rosenblatt and he
invented a perceptron and that started
getting funding for neural networks but
this clever guy Marvin Minsky at MIT
wrote a book and said well your
perceptron may take over the world but
it can't solve this simple problem so at
that point the the funding for AI kind
of dried up and I went more for expert
systems and then the 80s at UCSD
I don't know one's probably ever seen
this book has any of already had the
parallel distributed processing book no
one's ever seen this this was the book
that in it had the algorithm back
propagation and that led to a rebirth of
machine learning and you also have
Watkins developing cue learning and then
there was a book the first version of
reinforcement learning so you had the
basis now for what's modern machine
learning these two algorithms back
propagation which is used a lot like in
tensorflow
and then you also have the reinforcement
learning which isn't using alphago
I like I said I played around for about
three years you can see there's dis
there I still have them for when I was
playing one of those is from one of my
colleagues he did his PhD thesis on
temple difference learning and go I
never did anything with that this but
it's I still have it and and you had to
sorrow - sorrow was an important name
which people don't associate with
alphago he basically used a neural net
to learn to play backgammon and he got
okay results and then he tried self
learning game playing with backgammon in
the end he got it to play at a good
level and then IBM they attacked the
problem of chess but they used brute
force search so they just threw a lot of
hardware at the problem and they ended
up using alpha beta minimax which is an
older algorithm so you can really get
good results if you have a lot of
hardware with just a brute force um oops
oh shoot my Microsoft just crashed I'm
gonna sorry
when I moved to the Netherlands I liked
this algorithm that Tesoro had done and
I thought you know I'm interested and I
wanted to play around with it so I I got
q-learning and and some papers on it and
I wrote a version of cute learning and
did it for a while I had again a small
laptop and just ran ran it and was able
to duplicate the results so without
having any data it just self learns in
self plays but I had a girlfriend that
at the time and she didn't like that I
was doing this in the evenings so I kind
of cut it off but I did try to publish
the results but no one really no one
really knew what the power of this
algorithm was that I was told I have a
solution with looking for a problem
anyway so you have these other different
types of things like a deep face and
eventually alphago and I have nine
minutes left so I'm going to go pretty
quick this is the basis of machine
learning you have neural network
feed-forward you have one normal one
layer of multiple layers you feed it
patterns and then you just train it so
you loop through the patterns and it
learns those patterns and if you're
lucky it generalizes so you go through
and just yeah the more patterns that you
have the better because it doesn't learn
anything outside of those patterns you
teach it so for instance a famous X or
problem you have one or other or not to
both and with a back propagation you can
learn that but you can also learn more
complicated problems
Robert heck Neil said I remember him
talking a lot about this so if you have
any set of inputs and outputs you should
be able to map the two between them so
there exists for any two sets of inputs
and outputs a mapping between the two so
that means you can solve a lot of
problems again to sorrow use this
approach he first taught hit TD gammon
with with the neural network and then
later on he went and used reinforcement
learning
you can I didn't I emailed with him at
this time when I was doing mine because
I had some problems but I didn't notice
until way I went back
read it now that he did a two-place
search so he did it to look ahead and
then he said if I had three I could have
done even better so I think he had some
hardware limitations at the time and
reinforcement learning is a little bit
of a different algorithm it learns on
itself I'm gonna give a demo really
quick and and for tic-tac-toe you
basically with q-learning you go through
and you loop but instead of using
patterns you play itself so you you make
a move you adjust the the states you
make a movie of justice HC and go back
and forth but it does it learns outside
of the normal patterns because you use
randomness you don't always pick your
move you do you pick a random move and
keep going and again for for tic-tac-toe
there's 20,000 States for backgammon
there was quite a lot more and I'm gonna
quickly do a demo hopefully you can see
this
yeah okay
you see this guy okay don't they I don't
here we go sorry okay so for training a
neural network you can basically say je
prac prop and you give it a pattern XOR
that's rain and yeah this this was a
networking it and it's learn to play and
then I did that approach for a while you
can see that the patterns I generated
back then or like this it's a set of
inputs and then it had a measurement for
how good the move was going to be so I
generated a lot of different I'm sorry I
apologize I haven't said it correctly
all right you maximize this so yeah
that's the inputs in the output so you
can do that to play a game you can
generate lots of patterns and then
okay and I'm gonna go to the demo so I I
have a journey so I have q-learning here
this is and I trained it here there's a
Hugo SH and basic that loops through and
it goes does a lot of tries and it ends
up and I figure out what the best is and
you can see here in the end you have
nine it went swinging 99% of the time
when it goes first and wins 25% of the
time so I wanted it to be a hundred
percent so I was emailing to sorrow and
I said what do I do and he's I figured
out you have to do a look ahead so and
then I'll give you a quick demo of this
so again it only I'm gonna have it so
first it goes first and I play so do a
new game so so I won but if I make it do
a look ahead and I used a minimax in a
way then it does pretty well so in the
end even though it only well it does 99%
of the time it ends up playing a game
that's perfect okay
so alphago is a lot more complex I think
it's a pretty simple algorithm but yeah
you can self learning is a pretty simple
algorithm I won't have time to show you
the algorithm but I wanted to go over
this Monte alphago basically uses Monte
Carlo tree search and neural network in
reinforcement learning so they have one
network which they ask what's the next
move to make and it gives an answer and
they have another network which predicts
the winner of a game and they train it
for the policy network by using it 30
million moves and then eventually they
use reinforcement learning and
reinforcement learning is good because
it will sometimes make random moves and
they use the Paulista Network to train
the value network and I'm sorry one
thing I wanted to point out is the
Paulista Network ends up being so good
that they can use it without using look
ahead and it beats other algorithms and
then again the I'm gonna go fast so that
Monte Carlo Tresor it's they're able to
make this big tree and they combine
these two networks they basically ask
what move to make and how good can it
win and they're able to go through and
come up with a good answer which in the
end yeah that's some play that at a
really good level and yeah for those I
skipped once quite the yeah normally
they use a lot of hardware and so forth
a lot of CPUs and for the game against
fun here they use really a lot of a lot
of hardware and then that's alphago the
thing is it made a big leap forward when
they basically don't use neural networks
at all they only use reinforcement
learning so they didn't use any training
data they basically it plays against
itself and I wish I had time I could
show you the algorithm but I don't but
yeah it just they they started playing
and it does self learning by playing
against itself a lot of times so this is
a big thing we can use this algorithm
and other other applications where you
can learn by self learning and that's it
and there's also a lot of stuff out
there you guys can check out you got
deep learning 4G and so forth
play with this a little bit but I tend
to prefer to write my own software for
playing with this I got 30 seconds any
questions from anyone
no questions okay thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>