<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The New HTTP Client API in JDK 9 by Michael McMahon | Coder Coacher - Coaching Coders</title><meta content="The New HTTP Client API in JDK 9 by Michael McMahon - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The New HTTP Client API in JDK 9 by Michael McMahon</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gc6upLx7eog" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay good morning my name is Michael
McMahon I'm from the Java core libraries
team at Oracle and I'm going to be
talking to you today but the new HTTP
client API that we're developing for
Java so first to get this disclaimer out
of the way which we have to include all
the time so this presentation is for
information purposes
there's no commitments to to produce
anything it should be taken from this
presentation okay so this is the agenda
so basically I'm going to cover these
three or four topics first of all I'm
going to just give a brief introduction
to HTTP two and then go over the
similarities and differences between it
and HTTP 1.1 and then I'll give a quick
introduction to the the completable
future API which is quite that this HTTP
API makes a significant - you solve it
then we'll go into the HTTP API itself
and finally then I do a little bit about
the flow api which the HTTP api makes
use of but it's it's it's sections three
and four more or less the same they're
the same topic
okay so straight into the first section
so HTTP - what what are the similarities
first of all well if you consider HTTP
as a kind of as a service or an API then
HTTP two is pretty much the same as HTTP
one in particular the request methods
guest get post put delete etcetera they
all have exactly the same meaning in
HTTP - request and response headers like
content length cookie contents encoding
they all have exactly the same meaning
in HTTP - as in HTTP HTTP 1 it also has
exactly the same request and response
structure
an internal quest response exchange
comprises a single request potentially a
number of intermediate responses though
usually none followed by some fry a
final response and then also you have
requests in response body data depending
on the request method requests or
responses can have associated data body
data associated with them so that's all
exactly the same so what's different
well the biggest difference obviously is
the protocol it's completely different
not backwards compatible at all except
insofar as as a mechanism has been
defined to allow an upgrade from an
existing HTTP 1.1 connection to to http
2 but otherwise the protocol is totally
different and the biggest difference
probably is the way that HTTP 2
multiplexes multiple requests answer the
same TCP connection while avoiding the
head-of-line blocking problem that HTTP
1.1 pipeline requests had so just to
explain what that means with a little
illustration so with 1.1 if you if you
send 3 requests as shown here request 1
2 and 3 on the same TCP connection in
sequence that the responses must come
back in the same order so response 1
must come back first then response 2 and
3 and what happens if responsible and
takes a significant amount of time to
generate well that's too bad response 2
&amp;amp; 3 just have to wait until until that
happens so HTTP 2 deals with that that
problem
by basically been having a very thin
layer framing and streaming layer on top
of TCP and I'll just describe a little
bit give you an overview of that each
stream each request and response
interaction is given its own stream and
each stream is uniquely identified by by
a number and you can see their requests
1 2 &amp;amp; 3 have been given stream IDs 3 5 &amp;amp;
7
so all frames all messages so
with the stream have a have a stream ID
so they're identifiable and streams are
also independently flow controlled
that's that's a significant point as
well as well which will command to later
so you can see here in this example it's
possible to send back response to first
then response 3 and then response 1 so
therefore it's this whole head-of-line
blocking problem that that you would
have seen with HTTP 1 so what else is
different
well cancellation it's possible to it's
possible to cancel requests efficiently
now that was possible with 1.1 but only
at the cost of closing the TCP
connection which obviously means you
incur the overhead of
reopening a TCP connection for for
following connections or following
requests but in HTTP 2 there's an
explicit mechanism for resetting one
stream on a connection independently of
the others but probably the most
interesting feature of HTTP 2 and it's
really the only one with a noticeable
footprint in terms of API is server push
and this allows allow servers to push
resources directly into into appliance
cache now it's not a generalized push
mechanism it's it's pushes are always in
the context of a requests that have been
initiated by a client and so the server
will only push resources that it knows
the client or strongly suspects that the
client is going to ask for anyway and we
will see the primary use cases for that
later on and what else is different
maybe smaller features HTTP 2 allows you
to prioritize requests so they can be
prior given a waiting relative to each
other you can express dependencies
between different requests it's quite an
elaborate scheme and remains to be seen
how how widely is that becomes then
there's also a simple keepalive
mechanism based on on ping frames and
thirdly a very significant feature is
header compression there is a
specification called
H pack which defines how
headers are compressed it's quite a
quick complex system but it's defined in
such a way that receivers or decoders of
headers can be implemented fully
compliant and relatively easily whereas
encoders have a wide variety of
different strategies that they can
employ but it's it's from relatively
simple encoding and compression
techniques to somewhat more complicated
and finally the probably significant
difference since the fact that HTTP 2 is
a binary protocol whereas if you're
probably familiar with traditional HTTP
it's based on ascii strings with
carriage return line feeds that kind of
thing so what that means is you know
when you're if you're debugging an HTTP
connection you won't be able to just
look at a text dump and figure out
what's going on particularly with
respect to H Park it's impossible to to
understand just by looking at the bits
what's what's going on with H Pak you're
going to need tools to to be able to
decode HTTP to headers let's just take a
quick look at the HTTP to frame
structure each frame comprises a fixed 9
bytes header followed by a frame
specific payload so those 9 bytes are
this first the first 3 bytes are a
length length field so you have 24 bits
of length then you have a type field of
8 bits now I think there are only
roughly ten frames defined at the moment
so there's plenty of headroom there and
then there are 8 bits allocated for
flags and again I think only each each
each frame type specifies what whatever
Flags can be specified it can be
employed with each with that frame and I
think only up to the maximum number of
flags that are used as is 3 I think and
then finally the final part of it of the
header is the stream ID which it uses 31
bits of the of the last 4 bytes
stream IDs themselves as you saw earlier
the the 4 client initiated streams
they're always odd numbers start
everyone for the first request sent on a
connection each successive request
increments the the last students stream
ID by 2 so it goes 1 3 5 7 9 etc and for
4 server initiated streams 4 4 4 server
pushes they use even numbers starting at
2 so 2 4 6 8 etc so let's take a look at
a simple interaction request in a
response in terms of frames so on the
top there we have a request sent from
the client to the server and it
comprises a headers frame so every
request begins with a headers frame if
all of the headers don't fit in the
headers frame then there may be zero or
more continuation frames but they're
they're optional and then if the request
contains body data then that would be
followed by one or more data frames and
you can see there this is the because
data is flow controlled the server needs
to send window updates if if there's
going to be a quite a significant amount
of data a sliding window a flow control
scheme is used quite similar to the one
used in TCP so that that's that's how
the server regulates the amount of data
that the client is sending to it and you
can see then from the response that the
response use is exactly the same frames
which are sent in the opposite direction
so the other frame types which I won't
go into in any detail except maybe for
push promise these are the other frame
types which are mostly self-explanatory
except maybe settings settings frames
are exchanged at the beginning of a
connection in order to to establish the
parameters such as buffer sizes and flow
control window sizes that kind of thing
but I think the other the other frame
types are probably self-explanatory so
just to maybe show a comparison of a
request with between HTTP 1.1 and have
the same request would look in HTTP 2 on
the left hand side we have the
traditional familiar-looking HTTP 1
request
so what we have is a
get of a /resource with with two headers
host and accept so how does that look
then and HCB to will in this case we
have a single headers frame and it has
two flags set the end stream and the end
headers flags end stream signifies that
this is the final frame sent by this by
the client on this particular stream so
there are no more frames to follow this
one and that's simply because it's a
request with no no no no request body
and the end headers flag is set to
signify that all of the headers are
contained in this for in this this frame
or at least there are no following
continuation frames you can see also the
the same two headers host and accept
header names are always lower case in
HTTP to that's that's one significant
feature and then you can also see that
the the meta information that was
encoded on the request line in HTTP 1 is
encoded using special what are known as
pseudo headers in HTTP 2 and these are
headers with predefined names that
always begin with a colon character so
what is the response look like so let's
say on the left hand side we had the
traditional HTTP 1 response which is a
200 ok with with 2 response headers
content type and content length and then
followed by hundred and twenty three
bytes of binary data so in this case we
have a headers frame with this time only
one flag is set the end stream flag is
not set because this is not the final
frame of the stream from the server but
the end headers flag is set because all
of the headers are contained in this in
this frame so we see the same content
type content length and then a pseudo
header signifying the status code which
is in colon status and then following
this is a single data frame with 123
bytes of data and this this frame has
the end stream flag set so you can see
it's a very tightly defined protocol
there's not really much room for
ambiguity with HTTP 2 and in
in the way that sometimes was possible
with HTTP 1 let's take a quick look at
server push then at a high level and how
does that work so if a client issues a
request in this case this example I'm
saying it requests a resource their food
out HTML from the server so the server
yes sir receives a request and it looks
inside the resource the the food of HTML
and it sees okay there are three
references inside that HTML file to
resources that also exist on this server
so the plant is probably going to need
those those resources so I'm going to
push those resources back to the client
before the client even knows that it
needs them so that's that's the general
idea of the main use case for a server
push even though there are there are
other use cases and then file then it
would send the response now as I said
that's a high level view what actually
happens is is slightly slightly more
complicated which we'll see in the next
slide so it's actually a two-stage
process what happens first is the the
when the server receives the request it
actually sends push promised frames back
to the client saying okay I have these I
have this resource I'm going to send it
to you unless you say you don't want it
so so those those push it's those push
promises that inform the client that the
that these resources are on the way if
you want them and the Defiant has the
opportunity to to reset these frames
because you can see each push promise
contains a promise stream ID so it's
possible for the client to cancel those
sort of reset those promise streams if
if the client doesn't want to receive
the data if the client doesn't do that
then the responses will eventually
arrive on the relevant stream okay so
that's that's a real high level view of
HTTP 2 so let's go on quickly to the
computable future API
so basically computer future really is a
it's a framework for asynchronous
programming but rather than being based
on callbacks or the kind of thing it's
it uses what's known as a continuation
style which is a style of programming
this looks somewhat similar to
traditional blocking or synchronous code
but while maintaining you know fully
asynchronous capability well it looks
defined exactly what I mean by that in
some examples further on but in
particular specifically a computable
future implements the java.util
concurrent dot future interface which
has been around for for some time and it
provides a standard api for completion
so it guarantees that a computable
future objects can only be completed
once it can either be completed normally
by providing an object of the type that
you're expecting errors of the results
type that you're expecting are asset of
complete exceptionally with an
exceptional or throwable of some sort
computable feature also implements the
completion stage interface and this is
the interface with a large number of
methods that provides this what I'm
describing as the continuation style of
programming and it also implements very
static methods for creation of of
completable futures and ways to create
aggregated completable futures which we
will see in some examples further on so
what can you do with this with this
class let's just take a simple example
so let's imagine that we have a method
of some class and the method is called
load it takes a URI so instead of just
blocking and returning some objects like
a document this works asynchronously and
returns a computable future of documents
so so when you call load it just returns
immediately having started the load
operation in the background on a
background thread it returns your
computable future object which so what
can you do with that the simplest thing
you can do with this is just call get so
that blocks and effectively emulates
traditional blocking behavior which
not very interesting but when you call
us it blocks and returns documents RS
will throw an exception if it throws an
exception that means the computable
future completed exceptionally so let's
look at a more interesting example so
let's say we start off the same way we
call this load method which returns a
computable future of documents but what
we're going to do here is we're going to
add a second stage by calling then apply
a sync which is a method of completed
for the future and what that does it
adds a second a synchronous stage to
this operation so you're the first stage
it's the load and the it the second
stage takes the output of the first
stage which was a document and it in
this case in the simple example it calls
it creates an image object and that's
assumed to be something that takes a
significant amount of time and is
arranged to execute asynchronously but
what you can see that the return type of
this is it's no longer a computable
future of document it's now a computable
feature of image and that's that's just
a consequence of the way these types are
are set up so let's then add a third
stage so in this case third the output
of our the input to the third stage is
the output of the second stage which was
an image and in this case we just simply
display we display the image that we
have received and in this case there's
no there's no return value so the the
aggregated result of all this is a
completable future avoid so you can see
here that it's possible to to combine
multiple asynchronous operations to
create some kind of higher level
abstraction that maybe hide some of the
details that you're not interested in
you know at the end of all this assuming
that the computable future let's say we
yes when we call CF dot join which is
very similar to the GAF method if that
doesn't throw an exception it means that
all three of those stages succeeded if
any one of them threw an exception then
that joint method would throw an
exception and you could
to see what the what the actual
exception was so with that brief
introduction to a continual future I'll
go onto the HTTP API itself so first I
want to just talk a little bit about the
status of this work the the API and the
implementation are still wonder active
developments as part of JDK 9 but we've
kind of decided we need a little bit
more feedback how it's currently it's
currently integrated in JDK 9 but we're
still working on us what we're
considering doing is moving it out of
Java SE and into what we're calling an
incubator module now you probably
haven't heard of this before because
it's a brand new idea that were just
contemplating but the idea is that it
would be it would remain part of JDK 9
fully visible and usable but not part of
Java SE and in particular it wouldn't be
a standardized API wouldn't wouldn't
there isn't a commitment that it will
never change so the idea would be that
that the API the implementation can be
used in JDK 9 and then standardized in a
following release hopefully 10 so as I
said this is a just it's just an idea
that's been floated at the moment or
will be soon but it's not hasn't been
widely discussed yes or certainly not
approved so but if you're interested in
this I just keep keep an eye out for it
so yeah one other thing to mention is
that up to now the the this incubator
module idea will have a own specific
namespace so up to now we've been using
java.net HTTP for this work but that
would be different if it's if it moves
into this incubator namespace so once
the API itself well it's a relatively
simple API these are the lists there are
the classes that you will most likely
encounter for a very minimal application
really all you will need will be the
HTTP request and it's builder class they
HTTP client and it's builder and then
the HTTP response
now there are a number of others which
we will also have a look at so the API
and the implementation supports both
HTTP 1.1 and HTTP 2 but from what we've
seen earlier you would expect the API is
mostly agnostic about about the version
so let's take a look at a simple example
so building an HTTP request how do we do
that well it follows standard builder
pattern a static method on HTTP requests
called new builder takes takes a URI
and returns an HTTP request dot builder
object and then that builder class has
various setter type methods which return
the same instance so that you can chain
the you can chain these calls and then
eventually you'll you'll you'll set the
request the the request method type and
call build which returns an HTTP request
an immutable HTTP request object so it
should be fairly familiar I think so the
first example yeah you can set headers
and set the requests method or the
requests type and then build now this
example possibly is slightly more
interesting in that we're doing a post
here so we need to specify a request
body so what we're doing is we're we're
calling some method called from file
which takes a path object and that
specifies that the request body is going
to come from that file so the output
from this from file method is is a type
an object of type HTTP request of body
processor now we'll take a look at that
type later on but it's it's it's
essentially a type 4 that converts user
user-defined objects into sequences of
byte buffers that the library can send
out as part of the request and this from
file method where does it come from well
it's it's it's a static method in in
this body processor type
okay so let's take an example having
having built requests how do we had we
send us and receive the response so
let's assume we have a request
we need a client we didn't HTTP client
in order to send the request requests
are sent on HTTP client objects so one
way to create a client is to call HTTP
client dot new HTTP client so in this
case we're calling client send with the
request object that we've just created
and the second parameter is a handler
object which tells the implementation
how to handle the response body now in
this case we're using an object return
from body handler as string this is a
standard one of the standard body
handler response body handler types that
we define in the API and that means the
response body is treated as a string and
you can see the HTTP response type
itself is parameterized with the type T
and that type T is the type of the of
the response body so with that then you
can you can then query the status code
and the status code was 200 then you
call response stuff body and what you
get back as a string but of course it
doesn't just have to be string it can be
any type such as white array so if you
had specified a body handler dot as byte
array then HTTP response would be
parametrized with the byte array type
and then response dot body itself would
return a byte array and we will see the
complete list of standard body handlers
that are provided in the API and then on
how to implement your own ones if that's
what you want to do so let's compare the
so this example was a simple synchronous
send so what happens if we want to do is
asynchronously so the synchronous send a
method returns an HTTP response of
string in this example if we want to do
it asynchronously then we call send
async with exactly the same parameters
and what we get back is a computable
future of HTTP response of string
so what can you do with that well as
before you can simply call join which
which locks and waits for the further
response or else throws an exception if
if and if if the complete filled future
completed exceptionally but maybe what's
more interesting would be to see how we
can compel something more higher-level
so let's start with from a synchronous
point of view if you have a request and
you called a client of send getting back
at HTTP response with a path as the body
and then calling response dot body and
you return return the body objects to
some some higher level so you can see
that if this is the the implementation
of some some method your what you're
returning is the is just the body object
but not the the response because perhaps
the higher level is not interested in
the response object so how do you do
that asynchronously with with computable
future it's quite simple actually
so you start by calling clients and
async and you feed that into dot then
apply which takes the out the response
object output from the first stage and
it returns the response stuff body and
you can see the computer future in this
case is a computable feature of path so
in that case you're returning
higher-level object rather rather than
the HTTP response so what we're going to
do is we're going to take that duck
behavior and wrap a method around it and
then use that in another example so
defined a method called fetch async
which takes a URI and an HTTP client and
returns a computable future of path as
I've as I've shown already just one
caveat though when implementing this
kind of code it's important that if
you're mixing traditional blocking code
with asynchronous code and if the
blocking code can throw exceptions it's
quite important to actually catch those
exceptions inside your method because
you probably you probably want to all of
your errors
handled through the completable future
API rather than some of them being
thrown as exceptions up through the call
stack so it's better to do something
like this and catch exceptions that can
be thrown at the time when the up method
is called and in this case patching all
throwables returned he could fails
complete with future dot failed future
which is a computable future that has
already been completed exceptionally
with the exception that you've given us
okay so let's see what we can do with
this this fetch async method so in this
example we're going to start with a
client and a number of your eyes and we
just want to fetch these three your eyes
concurrently and of course there's
multitude of different ways to do this
but this just seems like a nice
illustration of how to do it so in this
case we're going to create a stream of
the three your eyes and then feed that
into a collector and then the collector
we're using here is an interesting one
returned from collectors dot to map and
what collectors thought to map does is
it takes the stream and produces a map
and the the map that it produces is
defined by two mapping functions that
you provide to the to map method the
first one Maps the the incoming object
type which is which are your eyes in
this case maps the your eye to the to
the key type of the map and the second
function maps the incoming your eyes to
the value type of the map so we're
simply using function dot identity
because the incoming URI is the actual
key type that we want and the we're
using fetch a sync which returns a
computable future of path so what we can
see the resulting map will be a map of
URI to computable future of path so when
you when you execute this code it will
return immediately with your map and it
will be executing the three URI loads
concurrently so what we do next
okay so what we want to do is we want to
have a single waiting point so again
there are multiple ways of doing this
but this just is useful illustration
this is one of the static methods
uncomputable future it's called Olav and
it takes an array of of any completable
future type and gives you a single
aggregated computable future which
completes when all of the given
completable future is complete either
normally or exceptionally so some kind
of similar to to like a networks level
select operation but for managing
multiple connections at the same time so
basically the the compute future voids
that's returned which I'm calling all in
this case you when you call all dive
join if that returns normally it means
that all of the individual you are eyes
were loaded normally if it throws an
exception it means at least one of them
failed and then you can go back to the
map and see which which one failed okay
so I think that gives a flavor of how
this asynchronous API can be used so we
just step back to the and look at the
HTTP client class and how it gets
configured it has a very similar builder
type of architecture as HTTP client you
simply you call HTTP client hot new
builder and it returns an HTTP client
top builder object you can set various
things like Java net Authenticator or
SSL parameter is the SSL context or SSL
parameters to be used for requests on
this lines sent on this client you can
set a proxy an executor so this would be
this object will be invoked to provide
the threads fir for asynchronous
operations that are that are sent
through this through this client you can
set the redirection policy and finally
know this cookie manager also that's
possible and then finally we have
version method which allows you to
specify either
this must be HTTP one or you're allowing
for the possibility of HTTP - I didn't
mention this earlier but it's what's
interesting about HTTP two is that it's
there's no particular additional
overhead with speculatively selecting
Haiti to be - and then falling back to
HTTP one HTTP two was defined or was
designed you know reasonably well in
that respect in that no additional round
trips are required if it turns out you
try to do HTTP - but it falls back to
HTTP 1 now there is a small overhead
involved in establishing HTTP 2
connection for the first request when it
succeeds but if you're not sure that the
server you're talking to talks HTTP 2
there's no particular problem with
selecting HTTP 2 as the version to use
anyway okay so just take a little look
at the kind of things you can do to an
HTTP request when you're building it you
can establish you can set headers in a
number of different ways these the
header method just accumulates
additional headers using a simple name
value syntax like laughs you can specify
timeout using a duration object and if
the response isn't received within that
time then an exception is thrown or the
operation completes exceptionally and as
shown earlier you can use specified you
must specify the request method type and
if it's supposed to or any type that
takes a request body then you also
specify a body and then finally you call
build which which returns the request
object itself so in this example we're
calling plaintiffs and yep which sends a
request and you expects a byte array as
the response body type and what about
the HTTP response type itself well these
are the methods
on that on that interface so these are
the things that you can you can examine
in a response after you've received us
you get status code the URI that was it
was received from the the requests that
was initially sent an associated there
that that was that generated this this
with this response if redirections
occurred then a last request may return
a different request to the one that you
was initially sent then you get the ssl
parameters the version that was used we
take a look at header is in a minute in
a moment and trailers and then finally
type the body which is type T the
parameterised type on the interface
itself just to take another a quick look
at the how headers work so you can see
those headers and trailers method which
return return an HTTP header is directly
or in the case of trailers a computable
future of HTTP headers because it's not
always guaranteed when the HTTP response
object is available that the NE trailers
would will be available at that same
time and then HTTP headers itself is a
fairly simple interface with those four
methods which allows you to access
headers as a single valued or multi
valued multi valued headers okay so to
go onto something a little more advanced
we just take a quick look at the request
and response body processor functions so
as I mentioned earlier the purpose of
these these interfaces is simply to
convert between user-defined body types
and sequences of byte buffers which is
what the library needs to send and
receive on the network and this is based
on the java.util concurrent dot flow api
which has been added in recently in jdk
9 i'll give it a little description of
flow itself in the next couple
slides but basically it's a published
fairly general-purpose publish/subscribe
mechanism that defines three types float
up publisher followed up subscriber and
float a subscription and the way it's
used in this API is that for a request
bodies the the processor acts as a
publisher and the HTTP implementation
acts as a subscriber so it subscribes to
the information that the processor is
generating and for response bodies it's
the other way around the the library is
the publisher because it's receiving the
data and the processor is a subscriber
to that so just a brief digression out
into the flow API itself as I mentioned
there's three types and this should give
you an idea of the sequence of events
that typically happen when one flow is
is is actually used so first thing that
happens is a subscriber and calls the
subscribed method of a publisher and or
at least a subscriber is provided to a
publisher through the subscribed method
so then the publisher immediately calls
back to the subscriber calling its
unsubscribe method and providing a
subscription object so what happens next
then is so at this point we're in a kind
of a data transfer phase where the
subscriber is allowed to request items
from the publisher by calling the
request method on the subscription so
this is this this is flow controlled in
the sense that there's always a there's
a window of unfulfilled demand so this
is like a number of items that the
publisher is allowed to send to the
subscriber and that's under the
completely under the control to
subscribe or this is to subscribe or
must call the request method which takes
an integer parameter and say so if it
calls requests with a number n then the
publisher is allowed to send and items
back to the subscriber so in other words
the publisher is allowed to call the our
next method of the subscriber end times
so that's kind of how the how the flow
control works
so then once all of the data has been
transferred the publisher calls
uncomplete on the subscriber and that
signifies the end of the of the
subscription if an error occurs there
are two ways the subscriber can cancel
the subscription at any time or the
publisher can signal an error by calling
on error on the on the subscriber now
that if this all looks kind of
complicated and most
HTTP applications don't need to know
anything about this but if you're
implementing new body processor types
then you need to know about this stuff
so in terms of specification the request
body processor type is extends flow to
publisher of byte buffer and it defines
one additional method called content
length and if the body processor knows
what the content length is then it can
it can supply this information through
this method and that can be useful to
the implementation for setting things
like content length header isms whatever
so these are the static implementations
that the implementation provides so you
can see there this is the complete list
of standard ones so you can what that
effectively means is that simple
applications can send request bodies as
strings byte arrays from input streams
from a file or from permanent from an
iterable of byte arrays are in certain
cases for a we know where nobody is
required then there's a method for that
but as I said earlier you can implement
your own by implementing this these
methods yourself now responses are
handled in a two-stage fashion there's
also a body processor which kind of
operates in a similar way to the to the
to the HTTP request of body processor
but there is a higher-level body handler
also and this is the object that's
actually provided by the caller and when
this when this method is invoked it
returns a lower-level body processor and
I'll explain the rationale for that in a
moment with an example
and you can see here the definition of
the body handler type it's a functional
interface which is a single method
called apply so this is called this
method will be called as soon as the H
as soon as the headers have been
received from a response so it
immediately gives you the response code
and the and the headers object and it
allows the application to decide exactly
what it wants to do with the body
whether it wants to receive it or not
and are and exactly where to where to
put it if it does want to receive it we
see some examples of that in a few
slides so the response body processor
type it extends flowed a subscriber of
byte buffer and it defines one
additional methods called get body and
this is the this returns a completion
stage of type T so so the implementation
needs to you know accumulate the data
and do whatever needs to be done to
create the the T object whatever
whatever the T type is for this
processor you need
Methodist's is the one that needs to
know how to how to create it from the
incoming data and then we provide
similar set of static implementations of
that of both body processor as what
we're looking at here and also body
handler so so these are the these are
standards these static implementations
they essentially don't look at the
incoming status code or our headers they
just simply return the under the
equivalent body processor in all cases
so that's for the simple case for you
where you always want to receive the
response body which would be the normal
case so if if if you don't want to use
one of these predefined body handlers
then the alternative is to write a
little lambda like what's shown here so
in this case we're calling client tough
send the first parameter is a request
and the second parameter is this lambda
which takes the status and the HTTP
headers and
looks at the stages and said well if
it's if the status is is not 200 then we
don't really want to look at the body so
we're just going to return a body
processor that discards the throws away
the response body and supplies this
string error response as a proxy for the
actual response for the actual response
body if status whilst 200 then we're
going to return a normal string body
processor where we treated as a string a
utf-8 string so that's an example of
where where that behavior can be
customized okay so the I would just want
to talk a little bit about the server
push API so how do we how do we handle
server pushes well the first two methods
you can see here are sand and sand async
which I've described already the third
one is a second version of sand async
which takes an request but in this
instead of taking a response to a body
handler it takes a multiprocessor so
this is a an object that knows how to
deal with all of the complexities of
server push and you can see here that
this method is parametrized with two
types U and T so T is the same as before
it's it's the type of the response
bodies that you're going to receive from
this sequence of server pushes and what
so what's you willyou is just some some
aggregate object that that has some
overall significance for the overall
operation it can it can be anything but
we think in in the most common use cases
it could be something like a collection
or a map a map of of requests to
responses for example and in fact we
think that cases be so common we've
provided a slightly higher level API
that caters for that and I'll describe
that in a moment but before I do that
let's take a look at the multiprocessor
interface itself
so Multi multi processor has a number of
callbacks these are just traditional
callbacks so the first one is on request
so on request is called first time for
the actual requests that the client
generators have sent and then it's
called
once for each push promise that the
server generated and sent back to us so
that gives the gives the client the
opportunity to to accept or reject each
individual push promise and that's why
the the return type of that method is
actually an optional body handler rather
than a body handler so if the optional
is empty that's telling the
implementation we don't want this as the
server push just throw it away
the second method dennis is on response
that's called once for every response
that's received so depending on which
which pushes were accepted in which were
rejected on response would be called for
every for the main response and for
every push promise that was accepted if
if an error occurred instead of on
response to being called then on error
gets called so either either of on
response or on error would be called for
every every expected response that you
are expecting through this interface so
the final method then this is the
methods the kind of the finisher method
which allows you to to create the do you
a grenade object and it actually
provides to two computable features as
input so that gives you the opportunity
to to generate this aggregated object at
one of two different times either after
all of the push promises have been
received are at the very end when all
responses have been received so so the
return computable future can be
dependent on either one of those of
those two input completable futures
let's take a look at the simplified
interface now may not look that much
simpler in terms of specification but
when it's used it is quite a bit simpler
so let's go back to the send async
method and then and the type you so what
we're what we're defining here is is is
a value for you which we're calling
multi map results and what that is is
simply a map of HTTP requests and
computable future HTTP HTTP response of
V with no additional methods so so
that's what what this simplified
interface is always going to return so
what type of multiprocessor do we need
then in order to to use that well
we've provided a method in a
multiprocessor a static method called as
map and that takes a function that takes
a function which is which is basically
the the complexity of server pushes
distilled down to this the
implementation of this function and
we'll see that in an implementation so
what that function does is it's called
with each incoming HTTP request and it
returns its it must return an optional
body handler for each each request and
we will see you know how that works so a
real simple implementation of that is
what's shown here so we're calling
client I'll send a sync with the
requests that was created and the second
parameter is multiprocessor data's map
and a lambda that essentially ignores
the incoming requests so what we're
saying here is here is where always
every push promise that comes in we're
always going to return a body handler
the treats it as a string and so at the
end of all of that when we call join
what we have is a multi map result of
string and we can search through the the
map and examine any of the requests or
any of the parameters of the response
object okay
it slightly more complicated example is
shown here so in this case instead of a
wooden line lambda we have maybe eight
lines of code here where we do actually
examine the push promises so in this
case we've decided we're only going to
accept push promises that our HTML files
so just just an arbitrary choice for
example so we take the incoming push
request we extract the or I extract the
path from the URI
if the path ends with if the path does
not end with HTML HTML then we return an
optional dot empty so that means we're
rejecting this push we don't want it
otherwise we create some kind of a path
to store the the incoming file and
return a response body handler
Dada's file with that path destination
and then that's that's where the
implementation will store the incoming
pushed resource so basically that's
that's that's pretty much fun a lot to
talk about today in conclusion the the
API it's it's relatively easy to use in
the current case and the common cases
but it does have enough richness to
support the last common cases
particularly with server push and it
leverages a lot of the new features that
have been I've been defined in JDK 8 and
JDK 9 and as I mentioned earlier the
plan or our hope is to include it in JDK
9 as what we're calling an incubator
module which will allow us to our
feeling is that the API is kind of 85 90
percent complete and ready but perhaps
around the server push area we need a
little more experience before we can
fully standardize this and with people
using us in JDK 9 we'd hope to
standardize it in JDK 10 and finally the
source code is available at the link
below if you want to play around with us
no it might not it's still changing a
little bit it might not be 100%
mapping to what part of presented there
today but it is mostly the same we
welcome feedback on on the emailing list
shown and if we updates to the
particularly this this incubator idea
will will be announced on on the various
email lists okay so that's it thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>