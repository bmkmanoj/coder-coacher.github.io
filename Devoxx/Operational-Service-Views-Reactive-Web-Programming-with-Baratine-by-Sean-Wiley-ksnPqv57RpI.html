<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Operational Service Views - Reactive Web Programming with Baratine by Sean Wiley | Coder Coacher - Coaching Coders</title><meta content="Operational Service Views - Reactive Web Programming with Baratine by Sean Wiley - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Operational Service Views - Reactive Web Programming with Baratine by Sean Wiley</b></h2><h5 class="post__date">2017-04-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ksnPqv57RpI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay well uh I'm going to kick things
off here so feel free to stop me two
guys have questions any point so today
we're going to be talking about Barrett
King operational service views so
originally when I had this the slide
started I had began writing about some
of the accolades of what the
architecture tries to do and what I
realized as I sort of worded it together
was you know bear teen is really
described as the same accolades as Sola
so if you recall the original
implementation the original words that
so we'll use explicit boundaries loose
coupled services agreeing with a
contract schema but not sharing an
actual class all of those same words are
now really rebranded as microservices
right micro services can be called sola
20 so rather than looking at the actual
words to describe the architecture I
thought it'd be more helpful to look at
what the underlying architecture of
ferreting is and why it is different
than the architectures that are out
there because if we're going to start
building microservices and implementing
Sola the question that arises is are we
going to use the same tools ended up
with the same problems that we've had
previously when looking at operating on
data services so what we have here is a
high-level overview of what a betting
service is and a couple key concepts
here within a betting service so from a
developer's standpoint much of what you
see here is hidden and a developer is
really only going to see the API and the
service itself very keen what we do
around that is we enforce an strong and
capsulation boundary so within a service
a service is bound by an inbox and
within that service itself a service is
single threaded so only operating in the
service itself is a single thread that's
known as a service thread so it's a
efficient and lock free inbox that does
automated batching to the service itself
and inside the service because it's only
operated on by a single
the application code can be single
threaded so we're inside of a bearing
service we're not going to be using a
concurrent hash map and we're not going
to be writing synchronized blocks
because operating within the service
itself is only a single thread so
persistent services load and store their
data to a document style key value
database so a service is backed by its
own portion of the key value database
document style database inside of their
team so services use their data in
memory loading and storing is
transparent to the developer data is
loaded once usually in memory and it's
not evict until its LRU and the final
point here about a bearing service that
I do want to talk about is that services
own their own data in an object oriented
model so just it's just a highlight
point here that within a service itself
only the services thread is ever going
to be modifying that data and because of
that there's no locking there's no
blocking and there's no actual
synchronized portions needed within a
bear eating service so a final point
here before we look at a few demos is
database persistence so the in-memory
persistent services are built into bear
team they use it's an asynchronous
high-performance database that we've
called crackin we have an application
service operates on its data in memory
which does improve performance and
simplified code so after my sequel we've
seen the rise of no sequel databases and
really that's just pushing the data into
memory because we know that in memory is
the fastest pace that we can operate so
the third point there is that data is
automatically loaded and saved into the
internal document database as part of
the assets lifecycle so I could go into
more detail about the architecture
itself but with the time we have I
thought it'd be useful to look at a few
use cases of what baratan looks like so
the first you skits will look at is an
API engine many people are familiar with
the rest services and what we get here
with very keen is that a bear eating
service can operate as a rest service
and within the beara team environment
what you're going to be automatically
guaranteed is that a service will be
highly efficient a service will be own
its own data so a service can shard
based upon its own data data shards are
automatically and we can really look at
getting prototypes of solutions rest
services up extremely fast so sort of
finalize this point and go over it a
little more clearly here i have an
application it's a simple rest service
here so bear routine is now up and
running i can go here and go to the port
8080 where it is running and what we can
see here now is that this is a rest
service so on the back end what's
actually happening is we have a simple
hello service and it's the hello world
and the updates going to the back end
the back end is simply the bearing
service and it's returning that value
and that's what you're seeing on the
front end here so updates are easy and
updates are also quick so a point here
though is that we talked about the
persistence of Arrakeen well if we kill
the application so if we kill the
application and reload the server here
we've got nothing going on I'll rerun
the application once the service does
come back up what you'll find is that
the persistence is still there so the
previous value that was stored in Barrow
teen is actually persisted and saved to
the internal document and back to disk
now what does the actual service itself
look like what we can see what the
service looks like
that is correct so so the services are
backed by the inbox and within the
actual the requests are going to be
batched over to the it's a ring buffer
similar to the disrupter so similar to
how nodejs gets its fast performance and
vertex gets its fast performance we
actually get better CPU cache
utilization on a single thread than what
you're getting when you try to parallel
eyes because when you're working with
the data as I'm Boleslaw did show that
you're always going to be limited by the
portion of your code that has to be done
in serial that has to be done in order
so what when we come to the portion of
doing a doing a code modification a data
modification in order the fastest way to
do that in the most efficient way to do
that is by using a single thread within
that CPU so here's the actual class
itself and let me just zoom in so you
can see it here so the results are
asynchronous what's needed to persist
the service is simply the asset
modification here and an explicit modify
here so what we're saying it's on every
update we want to go ahead and make sure
that this service has persisted to disk
result okay that is our callback so
Berra teen does do asynchronous as well
as synchronous services when you're
dealing with asynchronous services
you're going to be using the bearing
result and we simply tell the result
result that okay and what that what that
goes ahead and does is tell us the
request that it's finished so that's a
simple example of what in what a rest
service can look like and we can look at
a one that's a bit more involved here
with a bookstore so a bookstore as you
know is one of the typical job
applications that people do run and
people do show for how they can actually
how how I framework can be used so if I
look currently if I look currently what
you see is I do have one book that's
entered into my bookstore already i will
show you the code
that so I can enter in new books i can
say i am the author here and this is my
devoxx demo so i can author a title if I
check the list it goes in seven eight
nine Shawn to divx demo too so i can see
that i'm adding actually to the internal
databases embarrassing the problem
currently though is that if i were to
kill this application and restart this
well let's reload this okay so i cannot
be reach and restart this application
what you're going to what you're going
to find actually is that the data is not
persisted currently within the database
so the question would be how difficult
would it be to make our bookstore
persistent well with Berra team because
the service is owned by a single
threaded and it's very easy for us to
then back that service of data into a
store so what that means in this case is
i can open up my file here and simply
with the assets and with a explicit
modify on our post
I'll say that what this is going to
allow me to do now let me kill that well
this is going to allow me to do is
persist the data to disk with two simple
annotations so I've got it rebuilt let
me go ahead and bring it back up okay so
that it's back up and running we see the
current list here I'll add one book to
it again this is the dev ox demo book
that I'm authoring currently I will add
it to the list and we see it's in the
current list now when I kill the
application and I can reload my
localhost see nothing is there I can
bring up that application again and with
simply this just those two annotations
my data is now safe and persisted with
embarrassing so moving back to use cases
of bare teen let's look at the
differences of what what we're talking
about when it threads operating within a
service and parroting so traditionally
bookstore rest service the way it comes
in now this you don't actually have the
stub so the green the green marker there
is what would access the stuff but
really what happens is all the requests
do come in when data needs to be
modified you either must write a
synchronized block around that portion
or the request itself will go ahead and
lock that field while that field is
updated to the database so there's no
thread ownership multi-threading can
then result in let's say your databases
text and you cannot spin up a thread at
the at the back end you can bring down
an entire application server entire
stack just by having a lot of requests
come in and we actually are makers of
the resident application server which is
a multi-threaded server we've been
supporting it for years here 20 20 some
odd years so that is why we've sort of
started to see a new model where within
bear teen all of the requests will come
in and get cue to a thread lock
efficient inbox within the service
threat itself the operations are done in
memory there's going to be no
and blocking and we have single thread
ownership of the data so there's no need
to ever introduced a cache in front of
the service there's no need to extract
the data outside anywhere of the service
because the data is owned by that
service the data is operated only on a
single thread and that gives us great
actual performance so when we look at an
implementation of rest easy jax-rs
jax-rs implementation rest easy verse 13
we're getting over 2 times performance
we know that bear team can be scaled to
match the course on the CPU so we can be
very efficient with the actual CPUs the
CP the cache of that TPU and we also as
we did see that persistence is and added
with single annotation yes so it's
single threaded but one of the
annotations that I will introduce if you
want to scale per core what you could do
is there's a worker sanitation that will
allow you to spin up threads to the back
end of the service so it's the same way
that we are able to talk with jdbc
because jdbc is blocking so there's a
separate annotation that we can use if
you wanted to scale out per per core
that you could have four four threads
spun up on a fork or server so each each
core within the server each core within
the CPU is utilizing one thread very
efficient when we look at in memory
upper I'm sorry right so so the workers
annotation is a way to integrate with
the current traditional architecture
that that is out there when we use berra
teen and we scale out bear teen you're
scaling out Barrett teen based upon the
CPUs box itself so you can within a
docker image establish the CPU power you
want to give to that bear routine
service itself and from that we're going
to be very efficient when we're working
on a single thread so it does sound like
a single thread is going to be less
efficient than using a multiple
multi-threaded CPU but you know what the
data shows is that if we look at a
database on the same network and we look
at traditional servlet
versus in memory and this benchmark was
ran with one update per request the data
was persisted to my sequel bear teen is
a lot faster because it's removing the
database from the critical path so
everything is in memory and the first
request is actually slower than the
second request because of the CPU cache
in that utilization of a single thread
so there's actually a great white paper
out there it's called scalability but at
what cost and cost is what they define
as the configuration that outperforms a
single thread what they basically come
to realize within the paper is that
oftentimes the overhead introduced by a
framework means that the benefits of
scaling out horizontally you can never
actually you rarely do you achieve the
performance of a single thread efficient
implementation so we do back pressure
based upon the inbox itself so the inbox
is journaled and the request will fill
up so if your memory reaches its max
because of the you have that many
requests coming to the inbox but we're
limited by the hardware of the machine
itself so it's rare that we would reach
the case where an inbox that a service
will reject request services don't
reject request they journal the request
in to the inbox and they spend to that
inbox and it's a very highly efficient
manner of answering the actual request
so the in memory operations portion is
that data is loaded only once we have
large data sets that sets that will
shard by themselves again that is
because the service is the only
ownership of that data so we can easily
shard a service based upon its data and
continue to do operations as we scale
out to a multitude of and end servers we
have right through in place so bearing
does save the fields of an asset to an
embedded fully reactive document
database so it's an append only style
database that we do use and we have
journaling for reliability and failover
so the inboxes is
by a replayable journal and that is how
we're able to sort of recover the state
of a service if ever service does go
down so when we look at the performance
of barrett een you know our continuation
asynchronous performance is a lot better
than it is always consistently better
than our future performance so this is
the weight we get about 9 million
messages per second and 4 million calls
per second when we're using the
synchronous version of bear team so as
we scale out to the number of clients
here though what we realize is
asynchronous performance drops but
States well over two million calls for a
second and how is that possible that
Barry Kane is able to maintain such high
performance as you scale out to more
clients well it's able to do that
because Barry King does implicit
batching so you're getting better
performance as the number of clients
increase because the batch is a lot more
efficient to CPU cache is there and that
that thread that's running and answering
the request is able to maintain
performance as berra team at Barry King
is used here so if we look at another
use case of a very keen service it's
what I talked about earlier so I
microservice so an auction microservice
and when we talk about the reactive
manifesto services must be elastic they
must be recoverable and they must be
scalable the auction service that I will
demo to you is impressive because each
actual service that you're going to be
seeing can be scaled out individually so
we could we could have separate servers
for our user service we could have
separate servers for our auction service
and because of this because each service
is going to be its single owner of its
actual data it allows it heritage to the
actual end users and end servers there
that you might be using so let's take a
look at this in action so
right looks like it's up and running
there
oops looks like I did not kill this one
so let me close this port now let me get
it up and running
okay so what we have here is a auction
service similar to what eBay might be I
have a I can have a name here and so
just the user one and password 123 if I
try to log in to log in fails we first
create the user we see that the user is
now created down here we can go ahead
and log in to log in a successful I can
make an auction here trucks will start
the bidding at 10 and then when I go
ahead and search for my option I have
made it a name trucks earlier we can see
that you can bid and bidding takes place
button is being answered by the actual
inbox of the service itself so because
the service is ordered the inbox is
ordered and cereal or we're able to do
then is allow millions of requests to
come into this service and the service
then takes care of ordering those
requests what we have running in the
background of this auction service is
actually a timer so as you can see that
the the state has gone over to settled
why is the state settled well the state
settled because the timer service what
it does is it first verifies all the
requests coming through once the request
once the timer does hated 10 second
limit which is what I've set it to right
now it will automatically go through the
refund process it will go through the
paypal implementation process and it
will go ahead and actually run run those
portions and save them to persistent to
the database inside so as you can see
that the bids are going on at in the
back end we see that the bids are being
accepted but after after 10 seconds we
do see the state actually goes into us
into a settled nature here so the code
for this auction
we can look at it and see that so these
are the actual files we have implemented
in a full-blown sort of micro service
and everything here is within Verity so
we're doing database service we're using
Barrett events service we're using
WebSockets as the communication and
we're actually doing verification
through paypal we have the user
settlement and the settlement
transaction state so we're doing every
portion and we've really just prototype
this as a as a way to show how you can
use betting on full-scale for full scale
deployment so what we're looking at
though when you when you take a look at
one of the actual classes here
everything is internal we're only using
we have a service here our paypal
service that we're injecting for the
auction settlement so we have bids that
come in when a bit is settled we do call
the subtle info status is ok we we here
is where where we are actually going
ahead and settling any of the requests
that might have come in might have been
bid while the state was changed from
closed from open to closed and then to
settled so we go through three actual
changes there it happens a little bit
too fast to see it on the screen but the
auctions are actually going from open to
closed to settled and what that does at
the very end of having hit the settle
this anybody who was bidding on it let's
say this is a live auction on eBay they
would have actually had their refund
come through to them if the state was
closed and the bid was somehow accepted
because everything is journals and
backed by a journal we have a very
reliable way to replay any of the
information that's come through to the
service and it allows us to prototype
these sort of solutions on a large scale
and then scale them out with scalability
really being an afterthought because we
know that we've moved the database out
of the critical path of operation we're
allowed them to focus just on the code
itself we have we have the ability then
to you know put our service live into
the cloud you
recently I but we were on site with a
company who was looking to introduce a
new mobile selector in front of their
application they wrote it in PHP and it
actually ended up bringing down their
entire application stack now with bare
teen if they had youths parroting what
they could have done is put that service
up simple rest service simple selector
and known that the performance is not
going to degrade their application
because we can build jars here and not
war files so very keen can be used as a
library it can be use standalone or it
can be used it can be embedded within
the current architecture that you would
be using now the thing that is different
and imperative to understand here is
that as you build out services you know
that a single service is never going to
be responsible for bringing down all of
the other services that you do have
because they are only talking JSON so
you can integrate with every language
that does speak JSON and you can do so
without worrying that you're your new
portions of your application that you're
building out is going to be detrimental
to the data it's needed to operate on
you can stream analytics off of a
service very easily without actually
having to worry about some of the
portions of high performance within the
application itself so that does put me
five minutes over my time here but oh
sure thing it's just going to open it up
for questions
so this is part of the settlement
service here so what we're doing is we
are which which one are you looking at
here okay this one here yeah right so
what is what its first doing is it's
getting the data from the auction so the
auction data is owned by the auction
service itself so at first is actually
going ahead and getting getting that
data setting the auction and then what
it's doing is using a separate a
separate thread to go ahead and charge
the credit card and then what you're
seeing there is two portions so we have
a winner and we have the auction so we
have to get first the auction data
itself and we also have to get the
winner to see who was the actual winner
and who should we charge before the
payment structure there so in parallel
there it sends out to requests waits for
the option data to return once we have
the auction data which does include who
is the actual winner we take that and
we're charging that the charging that
end user with correct correct
correct so we well for proportions of
the proportions of the code right here
what we're doing is we're making sure
that the winner is charged based upon
who has won the auction and since the
auction is the only owner of its data we
do have to send out a request to the
data come back to the auction owning
service get get that actual get that
actual winter data back and then we can
go ahead and charge it so but this
method itself is not actually a blocking
method and that's based upon the idea
that within a call to an actual service
what we're doing is we're giving futures
and continuations to the calling and
threads and so the thread that calls
into the inbox is enough and doing more
work in the background these threats
once they complete past the result along
and we have a fully asynchronous portion
of the data that's been retrieved and
then used within the application itself
so it's a bit of a correct so what we
have when we do work with portions of
the code is you will have portions again
that will be done in serial so it we
couldn't actually charge a user without
knowing who has won the auction itself
so it's a way that we've chosen to
structure this application and show that
the separate entities and owning data
are owned by different services itself
so just going back to this image here
because the auction data is owned as an
outside service we need to verify that
it gets that actual auction data and
from that auction data we're pulling the
last bid winter and we're charging that
that winter based upon their
okay and we're there any other questions
great well thank you guys throwing up</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>