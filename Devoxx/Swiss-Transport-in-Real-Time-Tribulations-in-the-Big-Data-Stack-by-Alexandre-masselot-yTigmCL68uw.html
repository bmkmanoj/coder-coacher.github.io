<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Swiss Transport in Real Time: Tribulations in the Big Data Stack by Alexandre masselot | Coder Coacher - Coaching Coders</title><meta content="Swiss Transport in Real Time: Tribulations in the Big Data Stack by Alexandre masselot - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Swiss Transport in Real Time: Tribulations in the Big Data Stack by Alexandre masselot</b></h2><h5 class="post__date">2017-03-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yTigmCL68uw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning thanks for being here and
we read too common speak in an array kia
oh blah okay that's good and share with
you the work that we did on this matter
so I'm Alex maslow I work at the octo
technology in Lausanne so we're in small
firm were 15 in Lausanne and 215 Paris
and what we think that we see that we
have more and more customers or
prospects or friends or whatnot with big
data problems okay and that's good for
us and these people use technology and
we advise them to use some technology
and they have some problems so i will
present some of the technology that we
use with our customers and also some of
the technology that we don't use or
maybe we don't use yet because there are
more on the front side or more the next
step to come so we are this this firm in
other than we do recruit talented big
data data science and other topics but
today that's not the point today what I
want to share with you is the question
that we ask ourselves doing our twenty
percent of free time research
development how you may call it we
wanted to make a simple scalable
architecture to be able to dispatch to
transpose to visualize data in near
real-time and also to be able to store
it and then analyze it up a thyroid to
make maybe some machine learning or
visualization on wool gunshot data and
that was the question because it's a
pattern that seemed to be interesting at
the time that's a pattern that we find
over and
over in reward for the problems and the
first thing that we asked ourselves ok
cool we need to find data and there are
plenty of that available this is it part
of the internet and the world in which
we live more and more that they are
available I come from bioinformatics
background so there is plenty of
scientific data by informatics at a
health there is of course energy ok
plenty of things coming with IOT social
media of course there's also some things
in the finance industry and insurance
but somehow we wanted to be to take a
step beside our day-to-day work I wanted
to also to choose a topic which matters
to almost everyone so we pick up
transport because I think a lot of you
use the big transportation to come here
this morning and it's super strong in
the I think this is culture too so
transport in Switzerland is train is
that only the SBB it's plenty of smaller
train companies all over the country
it's buses city buses foster vs and I
think most of my time of development in
fact for this project was done during my
commute in training boss vs so that
happened more than once that I just miss
my stuff because I was to focus on what
I will try to present you today there
are also both in the public transport
system so we have learned we have see
somehow we have air you're so gondolas
that can be part of the public transport
and situation and what is great in a in
Switzerland is that all this public
transport system which is something than
more than 170 companies across the
country they are grouped together into a
union of public transport or something
like that which allow us to have
as a bond motion analysis pass which
allow us also to have applications that
may be using your mobile phone that will
regroup give you schedule or planning of
life fairs across this different
companies of course when are the only
one to play with that our to make a
business positioning that i am with
applications okay that's just a couple
of them there is this station board on
the SBB website what are the next train
that will leave the station there is a
mobile application that will tell us oh
I have a train between I Geneva and the
same and the train is between Geneva
Roseanne and it will be late in by swami
nutan laws on and so on and there is
also this application which is closer
that what we will present today which is
a map where you see the vehicle their
position what is the SQ on project
position you see the moving the more you
do the more you see versus and finer
grain transport and what we want to do
today is to hoe yeah two things we want
to do I will at one moment fall from
that thing is for sure two things sorry
it will be an application for real-time
visualization and also a posteriori
analyzes we will toward atta and then be
able to hug some some program to to ask
and answer some questions of course all
the code there is on github so don't
hesitate them to try or ask question if
you have any I start with the demo of
the real-time application so here is a
map of Switzerland so you could move in
and then you have stationed here the
station the bigger means that is both
more train that will leave the station
we have this
quarter showing how much how many trains
are late if we zoom in of course we see
the train moving so there is this all
interaction if we mouse over a map it
will show us the next day pass you up on
this map and so on and so on and just
for fun we also make the super cool
mundane o'clock because it's a nice
piece of their ask us to do alright so
let's get back to our our somehow our
table of content the agenda of the day
so I were able to build this simple
scalable infrastructure to dispatch
transform and visualize in near
real-time massive data woody to scale
and also to achieve this analysis with
the store data and it's pretty simple ok
we have vehicles position we have
station board information I am enjoying
what are the next time to leave I can
capture that in a real time and then I
will dispatch it to my web users and
also i will stow it i will propose a way
for more data analyst or data scientist
people to dig into them that's the
architecture of the thing and the first
thing we want to focus is simple ok and
because there's not much ok in fact if
we if we look at this architecture but
if we want to scale and go into the Big
Data journey nothing is really simple at
first ok this is a map of the technology
that are available to you that a basal
language I work visualization to message
ball carriers and so on this is a map
that is actualized even several time a
year by mastercam his and his folks it's
always moving and believe me they are a
lot of component in this on this map
which are not that simple
okay and I think no one can hear you
have a understanding of all what is this
map and this mask all with Edward who we
try to go on the to keep on the simple
side of it and we will focus on each of
these on this break try to show you
technology that we choose also also
proposed a couple of other technologies
something which is important to remember
that that's an LNG project as a proof of
concept I'm also for us to have fun and
discover technology and there are some
tools that will be presented here that
are certainly not suited for a
production already of such an
application in fact if customer come to
ask us would you use this database that
i will talk to you about for this
problem we really say no it's not suited
our other ones which are way better
suited but that's not important for
today ok let's that at first by the
first break of the architecture which is
dispatching events ok quite easy we have
the IPL positions and on the station Bob
and we need first before dispatching
them to acquire them so all this vehicle
they do have gps and most of them they
transmit near real-time the opposition
to post auto to SBB or whatever company
of course we don't have access as
outsider we do not have access to this
information so we have to find epoxy
this information can be found ok the
information on vehicle position can be
we can find a proxy to them with by
making just HTTP rest query to the SBB
so we have to try to keep it low to be
under da da da ok to do to go to to too
hard on their information system but we
can nonetheless grab the information
on the schedule for the list of station
bottom there is easier there is this
open data transport API which is
evolving also but which offers us a very
convenient way to know what are the next
train and ok and so on it's this API
which is used by a lot of the mobile
application that we have to go and hit
this this this API so we can add this a
DCP eyes get the information to do that
we just want a simple and og escape but
whatever spell if you want script or
whatever language could be enough to
make a few requests and push them
forward further just to see what it will
it will get for vehicle position more or
less will have a train or bus ID will
have I don't know where it goes to an
its current position that it you don't
longitude if we go to station balls okay
one station board is I don't know it
slows an where is loss on geological
coordinate where are the net what are
the next departure in Lausanne we have a
train leaving to domicile on 2013 it
would it's unknown for minute late and
also we have more information would go
back for an IV step which is a kind of
forecast of the of the you hear me like
that forecast of the how full it is so
we can get this information and then we
need to push it forward and what we use
soon message Boko and push event and
then the remaining part of architecture
cannon register to that and for that we
use a Kafka we use kefka because it's
really done done for real-time data
processing it's a great time data
pipelining
more precisely the ideas that we have
application we have audio source of
information that will push events to
cascal ok to a cask a cluster or gas
cassava and then we have other
application that will somehow consume
the information that will Hoge Easter
and this vodka this message vodka in the
middle this cask a layer will ensure
that if it fails all the consumer get
back the details that they missed and so
on so on so we get we get out of this
piece we get this piece out of our our
mind it's also something it's also an
infrastructure that scales very well you
can under handle easily up to 100,000
message per second so far beyond our
column today and the producer of
information of course is our new GF
script and the consumer is the real-time
visualization and the pipeline for
storage ok we use Kaska but there is way
more than one way to do a to-do message
blocking other famous solution are
certainly a habit mqz omq and many other
data I don't know of ok require data we
have a dispatcher now we can start to
store them I'm stalling very often this
world means we need to reformat the data
may be transformed it a little bit
remove some redundant tilt because it
will just burn a disk and push it to a
storage and to do that we decided to go
with log stash ok looks actually really
a pipe component that will do exactly
that I take event I take care yeah
messages confound them and push them
forward and they naturally push to the
elastic search database elasticsearch is
a is a document store yes it's a
document store it's easy to install
only scheduled oil it's very convenient
to query and so on it's maybe not the
best shooter database or the problem at
hand but it will do the job we can store
the information in the attic search
because we can also store the
information in a flat files because
maybe it's more convenient for you
post-processing or just for viewing
single it takes less space on your desk
again we could have used other tools
okay like flume in fact we started with
flume which is also pipelining a project
we somehow abandon it I mean we abandon
it after a few hours because I know okay
its lng project okay so sometimes say oh
it doesn't work like we want oh let's
stash it working 15 minutes was up and
running so it was an easy choice but
there is also filed be there is a wall
list of this of these tools to pipe
information and they are really
inherited from the ER to get a big
faction from the log processing a world
usually the database why I said that
elastic is not the best way to stop to
store this time series event the our
time series data bases but there are
also more all-purpose databases that
would have been more suited columnar
databases as like HBase the head upward
or cassandra is a very powerful storage
that would be way more suited for a
production oriented development so here
we are we're dispatching the divider the
events station board and position and
then we can store them for months and we
see at the end of the talk what we can
do them with this even now we go to the
other part of the of the pipeline the
real time processing path and until now
it was kind of somehow easy at least at
the at the proof-of-concept level
because it's only configuration okay
like few lines of load to request a
couple of API is but everything else
elasticsearch Cascada log stash
there's only some configuration and it's
there is no really could return to
handle that but of course for the upper
level then we need to dive a little bit
more you know in an encode so the first
thing we have to do with our events we
need to transform them and we need to
transfer them because somehow we have
atomic events a tiny member tells us
tell us oh yeah I'm a try I'm the Train
123 I am a dis joka pickle coordinate
that's it it doesn't say this stop if
it's where it was a 10 second ago it
doesn't say if it's a near a station
okay so we need to transform that to
remember what was a last position and if
it has the change in the last ten
seconds we can estimate that is that the
train is stopped and if the train
position is within a 100 meter radius
from the station we can even say oh yeah
this train is stopped in the station so
we can reconstruct a global map of the
of the of the situation we need to stay
persistency we also need state passes
and see because the train doesn't tell
us yeah I have finished I'm home no you
just disappear from the grid so we must
keep track of saying yeah we have not
have any information for 21 23 for I
don't know one minute let's consider is
of the grid I'm so on so we need this to
digest input flu but also to process it
with some state persistence and of
course to be able to say okay give me
the position of all the trains for
example and to do that they are there
are many possibilities okay the one we
took or one of we took the one I present
here today okay it's based first on
skala for the development language not
only working in low sign that we are
strongly influenced by scholar but I
think
aight language it's really a beautiful
language so how I went from girl to
scala was pretty big jumps in my great
language a direction but it's really
worth it is suited for big data is
functional and open how many people here
do programming Scala it's good ok it's
giving something that's really worth
considering ok that's not for the
language but we could have used Python
or Java SE anything then to store the
state there's a bit more tricky what we
did here is that we use actors actors
there are small entities that have a
state and then can easily commute they
can easily communicate with each other
so you send a message to the state to to
to the actor and the actor will maybe
send another message to some other actor
or back to you change its state so it's
very natural to say 120 our actor and
then actually super lightweight you get
you can put the tens of thousands of of
actors on the laptop it would be fine so
it's not like skies that you have to be
careful you can let me scale them so you
can have one actor / train one actor /
station and then a train is an actor so
it will automatically knows oh yeah I
know my position now you send me a new
position for me yeah I know if I have
moved or not okay and I can talk to all
the stations at once and say oh give me
your position so I can decide if my
train stopped in the station so the
world status of one train is captured
within a this action deserve this actor
actors it's another bad eggs who can
refer to the talk great talk that we had
addressed before it's it's it was first
designed in the 70s and 73 it's a really
appealing a model now with the akan
plement ation is a very usable model
okay it's easy to use but the thing is
that is very often hard to to find
problems where it suits the act or model
and this was a perfect case was pretty
hot
sometimes you have a model and you just
make it fit because you loved actors
it's not very clever okay put it to 22
in 22 back together skala actor the rest
api and so on we use a plate frame work
because it's well designed and very well
suited to that question so we use actors
we could have used other thing other
framework from this complex even
processing such as storm or fling or
whatnot other other framework certainly
we could have used spark screaming that
this is certainly the best choice for
this kind of problem okay and I see a
couple person I don't see very well in
there in a little bit ok I see cover
Tarzan modeling and the spark is it kind
of food or food it does also streaming
the things that when we launched this
proof-of-concept process the time state
and the time persistence that the state
persistence was not really matured or I
could not figure exactly how to do to
make it work at the time but I would
really go back with back screaming okay
we have a new adventure okay storage
processing dispatching acquisition and
then actors and rest api to expose the
data that has to be a decent
architecture for a sim simple proof of
concept project and we need to talk a
little bit about operations
infrastructure and also talk a little
bit about performances okay so the thing
is that we need to install all of this
component and obviously it's not easy to
install that on on your laptop okay
every choice so the big deal to install
it I want but if you have many projects
with different version of the tool then
you have problems and if i give you the
project and then you have to spend two
days just installing this different
components is that good okay fortunately
there are solutions
one solution is to use containers okay
and among the container solution Tokyo
is certainly the one which has a more
attraction nowadays it's also a pretty
elegant solution that we hear more and
more often at least at the developer
level with our with our customers and
contact so that we can say the
submission technology nowadays and the
idea is that we want easily that you
download the project on github and you
can shoot the wouldn't a structure in a
matter of minutes that's that's that's
the deal okay and to do that you want
all this component installed okay and
what doctor does it say all know I don't
package you a virtual machine with every
site in everything inside inside I will
package small components one for caprica
let's say one for your acquisition
application 14 elasticsearch 14 logstash
one for the spark or the actual
processing so each small component is
just like a super light virtual machine
okay it's a container and the good thing
about that they exist plenty of
craigslisting container I don't have to
take an empty container and install a
Kafka I just go to dock your hub and say
oh yeah I want duck your image for
caprica version 0 10 and that's it more
clever people than I did package the
stops and that's super useful and you do
that for elasticsearch and four lakhs
actual all the components for a lot of
components you have prepackaged images I
think that you can even orchestrate this
additional component because they need
their name like us dns somehow so you
will occur straight that we've reviewed
ocupamos file that's one solution where
you say okay i have an elastic search
server and its name is elastic and I etc
so each component knows each container
knows how to talk what is the address of
the other one and the docker file for
all the superstructure
I don't know maybe I don't know 30 lines
long something like that it's not that a
big deal all right and if we go back to
our architecture now which is technical
architecture we have the different
component and we package them in the
container okay so we have one container
for acquisition a cash cow we want to
make it hard on them okay I'm have a
zookeeper to orchestrate that okay let's
shoot a couple container with zookeeper
and Kafka elasticsearch the same thing
going to have more than one node for our
database to see how it okay how it
behaved that should a few for them same
thing for processing okay let's let's
make one container and we have this this
this infrastructure which is really
ready to deploy it and it's one of the
use case we want to demonstrate on one
of them I would never did that in size
and one of my colleague love to do that
to see if I say maybe but he just go to
github for in front of a customer and
check out the code and then you just
need just need to wait with you a couple
minutes to download all the images from
the public suppository and you have the
world application running ok we have it
before to it because the things that now
say yeah that's great but I could have
done everything in a single tomcat
application thank you getting the
information storing it showing it
starting to fight whatever why do you do
this all this then I could have done
that in my single application the
problem there is first we wanted to have
fun remember we are here to have fun so
this I have and we wanted to have some
fun by discovering technology sort of at
one point and the other point which is
no it doesn't scale okay what what if we
have tens or we have 1000 events per
second like we seen in some domain a
single term catification will not scale
so we wanted to have something lo haga
sanji on the screen so we have this
higher wisdom complex architecture and
the thing is how does it perform on in
terms of CPU and speed
first number is that when we compare it
to the classic SBB HTTP request you go
way faster okay something in the order
of 50 time faster and also it brings
back way more vehicle we can scale out
to either the classic request is 1000
vehicle position or back this is not
really fair comparison okay because if
you go to the SBB they have so much
control and so many more customer and so
on so but it just to give an order of
magnitude that the system can be really
reactive and we didn't touch much effort
into the performance side of it the
other thing is that rest of the wool
architecture without the elastic search
it was removed when i did this measure
because somehow i burn all my space on
the amazon cluster and wanted to a cast
of the storage with the world the war
thing took fifteen percent of one cpu to
process that and everything away so it's
pretty lightweight we were surprised by
the lightweight it is ok we have a
running infrastructure we can now go to
the data ok oh no sorry i mean something
we need ok I just every time I tell you
here it's scary scale so let's take a
few check box and see how it scale ok
and each component was chosen for the
scalability kafka naturally can be
partition and distribution is full
Talent thanks to also to zookeeper
behind it logstash it's full Talent then
to the matter of scaling frankly I don't
exactly know but the dhimmi that we see
with practical problem is so far beyond
the scope so that we didn't have
investigated that the storage we will
astok search again it's naturally
distributed the default installation
come at least with Windows if we use
back screaming it comes oh it's really
couple with the Hadoop or design for the
Hadoop word so it recovers our failure
and its distribute matcher alida skype
of a very well this type of processing
the action
it's a bit more tricky of course my
little actors I can spend them on a
cluster of machine and then there is
cottages for failure what should i do in
this or this situation but this thing is
that to really implement that in real
life it can be pretty tricky why we have
this warning signal okay if you want to
make fault tolerant ik application at
large okay you need to invest more than
than than a couple days that's an E and
for the darker okay it's done for
scaling we have orchestrator to multiply
the different component to have hot
update click of all our failures and
then you can distribute that on public
clouds like okay Amazon or Google with
mainly use Amazon and Google for this
demo but if you want to do to put it
more locally in Switzerland just go to
XO scares or or Hedorah or I don't know
there is a dozen of a cloud provider at
least in an intradermal okay we have the
data it stand out we can process the
data stand now to see them to bring them
from the system to the screen and we
want to visualize this near real-time
data ok again sorry I dentists server
that the near health times that we are
not at the millisecond level we are more
at the second a half a second level for
data to cause all the pipeline that's
the order of magnitude but it really
satisfies a lot of these not all the
need for sure you don't want your Tesla
to wait one second before processing an
event but for a lot of application
that's pattern enough ok so here here is
a snapshot of the demo we have the
station the size of the circle is the
new gold claim that we leave the station
we have this orange quadrant which shows
the percentage of trains that are
planned forecast to leave late we have
the vehicles of course if we move our
mouse over station or a train we gave us
some information
yeah that's it under map you can zoom in
and out and so on because visualization
again nowadays is interactive
visualization as in the border okay and
here there is a very good news is that
to make search visualization in the
water there is one obvious choice for
the vendors or the library to create the
visual component okay disc EGS is
certainly super common choice are many
libraries based on on it but and their
data is discrete OGS more it's a library
where that we control information data
into dom element into your browser
element and somehow to create
visualizations the only limit is your
imagination okay we can really create
crazy things with with the 3gs so that
was easy the other path that we need a
framework and then we will go to jail
escape choosing your frameworks or
something that change I don't know every
year there is a new super cool framework
okay it's really hard to keep up to date
you are not a full-time JavaScript
front-end developer and even though for
this problem we used react yes this grad
yes it's very well suited for Laughs
data set okay it's only a rendering a
live way to render components and if we
covered that with a flux architecture
that's the dismal as a default practice
it's really powerful to to to handle
that I don't go into detail of the
headaches of the readers architecture
but the pattern that is suited were the
component register to a central a
storage to show the data and then
describe how they did the event go
through action and the dispatcher the
thing with javascript is that somehow
it's a bit overlooked not this
application but we had other application
that were also we react
some way longer ago in backbone which
could handle up to 100,000 even-- even
elements 100 thousands elements and each
of these elements maybe have 50 items
into them and you could handle that you
can under that on the on the border so
you can really play with massive data in
the water and under language itself is
not really the limit nonetheless we have
to take care of performance issues and
here we see the the map okay the 22
which like in the station this map did
consume something like fifteen to twenty
percent of the CPU just because there is
no addiction okay that's it it kills you
CPU okay i will put the isolation i have
few weeks ago some measures about how
this kind of thinking ed kids UCP so
sometimes you have can do great thing in
the buzzer and be killed by these cool
CSS transitions if you make to too many
of them your dad easily we talked about
visualization and like everything that
we do we should do remember this i have
not seen the talk before before coming
here but we need to test ok everything
and we catch test visualization we can
test that showing train at different
levels give us different information we
can show tell that if we have small
station that are just close to the lake
when we zoom out there are not hidden
buys like they just go on top ok like
like this one and how they react when we
zoom differently in because we don't
want in your zooms be more readable same
thing for the watch how does it react
when we skills that the component the
behavior changes and so on so we can
test okay it's not fully automated test
at this level but at least we have one
page where we have all the components
okay in this own configuration with
boxed data so it's really easy to
inspect and for coding
you're a realization application that's
a really powerful a tool which is maybe
a bit out of the scope of today but i
also want to share that since then we
pushed the limit of visualization this
is with schedule data and then we have
up we have two thousand vehicles the
wall switzerland with buses we can even
plot city buses it's meaningless because
they don't move and it's fast forwarded
so the application here the real speed
on your browser we just take schedule
data and with fastball adam by a factor
of five hundred to see the trains go and
the birth goes through the country to
see and the idea was how the Bazar react
okay how can we how can we digest this
information and of course remember the
my simple clock if you go to the fridge
es then you hit a limit okay and if you
don't want your point to jump from one
position because it's not not nice okay
you want to have smooth transition and
with fading out tails you need to find
something else and to do this kind of
thing we use disk EG else but also pixie
which which is a library that relies on
the under GPU okay for some computation
so we can give it and you can couple DC
and pixie no problem and for that i have
to keep up ok that was morrison so we
have to go to Angela and good luck to
now we have to say on guitar and
observables and so on again these things
are described in a couple of post that
work recently published all right we did
it we have our user they are happy my
daughter can play with my mom okay
that's cool now we need to explore the
data that we stop we can start to ask
question maybe not super clever question
but question to see the other point
again is to to show how we can do the
things and we ask a question so let's
focus on Logan and Geneva but I could
have said balance vehicle and during a
week days what are the moment were train
is full or not
when during the day is it most probable
that might rain will be late this is
less trivial question and we're in
Switzerland are the train the most often
are the most often to be late so we have
a couple of quiz okay laganja never went
to have a seat it's pretty packed in the
morning lot of people are commuting okay
so this is the information the prognosis
information capacity prognosis
information which translate to your
mobile application by little I code see
red person means the train is pretty
packed in second class okay so you
pulled out the data oh I want all
weekdays for trains going from Geneva
Allison to Geneva and by our i want to
see how many trains will circulate okay
so we have the peak for the rush hours
and within these strains which is the
percentage or the fact of train which
are one person so there I saw that seeds
or have any pact and this is a big
discovery we think that between seven
and nine there is a lot of people taking
the train okay so that's the thing that
you will learn today I was sure you were
learning something same thing in the
evening okay so if I want a home because
it's hard to find a spot at this time I
can wake up earlier that's a solution
okay so much or we live in a capitalist
country we can pay and go to first class
and make the same measures of first
class and then we see that it's never
really pact between Geneva and design
okay the idea here is not to make a big
discovery scientific discovery about the
house I wish them we are small to see
how we what we can do with the data
question if you have a train at one
moment during the day when is it more
likely to be late is that six in the
morning at noon when is it it's a
question
sorry in the noon in the evening yeah we
did not cover that very woman for we
could have couple of the information we
didn't that yet I've been night in the
night they are very little pain okay
that the red line shows the number of
trains that are circulating died very
very little trains during the night but
they are very likely to be late don't
ask me why all right where are the train
de Mer most delayed so here is a map of
Switzerland here is some kind of histo
drama of the number of strains that are
in the that comes it through these
different places so here we have a hot
spot in a lake now we focus on where
they are later most often ok hiya I
think you have a lot of play trains here
and also okay if you go to da Matta
you're likely to be late we've is less
important but ok tuning how do we do
that we want I want I want a tool to
analyze the data and then be able to
show the results we convenient to
politics result but also to share the
results with you and to share the code
that goes to produce these results
because my code is a handy buggy so you
want to be able to reproduce my results
another data or whatever how do we do
that share the code should say that this
morning if all this movement about
reproducible science ok there are
notebooks that are used to that and this
is Jupiter it's a Python so even had to
do a little bit of spice and for for
this fermentation so you write code read
read the headlines with the store data
maybe you transform it and then you make
computation and within your notebooks
you see the result you can execute a few
lines and see the result and modify this
line so it's very interactive way to dig
into the data and if you are fine
despite on Jupiter is a very good way to
go Jupiter so is a web application its
interactive is strongly inclined to us I
turn also you can use of the language
you have ready to be where nonetheless
about the size just for a few months
that i will show you was for four or
five months okay takes up I don't know
two gigabyte of tsv 554 gigabyte you
cannot load the load that all energy
detail so you have to sample that and if
you want to process all the data in the
notebook you have to move to order a
solution to zeppelin which is a stack
oriented parallel oriented a notebook or
if you want to have fun and make
beautiful figures go to apps to do so we
have it all okay now about Warren a
structure we could remember don't pick
up I don't say oak to or alex at octo to
do that each of these component was was
the solution for your prediction
architecture we can talk about that okay
so conscious project we could have used
oil back with tried several other breaks
along this project like angular 2 or
whatever other databases and so on and
the list is really big so there is more
than one way to do it it's a part it's
on github and just which is cool that is
openness plenty of question and so never
Oh case we don't see the end of question
that we can start pursuing with this dis
dis project and I like to thank you very
very much I think if you have a couple
questions if you have
maybe just an easy question how do you
do the modélisation of the data so I'll
do you know of the best way to to create
models for the data okay and maybe what
do it is the best under if you know is
any standard for the Jo Jo yo make Joe
data because I think at the end is
justified like a cheetah okay yeah
thanks for the question the thing is
that this approach somehow you try to
turn it around you model the data
depending on what you would at the end
what the queries you want in fact you
know what the queries you want and
somehow you will very often d normalize
the data because it's more easier for
the analyzers it's easier for the
visualization so you are not afraid
about the anomaly which is kind of a
crime in the order of the main but you
were really often see what are the
queries what do i need and i model the
data regarding to whether what I need I
can endure the standard if you go to
elasticsearch visualization then the way
okay you're it would be easier if you
named latitude and longitude according
to the standards but that's more or less
all that it has if you go to some
databases suddenly you can use geo
objects so it's easier to then make
queries about I don't know packing
things together who is close to me so
there are some some database that will
have some some geographic coordinates so
thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>