<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microservices with Kafka by László Róbert Albert and Dan Balescu | Coder Coacher - Coaching Coders</title><meta content="Microservices with Kafka by László Róbert Albert and Dan Balescu - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Microservices with Kafka by László Róbert Albert and Dan Balescu</b></h2><h5 class="post__date">2017-08-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/c9S6fJaAlzw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to our presentation
it's microservices with Kafka this
presentation it's a Napoli tutorial or
in any way about micro-services nor
about Kafka but it's more to share with
you the challenges that we had with our
project and how we address them and also
to challenge you in building on top of
Kafka so you can bed it in any way you
want that we serve your needs almost any
way you want that will serve your needs
so this this is the idea with what we
want to do with this presentation of
course we have to do a short intro hi
i'm robert i am an enthusiastic java
developer and father of three two girls
and a boy and i had the opportunity to
work in large multinational companies
like IBM - undines and ing where i had
the opportunity to learn quite a lot
about how to do high-performance
software and partially this is what we
achieved and we will show you today and
I give and I am then Danville at school
I like Java what can I say I have like I
worked in many companies but the only
thing in common was Java also had
different roles and again Java related
so I could not escape Java Java could
not escape me also I like to travel and
to do some mountain biking also have a
very nice family and proud of it but we
do something very nice together
Robert which is we work for Angie in
Bucharest Bucharest we are Romania
basically I know it seems a bit a bit
more smaller compared to Poland
what is also an IT hub like Poland and
we really do like programming in Romania
in that we like it that much that we
have like around six of our GDP being
produced with like 100,000 programmers
of course this is not the latest data
maybe these numbers are change by now
and compared to a let's agriculture
which illuminate it was and it is very
famous for we have like point point four
of GDP with almost 1/2 million people so
you see the weight of programming in
aluminium now when we started this
journey with the project that we have we
want and what actually everybody wants
with this I mean things like the
performance for torrents real
scalability reliability these are like
it's almost we look at him like common
sense disease I mean we could not
imagine an application that could not
handle this kind of requirement however
to have this requirements in place you
need to I think it starts with a good
architecture and for the scope of this
presentation we have chosen two
architecture examples and yeah the first
one is this yeah it's it's actually not
an architecture it's this is Fiona for
those of you who have kids I'm sure you
know it she's a princess very beautiful
one yeah depends from the point of view
and she's priceless and she's very
high-maintenance so if I would have to
make an analogy I will look at Fiona
like a monolithic application yeah it
seems so more something like that
yes monolithically do you use my
heretical applications still anybody
I hope ok I'm sorry for you actually
it's not true because I don't believe
like we have a tool or a software
whatever it is that will answer all to
all of our needs so maybe in this world
somewhere some company in some far far
away corner they have some business case
where a monolithic 'el is the only way
for tor the best way for tailor their
approach it may be so I'm not saying
that yes monological are crap they have
some advantages they have for example
simplicity consistency you have a single
technology stack which yes it's useful
or it was India we useful sometimes but
also have some very dark side and yeah
don't scale very well this is something
that we also encountered I can give you
an example actually we I cannot give you
names but still we had in our company a
web application which was a monolithic
of application which was that large that
could not the application server where
you was deployed to could not handle
adding new more features so we basically
we're stuck with those features and we
couldn't do more so yeah sometimes can
be a pain in the ass to have a moment
equal application also tight coupling
which is not so good we all know it and
definitely have to move to new
technologies because it that's easy too
yes let's switch to a different
technology with all the wanted
application so ok what options do you
have actually Robert and I and the team
also thought of of it and nothing came
up actually we didn't came up with any
idea however one day we were in a park
here over tonight
we actually encountered this guy you
know I'm just walking like two guys in a
parka and look then he said donkey and
you know he's I don't know if you know
his name yes it's donkey obvious da and
then we realize like we had a aha moment
and here's this 41 we need a donkey for
our development and why a donkey because
donkey is not expensive right there are
so many donkeys compared to princesses
which they're not so many they do one
thing and one thing well I think this
like it's eating the shreds nerves and I
think this was something that we we
wanted because it was highly scalable we
could was loosely coupled which exactly
what we want so we could handle
different technology stacks different
application integrate them and I take
words together as a whole so why not and
then we took an let's say an example
since we are a bank right we work for
ing so we I think the best way is to
give you an example on the banking part
you have this Account Manager
application which is actually doing only
some banners checks so basically checks
how much money are in your account then
let's say that I want to transfer some
money from my account to or know from
Robert to come to my account I think
it's better this way
and yeah what can we do to have this
money in my wallet well I definitely use
this account manager and yes I need a
core banking component this component
will actually move the money from one
account to another account but there
must be some some logic somewhere
somebody needs to tell them what aha so
yes we need another one so as you can
see we'd have these three components by
working together
to deliver a service or a capability
mean ing actually we have many
capabilities to deliver so that is why I
think we have a lot of donkeys which is
very good but these donkeys actually as
you can see they work very well when
they are combined so when you tie them
up together then the real power comes
out if they take them in isolation they
won't do much but this is was idea and
having this donkeys working together
it's quite a challenge especially on the
communication part because communication
even though we thought okay it's easy we
just send some I don't know directives
from one component to another actually
when you have tons of them and so
complicated that it's not that easy and
the communication can become a
bottleneck in this case so in ng s we
have like a lot of not only these
donkeys but a lot of them but if I would
let's say give you an example from a you
bow-like company like halo which they
offer a simple easy to use like
everybody these days they want to offer
to their customers something very easy
to use however they don't say that
behind those easy easy UI that we have
there are tons of services working
together to deliver that service
basically for example halo it's using
around I think
let me count yeah 450 services yes I'm
very good at math yes but as you can see
many of them are talking to each other
there is a maze there so communication
is important and if we take for example
guys like Netflix or Twitter they have
quite a lot of micro services
so yes many of them communicating hmm
but how much actually they communicate
how how many messages they exchanged
well
Twitter is about 500 million messages
per day which is okay
Netflix like 700 billion so we move
scale which is quite a lot I think to me
and then we have LinkedIn with one point
four trillion messages per day I think
this is definitely much more than my
mother-in-law talks every day
and believe me I I actually worked on
counting how much she talked so they
exchanged a lot of messages that's the
idea Andy let's say the way that they
handle these messages yes there are a
lot of options on the market however the
performance for these those options will
not a stir the demand actually and the
solution came up from this little guys
which is you know the picture
it's Casca guy so if we take some
because definitely we wanted to
understand a bit okay
Kafka cost about how much this cost a
guy can do can handle well
we had a look at the features that have
to have and definitely Kafka has loads
of them so we did a short comparison
with active NQ and RabbitMQ which let's
say we're at that time our main come the
main competitors and you can see yes
both active NQ and web team queue offer
this feature but Kafka know then GMS
support so yes
Kafka again now the part of
authentication authorization again no at
some time we were wondering does Kafka
for something because we didn't find it
find it yet transactions no so what you
know filtering of messages of course no
yes we found one persistence but then we
look on the other side so but those guys
also are offering persistence so is
there anything else out there then we
came up with this which is a short
comparison in terms of performance and
then we also have okay that's with the
reason so we have performance so
performance in means the map the number
of messages that are same and how much
performance do we actually talk about we
have this comparison which is like I
think LinkedIn publishes like five years
ago and you can see you have a producer
this is what you have on the screen you
have a single producer Kafka producer
and also we have the comparison between
appearing to producer and also rabbitmq
and as you can see it's ending like I
mean this this use case was sent ten
million messages
it doesn't matter here with these three
producers and send them letting batches
of one and batches of fifty as you know
it's more performance wise not to send
every time a message but have a batch
and then send it but still the
comparison is that is good to show you
because also you can see so Kappa is
happening a batch of one which is the
most inefficient and still if I'm
counting again well Kafka is sending
like five fifty thousand messages like
with one batching like four hundred
thousand messages per second with fifty
with batches of fifty so it's quite
impressive when you talk about
performance then compare Kafka with
others so okay but what about the
consuming part because when you have a
broker definitely have right to
components you have actually
without the brachot itself you have to
like producer and consuming so on the
consuming side again Kafka is quite far
away from the his competitors actually
and it managed to consume like twenty to
twenty two thousand messages per second
which is again quite impressive so okay
now I think it's clear we understood why
we should use Kappa and this was
performance but we have a big drawback
didn't have any future future within the
offer a story feature they didn't offer
any feature
except this performance okay we have a
broker you have a consumer and the
producer but yeah except the the
performance they don't do nothing much
and then we have a force on business
cases I will talk later on to fulfill so
okay what can we do since craft is open
source and said okay now we can do
something about it and to to let's say
emphasize a bit why we have to do
something about it we can give you one
of the business cases which was this
micro service to micro service
communication so as you saw earlier we
have we have communication like a very
important thing to us and we needed high
performance communication so that's why
we had this case we have a micro service
trying to send a message to another
micro service so on the other hand we
have a producer and the other on the
other you have a consumer this was one
of the use cases so one-to-one and
unidirectional but also you have big
directional communication so also we
have to fulfill this use case right so
be that the micro service be should have
replied something to micro service a one
thing which I want to mention it's not a
synchronous our story is not synchronous
I mean we shouldn't think about
when you talk about CAFTA we shouldn't
think about the synchron so everything
here it's a synchronous so they
shouldn't be waiting or blocking for
some activity like Michael said we'll be
waiting for something also we have this
use case which is one too many so yes it
was important to us to have a relative
multi mark mark people micro-services
consuming messages the same we have the
same message from a producer so this was
again something that we had to forfeit
and I think I'll let Robert move on on
the challenges that we had please yes so
our first challenge is well you may ask
if these are the features that we have
to fulfill then why we just don't use
rest right because we trust you could do
all of this except the part of the
synchronous thing but it will do exactly
the same it will send messages
unidirectional way be directional way or
even even making a simple notification
so then let's assume we have a system
composed of two micro services service a
which will send a message and service B
which will receive that message and
doing some processing and maybe later on
to store it in a database so first of
all you will see two two issues with
this first of all is that well actually
even before that this communication is
synchronous but beside that you see the
other issue is that actually service a
has to know exactly what's where service
B is and it's it's response time is
dependent on service B's response time
so it's performance it is directly
related to the performance of service B
and also it it cannot answer without
first having the response of course
zombie and the it's also dependent on
the uptime of service B which means that
it's uptime independent on service on
service B well and what we can tell is
that a system is as weak as its weakest
service but before that we can raise
some other questions like how often does
service be failed how often is down for
maintenance
what is its peak performance and all
these can raise you some questions that
from some in some cases might be
difficult to answer so let's see then
how this would compare with having Kafka
instead well having Kafka we have quite
a different story
first of all a Kafka topic has a trick
half its in sleeve its persistent by
default so this means that system a has
to make sure that the message will be
delivered if Kafka and eventually system
B will take that message and will do its
processing again and everything as that
needs to do so then we see that well
first of all this rig is a synchronous
second of all we will see that actually
service a doesn't have to know where
service be actually is there so there is
no much coupling on it and if you go
further then let's see how we do if we
are talking about scaling this so let's
suppose that at some point service B
it's not fast enough so what you will do
you most probably start a new service B
right
and this is all fine until a certain
point is that actually you have to make
service a to know about the additional
services most of you what we'll do we'll
add most probably a load balancer in
front of it which is still working but
this means still that you have to make
service a to know about that load
balancer even more you have to do
additional monitoring on your services
for uptime for responsiveness so that
the load balancer actually could do it
balancing and if you go even further we
can also add another service G which at
some point my need exactly the same
message so this would need that again
service a now we'll have to know also
about service G so that it could deliver
the message to to that service as well
and if you are going with the analogy we
can see that if this we have to scale it
we quite have some issues there
of course there already some tools that
can help you in doing this and let's see
what would be if we would use kafka
instead well again
Kafka has another trick up in Eclipse is
that a topic can have almost as many
consumers as you want of course needs to
be tuned but from services point of view
it has to do nothing it will still
deliver the messages to the same topic
or if you are doing multiple service V
services in parallel you have to put
them in a in the same consumer group and
then Kafka will will load balance for
you out of the box if you need another
service like service G to consume
exactly the same message whoa you hook
it up to the same consumer without any
other change in your infrastructure so
all these shows that actually Kafka
would be a better choice
and using compared with spring starting
with rest yeah you can use Kafka with
spring as well well they have a pretty
good integration with it and then he's
not working for people on bodies but
having chosen Kafka actually we had the
opportunity to to implement a an
additional use case which would be the
login part as we have quite a lot of of
micro-services all of them are logging
quite a lot and well being a bank they
need to have these logs centralized to
store it for years even and this would
make them difficult to do it in
traditionally through files they do it
like that until now but this of course
gives them the opportunity to do even
more than is that well if you have an
application that it's working with some
other systems who knows if that system
is down not the guys that actually are
monitoring it is the application that
actually tries to use that service to do
something with it
so it will be the first to observe that
actually you have an issue and can
trigger an alarm so this opened up the
possibility to do near real-time
monitoring and to monitor your systems
by these alarms and they had pretty good
results having this in matter of one or
one and a half seconds they already know
if the system is down good so for that
first we need to start somewhere
so we could have used directly the
native Kafka API but this wouldn't allow
us to actually implement
and add all the features that were
needed because well most of our the
users that had to use Kafka they were
quite used to GMS having it before so
they wanted similar features to have
their and we had to open this
opportunity to actually be able to do
this to not have all of them to
implement the same things in different
applications all over so we started by
making a producer we try to make it as
simple as possible and this is quite as
simple as we could think of so you have
only a producer factory that is creating
you a producer that will send messages
to a given topic and then this producer
have a method that's called
send so it's pretty easy the message
here that you will see it's more like a
a message with having a payload and and
some key value pairs it's pretty similar
to other matched messaging systems that
they have as their generic message type
its architecture it's it's a bit come
more complicated than you see here
because actually we have we have an API
part for clients that wants to to use
our library and we have also an SBI for
those that actually want to extend with
further features our application sorry
our library so we but simplistically
it's it's more like this we have a
producer factory which in the background
uses of course the native Kafka producer
API you can of course tune your your
producer the native producer in the
background with the native properties as
well we treat the security part
separately because well security it's
quite important and
especially for for certificate their
location and the password that you have
are are very strictly monitored so we
are treating them differently and of
course from this we can produce the
producer that looks more like a rapper
but it's a rapper that opens you the
opportunity to implement all the
features that you will need so now that
we have a producer actually we were able
to implement the de login part and on
the left side you can see actually the
traditional way of logging by using the
file appender which will will produce a
log file
then we had some applications that log -
forwarders we are saying to them that
we'll monitor these these log files and
will forward those messages to the exact
and later on can be processed by other
systems as well on the right side you
see the implementation done throughout
our producer and we are then producing
messages - Kafka the logging messages
through Kafka okay so as we have a
consumer a producer part of course we
need those to be able to consume these
messages and our philosophy was more or
less the same to be as simple as
possible so again you have a consumer
factory from it you create a consumer
and then to that consumer you are you're
registering the receiver Handler to it
and you are processing the message
already it's architecture again it's
pretty similar with the one of the
producer again this is a simplistic
version here again we have an API part
and an SPI part but I don't want to
bother you with that anymore so let's
see what kind of features we enabled us
to do so our first feature we are
calling its realized what we did
actually is that opened up departed the
opportunity that when we are want to
send a message before that to be able to
do some transformation on those messages
and even more to do some custom
serialization on it by transformation I
mean informations like I don't know
inserting the user ID that currently
it's doing the transaction or inserting
the timestamp when this message was
triggered to insert maybe the hostname
from which this message was originated
when even more by civilization we were
meaning by I don't know encode the this
message as adjacent encoded as an XML or
encoded I don't know with Google proto
but maybe if you if this is your need
and actually even more we have the
opportunity to also encrypt the
information before sending and of course
on the consuming part you have the
reverse of it good so another feature
that we saw also in that table before
that we didn't had filtering and
actually we implemented filtering in two
ways one of it was doing another micro
service here is the one called filter
it's actually a micro service that with
us which simply listens to one topic and
based on some metadata will filter out
that information to be sent to another
topic or not you may ask why actually we
would do that if it's Kafka so and you
could hook anyone there well we have
some strange requirements like given
topics are allowed to be accessed only
by a little amount of applications and
no one has it allowed to actually
consume from there because the data is
too sensitive to to allow that everyone
to use it and but there are those
few amount of applications that actually
want to do processing with it they they
can use it like this and well their
power it's not necessarily by using it
individually it by using it together
with all the features again we have
another transformer another way of doing
transformation its besides how you how I
showed two slides before so here again
we have the same situation we are
listening to one topic based on some
method that that we do some
transformation of this message and
sending to another topic actually this
is something that also the monitoring
application is doing because from their
point of view a log message is just an
event like any other message and again
we have these forward and dispatch which
pretty similar it's more like doing
reading rereading the message from a
topic and based of course again some
metadata will will dispatch and for two
other two other topics and as I said all
of these individually are not doing too
much but when you combine them with our
donkeys then you start to get quite
interesting features and and
applications to implement and here is
another cool feature which we could do
because we are we used Kafka what this
feature does this replay feature is that
as you Ino a Kafka topic its persistent
its persisting the data on the hard disk
and actually that data it's available
for you for a given period of time which
opens you the opportunity to to do some
hacks Ani
and why actually we need this is well
how many of you actually here are
developers quite a good how many of you
actually develop bugs as well
I like this we are doing the same
so having micro-services of course we
have the opportunity to to update them
more often than before and of course
sometimes time we are developing some
bugs with the features as well actually
bug is a good feature or a feature it's
a bug
anyway so the idea is that if we realize
that actually we did process a message
in a wrong way then we have this
opportunity to actually reprocess those
messages and what this functionality
does is that it will go on the topic
message by message it will check if
indeed that message was one that was
processed in a wrong way and then gives
us the opportunity to resend it again
and reprocess it in the correct way okay
so well these are not all the features
it are features that we are presenting
now we have many other features that
opened up the opportunity for us like
having different versions of Kafka to
work with and many more and you may say
okay but these definitely they have some
costs and if they have actually what my
colleague didn't mentions was that in
2014 or 15 the guys that developed Kafka
they published the paper where they show
you how to send more than 2 million
messages per second via Kafka with four
or five simple hardware simple cheap
desktops so it's pretty easy to send an
amazing number of messages and we wanted
to know okay this overhead that we put
on it it will make us to be still able
to send that many messages or not so we
micro benchmark we micro benchmark the
amount of of processing that we are
doing from the moment you you call the
send method in the producer on to the
moment we would have actually send it to
the native Kafka producer so the amount
that we are wasting by processing by
doing our additional logic on it and
here you can see messages of different
sizes and different payloads and what is
important is that most of our messages
are around 500 500 bytes and with 500
bytes you could send about 2.7 million
messages per second and in some special
cases when you want to do even more you
can actually do of course by reducing
the size of the message so if you want
more performance then you will have to
drop some of your Aunt stamps or server
names and things like that but you can
send that essential data we were able to
achieve more than 9 million messages per
second so you can do it almost at the
same rate as as Kafka is doing because
when we are having all these and sending
to Kafka of course we weren't able to
get that 2 million messages but we were
pretty close to that on logging part we
were able to send only two hundred and
twenty four thousand messages per second
and this was due to the requirement that
we have actually these messages are
quite huge and they are containing a lot
of info and besides that they are also
having a digital signature made for each
in
visual message so this cost us quite a
lot but we were still able to process
two hundred and twenty thousand messages
per second with one producer okay so we
saw that actually we have Kafka which is
very performant not too many features we
have other competitors that have quite a
lot of features not that many
performance so by adding some features
on top of it you can actually make your
Kafka to be almost that performant as
the vanilla Kafka and almost as
feature-rich and the competitors and
this would be more or less a lot with it
and what we wanted to show you and we
would want to embrace you to to do the
same because it worth it you learn a lot
by doing this and your boss will
definitely pay you an attention by doing
that this is questionable thank you for
being with us</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>