<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Back to the CompletableFuture: Concurrency in Action by Dmitry Vinnik | Coder Coacher - Coaching Coders</title><meta content="Back to the CompletableFuture: Concurrency in Action by Dmitry Vinnik - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Devoxx/">Devoxx</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Back to the CompletableFuture: Concurrency in Action by Dmitry Vinnik</b></h2><h5 class="post__date">2018-04-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/i3iDIP4PTLk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks everyone for coming to this talk
so today I'll kind of goes through
concurrency in practice or as the fancy
name tells you we're gonna go back to
the completable future my name is
Dimitri Vinick I'm a lead software
engineer at Salesforce and so with such
a fancy title you might be asking
yourself what the goals of today talk
and so I want to be clear on what you're
trying to achieve today so the ghosts
are actually quite simple
so the first we'll actually talk about
concurrency in different forms and
ultimately we'll try to attend to couple
of misconceptions around concurrent
concurrency and ultimately ultimately
debunk them and at the end of the talk
we'll try to actually focus on workflows
on how and why to use them and so with
that you might be asking yourself why do
we even have to talk about this and
motivation is actually quite simple to
prove just by looking at the laptop that
I have you have to admit that multi-core
machines are a standard these days you
can also say that micro services are so
abandoned these days they're not even a
buzz word anymore
and obviously the computing cloud
services like Azure or AWS are driving a
huge chunk of the Internet and obviously
you can also say you know the Moore's
law and talk about this for hours which
we won't be actually doing and but you
still can make a conclusion here is that
the concurrency is a new reality and I
wouldn't go further to say that's a
reality today and you would either have
to embrace it or it will be imposed on
you and with that I like to actually
talk about what's in it for you guys
yes industry in changing the world is
changing itself but what's in it for you
as a developer and obviously there are
some benefits you might be interested in
so the first thing is obviously you
trying to minimize the waste I said
we've highlighted before the multi-core
laptops allow us to utilize CPUs further
than just one single thread application
so not to waste resources we have to
utilize them the abundance of agile is
the primary methodology to develop
software with the primary focus on the
user
concurrency allows you to increase the
user experience basically no more
painting window while you click on a
button or trying to change the views and
obviously you're trying to abstract
complexities because when you work with
concurrency it's complex enough so
you're trying to cap slate all the
difficult parts away from your code and
so yeah they're only the good parts
right not really there are complexities
hence this stock and so some of them are
pretty simple you know the thread safety
itself the race conditions that are
famously known and all the bugs are
usually blamed on them you can also say
liveness is a concern how multiple
threads share resources between each
other and obviously the performance the
common misconception is to assume I have
a single thread application let's make
it run as two threads and now we're
going to have a performance improvement
improvements twice full that's not often
true you I can actually degrade the
performance by switching to concurrent
application and also you're actually
impacting the entire development cycle
whether it's debugging development
itself or testing and so yes that's
complex the concurrency complex by
itself but obviously it's beneficial as
we highlighted earlier
and I would even go further it's an
engineer engineer I can call it someone
beautiful and you can think what it
actually mines you off personally
concurrency to me looks like this fella
so you can see so first and when you
actually try to read about concurrency
you let's say you open this book Java
concurrency in practice by Brian goats
you actually faced with the sheer fear
of complexity that you faced with it's
similar to this book the shark feel and
beauty by January you because you don't
really understand it whether it's a
shark or a concurrency your first feared
of it afraid of it and so by actually
exploring it more you can see the beauty
whether it's in concurrency or in sharks
and so this is actually a primary goal
of today's talk we'll start with the
fear of concurrency and I'll try to go
go with you through the path towards
admiration and this particular path it's
what this talk is going to be about and
it actually will create agenda for today
so we'll start with the concurrency in a
single-threaded world we will move on to
the multi-threading application of
concurrency then we'll talk concurrency
more in the context of Java or it
actually means for us the Java
developers I'll try to close off with
the workflows the synchronous
programming in Java particularly so
let's actually start with a single
threaded context so again you might be
asking that why do I even care about
concurrency because I can say you know
my app currently is a single threaded
app it's too complex to even care about
concurrency multi-threading or you know
the common approach to legacy system if
it's not broken don't touch it and I
would say some concept you can apply
regardless of the environment you're in
the such concepts like design for
concurrency that if you read the
pragmatic programmer really encourages
you to use throughout your day-to-day
job regardless what were you working and
so what it actually implies is you're
trying to tackle any patents like
programming by coincidence you're trying
to avoid them you're focusing more on
the patterns such as design by contract
another anti-patterns you're trying to
avoid is the temporal coupling that can
be applicable to you regardless of the
environment you in and also trying to
move towards this common pattern that we
all use throughout our practice like
imitability and keep your functions
atomic so let's actually look at them in
the isolation so let's start with a
simple NC pattern programming by
coincidence and this anti pattern it's
very easy to describe as soon as you
encounter a barking production because
when you face this about you usually ask
yourself you know he did just break or
was it broken all alone and to actually
show you a real use case as developer so
like we see the code itself right and
this is a common example as everyone
likes to complain about time packages
from all Java days this is a good
example the simple date formatter people
just made an assumption that you know
it's probably thread safe to share
between instances instances over a
single class let's make it static
because it's simply you know formatting
our date to string that we specify
but sexually not thread safe so the
assumption was wrong and many engineers
actually used it and so they tried to
use it between multiple threads and
ultimately it actually gave them the
incorrect results in certain cases in
unfortunately the Java dogs of this
class for the quite a few releases did
not even specify whether whether it was
a thread safe or not so it didn't
actually help developers to make their
decision and so the the way to tackle
this problem they had to basically
synchronize it in case if they actually
caught the problem but it shows you that
the code gets more and more complex and
so to tackle programming by coincidence
you really have to program in dentro
intentionally what it means is you need
to know exactly why it works you know
that meme online where you know it works
I don't know why it didn't work I don't
know why it's actually scares me quite a
bit because you really need to know why
it works but if in case you don't have a
ability to understand the you know
interconnectivity of a library you use
try to ensure that it actually works the
TDD is great for that
but you know if you try and to just test
the business logic you might also need
to test it under cases with one the
multi-threading environment comes into
play so do some low to stress tests and
really share how it works the case I
showed in a previous slide about simple
date formatter gives a great example of
undocumented functionality whether it's
thread safe or not really broke a lot of
applications along the line so don't be
that guy design by contract is another
great pattern that you can utilize on
your day to day job regardless of the
environment you're in
and the way to describe it is the look
at the contracts people have your
employment agreement for example you
have responsibilities to your employer
to do the work and you're you have the
right to get paid for that work that's
exactly what design by contract is but
in terms of code so how it actually
works is let's say you have a function
where we just sum two integers and so we
say I have a write for this function
that both integers are not now so that's
my right then
I can also say you know in Java I can
also add annotation it also gives the
information
to the caller that I expect them not to
be now and it's your job to handle it
then you do some operations which is
meaningless for us in this scenario but
what actually matters for us is this
last statement it's our responsibility
for this API to give a non negative
result that's what the design by
contract is the first couple statements
where we come we say we expect it to be
non malleable and we're going to give
the result which going to be larger or
equal to zero so to sum it up it's
basically all about rights and
responsibilities of your API it's a fail
fast design that you try to enforce you
know instead of handling now throughout
the code you just check it right upfront
and again you use your code to
documentation it tells the course of
your API directly what you expect it to
be another anti-pattern that common in
any application is it important and so
what actually it means is where you
where time and order of your operation
changes state of your behavior
drastically so to give you an example
maybe this phrase was kind of a
cumbersome to give you in a good example
let's say it's lunch time I'm getting
hungry I have some leftovers from
yesterday I go over to the microwave I
you know I initialize my microwave and I
say hit my lunch in this case it's pasta
but nothing actually happened after me
doing that and the reason why it didn't
happen is because there was the state
identifier the field on the microwave
whether it's plugged in or not and it's
not plugged in by default and so to fix
it I actually had to invoke the
operation to plug in the microwave
before I was able to use it this is what
the power coupling is about the the
difference between me calling plug in
before the actual operation versus after
changes the state of microwave and
ultimately the result of the function
drastically and so to tackle it you need
to understand your flows really you know
people don't use UML's as much even
though they hope to just you know join a
white board some time what the main
flows that you have it will allow you to
pinpoint dependencies and minimize them
ultimately but if you really have to use
steamed pork coupling and other matters
to you try to minimize room for error if
the state of your instance is important
to you try to pass the flag for example
in this case plug in as the argument to
the constructor you call it and so the
last button that you might be using
today is the keeping your code immutable
I'm not going to talk about it too much
because we all know it's been written
about for decades now and thanks to
jashub law who actually popularized it
quite a bit in java so this small
snippet actually illustrates it quite
nicely you know when you initialize the
instance you have a state in this case a
path over file which cannot be changed
but it can be retrieved and so what it
actually gives us is minimum number of
side effects you know the state
regardless of how many threads using
this instance you are minimizing these
design smells like tempura coupling
because the state cannot be out that you
don't have to worry about operation that
being cold and it also simplifies the
development itself you have fewer moving
pieces in your code and so with that if
you were to just use this design for
concurrency principle throughout your
code whether it's a existing application
or writing a new app doesn't matter if
you were to take this away from this
talk it would be great achievement and
so to move forward to the
multi-threading bit more interesting
it's the good question to ask is what
kind of forms can multi-threading take
and there are three main forms we're
going to talk about today and they will
be a concurrency there are parallel form
and a synchronous form and so let's
start from the top the concurrent form
basically implies that you have multiple
tasks running logically in parallel what
means what that means is that if you
have a single CPU which means the
multiple CPUs are not required for this
pattern for this form you you're going
to think that it's actually parallel but
in reality the single CPU actually keeps
pausing the single task switch into a
nag next one then switching back and so
on and it can be kind of illustrated the
ideal scenario with multiple CPU using
this diagram but you can say it's way
too abstract
so let's actually do something about
this form and I would say let's set the
goal to develop an application and what
do we need to develop a new app it's
fairly obvious we need coffee and we
need the laptop and you can see the
priorities are in order first the coffee
and then the laptop and so let's look an
example we have a great engineer John
John has a single line of focus he can
only do a single thing at a time
but he ultimately has a goal to develop
an application so John drinks coffee and
he put down the cup he grabs his laptop
he does some coding put the put down the
laptop grabs the cup of coffee and so on
so well it seems like he actually
performs both tasks in parallel so it's
logically simultaneous he's actually
doing them interchangeably so it seems
like he's done them all in autumn would
ultimately develop an application so
that's John I took in a second form the
parallel form she bit more complex than
that so the parallel form is similar
it's more about multiple subtasks that
one physically simultaneously so that
would require multiple CPUs to be in
place a good diagram to show and to
actually distinguish from the concurrent
form is if you have a single task you
split it into two sub tasks after they
complete the result get merged and you
ultimately complete your primary goal
again let's go back to developing an
application so developing an app again
you have a cup of coffee you have a
laptop but now you have a developer who
is an ambidextrous are people who can
actually use their hands you know in
isolation without interruption and so
let's look at the web developer Jenny
Jenny has two points of focus now
because she's 90 Dexter she can drink
her coffee
and develop an app using the second hand
without interruption and so it actually
means to us that she can be doing these
two tasks these two sub tasks completely
in isolation in parallel you can say so
that's Janey
let's now look at the last form a
synchronous form the one that we're
going to focus at the end of this talk
and so with that it's more of a pattern
fire-and-forget while you have a primary
goal like we had in the previous
scenario to develop an app you fire some
outside tasks that we don't really
depend on but we care about the result
of for example if you're you know
customer going to the ATM to withdraw
some money you start in a synchronous
task to log information to spunk if you
fail to do so in this asynchronous task
you don't want to just interrupt there
with Joe in process but you still want
to know and log it somewhere else and so
it's important not to be blocking
because again we don't depend on this
task and it requires multiple CPUs and
the in terms of the diagram again you
can see you have a separate asynchronous
task triggered while the main one is
running in separate high CPU so again to
develop our application we have a cup of
coffee I have a laptop but here's a
question that you might have already
asked yourself where does the coffee
come from
obviously it's coming from the coffee
machine but now scenario again we're
coming back to John who can only do one
thing at the time he can you know drink
coffee put it down to some coding etc
but then we also have a great colleague
of John Henry who has an asynchronous
task gonna be the guy bringing in the
coffee there is such excessive amount of
coffee on John's desk that John is not
dependent on it but still it's nice for
Henry to be doing that and so Henry
keeps brewing the coffee for for John
and that's basically a synchronous task
that we don't depend on
we're not blocked by but ultimately it
helps us with the completion of primary
tasks so that let's actually look back
at the concurrency in Java so you
probably all worked with runnable sand
threads they actually question for you
guys how many of you used runnable sand
threads before raise your hands great
that's what I would expect it's actually
the reason why many of us have the
misconceptions and fear of concurrency
because after
use threats and runnable this is where
we actually stopped but the concurrency
API moved quite a bit but first let's
look at what people had to deal with so
runnable is full now you know it was
quite a selfish class it takes no input
it gives us no output and it doesn't
have any checked exceptions so again
it's a simple example you know you have
a drinking coffee process that you
initialize the runnable you override the
run process by some logic then you run
it if you run it outside of threat it
doesn't actually do anything special so
nothing interesting here but the threat
though it's backed by runnable and so
you always have at least one threat so
if anyone hasn't raised their hand
before you actually use threat one way
or another so an example here again the
same process of drinking coffee you
supply your runnable in a constructor so
using composition and ultimately you
know you try to start it but you
actually have to be aware of a creation
overhead that wouldn't be important in
the next couple of slides creation of
threads is not cheap so then you know
runnable threats are great but then GDK
five came along I believe it was
released around September 2004 so and we
actually were able to welcome
concurrency API so with that I'd like to
point a couple of nice glasses that
allowed us to move towards this
declarative model where we can focus
instead of you know how to manage
threads how to operate them and focus on
what we want to do with those threats so
that's the idea of declarative model
they started moving towards so we're
going to talk about the thread-local the
atomic operations the thread safe
collections and now of course there were
a lot more other classes that came along
with concurrent concurrency api but we
were gone only going to focus on these
three first and so let's start looking
at the thread local first the thread
local is a nice resource confinement
class that if you look back at our
example with a simple date format which
wasn't thread safe you can actually wrap
it in the thread local and if the nother
thread was to evoke it as you see here
with the threat without using
synchronization at the point where you
say my thread-local give it to me for my
current threat it allocates resources
confines those resources for this
particular threat so it allows us to
avoid unnecessary synchronization while
focusing on the task at hand but you
have to be aware obviously about memory
leaks again it's a resource confinement
so you have to deal with them afterwards
and also don't really abuse the idea of
global fields anyways the atomic
operations are a great addition to the
concurrency API they primarily tackle
so-called compound operations a good
example will be inline commentation of
integers you know if you have like AI
plus plus in the for loop it's actually
not a single operation it's three of
them you have to get the current value
of the variable at hand you have to add
one to that variable and then assign the
new sum to the variable itself so there
are three different operations and if
you were to do them individually you'd
have to synchronize it which is fairly
challenging in terms of a resources
waste and the hands with atomic
operation you can really increase the
speed of your operations by using
so-called compare and swap operation
under the hood and so if you look at the
real example the atomic long it just has
a single invocation of increment and get
on the counter itself you can also use
it to you know wrap reference if you
were to switch context during you know
if you're writing the crawler of some
kind without unnecessary synchronization
that you might be establishing and so
with that I'd like to move on to the
thread safe collections and with an
example of concurrent hash map which
people probably know from working with
concurrency so the thread safe
collections again they trying to tackle
the compound compound operations when
you check the collection for an element
and you retrieving it it all will be
multiple operations you usually would
have to synchronize on again it's
tackling the the speed the loss that you
would have with synchronization by the
way to clarify synchronization implies
that you have to stop the block of code
you wrap we think
nice block for all the threats while one
threat is working on it so you can
understand how much of a performance
heat it would be and also this thread
safe collections allow us to configure
for concurrency so let's look at an
example imagine an old way to handle you
know a collection which will have
process ID map to its counter let's say
a good use case you're tracking how
often the separation was called so what
you would have to do before you would
have to synchronize on that collection
and you would retrieve a counter
incremented send it back to the
collection so it's fairly verbose not
even talking about the performance here
but now it's concurrent hash map what
you would have to do is a simple as
initialize it you can also notice at the
end of the constructor
you can specify additional concurrency
configuration and the only thing you
have to do now is basically retrieve the
counter directly incremented and you
done you don't have to worry about
synchronization and that's a big
improvement not just about the coding
itself but performance as well so if you
were to compare with the previous
example it's much smaller than the
synchronization block and so let's now
go towards the workflows which also will
be looking back the concurrency api that
was introduced in GDG 5 but you can be
asking where do actually start and talk
about work folks you have to talk about
JavaScript because it's a great way to
look back at what they had to work with
and how to try to tackle the problem
then we're going to look at futures in
callable transition to the executor
framework it allow us to actually
utilize the futures and wrap up with the
completable future which is part of the
title of today's talk so let's look
first to the promises in javascript and
you can talk about promises without the
callback help to basically clarify for
you guys the callback hell is an
incredibly verbose way to write code
it's completely non-intuitive and to
give an example imagine you have a
function a that supplies its result down
to function B function B perform
separation and sends it down all the way
to you know as many function as it can
handle and then you're asking yourself
why am I even here
and so how do they actually fix it they
really looked at so-called promises so
again let's look at the example imagine
you have a logic to fix a bug what you
would have to do before you have to
supply the operation you would perform
on success of this fixing but process
and on the failure so you kind of
polluting the atomicity of this
operation as well because it has to do
both the operation itself and invoking a
sub operation on the result so you have
you know you will work it like this
you supply you know go home if you were
successful and start again if you failed
in fixing the bug that was before
promises whis promises it's got much
simpler and nicer again the fix back now
only does fixing the bug and it's the
promises itself you have that you
basically chain operations you know you
get the result of the fixing the bug and
then you take care of handling failure
or success so the look actually how it's
applied in Java let's look at future in
callable and to talk about callable in
futures it's a great way to look back at
Chernobyl in threats runnable is
basically a unit of work for threat the
same koala bowl is a unit of work for
future and so what color ball is is
basically similar to runnable it doesn't
take any input but it's a bit nicer
because it gives us the output and it
has checked exceptions and so for
instance you know again looking back to
the example with JavaScript you have a
operation fixing the bug and when it
gives you the result you're handling it
for success for failure or even for
exception so nothing special here very
simple but then the futures there's
again similar to threats because they
use callable as the unit of work and
obviously future is something that gets
completed in the future so fortunately
semantics here was pretty clear and use
the so-called executive framework to
interact with futures themselves in Java
and we'll talk about executive framework
in just a couple of minutes so again
let's not focus on the executor itself
but we have to initialize a service then
you let's say you know it's
completing two dues and cult it's one of
those things you promise to do in the
future so it's a great example here so I
say I going to finish this to do in my
code eventually so I create a callable
then I say plus apply it to the executor
service and the moment when I call
service submit is when the execution
starts and it gives me the future and at
the moment where I say you know give me
the future result this is when I going
to get the code itself so that's how
futures future sexually represented so a
future sounds great but how do I
actually use it that's a great question
to ask and here is where executive
framework comes into play a great
addition to the concurrency Abe API as
well and so it's nothing more than
thread management again it's moving to
work the declarative model where it
obstructs this complex thread life cycle
lifecycle management through usage all
the threads that creation overhead I
mentioned for threads is handled here
perfectly and to give you the class
diagram again we're going to focus only
on three main pieces from here the
executor service the executor itself and
the thread pools so to start with a
simple executor itself it's nothing
special it's just a functional interface
with a single operation that's driven by
runnable so no magic here as well you
initialize the executor and you walk
execute and it's applying runnable so
again simple operation but the thread
pools transpose posts are actually
amazing they are the ones handling the
thread management and the friend thread
configuration if you were to look at
thread pools themselves you would see
that it has six different arguments
fairly complex to manage and just by
looking at it for a second you can tell
way too many arguments you know six
arguments is way too many to handle the
hence you have factories fact and more
particularly executor factories it
helped you along along the way so we're
going to look at a couple of them there
is a single threaded pool the cached
pool
fixed schedule and work-stealing pools
and so to look in just the you know tiny
little details the single thread pool
as the name suggests manages just a
single thread it's a short leaf thread
and it's great for prototyping again if
you're using interfaces executor service
you can abstract what kind of thread
pool you use so for instance you write
your code as if it was written for a
single thread first make sure that
actually works then you switch it to
some other pool for example you can
switch it to cash thread pool cash
thread pool is perfect for dynamic tasks
dynamic number of tasks I would say
somewhat short-lived ones and the good
example would be creation of crawler
service if you don't know exactly how
many URLs the website might have and
it's a fairly short operation to just
scan the content and parse it somewhere
the fig thread pool is a bit more
complex
it's handling a set number of tasks
which are running for long time it's
great for some lawn operations a
computation that you might be doing and
the initialization requires you to
actually specify how many threats you
have the schedule thread pool is
somewhat a different beast here here you
can schedule tart to run at once
somewhere in the future you can just say
chill a the run of this task you know
two seconds in the future or you can
just have a recurring process if you're
doing some monitoring or you trying to
implement your own cron scheduler or sub
sort and again there is a factory for
that the work still in pool is a bit
more complex and it's perfect for
recursive tasks tasks or tasks in the
fork/join framework that you might be
using basically the idea of you know
dividing conquer operations and it's
actually what's used behind the scene
for streams API and operations parallel
operations like that
and so you have those great thread pools
you have executors and if you were to
combine them you would get executor
service and the exhibitor service would
actually allows us to do some
asynchronous operations that you've seen
a couple slides before with futures
and it also gives us functionalities of
a thread pulls the thread management and
so again you initialize your thread
service and you're trying to crawl your
website so you have a collection of URLs
to crawl you woke the operation of
crawling on the service itself so you
submit bunch of you know futures to it
bunch of cobbles and it gives you in the
future
document the the content that you parsed
from the website it's nothing special
here
so they simple as that so you can be
asking what are we done yet and I would
say unfortunately no because the future
is not perfect future has pitfalls
tensed we have complete above issue in
place and so talk about the pitfalls of
future the issue that it might have it
really relies on a lot of blocking
operations it doesn't have an idea of
changing results so you can't really
achieve the full workflow operations in
in Java using futures long you cannot
really easily combine them and the
exception handling is somewhat
cumbersome and to look first to the
blocking operation a good one but have
actually seen couple slides before was
the get operation if you actually trying
to retrieve the result for instance you
have a crawler which crawls your website
again but you're impatient you want to
just get the result now I can't wait but
it will actually block the entire threat
here in which can be very bad for your
application you can just hang the entire
threat at least to mitigate this a
little bit always use a timeout to store
some of some sort and future fortunately
allows you to do that you can say give
it to me for you know try for 10 seconds
if it fails just throw the exception you
cannot really chain futures the the
example we've seen with promises where
we're able to you know get the operation
result and then do something about it I
can't really do it with futures and
let's look at the use case you know you
have a team that works in Kanban you
have a developer that creates a new
application but and but we actually have
to stop the entire work of the entire
team waiting for this engineer to come
with their part and only then we can say
tester go ahead and do some verification
and then again block the entire team
while the tester is working
it's very non-productive team I would
say and obviously you can try to fix it
by going towards that callback hell
JavaScript had to deal with we're not
gonna go there the future combination is
another problem using futures themselves
because again it has a lot of blocking
operations it has blocking invoke any
invoke all a good example would be lets
say you have a collection of integers
and you're trying to find the value in
them and you say I have two different
ways to search for a value I only know
linear search in binary search and let's
just walk both of them using invoke any
and whatever produces the result first
give it to me find the location location
will be the same using whatever
algorithm but whatever can find it first
give it to me but the Evoque invoke any
gain will be blocking for us the
exception handling is very important for
engineers and unfortunately with futures
you have a lot of the exceptions to
handle on most of the operations for
instance if you just have a simple login
operation here if you were evoke the
result retrieval you have about three
different exceptions to handle and all
the handling will have to happen
differently
so there are so many issues but
fortunately we have complete about
future and so with that actually would
like to focus on complete all feature
itself so unfortunately it has a variety
of operations like terms of
transformation composition chaining
combination which will allow us to
tackle the pitfalls of futures what it
actually is it implements the future and
the completion stage interface which
allow us to tackle those into pitfalls
we just mentioned and so to reiterate
futures had blocking operations it had a
problem with chaining basically having
the actual workflows the combinations
and exception handling
so let's actually tackle them now one by
one
but first we're going to talk about and
transformation and chaining to actually
get into the workflows there is a thing
again those for doing pool that I've
tried to talk about before it's actually
what used behind the scene for majority
of completable future so let's look at
that real example here you have a
developer coding their way throughout a
day but then you say you know there is a
brewing machine let's just start the
coffee making there but my work as a
developer still continues I'm still
focused on my code so that operation
making coffee doesn't block me so I
trigger it using the completable future
supply sync and then as soon as it's
done while I'm still not interrupted
it's a developer I go and grab my coffee
and drink it eventually to mention the
completable future has a lot of
overloaded constructors like you can
supply separate thread pool to use for
subsequent operations or in all ways
gdk9 that even goes back to use for
doing pool if you were to minimize your
code that you write for thread pool
interchange for the TAS composition
though it still workflows but it
functions like a flat map if you work
with streaming API you would use flat
map quite a bit and so not actually
tackles remember our use case where we
had a Kanban team that developer was
focused on production code and a tester
verifying their application so we have a
developer creating the program and you
have a tester that's going to verify it
eventually but the thing is the
verification it doesn't end the process
at all it can produce you know more bugs
it can restart the development cycle so
it's a few computable future of itself
as well and so we were to look at it it
would be something like that you would
say after developing program is Cup
completes user then apply from a
previous example using the verification
process but it will eventually create a
computable future of completable future
which is an awful thing to do and to
tackle this there is a call then compose
it basically gain functions as a flat
map while doing the same
ductwork the controllable futures again
it allows us to have a much more control
over what we're working with over a
synchronous tasks it allows us to make
them completable in a way we want
whether it's a default value or a proper
interruption of some sort
for instance I'm again a developer who's
obsessed with coffee at this point but I
got picky and now I want lot that and so
I say please make me a lot it but at
some point I really get to know it and I
say just just give me the americano if
you haven't finished making a lotta for
me and it what does is if the operation
finished the rata production they're
gonna give it to me if not I'll just
grab americano I can also say you know
if you feel making a lot of you
basically make espresso then you mix it
with milk and you'll get a lot of
basically the simplistic way and I say
you know if I finish the first part the
espresso part just give it to me I call
complete on it and ultimately get there
is a get the resolve get my coffee well
I'm trying to highlight here is that you
don't have to block anymore you have
much more control of how you interrupt
your operation you have a lot more
control control over overall multi put
multiple futures at hand and so again
it's all off or any of similar to invoke
any or invoke of we've seen on futures
so example would be imagine you writing
the webdriver tests for your application
and you have three different browsers to
test completely independent from one
another and you combine them calling
completable future all of the problem is
the result it's not very formatted in a
way that you might want it's not a
collection of results it's a it's a
computable feature of voice so it gives
you what little not as much information
as you might like to have so you have to
check if it's done if it's done
exceptionally and you have some you know
overall check for how many threads are
still running they're obviously
workarounds from this but it also
highlights the completable future is not
perfect either
and the task combination another good
example that you can actually collect
the results
whether the synchronous or asynchronous
if we don't really depend on that so a
good example is you're working the
platform team of some sort you have a
team a that files a request is you to
develop an API for them then you also
have a team B that also files and accept
a request for you to develop completely
different API so you have those isolated
asynchronous tasks to be complete but we
combine them and then I say team a file
a request in B file request and then I
will process both of them come up with a
plan for the next release and I'm going
to work on something so I give you the
plan afterwards but I will combine both
I synchronous operations work with them
and then give you the plan the exception
handling
it's a fortunately computable future
tackled is quite nicely
it works with what you already know with
the simple trycatch operations in a
sequential code but utilizing it in a
complete able future for instance again
you have a crawler of some sort you
trying to crawl a website but the
website went down so it's going to fail
on us we have two choices you can do
exceptionally close which functions like
catch in try-catch meaning that it only
will be invoked if something were to
fail and you can either you know that
would gracefully by falling back to some
default value or throwing the exception
further but there is also handle which
functions somewhat like finally every
code would go through this clause and if
you know throwable is not now means the
exception happened and you can handle it
with every way you want so again the use
what we already know and applied it to
this synchronous flow empowering us I
said engineers and so with this overall
you know talk today I'd like to have a
couple of cold fractions for you guys so
again embrace the concurrency I hope
today I try to encourage you to
understand that there is no need for you
know fear of concurrency it's more about
admiration I personally went through the
same process myself as I mentioned with
like my example with books at the
beginning of this talk it's exactly what
I had to go through and so I hope today
I try to highlight for you that
the things changed quite a bit and
they're going to continue changing and
really try to review a current
application or writing a new application
try to use the you know design for
concurrency or a new frameworks you
might have learned today
and also continue learning again the
Java 9 introduced in the live Java
libraries the handling of reactive
programming that's another way to do the
concurrency in Java so really don't
don't stay behind the Java changing
rapidly and so keep the learning up and
so with that I like to go into the Q&amp;amp;A
if you have any questions after the talk
I will be here as well a please feel
free to grab me and just talk about
concurrency or anything for that matter
but yeah thank you for listening to me
and I appreciate that thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>