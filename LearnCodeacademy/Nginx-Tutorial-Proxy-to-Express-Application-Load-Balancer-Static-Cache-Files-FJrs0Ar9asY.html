<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Nginx Tutorial - Proxy to Express Application, Load Balancer, Static Cache Files | Coder Coacher - Coaching Coders</title><meta content="Nginx Tutorial - Proxy to Express Application, Load Balancer, Static Cache Files - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/LearnCodeacademy/">LearnCode.academy</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Nginx Tutorial - Proxy to Express Application, Load Balancer, Static Cache Files</b></h2><h5 class="post__date">2014-07-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FJrs0Ar9asY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright in this video we are going to be
adding nginx as a front-end to our node
application which is running on port
3000 and we're going to be setting it up
as a load balancer so as our application
grows and grows and grows we can add a
second third fourth server and it will
load balance between the four and then
we're also setting it up to where it
will cache some static assets to improve
in Crees performance so I've got my
application server we'll call this the
dot two box the dot two box is running
on port 3,000 like a normal node
application wood you can see as I load
request they're coming through i'm ssh
ten over here so you can see it and
here's a dot four box you can install
nginx on the same box if you don't think
your application is going to grow but I
already know I'm planning on multiple
boxes to come so I'm going to install
nginx on its own box you know to better
handle the load so the dot four box
currently does nothing this is where the
domain will resolve is to this IP
address and I'm SSH into the dot four
box let's go ahead and get nginx setup
the first thing you're going to want to
do is sudo apt-get updates which I've
already ran I don't need to do that so
then you're going to go sudo apt-get
install nginx which I've already done it
says it's at the newest version
so now nginx is installed you can go CD
slash et Cie slash hope not not slash
hosts slash nginx and then you can see
here's my nginx I've got a default nginx
configuration file let's take a look at
that let's vim and look at this guy you
can see by default it started for worker
processes you're going to want kind of
as a rule one worker process per CPU
that you're running that's kind of the
most efficient way to run nginx it's
running seven 768 connections and all
this other stuff and as you can see
let's scroll down here these are all
decent things to look into to get to
know what they are but what it's doing
is it's also including any file in the
sites in abled directory so that's we're
going to add our that's we're going to
add our specific configuration so let's
go into the site's enabled folder
and then there might be a default file
in here if not you're going to want to
create it defaults let's go ahead and
create that I'm going to go over here
here's the gist that I've created for
you with the code that I'm going to be
using so I'm going to copy the upstream
project let's paste that I'm also going
to copy the first portion of the server
I'm going to wrap that out so what I've
done here is I've got three nodes I've
got my dot two node my dot three node in
my dot five node let's go ahead and
comment out the other two and save my
file what I'm also going to be doing
here's the actual server that's going on
is I'm listening to port 80 which is
your default port for your URL and then
I'm going to be forwarding that on to
project which is up here and so any
nodes I add will automatically get load
balance let's save this and then let's
go sudo service nginx starts there we go
starting nginx and now I should be able
to refresh and it's automatically
forwarding it to the dot two server you
see as I load this then the requests are
coming through to the dot two server
awesome let's say the load has increased
and we should now add some nodes I've
got some more nodes going on here let me
drag one over here for now let's go
ahead so we're getting a lot of traffic
constantly we don't ever want to have to
shutdown nginx let's go back into our
default file let's uncomment these two
servers save and quit nothing has
changed if you notice I'm loading these
I'd still all the requests are going
through to my dot two server it's
because I have to reload not restart
reload nginx so I'm going to go sudo
service nginx reload that's going to
keep it going it's going to reload the
configuration file and now let me go
ahead and minimize you bring you over
here all my requests are now getting
load balanced between all three boxes
which is awesome now let's have some fun
and do some bench testing shall we let's
go ahead and I'm going to turn the
is back off turn you off turn you off
save and reload okay let's run some
bench testing here let's run an Apache
bench pretty basic I'm going to run 40
concurrent requests going to run a
thousand requests and we're going to hit
the dot for server which is all going to
be coming through here right now running
hundred two hundred three hundred
thousand requests you can see that took
about five and a half seconds to
complete let's go ahead and go back into
defaults add my load balancing here
reload my configuration file and let's
start seeing this fly I'm going to make
you take up a little different space
here there we go let's run that exact
same benchmarking now you can see the
requests are flying through all of them
and that's going way faster instead of
five seconds that took about three
seconds to run great let's go ahead and
add some static caching now I'm going to
edit my default file again and let's
cache static assets which is this little
piece of code right here we're basically
going to take anything CSS jjs PNG any
images and we're going to cache them
they're not going to they're not going
to reload to express for 168 hours so
let's go ahead and add this in there we
go let's reload that service and now
let's go ahead and bench test style
sheets I think that style sheets style
dot CSS I believe that's it let's go
ahead and bench test that guy there we
go so that flew through as you can see
almost no time whatsoever complete
requests let's give that a bench
actually before I'm kind of static
caching that let me edit my default here
and let's go ahead and comment this
whole thing out I didn't give you a
chance to see what it does without it
let's save let's reload there we go you
can see the style she
these are all coming through here our
requests are coming in at a rate of 20
milliseconds to 194 milliseconds that
took about 1.3 seconds let me edit that
again reload boom that took almost no
time at all we went down from 20
milliseconds to about 4 milliseconds
which the highest is still around 210
but that went down to a point three
seconds so as you can see static cashing
your assets with nginx is way faster
than serving in them up with Express so
that's kind of a little bit of fun with
nginx you can cache as I think I gave
you some examples of how to cache some
difference you can cache specific API
URLs which is nice to cut down the load
on your servers have some fun with that
and have a great day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>