<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Node.js Cluster - Boost Node App Performance &amp; Stability with Clustering | Coder Coacher - Coaching Coders</title><meta content="Node.js Cluster - Boost Node App Performance &amp; Stability with Clustering - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/LearnCodeacademy/">LearnCode.academy</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Node.js Cluster - Boost Node App Performance &amp; Stability with Clustering</b></h2><h5 class="post__date">2014-10-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6xIbVPyh9wo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">one thing a lot of new node.js
developers don't realize is that by
default node will only use one core of
your computer's processor so if you're
on a four core machine you're only using
one if you're on an eight core machine
you're only using one that's by design
that's intentional that's a great
feature and they give you the ability to
do what's called clustering to use all
of them if you know what clustering is
you don't need to watch this video have
an awesome day
but what clustering does is it will spin
up copies of your program so if you're
on a four core machine you'll be running
four copies of your program which means
you can handle four times the traffic
capacity we when first deployed our
first node app into production we didn't
know about clustering and no it's
supposed to be all awesome and fast and
so we deployed it and it actually took a
performance hit from what the PHP
application is replacing did because
we're only using a quarter of the
processing power even though node is by
design a better a better a faster way of
handling requests we were only using 25%
of the capacity so it actually got a lot
slower we add a cluster and it blew the
other one away so here's kind of before
I show you a cluster here's kind of your
default pattern for a node app is you've
got your server j/s which is what your
actual program loads when you launch
your program at load server this is a
really good pattern to keep your
application code separate from your
server code so you'll see this all the
time if you use Express generator then
it generates a bin slash www file that's
basically what we're calling server j/s
here so server loads your application
and then start your server listening on
port 3,000 your app is where you load
express or Khoa whatever you're using
for your front-end framework for your
node framework loads your routes and all
that so you load server j/s on your
local machine you're still going to do
this with your local workflow you don't
need eight processors for your local
workflow you're just one guy hitting it
so you're doing that and then when you
want to deploy you're actually going to
load cluster j/s in production and this
is basically copy and paste code I will
give you a link to this in the
description and you can copy this and
paste it it does not care what your
application is all the only line you may
need to tweak is this line right here
because this points to your server
is file or your bin slash www file so
when you run cluster by default it's the
master so it's running this master
process and all this process does is it
counts your CPUs and it Forks say you're
on the 8 core machine it'll fork 8 times
so it will recall itself 8 more times
and it will listen to each one of those
Forks and when one dies or has a fatal
error it will spin up a new one in its
place so your application just got eight
times more powerful and it got more
stable because it's not your server is
not going to die now in most of the
scenarios what would kill your what
would kill your server will now just
kill one fork of it and it will spin up
another one so if it's not the master
those 8 Forks were spinning up ignore
all that and they just require server so
server gets required 8 times now so if
you're loading new relic or something
for your logging you would add new relic
into cluster not into server so that's
pretty much it
now when you deploy to production once
again use server on your local dev
environment for gulp or grunt or
whatever you're going to load server and
then when you deploy to production
you're going to load cluster j/s which
is going to load 4 or 8 or whatever
server instances and it's all going to
act like one program but it's going to
and so this will load balance between
your eight Forks going on so what you
actually end up with is you end up with
another layer of stability you've added
so say you're already running a load
balancer and that's handling two nodes
or say two servers since so we don't
confuse with node the load balancers
balancing the load between two servers
well now those servers are balancing it
between eight processes so now if any
one of these fails it spins up another
one the odds of your actual server
process failing have just gotten pretty
slim and even if it does fail altogether
you should be running something like the
forever NPM package so in case some way
somehow the whole thing died memory or
whatever then forever will restart all
eight
again and then of course you could be
doing some DNS load balancing between
your load balancers and that's kind of
how you scale an Express app or scale
and nodejs app to massive capacity so
hope this helped you out and have
yourself a great day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>