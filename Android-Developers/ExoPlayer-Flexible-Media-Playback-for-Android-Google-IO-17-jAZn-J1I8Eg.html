<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>ExoPlayer: Flexible Media Playback for Android (Google I/O '17) | Coder Coacher - Coaching Coders</title><meta content="ExoPlayer: Flexible Media Playback for Android (Google I/O '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>ExoPlayer: Flexible Media Playback for Android (Google I/O '17)</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jAZn-J1I8Eg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my name is Ollie this is Andrew it's
great to see so many of you here I know
it's been a long day and today we're
going to talk to you about media
playback on androids are using exoplayer
in terms of what we're going to cover
we're really going to try and cater a
little bit for everyone in this talk so
while a means is we're going to start
with some fundamentals so we're going to
briefly discuss what EXO Flair is we're
going to discuss some of its features
we're going to discuss a little bit
about when you might want to use
exoplayer and we're going to go through
a simple example that shows how you
might be able to get started after that
perhaps more for those who are already
familiar with actually player where line
going to run pub quite quickly through
some more advanced topics so we'll talk
about media composition which is a new
feature in exoplayer v2 we'll talk about
some of the internals of EXO player and
we'll describe a little bit about how
they work and how playback actually
works and then finally we'll build on
that knowledge and we'll start to talk
about how you can really customize and
fine-tune exoplayer to do a really good
job of matching your specific use case
ok so let's get started what is exit
plan so for those of you who aren't
familiar with exits are already it's a
media playback library for Android it
works on jellybean and above and it's
written in Java so as Android developers
it's already in the language that you're
most familiar with if you want to use
exoplayer you included as a dependency
just as you would include any other Java
library and it's also open source so if
you're inspired to check out our source
code after this talk you can easily do
that and the last slide of this
presentation will actually have a link
to our github repository in terms of
features we've come a long way since we
initially open source actually player
which was back at Google i/o in 2014 so
in that initial release we supported -
and smooth streaming adaptive media play
backs primarily using fragmented mp4 is
format we also supported ttml captions
and common encryption not too long after
that we added fourth HLS and the MPEG TS
container format and also some
additional caption formats and since
then we've really been quite busy adding
support for loads of more traditional
media formats like mp3 mp4 organ
matroska and so on we also added several
extensions what exoplayer extensions are
is a way of bringing functionality from
other libraries into exoplayer so as a
concrete example if you use okay HTTP as
your networking stack for the rest of
your application you might actually want
to use that exact same networking stack
some media player backs and you can do
that with our ok HTTP extension which
allows you to use that exact same
network stack inside of exoplayer so
this brings us up to the middle of last
year another point we kind of took a
step back and we made some quite
in-depth architectural changes inside
the player and we released exoplayer
version 2 and this release we had a
support for more advanced features like
multi-period - supports gapless audio
and media composition which is something
we'll talk quite a lot about in a little
while at the same time we tried to make
extra player easier to use so we added
simple active player view
sorry simple XO player which is a
slightly higher level API for using X a
player and also some playback UI
components that you can use to get
started really quickly out of the box
since then we've been adding more
features most notably we recently added
support for variable speed playback
we've also been building up our ability
to cache media as is plays and so this
is where we're out today and the key
takeaway from the slide isn't
necessarily that you should understand
everything that's on it probably for
your particular use case you need a very
small subset of these features the key
takeaway here is really look exoplayer
has kind of evolved into quite a fully
featured media library now
and so if you have a media playback use
case for Android probably exoplayer is
going to support what you want to do so
now we know a bit about the feature set
let's talk about when it might make
sense to use exoplayer and when it might
make sense to use the obviously
alternatives to exoplayer which is
androids built-in media player API so
the first thing to note is that media
player works all the way back to the
beginning of Android exoplayer is
jellybean and above only this is far
less of an issue than it used to be and
in fact there's only around 2% of active
Android devices still on earlier
versions for Android but if you really
care a lot about providing continued
support to like 2% the media flower is
going to be your best bet in terms of
what use cases each of these solutions
is best suited for media player actually
does quite a good job of simple use
cases so if you just have an mp3 let's
maybe bundled in your apk and you want
to play it inside your app the media
player is going to work just fine for
you maybe you're already using it and
there's no real reason why you should
switch we're exoplayer really comes into
its own is for more advanced use cases
so specifically any kind of adaptive
streaming including - smooth streaming
and HLS and use cases where you really
want to leverage some of the advanced
features that Exeter provides like media
composition and caching another
difference is worth bearing in mind is
the whale at least you api's have been
designed media player is very much a
black box you don't get very much
control over the inner workings of the
player and in contrast XO player is
designed really to be very customizable
and extensible and you can really dig in
and start to fine-tune the various
dollars and side-effects of player to
get things working just the way you want
want them to
so actually player is really best if you
are probably an advanced user and you
want to kind of tweak these things a
final bit important consideration is to
consider the difference of where the
player actually lives when using media
player and exit layer so when you use
media player as you can see on the left
there
the media player implementation is
actually in the Android operating system
and the division here is the horizontal
line that you see so below is the
operating system and above is your
application when you use X we player the
actual player implementation chips as
part of your application and it really
just calls through to some quite low
level media API in the platform mainly
for providing access to hardware
decoders so why is this important well
one reason is that Android media player
is actually evolved over time so as a
result of that the behavior that you get
may vary slightly from Android release
to Android release in contrast with
exoplayer we have an advantage that you
can ship a single version of the player
inside your application and you're going
to get a lot exact same version across
all versions of Android and this means
that exit player is really better
positioned to provide a very consistent
experience another important benefit of
this model is when we add a new feature
we can generally support all the way
back to jelly bean with active player
where as a new feature media player is
only going to be available for
subsequent releases of Android an
interesting example of these advantages
is actually variable speed playback
support so little supported a media
player from marshmallow and recently we
added support an egg supplier and
because we didn't have any dependencies
on you low-level media ap is or anything
like that in the platform we were able
to add support all the way back to
jellybean what we discovered next
towards the low is actually a bug in the
playback rate and pitch adjustment
implementation that affected both media
player and axis layer and we were able
to fix our bug again all the way back to
jelly bean with exoplayer and only in oh
and laser for media player so at this
point hopefully you can see some of the
benefits that XA player has but you
might be thinking that you would be more
confident in using it if you knew Lou
some people were using it already and
I'm happy to say ler we actually use
exoplayer very extensively in google's
own applications
so most notably YouTube which is
obviously a huge video streaming service
and also applications like Google Play
Movies and Google photos and we've
actually seen really strong adoption
from the wider development community as
well so here are just some of the
applications that there's some user
rather use exoplayer today and it's not
just a handful either there are actually
over 140,000 applications on Play Store
today that are making use of exit there
if your apps one of these and thank you
very much for your adoption and please
keep this and keep sending us feedback
it's really important to us and it
actually does guys a lot of what we work
on so next up we're going to dive in
some code and show a simple example and
for that I'm going to hand you over to
Andrew hi everyone so let's imagine that
you've got an existing app and you'd
like to add an mp4 player to that app so
just showing a simple video in your
existing app I'm going to go through the
minimal changes that you would need to
make to use exoplayer so the first step
is going to be to add a dependency on
exoplayer
and there are two main options here you
can either bring in the whole of the
exoplayer library and that will include
support for adaptive streaming formats
like - an HLS and for that you can use
this line in your build up Gradle file
this is kind of the kitchen sink option
so the alternative is that you can just
pick and choose the specific modules
from the XO per library that you need so
for this example I'm going to add a
dependency on the core library which
contains the main file obviously and
also support for regular media files
like mp4s and mp3s and there's also a
dependency here on the UI library which
we which brings in simple exoplayer view
which is a minimal that customizable
player that you've a player view that
you can put in your app ok so once we've
added the dependencies the next step is
to add some code snippets to your
activity which will create a player and
use it so we have this exoplayer Factory
which has several methods for creating
player instances and this is the easiest
to use one it takes the context
a track selector and for this simple use
case we can use the default track
selector which has sensible defaults for
almost everything you want to do once
we've created the player the next step
is to drop a view into your apps layout
and then bind it to the player by
calling the set player method now most
importantly we need to tell the player
exactly what we want to play and for
this we're going to use a media source
in EXO player everything that you can
play is a media source it's responsible
for loading the media and providing it
to the player so we're going to create
an extract a media source which has
support for regular media files like mp4
mp3s and matroska files and so on so you
passed that to the prepare method and
then we call set play when ready to tell
the player that as soon as buffering is
completed and playback can begin then
say that should start
and finally it's very important that you
release the player when playback is
complete because the player holds system
resources like codecs and it uses memory
for bottles so these code snippets would
generally go in activity lifecycle
methods in your app okay so this is a
video of what you get got a nice video
of the skyline of London and and you can
see there that it had basic playback
controls like play and pause button and
a sequel so if you'd like to try this
out and there's a codelab
being published as part of i/o which you
can go and try out and there's also a
developer guide on our project page
which will walk you through these steps
ok so as I mentioned everything that you
can play is a media source and it's
responsible for loading media for the
player and we in that example we use the
extractor media source but there are
actually other more advanced media
sources available so you may have heard
of - which is a specification for
streaming which allows for adaptation
between qualities to handle varying
network conditions and we provide -
media source so support for - we also
have a HLS media source for supporting
HTTP Live Streaming
and a media source of Smooth Streaming
and with our recent v2 release we've
also added a new category of media
sources which are designed for
composition and by composition we mean
joining together other media sources why
would we want to do this well I'll go
through an example so let's say we've
got a video that we want to play and
also some subtitles which are in a
separate file and SRT file in that case
we can create an extractor media source
to load the video a single sample media
source which is going to load the SRT
file and then we're going to play the
the subtitles alongside the video now
you could try and do this yourself by
looking at the player position and
synchronizing the playback position with
the subtitles that you're showing but
this is actually quite difficult to do
in general it's much easier to use a
merging media source and the merging
media source just takes the video you
want to play in the subtitles and
handles everything for you and so we'll
handle synchronization and then they'll
be shown in the player another time you
use composition is for playlists and so
in this case you have say you have an
album of mp3s that you want to play
backs back and you could try and do this
yourself by playing the first screen and
then swapping out the source for the
next one
but that's not going to be great because
the player is going to buffer when you
swap out the source so we've added a
concatenated media source which takes a
list of sources that you want to combine
together and then play them back back
with a consistent buffering policy so if
you tell the player to have three
seconds of media buffered at all times
then it will ensure that that is the
case even across transitions from one
source to the next and it also supports
capless playback metadata so you can
play that album of mp3s with completely
seamless playback and and also
composition is very flexible so we can
combine those two examples that we saw
so we can concatenate a video with the
merged source that we created earlier
that had subtitles
and if you do that this is what you're
going to get so the first video plays
and then when the first video completes
we get a seamless transition to the next
video and you can see the subtitles are
coming up as we'd expect there okay so
this is great we can play these
compositions of media but then so we
implemented this and then we thought
hold on a moment we've got this speak to
you method on the player but now we've
got playlists that we want to play back
that have multiple sources and a
timestamp is not really enough
information to know where you want to
speak to you anymore so and we thought
about this and we thought about other
types of media source you won't want to
play like live media sources and we
realized that we really need a way to
and expose to the app the structure of
the media source and what media is
available so to solve the issue of
needing to have a know which source you
want to speak in to you we added a
parameter that tells the player which of
the sources in the playlist you want to
speak to and and then we thought we're
going to need a description of the media
available so we added a new data
structure called a timeline and a
timeline basically is a representation
of all the media that is available in a
media source and it consists of a list
of Windows each of those windows
corresponds to one item in a playlist
and it describes which parts of the
media you can seek to at any given
moment so I'm going to show an example
of this to make it a bit clearer and so
let's imagine we've got a single source
where you can see Kenny where the red
line here represents one window the dot
at the left hand side represents that
the default start position for this
media source is at zero so when the
player reaches this source if it's in a
concatenation that it will go to time
zero and the window extends all the way
to the duration of the media source more
interesting case is if you can catenate
two sources together and in this case
you end up with a timeline that has two
windows and as you can see for both
windows the start position is at the
beginning of that source
what about if we have a live media
source well in this case the timeline is
actually dynamic so as the live event
progresses more media is becoming
available in the window and you can see
that the default position is tracking
the live edge and then when the live
event completes the default position
snaps back to the beginning and so that
this becomes a regular stream where play
that begins at the beginning and you can
see - any position and we can build on
top of this to have concatenations of
regular streams and live streams and
this works in the way you'd expect so
when you concatenate sources you end up
with a timeline that consists of the
concatenation of the windows of those
individual sources so you'll see this
timeline exposed in exif where's top
level api you can get the current
timeline you can pass in a window index
when you seek the player so you can say
please speak to the second item in the
playlist at a particular offset and you
can inspect details about these windows
like where the window starts and how
long it is okay now back over to lead to
talk a bit about the internals of the
player okay so as Andrew says we're now
going to dive in a bit deeper select a
player and really talk about what
happens internally during a playback and
the reason that we're going to do list
of the apps that we've talked about some
of the internal components we're then
going to go on to talk about how we
might customize those to very fine tune
the player to your specific use case so
here we have an extra player and it's
just received this media source that is
going to playback so what are the
important internal components well the
first important component that we should
mention our renderers a renderer is
responsible for rendering a single
component of media so a video renderer
will decode and display just video and
an audio renderer similarly will decode
and output just audio and a real
ex-employer instance will have
additional renderers for things like
text and metadata as well but we're
going to emit lows from this diagram
just for simplicity
another component is important is a
track selector a media source may
actually expose multiple tracks that
could be playback by the player
particularly if you have a - or HLS
adaptive playback the media source may
actually expose multiple video streams
at different resolutions and maybe
multiple audio languages as well and
it's the job of the track selector to
select the subset of those tracks so it
should actually buffered and plays by
the player the last component that we
need to talk about is a load control a
load control actually has two jobs its
first job is to tell the media source
whether it should be buffering at this
point in time and this is indicated in
this diagram by the green dots on the
left hand side since we haven't started
playback yet we don't have anything
buffered and therefore it's green to
represent the low media source should be
buffering a second job is to tell the
player when playback is actually allowed
to start this is represented by low
right hand side dot and because we don't
have any media yet it's obviously too
soon start playback and therefore is red
one other component that we should
mention our data sources media sources
use stage sources to load the actual
media layer I'm going to provide to the
player for playback ok so I've kind of
given you some major components but
let's talk a little bit about how these
components actually interact during a
playback
well we haven't bought anything yet and
load control is telling the media source
that they should be buffering and so the
media source is going to start loading
data through its data source and after
it's loaded enough media probably not
very much just the header for a normal
media file the media source is going to
be able to work out what tracks that can
actually expose to the player and it
does this by exposing something called
track groups now we know that the track
selector is the thing that's going to
choose which of the tracks to actually
play when the tag selector needs
something else and the reason it needs
something else is that different devices
have different capabilities and in
particular the video renderer may only
be able to decode up to a particular
resolution and so even if the media
source exposes
a 4k video stream if you're on a low-end
device it's not going to make sense for
the track selector to actually choose
that stream and the way we represent
these kind of capabilities in the player
is we have each renderer exposed
something called a renderer capabilities
object that describes specifically what
it's actually able to handle so what
happens next is that the track groups
and the renderer capabilities are fed
into the track selector the track
selector does it's magic it produces a
selection and that selection goes back
to the media source at this point the
media source knows what is going to
buffer because it knows what the track
section is and so allocates some buffers
of course we still haven't actually
loaded any useful media for playback the
load control is still telling the media
source to lows and therefore the Loken
the media source continues to load data
and it starts to fill its buses and what
you can see here is that as soon as
these buses start to get fill for the
renderer is actually start consuming
from those buses and feeding that media
data through layer decoders getting
ready for playback so at this point we
have some media buffers the renders have
decoded a bit of media filler kind of
primed and ready to go and so the load
control may at this point actually start
the playback so that little red circle
has gone green and of course the media
source is continuing to buffer and at
this point we've actually buffered quite
a lot of media so these buses on the
left-hand side are quite for course you
don't want to buffer arbitrarily far
ahead so a load control may stop
offering at this point because playbacks
continuing the renderers are still
consuming and therefore these losses of
draining back down to a lower level of
course you don't want the bosses to run
out so the load control might toggle
buffering on it on again and so you see
this pattern emerging of data being
pulled through the data source into
media source and out surrenders one
additional complexity to keep in mind
when you're thinking about this is that
I've Andrew said that media source can
actually be a concatenation of for
example different videos and those
videos may have a different selection of
tracks available
and so as this process is continuing you
may actually get additional tracks
elections taking place at the same time
and so here we have the playback
continuing the bosses are filling up and
draining down and you see this pattern
of data being intimate in the irregular
data source and continuously consumed by
the renderers again so now we know a bit
about actually how the important
components works during a playback let's
talk a little bit about how we might
customize those internal behaviors so
here is a code snippet and we showed you
earlier we're creating an X a player
with X a player Factory there are
actually more complicated methods for
creating an active player this is one of
them and you can see that what we're
injecting into this player instances
that are exactly the components that
we've just been talking about so the
renderer is a track selector and the
load control and here we're just
inserting p4 implementations so let's
look at how we might fine tune the
player by pulling one of those out so
we'll look at the load control and here
we're still using the default
implementation but we can actually pass
some variable is infla constructor to
manipulate its behavior solicit default
load control is saying that it wants
between 15 and 30 seconds in the buffer
and it wants to start playback when
there's 2.5 seconds buffett so what does
that look like in terms of wall clock
time versus duration of media in the
buffer well the buffer starts to fill in
at 2.5 seconds we allow playback starts
as indicated by the little orange dot
and the load control allows buffering to
continue up until 30 seconds
buffering will then be turned off for a
while and the media source buffers will
drain down to 15 seconds which is lower
than it
I'm buffering would then turn on again
and so you get this kind of sawtooth
pattern in terms of buffering behavior
so at this point is probably quite clear
that you can start to really influence
this behavior so you could change this
number from 15 to 25 if you're not
comfortable with allowing a buffer to
drain that low
and because we understand how default
load control works we can show the new
graph so here the buffer is kept more
full at all points during the playback
and buffering is toggled on and off far
more frequently we could also decide we
might want to be more conservative that
when we allow playback to start so we
bump up the value from 2.5 seconds to 10
seconds and again we can understand the
difference in terms of this graph we can
now take our modified default load
control and inject it back into the
player okay so what if default load
control just isn't flexible enough for
the actual buffering policy that you
want where you can go further and you
can just implement your own load control
from scratch so one of the methods that
you have to implement if you do this is
called should continue loading it
returns a boolean is polled during
playback and this is exactly the method
that's actually controlling whether the
media source busses or not and you could
implement all kinds of behaviors and
logics and your own implementation you
can do similar things with the track
selector as well
so in this case we can actually get some
parameters and we can start manipulating
the way in the default track selector
actually chooses tracks so here we're
limiting the video tracks to SD so 480p
and you might want to do lists if you
know that your user is on a metered
mobile connection and even if they have
really great bandwidth you probably
don't want to use all of their data very
quickly so you might want to keep a cap
on the quality that you deliver
similarly if you know that your user is
German you might select a preferred
audio language for the case where there
are multiple audio tracks exposed by the
media source and you can certainly use
modify parameters back on the selector
to actually activate this new behavior
again if the default fermentation of
track selector isn't suitable you can go
a step further and implement your own
track selector one of the methods you
need to implement if you do list is
select tracks and hopefully you can map
the signature of this method back to the
diagram we saw earlier it's receiving
the capabilities from the renders and
the track groups from the media source
and it's generating a
selection and of course the same tricks
can be applied for the renderers as well
implementing your own video render from
scratch is a pretty advanced
customization but you could do it if you
really want to and you kind of have a
good handle on exactly what you have to
do to achieve up and you could extend
default renderers factory override the
bills video renders method and actually
inject your own video renderer into the
player instead of the default that would
normally be created okay great so
hopefully you can see a pattern emerging
in each of the examples of custom ADA
customizations that Olli talked about so
the first step was establishing which
component in the player we need to
customize whether it's the track
selector or the load control then you
look at the API for that component and
see if there's a way to customize its
behavior using say a different parameter
as we did with load control if that's
not a possibility then you might be able
to extend will actually implement your
own version of this component from
scratch okay so I'm just going to do one
more example of customization on the
media source slide this time and so
imagine that we need to send an
authorization header with each HTTP
request that a media source makes well
we know that we're passing in a data
source HTTP data source Factory and this
has a convenient method to get the
default request properties and by
getting the default request properties
we can actually set a new header to set
the authorization header on the HTTP
request and once you've done that you
pass that HTTP data source factory into
the media source and that header will
appear on all requests that it makes as
another example let's say that you know
that users are going to rewind videos
quite a lot so you want to add a cash-in
so that the player doesn't repeatedly
load the same media off the network
exoplayer has a simple cache which you
can use and and in this example I'm
passing in a least recently used cache
of extra so the way this is going to
work is the cache
the maximum size but if the media is
longer than that then when the media
finishes if they've watched the media
all the way through then the cash will
actually have started to evict they're
very beginning on it okay and so this
cash gets passed into a cash data source
Factory and it also needs to take a
normal data source which is used if
there's a cache miss and also to
populate the cache and then you pause
the cached data source factory to the
extracted media source so hopefully to
make this a little bit clearer let's
clearer let's see how it fits in with
the player architecture we saw earlier
this cache is actually going to sit
between the media source and the HTTP
data source and when the player when the
media source requests data it starts
going to look it up in the cache it's as
a cache miss then it's going to go to
the network and use a HDTV data source
then on the way when that request is
satisfied it's going to come back and
fill in the cache so that next time the
media source requests the same chunk
then hopefully it's going to be in the
cache okay
so we talked about how the kind of
extreme case of customization is
providing a media source or whatever
that you've implemented yourself and so
I'm going to go through an example of
doing that let's say that you've got an
app where you're showing some content
but now you want to monetize that
content by showing ads alongside it and
let's have a think about what the
timeline is going to look like in this
case well it might be very simple and in
this example on the screen there's just
one ad at the beginning of pre-roll ad
or it may be more complicated and so in
this case there's a pre-roll ad and a
mid-roll ad and a poster or ad and they
kind of split up the content so at first
glance you might think this is a place
where we could use concatenating media
source but unfortunately normally when
you're loading ads you can't actually
commit to a particular ad URI until the
time when you're about to play it it's
not the case that we have a list of
exactly what ads we're going to play
upfront so let's see what would happen
if we try to use just one player and
with conventional media sources to play
these
so at the beginning of playback we get
the URI for the first ad and then we can
play it but then we know that we need to
play the content so the player is
actually going to buffer when we tell it
that we want to play the content instead
then the content will play back and the
user is going to see buffering again
then the add more buffering and I guess
you're seeing how this is going to work
there's a lot of buffering and this is
not a good user experience so one way
that people try to work around this is
they will try and use two players and
the idea is that one player is going to
play what's on the screen at the moment
while the other player is in the
background buffering whatever is coming
up next and so when they're you're as
soon as the add URI arrived
you can populate the background player
and hopefully get some data buffered
before playback begins and in this case
the playback will switch in between the
ad and the content but this solution
also has its drawbacks these two players
are both going to use out memory for
buffering and they may even both be
using codecs at the same time and so
that's not very good and also this is
just very difficult to implement
correctly if you've ever tried doing
this so we thought about implementing a
media source that specifically does
design to ads and this media source is
implemented in the slightly similar way
to the concatenated media source except
that it has these playlist items which
are not populated and those are
represented by the question marks those
are going to get filled in with the ads
as soon as they arrive okay so let's see
what playback would look like with this
hypothetical media source playback
begins and we get the first ad then the
content plays hopefully we get the next
add a little bit early and that
placeholder is filled in in the timeline
and if this works well then the user is
actually not going to be any buffering
during playback so as a real practical
example of this Google provides the
interactive media ads SDK you may have
heard of it and we're using that for
loading ads in this IMA ads media source
and as you can see and the arrow kind of
highlights when the ad is loaded from
ima and the the media source is rapping
ima so you don't the player doesn't need
to worry about any details of how ads
are actually loaded and in this timeline
you get seamless transitions between
contents and ads so we've actually
pushed this to our development branch
today if you want an early preview if
you want to try inserting ads in your
content it's very easy to use so you
take your content media source and you
pass it into the constructor of an ima
ads media source along with an ad tag
URI which defines what ads are playlists
to load and it also takes an overlay
view group which interactive media ads
will use to show any add user interface
on top of your player likely to get
button for example okay here's what you
get if you try doing this so you can see
the pre-roll ad is playing and then when
the ad finishes we get a pretty seamless
transition between that ad into the
content and you can see that our
playback controls have support for
showing little ad markers so the user
can see where the mid-roll ads are and
during this playback there's a
consistent buffering policy being
applied at all times okay now back to
all need to talk about some of our
future plans okay so before we leave you
I just want to say a little bit about
the direction in which exoplayer is
headed just to caveat lists this is no
way a promise and we're not going to put
timelines on anything but in terms of
the kind of things that we're going to
be looking at over the next six months
to a year we're going to fill in the
continue to fill in the remaining
feature gaps that we have in terms of
becoming a really complete media
playback library one specific thing here
that we know is causing a lot of you
problems is proper support for offline
so this is where you actually download
media to playback later and so you can
expect us to start building up supports
offline during the next six months to a
year we're also going to continue to
work on performance enhancements and by
that I mean things like maintaining
decoder instances from the platform from
one playback to the next
because releasing and reinstating those
decoders as we do now could be quite
expensive another aspect of performance
that we intend to look at is improved
adaptive track selections for dashing
HLS and Smooth Streaming adaptive
playbacks and also more advanced
buffering policies so the default
components that we currently provides
for performing these tasks they're
pretty effective but they're quite
simple in terms of the policies to late
insulin so we really want to start kind
of kind of diving deeper and doing some
proper research and kind of fine-tuning
these to deliver better performance out
of the box and finally we know that the
exoplayer api is very large and that it
can be daunting to get started with and
to figure out exactly where you need to
dive in if you want to customize
something so we're going to work on some
better documentation as well probably
starting with documenting some of the
internal components that the player is
using as we described earlier in terms
of what you can do next with exoplayer
whilst you're here we have office hours
tomorrow over in the office hours box a
9:30 in the morning so if you have any
questions for us simply if you come
along and we'd be more than happy to
have a chat and to answer them if you
want to go and check out our source code
the github repository is public and you
can go and have a look and we also have
a home page which includes the developer
guides that will help you get started
and it also has various types of
documentation such as supported formats
and with that I'd like to just thank you
all for coming we unfortunately don't
have time for questions now but we will
probably be just down in the corner
afterwards and as I said if you do have
questions that we can't answer now
please do come along tomorrow morning
and we'd be happy to answer them so
thank you very much your time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>