<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>DevBytes: Efficient Data Transfers - Effective Prefetching | Coder Coacher - Coaching Coders</title><meta content="DevBytes: Efficient Data Transfers - Effective Prefetching - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>DevBytes: Efficient Data Transfers - Effective Prefetching</b></h2><h5 class="post__date">2013-09-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Rk1u7VVmadE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is reto Meier and I'm the
tech lead for Google's Android developer
relations team this efficient data
transfers dev byte focuses on how you
can use prefetching to implement the big
cookie model of efficient data transfers
and improve your apps user experience by
reducing latency and improving battery
life in previous efficient data
transfers dev bytes I looked at the cell
radio state machine and examined ways to
analyze apps data transfer profiles to
uncover anti patterns such as these
short intermittent Peaks and consecutive
but non overlapping downloads having
discovered potential problems in this
episode I'll look at how to use
prefetching to solve some of them we
know that carriers adjust the timings of
cell radio state machine to compromise
between data transfer latency and
battery drain but within our app we want
to create the perfect user experience
that actually sits here at the sweet
spot of non-existent latency and
virtually no battery impact is such a
thing even possible yes it is
prefetching offers the best of both
worlds an effective way to reduce
battery drain by reducing the number of
data transfers and minimizing the in
herb latency triggered when users have
to wait for dollars to complete before
performing in action or viewing data by
downloading all of the data that they're
likely to need for the current session
in a single burst over a single
connection at full capacity you can
significantly reduce the number of radio
activations your challenge is figuring
out what you need to download ahead of
time so that you can present the user
with exactly what they need when they
need it without simply downloading
everything and wasting battery power and
bandwidth downloading data that's never
used how aggressively you prefetch
depends on the size of the data being
downloaded and the likelihood over being
used as a rough guide for a typical cell
radio connected over 3G you can prefetch
around 6 seconds that's about 1 to 2
Meg's worth of data if that data has a
50% chance of being used within the
current session now at that point the
likely cost of downloading any unused
data matches the potential savings lost
by not downloading that data to begin
with but of course not every network
transfers data at the same rate so the
equation will change based on the speed
of transfers and the efficiency of the
cell radio technology
this code sets a default value for 3G
networks and increases and/or decreases
the size of the prefetch cache based on
the speed and cost of each network note
that we want to prefetch significantly
more data on faster 4G networks and
that's both to account for the larger
amount of data that can be downloaded
within the same time period but also
because the higher battery cost
associated with these radios so that
makes it even more important that we
avoid extra straight transitions
whenever we can
but if networks are different so are our
apps and as the likelihood of the data
being used increases so does the amount
of data it's worth prefetching so it's
important to understand both what data
your users will likely use and what your
app's
average session length is a good
starting point is to expect session
lengths of around 2 to 5 minutes so
large downloads such as video files
should be downloaded in chunks at
regular intervals using the same logic
for a music player it will be good
practice to maintain a buffer of one
song in addition to the one already
being played rather than prefetching say
a whole album or playlist this mitigates
the risk of wasting significant
bandwidth and battery life if you user
stops listening halfway through a song
you can take a similar approach when
streaming by using HTTP Live Streaming
which transmits audio in bursts rather
than maintaining a continuous string
that will keep the radio constantly
active if we look at something like a
news app things get a little more
complicated a typical use case for music
players to find an album or playlist hit
play and then listen so you have a
really good chance of knowing what's
coming next and a reasonable expectation
for what your user is going to do and
they're gonna have a reasonable
expectation that there's going to be a
start up latency if they select a new
track now in contrast the browsing path
when you're using something like a news
reader is much less predictable with
readers potentially swiping between
dozens of different categories and
jumping between hundreds of articles in
many ways and users rate reader behaves
a lot like a browser so your approach to
prefetching can utilize some of the same
techniques browsers use to improve
speeds now the most naive solution is to
download the headlines for a category
once it's been selected and download the
related thumbnails when they scroll into
view and then each of the articles once
it's being clicked now
this forces the radio to remain active
for basically the entire session is
you're switching categories scrolling
headlines and reading different articles
and as a bonus each click is going to
have that latency associated with it as
it has to download and process and
present the data that you've selected a
much better approach is prefetching a
reasonable amount of data at startup
prioritizing the first set of news
headlines and thumbnails which are
likely to be displayed and continuing on
with the remaining headlines and
thumbnails and also article text now
it's also important to ensure that your
prefetching doesn't delay the app
startup by making the app wait for the
prefetch to complete fully before
letting the user interact the worst
example of this is after the display a
splash screen until a ping or download
or process cycle is completed so be sure
to process all of your downloads in the
background using intense services and
libraries like volley to help process
that data progressively and concurrently
and therefore minimize that startup
latency the real trick is being able to
accurately guess which articles each
user is likely to read and prefetch only
those now one approach is a
breadth-first search assuming that users
are more likely to read articles near
the current one or you can go
depth-first and bank on them reading
lots of articles on a given topic now a
better approach is to use science
measure how your content is actually
being consumed and use that to inform
your decisions dynamically and on a per
user basis you can start by keeping
track of the metadata associated with a
content read by each user such as the
categories of authors you can widen this
go further by incorporating the content
that their friends use by integrating a
social graph like Google+ and finally
you can aggregate all of this
information together across all of your
users and just go discover what's being
used by a lot of people now taken
together you can form a sophisticated
picture of typical and expected usage
patterns of your app customized for each
user and that allows you to make an
intelligent choice over which data you
should prefetch if that all sounds like
a bit too much work than the some apps
it may even make sense to simply
prefetch everything effectively
providing support for a fully offline
experience this can be really effective
for apps with data that doesn't change
very often such as magazines but you
risk spending
sniffing in bandwidth and battery life
downloading contact that's never used so
it should be done with caution
one way to mitigate that cost associated
with downloading more than five minutes
worth of data is to schedule the
download to occur at a time when
bandwidth and battery life isn't as
important specifically when the device
is charging and connected to Wi-Fi as
determined here by using the
connectivity manager and battery manager
and as long as you monitoring the device
state why not take it a step further and
track the current activity of the user
using the new location-based services
activity recognition API you can modify
the aggressiveness of your prefetching
based on what the user is doing in this
example we're going to increase the
amount that we prefetch when the user
has the app open and is standing skill
still the assumption being that they're
more likely to be browsing articles
while stationary than if they're riding
a bike now so far we've talked about the
case where the app is active in the
foreground but it's worth considering
the background case to should we
prefetch the item when the app is in the
background well generally speaking it's
better practice to delay your dollas
until the app is open though this will
increase your startup latency a good
approach is to use Google Cloud
messaging to notify your app of updates
available on the server and that
eliminates the need to pull to check for
updates and provides a channel to notify
your app of exactly what it should be
requesting at startup typically you'll
use GCM as a way to initiate client-side
notifications without the app needing to
initiate a separate download but where
it makes sense you can use this same
mechanism to trigger background updates
I'll cover GCM in more detail as well as
topics including batching bundling
transfers and using sync adapters in
future episodes of the efficient data
transfers devbyte series</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>