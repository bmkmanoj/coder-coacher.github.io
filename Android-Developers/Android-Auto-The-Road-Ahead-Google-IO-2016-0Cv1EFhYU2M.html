<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Android Auto: The Road Ahead - Google I/O 2016 | Coder Coacher - Coaching Coders</title><meta content="Android Auto: The Road Ahead - Google I/O 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Android Auto: The Road Ahead - Google I/O 2016</b></h2><h5 class="post__date">2016-05-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0Cv1EFhYU2M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everybody my name is Jeff bush and
I'm an engineering manager on the
Android auto team so great to see so
many people here I hope people didn't
get you sunburned today so we're going
to talk about a few things in today's
session first I'm going to spend a few
minutes talking about where we are today
and what we're working on then a few of
my colleagues are gonna colleagues are
gonna come up and do some short demos
but the majority of this session is
going to be deep dive into how to bring
your apps to Android auto in 2014 we
launched Android auto with our partners
in the open automotive alliance to
create a platform that connected
services in the car and the two years
since we've gained a lot of momentum we
now have 40 manufacturers signed up to
support Android auto and there are over
a hundred models of cars on the road
today they use Android auto by the end
of the year we're expecting to double
this number to 200 and support every
major car manufacturer and developers
are flocking to the platform we
currently have hundreds apps available
and more coming everyday so I wanted to
take a minute to say thank you to all
the developers who supported Android
auto we've also recently launched the
Android auto in 19 new countries
including Brazil Russia and India which
brings us to 30 countries and more are
on the way we're really excited about
how far the platform is coming we're
even more excited about the future we've
gotten a lot of great feedback from our
users and I'm pleased to say that the
three most requested features are coming
soon
the first is OK Google Android auto
already supports a rich voice interface
but have being able to initiate commands
hands freeze and natural for the car so
we're bringing ok Google forwarding to
Android auto the second is ways as some
of the commutes every day in Silicon
Valley I'm pretty excited about this
Waze has an active community of millions
of users sharing real-time traffic and
accident information to save time on the
commute the Weezer's have been very
vocal about Android auto support so
we've been working with ways to make
that happen
I think they've done an awesome job and
you can actually see an action in our
demo cars in the sandbox
right over that way the third is
Wireless we think Android auto is a
great experience but wouldn't it be even
better if you could get you could use it
without even having to take your phone
out of your pocket so the good news is
that we're working with our
manufacturing partners to bring
support for wireless to their Wi-Fi
enabled cars so these are three new
exciting new features there are many
other smaller improvements that we're
working on but we can't ignore the fact
that there are over a billion drivers on
the road who don't yet have cars that
support Android auto we know that many
eight drivers are already using Android
phones in their car dock for
turn-by-turn navigation and media
streaming we think we can make that
experience easier and safer by letting
people use Android auto on their phone
screen while docked so coming soon
Android auto will give access to the
same features voice enabled media
messaging and navigation right on the
phone screen using an interface that's
designed for driving Paco will be up on
stage to tell us more about it in a few
minutes we also have this running in our
sandbox and I recommend checking that
out as well this opens up Android auto
to a huge number of you new users and
that's a great thing for developers too
so we're excited about bringing Android
auto to old cars and new but what about
the future
a trend that we're seeing is cars with
larger screens fully digital instrument
clusters and cellular connectivity but
to get the innovation we've seen on the
web and smartphones we need a platform
and more importantly we need an
ecosystem in fact many manufacturers
have recognized this and are already
choosing Android auto for their ibi
operating system but they have to do a
lot of work to adapt it to an end cabin
experience so we're putting automotive
support into mainline Android to make a
great platform for built-in infotainment
this includes support for vehicle
networks HVAC and infotainment user
interface and built-in apps being built
on Android it supports everything that
makes Android great like multi-user and
multitasking and it'll be completely
free and open-source part of the Android
Open Source project in fact in the
Android and release coming later this
year will include many these features
already we're really excited to work
with our car manufacturing partners to
bring Android to their future cars and
in our sandbox we have a concept car
that we've built with Qualcomm showing
off this technology that's when I would
definitely recommend you check out a
little bit of line right now
but most importantly we're working to
ensure the apps built for Android auto
works seamlessly on our built-in
infotainment systems so there's a lot of
cool stuff in the works and with that
I'd like to hand over to Paco Vincent
and Victor to show you some of demos of
some of the things I've talked about
thank you Jeff
thank you it's good to see so many of
you here today it helps at least
air-conditioned in here it's pretty hot
out senpai Google honest in I'm an
engineering lead with Android auto as
Jeff mentioned before we are expanding
the Android auto platform to create new
experiences for existing drivers by
expanding the underly platform into the
car and sorry by bringing up the
experience that we've done we've shown
you in the car
directly into the phone screen we are
also expanding Android directly natively
into the car and that is the concept car
that Jeff already announced I'm gonna
now give you a demo of how this all
works together
and show some of the features that just
announced all right so we have Benson
here and he is showing the desktop head
unit this is a tool that all developers
have available and it emulates how the
car screen works once you plug your
phone in alright so once you plug in you
launch into the home screen and that
gives you access to tasks that you may
perform right to get started you know we
have suggested destinations we know what
you are your location your time of day
so we can tell you you may want to start
navigating to work today and all these
of course uses the same google smarts
that we use all throughout the platform
for those of you not familiar with the
platform already let's do a quick
walkthrough so the activity bar at the
bottom of the screen gives you access to
common applications that you will be
using while driving
we have media of course do you have
access to your dialer in your common
contacts that was in it contacts the
hell're that it is and of course you
have also access to navigation in maps
all right perfect
let's go back to the home page to the
home notice that the whole screen is a
lot bigger than any other application
that runs on your phone and this is
because east fi is designed for driving
you need to tap that screen while he's
running around length on your dashboard
all right let's go into navigation now
of course we have integrated Google Maps
with all the great navigation tools that
you are all familiar with but unless a
platform were working on also
integrating ways as Jeff announced which
is a tremendously popular navigation app
as you all are aware let's switch to it
that is all right whoo
vincent is gonna pick directions we're
going to the beach later today so he's
getting a head start he has the
directions right there in keys favorites
and off he goes great as with us with
Google Maps the same applies here we
display the next turn right there in
this interface but you also recognize
some of the ways specific features in
the screen reporting an incident right
there great we've also integrated
messaging by the way though is mostly a
voice driven experience and in speaking
of voice of course you know we've
enabled most of the common tasks that
you can perform while in the platform
while using Android auto via voice all
right let me show you how many searching
actually works in the platform we're
gonna text him telling him that I'll
meet him later
of course he gets a quick notification
messaging is a notification driven
application in the alert we show you
enough information to know if you really
need to take it or not but it goes away
and it's always available through the
home screen she can decide to listen to
the message one is safe to do so right
here's the message finishing my
presentation at Google i/o let me know
when you get there now he could use
voice to send me a quick message or we
always give you a pre-canned
customizable message that you can just
tap and let me know that you know I'm
driving now don't disturb me note that
this works with many messaging works not
only SMS we have many applications are
already integrated chances are that your
favorite application is already in the
platform if you have an integrated
Europe yet we'll show you later how to
do so Thank You Vincent
let's switch to the video down below
and let's see what Victor has for us
there all right so that is a testing
harness for the for the concept car that
we have out there in the sandbox the
Maserati comes here later if you get a
chance the concept has two screens both
powered by Android the instrument
cluster right above the steering wheel
of course and they bigger infotainment
system to the right very good because of
the larger screen that we have available
here in instrument S or in via
infotainment screen we can make use of
the multi window features of Android and
to display more than one application at
the same time you notice at the bottom
we have the climate control application
it gets harder today so let's cool it
down in the middle we have the currently
raining application right now navigation
and maps he's already going to meet us
later in at the top we have a permanent
screen where we can show you all the
running applications or the running
activities and we can also of course
show you some content coming from you
know from Google now or other
notifications from the system alright
let's let's focus in the cluster for a
minute
very traditionally look traditional
looking plaster with fuel gauge
speedometer and something new there
which is the next turn from Google Maps
that area can also be used for other
notifications like in this case the next
track from from the media player let's
move back to the to the big screen
please alright now here we see how
Victor switched today to the media
player as they main application and
notice that I don't know if you notice
that the navigation car went on top to
the notification area to the permanent
area right there perfect thank you for
the media section he has access to all
the Android auto enabled applications
media applications that are already out
there whatever is in in his car he'll
pick one great media applications have
two main screens we saw the first one
with the playback controls those flavor
controls are standard play pause skip
some of them are customizable and of
course we have a second screen which is
showing now which is the menu for
browsing content where applications show
what what's available for the user to
pick we recommend that we keep the
hierarchies kinda shallow and that we
tried to surface on top personalized
content frequents favorite cetera so
it's less distracting alright hope you
can hear that this can help anyone get
really good
it's just bad I thought he was a place
outside she's on the podcast today
alright Victor will talk to you later
about how to integrate a media
applications into the platform if you
haven't done so already
Thank You Victor let's move to
the phone area here great let me show
you how the third Android surface will
work its Android auto on the phone
screen no new car needed all I have to
do is bring up the Android auto
application from the icon and Here I am
in the Android auto home screen but
update to the screen in my phone this
should look very familiar to you already
I can also sit and read Auto to
auto-launch we need to take the
Bluetooth device in my phone when I turn
it on for instance from the home screen
I have access to the same suggested
destinations we talked about before is
Android auto is the same platform I also
have ongoing activities like media and
you can show me miss messages or missed
calls that I may want to return alright
so from the media media card I can
always go to the media app again I have
access to all the media applications
that are running on my phone that are
Android auto enable books on Ted books
podcast several music apps let me pick
on me pick one and when we launch the
app I can start playing where I left off
but I also have access to the full menu
just one swipe away by the way the
customizable controls are also here
alright another thing that I wanted to
show you quickly is how many Jing works
in this screen so Vinson is gonna tell
me when he's appeared that he's already
in Santa Cruz waiting for me
taking him a little long to get there
today alright so here is a message
notice that the notifications in the
phone screen a little larger than usual
they are adapted for the smaller screen
size so I can tap him while I'm driving
a soui so before I don't have to tap
that time notification to listen to it
it's always in my home screen here's the
message hey I'm here now you can press
the voice button and say reply of course
I could try to reply with voice but as
always the auto reply message is there
and I can just tell him I'm driving
right now I'll catch you later all right
the last thing I wanted to show you is
how the power of voice integration works
with Android auto I don't know if this
will work in the environment
you guys are kind of quiet so I'm gonna
try let me see
navigate to Santa Cruz Santa Cruz USA
alright you should watch your
destination by 7:30 2 p.m. great
so I'm navigating and of course the next
turn is always available from the home
screen so I don't miss a turn no matter
what I'm doing until Graham Parkway let
me stop these for a second
all right so I hope that this quick demo
gave you an idea of how the platform
works together a next thing that we're
gonna do is let's go back to the slides
perfect we're gonna go into more detail
about how you integrate your apps into
the into them to the other platform
we're going to talk about messaging and
we're going to talk about media and
remember that if you already integrated
your app it will run seamlessly on both
phone and car screams we use the same
interfaces across all three surfaces if
you have an integrated yet stay around
and victor is gonna tell us how to
integrate with me thanks
hi
hi I'm Victor I'm a software engineer on
the Android auto team and I'm here to
talk about media apps there are a couple
things I want to focus on today
first of all well look at how to make
your media app compatible with Android
auto then I'll offer some tips and best
practices to help you provide the great
a great media experience inside of a
vehicle so as you saw earlier in the
demo media content can show up in many
different forms and various Android auto
devices on the left here we have our
media facet which is a templated UI
experience where the user can control
playback and also we offer browsing
capabilities on the other hand media
content can appear more passively such
as a card inside of our overview stream
or as a notification inside of our
instrument cluster I just want to point
out again across all these different
surfaces whether it's a phone screen or
a car screen a developer only means to
implement the necessary API or service
just once and when that's done Android
auto will do all the heavy lifting to
ensure a safe and engaging experience
across all these scenarios alright let's
dive into code so first of all we need
to do a bit of setup because we want
Android auto to be able to find your app
so here in our Android manifest file I
point to a secondary XML file named Auto
app descriptor and inside the auto app
descriptor I say that this is a
automotive app and it is it the type
medium so this really lets us know that
your app can provide audio content for
auto devices once we can find you you'll
need to implement a service in this case
the Media Browser service the Media
Browser service does two things first of
all it provides a content hierarchy
which is what we use to create a content
browser that the user can then use to
find and explore audio tracks at the
same time the media browser should catch
a media session which is what we use to
control a rather remote control playback
in
so here is a sample Media Browser
service as you can see we're
implementing or rather extending Media
Browser service compat which is
available in support library 23.2 and
higher and of course this will help your
app run order devices there are two
methods that we need to implement inside
the Media Browser service the first one
is the on get route method now this is
called to retrieve the browser route of
your content tree this route itself is
not a media item however we use this
route to retrieve a list of media items
which are then used to populate the top
level of our content menu also note that
root hints may be passed to you these
can include things like offline recent
or suggested and these are really just
hints that Android auto wants to tell
you in terms of what kind of content you
should be sending back so try to respect
these when you're exposing your content
the second method that you need to
override is the onload children call
now whatever Android auto needs to
display a list of media content inside
of our media app this method is invoked
and you will be passed a parent ID of
the media item and we expect you to
return a list of its children now let's
take a closer look at this onload
children method first of all I want to
say if you are returning media items try
to do so from a cache and the reason is
you could imagine a users driving down
the highway they're listening to some
songs and they're going and they want to
play a different playlist and now
suddenly your app needs to go across the
network to download all those songs and
you can imagine if the cell signal is
not great the user is looking at a
screen that's loading and their eyes are
not on the road anymore
so not only is this a bad experience
it's also not very safe so we really
recommend you to cache your media items
as you're creating the content tree so
when onload children gets called you're
able to return the media
immediately from memory now if you have
to go over the network just simply
detach the result object set up your
asynchronous attacks and once you're
finished loading just send it back
through the results object so while
we're on the subject of content
hierarchies let's take a look at some of
the common pitfalls or mistakes that
people tend to make so in this example
here and we have a media app that can
play radio and a separate state
separates it down into local radio and
further breaks it down into different
genres like jazz or pop or other types
of music in this case the user has to
click at least three times before they
can reach the first playable item so
this deep nest thing is actually not
very good because you can imagine again
the users on the road and they're
tapping the screen three times before
they can do anything so again in this
case you should really try to surface
interesting content or engaging content
higher up in the tree so it's available
to the user right away the next thing is
we've heard a lot of feedback from our
users that they want to be able to
explore media contact while they're
inside the car so we're working on ways
for users to browse through large
amounts of media content of course in a
safe manner
so what does this mean for the app
developers well this means is you should
not shrunk a your content trees
prematurely in this example the user has
finally gone to the jazz section and
there's actually just two stations
because everything else got cut off so
let's try not to do that
so the last thing i want to talk about
content browser it's if your data is
dynamic so for example you're a media
app that generates a playlist based on
where the user is or the traffic
conditions then when that content
changes you need to notify us because we
can update the content browser for the
user and you would do this through the
notified children change call alright
now that we talked about media browsing
let's take a look at media session so
the media session serves two purposes
first it lets you update send updates to
us about playback States or metadata
changes also allows us to remote control
playback inside your media app so here
we have our Media Browser service again
this time let's take a look at the
oncreate method inside of on create we
instantiate a media session object and
the first thing that we do is we take
its to a session token and we set it as
the session token for the Media Browser
service now this is important because
when Android auto connects through your
media app the first thing it does is
they retrieves this session token and
creates a Media Browser media controller
object which is then used to control
playback and receive updates also there
is the media session callback which we
use to handle a playback event which you
will implement to handle playback events
from Android auto we'll take a closer
look at this in the next slide and
finally remember when everything is done
release the media session this frees up
any system resources and actually tells
Android auto that you're finished play
so we can clean up any leftover UI
elements
all right so here's our sample media
session callback so the methods here
allow the callback object to handle
various playback events you overwrite
them as you need so for example if your
app is a streaming radio app and then
maybe you don't need the on script to
Next button because that doesn't make
any sense so in that case you can simply
leave that as the default implementation
now in the case of a on play or on
resume you should check if your media
session is active if your media session
is not active set it to active and this
tells Android auto that you're in fact
playing and that we can surface your
content inside of our stream or inside
of our notification area another method
we want to talk about here is the on
play from media ID so this method is
invoked when a user goes through the
content browser clicks a playable media
item and they expect something to play
this method will being invoked and the
media ID were passed in and this media
ID is the same that you have passed to
us through the media item in the onload
children call so you can imagine the
media ID should be unique and it should
be persisted so you can find the right
song to play when the user clicks on it
I note about voice support so if you
want your app to support command through
voice like play jazz on my media app
you'll first need to specify intent
filter inside your manifest file this
basically tells us that you are able to
handle playback from search so when the
user issues the actual command we'll
launch your app and the on play from
search call will be invoked now you will
be passed through the query and a set of
extras so if the query first of all is
empty you should still try to play
something back because this tells the
user that your app is responsive and
that their action has taken place now if
they query is valid
you can try to parse the query yourself
or you can listen inside the extras and
will pass your information such as title
album or artist name
and finally if you can't actually find
this on that's okay just showing error
again this is to tell the user that your
app is responsive so now let's look at
some of the updates that your apps can
send over to Android auto first of all
there's the metadata object this
contains things like title artist or
album art and let's focus a little on
album art here as you saw earlier in the
demo the album art of this title of the
track that's point can show up as the
background image of maybe a 15 inch 4k
screen in this case resolution is really
important so you can send us that album
art in two ways you can send it to us
either through a bitmap or a URI I
recommend you guys to do that in a URI
because Android the framework actually
scales down the bitmap to 320 by 320 DP
so if you want a high resolution image
the UI is the way to go so the other
state that you can send us is the
playback state this tells us things like
if your app is playing if it's stopped
and actions that can take if it can skip
forward if it can pause it also tells us
the playback position how far along in
the song you're currently playing a
couple of tips here don't send us a
playback state change every second if
the only thing that is changing is the
playback position because we don't use
this value to update the progress bar
instead of our media app in fact you're
just taxing the system and we're
ignoring these updates on a similar note
if your app is actually stopped
don't send playback States unless
they're actually changing because again
we're just ignoring them and you're
taxing this system finally I want to
talk about the buffering State this is
an interesting one because when the user
clicks play and you need to download the
song you should send the state to us
right away because we can then tell the
user through a spinner or a progress bar
that the track is being downloaded
because if you don't do that your UI
will seem somewhat unresponsive
and with that I'll hand it over to
Vincent for customizations thanks Victor
hi everyone my name is Vincent and I'm
an engineer manager on the Android auto
team so with Android auto we want media
apps to be able to showcase the
uniqueness their users have grown to
love and expect in the car it's also
important that the user experience is
one that is optimized and friendly for
driving and to be honest this is a
challenging task Android all aimed right
auto itself has undergone extensive user
studies driver distraction testing and
simulators and in real life driving
scenarios where minimum contrast ratio
tap target sizes glands tines cognitive
load and driving performance are all
factored into its design as you can
imagine this isn't something that we
want or we think every media app should
have to get right in the end we thought
that it was best for the users and
developers to have an API that abstracts
this out so developers like you can
focus on making your apps great knowing
Android auto will provide an appropriate
in card user experience so in this
section I'll be walking you through how
you can easily customize your media app
for Android auto so media playback
controls are the primary interface for
users to control their media playback
experience these controls are displayed
throughout Android auto and laid out two
differently depending on the surface and
the condition that Android auto is
running in for example the audio
controls card on the phone screen I look
different than the audio control cards
on the car screen and it also looks
different in night mode versus in day
mode again this isn't something that
your app needs to be concerned about
since Android auto will handle this
behind the scenes so how do you get your
apps who surface the appropriate actions
are the controls for your app in in the
media session playback state remember
that your app is actually already
updating the playback state for the
media session set the supporting actions
via the set actions method and the
playback state builder
the playback state compact class if you
look into it has a defined set of
standard Media Action constants like
play pause skip forward and skip
previous let's look at the action skip
to next constant as an example because
it's listed as a supported action
Android auto will surface the button in
the controls panel when the user
interacts with this button the media
sessions callback on skip tunics API
will get invoked a few things to keep in
mind remember to always keep the
supported actions up to date based based
on the appropriate playback state that
they that the user may be in for example
the user is at the beginning of the
playlist it might be a good idea to
remove these skip to previous action we
also recommend that apps always report
all the supported actions so that the
app doesn't lose any functionality now
what if your media app supports
additional actions that aren't defined
in the playback state compact for
example maybe a thumbs up well you can
create your own custom action a custom
action contains a few things in action
string this is very specific to your app
and it's unique for each custom action
an action label text this may be
displayed for accessibility a drawable
resource this is shown in the actual
playback control we remember to include
transparency in it and we also recommend
using SVG so that we can properly
display it in various screen sizes and
lastly there's also an extras bundle
that is optional so when the user
interacts with the custom action
playback control the on custom action
method of your media session callback
gets invoked this is where you can
handle the actual like action we also
know product and product branding is
important for you and we want your apps
branding to show through well in Android
auto so if your app already uses the
material design color theme like the
color primary color accent and color
primary dark Android auto will show
these colors in the appropriate places
throughout our our UI you can also
define an Android auto specific theme
in your media app by adding a metadata
element in your apps manifests as shown
lastly Android auto may show a media
related notification for example when
the next track is being played a
notification with the track name will be
shown so be sure to specify an icon
resource in your manifest so that your
apps icon is also displayed in the
notification so that's it with a simple
fuse with a few simple steps you can
customize your media app with an Android
auto that works across all the supported
surfaces while getting a driver tested
user experience for free so next I want
to talk about messaging we know that
Steam connected to people that we care
about like a friends or family is very
important to all of us regardless of
whether we're in the car or not with
drivers safety in mind it's important
that users can access their messages in
Android auto with minimum distractions
so drivers can focus on the road we
don't think every messaging app should
be burdened with having to do extensive
drivers driver distraction testing to
achieve this goal
so with messaging we've taken the
similar approach as we have with media
we have an API to abstract out these
things like so that you don't have to
worry about and focused on getting the
messaging experience right this is just
a recap of how messaging works as Paco
demoed earlier it's pretty
straightforward we have a notification
that appears when it comes and then
there's a messaging card that remains in
the overview screen the API is quite
simple it's actually built on top of
Android notifications which is something
I'm sure your app is already using so
when a when an incoming message arrives
your media well your messaging app
already will just notify Android of the
notification now if your notification is
extended with car extender
Android audible will be able to receive
the notification and display the
notification to the user when the user
issues a a read command of the
viavoice red pending intense gets sent
back to your app similarly when the user
replies to a conversation that reply
pending intent gets sent back like media
before you get Android auto to recognize
your app for messaging make sure you
include the notification usage in your
Android manifest
okay so let's dive into the part of
extending your notification with car
extender the first portion of this code
snippet looks familiar
the interesting part that we care about
here is where we extend it with an a car
extender object one tip that I want to
to pass on is if your app is actually
checking to see if Android auto is
present before extending the
notification we're recommending we
recommend not checking for the existence
of the Android auto package since that's
not very reliable instead you can use
the UI mode manager and see if Android
auto is running car mode so let's look
at the unread conversation object first
I think will be useful to define some
definitions so a message is essentially
just a short length of text that allows
Android auto that Android auto will read
out to the user it's best to not make
these messages too long a conversation
essentially is a collection of messages
that are grouped together in some way
and typically messages between user and
another person will be a conversation so
with that an emetic conversation is
actually just a set of unread messages
for a particular conversation okay so
what goes inside this conversation this
unread conversation you can pass any
conversation name this is the text that
gets appeared that gets presented to the
user when Android auto presents an
unread a message obviously you pass in
the actual messages there might be more
than one and in this case when you set
the timestamp for these messages include
the time stamped for
the most recent message and there are
two remaining ones the red pending
intent and the reply action that will
dive into more in the next slides also
if there's a message that is that only
has an image we recommend including a
readable alt text so that the user
doesn't doesn't experience a broken
experience when reading back a few
messages also please do think about how
this works for group chats we recommend
actually just testing out the flow and
seeing if when the user is reading back
the message if it's an actual as it's a
good user experience alright okay so the
read pending intent again is a pending
intent that Android autos sends back to
your messaging app when the user has
invoked a read action it's creating the
read pending intent is pretty simple you
create the intent that you want the app
to that you want Android auto to send
back when the user has completed a read
message the primary things to highlight
is you just want to set the action
string that is specific to to this read
action be sure to set the component
because we want this intent to be
explicit this way
it's guarantee that your app will get
the pending intent and then lastly
put the extra width or petty
conversation ID as an extra and the
intent that you can later check and once
you have that then you can just wrap it
in the pending and checks
so receiving this pending this red pen
pending intent is pretty simple in your
apps manifest just have a receiver that
is registered against the red message
action string that we defined earlier
and this way when you're when the repent
the red pending intent is sent back to
your app the appropriate receiver the
appropriate receiver is invoked and in
the on receive callback this is where
you can process the intent and handle
the the Brad message and event so the
last part is the reply action I was kind
of just glanced over this again this is
sense when there's a reply event similar
to to the read pending intent you create
an intent with the appropriate action
string that is specific for the reply
message and then you can wrap the intent
within the pending intent the remote
input object is just passed along with
me pending intent that gets sent back to
your app which will store the actual
string making up of the user's reply
message and with that yet the broadcast
receiver and that you've registered will
get the on receive call back and then
you can extract the cut the ID and then
the message reply one one hint or one
tip is when you get this just don't
assume that you the user has read any
unread messages since the user can
actually send replies out-of-band and
then like media you can also customize
the look and feel in this notification
the car extender object again that was a
simple way of making your messaging app
support Android auto and next I'm gonna
invite Paco back all right Thank You
Vincent
just wanted to conclude summarizing what
I believe are the main three takeaways
of the presentation the first one is
that Android is showing great momentum
in the number of cars that are
supporting Android auto the number of
applications that are already running on
the platform and also the number of
countries were is already available the
second one is that we expand in an
original platform to heat your
applications significantly more reach by
enabling Android auto on your phone
screen and of course bringing the power
the power of Android and natively into
the car and the last point still the
same interfaces will work across all
three surfaces your application will run
in a framework that is interested for
this driver distraction to minimize
travel destruction including voice
integration to power the most common
tasks that you can perform as for next
steps if you are ready to start
implementing to start integrating with
the application with the platform all
the technical details that we talked
about today are viable and these links
please join the development the
developer group Android auto dev and if
you remember any link out of this talk
developer.android.com/design
if you want to learn more you have
questions come talk to us the sandbox is
right behind the big tent here and check
out the cars from our partners check out
the concept car and all of the other
ones we also have phone stairs that you
can you can see how these works if you
if you have time and wanna give coding a
try we also have an Android order
specific code lab in the code lab
section if you want to hear from us in
the future
sign up for news or Android comm splash
water and I don't think we have time for
QA but again come talk to us we're in
the sandbox and I don't want to really
take any more time of yours
please it's been a long day go enjoy the
concert go relax and thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>