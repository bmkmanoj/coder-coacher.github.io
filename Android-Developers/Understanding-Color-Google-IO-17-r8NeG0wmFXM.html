<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Understanding Color (Google I/O '17) | Coder Coacher - Coaching Coders</title><meta content="Understanding Color (Google I/O '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Understanding Color (Google I/O '17)</b></h2><h5 class="post__date">2017-05-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/r8NeG0wmFXM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone and welcome to
this talk about color so how many of you
think they understand color raise your
hand nobody ok I guess that's why you're
here so I gave a similar talk last year
at the end of 360 and there was a lot of
math in a lot of equations and a lot of
worried developers asked me if there's
going to be math in this presentation
there's going to be no mass no equations
instead there's going to be physics so
let's talk about color the first
question we have to ask ourselves is
what is color it sounds like you know a
deep question the answer is not so deep
so here's the definition that applies to
most of us as human beings on that
developers were just regular people so
it's a visual visual perception that can
be described by a hue brightness and
colorfulness sometimes colorfulness is
also called saturation and if you've
ever used the HLS HSL or HSV colors in
the Android API you might be familiar
with that kind of definition what's
really important to understand is that
color is just the perception of our
brain it's not the real thing
and we're going to see why that is so
obviously we see colors with our eyes
and if any of you does lexy color
through another mean I would love to
talk to you and to understand how we
perceive color we first have to go back
22 high school or college and and try to
understand what light is made of so I'm
sure most of you know that light is made
of photons but there's a duality to
light it can be a wave or a particle and
we're going to look at the wave nature
of light first so light is an
electromagnetic wave and our eyes are
just receptors for those electromagnetic
waves so here's the electromagnetic
spectrum is not it's not to scale and
from the shortest wavelength to the left
to the longest wavelength to the right
we have in order the gamma rays the X
rays the ultraviolet the visible
spectrum they're tiny little bit in the
middle full of colors then we have the
microwaves and sorry the infrared the
microwaves and then the radio waves the
part that interests us that
that deadly bit in the middle so that's
what we call the visible spectrum it
goes from about 400 nanometers to 700
nanometers and all of us
these are the only wavelengths that we
can see why does this matter our eyes
against it are receptors that are
actually made of millions of small
receptors called cones
most of us almost everybody has three
types of cones that can detect different
parts of that spectrum so you see the
spectrum here at the bottom these are
all the wavelengths of colors that we
can see and this diagram shows in three
different colors the the sensitivity of
each type of cone that we have in our
eyes
they're called short medium and long
sometimes they are called blue green and
red it's not technically accurate to
call them red green and blue since
that's what I call them shorten them in
all and they'll call that way because
the short ones help us see in the blue
wavelengths so ultra violet violet and
blues then we have the medium ones that
help us see the greenish colors and the
long ones that help us see green orange
yellow and a little bit of red and you
can see there's a lot of overlap between
the the medium and the long wave the
longer receptors so now what is light so
light is a distribution of several
wavelengths so this is the what we call
the spectral power distribution
distribution of a light bulb so the kind
of light bulbs that you know you can
find in any house
it's an orange light bulb and you can
see the amount of energy it outputs in
different parts of the visible spectrum
you can see here that this type of light
bulb I will put most of its energy in
the red and orange part of the spectrum
and that's why we perceive it that way
but what happens when the lights from
that level hits our eyes so we saw that
we have those receptors that different
sensitivities so different part of the
of the spectrum so we just multiply the
distribution of the incoming light with
these with the sensitivity of our
different cones and the result is what
we perceive so when we multiply both we
get this so when you look at one of
those light bulbs you see almost nothing
in the blues you see a little bit of
green and more orange and red and then
our brain will interpret that as an
orange color the way we actually
interpret the result of this cone
so it is a little complicated and we
know last time to go into the details
here you can go look on Wikipedia how it
works if you are interested so here's
what happens exactly when we look at the
light source so the light is emitted by
the LA sorry the this wavelengths
emitted by the light source it hits our
eyes multiplied by the current as well
through verses but most of the time
you're not looking directly at the light
you're looking at different objects that
surround us and how do those objects get
their color from so every object also
has what's called a spectral power
distribution it's a description of the
wavelengths that the object can reflect
we call that the reflectance so some of
the wavelengths will be absorbed so for
instance a black object absorbs almost
everything that's incoming and a white
object will reflect pretty much all the
wavelengths so we also multiply to
perceive the color of an object what
happens that we have light coming down
sees of an object some of it is
reflected so we just multiply the two
distributions then it hits our eyes and
we get the the final perceive color
what's very interesting here is that any
combination because it's a
multiplication any combination of light
and reflectance can yield to the same
perceived color in our brain so
basically for example is that if you
have an orange object lead by white
light you can ask it orange but if you
have a white object lead by an orange
light you're also going to see it orange
and our brain does a lot of
post-processing really to help us
understand what is the color of the
light what is the color of the object
and you know a few years ago there was
this famous example of the press some
people were saying it's in black and
blue some people were saying it in gold
and something else and that's exactly
what's happening is that some of us were
interpreting the result differently and
nobody was wrong it's just without the
context you can't really know for sure
so yeah that we can swap the colors the
distribution of the light source and the
object and you're going to see the same
result so that's Lee that leads us to
something called the chromaticity
diagram it was standardised in 1931 by
the Commission intl delay Claridge CIE
French French commissioner partly and it
represents all the colors that
we can perceive as human beings so on
that horseshoe shape the outside edge is
called the spectral locus it represents
all the pure colors the pure spectral
color so that that spectrum of colors
that we saw in the previous diagram is
actually actually bends around that edge
all along and everything in between
all the colors that we can actually see
are a mix of all those different
wavelengths then so it does we have
shaped it's not a rectangle or anything
and there's a lot of colors that leave
outside of that spectrum we call them
the imaginary colors because we cannot
see them no matter how hard you try you
won't be able to see those colors there
are some multiple optical illusions that
you can find online that will kind of
help you find those colors it's actually
really weird not everybody can can see
them or perceive them there's one for
instance where it shows you blue a blue
rectangle for one of your eyes and the
yellow rectangle for your other eye and
the way I see this is really weird color
that you can't really describe that
keeps changing from blue to yellow but
doesn't but never stops on one of those
two colors the visible spectrum is
actually a little bit more complicated
than that what you're seeing is it
sliced it's a 2d slice there's a z-axis
that's coming towards you and that is
the brightness so the footprint at the
bottom like the sub footprint you see is
the dark colors it's because our eyes
are better at seeing dark colors than
they are seeing light colors so we think
what colors are for us as human beings
but you know everybody is a developer I
think in the audience so the real
question is what is color for us as
developers what does it mean for your
application so color really is an
including scheme for brain sensations
and the formal definition is that it's a
tuple of numbers or lists of numbers
defined within a color model and
associated with what we call a color
space we're gonna look at some examples
to make you understand that so here's
our here are some of the color models
that you may be coming out with RGB is
one of the obvious one I'm sure
everybody's use that CMYK
if you have ever printed a picture or a
book or something you might not also
have you might have also dealt with it
and there's the another one for instance
called Li B there are others as X Y Z
doesn't many others what's interesting
is that the color model defines how many
numbers we need to define a color so
you're used to RGB to three colors it
has three values but CMYK requires four
values for instance so the one that
we're interested in today is the RGB
color model it is a triplet of values
hence the name and you are mostly I'm
sure most of you or all of you are
familiar with the hexadecimal notation
so there are many ways of representing
the triple of numbers this is one of
them is pretty popular description on
the web you've probably found it used it
a lot on Android when you want to pass a
color directly to one of our API s so
this is a pinkish color so this is the
same color represented as a triplet of
8-bit unsigned integers you're also most
likely familiar with it this is
something we use a lot on Android when
you set the color on the paint or when
use the color that's ready to expect the
right component of a color and this is
another notation this is actually the
one I prefer this release floats so the
values are between 0 and 1 and it's
interesting because it's more versatile
you can use it to represent HDR colors
and we'll see that Android actually
makes use now in O floats the third
rotation if you have negative colors and
colors that go beyond one so to
reproduce so the big question is once we
have those numbers what colors do they
actually represent so I told you this is
a pink but you've seen that spectrum of
cars done many many many things is
actually an infinity of things so which
one of those things does this represent
so to reproduce colors are all of our
displays use additive lights so we use
red green and blue and our TVs are
phones our computers are all charged
monitors and it just mix those different
lights so the numbers that you just saw
the RGB triplets it might sound obvious
but they're an intensity for each one of
those lights so let's say we pick 3
lights we pick your green light or red
light in a blue light and they're not
perfect spectral lights they are just
random lies that you found they are
found somewhere in the visible spectrum
and the together they form a triangle so
when you have an RGB color in your
application
you are just you can only represent one
of the colors within that triangle you
cannot represent colors that live in the
entire visible spectrum so and there's
and that triangle is what we call a
color space and there's an infinity of
them depending on the the three lights
you choose you can represent any of an
infinity of color spaces so here for
instance the widest or one of the widest
color spaces we could create the point
we have that with a triangle with just
three lights
we cannot encompass all the visible
spectrum we have to choose a smaller
slice so this one in particular is
called the ID a double white game with
RGB color space there's no device that I
know of that can capture or or recreate
this color spectrum this color space and
the problem is that if we wanted to
create a color space with RGB that that
contains all the visible colors we'd
have to create lights that are in the
imaginary space so light that we cannot
perceive because we've seen that our
eyes cannot receive outside of that
foster shape the color space is Audion
more complicated than that
so color space is actually defined by
three components the first ones are
called the primaries there are three of
them then we need a white point and then
we need something called transfer
functions so this might look like a
complicated diagram but what I did is I
put the visible spectrum or on the left
and I've overlaid three triangles that
represent three common color spaces that
are used in for still images so the
smallest one you see in the middle the
blue triangle is the one we call srgb
I'm sure you've heard that term before
so it's R to B stands for standard RGB
and was designed in the 90s and kind of
matches the reproduction capabilities of
the shakti monitors of back then
and to this day still used everywhere
and pretty much the universal color
space the only color space that you can
you can count on there are other color
spaces there's Adobe RGB for instance
it's the orange triangle because it's
bigger than the sRGB color space we say
that it's a wide color space or it's a
wide gamut
three vertices of the triangle the
triangle is something we call the gamut
and then there's something called
prophoto RGB that you can see extends
beyond the visible spectrum and it is
not a color space that we use to
actually represent colors on the screen
this is what we call a working color
space for instance when I take a picture
with my camera my camera is said to
Adobe RGB so it captures everything in
the color space that you see on screen
then when I import my photo in Lightroom
Lightroom internally Adobe Lightroom
works in prophoto RGB and it won't be
able to recreate all the colors that
it's working with on screen but the idea
is to have as much precision as possible
so you can ignore this kind of color
space for for your needs on Android
applications so I said a color space has
three primaries and the primaries really
are the coordinate of each one of the
three vertices of a triangle in that
chromaticity diagram in the visible
spectrum so they identify when you set
one such that you want to color that red
equals one Green equals zero blue equals
zero it tells you what red we're talking
about and if you look here on the on the
screen srgb and Adobe RGB when you say
red equals one they have the same exact
red but profit orgt has a different red
so it's two different rights for us let
me study for computers we'll take a look
at that and then we also need a white
point and the white points the same idea
it gives us the coordinates of white in
that in in that color space and we'll
get back to that so I also mentioned
transfer functions transfer functions
audio bit complicated that's where a lot
of math comes into play you've already
heard about them under the name Agana so
if you heard about gamma correction
that's actually transfer functions so I
gave a talk last year about transfer
functions I don't have time to talk
about them today I'm going to give gonna
show you a link at the end of the talk
if you're interested you should
definitely go look at the talk there's a
lot of things that you should learn
about transfer functions that can impact
your applications so I've been talking
about current spaces but why do we care
so much about color spaces so the
problem is that every device out there
has every different color space so for
instance you can have a phone that has
an LCD screen is going to be close to
srgb you have a
phone that has an OLED screen it's going
to be closer to p3 to a color space
called p3 or to the other the RGB color
space that we just saw and something for
your laptop for your computer for your
TV and things get even worse because
even if you have two phones they're the
same model that's the same manufacturer
they are both supposed to be lets say p3
there are variations in the
manufacturing process so they won't be
the exact same p3 so the colors won't be
exactly the same on those two devices
and I'll show you an example of what
happens so let's imagine that we have
content that we created for srgb so it's
in this RGB color space we designed it
at home on a computer that shows srgb
colors that's the white triangle you see
and then if we take that content as it
is we don't do anything to it and we
just show it on the display that's Adobe
RGB what we're going to do is we're
going to just take those RGB triplet
those values we had and reinterpret them
in the different color space so suddenly
you're green that you had in this RGB
like that green equals 1 is going to be
a different grain it's going to look
completely different to your user who's
using another way out of the screen so
here are concrete examples this is a
photo I took I I took it in Adobe RGB I
processed it in prophoto RGB I converted
it I converted it nicely on my
calibrated monitor - srgb
this is what it should look like
actually this is not what it should look
like on my laptop it's what it should
look like because those trains have a
current state I have no idea what it is
but it's definitely not srgb and what
this is really wrong but what matters
the difference between the next photos
so let's say that this is proper subsidy
this is how I wanted you to see the
picture now if I display the picture as
is on a different screen let's say DCI
p3 it's going to look like this which I
go back and forth you can see there's a
difference in contrast some of the
Khorasan be a bit more saturated so
already my photo does not look like the
way I intended then if I displayed on a
prophoto RGB display your searching
existed it would look like this
so super saturated really garish I don't
know about you I really don't like this
picture and those are only when we have
that happens when you only effect the
primaries but you can have similar
issues when you effect
your white points so the next slide here
that is the same srgb photo so we kept
the primaries but I changed the white
point to something that's blueish and
certainly my photo well you know it's
other water so I can kind of make sense
to be blue but it is not the way I
wanted it to look like
so again if you take multiple Android
devices for instance and you put them
side-by-side chances are that some
screens will appear yellow to use some
screens will appear blue to your green
and that's because of the white points
we have different white points across
multiple displays and once again the
same model of device from the same
manufacturer there are going to be a
white point variations so when this
happens we said that colors are
unmanaged this is what Android has been
doing since Android 1.0 and I hate it
absolutely hate it it's horrible you
know your designers will spend hours and
hours like slaving away on the computer
like creating a beautiful UI then you
test it on the phone and it's completely
different and you test it on another
phone and it looks completely different
again so you might be thinking how can
we have our design look exactly the way
we want so the solution is something
called color management and it's a new
to Android oh so the idea is that every
color that we want to display needs to
be associated with a color space we need
to know what was the original intent of
the design so we need that information
then through the magic of a lot of math
and matrices it's actually a lot more
complicated than just the matrix but
that's most of it we're going to do a
controlled conversion to the destination
color space so what we're going to do is
that when we manufacture a device we're
going to use special devices that will
measure the capabilities of the display
we're going to measure the primaries and
the white point of the device we're
going to create the destination color
space and then we can convert your
original content through the destination
color space and preserve the same colors
that you wanted to have so this is
something we're introducing in Android
oh and there are two parts of it there's
first color management
proper and then there's something called
the white color gamut rendering it when
I take a look at those but first before
you need to worry about Android you need
to make sure that you or your designers
are
using color spaces properly in your
design application and there are two
things you can do with pictures you can
assign a color space or you can convert
to color space so I'm going to switch to
a demo but first I just want to show you
earlier I said that color spaces the
disco mattes is the diagram we had the
horseshoe shape it's a slice of the
color space and so are the the game
mixes triangles so this is srgb in 3d
and it's interesting because I mentioned
that our eyes see more in the darks and
you can see that in that diagram the
brighter the colors the less the less
the fewer use we can pursue all right so
for the demo so I'm using a tool called
affinity photo and this is a picture I
took same process in all two kitchen
either the RGB I was using wall files
from my camera from my DSLR
I use prefer to RGB to do my work in
Lightroom and I created an sRGB version
of the picture and if we zoom in pretty
much every any good design tool
somewhere will show you the color space
of your image so here we know it's in
this RGB image I'm on a calibrated
display looks fine and I can said you
can assign a color space often called an
ICC profile or you can convert so if you
assign what you're saying is you're just
saying keep the colors the way they are
keep the same values I just want to move
them to a different color space so let's
say we move to the Profoto color space
and now it looks like this this is
exactly what Android does this is not
the right way of doing it sometimes
that's what you want because you know
what you're doing but very often it's
not going to be which one so instead
what you want to do is to convert ICC
profile sometimes called map it's
sometimes called match so we pick
Profoto and when I click you'll see no
difference and this is what we wanted
but what happens that every single RGB
value has changed it just looks the same
we just have different values stored
inside the image and to give you an idea
what happens to your Android design so
this is a screenshot I took of my pixel
2016 running Android
and and on Android we pretty much assume
that all the content is srgb so when I
open this file
in the tool I was one that there was no
color space and that the tool this room
srgb now when you display the screenshot
on a on an OLED display because we don't
find edge color what happens on that
pixel 2016 is this so I hope you can see
the difference if you look at the right
icons at the bottom you can see that
everything becomes more saturated so
that's what you designed and that's what
you see on an actual phone right so when
you don't know what the color space is
just assume it is RGB the only
assumption you can make and this is why
electrons on my photos are thought to be
because when I put them online on the
web has no idea where display you're
going to use that I've no idea what
device you're going to use I don't know
if your app is going to be color managed
or not and it's our job is your safest
bet it won't be always correct but it's
just as bad so when use the design tool
and you have a color picker if there's
no information about the correct space
anywhere in the tool you are most likely
using either srgb or what we call native
gamut which is whatever the screen can
do for instance this is what Apple
Keynote does when you pick a color you
pick the color directly for your display
and that's another this way if your
application is color managed in your
document has a color space you're
picking a color in that color space some
color Pickers are more advanced so this
is for instance on Mac OS Sierra if you
click that here gear in the second tab
you can choose the color space you want
to use for the color picker and actually
when I was working on the slides
I picked colors for the slides and I was
creating diagrams into a different tool
and I tried to match the colors and I
forgot that hi to change the the to srgb
in the speakers we took me five minutes
to understand why my colors were
different so even when you know that
Cora spaces in color management it can
sometimes be confusing another tool you
can use on Mac on likewise functions and
other platforms that studio tools is the
digital color meter it's in the
application slash utilities folder it
lets you pick any color on the screen
and using the drop-down you can choose
the color space
you want for that color so you can look
at the color in the native game without
the display or you can use srgb or p3 or
whatever on Android if you have a recent
version of Android and if you have a
pixel device for instance if you go to
the developer options you can turn on
the srgb mode so here what we're going
to do is apply color correction we're
going to apply color management to the
to the display to make sure that all the
colors are interpreted and reproduced as
srgb you might be surprised at first a
lot of people complain that the colors
look washed out that they actually more
accurate it just matter habits all right
so now some code so on Android what
you've been using so far is what we call
the color int just an inch it contains
alpha red green and blue and the only
assumption we can make because we don't
know what color space you're using is
that it's srgb so it's pretty simple now
in all when producing a crazy new API we
let that color class for 10 years but
the only aesthetic methods now you can
create instances of the car class you
can actually use color as the way it was
meant to be so you just call value of
you give your RGB values and that's
going to give you an instance of the
color class in srgb because note I
didn't specify the color space so my
assumption is it is RGB you can also
specify the color space so here we also
call that U of we passed the Alpha so
the other is RGB a when it floats and
then we say that we want that color to
be in the Adobe RGB space what this
allows us to do is work with colors so
we can convert them from one color space
to the other so as this other be able to
be color and if I called converts I can
convert it to display p3 for instance
someone's happy something else we
introducing so color ins are really
useful because they are easy to
manipulate this small they're easy to
store and color objects they're the
color class is very generic it can
represent colors it is a floater
arrangement it as a reference to color
space so they can be pretty heavy object
so now we have something we call the
color long the same idea is the color
int will use a primitive type to store
color which we also store the correct
space for that color so it's similar to
value as you just called pack instead
and you get along and here's the format
of the long so we have 16 bits for the
red channel 16 bits for the green
Channel 16 bits for the blue Channel we
have tended for the Alpha Channel and
then we have 6 bits that identify one of
the built-in color spaces and those
16-bit values they use something called
half floats so there floats that use
only 16 bits instead of 32 bits so
there's a new API called Android that
you don't have that lead to manipulate
have cells anybody who does HDR or you
know advanced rendering in OpenGL Vulcan
might find that API useful if you use
the color class you don't have to worry
too much about it there's a ton of
utility methods on color that will use
the house API on your behalf so we also
have the color space class it's well
documented it's pretty easy to do you
just call get and you can create one of
the common color spaces that we provide
you can create your own color spaces if
you want to methods that are interesting
on color space this is wide gamut it
will tell you if you'd say a wider
damage than srgb and get model it will
tell you how many components are in the
color in the color space or RGB CMYK
Arabia stuff like that if the model is
srgb is RGB sorry you can cast it to
color space that RGB that gives you
access to more API as you can query the
primaries you can create the white point
you have access to transfer functions
this is this is also very well
documented if you want to do conversions
between color spaces it's pretty simple
you call connect you give us the source
card space in the destination color
space and the reason why where you need
to call connect is that we need to make
sure that both color spaces use the same
white points so when the cross species
have different
white points we do a little bit of maths
internally to turn them into the same to
make them use my point addictive way so
then you should call the transform
method you can give us RGB values and
we're going to give you back the
corrected RGB values you can also change
the white point of a color space so if
you go adapt or asbestos adapt so here
for instance we do what I did for one of
my examples my photo of the fish that
was very blue we took the sRGB color
space and I change the white point from
something called d65
to something called d50 that's that's
bluer white points are usually defined
as a color temperature
it's the perceived color of a blackbody
when you heat it to that temperature so
here D 55,000 degrees Kelvin and it's
it's blue and this 65 which is a very
common white point in color spaces for
our monitors it's 600 so it's six
thousand five hundred and four degrees
Kelvin and more yellow bitmaps we now
support color space current spaces
embedded in bitmaps so they're called
ICC profiles until now we were just even
alright completely on Android so if use
bitmap factory to decode the bitmap that
you can call get color space on the
bitmap we're going to tell you what it
is most likely for most images you're
gonna load and presumably for all your
resources that come inside your apk the
answer is going to be srgb so you can
call color space that is hardly to check
what kind of color space it is and
that's very important all the bitmaps on
Android are always in the RGB color
model we might expand on that in the
future
but we don't like to use Li B or CMYK or
XYZ or any of that they're always RGB so
you can only write now when you call get
color space in the bitmap you can always
cast it to current space at the artery
it might not be future proof so just
make sure that by checking the color
model you can do more interesting things
with the bitmap factory so on this map
factory those options we have this
horribly named field called in just
decode balance it was origin created to
let you query the dimension
of an image with a heart without having
to decode all the pixels in the image so
it's really quick gives you an idea of
how big the image going to be over the
years we've kind of abused this field so
now it's going to tell you the
configuration of the bitmap you know is
it a RGB a today is the RTD five six
I'll and now it also tells you what the
color space is so if you want to know
the color space of a bitmap ahead of
time you have to ask us to give you just
the balance to the dimensions so you
could you're you call your decode method
on this map factorial you place your
options and then we have this field
called out color space that tells you
what is the cost piece of the bitmap so
if you want to make sure that the bitmap
is in the right color space before
loading it you can do this and if it's
not in the right color space you can use
this other API options called in
preferred color space where you can tell
us what you want the color spaces the
decoded bitmap to be so in this example
for instance let's say we create the
color space at the bitmap we saw that
was Adobe RGB I don't want Adobe RGB I
want srgb so I can use in preferred
color space to force the system to to
convert it that load time then you can
just call the code we also introducing
in Android also 16-bit bitmaps
so there are bitmaps that use 16 bits
per channel and those bitmaps are always
always in the color space called linear
extended srgb we're going to take a look
at other what it is so when you have a
16-bit bitmap don't try to convert the
color space we're not gonna let you at
least for now this is how you create a
wide gamut bitmap you just create
concrete did not specify the width the
height the configuration the boolean
tells us whether there's alpha in the
bitmap and then you just give us a call
space so pretty simple bitmap as API
that lets you read and write pixels
inside the bitmap so because get pixel
and set pixel use current they have to
use srgb so when you call get pixel on a
bitmap that is not a sort of view we're
going to do a conversion for you
something when you call set pixel we
expect this RGB so you have to do
conversion yourself now if you use this
other API called copy these pixels to
buffer it gives you access to the raw
data of the business so that data is
going to be in the native color space of
the business
left completely untouched you have to be
a little bit careful because of that new
configuration for 16-bit bitmaps so if
you do the succeeded TNG the data into
that button that byte buffer is going to
be half float it's not going to be the
score inch and that's why you might want
to take a look at Android the
three-tailed at half all right
so now what happens when you draw
bitmaps on the screen so until now what
we are doing is we take a bitmap we
assume it's srgb we send it to the
screen and if the screen is that this
RGB too bad the colors are going to be
completely wrong this is still what we
do a by default on on Android oh now if
you have a bitmap that we know is not as
RGB it has a color space associated with
it we're going to do an sRGB conversion
on your behalf in the rendering pipeline
it can be a little bit expensive so you
should avoid it as much as you can if
you don't need knowledge RGB bitmaps but
at least the colors are going to be
correct on the display now if you render
a bitmap into another bitmap so if you
create a bitmap to create the canvas and
then you call draw a bitmap on that
canvas we're going to do we're gonna
convert from whatever the colors the
source card space is whatever the
destination card space is so if you want
to convert a bitmap from one color space
to another not at load time this is the
way you do it you just create the
destination bitmap you create the canvas
and you just draw so pretty simple so we
make all those assumptions about srgb
but like I said earlier if you remember
I said that already displays on our
phones have white gamut they can show
more colors than it's hard to be that
the problem is is that if we take your
ice RGB content and we don't stretch it
to the entire gamut of the display
anymore and we keep it in that field
triangle we have all those onions colors
that are not taking advantage of so in
Android all we're adding this new API
and super-complicated it's just one
attribute that you add to the manifest
per activity you have to tell us that
you want to render using those extra
colors you want the white color gamut
mode the way it works is as follows so
you have if you have srgb content sorry
if you want a device that does not
support that mode not all devices will
support that mode so if you own the
device that does does not support that
node
your window is going to use the a RGB
edit a format that's what we've been
using for 10 years so there's no nothing
new there you have the content we just
draw directly on screen you have none
less a 2d content we convert it to a
surgery and we send everything to the
screen colors might be wrong but it's
just because the device does not support
the new white color gamut rendering on
the device that does record white color
gamut rendering we're going to make a
much larger window we're going to use
16-bit per channel so it's going to
double the size in memory of your window
it's going to double the needs in
bandwidth so it is an expensive thing so
if you don't really need white color
gamut rendering think twice before
enabling it if we have a sadly content
we're going to send it directly to this
display as well and if you have known
it's a 2d content we're going to convert
it to a current space called extended
srgb and what is extended sadly it's a
color weird color space it's a really
big color space is way bigger than the
visible spectrum much much bigger and
some of the values are negative and some
of the values are greater than one they
go all the way through 7.5 and what's
interesting about that color space that
all the values between 0 &amp;amp; 1 match
exactly this RGB color space so what
enables us to do is we can take your
existing content all urs RGB content
basically everything you have in your
app today and we can draw a direct Li we
don't need to do any conversion because
it's an animagus RGB so what we do is we
only the pedal cost of a conversion when
we are drawing non srgb content so we
have you know the expenses that we need
16 bit per channel because we need a lot
of precision and range to be able to
encode as the RGB space but it's much
better for it's much simpler you just
have one attribute in your application
interestingly because we use 16-bit per
channel because of extend this RGB we
can or we will be able to maybe in the
future to render in HD I'll directly so
we could have HD RS user interfaces we
also have a new resource qualifier
called wide CG for wide color gamut so
you can create layouts or strings or
draw balls that are specific to a
display that support the white color
gamut rendering mode
we also have a few API that you can use
to query whether the device supports web
demo so if you have a resources instance
you can grab the configuration the
configuration will tell you if you have
a white color game with display if you
have a view you can call get display
give you a display object and you can
ask the display whether or not it's it's
white color gamut so the main conclusion
of all this is don't panic I put a bunch
of hearts on the slides to make you feel
better about all this I know it's
complicated and no matter how hard you
try and I don't want to stop this
happening but your colors are going to
be wrong somewhere for someone like that
wrong for me on that screen and I know a
little thing or two about color spaces
in current management but you're not in
control of everything you're not in
control of the final display and you're
not in control of all the software that
intervenes in there in the pipeline of
an application of rendering colors so
don't worry too much about it
do your best make sure that the
designers work on calibrated displays
make sure they work in srgb make sure
the images contain color spaces and you
should be okay it is mostly okay so if
you want to learn more about transfer
functions so there's this talk I gave
last year with Chet so if you go to that
URL and you go to minutes 29 that's when
the color part of the talk starts the
first half is about animations it's also
super interesting you can also look at
the documentation for color space that
RGB there's a lot of details and
information that transfer functions and
what they mean for you if you want to
learn even more about colors I gave a
talk at devoxx us a couple months ago I
talked about bending and dithering what
is bending how how can you fight it what
do we do in the platform to fight it on
your behalf so if you're interested go
at that URL and so it starts at mini
minute 36 and I think that's it we're
only have one minute left so I don't
have time for questions but I'll be at
the Android the sandbox if you want to
talk more about color and comments right
all that thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>