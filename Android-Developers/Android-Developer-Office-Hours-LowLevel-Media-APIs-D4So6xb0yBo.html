<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Android Developer Office Hours: Low-Level Media APIs | Coder Coacher - Coaching Coders</title><meta content="Android Developer Office Hours: Low-Level Media APIs - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Android Developer Office Hours: Low-Level Media APIs</b></h2><h5 class="post__date">2012-08-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/D4So6xb0yBo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Joe Fernandez and welcome to Android
developer office hours
joining me is Trevor Jones honey and a
little while we'll have our special
guest James dawn from the media
framework team as a reminder of folks
who've got questions please join us in
the Hangout and we can take your
questions live would you like to talk to
real heads every once in a while to get
started though we'll look at the
questions in the moderator queue you've
got questions please post them there and
if you like the questions in there put
plug them up for the ones that you want
to give the answer to so first one we've
got is from white out in Oklahoma and he
asks as a follow-on to the question
asked today on the AMIA show about the
issue tracker focusing on the most
starred issues may make sense for
enhancements but for defects and doesn't
that seem that doesn't seem effective
how about setting up a triage team from
the community all right
so for those of you who were not
watching the AMIA office hours the
question was basically how are bugs in
the android issue tracker which by the
way is located at be Android comm so you
know like bugs betta Android calm and
the answer was that we look at them
there are a lot of issues there and we
look at them primarily by number of
stars which is what we use as our voting
mechanism so if issues get a lot of
stars they bubble up to the top and they
get the most attention of course you
know we do try and take a look at all
bugs but you know some get of course
some more attention than others so and
the ESO as far as you know does that
make sense for defects I think sometimes
it does there certainly are some really
annoying defects that impact a lot of
people and it's good to go and make sure
there's a way to go and get you know
yeah you have a way to voice that you
need those fixed and so I think stars
work really well for that that being
said you know sometimes there are some
bugs that don't impact a lot of people
but the few people that impacts there is
you know it's still worth fixing because
it's annoyance to that's small number of
people right if if it's a blocking bug
you know that if it
prevents you from building something
right if you can't you know stream media
if you can't you're just for an example
yeah that should be fixed probably a
little bit quicker than something that's
more of a cosmetic change so in those
cases I mean we still do take a look at
pretty much every bug when it comes in
we need to go we assign them we do do
initial triage so yes even though we do
look at the start issues first we do
look at all the bugs so I'm not sure
that we really need to add another level
of trajan triage on there since we're
already doing another level internally
but that being said I'll certainly go
ahead and pass this along to the rest of
the team and see if management likes
that idea and you know it's possible to
go somewhere we'll see so feature
requests noted great all right thanks
for that question and next up we've got
Bruce software design and Luca idli who
asks audio and audio record an audio
tracker hi our critical CPU demanding
classes I experienced distorted and
choppy audio in my voice over IP are
there best practices or patterns of use
to help avoid these problems deep specs
on the internal behavior would help
that's a good question a little bit out
of my league about you yeah I can I can
speak a little bit on that one so we
added low latency audio paths in
jellybean but this is primarily for
playback for recording there's not
really a really good low latency path
yet audio record is the best one
available and it does work but you just
have to be super careful when you use it
the most important thing is to make sure
that you pick your buffer sizes
carefully and keep in mind those buffer
sizes will change on a device by device
basis so there are some methods in you
there you can go and use to try and
figure out what size buffer is
appropriate for the device you're on and
that will help go and avoid some of
those stuttering issues that you're
running into and hopefully it's oh it's
some point in the future we'll go and
add some more API is or improve the
existing
guys it'll help improve latency there as
well but latency shouldn't cause
distortion right latency is more of a
you know you'll have a little bit of lag
yeah choppy audio almost exclusively is
a buffer problem so check your buffer
sizes now that's it
since you are doing a voice over IP app
I will also point out that Android has a
built-in sips tackle ready and you might
want to consider reusing that especially
if you are talking to a sip server which
a lot of voice over IP apps are and you
can just go ahead and tie into that and
then have the OS handle all of your
audio decoding and encoding and send to
the server for you and then all you have
to do is write a UI on top of that so if
that makes sense definitely something to
look at look look into this well okay
great thanks for that do you have
anybody in the Hangout for questions
okay all right so next up we've got
Marcus and Europe asks how do we how to
determine if it did specific audio
recording say mr - WB is supported for
encoding audio codec codec has no
constant for AMR WB and others
background at least Xperia x10 has no
MRI has that doesn't have this format
they need to detect this as or else the
app just crashes in native C alright so
detecting audio formats supported on a
specific device which is I guess it is
device specific yeah well there's I see
Nicole the receipt get codecs methods
it'll go and tell you what codecs are
present and I can't remember if there's
a way to go industry I think there's
even a way distinction AMR wide band and
narrow band so I'm pretty sure that
would work there as well so if you get
constant forward you know that you know
there's there's just a generic constant
for AMR fiber correctly oh it's a more
okay the the specific brand of AMR yeah
well yeah the flavor of AMR yes right
okay yeah I'm not sure why are you
dissociating the two different types of
AMR I'm sure there's a way to go and
distinguish you lifting them if you post
a stack overflow question go ahead and
look into that a little bit more but in
general I mean that you know the correct
approach is to go and call get codex and
check which codex are present and that
at least gets you as far as AMR and
we'll try and find some information
about how to entertain the two different
flavours of AMR for you alright thanks
for that question let's see what else
we've got here Marcus also asks will
there be support for streaming a a
capable container format capable
container font in media recorder like
MPEG TS let's see in the future so a
little container format I'm not sure
what he's asking there
yeah I'm not familiar with MPEG PS
myself this is probably a good question
for our guests when he finally arrives
so let's go let's come back to this one
in a bit okay let's move up here alright
Alex asks I would love to see more
working code samples in the
documentation yes you and many other
people actually more specifically if we
take a good look at the code that was
presented at Google 2012 we can see that
it was had a lot of mistakes and all of
them were copy pasted to the developer
documentation I'm not sure that that's
actually true it may seem like the stuff
that you're working on was copy pasted
from the developers documentation we do
use our documentation extensively to
build our samples and code samples and
unfortunately when we write them
sometimes we make mistakes so definitely
appreciate the the feedback on that but
more helpful would be pointing out some
of those issues certainly you can go to
be Android calm and file some bugs on
that one we definitely look at that for
documentation errors
coding errors and all that stuff so
appreciate the feedback yeah and if
you're feeling a bit more adventurous
too I'll point out you actually can go
and modify all the docs yourself we
don't normally point it out too heavily
because our documentation system could
be a little nicer but if you look in the
source tree under framework space Docs
HTML everything in there is in there
with the dot JD extension and you can
make a change or also Java Docs as well
for the API reference and if you send us
a patch in Garrett especially for you
know anything that's an error we
definitely you know would love to have a
patch to go and fix that but that said
that shouldn't stop you from filing a
bug right we'd much rather have a bug
than nothing at all so either way let us
know if you do discover an error and you
with an ass by a patch or us fixing it
for you we want to go and get that
documentation straightened out yeah so
definitely do file a bug if you're
feeling more adventurous like it's
Trevor said you can go ahead and
actually make it change and file a patch
and we'll take a look at that but you
know please do tell us about the stuff
that is missing or incorrect we're
always working on improvements to the
documentation so you know we do
appreciate that feedback and we
definitely take a look at that when
folks file bugs so please give us more
feedback we appreciate it all right
let's move on to Markus is very popular
with the questions today again from
European kin of new video recordings
start exactly where our previous one
ends I want to say not likely because
just you're gonna have to stop the video
recording start the video recording and
in between that time yeah some number of
milliseconds will pass while you're
performing operations I think the best
option would be to go and have a single
continuous recording and then trim it up
afterwards alternatively recording to
some in-memory store and then just go in
to splice it in memory I think if you're
just going and writing out to a file and
you're trying to switch files there's
gonna be overhead there and it's not
going to start and stop exactly where
you left off on top of that I think when
you stop recording the videos and it
closed the camera connection as well
which is going to add additional lag
when the camera needs to be
reinitialized yeah probably you want to
do a different
approach there maybe you're putting
bookmarks or noting particular tags in
the file just for example a time stamp
that says alright there's the beginning
the end of one clip in the beginning of
a new one rather than like starting and
stopping the video recording as Trevor
says that's going to have that
start/stop problem has a lot of lag to
it and there's some overhead that you're
going to incur as soon as you stop and
start something alright so another good
question for Marcus let's see if we've
been it's some other folks to talk about
here let's see anon says as anonymous I
suppose I imagine yeah yes and on our
favourite contributor says shortcuts
were retcons know what that verb means
it retroactively will be added to I
think continuity but basically is it's
changing the past
we're okay so we're added into widgets
in 4.0 was an intentional that they
aren't part of the new jellybean widget
design guidelines are we phasing them
out discouraging their use since they
don't get mentioned in the new dev site
either so yeah the shortcuts are
definitely something that we're not
heavily promoting right now and in favor
of widgets so I mean I'd say there is
definitely a reason why they're not
mentioned in our in the new design
guidelines as well as not featured as
prominently in the API documentation as
well your so yeah we pretty much in all
pieces we're recommending you go with a
widget where you'd previously used a
shortcut alright thanks for that one
mark is our very popular poster today
again asks why does the camera need to
be visible on the screen to be recorded
I wasn't aware that that's actually
requirement although I know that for the
camera anyway that's usually the
behavior that we thing and that's yeah
it's probably one of two things either
age was a conscious decision by the
media team to make sure that the user
knows something is being recorded or
alternatively was just an oversight in
our design and hasn't been addressed yet
without having somebody in the room who
actually wrote the camera API I can't
tell you for sure but either one sounds
possible to me so sorry I don't have an
authority on sir for you there yeah my
having talked to a few of the guys on
the guys who work on the camera team I'm
guessing that that was a design choice
initially since we do want folks to be
able to see what they're actually
recording as they're looking as they're
got the camera on I have seen apps at
least one app that I've used myself for
doing something like a camera
surveillance that you can't turn off the
thing although I believe what's going on
is that the video preview is just not
being shown on screen it's actually
still playing in the background so
believe that's a design issue but again
since we don't have the media team with
us and James to ask that question we're
speculating a little bit there all right
hey guys I've actually got a question
from someone on the Hangout I'm gonna
put them on for you right now
all right yes please oh go ahead he
actually has no videos okay yeah yeah
yeah hi everybody hi honey I had the
question about encoding capabilities
with the new media API and I tried it
already and the decoder stuff works
great so I put videos to the
and project and it's decoded visual
problems and it's rendered in the
surface but when I tried to create
encoder it tells me that some exception
an array C in the native code in the
open
max I guess and the error code is 38 and
it says as some parameters are not
specified and that's it I I just simply
come create and further so probably I'm
doing something wrong but there is
nothing about it in documentation and
I'm just this is a problem here so I can
decode video but I cannot control so
this is main problem yeah I say that the
first step to debugging that to be to
try and figure out what a code 38 error
is I know there are a number of numeric
errors like that can happen when you
work with the mediate media api's and as
much as I hate time people look at the
source it is actually the best way to
figure out what's causing that so if you
take a look in the invert source code
and search for that error you can
actually find out what the condition is
that causes it and that'll tell you
where to go and look my guess is
probably something to do with your
encoding settings possibly you know
maybe some unsupported codec on that
device something like that
yeah our documentation probably should
be a bit better there so I apologize for
that
but yeah that's usually where you wind
up doing when I run into those have you
tried this on multiple devices or the
same error or just on one specific yes
multiple devices and the same error and
I tried to create it with different
codecs from my which were available in
the system and the 3-3 GP or AVC impact
for so the same error and nothing else
so and I also supplied different sets of
parameters or product and it did not
help either
so okay then I will take a look into and
I'm decay with
the open maxium and probably there is a
some description of it yeah and then you
can put a post something on Stack
Overflow so we can get a little bit more
detail on that having worked with you
know some of the media stuff myself I
know it's very finicky you run into some
issues myself not even using the more
the more recent API so if you can give
us a little bit more detail on that we
can hopefully follow up and talk to the
media team and see what's going on there
their markets probably there might be
just a bit you're not flipping that
isn't obvious to to you or us so so we
can follow up with you on that one too
mm-hmm and I have also one question I
was trying to create some filters for
the camera and I looked into the source
code and as you know for sure we have
several possible filters for the camera
and they depends on the manufacturer and
so different devices have different sets
of the filters that we can apply to the
camera and I was browsing the source
code and actually I did not find any
implementation of the filters so I could
find the constants same kind of sepia or
like invite etcetera etc but I could not
find the implementation of this filter
filters itself in the native code
anywhere so can you but I think we
missed the end of your question there
well if you happen to get back on or if
you just won't leave a comment on the
the Google+ post as well would work too
so that way we can actually note your
question was there yeah sadly we've
missed the very end and so we're not
sure what you're actually trying to ask
so it sounded to me like what he was
finding is that the the filters so the
different camera filters that you can
apply to the camera so like sepia is one
of them I think there's like poster eyes
and some other things that are kind of
like standard image filters there that
there was an actually source code for
that when I was looking at the one who's
looking at the platform my guess is that
that's as expected that the camera
operations and the different filters are
actually implemented by the
manufacturers that that source code that
sets the custom source code didn't
develop by the the folks who actually
built the camera and put the device
together so probably what you're looking
at is having to do if you're I think the
goal was I'm guessing that the goal was
to make his own filters and try to do
that stuff I know that that's possible
because I've seen a couple different
camera apps that do something like that
though being able to take the
manufacturer source code I don't think
they're gonna be lookin to do that right
now so anyway if we can
if you manage to get back on and ask us
because I'm not sure we got actual what
your question was there but I think
we've fixed the Santa she could you try
speaking again from the Hangout and see
your honor again not hearing it yeah
he's it's fine he said okay thanks okay
so I think we gotta say it's question
then yeah okay thanks for the question
appreciate it any more hanging out
questions not at the moment
okay please feel free to jump on and
talk to us in person it would be glad to
talk to you about it let's see do I have
any more questions from someone who is
not Marcus we've got Frank
suppose our EO Pissarro asks I wanted to
choose a photo from the gallery no
problems if a local image is chosen
however a Picasa photo returns a URI
instead of a location is there an
approved way of handling this can I
modify my intent to only show local
images so I would recommend against
doing that because photos coming from
Picasa are still photos that belong to
the user and is something you might want
to pick and you should still have them
so the answer here is just make sure
that you know whatever URL you get back
with a lot of content URL or file URL or
an HTTP URL treat it as a URL and decode
it properly right if it's nation URL you
should go and fetch the image from the
network and display it and yeah that's
the the proper way to do it so I don't
think there's a really good way to go
and say you don't want those images from
other sources because they are there for
a reason it is something user can select
right yeah so I think the answer is yeah
you probably could do that but we prefer
that you make your app more awesome and
actually handle all the images at the
user has access to because that will
give them all the choices that they want
so a good question
it'll take a little slightly different
tack on that one all right so moving on
to our next question
Julius from Auckland says can you
recommend a way to implement gapless
music playback DJ loading to files at
not experiencing a gap so like doing
crossfade basically an api 7 plus so api
7 and up i'm currently thinking of using
an input stream or something hmm
interesting question yeah I'm sure it's
got to be a way to do it
what's the name of that API shoot I'm
suddenly drawing a blank on the API you
that you'd want to use for that I don't
know it either
yeah I think we're gonna have to get
back to you on that one
again if you can post a question on
Stack Overflow we'll go ahead and try
and get you some more information after
the show unless Fredo you happen to know
the answer off the top of your head
now I'm getting a no from offset head
Jake no that's a no Willie get back to
James on that one yeah if you've stumped
Fredo you know you've asked a tough
question another question from anon Dave
who's Dave we're not thinking for you
Dave Dave Burke who was supposed to join
us today but unfortunately had a
conflict so we do have other member of
the media team who are supposed to join
us at some point during the show so this
is another question that we can do and
revisit once we have somebody here there
you go all right so Dave who is not here
what would you say are the most exciting
capabilities use cases for enabled by
the new corporate one Audio API is that
weren't possible beforehand I think this
is a question for the media team so
let's revisit this one I think unless
you know unless you know well I mean I
think the most important features that I
added with 4.1 were the low latency
api's so being able to play the audio
very quickly versus having a little bit
of a delay actually in the previous
versions I think it's like probably the
most important improvement that they put
in there there are some other ones as
well but it's again I feel like I'm not
not the right question for me so there's
a piece of an answer there anyway
there's some other interesting stuff if
you look at the developer site and look
at their release notes for 4.1 we do
have a section on the MIDI API s and
some of the changes there so it's a way
to go get some of that information and
if Dave shows up we'll definitely come
back and ask the ask that question BAM
oh well for that matter anyone from your
team or anyone for the media team yes
media team please come and see us
let's see moving on we've got another
question I have a question from mark in
Virginia
can you speak to using the DRM API in
conjunction with the media api's to
first apply DRM to a video and then
verify it and play it back this might be
too complex a topic for the Hangout yeah
you might be correct in that but maybe a
blog post our pointers to example code
yeah so the DRM API is really designed
more for DRM schemes that are included
as part of the device so if you're
writing your own DRM scheme from scratch
honestly I don't think you're gonna find
the built in DRM API is very useful for
that that's just been my experience it's
possible there's a better way to the use
of them that I've never heard about but
usually when you do use that the DRM
provider has to be part of the system
image yeah yeah so I think that's all
we've got to say about that one for
today another question for Dave who's
not here from anonymous Dave what kind
of hardware disqualifies a four point
one Plus device from being able to
support the new audio effects api's ie
would it be possible to preemptively
predict whether a device supports it or
not just from it's just figure out from
its hardware specs essentially
hmm another good question support the
new audio fix yeah is it sort of sounds
like there's a hardware limitation based
on what's been implemented by the
manufacturer in terms of audio alright
somehow I doubt it's gonna be just a
matter of looking at the hardware specs
I imagine there's some driver issues
involved as well too right so I'm not
sure that just looking at the hardware
specs would give you enough information
to determine whether or not audio
effects are possible or not all right
let's see movie on our bro and software
design and Lucca Italy ASCII and Android
API greater than or equal of 12 and this
is a very complex question here okay
Android net RTP audio group and audio
stream are there examples of tutorial of
this of use of this API is documentation
is essential for such a rich api's
real-time yes so yeah RTP stream
basically streaming as far as I'm aware
of no not yet but that's some good some
feedback to take back to the team I know
they wanted to do some more coverage on
this but I don't think there's no
there's nothing out there right now and
that's probably why he's asking the
question there are some Stack Overflow
questions asking a very similar thing
where you just asked and there is some
user provided sample code it's not the
same as something provided officially so
again it's very good feedback and
something will take back to the rest of
the team but for now I'd go and look at
that if you need an example of how to
use our TP
Simmons on the G+ strict Sherpa is it
possible to use me with audio record to
do real-time compression from the mic so
media codec with audio record to do
real-time compression that's a good
question actually I've never tried it
myself
I want to say it's probably possible at
some level given that whenever you
select the codec there's a certain
amount of compression and processing
that's done at that time anyway so
shorter answer is is probably but I
think we need somebody from the media
from the media team here to actually go
and explain a little bit more about
what's involved in doing that since I
don't think anyone here has actually
ever tried it
yes so good question but unfortunately
we're a little out of our depth on that
one
let's see any other questions from the
Hangout they get a head shake there okay
Julie is from Auckland asks is there a
way to calculate the duration of the
audio produced by a text-to-speech
request currently we have to push audio
to a file to get the duration from the
file we wish to supply the user with a
visual indicator of the length in
advance it is and somehow my gut feeling
is probably not because usually when
you're using the text-to-speech API as
you're doing it to play it back
immediately
and for example driving directions and
Google Maps right you just have a voice
that's reading off directions to you and
it's very much a you know just take my
text and read it and I want to be done
so it I don't think there's much in the
way of the API therefore things like
getting the link things like that
so I suspect what you're doing is
probably the best way to do it i I'm
can't say that authority but my gut
feeling is that's probably the best way
to do it right now alright thanks for
that question Julius and
we've got another one from I hear Jeff
Jeff from Seattle Washington is it
possible to use the mediacodec class in
conjunction with audio record that
sounds like the same question it does
and yeah I suspect it is but we need to
use me for the team to confirm that okay
you guys know James from the media
framework team is currently hardly
trying to grab a last minute lunch and
hopefully the last 15 minutes these
media guys in their lunches goes open he
can get a sandwich after the show all
right moving along here we've got from
Thomas secure and our Vika Sweden
alright somebody from Sweden excellent
we've been when using the MHL adapter to
get HDMI out some apps like YouTube
showed different views of the device
display an HDMI output how is that done
I could not find any API for this is it
Hardware dependent okay I actually do
know that for this one all right looks
like it came up a couple weeks ago so
the answer is there is support in the
system specifically for video services
and HDMI output so it is a manufacturer
specific setting so not all Android
devices are guaranteed to do this even
if they're running the latest version
but at least on the versions that
Google's produced whenever you have a
video surface on the screen the contents
of that video service will be used as
the HDMI output so it's not an API
that's available for developers organs
you just use the system media API and if
you do that whenever you have video
on-screen it should be mirrored over
HDMI all right so it's specifically
keyed to the video service that's
correct
got it but only on certain devices only
on certain devices other devices can
handle it differently they might choose
to you know provide their own private
API is they could go and just use
mirroring all the time yeah it really
does depend on what the manufacturer
wants further or HDMI output
all right great good question Thank You
Thomas next we have Marcus from Europe
it has been very productive today with
his questions
when will the camera service ever auto
unlock or how will unlock when it can't
I will unlock it when it crash it
crashes the app crash still holds the
lock and blocks all other apps from
using the camera until the phone reboots
yes this is a problem so for those of
you who have done some development and
camera with the with the camera as I
have if you write bad code and you have
errors in your code and your camera
crashes without you actually unlocking
the camera app our access to the camera
yes you will walk out not only yourself
but anybody else and any other apps that
actually try to use the camera because
that lock has not been undone barely
released probably the first answer is
make sure your app doesn't crash in the
middle of using the camera you know test
your code thoroughly to make sure that
this doesn't happen because that is in
fact I think the only way you can really
unlock it if that kind of inherit occurs
I think even if you put in it's probably
a good idea to have in your code and one
of your your on pause or what's the
other the final run destroying to make
sure that to check that you've done a
release of the camera object before your
app actually exits so make sure that
that codes in there in fact you can see
an example of that code when you look at
the developer guide for a camera so make
sure you put that into your code but the
really the only other answer is if your
app is crashing and misbehaving then
yeah you're gonna cause that kind of a
problem and you're gonna upset your
users so make sure you test it's that
kind of an app thoroughly and make sure
that that doesn't happen
any other thoughts I think that
explained it pretty thoroughly I don't
have anything else to add to that okay
all right good question thank you sir
Joe I've actually got Alexander back on
the Hangout and he wants to chime back
in about cameras and whatnot so I want
to put him on from the Hangout
great go ahead Alexander Alex go ahead
you're on hi guys again so sorry Alex
we're getting a little oh can you hear
me
hi I'm getting it from Ella's oh there
you go we can hear you good so as you
know if we want to process the video as
a picture from the camera in leaf we
have a really small
FPS coming back from camera and this is
really frustrating because if we want to
make some possession some filters etc
etc who would really like to have a kind
of real-time stream and do you guys plan
to provide us with such I don't know a
civilities SDK too but says the stuff in
native code just to gain more affairs
and Tetra etcetera so yeah so that's
that's a good question there's actually
three different ways that I know of that
you can get the different images coming
through the camera device whatever that
camera hardware is we only and the first
one is free is pretty obvious but
there's a two additional ones that I at
least I know of that you can use to to
get the frame the different frames from
the camera at an escalating levels of
the complexity actually if you would
actually and actually I'd have to go
back and look at my nose to kind of
explain some of this unless James who's
come and joined us recently can to talk
about this stuff
James we wanted to talk about the
different ways that you could get the
different frames from the camera I know
there's a couple of different approaches
that you can take well this is James I
think that in order to get the frames
are from camera there are a couple of
ways one is you can use the preview
callback
basically the Java API we published
mandate the two colors format must be
supported one is why we 12
the other one is MB 21 so if you use a
preview frame callback you can you know
have access to the frame data that way I
think
that's currently if you use a Java API
that's probably the only way and native
layer basically we have the recording
for him callback also you can you can
gain access to the camera how recording
frames also does this answer your
question can I get to this callback so
I'm not sure that it's documented so I
use their way I can find it and put the
listener on it yeah there's no steps
involved basically you just need to a
set a register a callback the callback
is a preview frame callback on the
camera java class and then the
application shooter receive callbacks
from the camera but it's the if s is
really low there so it's maximum 10 15
FPS frames per seconds I can get from
there and if I need to amend the data
from it it becomes even slower so I'm
really eager to find the way to make it
fast
so I understand that we can use native
stuff and for example if we look to the
OpenCV project as a work with camera and
it's written purely and see as I
understand so I really hope you guys
someday decide to open such capabilities
for us developers so we could use at
least certainly fps for the camera yes
III think you are right when you use
this preview Copic the frame rate is is
low the reason like the frame rate is
low is because the the frame data has to
be copied out so there is a mem copy
involved we are working on some like
enhancement to the whole camera
framework I cannot say for sure like
when new API will be available but
definitely we are working on something
to improve in this regard for future API
release but not anytime soon okay thank
you sure great and if you could post a
question on this for on Stack Overflow
and I'll see if I can get you a little
bit more information I believe there's
some other way other approaches that you
can take with this but I can't talk
about them off the top of my head so
just post a question on Stack Overflow
and posted in the Hangout and I'll go
follow up with you there now that we've
actually got James in the room do you
think you may be able to introduce
yourself until the view is a little bit
about who you are and what you do in the
Android team okay okay my name is Jim
stone I'm the tech lead for Android
media team basically like our team is
dealing with how the
a media framework and camera framework
and we also have a separate team for
like a audio framework so pretty much
like a multimedia stuff everything
thanks
great yes a couple of questions that we
had queued up from earlier on for James
so while you guys look those up I've got
one from Tom on the live stream he'd
like to apply arbitrary effects to the
system media stream so things like
creating the equalizer etc he can do
this too he writes his own media player
but he'd really like to be able to just
create the effects and let users use
whatever media player they would usually
use to apply this effect is that
possible the effect you want to apply it
depends on how you get the frame in the
first place I if you want to apply
effects to the decoder output that's
possible we just published a new media
API called the media codec dot Java cast
which allows you to gain access to the
decoder output directly and then you can
do image processing on the decoder
output I think that what this really
depends on the context like how you want
to apply the effects so that's one way
thank you
okay great don't put down that
microphone just yet we've still got a
few more questions
scaling back to earlier question here
how do I determine if there's a specific
audio encoding so am our that's WB
rather than some of the other flavors of
AMR NB a r NB and some of the other ones
so audio codec get codec has no constant
for mr WWV and others for example the
Xperia x10 doesn't have doesn't support
it and I want to be able to detect that
so let and if I try to do it it actually
crashes the native C so this question is
how to detect if those formats are
supported that's a great question
really like in a timely fashion like a
in jellybean we release this set when
you a Java guys one of the API allows
you to find out all the codecs available
on a specific device Android device the
class name is a code media codec list
and media codec lists the info so using
these two classes you can basically walk
through all the media codecs available
on a device and you can find out the
capabilities of each codec such as you
know whether this is a narrow band or a
wide band whether this is like a AAC or
any other video codecs for video codecs
you can find out whether like what kind
of a profiles and the levels of support
for that specific video codec so it is a
it is a new
set of an API we just published and it
is very useful I think to you guys
great thanks for that
let's see scrolling back to our some
previous questions we had is it possible
to use the mediacodec classic in
conjunction with audio record right no
we had a a second question which is very
similar is it is it possible to do
compression when you're using media
record I think media product is designed
in a way that is generic so it's
basically the same set of API message
can be up applicable to both encoder and
decoder so you should be able to use for
encoding purpose also okay great let's
see Marcus from your asked us
will there be support for any streaming
capable container format and media
recorder like mpeg-dash TS in the future
actually we can't answer that question
because that's a future looking question
right yeah that would be probably
deafness care I mean less of something
you can share but generally speaking
questions like this we have to skip so
alright movie on that one might be good
runner even if the camera right camera
question why does the camera need a
visible surface on the screen to be
recorded is that actually true actually
is the next question yeah this is a I
think this is a tool current before the
camera dot Java past we have the this is
due to a legacy reason because like in
the past be some of the vendor has to
run the preview before they can supply
the video frames or preview frames so
that's why we have to have
available okay so there's a little bit
of a legacy problem yeah okay
and so now we're actually back to new
questions alright then we're back to our
regular questions excellent
I've actually got a question from
hangout it's gonna be live in a video
this time stuff oh yeah we actual live
person fantastic yeah well question the
SDK manager and others recent update
20.3 and I saw a new option there says
enable preview tools so I tried checking
that and I'm not seeing the preview for
tools 21 you know if that's a new button
they haven't put on they haven't fixed
yet or twenty ones not available for
previous 2k manager
I don't believe 21 is available yet so
it was nice to me that they had that
they have the the preview button there
so okay yeah I suspect probably some
time soon but it is xx preview is
announced on the night should be edit
out it's on the download page very
obscurely it's not listed on the main
downloads we go to the bottom it's a sub
page ATT 21 free bu requires the r21
preview
yeah just to check did you try
refreshing this DK manager because I
know it does do some caching I did I
turned off cache a while ago because it
I had problems the caching and I think
the newest update the 24 points were you
supposed to fix a caching problem I did
I did a clear clear download cache and
every turned it off off and on and right
so what a clue take me I'd have to check
the version numbers but is it possible
that the reason you can't see the
preview is because the final version got
released a couple of days ago so I
actually I think I get it well this is
the the preview of our 21 wasn't
released yet this is I only have 20
point 0.3 route of the of the SDK
manager tool in general so the tools
guys I work with them actually quite a
bit okay
the preview steps doesn't actually get
released through the SDK manager you
have to go tools.android.com right as I
got from it I just saw the new to that
new preview button it says you know to
allow you get tools through that or the
previews yeah I think I believe they're
working on a new feature to actually let
you get the preview through the SDK
manager but I
that's quite working yet and has really
been busy working on the the 2003
release because of that caching problem
that you noticed right out so I'm very
busy with that and so I'm not surprised
that there's no 21 preview out at the
moment so just stay tuned I know those
guys are working on quite a few things
so yeah it's stay tuned on the tool site
yeah that's it and then you'll see it in
the SDK manager on the tool specialists
are 19 is the latest release well behind
what's actually annotation now so pass
it along they looked at there you're
trying to do too many things at once
they're probably ok thanks sure thanks
for the question all right let's see
we've got a few more minutes to do
questions and Nick from Chicago asks is
it possible to play audio backward wow
it's very tempting question oh geez you
want to tackle that one do we have an
idea of that one or we're gonna have to
punt on this partially so you can play
audio backwards of you using the audio
record and audio play mechanisms I don't
think you can do it using the media
recorder but if using the raw wav files
then you can just flip the bits and play
everything in reverse order
alright Ritter says it is possible so I
believe him but only with which
particularly the audio recording audio
playback so that's for raw WAV audio
effectively so you can't just play an
arbitrary song it needs to effectively
be something you have recorded with no
encoding got it was so unencoded audio
probably the encoded audio you're gonna
be out of luck you have to decode it
first probably alright great nice
question there very interesting our
redneck Republican from Texas is joining
us and says I see low-level media API is
a good opportunity to save power
on OS devices do we have any tips to
make good use of the API to do so also
is there a way to offload some
pertaining work to the GPU when we using
a low-level the low media API a good
question I see James shaking his head oh
yeah I've answered that one so for this
a low-level media API I think one one of
the interesting point is like how to
find out was the battery consumption
when you use is the low-level media API
versus the high-level API we used to
have one if you want to do like some
filtering applied to this decoder output
definitely you can leverage the GPU to
do some image processing so that you can
save some power in addition to that you
can for example if you are writing a
streaming application you can do smart
things like - better buffering in terms
of using the default buffering mechanism
from the media framework so that you can
for example turn off the radio for
better radio usage and so that you can
save some time because for streaming
application see if you try to get as
much as theta as much as possible at
once and then shut down the radio and
then after
sometimes your turn on radio and then do
it again
this can save power so this is like
advantage using a low level media ap is
on the other hand this low level media
API because it introduced some like
traffic between the j'ni layer and the
Java layer so you have some additional
overhead compared to the previous high
level API so it's it's kind of trade-off
if you write a application like you know
a better or smarter way then probably
you can gain in terms of battery
consumption okay great thanks any more
hanging out questions not actually I do
have one from Jonathan I'm gonna put him
on in a second but you get once you go
ahead and answer one from the moderator
page and I'll put Jonathan on next
it sounds great okay so we've got Robin
from George Georgia who asks I have a
live audio feed that I'd like to stream
to Android apps just have web browsers
and iOS apps mmm the multi-platform
audio feed do you have a suggestion for
a common codec that could be used if any
I'm not familiar enough with audio
formats to answer that one anybody else
got a
well for audio streaming you can come
only on Android devices like the
multiple audio codecs are supported like
AC and AMR narrow band wideband those
can be used for streaming applications
yeah I think you know the constraining
factor is not gonna be the desktop
pretty much any audio format you find
you'll be able to play somehow on a
desktop the tricky part is mobile
devices because they have limited
capabilities and they rely on hardware
decoding which means a lot of times you
need to have hardware support so take oh
yeah I don't think anybody in this room
it can really speak as to what codecs
iOS supports but on Android I I think
but yeah like you said AMR NAC both have
pretty wide support if amber correctly
so both of those are a safe bet and then
from there find one that works on iOS
and the desktop won't be a problem
all right you guys all ready for hangout
then I'm gonna go ahead and put you
under than on and this will probably be
our last question I suspect right go
ahead Jonathan hello I need to build an
application that reacts to the user
input by changing the music and for that
I have several music files that I need
to somehow either switch seamlessly from
one to another in a registered manners
of their so generally I needed to trick
the user into believing into not
noticing that I have changed from one
music tracker to another since they
differ in very small details and I was
wondering what was the best way if at
all that could implement that and I
think this is sort of a lead to the
question earlier about how to crossfade
in music as well I know it was that your
question or was that something else that
was not my question but this is a this
was a good group of questions to listen
in on right so James do you have any
feedback on that yeah
I I can provide you a hint you can cut
it out and see whether it works for you
basically we also in jellybean we
publish the API allows you to do gapless
playback for like audio you can try it
out the API should be available in a
media player dock Java costs
tried out let us know your feedback
thank you that's more for gapless though
right so playing one song and
immediately cutting to the other right
yeah is there any way to do a crossfade
or is that not possible crossfade as far
as I know currently no no not possible
okay thank you
great thanks for the question and with
that I think we're out of time and you
want to give it a little bit of a
preview for what we've got on tap next
week indeed so for those of you who are
joining us for the first time we are on
the air every Wednesday at 2:00 p.m.
Pacific time so take a look at actually
I guess our Google+ page is the best
place to find us developers docked
Android or developer.android.com slash
plus I believe it's just plural there's
only one anyway yeah developer intern
accomplished plus you can find links to
each broadcast as well as the moderator
page next week we will have folks from
the Android security team on the hand
including Kenny root who will be able to
answer all of your questions about
Android security so be sure to join us
next week all right and with that I
think that's it thanks for joining us
all right we'll see y'all next week
Oh actually one last thing though thank
you - we should yes thank you - Daniel
Pham our engineer as well as radio Meyer
who's the producer for this show
and once again my name is Trevor Jones
I'm Joe Fernandez yes and a very special
thank you to our guest so yes thank you
James
all right oh I think that's it see you
all next week
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>