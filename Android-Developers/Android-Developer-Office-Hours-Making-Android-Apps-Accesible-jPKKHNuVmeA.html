<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Android Developer Office Hours: Making Android Apps Accesible | Coder Coacher - Coaching Coders</title><meta content="Android Developer Office Hours: Making Android Apps Accesible - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Android Developer Office Hours: Making Android Apps Accesible</b></h2><h5 class="post__date">2012-09-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jPKKHNuVmeA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi and welcome to Android developer
office hours I'm Joe Fernandez from
Android developer relations and this
week we're going to talk about making
Android applications accessible I'm
joined by a guest from our Google
accessibility team we have a TV room on
to my left Casey Burkhardt and Allen
VEVRAA under-the-table who you can't see
is Tilden Ramon's
guide dog who is being very fluffy and
cute but it won't be speaking today
we're gonna do things a little bit
different today because we're focusing
on accessibility we're gonna really just
talk about those issues Casey and Allen
are going to talk about I have some
material to present and at the end we'll
take some more questions on Cait
accessibility and if you don't have
accessibility questions don't worry
about it next week we'll make sure to
cover those things as well so with that
I'll introduce Vermont Thank You Jo
welcome everyone to the session on
Android accessibility
my name is Timmy Raman I lead
accessibility efforts for Android and
Chrome and with me I have two engineers
from my team Casey and Salim to give you
a brief overview slash intro of what we
are talking about today so as developers
when you will step back and look at
Android the platform what does the
Android give you Android basically makes
it easy for you to focus on your
application as opposed to worrying about
different devices different screen sizes
somebody has a keyboard somebody doesn't
have a keyboard you focus on your
Affleck
that's really the core thing that the
Android platform provides for you and so
you can write your application and have
it running on hundreds of millions of
different devices what we from
accessibility do is we broaden this
focus even more so we just talked about
different devices but people are
different to some of your users might be
able to see a little less than others
some of your users might need a slightly
different color scheme some of them
might need larger text some of them may
not see at all and may need spoken
output some of your users may need
specific affordances so accessibility is
then about increasing and significantly
increasing the size of the user base of
your applications and writing
applications that are really cool that
work in a lot of different user
scenarios I myself work on applications
that are relevant to blind users and I
describe it as working for the eyes-free
user context so don't think about the
user not being able to see think about
the user not looking at the screen so
that's the broad thrust of accessibility
and what we've been working on as part
of the Android accessibility effort is
to build the right set of API is into
the platform so that you as a developer
can focus on what you do best and what
you enjoy which is writing your
application they'll give you a brief
overview of how Android accessibility
works we gave a detailed talk at Google
i/o this year and you can watch that
talk in its entirety on YouTube but
essentially Android accessibility is
something we started working on in 2008
and originally shipped as part of donut
in 2009 and we've come a long way since
the typical way of line user interacts
with your application is by navigating
through your app and getting spoken
feedback auditory feedback for the item
that's in focus as of jelly bean we what
else also added Braille support that is
in beta but what happens then is that
the blind user is essentially navigating
your application item at a time control
at a time getting spoken feedback and so
over the years we've introduced better
and better user a user level affordances
for doing this what this all looks like
in jelly bean is that the user navigates
using a combination of metaphors one is
that of touch exploration where the user
can touch different parts of the screen
in here's appropriate feedback for what
you're taught right that's what it gives
you random access to all all parts of
your display random access is great it's
yeah order one complexity if you're a
developer right you can get to anything
with the same level of effort its
problem is it's random so what we also
added in jellybean was for the ability
to what we call linearly navigates
entities which then gives you a more
deterministic access to different
aspects of your app and in practice as
an end user when I use this I use both
so I pull up an app approximately know
that the search button is on the top
right I'll go touch there and if I don't
hear the search button I'll flick left
or right from there and arrive at the
search button and then
how all of this works in the framework
is through three concepts that KC and
Allen will explain to you in a lot more
detail there is a notion called
accessibility focus in the system which
is implemented alongside system focus
with the difference that everything in
the user interface can get accessibility
focus and as accessibility focus moves
our accessibility services like talkback
speak it or brailleback Braille without
on a Braille display so now you have
accessibility focus as I said when you
touch your accessibility focus lands on
that spot but you can also navigate with
gestures and Allen will show you those
during the demos as we go through this
and we call those the accessibility
gestures now via computer scientists so
and all computer scientists - things
were introduced and introducing a level
of interest in direction and so what we
do in the end ROI dpi is that the
accessibility gestures actually invoke
accessibility actions and it's those
actions that actually perform perform
user actions and this actually makes for
a level of flexibility because then in
the you know you can actually build more
innovative user interfaces for people
with motor impairments and things like
that where you can then trigger these
accessibility actions through other
affordances so
the the goal as I said of accessibility
API is to work behind the covers and
just make your applications work and
that's pretty much true if you use
built-in Android user interface controls
and do all the everything right but then
as you step out of that box as you start
becoming inventor as you write custom
controls then you have to give the EPI
and the framework a little bit of help
and it's really those aspects that these
next 3040 minutes would be spent on a
danandcasey will show you a sequence of
demos and show you how these can be
fixed there is a sample app to go with
this and we can point you at the source
code to this later during the talk so
Allen and Casey take it away
thanks for one so as Raman mentioned
there's accessibility api's on Android
we've had those in Sedona an Ice Cream
Sandwich we introduced the new concept
that your feature of explored by touch
which allows the blind user to touch the
screen and have the content that's being
touched spoken to them so the way that
this works is when the user actually
touches it control the android framework
takes that control mumbles in a nice
package sends it through the
accessibility API to any accessibility
services that might be listen listening
an accessibility service is want us to
talk back that's software that Allen and
I right we basically intercept these
accessibility events that the framework
sends take the data out of them explore
the view hierarchy of an application and
provide spoken and other auditory and
haptic feedback to the blind user to
make the application and then it mice
accessible Allen actually is going to
turn the device on now and show you
talk that looks like the first time
booting up here alright so one of the
really great things about the
accessibility service is that as a
developer you don't have to worry that
much about it
so as Raman mentioned if you use
standard widgets things just work so
we're gonna turn on talkback first so
we're going to elapse settings and down
here at the bottom we have accessibility
and one of the services is talkback so
we'll turn that on there's a switch up
at the top that you can't see
so this dialog pops up explaining that
talkback sees basically everything that
is shown to the user so all of the text
that's on the screen talkback has access
to so we'll just click OK it's OK that
talkback can interact with things the
way that a user would so as as talkback
is turned on you see certain items on
the screen receive a yellow pilot in
jellybean
this represents the accessibility focus
so as Robin mentioned accessibility
focus works just like system focus
except any item whether it's system
focusable or not can receive it so that
the accessibility service can
interrogate it and find morning to find
out more information about it
so as Allen moves his finger around the
screen you'll see the different recent
accessibility focus talkback versus
events regarding the changing focus
speaks to the user to let them know that
they've touched in jellybean
there's also the concept of navigation
in a linear way so Allen can use a
gesture from swiping left to right or
top to bottom to move focus through the
user interface so we'll move out to the
launch where it's a little bit more
interesting so touch home DoubleTap to
activate it and now I can just swipe
left and right to move through items on
the home screen so I'll swipe right a
couple times
so down here at the bottom we have all
apps and then one app that we're going
to be using for demos later on is so in
addition to exploring by touch you can
use gestures to navigate linearly
through the UI gentlemen we've also
added gestures associated with that
accessibility actions so for example how
one can do a two part swipe up and then
right and that will perform the system
action of pulling down the notification
shade so I'll just go right and then
swipe down and left and that will
dismiss the notification as if he
pressed the back button so I'll do down
and left to do a back action so we have
a couple other system gestures as well
so and what's also worth mentioning is
from Ice Cream Sandwich and on
accessibility services when they receive
one of these events can interrogate the
view hierarchy so talkback for example
can deep dive into the views your
application presents and get get more
information about them well such as
whether a button is clickable a view is
checkable and so forth so this is used
throughout talkback
so now we're actually going to cover the
top three problems that we see most
often in third-party developer
applications we have a sample app which
we're going to use to sort of get into
these issues and illustrate them for you
and I'll double tap to launch that okay
and so Casey's going to take us through
the inaccessible content descriptions
app so this is a very common mistake
that we see actually Casey we're getting
a little Russell from your mic could you
just make sure that you can run you can
run it up the outside of your shirt sure
all right so I'll just take us through
the inaccessible version of the content
description all right so one of the
first things that we see is this edit
box and there's an icon in the top left
of the screen here that has a little
search icon and since I only hear edit
box I don't know that the meaning of
this edit box is let's say a search term
so swiping through the rest of the
interface that's pretty clear now image
76 isn't the best description for this
if you can see it there's a little map
here so as a sighted user I can guess
okay this probably has something to do
with location but because there's no
text attached to it
through the accessibility service I
don't know what's going on so I'll
continue straight through and we have
the same unlabeled images here so let's
take a step back and look at some of the
ways that we can fix this say well
back out of the keyboard go back out of
this particular demo and open up the
fixed version so you could see English
in this edit box later this edit text
element that we have now there's
actually hit text and since talkback and
other accessibility services can get
information about the view hierarchy it
can pull out information from the
accessibility event and from your view
to learn what it in text is so now when
I navigate to it I hear the hit text
which gives me more context into what
I'm actually doing is a user and as I
move through the user interface I get
the Go button and now we've added
content descriptions to these image
buttons so when I navigate to them local
deals social deals and real time deals
rather than hearing image 91 image 76 so
as a developer this is one of the
easiest things that you can fix you
simply go into your layout XML you go to
each item so you go to your image view
or your image button and you add an
Android colon content description and if
you have things that you specifically
don't want to have a Content description
you'll notice that you still get lint
errors if you put no description so
you'll get these little yellow schools
in your layout XML so for something like
there's a little star here that we're
purely using it's decoration there's no
reason that a user needs to know that
it's a star we simply put content
description equals at no so that at null
lets it know that you've thought about
whether or not your image needs a
content description and you've decided
that because it's purely decorative it's
okay to be skipped
for things that have dynamic content
descriptions you can also call view dot
set content description so if the
meaning of is going to change sometimes
during the execution of the application
I'll simply call whatever variable I
have to store that in dot set content
description and pass it the new
explanation of what that button does
we'd also like to mention that we prefer
that you would not override get content
description on the view class
avoid taking that shortcut because we do
some caching when set content
description is called and it helps us
out and make sure that your users can
get the correct description of that
button when they need to so always use
set content description if you're
setting your content description
dynamically all right so let's back out
of this and one other thing to take note
here is that each of these buttons is
totally accessible on Ice Cream Sandwich
a lot of developers are going to be
developing for let's say Gingerbread or
below and on these devices accessibility
relies on use of a trackball or
directional pad on a hardware keyboard
so each of these buttons is also set to
be Android focusable equals true which
means if a user has a keyboard and they
start pressing down or right they'll
move from this icon to this icon to this
icon buttons and image buttons are going
to have this set by default but if you
use an image view you'll have to
explicitly say this image view should be
able to receive keyboard focus all right
so let's move on to one of the next
things which is grouping and ordering of
items so as we move through this user
interface we see that we have some
header text and we have a table with
some data in it let's jump right into
the table you see as I as I navigate
through this UI when I touch the table
I'm not I'm not actually getting any
kind of feedback I have to go over and
touch the actual item and as I swipe
left and right through the UI I'm
getting getting very granular
information also if I touch the table as
a whole it's gonna read all of this
content which is hard to follow what we
need to improve here is the way that the
views are grouped so that the user can
access the information
an individual way so they don't have to
get this large burst of text so what
talkback sees when you open up this
application is a bunch of text so these
are all all of these items here are
actually just thrown into a relative
layout so date is below from statuses
below date just walk back this just
looks like a big bag of text views so
what it reads is a big bag of text views
in order on of the screen left to right
top to bottom which is nice if you want
to spend 12 minutes listening to the
screen but we go into the fixed version
we've now put all of these text views
that are in a relative layout in their
own individual groupings in a hierarchal
wet heart hierarchical way that makes
sense so now when I touch explore that's
exactly what I want to hear one row in
the table $23.45 USD so the user can
explore each one of these rows one by
one without having to hear the full text
and in entire tool in our layout what
we've actually done is provide a little
bit more context so amount here is
actually inside of linear a relative
layout inside of a linear layout that
contains each of these rows and we've
also for keyboard accessibility made
this row focusable so that lets talk
back know that the things inside of that
layout should be grouped together one
thing you'll also notice is when I go to
this top bar right here which starts out
with payment processed in the top left
and moves into a description of this
deal at the bottom it actually reads the
title the description and then it reads
the notes payment processed and the date
the reason that we've done this is
because visually this information at the
top local social real-time deals this
title is larger it's more important it's
more immediate for the user this
description is also a more immediate if
the user wants to hear more about it
they just stay on it for a little longer
they hear what the status and the data
and the way that this actually works in
code is that we've sent the content
description of this entire group so
we've taken this this relative layout
and done set content description to be
the text of each of these items
concatenated in the order that we want
them read so when I tap on it so you
hear those in the order that you really
want to hear them for efficiency our
last demo here deals with using custom
views so what we have here is a part of
an application that is just directly
drawn we've basically implemented the
ondraw method we have several objects
and we call each of those objects on
draw within the context of the the
larger canvas we draw it directly to the
screen when talkback is on because
there's no textual content actually
associated with this view it's
completely dead there's no touch
exploration there's no feedback nothing
the application action bar will speak
because it's a standard Android action
bar but nothing else will the way we
fixed this we have api's on jellybean
that allow for developers to use custom
drawn views and make them accessible we
also have a helper class available touch
exploration helper which is available on
the ice cream web site will point you to
the source for that shortly and now that
I've implemented this node provider this
new jellybean API that allows us to
define regions and custom views for
things I can touch explore the content
I can also double tap to make things
happen and I can even do something like
long pressing so this is basically the
mechanism and jellybean that allows
developers to make their entirely custom
drawing views accessible to the standard
jellybean accessibility services so if
you're rendering something in OpenGL
which is great and pretty and fast you
can also make it totally accessible and
so this requires a little bit more work
we've made this node provider helper
class to make it a little bit easier but
you can provide an entire view hierarchy
virtually that talkback and a user of
accessibility will be able to explore so
actually I'd like to swipe through this
too just to show when you implement the
node provider you sort of magically get
a lot of extra features so I can swipe
left and right through this and that
didn't take any extra effort just adding
those those virtual nodes
let's talk back manage swiping left and
right through the hierarchy so one thing
that we didn't mention earlier I'd like
to back out for a real quick so you'll
notice that on this tablet everything is
really small and for somebody with low
vision they might find that things in
your app are a little difficult to see
so one way to get around that and I'll
pop in to accessibility settings is to
turn on a feature called large text mode
so this is going to do exactly what you
expect it to so for anybody on the
Hangout or for anybody watching in
and maybe low resolution you can
hopefully read the text now it's a lot
bigger and one really easy mistake to
make is in your application when you're
setting your text sizes to use density
independent pixels dips instead of
scaled pixels so when you set text size
if you use scaled pixels it respects the
system's desired text size one thing
that this can be a problem for is if you
don't test your app with slightly larger
text or slightly longer strings you may
find that strings extend off the edge of
the screen or wrap in ways that you
don't expect if you're doing
internationalization of your apps it's
important to make sure that you're
testing for this anyway so if you have a
string that shows up as a certain size
in German it may end up being longer and
with large fonts on it's going to be
longer as well as a little bit taller so
it's important to test your app with
that to make sure it works but generally
if you use scaled pixels instead of dips
this will just work so let's go into one
of the test apps real quick to see what
the difference so we'll pop into the
inaccessible version of item grouping
and I'll see that the text size was
exactly the same what you're really
looking at here is the header it's the
same as it was previously because we've
actually constructed this view using
dips rather than scaled pixels if we go
back out onto the fixed version you can
see that the header now is quite large
and it follows the convention of the
platform by using scale pixels so the
text is larger for users of the large
text feature you also knows that the
text which used to take up only one line
has now wrapped onto two unfortunately
that doesn't mess up the rest of our
view it works very well if the line
needs to wrap again all right so some of
the other features that we're just going
to cover real quick but we're not going
to do specific demos for our web
accessibility so Android Ice Cream
Sandwich and jelly bean have support for
opening webview content and touch
exploring so a lot of apps are hybrid
you have both a webview and native
Android content and if you go into
accessibility options and turn on
talkback you should also make sure I'll
just pop in there again actually I'm
going to use the recent apps swipe to
get in there so we'll do down right I'll
swipe over to settings so that's just
gonna be a couple of swipes to the right
all right settings and I'll double tap
to open that up okay and I'm just going
to go straight to accessibility since
it's usually located near the bottom and
you'll notice this item enhanced web
accessibility when I double-click that
it gets a little bit more obvious so
what this means is that when this
feature is turned on web views that have
JavaScript are going to inject something
called Android Vox this is similar to
Chrome Vox which is our web
accessibility solution on Chrome it's
basically a JavaScript screen reader and
it allows users to touch your web view
content and receive touch exploration
feedback the same way that they would
for native Android views this also works
for swiping left and right so if you
have a hybrid web app this is features
turned on by default when you do setup
wizard' accessibility for a new device
if you turn on talkback afterwards
you'll have to make sure to turn this on
so I'm just going to allow this and now
when I have web content and I'm testing
my application for accessibility I can
swipe through normal Android content and
then it'll automatically start moving
into my web content when I get to that
and our recommendation for developers
who have hybrid apps or web apps are
basically to use your web accessibility
standards the w3c accessibility
standards within your hybrid app web
views
to make sure that your content is
accessible so use already live regions
you label your images with alt tags
those standard web accessibility
recommendations and the same caveat
supply for alt text so if you have
decorative edges decorative images they
print if they don't need content
descriptions for native Android they
wouldn't need alt text for web content
alright so that's a quick overview of
all of the features in Android
accessibility we haven't covered Braille
we don't have a Braille device with us
right now to demo but for making sure
that your app works with Braille you can
actually typically just swipe through if
you can swipe through and you can double
click to activate things in your app and
everything is read as you would expect
then your app should work very well for
a user with a Braille input device think
of a Braille device as both an input and
an output device which is what it
actually is it's a Bluetooth device that
those acts as a break you both and
without the find user to input text and
then also displays text on it it's a
very cool thing to see you can
yes but as a developer you you know you
shouldn't have to worry about paralysis
speech what do you need to be letting
about whoppin evening these
accessibility events ethically so that
so as a developer there are a lot of
resources at your disposal for
implementing accessibility we have a
great developer guidelines section on
the Android website regarding
accessibility we have great UX
guidelines regarding accessibility on
the Android site talkback is open source
so if you need to know a lot you can
actually check that out online and the
sample app that we ran through with bad
and good versions of accessibility in
applications is also open sourced and
available online with that I think we'll
hand it back for questions actually have
Richard on the Hangout and when I put
him on
so you can ask you guys a question he's
31 second
Richard can yours
one more time sorry about that we're
working on hearing you yeah give me one
second I'm gonna sort this out real
quick sorry one sec so yeah why we might
be you get the audition started here um
contrivance to developers I mean this
looks way enough forth using your apps
on devices with ever more user
interfaces there's a fun stuff to do and
you're probably discovered in the
process of making your apps more
accessible that there are simple
usability issues that you discover I
think one of the most important things
in making an app accessible is making
sure that it's orderly and simplified
simplification is good for everyone
so if it doesn't take 15 button clicks
to get from one place to another
everyone wins explicit pieces of content
that users have to read in order to
figure out how to use your application
and you know things that are
showstoppers for your blind user they
usually a pain in the neck for your avid
users who don't want to come about it
these are mobile devices right these are
devices we use on the go the faster
somebody can do something on your
application
and the best way to test for this stuff
as a developer is testing by doing so
going go ahead into accessibility
settings and turn on talkback and go
into your application and try to explore
by touch try to swipe through your user
interface and close your eyes and keep
them closed absolutely no cheating all
right I think Richard sound may be
working Richard can give it another shot
please all right sorry guys I'm gonna
just go ahead and read Richard's
question now from the from the Hangout
sorry about that Richard we'll get that
question right for you so Richards
question is let me just scroll up
so so so the performance you see on the
device x2 speech does take up sleepy of
cycles we have a lot of developers who
ask us often is there a way we can only
implement some accessibility features
and turn them on if accessibility itself
is on and that's that's something that
you can do through the accessibility
manager class there is a check to see if
accessibility and accessibility services
on and if Explorer metouch is enabled
yeah so if you're using the
accessibility helper class and you're
creating a virtual view hierarchy for
all of your nodes you can do this only
when accessibility is turned on and
that's really easy to check
that's accessibility manager dot is
enabled and is touch exploration enabled
on newer devices newer api's in terms of
the performance hit that your
application takes as Raman to mention
there really is none and we care very
deeply about performance I think tens of
milliseconds is really pushing it as far
as the
performance hit that somebody has to
deal with profiling and making sure I
also use my phone a lot I think I may
actually get worse battery time than
Raman because I have my screen
brightness set a lot higher so that I
think that's actually one of the most
interesting things is that while we are
doing speech in the background we're
doing vibration in the background if the
user just turns their brightness down
they're probably going to save more
battery than they're eating up from the
vibration the haptic feedback yeah so on
an OLED device he's he's saving a lot of
battery on on screen brightness laptop
gives me about six six to eight hours so
good thing
the other one was adjusting the voice
what's your advice for folks who want to
try to support that be releases prior to
Ice Cream Sandwich and four so um
actually the back view access was also
then in honeycomb which is beside the
point so we had three different devices
if you have it if you have an
application that's a hybrid application
and you want to support accessibility
for that views you could do what our
gmail team did and what they did was to
take the chromevox codebase so from box
and that on expenses is a javascript
stadium and what happens in Ice Cream
Sandwich honeycomb has been sufficient
about is that the android framework when
accessibility is in evil and that option
is turned on it actually adds a little
piece of code that injects that script
into everybody so that script is
downloaded once cashed on your device
and then injected into HTML pages as
they load by adding a script tag so if
you have a specific application as an
obvious Gmail but the Gmail team did was
going all the way back to Froyo
they took Oscar and
so if you're looking into doing this
yourself you can actually check out the
web view source code on the Android
project site look for accessibility and
you'll find all the places where we're
getting the URL for the accessibility
script injecting it providing Java
Bridge API to JavaScript and you can add
that to your own web view being careful
to not turn that on on Honeycomb and
above because it's already being
injected you and also if you're
concerned about performance hits around
the injection you can again check
accessibility manager to see if an
accessibility services act is active
right on the device yeah that's super
important you don't want to inject the
script if accessibility is alright
because then everybody will get touch
exploration and people talk and that was
weird
yeah Richard also wants to know there's
a way to change the voice parameters I
think he is referring to
maybe using a different voice explain
for confirmation
this is my favorite thing about Android
sure let's we'll all I think we've all
sort of had an experience with this so I
personally use an Australian voice on my
phone a female Australian voice it
sounds really great for driving
directions but one of the cool things
about Android is anyone can write a
text-to-speech engine so if you go on
the Play Store look for text-to-speech
there are a lot of engines that you can
download for like three or four dollars
and you get great quality voices these
are drop-in replacements so if somebody
installs a German voice and their device
locale is set to German it will just
speak it will speak everything in German
correctly but we have translations and
talkback for all of the languages that
are available for TTS on Android and
also as far as changing voice parameters
talkback will respect whatever sassette
in text-to-speech settings so if you
prefer voice faster you can set the the
voice speed to very fast
talkback will use that and send all the
device feedback in a very fast manner
API we had a couple of
we want users to be able to get better
voices and have all their talking
applications talk with that better voice
both stock back all other applications
right so let's say somebody's written
you that that reads the book you get a
better voice as a user you should be
able to use that voice for that other
app so voices and apps are not tied and
that actually creates for a good
ecosystem because if you're a developer
who's writing an application that talks
you can focus on writing your
application and be assured that when a
user gets a better voice your absence
better just as if I download your app if
I buy your app today and then I use it
on the phone with a better display it
looks better so similarly for YouTube
but out on your after day and I get a
voice that sounds better you hear that
so thanks for the question
to stream which I'm not sure I can find
yeah so the one I found is from ferner
goat quest question is any tips
regarding accessibility and app widgets
what type of applets do target users get
the most use out of
so speaking for myself as a user app
features that you know display a
succinct piece of information are D&amp;amp;E
very useful so I highlight both are
features that I find useful and half
which is that I don't find useful so don
t necessarily a criticism of those
widgets but more more a user's point of
work so it shows you the seven books you
have
right because the thing is if you
started doing accessible speakable
version of that where you touch it and
it speaks the titles of the seven box it
might as well launch something and so on
the other hands of widget that directly
launches a book is very useful because
that's like if you're reading a book you
just the process of reading it your paws
reading it maybe it's a populating over
three weeks having up to that book so
yeah it's it's the same deal add content
descriptions always make sure that you
have content descriptions always test
your apps with accessibility turned on
and your eyes closed because you'll find
out a lot of short short comings
yeah I'm gonna put Richard back on we
actually have sound now I was able to
debug so welcome back how you doing sir
I'm on a Matt - I restarted my browser
so that helps so I was kind of curious
about anytime a feature comes out I work
for a company in Milpitas and what we do
is certification programs so my jobs
under it full-time and my job is to be
aware of these features run the
development crew in what we're doing
particularly interested in are like the
certification that goes around the
device so you implement the feature goes
to the carrier or the oh yeah they
implement the feature how do you when
you make them do to go to show that the
features working properly did you say
CTS tests no that's fine
I just haven't seen that that particular
test suite yet okay so you do have your
test suite out there I've got all the
code of course and and I'll just go
ahead and take a look look down in there
and see what you do because one of the
things that I have to deal with too is
when an arbitrary person writes an app
and they're using it I have to be able
to tell them whether or not they've done
it right what you asked before
okay perfect
those are very useful by the way I threw
out the platform thank you so much for
putting those out there that's uh it
allows it literally allows me to do my
job
oh absolutely the hard part I have is
getting through all the code I spend so
much time just going through the code
and making adjustments I wish I had more
time actually put back in in fact today
I just signed the contributor agreement
for Google after all these years so
hopefully you'll be seeing some things
but yeah it's it's a lot of code to go
through that's good I know I know well
part of the part of the challenge with
picking a contribution is to work on is
how do I not duplicate what's already
been done because I don't know what
someone's doing at 2:00 in the morning
you know no there isn't
so that's part of doing a lot of virtual
machine work right now and down and down
in the guts of dalvik right now and so
what I'll be looking for is you'll have
this virtual machine handle the talkback
because you're dealing there's a native
interface i/o this is actually a great
time to mention that if you turn on
talkback on the emulator alright it just
works so the emulator has text speech
you may need to install talkback just
talkers talkback built into the emulator
now
you may need to install talkback
separately that's available also on the
iceberg project site that we mentioned
where the source code for talkback is
but if you turn on you can use touch
exploration by moving your mouse around
the screen you can basically actually
that's a great way to test keyboard
accessibility so you've got a desktop
with a keyboard you open up to the
emulator and you can use the arrow keys
to move through your application and
that works the same way that a hardware
keyboard key word would on that device
like the Droid and so when you move your
mouse pointer generates power enter in
how I exited events and that's actually
watch the finger is generating when you
are doing touch explanation okay so what
what part of the OS handles the event
the actual event is that that's done on
the main thread or are you passing it
off to some other service so I can I can
go into a 30-minute explanation and you
can actually do touch expression using
the things it's actually pretty cool
I'll go down I'll go down look at the
code that'll probably answer my
questions you're welcome thank you very
much
right yeah thanks for joining us
we're just about out of time so we're
gonna wrap up thanks to Alan Casey and
Ramon today for joining me and telling
us all about how to make our
applications accessible we'll be posting
those resources that they mentioned in
the project the application code that
they were demonstrating today which
includes the upper class for
accessibility correct that's right and
so take a look for that on our Google+
stream and that's it for today we'll be
in over here Ian next week take our
general general questions around Android
development so thanks for joining us
we'll see you next week</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>