<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What's New in Android Accessibility (Google I/O '17) | Coder Coacher - Coaching Coders</title><meta content="What's New in Android Accessibility (Google I/O '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What's New in Android Accessibility (Google I/O '17)</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/h5rRNXzy1xo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all righty welcome everybody well that's
right we are here to talk today about
accessibility and great so my name is
Patrick Clary I'm a product manager on
accessibility here at Google and I'll be
kicking things off we also have a great
group of presenters from different areas
across Google with me here today and
there's a few things that I want you to
take away with you as you leave today
the first one is why designing for
accessibility is really so important and
benefits our users and this isn't just
users with a disability or an
accessibility need but I want to get
across that this actually helps all
users the second thing you'll learn
about is accessibility on Android you'll
hear about what's coming in Android oh
and you'll see some awesome new demos of
these things and then third is tips on
user research for users who have an
accessibility need you'll hear about
this and you also see an inside look
with a couple examples on things we've
done at Google how we perform research
on a couple of different products it's
very exciting so first why accessibility
so accessibility is something that you
know is near and dear to my heart but I
want to give you a few reasons why it's
important and I'm speaking to the
developer it's why it's important to
developers to consider as well so here's
a metric that I actually find very
compelling right one-in-five just one in
five people will have a disability in
their lifetime this is just a staggering
number so addressing accessibility can
have a direct benefit on these users
it's a huge benefit right it's actually
a life-changing benefit so for these
users it actually means the difference
with connecting to friends family is
really taking advantage of the
technology that mainstream users really
use and enjoy the second as I mentioned
is that designing for accessibility
really benefits all users and let me
give you a couple
example so first think about designing a
product that's meant for a blind or a
low vision user so when you're doing
this you actually help users that might
just have their eyes occupied so perhaps
they're driving they're looking at
another screen they're not looking
directly at their Android device
another example is designing for user
that might have a motor impairment so an
example would be a trimmer this is an
impairment that affects their use of a
touchscreen it makes it difficult for
them to use the touchscreen so designing
effectively for these users actually
benefits mainstream users too for
otherwise they just can't use their
touchscreen maybe they're holding
groceries maybe they're cooking but they
can't use their touchscreen effectively
now when you think about it this way
designing for accessibility is really
about designing for the widest possible
range of abilities within the widest
possible range of situations it's not
really about designing for disabilities
it's about designing for all users so
where does Android fit in so in Android
we have a series of settings api's and
services for accessibility so settings
these really allow users to customize
how their device looks and feels right
api's allow developers to build out
their apps in ways that meet the needs
of users who have accessibility needs it
also allows us to build accessibility
services so an accessibility service is
a long-running privilege program that
runs on your device that either changes
the way users consume the contents of
your device or it changes the way they
interact with your device and we have a
few here these are for that Google has
developed talkback brailleback switch
access and voice access so talkback and
brailleback these are services designed
for users who are blind or have low
vision talkback is our screen reader
what this allows users to do is
basically interpret the content of their
device through an audio stream so users
will listen to what's on their device
using talkback brailleback it's similar
but instead of an audio stream the
content goes to refreshable Braille
display this is a little handheld
Braille device
where a user can scan their fingers
across it and interpret the content on
the screen we also have switch access
and voice access these are two services
that are targeted to users with motor
impairments so for example as I
mentioned users that have a tremor
these are users that typically can't use
a touchscreen so it's switch access and
voice access we actually provide full
Android control without ever having to
touch the screen so with switch access
users typically use an adaptive switch
device you'll see an example of one of
these later but this is a physical
Hardware switch that a user might have
mounted in front of them mounted to a
wheelchair and they'll tap on the switch
to linearly scroll through things on
their on their device voice access
actually allows users to control their
device purely by voice
so you'll issue voice commands that
correspond to touch controls these are
things like scroll up scroll down half
Gmail go home etc so that's what we have
in Android for a deeper look into the
upcoming version of Android I'll hand it
off to my end victor
hello Thank You Patrick my name is
Victor sarin and I'm a technical program
manager on the Android accessibility
services team for Android Oh our major
focus was to increase productivity for
users of accessibility services in
particular we looked at users who are
blind and visually impaired and use
talkback screenreader we're introducing
accessibility API is to help developers
who develop accessibility services for
people with physical disabilities one
such service
you guys already heard about is called
switch access last but not least we're
introducing a new accessibility service
which will help people with print and
learning disabilities to read
information on the screen but let me
start with new features for talkback the
first feature I would like to talk about
is called accessibility volume behind
the fancy words is an ability for
someone who is blind or visually
impaired or specifically loses talkback
screen there to adjust the volume of
speech independently from the volume of
media for example when watching the
YouTube video or listening to music
we're doing this by introducing a new
audio stream in oh we called
accessibility stream as a developer of
an accessibility service what that means
to you is that you will have to request
this feature when writing your
accessibility service otherwise it is
not available to you so let me show you
how this feature works device and loss 3
home pixel overview overview setting oh
I will just remove those guys that
dismiss muted setting this misused open
YouTube app YouTube issues showing items
1 to 2 207 the developer show TL DR o-69
developer show TL DR o-69 11k view so
uses the advantage here to ask
development online I'm trying to listen
to talk Mike and Liston is talking back
at me oh my god I came here as more
button what I can do right now I can
completely shut off the volume of the
video and I can still hear total by a
four button like this portable acid hero
24 is this single up next so this is
essentially how this works so tobik user
is now able to adjust the speech of the
volume of the speech independently from
media volume rc-135 is more detailed and
links are on 100 expand tonight data is
now available incidentally you also
notice that there is now a new
accessibility volume slider at the top
of the screen so that again allows you
if your visual user you can adjust this
slider as well from the holy entree
rewind pause video play video help home
screen one of two so the next feature I
would like to talk about a green all has
to do with new gestures for talkback we
many of the new Android devices use a
fingerprint sensor at the back of their
device so we decided why not utilize the
fingerprint sensor for additional
gestures to allow talkback users
activate some of the favorite of their
features so we are introducing in all
ability for an accessibility service
such as top web to utilize fingerprint
sensor the gestures available to the
user are swiping left right up or down
these gestures are ensign able so the
user can decide what talkback features
each gesture will launch again as a
developer of an accessibility service
you will have to request a special flag
in order to be able to take advantage of
fingerprint gestures fingerprint
gestures work again only on all devices
I just wanted to point it out and let me
show you how this works device unlocked
3:10 p.m. home screen one of Kim bot
chrome camera so I'm going to attempt
something very brave I'll take a selfie
camera camera and I'll be using here
prima gestures to do that photo gallery
shutter switch to front camera switch to
back camera one face right with 50% of
screen very close hero faces shutter
photo taken photo gallery one face
center right this 50% of screen very
slice hero home screen one of two free
pen create very marking resemblance the
other finger bring gestures on in
Android Oh for accessibility the next
feature I would like to talk about is
multilingual support one of the things
we realize that since Android has been
used so much outside of the US we badly
need to support international users and
in our introducing ability for the
Google text-to-speech engine to
automatically recognize languages that
are appearing on the screen and switch
text-to-speech to speak in that
particular language if you're a
developer and you would like to trigger
language automatic switching you can use
locale spend you have to wrap your
strings in locale spans to trigger that
change but before you get excited let me
show you how actually the language
switching feature works device unlocked
311 home overview overview showing home
home home screen captain boss fixed
messages inbox inbox
remember subject beautiful day remember
to from Cara please may 11th for menu hi
there come hi there
okay so my wife lovely wife likes to you
don't pull little jokes with me well
this in this particular case this is not
a joke so send me a message if you days
ago try to invite me for dinner and she
does a lot of things in style so this
particular case is no exception
so she decided to send me a message in
four languages because you know we're so
cool right so let's see how talkback
deals with this particular situation
more menus hi there
comment lost hi there good move I choose
mwah smooching twizzle loses his penis
polish Nevada inhibition for low signal
kappa until the chokecherry my sister
here she is on trial of two women one
day kinky let's have dinner tonight okay
yep
thank you so that's you know likely both
of us can speak all those languages I
was able to understand what she said
so the languages were French polish
Ukrainian and Chinese just for your
information so and the last feature I
would like to talk about is the new
accessibility shortcut for quite a bit
of time users have been asking us for
ability to turn off their favorite
accessibility service regardless of
which screen they're on so they wanted a
shortcut key that they can press and the
search service will toggle on and off
for example if a blind person walked
into the store that sold Android phones
they wanted to be able to launch
talkback and start exploring the phone
to decide whether this is something they
wanted to purchase or not well in all
we're introducing this accessibility
shortcut by default it's configured to
launch talkback however it can be
reconfigured to launch any of the
available accessibility services on your
device I want to point out that this
works on any screen even after the exit
setup wizard so once the shortcut is
configured it will be available to the
user at all time as a developer of an
accessibility service you will have to
request this feature at runtime when
your service runs otherwise it is not
available to you so it's only available
to accessibility services and as you can
guess the demo is going to be pretty
simple so I'll show you how this works
home all I have to do right now is press
to home to volume keys at the same time
and accessibility services off if I
press them again top that on in bus
that's it and that's when accessibility
service accessibility shortcut works so
as you can imagine I just scratched the
surface there's much more coming up but
I would like Maya to talk about these
other exciting services and API thank
you thank you for sure Thank You Victor
for the lovely demos my name is Maya
binary I'm a product manager on Android
accessibility the next type of feature
we're going to talk about our new API to
framework to support new accessibility
functionality we're adding continuous
gesture API in Android nougat we added
an API to allow profund to allow
performing gestures on behalf of the
user
in Android oh we are extending this API
to make it easier to perform continuous
gestures what does it mean is that for
example it will be easier for a user's
using a wheelchair mouse or a hair
tracker to perform gestures such as drag
and drop text election answering phone
calls and zooming in and out of maps the
next feature I'm very excited about it's
called the accessibility button in the
navigation bar what we added here is a
new button accessibility button to the
right of the navigation bar to quickly
invoke context dependent accessibility
features let's give an example right now
we have magnification so a user using
magnification can triple tap to magnify
the screen however some users might be
challenging to perform the triple tap
gesture in android oh we are adding an
alternative to invoke magnification so
let me show me let me show you how this
works
so I have that set ability button on the
bottom right of the screen I can simply
tap the button and if I tap anywhere on
the screen I will magnify the content
now I can move this around using two
fingers and if I want to de magnify I
will just press the accessibility button
again back to the slide now this is
optionally supported by developers for
devices with software and the navigation
bar and the button will be shown there
only if there is an accessibility
service or feature that supports it and
is turned on the next set of feature are
for people with print disabilities print
disabilities of people will have
difficulty of reading test those include
people with dyslexia or sighted low
vision a literal or even people who just
want to learn a new language we recently
launched a service called selective
speak selective speech is part of talk
about 5.2 and what the service does is
it vocalize content on the screen by
allowing users to select elements to
read now this service is available from
lollipop mr1 and up now this is an
example of how select to speak words you
can see a floating action button then
the user can either tap an element or
select marquee select elements to read
and the content will be read out loud
in android oh we're adding additional
functionality for select to speak
including reading the old page at that
controller to move backwards and next
error adjust the speed we add also word
level line lighting and we integrated
this service into the setup wizard now
let me show you how it works so I have
here the accessibility button and if I
long press on the accessibility button I
can show that also I have a service
which uses this button called select to
speak I will select that one and if I
will tap the button again then I will be
shown a controller bar at this point I
can drag and drop or move the controller
bar on the screen now I can either
support the functionality I already have
for example I can marquee select or top
an element map
slap and it will be read out loud now
what I can also have is continuous
reading 69 degrees Fahrenheit Wednesday
May 17th math clock Playstore from Drive
also does one know
we also have this Alexis Vicki can read
the whole page and it can read all the
whole sentences and I can go backward
and forward with the sentences and also
increase decrease increase and decrease
the speech by pressing the plus and
minus button let me show you how to work
navigate up select to speak setting
Quinn select to speak is on you can have
specific items on your screen to eat
first half the MN you can have a
specific item items like Hector an image
drag your fingers off for free to
collect multiple item item caps have to
play button to hear everything thank you
and this is Celeste to speak available
in Android oh and we talked back five
points to know the next section is about
testing we'd like to make androids more
accessible for everyone and developer or
a crucial part of this mission you can
develop better experience for people
with disability but a lot of it has to
do with how you test your app for
accessibility in the next section I'm
going to talk about manual and automated
testing for accessibility now let's
start with manual testing the first
thing that you want to do is you want to
get familiar familiar set yourself and
understand how the experience work with
Android accessibility services
specifically we talked back in switch
access so download talkback turn it on
and cover your eyes and try to go
through the experience in your app you
would like to notice whether you are
your app is representing correctly the
content for talkback for example maybe
you have unlabeled bottles or maybe
you're missing perfect description or
maybe you have controllers which are
hard to interact with pay special
attention for issues that may impact you
efficiently well you are performing
common Slone now if it works well we
talk back which will also like it will
also likely work well with Braille back
and select to speak because what you are
doing is you're actually testing your
app output you are testing whether you
are representing correctly your content
to the accessibility service then the
next thing that you want to test if you
want to test with switch access as
Patrick mentioned switch access is a
service targeted for user with motor
impairments who have difficulty
interacting with their device in that
case the user connects something which
is called an adaptive switch this is an
example of an adaptive switch now the
adults which can contain two buttons
less or more and in that case the user
can map one button for a next operation
and one for an enter now if you don't
have an adaptive switch you can just
connect an external keyboard and map
your keyboard buttons to specific
activities in switch access now after
you do that you want to go through
comments flow and you want to note where
the switch access interacts correctly
with your app UI now if it works well
with which access it will also likely
work well with all voice access because
what you are doing at that point you are
testing your app input we switch access
and talkback you are testing both your
app output and input now testing switch
access and with switch access and
talkback is the best way for you to
understand the experience that you're
providing for users with different names
yeah but there but this is not all so
there are multiple other features
available on the platform including
magnification and large text to
facilitate accessibility testing we also
provide a
which is called accessibility scanner
accessibility scanner is a standalone
app which you can download free from the
Play Store and the APIs targeted for app
developer for app developer and QA tells
QA testers and it suggests way for you
to improve the accessibility of your app
how you can use it just download it turn
it on and then you will see a floating
action button on your screen
bring the UI you are interested in into
the foreground press the button and then
accessibility scanner will analyze the
UI and will show some suggestion of how
to improve your accessibility and in
this example it shown examples for
improving your tech contrast we ship
this app and merge it March last year
and we're very happy to announce that in
the last year accessibility user used
accessibility scanner to find over 1
million opportunities for improving
their app accessibility definitely check
it out and download accessibility
scanner from the Play Store
and obesity about automated testing we
also created accessibility testing
framework to allow you to perform
automated testing accessibility testing
framework is an open-source library that
provides that provides runtime
evaluation on real Android UI for
structs
we need to graded this testing framework
into two into two common test framework
called robolectric and espresso if you
are already using those testing
framework you can simply turn on
accessibility test functionality within
those framework and then you might see
some of your tests fun start failing
because they could have an improved
accessibility
lastly we launched a new section about
accessibility on developer.android.com
and this can help you guide to better
understand how to implement
accessibility in your app specifically
we have a page about testing your app
accessibility in general we recommend a
balance between manual testing and
automated testing for making your app
accessible with this page the page
summarize how you can develop an
holistic test strategy does improve both
manual and automated testing but with
all these testing there is no better way
than interacting with actual user and
conducting user research and for that
Astrid and Melissa are going to tell you
all about that
Thank You Maya I mastered rubber and I
work on user experience research for
accessibility engineering at Google and
I'm Melissa Bernhardt and I'm a UX
researcher on Android so what is
actually UX research and why do we need
it
imagine you have a dream of opening a
bar I mean how many of us haven't had it
at some point in our lives you have
these cool design ideas for the interior
of your bar you know exactly what you
want to serve on your drinking menu and
you really know that the music you're
going to play is what you basically have
at home and you play yourself almost
basically while you're building your bar
you're imagining how perfect a bar could
be if it would just be the perfect place
for someone with exactly the same taste
like yourself basically your users they
are just like yourself right
chances are unfortunately that your bar
might be empty and your business idea
might be failing like over 50% of all
bars and restaurants are failing within
the first year of the existence and I'm
pretty sure that all the owners of these
bars and restaurants really wanted to
create a good experience and really made
choices that they would have taken
themselves and this brings us up to the
importance of user experience research
and design for restaurants and bars but
also for technology development because
unfortunately the failure rate among
startups is at 90% which is much higher
and actually the one wrong restaurant at
the same time research shows that if you
are testing your own assumptions and
your user needs often and early your
chances increase so much more that you
will end up with evaluated app and
satisfied users
which brings us very close to the
definition of actual and objective UX
research which really is all about
changing your own perspective to that of
your users to understand their needs
including all the accessibility needs
user research focuses on understanding
user behaviors needs and motivations
through various research techniques it
is the process of understanding the
impact of design on an audience now that
we have a common understanding of the
concept of UX research what does it
actually entail Europe's research is a
set of research methods that can help
you during the whole process of your
product development cycle UX research
methods such as field studies interviews
or competitive analyzers are very well
suited in the beginning of your product
development work because they are
especially useful in order to understand
how to acknowledge usage works and how
new innovative fields work once you have
decided what you built and you have a
first prototype research methods such as
usability studies participatory design
exercises or remote research actually
really useful for you to understand what
works and what doesn't work in the hands
of your users and lastly once your
product is out there in the market you
really want to understand how it's doing
right research methods such as cognitive
walkthrough is a bill M cognitive
walkthroughs
no research methods such as block
analyzers diary studies as well as
remote testing really help you at that
stage of your product development to
understand how the app is doing in the
market and if people really like it and
with that I hand it over to Melissa who
has a very concrete example for you from
our recent accessibility Android
development on Oh
okay thank you aspirin so today I'd like
to show you exactly how accessibility
research has informed the design process
for Android let's take the example of
settings we want all users to be able to
easily access and understand settings
that are relevant to them including
users with accessibility needs here we
have a screen shot of the accessibility
settings page for Android n when
planning for Android oh we had some
assumptions about this page firstly we
felt that it was a bit unorganized
making it difficult for users to find
what they need secondly we questioned
whether or not categories like services
and system had any real meaning to users
so we turn to research to check our
assumptions and make more informed
design decisions we use two research
methods usability studies and intercepts
and is Astro just mentioned these
methods are well suited for the design
develop stage so we started with
usability studies in these studies we
invited people with visual impairments
to our offices and prompted them to
interact with the accessibility settings
page you just saw now we immediately
observe some issues specifically the
participants could not always find the
settings we asked them to find and even
when they did they weren't always sure
what those settings would do now our
approach to this research was iterative
so we learn things in one study adjust
the design and then retest the adjusted
design in the next study but we wanted
to hear from a wider more diverse
audience so we went to a conference in
January we attended the assistive
technology Industry Association
conference in Orlando Florida with just
a clipboard pen paper and phone we
approached conference attendees and
asked them for ten minutes of feedback
on our latest design these intercepts
allowed us to gather a lot of feedback
in a relatively short timeframe in just
two days we talked to 15 people with
visual cognitive and motor impairments
as well as 80 professionals and
educators as a result of this research
we verified a lot of our assumptions and
fine-tuned our design and here's a sneak
peek at the accessibility settings page
for Android Oh on the right you'll see
that we're introducing categorizations
by utility so instead of categories like
services and system you'll find
categories like screen readers and
display also we've added colorful icons
to make Android services pop lastly
below each setting we've included a
short description to explain what the
settings does now accessibility research
help guide this design approach and it
can help you too so if you want to build
products for the widest possible
audience and genuinely improve people's
lives consider incorporating
accessibility research into your current
process I promise you don't need fancy
equipment or a big budget to get started
think creatively about how you can talk
to users with accessibility needs maybe
you attend a conference like we did
maybe you reach out to a local
organization or university or maybe you
have a friend with dyslexia or color
blindness who would be willing to try
your app and give you 15 minutes of
feedback try to include one person with
accessibility needs in your next
research study and see what you learn
the difference between zero and even a
little bit of data is astounding and
with that I will hand it back over to
Astrid
thanks Melissa those of you working on
consumer facing apps hopefully already
mark your calendars now to conduct some
accessibility research as soon as you're
back in the office those of you who work
on developer facing applications might
be wondering but what about my target
group well the good news is they can
also benefit from UX research and we
have an example of our very own
accessibility scanner app about how the
UX research really helps us to develop a
better application we tested
accessibility scanner with designers
test engineers developers and product
managers we did early-stage prototyping
with some paper mocks in addition to
that we also tested the name itself yes
you heard correctly accessibility
scanner was not born with that name we
had a long list of options but rather
just following our own intuition or
preference we asked our users in
interviews because we wanted to
understand which name would be most
memorable and what people are
associating with each of the options
thanks to UX research we also made some
visual and interaction design changes to
the application one of the visual design
changes entails that we do not use
colors anymore to distinguish the kind
of issues being detected
having a diverse sample of users really
helped us there because the color blinds
participants of our study clearly
signaled to us that they felt liked out
of the experience if you use color
because they could not necessarily
distinguish the elements based on that
factor we also improve the overall flow
of the application by making it easy to
just click on any element of detection
and then get a short description of the
issue this way the application became
especially useful and usable to those
Meucci accessibility testing and on that
note I will hand it back to Patrick with
our final thoughts and
look on what's next all right Thank You
Astrid so I hope everyone's inspired to
go home no work look at your own
products look Li your own apps think
about accessibility the benefit that it
can have on these users along those
lines I have a few challenges to the
developers in the audience so the first
one is familiarize yourself with
accessibility services and these api's
that were mentioned so when you go home
turn on talkback turn on switch access
put yourself in the shoes of these users
and run through your apps do you want
things you uncover the second is to
download accessibility scanner right
download it's very easy you can get it
you can test your app very easy to find
some low-hanging fruit some quick and
easy ways to improve the accessibility
of your app and finally think about
performing user research with users that
have an accessibility need so find a
family member a friend someone in your
community go to a conference sit with
them as they use your app and I bet
you'll be surprised with things you
learn we have a few other really
interesting things happening at Google
i/o for accessibility so we have a
couple other sessions designing for the
next billion users and pragmatic
accessibility tomorrow and Stage five we
also have a sandbox just back here this
is your chance to come talk to us learn
more about accessibility see these demos
you know speak to a Google or one-on-one
and get more information we also have
the on Thursday at 6:30 we have the
Google Play Awards and there'll be an
awesome award for the best accessibility
experience so I recommend you check that
out so with that I'd like to thank you
and make sure you keep in touch you can
use our Twitter handle
at Google access thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>