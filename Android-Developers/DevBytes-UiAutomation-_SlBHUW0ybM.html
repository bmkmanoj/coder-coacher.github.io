<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>DevBytes: UiAutomation | Coder Coacher - Coaching Coders</title><meta content="DevBytes: UiAutomation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>DevBytes: UiAutomation</b></h2><h5 class="post__date">2013-08-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_SlBHUW0ybM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is Stefan Lanza and I'm a
developer advocate on the Android team
here at Google today I'm going to talk
about a new testing API which we've
introduced with Android 4.3 UI
automation your automation is a new API
that introduces full screen
introspection support into the Android
instrumentation framework why is this
important because it enables testing
across application boundaries within
your instrumentation tests but let's
have a look at a quick example here's
some screenshots of the new Google Maps
app let's say we want to write a
functional test for this scenario using
the instrumentation framework what we
would do is to start activity on the
Left click on the navigation icon wait
for the dialogue to appear then click
the enable button but as of now there
was no easy way to actually turn a GPS
on the problem is that the
instrumentation framework is limited to
test within its target package only with
your automation this restriction no
longer holds and now we can test the
complete user flow go to the settings
screen and able the GPS by checking the
box and press the back button so let's
have a quick look at the API supported
by UI automation you our automation
enables full screen introspection
support using the accessibility
attributes it allows for taking
screenshots from right within your
instrumentation tests and then now this
was a feature that was requested for a
very long time
it also supports changing of the change
of the device orientation and injection
of raw input events maybe one more note
here your automation is a very low-level
API but this was done on purpose to
encourage development of your AI testing
tools such as your Automator as well as
to allow developers to use it in their
instrumentation tests and in fact the UI
Automator framework which were
introduced with jellybean 4.1 is built
on top of the year automation API
so let's have a look at some code what
do you have to do to get started with
your automation it's very simple you
just have to inherit from
instrumentation test case or from any
other subclass
like activity instrumentation test case
- then in your test method just call get
instrumentation that get you our
automation to get a reference to the UI
automation object the question is how do
you run these tests it's not so
different from what it was before you
just have to use the adb shell am
instrument command with providing the -
W option your target package and your
test Runner so let me show you how you
could introspect any visible screen
content from within your instrumentation
tests first we get a reference to the
you are automating object but as the
window content is presented as a tree of
accessibility notes in this case we have
to obtain the active window root
accessibility node first this is done by
calling get root in activity window from
there we can continue and create for any
note by text or ID but note this search
is always relative to the retrieved root
access accessibility node another cool
feature which your automation introduces
is to capture screenshots using the
instrumentation framework in order to
retrieve a bitmap of the current screen
content we have to call take screenshot
which returns a bitmap object which then
can be written to the filesystem your
automation also allows for the injection
of raw input events into the system in
order to inject an event you have to
call the inject input event method for
example if you want to inject a motion
event just obtain event object from the
pool and pass it as a parameter but note
that it's your responsibility to recycle
the input event and return it to the
pool furthermore you can execute come
and listen for their corresponding
accessibility events using an
accessibility event filter for example
we can pass a runnable as a parameter to
execute and wait for event which taps on
the screen and then verify this tab by
listening for the corresponding
accessibility event but what you also
can do is listen for all accessibility
events in the event stream this is also
very easy by just passing an instance of
on accessibility event listener to the
set on accessibility event listener
method your listener interface then
receives a callback each time an
accessibility event occurs thank you
very much for listening and happy
testing</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>