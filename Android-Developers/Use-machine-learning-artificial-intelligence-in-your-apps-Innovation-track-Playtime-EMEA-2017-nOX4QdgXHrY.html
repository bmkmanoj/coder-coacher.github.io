<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Use machine learning &amp; artificial intelligence in your apps (Innovation track - Playtime EMEA 2017) | Coder Coacher - Coaching Coders</title><meta content="Use machine learning &amp; artificial intelligence in your apps (Innovation track - Playtime EMEA 2017) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Use machine learning &amp; artificial intelligence in your apps (Innovation track - Playtime EMEA 2017)</b></h2><h5 class="post__date">2018-02-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nOX4QdgXHrY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone thank you for being here I
hope you are all comfortably seated so
my name is Albert Renault I work in the
Android and play business development
team looking after app developers across
Europe and I'm based in London so today
as you heard this morning with being
kind of announcing a few things and we
kind of excited you kind of do all these
announcements we've been working it
really hard over the past few months to
kind of bring keep on innovating within
the console trying to bring new tools
trying to bring new functionalities so
you can then come back home and also
start innovating so we really kind of
exciting about having you here I hope
you enjoying your stay in Berlin I hope
that you're enjoying your day so far and
as you can see in this innovation track
we've got a pretty packed agenda we're
going to start talking about machine
learning / assistant topics and then
we're gonna discuss VR and have some
kind of panel discussions and we'll
finish with sharing like insights and
research findings about design so let's
start with the first presentation focus
on machine learning that I will be
presenting together with Daniel from
memorize and Hassim from I am so earlier
this morning how she gave you a
presentation by machine learning giving
you like an overview of the key
principles of machine learning as well
as why we believe at Google that this is
important in this session we'll try to
have a slightly different angle and try
to give you like insight on how as a
developer you should be approaching it
and thinking about it and also how some
of your peers are being approaching it
recently within the app so I know that
machine learning artificial intelligence
probably hear a lot about it a lot of
people talk about it it's probably one
of the top buzzword of 2017 probably a
lot less people are actually really
doing it but and I'm sure that many of
you are kind of excitingly confused
about this but if you hear at least that
means that you are interested who in the
room is actually
of doing some kind of machine learning
related project within the app okay so
we go like maybe good 20% and who is
considering it for the next six twelve
months okay so we go up to 50 percents I
hope that's at the end of this talk
we're gonna have more than 50% but
that's great so any case Isis you
mentioned machine learning has become
the number one priority for Google we're
moving from a mobile-first world towards
a AI first world and the way I think
about it is sometimes thinking about
five ten years ago these companies that
we're not really considering Mobile's
seriously in their strategy right and
actually the success of many of you is
linked to the fact that all traditional
players were not taking into their
strategy mobile seriously and we hope
that you not gonna do the same mistake
with machine learning today so it's good
machine learnings already a reality as
we saw this morning from kind of image
recognition in Google photos content
recommendation on YouTube over a hundred
project production ready project are
actually using neural network technology
at Google but you probably thinking
right now yes right this is great but
how does it apply to me
right I'm not Google I don't have the
resources I don't have maybe the skills
to do it how should I be thinking about
it and how should I even get started so
doing this presentation we're going to
try to get look at the key aspect you
should be considering when kind of
thinking about machine learning and
starting by thinking okay are you
machine learning ready okay so what are
the key initial conditions before taking
up a machine learning process a project
so first of all do you have a problem
sounds a bit silly but this is probably
one of the most common mistake we
observe in industry like people are
looking at what ml can do and try to
kind of randomly apply that to their
business however you should take the
problem the other way around right you
should look at your problems and not
simple problem like mission-critical
problems and try to see how machine
can help you solve these problems this
is important because you might end up
building a great model super successful
machine learning feature but it's
useless because it's not actually not
solving a problem within your company
once you have a problem obviously you
need data you need a lot of data you
need a lot of quality data large volume
and you need to be able to kind of
access it and process it acts at scale
so that means that you might have to go
through a process of improvement of your
infrastructure you have to clean your
data and you might have to even think
about collecting labels for your data
and finally you need to identify the
people that are going to execute this
project within your companies and if you
don't have anyone please don't feel
discouraged right away there are a lot
of resources online that are available
to everyone to train your teams Coursera
Udacity YouTube and all the kind of
github etc etc there's a lot of
resources out there that you can
leverage but ideally in an ideal world
what we tend to recommend is to combine
two type of skills on one hand what we
call data scientists so people that are
able to kind of conceptualize
mathematical model that kind of take
into account your business requirements
and on one and the other side we call
data as engineers that translate this
into code able to train the model and to
kind of run it on production so at the
beginning of you're going to be kind of
tapping into whatever resources you have
but the more you grow the more we
encourage you to think about structuring
this team into one centralized team that
is then going to diffuse their knowledge
into the different division and process
of the organization so now you have a
clear problem you have skills you have
data you need to start thinking about
choosing your model here see this
morning mentioned describe a few of them
from classic image classification to
reinforcement learning within
self-driving cars you need to choose
your model and even maybe a combination
of several model and it's often where
the magic happens one key aspect of it
is the presence or not of labels within
your data so in the example of image
recognition you might have data that
will tell you the object that is present
within your image right but
unfortunately often this might not be
the case in this case you might have to
consider starting to collect these
labels or even think about choosing
another model that will not require
these labels a lot of companies in the
machine learning field believe in what
we call open research right so including
Google all you need deep mine we believe
in open research this means that a lot
of the research finding a lot of the
libraries lot of the models are being
developed are being put like published
online available open source to everyone
this means that as a developer you will
have to choose between the to what
extent you will have you will rely on
existing models and to what extent you
will actually develop your own models
right so of course obviously at the
beginning we encourage you to tap as
much as you can into our exist existing
libraries that are built but quickly you
might realize that this doesn't really
fit exactly your needs and you might
have to either train your own model with
your own data or even like build your
own custom model as far as Google is
concerned we kind of we have this
trade-off between simplicity and
flexibility we'll also kind of determine
what technology called kind of solution
you're going to be using so as far as
Google is concerned we can help you
along the whole spectrum with on the
kind of ready to use side of the
spectrum we got solution like Google
Cloud machine learning api's which gives
you cloud dishin speech and translate
and natural language and of ATIS as well
as well as action on google that we're
going to be kind of discussing in the
next presentation but if this is not
enough one of the most commonly can of
use use framework by developer is
tensorflow
HT mention it this morning it's has
become the most common use machine
learning framework it's you can use it
you can have
build your own custom model you can use
it to pre to train your model you have a
lot of libraries available out there you
can kind of run it on different
processing units on different cloud
platform etc etc and as he mentioned
this morning we're going to be launching
soon tensorflow light which will enable
running machine learning models directly
on device with this I will pass it over
to memorize and I am do Daniel and have
sinned who are going to share with you
how they been approaching machine
learning within their own app thank you
very much
hello hi so thank you very much Hubbard
and thank you for having us here I think
it's an amazing conference thank you
very much so right so my name is Daniel
I'm the CTO of memorize and if you don't
know memorize we're one of the leading
language learning apps in the world with
over 25 million users and 200 language
combinations to learn from we really
strive to make language learning as
joyful and effective as possible and
very simply we want the best app on
Google Play we're very proud of this
achievement and today I'd like to talk
to you about how we build product
feature using machine learning so I
think I would ask you guys how many
people are interested or playing around
with using machine learning to before
but how many of you actually have
delivered product using machine learning
right so not as many so it's obvious
that everybody's really excited about
the possibilities of machine learning
but it's not as easy to get from having
ideas and using the technology to get
something out there
so we we're doing hackathons on a
regular basis like every six weeks and
we really want to give people time to
play around with ideas and technologies
they think might work well on the
product and this particular feature
started as a hat so we try to think okay
so what could we do it's object
recognition and after a couple of days
with developer flying around it they
came up with a very neat concept which
is turning the the world.the to its own
dictionary so imagine taking your phone
looking around and we feel on German
then you look at the screen you learn
how to say screen or TV in German and
there was the idea so once once we had
that in place after the hack there was
thought okay this is really cool how can
we take this and actually make this
something that we can give to our users
so don't we we started kind of looking
at the product and try to define it
better and what we what we knew we want
to have we want to make sure that it's
very accurate because we teach people
languages we can teach them the wrong
thing it has to be in the right
difficulty level it and it has to be
really fast and give like oh wow this is
my
like really bringing the technology
forward the interesting thing is that
actually getting a machine learning
model or in this particular case object
recognition was really the easy part
the more difficult part was to get it to
recognize the right things so if you
guys look at that picture what do you
see yeah so a guy a man if I look at
that which actually I see James who's
one of the people that worked on this
project now we took this image and we
gave it to Google vision API which is an
amazing piece of technology and this is
what it came up with so hair facial hair
beard well this picture is definitely
very much fun but I think that's not the
first thing when we look at the picture
we think it so I think context is really
really important it's not about
recognizing object is recognizing the
right objects and we spend most of the
time really focusing on that so once we
after playing around with a lot of
models and the quite a few out there we
actually decide to train our own model
so we used the based on was using
Inception v3 which is a model which
exists on on top of that we trained our
own model so what we actually did is we
got product managers to to collect a lot
of images we first define the images
that we care about so we do a lot of
user surveys which was done somehow our
users use the app and we know they often
time for example they use it at their
homes so we thought about okay so which
objects are available in their immediate
surroundings so we try to define that
list of objects which were in the
hundreds and then start collecting
collecting the images and actually
product managers spend a lot of time
collecting images from from different
sources and we found out that actually
we need quite a few example and like
some objects needed more than others for
example people so as you can see here
there is a one example of has a secured
engineer which is not quite a hair dryer
maybe needs one but but yeah but so this
was an example of something which was a
bit difficult and as you can see there
there
a picture of bicycle and a picture of
glasses and they're both recognized as
glasses something that we wouldn't
imagine that it will you would never
look at the bicycle sir oh it's glasses
but it's actually a problems that emerge
and we had to do a lot of back-and-forth
collecting more and more images focusing
on amateur photography and also
different sizes and shapes of the
objects that we really care about so
there are a lot of interesting examples
in the slides were there were problems
but by iterating and understand what it
is that we want to build and what we
care what we care about being the final
result we came up with a really neat
product so it's just a few images from
the finished product that actually
trekking has really nice things like
airplanes and stuff like that and now
were in the process of finding how to
integrate it best with our product so
just a few lessons learned I think like
I like I said I think even with a really
good model different data sets really
equal different products so like you see
so in the Google vision API it's not
that it was wrong it just gave us we
didn't give us what we wanted it to be
really carried in our product we wanted
people to look around them and learn how
objects are called so really cared about
single objects how the user is
experiencing it and additional to that I
just want to say that I think machine
learning I think as Albert said as well
it's a tool you want to educate people
on how to use it there's a lot of
resources out there
educate your teams and try to encourage
them to use it and try to find the right
problems that machine learning can solve
thank you very much and I hand over to
Hoshi from iron
morning so today we're going to talk
about how we use machine learning at I
am to help improve our workflow for the
photographers and what is I am so I'm in
cyclic combination of our community so
that these are photographers we have
around 20 million photographers who
upload their content onto our platform
and we also have a marketplace where
people can sell their photographs for
for life thing which can be used by
brands for their PR campaign or
advertisement and to connect the right
photographer with the right buyer and we
build the technology and the technology
we build is called I envision so the our
vision focuses on understanding
everything about a photograph so what's
inside a photograph there's a dog
jumping a dog leaping a stick frozen
frozen lake atmosphere outdoors but we
also want to know how good the
photograph is composed how does it a
photograph uploaded by any person on the
web compared to the photographs taken by
professional photographers and that
that's what we captured through
aesthetics so we have a deep learning
model machine learning model which can
rate a photograph a score between zero
and hundred hundred means that it is as
good by a professional photographer and
so the core of training any machine
learning machine learning model is the
problem the problem is problem you want
to solve and machine learning model
needs an objective an objective in this
case would be given a collection of
images give me the right answer that I
expect and when you don't give me the
right answer go correct yourself so this
is the feedback that the machine
learning model gets and as you can
imagine the more complicated your
problem the more complex your model
needs to be and that complexity usually
translates into the size of the model in
megabytes or gigabytes and that's that's
a concern when you
to go mobile so if you want to run a
machine learning model on mobile you're
constrained on the size of the machine
learning model that can a phone can run
on a CPU or a GPU so that's an
additional constraint that the model has
to take into account you can you can
actually take an existing large-scale
big complexity model and then shrink it
down to D to the size you want there
there are many methods out there
quantization and compression is one an
analogy would be changing a PG PNG image
into a JPEG image for all practical
purposes their visual quality is similar
but the more attention you pay to the
detail you start to see the cracks and
this is this is all and well once you
have a machine learning model that can
run on the phone it can produce all the
information we need to know about about
an image you can detect the tags you can
detect what's inside the photograph but
you can also get a score a score how
good the for the photograph is composed
compared to professional photographers
and once we have all the information the
question is you can send all the
photographs to a AWS machine or a Google
cloud and get all the answers you want
why why go why bother with miniaturizing
your mobile miniaturizing your machine
learning model what's what's the
advantage why spend so much effort into
something that is already working for
you one key aspect is privacy so in in
our case we are working with people's
personal collection so it's your
personal photos it could be photos of
your partners it could be pictures of
your kids or private moments and it's
very tedious to upload your your whole
of your collection to cloud and get it
analyzed by the algorithm and the second
key aspect is that the current
functionality is that multiple people
upload their photos and they go to a
single server but with mobile phones the
we have a perfect scenario we have one
user and one computing machine the
handheld device and the third third
reason is it's available everywhere you
don't need to be connected the internet
you don't need to have Wi-Fi
and that that makes sense because give
it taking example of machine translation
you need the translation the most when
you're traveling abroad when you don't
have access to internet or Wi-Fi so you
want your machine learning model to be
run to be able to run everywhere so if
you are a machine learning engineer or
data scientist that's that's your part
of the problem but this is the problem
half solved now as the product managers
to managers turn to turn that into a
feature and that goes through various
cycles so once you have a prototype that
could come through a hackathon that
could come through an eternal effort you
build the first prototype and you let
the PM's play with it and they they can
think about how they can use this
machine learning model in a feature and
that's the place where either your
clients team the Android iOS and the
designer come together to build a
specific feature the next step is
actually getting user feedback so let
let real users of the app or the feature
play with the model and get their
feedback and this is this is the
critical this is a critical part of
actually retaining your machine learning
model and collect a new data set that
new data set should reflect the feedback
that you get from real users and that
the next stage is actually retraining
your machine learning model to better
fit with that in mind if we lost a
feature a few months ago : selects which
runs our deep learning models on the
phone you know it analyzes all your
photo collection you could have
thousands of photos and then then it
suggests what the best pictures you
should upload to the platform this makes
sense you don't want to upload your
private photos and also if you're a new
user - I am you see all the good photos
and good photographers and you get
intimidated what should i upload am I
good enough
this machine learning model helps us
help them find the best photos they can
upload onto our platform and this
entirely runs on tensorflow we haven't
yet moved intensive low light but that's
the it's gonna come very soon if you
have a machine learning model you can
assess its performance by various
metrics there is precision recall
toughen accuracy but you also wanna
measure the performance based on how
well your target feature is
in our case we wanted the users to
upload not just more photos but also
better photos and so when a user uploads
a photo that is recommended by a machine
learning model we automatically add a
hashtag to it called I am selects and
then we assess how does that how does
that photos with that hashtag compared
to everything else we have on our
platform and we saw that people were
actually uploading better content over
time I think that's it if you have
questions for for us please leave me
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>