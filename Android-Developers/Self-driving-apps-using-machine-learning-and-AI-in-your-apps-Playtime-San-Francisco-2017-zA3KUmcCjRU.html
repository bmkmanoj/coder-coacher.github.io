<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Self driving apps: using machine learning and AI in your apps - Playtime San Francisco 2017 | Coder Coacher - Coaching Coders</title><meta content="Self driving apps: using machine learning and AI in your apps - Playtime San Francisco 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Android-Developers/">Android Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Self driving apps: using machine learning and AI in your apps - Playtime San Francisco 2017</b></h2><h5 class="post__date">2018-02-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zA3KUmcCjRU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right first of all thank you all so
much for being here my name is Kevin and
today Montana and I are gonna talk to
you about machine learning now this may
not be the first time that you've heard
someone from google talk about machine
learning we we talk about it a lot
in fact our CEO sundar has gone as far
as to say that we will move from a
mobile first world to an AI first world
but when we talked to developers the
question that we get most often is how
to think about machine learning within
the context of their business
sure they've heard about alphago or
they've used google photos but what
about practical ways they can start with
machine learning today now we have a
diverse audience here today there's a
mix of business people and product
managers designers and developers some
of you might be experts in machine
learning others maybe have heard the
term but you're not quite sure where to
start or what all the fuss is about so
we're gonna break the talk into two
parts mine will be pretty short I'm
gonna give sort of a high-level
practical overview of machine learning
to make sure that everyone has context
for Montana's section Montana will then
share how instacart uses machine
learning and the real-world problems
that they're solving using ml okay so
let's get started so the first question
is why use machine learning at all and
to answer this I'd like to give a very
simple example what if I was to ask you
to write a program that tells the
difference between an apple and an
orange you might start by writing manual
rules for example maybe you'd count the
number of orange pixels in an image
versus the number of green pixels and
compare the ratio and that might work
for these two images but the problem
with writing manual rules is that it
doesn't scale and for every rule that
you can that you come up with I can find
an example that breaks that rule for
instance what if I gave you an image
that was in black and white or what if
instead of a green apple
I gave you an image of a red apple
accounting for all of these exceptions
and writing all of these rules would
require lots and lots of code and if I
gave you a similar problem in the future
like tell me the difference between
a raspberry and a strawberry you'd need
to start all over clearly there has to
be a better way rather than relying on
manual rules machine learning learns
from examples and the general way that a
machine learning model works is you take
a set of inputs in this case labeled
images you feed them into a machine
learning model in this case a
convolutional neural network and the
model makes predictions and if the
predictions are incorrect what happens
is it actually slightly adjusts the
model to make it more accurate generally
the more data that you put into a
machine learning model it's a more
accurate it will be what this allows you
to do is then you can take a new set of
data that's totally unlabeled feed it
into a machine learning model and the
model will tell you either that this is
an orange or an apple now I'm
simplifying a little bit here Montana
please don't kill me but in general when
you think of the workflow for machine
learning there are really three steps
that you need to follow the first is to
collect data so what does data mean data
comes in different forms their data can
be images or audio it can be numbers in
a database or a spreadsheet it can be
structured or it can be unstructured the
data collection steps specifically by
that I mean you know quantity of data
quality of data maybe which features you
choose to include in your model is often
the most challenging step to getting
started with machine learning when we
talk to developers this is the biggest
obstacle that they have to overcome and
Montana's going to talk about this a
little bit more in a minute the second
step is you need to choose your model
models come in different flavors to
their deep learning models and shallow
learning models there are pre-built
models or models that you can build on
your own there are models that need
label data and those that don't
this is often a step that I think
developers that are new to machine
learning are most intimidated by but the
truth is for most common machine
learning tasks there are open source
models that you can use so when you when
you choose a model what should you think
about the first thing is what problem
are you trying to solve there are
different ML models for different
problems the second is what data do you
have at your disposal and then the third
is what other considerations do you have
for example are there latency
requirements where you might need to use
on device machine learning
or are there compute restrictions the
last step is to predict in tune now
tuning really depends on your level of
sophistication if you're new to machine
learning like I said there are plenty of
models you can use that don't require
any tuning at all but if you're more
sophisticated there are things you can
do to tweak a model and make it more
accurate okay so that's great
what about real-world use cases what
problems can machine learning actually
solve so I put together some use cases
that I think are broadly applicable to
folks in this room this is not a
comprehensive list the beauty of machine
learning really is that it can solve
many many different types of problems
I should also caveat this by saying that
in some cases you can solve some of
these problems in multiple ways but one
way to use one framework that you can
use when thinking about what problems
you can solve for your specific business
is to start with what kind of data is
available if you have high quality
labeled data you can do something called
supervised learning and supervised
learning kind of has two buckets the
first is classification right identify
an image the second is regression you
know for the game developers in the room
may be forecasting LTV or predicting the
likelihood that a given transaction is
fraudulent even if you don't have high
quality labeled data you can still
conduct what we call unsupervised
learning tasks this is essentially where
the model where we'll infer patterns or
commonalities in data and you can use
clustering or Association models to do
things like segment your customers or
determine which product you want to
cross sell at the time of purchase so
I'm not gonna spend too much more time
here Montana has some really great
examples that he's going to share in
about a minute and it's easy to get
started like I said there are plenty of
pre trained in off-the-shelf models you
can use using the Google cloud machine
learning API things like vision speech
translation and natural language I'd
also encourage everyone to check out
tensor flow tensor flow is the best in
class and most popular open source
machine learning library it's the same
code that we use internally for most of
our projects internally at Google
finally since this is a mobile audience
I want to let you know that we're making
mobile specific investments as well so
three quick plugs the first is that with
mr1 which is coming later this year
we'll be announcing the neural Nets API
which enables hardware acceleration on
the device
the second is tensorflow light something
that we announced at Google i/o this
year we're also hoping to launch before
the end of the year tensorflow light is
essentially tensorflow that's optimized
for smartphone runtimes and then third
we're working on a set of top-level
api's that make common machine learning
tasks easier I'd also like to say if
anyone is thinking about machine
learning at all we have brahim who's our
PM for machine learning at Android as
well as a number of our engineers that
are going to be in the classroom later
please please go find them they'd love
to hear about what problems you're
trying to solve and answer any questions
that you have okay so with that I'd like
to I'd like to introduce Montana who's
going to talk about how instacart uses
machine learning thanks Kevin
so I'm always impressed when somebody
could summarize a very complex topic in
three easy steps it's my my artistic
friend did one better when I asked them
how do you draw an owl well if they said
first you start off with a circle and
add another circle and this is sort of
the head in the body and then you just
draw the damn out I'm going to try and
break this down those three steps into
quite a few more as we go through
several high-level overviews of when we
use supervised learning and instruct
when we use unsupervised learning and in
the end of the talk we'll go through a
detailed feature development use case
and we'll talk about how we start and
how we finish to begin I'd like to give
you some context of what instacart is
how our business works so that you
understand why we would use machine
learning to solve any problem we have we
deliver groceries from stores you love
in as little as an hour we connect
personal shoppers to our customers so
that they can deliver the service those
customers expect in real time we also
partner with hundreds of retailers
around the country so that we can shop
out of their stores we can provide
discount prices that way we have
deep integrations with their product
catalogs we host on our website it's a
fourth party in this marketplace are the
actual product manufacturers we partner
with them to give our customers
discounts coupons and other incentives
on the website so at the heart of this
is a ton of data passing back and forth
between a lot of parties and what really
drives this engine in terms of growth
and efficiency are deep machine learning
models I'm gonna walk you through the
customer experience to begin when they
get to the app they choose a store they
shop for their groceries they go ahead
and check-out in the app we have all
their payment information saved so it's
real easy they select a delivery time
that's convenient for them and after
that we've got it in the bag I promise
that's the only pun in this talk I think
on the other side of the transaction
there's a shopper the shopper lets us
know when they're available to do work
they'll acknowledge an order as it comes
in they'll go pick all of the groceries
for that customer
they make sure they scan every item for
accuracy this is actually a step that
improves their speed because it's easier
to time for your phone to tell you yes
or no when you're trying to decide 2% 1%
light hole all the labels look the same
so this is a nice improvement and then
the shopper actually delivers it to the
customers address we don't discriminate
between cats and dogs we're an equal pet
service I'd like to show you an example
of one of our teams that uses machine
learning pretty extensively
it's our search and discovery team which
powers our storefront that all of our
customers use if you think about search
when you're dealing with a product
catalog very minor changes in search
terms should have completely different
results page what you see on a milk
results page should be completely
different than a chocolate milk results
page and should be completely different
than a milk chocolate results page
that's hard if you just
using text so one reason we use machine
learning is to to extract more meaning
and provide more relevant results to the
beginning of any machine learning
problem is to break down all of your
input into specific features in this
case the features of all of our products
are is it USDA is it organic
what's the fat content what's the size
of the container what's the color of the
image all of these become features of
products and so we don't really think of
products as you know an ID or name but
there are a huge collection of
potentially dozens or more of these
features and the important thing about
all of these features is that they can
be quantified numerically we can for
color we can assign red green blue
numbers machine learning models only
work with numbers fundamentally they're
arithmetic all the way down so if we can
quantify milk in a series of features
they're embedded as numbers in our
models then we can actually apply really
advanced mathematics to get better
search results so the way that we
actually translate a search ranking
problem into a supervised machine
learning problem is we use the signal of
when a user adds a search result to
their cart if they actually decide to
buy something that we show them when
they search for a milk that's a
supervisor saying this is the correct
search result there's also an implicit
negative signal there of everything else
we showed them on that page isn't quite
as Milky to them so doing this with
libraries like tensorflow that Kevin
pointed out we can really improve the
situation and what's even cooler is that
as we launch new retailers and add
hundreds of new products to our catalog
every single day we can identify what
new products will also be highly ranked
search results immediately because we
look at these products in terms of their
features not in terms of any individual
products history so the fact that this
product has similar features to other
things that have ranked highly from milk
means this product should probably rank
highly for milk as well once you've
built one machine learning model and
you've got your data in a good shape
then you can start to think about all of
the other signals you have one of the
superpowers of deep learning is called
transfer learning you can take the
understanding that one model has
developed in this case our search
results model it understands that these
particular features are closely related
to the term milk or in this case these
two sets of features the ones that
represent Coca Cola and Pepsi are
closely related to the term Cola in in
terms of their features they're very
similar we could subtract them and get
zero in mathematical sense but what we
see when we have Coca Cola and Pepsi is
that people almost never add them to the
cart at the same time so this is another
signal they even though these two
products have incredibly similar
features they're never added to the cart
at the same time making them competitive
so now we can start merchandising all of
our website and people are looking at
Coke they should also see Pepsi when
people are looking at all of these
different types of items that are
similar we can take another signal very
similar but it's the opposite in this
case peanut butter and jelly are often
added to the cart at the same time but
they have very dissimilar features so
using this knowledge we have now about
what features are similar and how they
work we can recommend products after we
see you add peanut butter to your cart
then we can say hey you probably are
forgetting the jelly and that's a
different application than organizing
our storefront in the beginning all of
this requires that we collect the data
from the user acting as a supervisor for
our machine learning algorithms that are
continuously running and taking in new
data over time
I'd like to move on to an example of
unsupervised learning that Kevin
mentioned it's called clustering in this
case we don't necessarily start with the
answers we don't have somebody training
our algorithm with the correct answer we
start with questions we want to know
more about who our users are what they
want what motivates them some people in
the past would use demographic data to
understand their user base but that's
sort of irrelevant in many cases it
doesn't really matter you know how old
you are or what sex you are or what age
you are when you're talking about
behavior driven development and what we
want to do is we want to actually
segment our users not by these
superficial qualities but instead by how
they actually use the app and derive
value from it it starts just the same
way we break our users down into a set
of features it might be what platform
are they visiting the site on what time
of day do they come to this site funny
one is aol.com email addresses are
significantly different than gmail.com
email addresses those users tend to
engage with the site differently at
different times of the day and so even
at signup time we know a lot about a
user and how they're going to behave we
can use an unsupervised learning model
to begin to cluster these users and so
it will actually begin to pull out
groups of these people in this case I've
asked for three groups from the and
that's the only parameter I specified
for the model because I want to maybe
make a small medium and a large version
of my product and I want to decide what
should those three versions of my
product be in this case we've got Group
one which are green people group two
which are orange people and group three
which are blue people to begin with the
the unsupervised model has just told me
that blue people are very much like blue
people orange people are very much like
orange people agreeing people are very
much like green people but that doesn't
really help me too much what I need to
then do is do some deep analysis on the
green people versus the orange people
versus the blue people versus our our
normal overall global user base and what
I might find is that green people
prefer organic food orange people then
prefer spicy food and blue people really
love ice cream late at night with a
frozen pizza so that's one way that we
can use machine learning to plan how
we're going to build products that
people are going to engage with even
before we launch I'd like to go through
a detailed sort of analysis on what our
product development looks like this is a
case for picking groceries we do a lot
of picking groceries it's sort of where
a huge portion of time goes we have this
enormous catalog that shoppers are
handed in a single shopping list they go
out all these different stores that they
may never have been to before
and eventually they will complete the
order if we can save you know 10 seconds
20 seconds for order at scale this
becomes hugely valuable to the company
so we've looked at lots of ways to
improve their speed I mentioned the
barcode scanner was one incidental
metric but when we do these things at
scale it becomes very different are very
difficult we have hundreds of different
retailers that we partner with millions
of products thousands of stores actually
organizing the data on how every single
store is laid out is incredibly
challenging so you know we go to our CEO
after he says speed up picking I said
well you know if we could just be like
some of our competitors why don't we
just build our warehouses and then we'll
know where everything is and we can have
like robots do this they'll be super
fast these Apoorva said no that's not
our business model we don't build rare
houses we shop out of stores people like
so we said okay well maybe we can get
more data about each individual store
and maybe we can sort the shopping lists
that way and we can speed up shopping
time so we do a little weekend hackathon
project and it's a little little rails
app that lets us sort of take where baby
accessories are and put them on an aisle
number in the store and then some
shift lead and historic and drag and
drop all of our categories in order they
can say I'll 15 comes after I'll 14
after 13 and then when we ship a
shopping list this way we can put things
in the order that has been specified at
that store this is our baseline control
where we started if you notice it goes
up into the right which is generally
good in this case what that means is as
we add more items to the order the
individual time per item goes down so
this it's an improvement that if you're
shopping for 10 items in the store you
have to walk around the whole store to
only get 10 items if you're shopping for
50 items in a store you walk around the
whole store still only one time but now
you've got 50 items so we've known for a
long time that this is a key to our
business well we haven't known as if we
can change the shape of this curve when
we launched that experiment we actually
showed that there's a significant slope
improvement and we're very excited
unfortunately this is too expensive our
CEO says this works in one store that's
great but next week when they move
everything around again we're gonna have
to go do this over again and by the way
we're growing insanely fast so I can't
see us sparing the labor hours to do
this so we say ok fine Apoorva maybe
there's something smarter we can do we
have phones with GPS on them shoppers
are in these stores you know eight hours
a day
they're picking hundreds of times a day
maybe we can actually sort of map
implicitly using GPS we know the time
they pick the item because they're
scanning it with the barcode we know
relatively where they are in the store
with GPS if we see enough pics on that
product over time we can start to map
the whole store and we can start to
build up a detailed analysis of where
the baby diapers are in this storm once
we have a map like this for any given
order we can plop the dots on the map we
can solve the Traveling Salesman problem
we can actually solve it for small
orders we use heuristic approximations
for large orders
and the results for that we're exciting
but disappointing because we actually
saw a significant improvement over
baseline and now we're not paying
anybody to do this now this is implicit
data that we get for free it's just an
algorithm running but we know that it's
not really as good as what the humans
were able to do there's some
deficiencies in this algorithm that it
doesn't know where walls are so it might
ask you to walk through an aisle and so
we weren't we weren't quite ready to to
stop there
we started looking around for is there
tech that will give us more accurate
mapping information we're really excited
about things like google tango coming
out a lot of this AR is going to be big
for us it's going to really change the
way we do things but it's not really
ubiquitous yet so we can't expect all of
our shoppers to go buy brand new devices
to shop with us once we've exhausted all
of the options what do we do we kind of
smear some machine learning on the
problem and see what happens so - in any
machine learning problem you need a
formal problem statement we like to do
our problem statements in emoji in this
case you have ten products of some corn
- coffee and the goal of this machine
learning algorithm is to put those
products in the correct sequence so that
then we can predict this sequence for a
specific instance stated mathematically
the probability that the next item is
going to be the cookie given that the
last item is bread and your candidates
are the items that remain to be shocked
is is the function that we're trying to
learn with the machine learning model we
use a tensorflow architecture to build
this machine learning model in this case
you can see that our model actually
takes features from several different
things it considers what the features of
the shopper that shopping is how
experienced are they how long have they
been on shift how many refunds they
typically do to
in order how quickly do they technically
shop in order it looks at the warehouse
location that they're at so if you can
say how big is this place how
confusingly is it laid out do they
typically have things that are out of
stock that they haven't told us about it
looks at the previous item that they
just picked which in this case is bread
and it looks at the next item that they
might pick one really important thing
that I touched on earlier is this notion
of embeddings when you have features for
a product that are numerically
represented the model as it's
incrementally updated it embeds dot set
of features into itself and so in this
case we actually have two products that
are coming into this model its features
tensorflow lets us share that embedding
so the model only has to learn about
products one time which doubles the
efficiency the goal of this model is to
actually make a prediction of whether
the chocolate bar will be the next item
picked given that bread was the previous
item picked there at this retailer with
this shopper with enough examples we can
actually train this model and learn this
function we're gonna call this thing
this model that we've just trained
trained the score generator and we're
gonna set it up the top right hand
corner for now and go a little bit
deeper and how we use this score
generator to actually sequence an order
we generate a score for every product
given the input features and then we do
that for every remaining product inside
the availability set you can see that
it's going to predict several different
scores some things are very probable to
be picked next some things are less
probable to be picked next we take the
most likely one of that softmax is a
fancy mathematical term for that we get
a prediction and we actually use
cross-entropy which is a way to teach
the model that these answers are
constrained to the available ones you're
looking at now there are millions of
other
in our catalog I don't know if you're
familiar with Silicon Valley if anybody
watches that the the hot dog no hot dog
machine learning classifier he couldn't
actually make it Universal he couldn't
train it so that it can actually do more
than one thing our classifier actually
can consider all things because it's a
single model that represents all stores
all products confined to the very very
small list of available products
remaining in your shopping list that's
the cross entropy function gives us that
little extra nudge and so given that
model we can now actually make
predictions every step of the way that
corn will be the most likely item picked
first
once that given that they've just picked
corn what will be the next item that
they pick with all the rest of these we
repeat that until we've actually
exhausted the entire list of available
products and then we can show that to
the shoppers so the question is this
sounds really complicated does it
actually work and the answer is
smashingly
we're very very excited with the results
here to give you an idea if there are
125 million households in the US if 5
percent of them do business on
interesting art they typically shop for
groceries about once a week if we can
save about a minute a week then that's
618 years of labor that we save every
single week with a model like this once
we have a model in production like this
it's really easy to tweak it to add more
features to see which ones make sense
which ones are harming the the models
performance to add extra hidden layers
we went through about seven iterations
on this one and we actually doubled the
performance of it compared to the
baseline so we're at over a millennia
saved per week now which which were very
happy about
so that that's all I've got I'm gonna
turn it back over into Kevin who should
be able to give us some closing notes
before lunch
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>