<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[See Description] Creating our Machine Learning Classifiers - Python for Finance 16 | Coder Coacher - Coaching Coders</title><meta content="[See Description] Creating our Machine Learning Classifiers - Python for Finance 16 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>[See Description] Creating our Machine Learning Classifiers - Python for Finance 16</b></h2><h5 class="post__date">2015-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IzDPLu1oKfo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what is going on everyone welcome to
part 15 of our finance with Python
tutorial series using quanto pain and
zipline
in this tutorial we're just gonna be
building on the last tutorial so if you
are lost up to this point please go back
to the previous tutorial and ask
questions because it's only gonna
compound on top of this so we've got our
features now and here's our features
right these are our feature sets now
with machine learning at least for
supervised machine learning what you do
is you have features you've got labels a
lot usually you've got your features
assigned to this capital X and they've
got labels which are assigned to a
lowercase Y but you can actually call
them features and labels it does doesn't
really matter people will understand
what you're saying now so we've got our
features now we need to create the label
so the label is basically what we use to
say hey with this list of features this
is what it created okay and so the
machine learning what it's going to do
is it's going to go through and it's
going to start taking all these features
and it's gonna be like okay well when
you have features that are like of this
pattern basically this is usually the
outcome okay and then in and that's what
it's going to do for each set of
features so we take features and labels
to Train it and then when we're all said
and done what we do is we say okay a man
today here here's the price here's the
last you know nine prices basically
these are the percentage changes so
those are features tell me what its
gonna be and then the machine learning
is gonna be like we think it's gonna be
this okay and then we'll either buy or
short based on that okay so we've got
our features we need to make our label
simple enough label is going to be
whether or not the end price is greater
than the start price and so start price
I'm gonna call this begin price because
start price to me should be like the
zero with element but it's not the zero
element it's like the second-to-last
element okay actually the begin price
will actually be the last element and
price would be like the last element
plus 1 so we'll take begin price end
price in the way that we're going to do
this is we're just will keep it really
simple right now we could go later on
and add more labels to it so
for example will do if end price is
greater than begin price this means with
this set of features and percentage
changes the ending price from the point
of investment was higher so this would
be that's a good thing right that's
where we want to invest so if that's the
case we're gonna say label equals 1
otherwise label equals and we'll do
negative 1 what I'm gonna do anything
else we'll do bar plus equals 1 that's
totally fine and then what we need to do
is in our global kind of x and y's and
XY pertains to the stock so every day
per stock we're gonna do this so it's
going to be machine learning that's fit
to that specific instrument basically so
X Y we get we're gonna add that to X &amp;amp; Y
so we'll just do it right here say
capital X dot append features y dot
append label that's it the only thing
that we would want to do now is if you
are mr. Li over here you should see that
because of this this is a while loop and
this while loop is dictated by this bar
okay and so while that bar is less than
the length of that this loop will run so
is it conceivable that at some point
this try somewhere in here is gonna fail
maybe we're gonna we're gonna but not a
number in here and numpy is not gonna be
able to round it we're gonna fail well
we're gonna be stuck in an infinite loop
because bar is not + equals 1 so what
we're gonna do is in this exception as
well if the exception is hit we're gonna
say bar plus equals 1 and that will look
sorry unless oh my goodness there we go
so bar plus equals 1 and that will make
sure we don't wind up in an infinite
while loop doing nothing so we've got
everything up to this point we're all
set now we've got the labels we've got
the features so we're ready to
or algorithm so we'll come down to the
very at this point here and we can start
with like one classifier so we could say
for example CLF equals and we can come
up here we can really pick any of these
classifiers we can start with a random
forest classifier and we'll just paste
that in there so the random forest
classifier what it does is it makes
basically these decision trees and
what's neat about the random for
basically the random forest classifier
to put it really simply is like the
combination of a lot of like really
really weak classifiers and as you'll
find if you ever dive deep into machine
learning there's a penalty for you've
got processing and like the cost of
computing and the speed of computing
versus the reliability of the results so
why it's what a lot of people do what
we'll do here is we combine classifiers
well random force classifier basically
allows you to say hey I want 50 crummy
classifiers
but then what we're gonna do is we're
going to take the out of those 50 crummy
classifiers what's like the most
reliable result that everyone you know
all those classifiers come to consensus
about and that's the answer that's
basically how random forest classifier
works so we'll say CLF equals that and
then in inside the random forest
classifier you can pick how many
classifiers you want to use the default
for here is 10 we're gonna use that I
don't really see any reason to change
that but if you wanted to change it
again you would go to SK learn and let's
just do random forests click on that
here we go we come here and we're like
hey how do we change this well BAM there
you go number of estimators and then
basically number of trees in the forest
these are your decision trees the
defaults 10 we're going to use it but
say you want 50 go for it but just know
50 is gonna take you know roughly 5
times longer to process so keep that in
mind so we'll just stick with a default
10 that's totally fine so that's our
classifier now what we're going to do is
we want to
first we'll take we've got classifier
we'll do the last underscore prices so
this is the list of the last prices
that's gonna be the price underscore
list and then we're gonna slice that and
it will be minus context feature
underscore window to the end so that it
those are our last prices and then we'll
take we'll say okay cool now our current
underscore features are equal to
basically this right here so let's just
take this copy-paste and instead of
pricing list this is applied to last
prices and again here to last prices so
we're moving all the way through here
and so those are our percentage changes
and we'll continue rounding to the one
decimal point cool and then so we've got
current features done now what we're
gonna do is you can either engage in
pre-processing or not generally machine
learning is gonna be more reliable and
quicker if you do pre-processing so I'm
gonna show you guys how to do it I
encourage you to try with and without
pre-processing and you can see what fits
best for you but the way that we're
gonna do it is we're going to append the
current features to the list of all the
features we have so everything is scaled
with each other so we're gonna do
capital X dot append and what we'll do
is we'll append the current features
list okay and then we're gonna say x
equals pre processing processing dot
scale X and what this does is it at
least attempts it makes a really valiant
effort to scale all of our features to a
negative one to positive one now if we
have outliers they will still remain
outliers outside of negative one to
positive one but generally the focus of
pre-processing is to put all features
within that range now it just so happens
the reason why I'm saying that you know
pre-processing may or may not really
help here it may actually cost us more
than we gain
is our features are already basically
between that alright our features are
already between negative 1 and positive
1 for the most part because their
percentage change over the course of
days so we're already probably fine but
we'll do it anyways so we scaled X now
we need to go back and redefine our
current features and the training set so
we're now we're gonna say again just
current features equals X minus 1 so is
that last set of features there that we
appended just moments ago and then we
also redefine X as X is equal to X
everything up to the negative first if
element but not the negative first if ok
done now we do CLF donít fit and dot
fit is where we actually train the
algorithm so we train the algorithm
against X and then Y for the labels so
again this is where we're saying okay
here all the features that we know of
and here all the labels that we know to
apply to these specific sets of features
and now we'll fit it we train it based
on that data and then once we fit we can
make predictions so we as ap equals CL f
dot predict and then we can say we want
to predict against the current
underscore features and the prediction
comes out as an empire array and it's
just a one element numpy array so just
to reference that specific element we
just say the zeroeth element
bam that's going to be a 1 or a negative
1 so now what we can do is we can print
and then let's print prediction and then
we'll print P so hopefully we don't hit
errors let's go ahead and run this and
see what what comes our way
where are we printing and we're printing
these features I should probably stop
doing that right here so we'll stop
printing features let's scroll down
hopefully we're gonna get some
predictions here I'm not seeing our
predictions
we stopped logging mostly because of
this the seen prediction we'll see you
and we're not hitting errors either so
we should eventually let's see are we
putting this underneath now Wow okay
it's outside of a while loop for stock
loop were in there not quite sure why
we're not showing let's say let's cancel
this one more time it's probably just
because every day they probably give you
so many things that you can log out
because otherwise what people probably
would do is steal the minute bar data
yeah it's print it to console and then
steal it so every day they only they
limit how much you'll output to this log
I'm guessing yeah okay
that's probably what was hitting us
there so we got our prediction and
here's all of our predictions so cool so
we're getting these negative ones and
one predictions so now in the next
tutorial what we're gonna do is we'll
take these predictions and we'll make
trades based on those predictions so
that will be pretty darn cool so we'll
go ahead and cancel this from running
and that's what we're going to be
talking about the next tutorial if
you've got questions or comments up to
this point please feel free to leave
them below otherwise as always thanks
for watching thanks for all the support
and subscriptions and until next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>