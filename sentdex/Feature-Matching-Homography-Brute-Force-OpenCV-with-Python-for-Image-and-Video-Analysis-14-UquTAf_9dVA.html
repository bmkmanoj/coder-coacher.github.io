<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Feature Matching (Homography) Brute Force - OpenCV with Python for Image and Video Analysis 14 | Coder Coacher - Coaching Coders</title><meta content="Feature Matching (Homography) Brute Force - OpenCV with Python for Image and Video Analysis 14 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Feature Matching (Homography) Brute Force - OpenCV with Python for Image and Video Analysis 14</b></h2><h5 class="post__date">2016-01-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UquTAf_9dVA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what is going on everybody welcome to
yet another open CV with Python tutorial
in this tutorial we're going to be
talking a little bit more about feature
matching in the past we've shown
template matching where you can apply a
threshold and be you know slightly
dynamic but not very especially if
things are at a different angle or
different lighting or different rotation
and so on so in this tutorial going to
talk about feature matching which will
allow us to start with a template and
have an image just like we did before
only this time our template in the image
can have different lighting different
angles and different rotation so as an
example I'm going to use the following
images so one is just a pile of pillows
and dog toys the other one is just one
of those pillows and the template image
is actually a different angled some a
little bit different lighting a
different rotation so we're going to try
to match this pillow to that pile of
pillows and only get that match there
now you can use your own images if you
want I highly encourage you to do that
if you want to use those image these the
same images on using you can go to
Python program at net there's a link in
the description of this video for this
specific tutorial and you can get the
images there so the way that we do this
is kind of thought through form of brute
force matching it's going to match
everything it's going to sort the
matching based on the best matches
basically but it's going to make a lot
of plausible matches so you'll see what
I mean towards the end when we show it
but it's basically a form of brute force
so we're going to go ahead and import
one more thing here we've got CV - enum
PI's as NP but import mat plot
matplotlib pie plot as p LT as well now
we're going to load in both our images
so image one is going to be CV - M read
and we're going to read in open CV -
feature - matching - template jpg as 0
then we're going to take that paste and
this will be image 2 and then
instead of template we just rename this
image
those are just my name's you can use
your own image of course so there we go
we have our images and all that now
we're going to define our little
detector of similarities so or D equals
c b2 or or by underscore create now
we're going to create our key points and
they're descriptors so KP 1 is going to
be equal or actually KP 1 - des 1 is
equal to orb dot detect and Compu temple
in okay so take that copy paste 2 2 and
2 so those are our key points and our
descriptors now we're going to find the
key points and their descriptors with
our orb detector so B F equals C V 2 dot
B F matcher and C v2 dot norm underscore
Hamming this is just the method we're
going to use and cross-check is going to
equal true so that's our bf match our
object just being saved as bf now we're
going to find the matches and then we're
going to sort them based on the
basically their distance or accuracy
maybe or confidence I'm trying to have a
hard time finding a good word on that
but anyway matches now equals force
equals bf match des 1 s 2 and then 1
we'll sort them matches equals sorted
matches and then the key for these sort
will be lambda lambda X X dot distance
okay so we've got matches of the
descriptors and we've now sorted them
basically from most likely a match to
least likely a match so then we're
prepared to show this so image three
will see me to draw matches from image 1
K P 1 image to K P 2 matches and then
here you can decide how many you want 10
is probably the safe bet
none and flags will just say 2 and then
p LT in show 3 and then we'll do a peel
to that show here and this will show us
the first 10 matches so it might be a
little hard to see on the video here but
sure enough we have matched relatively
accurately we've got the butthole here
apparently so it's just a good idea to
find find the matches so like this
purple line does indeed go to the tail
this little rock here sure enough goes
to the same rock this spot appears to go
to the same spot and then we've got like
a little match on the ear which again as
well is a good match so that's good but
what happens if we let's allow for more
than 10 let's do 30 well we load up 30
and we're probably going to see yeah
we've got a few matches that aren't
quite what we wanted right so most of
these are good yeah the pillow but then
we start matching like this exact spot
on this eye and it tracks all the way
back to here and they're basically that
little spot yeah it's like it's like
basically identical but not right ok so
most of the matches still went to the
pillow object so then you could like
edge detect or something I don't know
and come up with ok this pillow object
has the most match you could also like I
don't know light up the pillow more just
keep you know say the most likely you
know location for the pillow is right
here something like that
but anyway we've got a few false
false-positives going on so if you let
too many come through you're going to
probably have a problem but at least
with like ten that was pretty good and
as long as you keep the number low you
probably really will be fairly accurate
and if your image is a hot really high
quality image you could probably match
even more than that especially if both
of your objects are like really high
quality and have a lot of features to
them
this pillow didn't really have too many
features and then all these other things
have all kinds of little designs and
stuff on them so it wasn't too
surprising that matches were made so um
I wonder what if we said instead of zero
zero we said one and I'm just looking to
see if that I'll actually even work
right out of the box shouldn't do these
live tests all right okay so here's a
good example
I don't know hopefully you guys have
been following since the beginning but
matplotlib displays things in RGB in CV
displays BGR so what has happened here
is this is matplotlib trying to display
as RGB but being fed BGR data but anyway
that's okay let's try to make a four
matches and just see if adding the color
makes any significant difference I see a
lot of false positives anyways so the
same kind of false matches are still
being made bummer
anyway um so that's it for the feature
matching and the next tutorial we're
going to do is return back to the idea
of foreground extraction this time what
we're going to do actually is extract a
foreground based on motion so things
that are moving we can actually pull
them to the front or say hey that's
where the activity is let's zero in
exactly on that so that's what we're
going to talk talking about the next
tutorial if you have questions or
whatever on this you trejo feel free to
leave them below otherwise as always
thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>