<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Investigating Bias - Natural Language Processing With Python and NLTK p.17 | Coder Coacher - Coaching Coders</title><meta content="Investigating Bias - Natural Language Processing With Python and NLTK p.17 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Investigating Bias - Natural Language Processing With Python and NLTK p.17</b></h2><h5 class="post__date">2015-05-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/h44hI7lr8w4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody and welcome to the 17th
Python with ML TK for natural language
processing tutorial video in this video
we're going to do one last look at some
some of the data and our accuracy before
I move on and actually apply this to a
real-world situation moving forward
rather than testing historical data so
the question I have before we move on is
uh our accuracy are we how accurate are
we so we have a basically a binary
system here either something is one
thing or it's the other thing true or
false in our case it is positive or
negative
so my question is well with the 70%
accuracy that could mean a lot of things
that could mean we are 100% accurate on
um let's say over 75% accurate average
that could be 100% accurate on negative
stuff but we're 50% accurate on positive
stuffs or our average is 75 well we
wouldn't we would want to dig in deeper
if that was the case so what we want to
know right now is what is the
distribution between our accuracy and
positive information our accuracy on
negative information so to do that we
can kind of actually do this rather
simply we can stop shuffling our data so
now we know what's positive what's
negative so the first thousand documents
here are positive or negative and the
second thousand documents are positive
so what we can do now is we can come on
down here we've got a training and
testing set let's train against again
the first 1900 and we can test against
the last 100 so from 1900 onward and so
this will be all positive data and we
can really let this whole thing play out
if we want it's not totally necessary
well at least we can cancel these from
running so let's run this and see what
our accuracy is against you know
positive data and then we can run it
again
and check it on negative data what is
this what is this testing set five to
zero I'm not quite sure why that was
there hopefully you guys don't have that
not sure why that was their testing set
five zero that probably came from down
here and I'm just not sure what so okay
anyway back to the data while that's
running let's modify the other code that
we need to modify actually we're to get
a result here you go
original naivebayes algo accuracy is 49%
so we're actually less than half of the
time we'd be better off just like
randomly guessing they're slightly
better with the multinomial naive bayes
54 it could be argued that we're testing
against a slightly smaller sample size
unlikely that that has a huge impact
honestly so anyways this was for a
positive data positive o2 data example
now let's do a negative data set while
this is still playing at least one of
these has 60% positive data now we'll do
negative data so the training set will
be basically anything from 100 onward
and the testing set will be up to 100 so
that'll be the hundred negatives holy
what Wow
the SG DC classifier was a hundred
percent accurate on the positive data
I'm just not buying it that's insane
can y'all believe that holy apparently
at GDC maybe it might be the case SG DC
just chooses positive every time I don't
know laughter I'm gonna have to run this
one again after we run the negatives
we're gonna run this one more time and
see what it's the cast at greenie in
this thing gives a hundred percent I
can't believe that that's insane
it's always a scary thing when you see
stuff like that
kind of want to like run this in a
different console or something's is
taking forever that's okay we're already
on new SVC so the voted classifier at
the oops at the end of the day are voted
accuracy on positive stuff is 64% which
isn't too bad
oh the SGD CS us I mean I can't envision
a way that could be wrong other than it
predicts positive every single time but
then if that was the case we would be
like around 50% well this would always
be around 75% accurate and I don't
recall it always being around 75 but
that could be interesting
so anyways we'll leave that for now what
was the other thing we were going to do
or actually would have to be it would be
like 50% on average anyways what am I
thinking okay so so this was for
positive now let's go ahead and run this
for negative Oh
save and run whoops I should have done
that let's just do it one more time so
we don't screw anything up so this is on
negative data so we just basically
redefined the data sample so this will
be on negative data again and from this
the answer here so okay so this one at
least we're starting off about 80%
accurate so I mean we can run this test
like you know five ten times on each one
just to kind of get a good idea but
probably with the voter we'll get
relatively accurate stuff so um still I
got to go back and check this SGD see
we'll see I guess we'll know in this in
this one if SG DC is like zero percent
accurate right thank that will give us
our answer and that'll be interesting
something's going wrong there if that's
the case but anyway you know sixty-four
percent accuracy and then if this one is
somewhere in the 70s it's not really
worth looking into but at least
initially it appears pretty clear to me
that
this one is a lot less accurate on the
positive data as it is on the okay SRS
GT classifier is unreliable we need to
toss that one out or figure out what's
going on there so trying to figure out
how we would have 70 let's see before in
theory we should have always been at 50%
so maybe it's having it because we
trained it training data training data
now we're training it on a good data set
so we're not training it sniper training
only on positive stuff but I'm still not
it's not clicking with me why the SGD C
classifier would be anything about 50%
accurate or at least close to 50%
accurate on the other test that we ran
something else has to be wrong with the
code so have to look into that or just
toss that one out and maybe toss out the
original algo as well so we have stuff
an odd number because we have plenty of
naive Bayes algos being used here so
including this zero percent accurate
algorithm we have about 65 percent so
man I'm really irritated about about
this boat anyway well we'll toss the
original and we'll toss the SGD C
classifier I don't have to play with
that on my own time and see if I can't
discern why we are only returning a
positive evaluation there and why that
for some reason wasn't totally clear
before because we were using a random
sample so before SGD c should have
always been around 50% if it's always
predicting positive so I'm not sure why
that's all of a sudden changed the
training data is still about and it's
relatively balanced it's more so
positive but not hugely we could cut
this off we could say the training set
is like 100 to 1900 then it would be
balanced but I don't really see why that
is
being such a huge but even then this one
wasn't about I don't know anyway I'll
look into it if anybody else can figure
it out feel free to post it below fully
by the next video I'll have an answer
but we'll see anyway that's that so so
we're kind of confident here clearly
though um at least with this basic one
although with the voting you know if you
threw out this one hundred percent
accuracy I think we would find that the
positive one is a lot less accurate and
the negative one is a lot more accurate
I mean we're talking about at least by
fifteen percent so it's a decent
distribution so you actually you know
going down the down the line we might
want to require you know for a negative
four so you know we're more accurate on
negative stuff so you might require a
little less confidence on the negative
stuff but we're a little Lessing in act
or a little less accurate on the
positive stuff so you might actually
raise the bar on the requirement for
confidence before you you know choose
something so anyways that's that I just
wanted to show you guys uni it's good
idea to always look at that especially
we have like binary data you might as
well train or you can train against all
the data but test against you know one
sample at a time because then this is
actually a really great reason why
something is wrong with our SG DC
classifier had we not done this test we
might not have figured that out although
we should have I still am not buying how
wasn't always 50 percent but whatever
but without doing that we wouldn't even
even come across this air and we'd be
trucking along with this steady air
although it might actually be the case
that it's better off to have something
always voting for positive because
because clearly positive it was a little
lesson accurate that's that was actually
probably leveling out the scores a
little bit I don't know
anyways that's that question your
comments leave them below as always
thanks for watching and until next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>