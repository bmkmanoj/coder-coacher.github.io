<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Regression Training and Testing - Practical Machine Learning Tutorial with Python p.4 | Coder Coacher - Coaching Coders</title><meta content="Regression Training and Testing - Practical Machine Learning Tutorial with Python p.4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Regression Training and Testing - Practical Machine Learning Tutorial with Python p.4</b></h2><h5 class="post__date">2016-04-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/r4mwkS2T9aI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what is going on everybody welcome to
the fourth machine learning and third
regression tutorial where we left off we
had defined our or at least figured out
what our features in our labels were we
haven't quite yet defined them but in
this one we're going to define them
we're going to actually pass them
through to a classifier train and test
that classifier to see how we do so
before we get started let's go ahead
make some imports also I'm just going to
put Kwan DeLand math on the same line
now we're going to go ahead and import
numpy as NP numpy is just a nice
computing library it's going to allow us
to use arrays Python doesn't actually
have arrays but numpy will let us do
that also from SK learn we're going to
import pre-processing this gives us
quite a few things but we're actually
going to be using the scaling scaling
your data aspect is usually done on the
on the features and the goal is often to
get your features to be between
somewhere between negative 1 and a
positive 1 this can just help with
accuracy as well as just processing
speed or how long it might take to
actually do the calculations when we get
there I'll explain why you may actually
just either choose not to do
pre-processing or maybe it's just too
you know too tedious to incorporate it
in reality but anyway we'll show it
because it exists and it can be useful
next is cross-validation we're going to
use cross-validation to create our
training and testing samples it's just a
really nice way to split up your data
into it'll shuffle your data for you and
which helps with that with statistics
basically so you don't have a biased
sample and then also it helps separate
your data it's just nice time-saver
basically and we're also going to bring
an SVM that we're not to the support
vector machine part and we're not I'm
not going to explain support vector
machines just yet we will get there but
you can use an SVM to do regression and
this is probably we are probably not
going to come back to regression so
we'll just show it as an example using
it.also it's useful because I'll show
you how frigging simple it is to change
the algorithm that you're using
so anyways SVM
next we're actually gonna bring in
regression so from SK learn dot
underscore model import linear whoops
linear regression okay now we are ready
to rhumble so the first thing that we're
going to go ahead and do is define our x
and y so generally features and labels
are defined features will be a capital X
labels will be a lowercase Y X is going
to be equal to numpy array of DF drop
and we're going to drop the label column
right so your features are basically
everything except for the label column
and we can do this because DF drop
returns a new data frame so it's
returning a new data frame it's can
being converted to a numpy array it's
being saved to the value of x now the
value of y is our labels so you might be
able to surmise that we're going to say
MP dot array DF label easy enough okay
so now we're going to scale X so x
equals pre-processing dot scale X okay
now think about it so here we're scaling
X before we feed it through the
classifier but let's say we feed it
through a classifier we have a
classifier and then we're using it in
real time on real data well let's say
you're reading in that data and you feed
it through your classifier but before
you do that you really have to have
scaled it and to scale it it's all
scaled together so it's like normalized
with all the other data points so in
order to properly scale it you would
have to include it with your training
data so keep that in mind if you ever go
into the future and you're actually
using this you need to scale the new
values but not just scale alone but
scale them alongside all your other
values so this can add action while it
can help with the training and testing
it can actually add to processing time
especially if you're doing like any sort
of like for example but with
using stock prices you're doing like
high-frequency trading you would almost
certainly skip this step but anyway
there's that now we're going to redefine
X as being equal to X to the point of
where we got where we were able to
forecast underscore out +1 so this is is
it includes all the points because
remember we shifted to you know this
point zero one you know so that's like
what 1% basically so we made that shift
so we just want to make sure that we
only have X's where we have values for y
and so we do that and then we're going
to say D F dot drop in a in place equals
true and then we're going to do we're
going to define Y is equal to NP R a DF
label and let's go ahead and let's print
LEM of X and then Len of Y so just make
sure we have the correct lengths here
right so we don't have the correct
lengths so let's close this and really
probably at this point so we actually
may not need to have this let me rerun
that real quick so I'm thinking yeah
okay so so because we won't have a label
for the reason why I was doing this
shift initially was because we wouldn't
actually have labels but we dropped
those labels here are those those rows
here so we didn't need to do what we
were doing there okay so we've got our
X's on our Y's and we don't need this
hopefully okay so now what we're ready
to do is create our training and testing
sets so we're going to say X underscore
train X underscore
test why underscore train why underscore
test equals cross-validation dot train
underscore test underscore split and
what you're going to pass through here
is the X's the Y's and then how big of a
test size do you want and we're going to
do point two so 20% of the data we want
to actually use as testing data so again
what this is going to do is is going to
take all our features on our labels
remember kind of the order it's going to
shuffle them up right keeping X's and
Y's connected right so it's not going to
shuffle them up to the point where you
lose accuracy so it shoves them up and
then it outputs for X training data wide
training data X testing data and Y
testing data so x training y train we
use to fit our classifiers so let's do
that next so first we're going to need
to find a classifier so we're going to
say classifier equals and we'll use
linear regression to start and then to
fit or train a classifier just see a
left fit and you fit features and labels
so which ones should we use well we
would use the X train and y train now
we've got our classifier we can actually
use this classifier to predict into the
future do all kinds of crazy stuff but
first we probably should test it right
200c is so now what we would say is CL f
dot score so fit is synonymous with
train score is synonymous with test so
we'll use X test Y test so real quick
why might you want to train and test on
separate data well if you train a
classifier to predict based on the same
data that you test against when you go
to test it it's going to be like I've
already seen this information so I know
exactly what the answer is right so
that's not good you don't want to do
that it's no different than if you know
if you were in school or whatever and
you were the same questions that you
were asked in class were the exact
identical questions on a test right if
you missed those then you just weren't
paying attention or something so here we
have our score and what we're going to
say is
thence equals CL f dot score you could
also maybe replace confidence with
accuracy accuracy that's probably a
better choice because confident you not
only you can kind of get to values not
necessarily from this one but as we go
into the future you can actually compute
both accuracy and confidence as two
different values so we'll go ahead and
keep accuracy there and let's print
accuracy so let's save and run that wait
for root and the accuracy that we got
out of this is 0.96 so ninety-six
percent accuracy on predicting what the
price would be shifted one percent of
the days so this would be let's go ahead
and print forecasts out so we can see
what that value actually is so with
linear regression just four just so you
know the accuracy is going to be the
squared error and we'll talk about that
coming up next as we break down how
linear regression actually works so this
is actually still 30 days in advanced so
it's pretty interesting that you'd still
be that accurate but okay so it's okay
yeah so now what if though a couple
things first of all its squared error so
this this actual percentage of accuracy
is not necessarily like you would get
rich off this algorithm it's almost like
maybe directionally accurate but that's
actually that's pretty darn pretty darn
accurate so let's say though remember I
what we also brought in SVM let's say we
wanted to use the support vector
regression which is not simple linear
regression so we're not going to
actually break down but what if we
wanted to use a different algorithm so
we're using linear regression here's how
easy it is to switch our algorithm svms
B are done so now we're testing a new
algorithm and this one does actually a
lot worse Wow
let's run that
more time let's see if it still is
inaccurate yeah Wow
that's that's interesting that's a huge
difference anyway you will actually kind
of find that that happens now for
example in with machine learning like
with support vector regression for
example you have these things called
kernels so you might say kernel kernel
equals I want to say the default is
linear so let's try a polynomial kernel
so you can change these kernels in there
and you can kind of fiddle with it and
see if you could get better values oh my
gosh
so 51% accuracy is like just barely
better than average or better barely
better than like clique coin toss let's
see if we can actually get under 50 no
wow that's that's a significant variance
oh goodness
anyway as we can see it's e support
vector regression is not what we're
going to be using in this case anyways
but so here's another decent example
about why you'd want to follow this
tutorial series though like what's a
kernel alright so we'll be explaining
what a kernel is when we get to support
vector machines but anyway what this was
meant to show is how easy it is to
switch between clatter algorithms and
this is the case whether you're doing
regression or whether you're doing
classification or clustering you can
switch out rhythms really quick so you
you definitely want to like test the
algorithms
oops do we do Oh SVM linear regression
okay so anyways there's that one more
thing to talk about before I let you
guys go is with the various algorithms
you'll want to check the documentation
so let me pull up the documentation for
linear regression for example and what
you're looking for is which algorithms
can be threaded so in this case we are
looking for and underscore jobs this the
question is how many jobs can we perform
at any given time and so right now it
may not be totally obvious to you why
with let's say linear regression we can
thread the heck out of linear regression
as opposed to a support vector machine
where there are ways that you could do
it you could like do it in batches or
something there are ways that you could
do it but it's just not inherently as
easy as something like regression is to
thread it massively and run it in huge
parallel operations but with regression
it totally is and you'll see why later
on but anyway so yeah so this is just so
if if you were following along and let's
say you're skipping the true breakdowns
shame on you but but to find out if it
really quickly if the algorithm could be
threaded you would just go to the page
right you can just search linear
regression support vector machine on
Google you'd find yourself on this page
and you're looking for n jobs so this
just means how many jobs how many
threads are we willing to run at any
given time so the default let me think
here so the default for regression is
actually 1 so this means it's running in
I hate to use the word linear here but
it is running linearly right whereas we
could run it in parallel by doing n jobs
equals and you could say okay I want to
run at least ten jobs at a time so I
will run ten jobs at a time and in
theory the training and testing part
actually I'm sorry just the training
part would be significantly faster or
you can use negative one and this will
just run as many jobs as as possible by
your your processor so anyway speaking
of which processor wise as you follow
along this series if you get to a point
where like I'm getting it really fast
and you're going really slow like if
you're following on like an older
computer or a laptop or something like
that it may take you a little longer to
run some of these things this one should
be pretty quick but it's conceivable
especially when we get into like deep
learning you might want to think about
spinning up a server or something like
that but that's obviously way down the
line well we'll talk about it when we
get there I suppose but just keep that
in mind so anyways just remember this
but then again just one more plug about
why you'd want to dig in deep which
we're about to be doing
is to understand which algorithms you
can do this with so exam for example
with deep learning like linear
regression not just in deep learning
like all the algorithms really there's a
lot of regret a lot of like linear
algebra that goes in because a lot of
these things can be super threaded and
you can run many operations at once and
like so as we grow in processing power
that becomes very useful to have
calculations and methodologies that can
that can scale like that anyway that's
it here in the next tutorial we're going
to be talking about predictions into the
future using scikit-learn and then after
that we'll actually going to be breaking
down linear regression and doing it
ourselves so stay tuned for that if you
have questions comments concerns or
whatever up to this point feel free to
leave them below otherwise as always
thanks for watching thanks for all the
support and subscriptions and it's he'll
next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>