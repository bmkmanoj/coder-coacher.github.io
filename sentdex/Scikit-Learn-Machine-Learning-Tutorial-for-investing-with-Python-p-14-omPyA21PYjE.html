<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Scikit Learn Machine Learning Tutorial for investing with Python p. 14 | Coder Coacher - Coaching Coders</title><meta content="Scikit Learn Machine Learning Tutorial for investing with Python p. 14 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Scikit Learn Machine Learning Tutorial for investing with Python p. 14</b></h2><h5 class="post__date">2015-01-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/omPyA21PYjE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody I welcome to the 14th
machine learning with Python
scikit-learn with investing tutorial
video in this video we're gonna be
basically building on the last video and
we're gonna add some features add a lot
more features here as well as talk about
another issue so a pretty important
issue is the following let's just bring
up an example so with say Apple
computers
obviously I've already kind of brought
up the issue of say look what kind of
sector are they in is this technology is
this Bank as mining companies is a
consumer you know do they make shirts oh
this is you know like air possible or
something like that are they a
restaurant like Chipotle something like
that you want to classify these things
into sectors but another issue is just
kind of general normalization so
typically a machine learning people say
hey we we think that you want to have
all of your data points be between
negative 1 and positive 1 now it's ok if
all if you need a little bit more
granularity there so to speak or at
least magnitude and you can do you know
negative 5 to 5 that's okay it's
acceptable but what's challenging is if
some of your data goes from you know
negative 1 to 1 some of your data goes
from negative 15 to 9000 and some of
your data goes from you know negative 1
billion to 72 billion that's it's ok you
can still kind of run that through your
machine learning algorithm but it's not
not best practice so to speak so for
that reason we want to use some sort of
scaling of our data and kind of get
everything as close to normalized ie
it's close to basically kind of the same
range as everyone else so the first
thing that we're gonna go ahead and do
is talk about that now we there's a lot
of ways you can normalize your data one
way I can think of would be say with our
pandas dataframe we for each column we
could say you know each column you could
find the minimum and the maximum and you
could say the maximum is 1
negative one boom done that's a problem
because you obviously are from time to
time you're gonna have massive outliers
so then you can say okay okay
the average is zero and then we'll
convert you know the real average to
zero or let's say you know point zero
zero zero one and then everything else
will convert using the same formula well
that's okay but you're still gonna have
this scaling issue where some things are
gonna have a different maximum than
others as far especially when you
consider variance so then you're like
okay okay okay we're gonna use standard
deviation we're intake standard
deviation and we'll apply this to our
formula won't take standard deviation
and then I'll use the deviation from the
average to the max and we're gonna do
that that's gonna have a lot of problems
too so as usual I'm just gonna say that
someone's already done it for you okay
and with scikit-learn it's no different
we're going to use a simple simple
function here so we're gonna use this
function on X which is what needs to be
normalized and we're just going to say
now we're gonna redefine X as X equals
pre-processing dot scale and we're gonna
scale X okay and now we need to actually
import pre-processing so from SK learn
import SVM and then also we're going to
import pre-processing so pre-processing
is a scikit-learn kind of module but
it's of its own that helps you pre
process your data before you use it for
training it's really helpful we might
touch on some other things but for now
we're just mostly interested in this
scaling function so we will scale our
data with that and we could really just
take it from here so we're still going
to to 100 so so for example we can we
can run this really quick I think this
pops up pretty fast so you can already
see that it looks almost identical but
it's been scaled I can't remember how
off this stuff was but okay so here
we've got a 5 and here is a 10 so let me
close this and we'll take away the
scaling just curious if this makes a
huge difference in this graph right so
you can see that now from before we were
in you know
almost single digits here is you know
relative integers but here we're
actually we're going all the way up to
600 this one goes up to all the way a
hundred and looking at our output it
looks almost identical it really does so
what do I have like two features or
something that's okay but again as
always with machine learning where it
really shines is with a lot of features
so we'll go ahead and leave this there
and now what we want to do is use a
bunch of features so as usual I'm gonna
go ahead and just say I see no point and
you guys making this list yourself so
I'm gonna just copy and paste the list
and you guys can I'll put it in the
description as well as usually I post
the sample code from all my videos on
Python programming net so you can also
check there but it will be in the
description of the video what you
absolutely need so I'm gonna copy and
I'm gonna do paste and this is a huge
list of features if you'll see I've kind
of made it its own constant in theory we
could call features actually more better
features like that doing my best to be
Pepe but it's really hard to be Pepe
when you're making a video so sorry guys
anyway features caps and then this is
all the features that we're going to
consider I believe it's 35 features
we'll come down here and uh we'll say
we'll just say actually better need to
put it in there okay just make that an
empty empty and all we need to do
actually is capitalize this feature so
features like that and so now we will
take all this data we're gonna pass it
through X&amp;amp;Y and then we're going to
basically run it now we'll leave this :
100 there for now I already think is
necessary actually I think this should
all process pretty darn fast so I'm just
gonna comment out that line we'll return
to it if we need it but we should be
able to do that pretty quick we're not
gonna be able to graph this anymore so
I'm gonna I'm always gonna comment it
out I think I'm gonna delete this we're
simply not gonna be able to graph
anymore as though it was the point so so
we do X Y that builds the data set
we specify what our classifier is here
we're training our classifier now I'm
gonna go ahead and add some stuff here
so in general it's a kind of test how
things are going you do a training and
then you do a testing and testing isn't
forward testing in the sense where we
actually put this in real time and we
see how it does actually testing is done
where we know what the answer is we
don't tell the computer what the answer
is we only tell the computer what the
answer is after it's already made its
prediction and then we can see were you
right in your prediction or weren't you
so we're gonna say we're gonna have a
variable here called test size and test
size is gonna be you know how much of
this data do we want to have as testing
data so let's just say 500 testing data
and then we're gonna say X y equals
build data set that's totally fine let's
go ahead and print the lane of capital X
so the length of X the classifier stays
the same and then fit basically we fit X
minus actually sorry X to the colon
minus 500 or now I'm blanking out yes
right okay so the training this I see
I'm confusing training and testing
anyway X Y and then again colon to the
and it's not minus 500 is minus test
size - test size and this will probably
be the last video I film today brain is
just too slow she looked a fit right so
this is what we're doing is we're
leaving the last 500 um you know data
samples we're leaving those we're not
gonna test on those because that would
be really silly right if you test the
same data that you trained on well
that's a bit of a mistake don't you
think and and some people think well as
long as it's not exactly sound like what
if 80% of your data is non testing data
but then 20% is the testing data like
won't it kind of average out no it will
not don't do it it will always skew your
results
so anyways see you left out fit then
we're going to go ahead and do Karev
it's underscore count Frette count is
gonna equal zero and in each time we do
anything right we're gonna say
congratulations I wanted to correct
count so then we're going to say 4x in
range and that's gonna be in range of
anything from 1 to the test underscore
size plus 1 or anything in that range
we're gonna do if CL f dot predicts
predicts capital X minus X and then 0 so
that's just basically what sealife
predict it always gives you the answer
in a list and we want the zeroth element
that's the actual prediction so if that
if the prediction is identical to the
value that we know it's true which is y
to the negative x we're going to say
corrects counts plus equals 1 then at
the very end we can do something like
this print accuracy accuracy corn comma
and then we do correct counts / test
size times one point zero zero now let's
make sure that's a full yep and that
should be it
so I cannot remember if we said we're
doing the whole yeah we are gonna do the
whole thing so let's go ahead and say
run that see what we get okay so our
entire list is two thousand nine hundred
ninety one samples long and we see our
actual accuracy in prediction is just
over fifty percent it's fifty three
point or so let's make our sample size a
little larger let's say we do let's do
1500 run that and so then we have a
slightly more accurate reading there
let's do a thousand don't see if we how
we do there all right
so at about a thousand ish we see that
we're doing okay now this could be
actually the result of a lot of things
one thing that you might consider doing
it well now that wouldn't change
anything actually okay so now that I'm
thinking about it we we do want to do
one thing and that would be a fad but
after we've organized all our data in
the data frame what we're going to want
to do is we want to random lines that
data frame so for example when we look
here our data frame starts at a and it
goes all the way down to xanga and the
problem is say we do you know say we use
half of the stocks for training half of
the stocks for testing what happens well
at about at this point that you know
every stock up to jwn is trained on and
then every stock after that is tested on
that's not good that's not the best way
to go about this so before we go
training and testing probably what we
need to do is shuffle these up a little
bit okay so so that doesn't work that
way so cuz it could be the case that
these stocks you know the lower numbered
stocks are just different versus not any
reason who knows but basically what
we're doing is we're training with a
handful of stocks and then we're testing
on a handful of stocks that are not the
same stocks that we just trained on so
that's just inherently a huge problem so
we can't do that so curiously though I
do wonder like what if you trained you
know like a test size we'll say is let's
do the lap like 100 ok now I can't
really do that so if we did this right
if we just said testing is XY and we ran
that and then yeah you get so you get
your answer
so we've tested or we've trained on all
of the data that's available to us and
then we just tested against the data
that we've trained again so some
the test we actually trained against and
we see our accuracy is 66.7% so even
with the randomization dog is over here
about to snore or something on fun
things in a fight or something to sleep
anyway even if at our best-case scenario
we randomized this data we might get up
to sixty six point seven percent
accuracy but that's actually not that
bad all things considered even 60%
accuracy I'm pretty excited about that
that's that's not bad considering even
though you know the topic of machine
learning people say is very it's very
complex it's really not that complex
especially what we've done so far I mean
within a few hours here of watching my
my videos all of you are up to this
point and hopefully see that that was
pretty simple so I'm pretty surprised at
our accuracy sixty-three percent at this
point but I do think it would be best to
randomize up at least our testing sample
but then that causes problems because
actually what we want to see is into the
future not into the past so you know
that that causes some trouble now a few
other things we have a generic lack of
data we don't really have that many
stocks 500 stocks is nice but that's not
the best then also just looking in our
stock files I mean you know some of
these companies we have like one update
a year or something like that a lot can
happen in a year so one of mine some
more data also I did do some looking
around sadly no one kind of pointed me
in the right direction on videos but
maybe someone still will in the future
but there are a few api's that connects
to Edgar and there's a few examples of
how to do it that would be really really
cool to connect straight to Edgar which
is the SCC Govs based in a database of
just data so I'm really excited about
that there's also a lot of data we can
get from quantal as far as the in terms
of super sets and stuff so we can do
some cool stuff there so we don't have a
lot of interesting things to think about
and do in the future
we also have this slight probable issue
with basically testing against stocks
that were not trained against so we need
to figure out that
and then probably do some other stuff
there's a few things that we actually
want to do they also might consider
doing some more pre-processing as well
but most of what I want to do is get
some better data it's some more data as
well as fix the issue that we have down
here also we have a few issues as far as
underperforming outperform is concerned
should we use the last value or should
we use value each step of the way if we
are of the mindset that we you should
use underperformer outperform at each
step of the way we actually need to
shift that entire column per stock
because at the point of outperform that
means we should have invested in the
stock at the previous set of values okay
so from six months ago that's when we
need to have have invested if we invest
at the point about performance that
doesn't necessarily mean that you're
gonna get anywhere at all so anyway
that's gonna be it for this video I hope
hope you guys enjoyed I'm pretty excited
that with this kind of crappy code
apparently we have some darn good act
you know above 50% is exciting when you
know when you haven't written very good
code here 66 pairs sixty-three percent
accuracy is pretty darn good now before
we get into making our code any more
advanced than it already is there's one
more problem
so 66 oh let's uh let me fix our issue
here there we go that's a that's a
fallacy
we can't can't actually do that I just
was curious what the answer was so let's
say on a thousand data sets or actually
is about sixty percent not bad
sixty percent could mean a lot of stuff
though what if for example you know we
might pick you know sixty percent of
time we might pick winners that
outperform the market but what about the
other forty percent of the time are we
picking you know people that still you
know kind of perform pretty well with
the market so for example you know sixty
percent of the time we pick out
performers or actually I'm sorry I'm
sorry
sixty percent is not picking out
performers sixty percent is deciding
whether it's an out performer or under
performer so let's say our actually
sixty percent at picking out performers
in the areas or I'm sorry identifying
whether they're in our performer an
underperformer what if let's say we find
a handful of stocks that we believe are
out performers we're gonna be you know
about sixty percent accurate on that but
then how strong of an out performer are
those companies right and how bad of an
underperformer are the ones that we
picked and got wrong right so if this
strategy is good just recognizing in
general good company structures
fundamentally then in theory even the
under performers should underperform but
at but still perform pretty close to
market and the out performers in theory
probably perform close to market but
they might perform way better but that's
the question is this is just a number of
our accuracy what matters the matters
more than your accuracy is was the
actual performance when you actually you
know by ourselves so a really good point
made by gosh I can't think of the guy's
name right now he wrote anti fragile and
stuff but anyway
and his point is you know you could be
your your accuracy could actually be ten
percent but if the things that you're
right on you know give you times ten
back then congratulations and conversely
you could be right ninety percent of the
time but what if that other ten percent
of the time you you lose you know fifty
times all the money you just made that's
no good your that's just worthless so in
the case of investing or trading or
whatever your accuracy is actually
pretty insignificant what really matters
is your performance and how well did you
actually do in practice so we we need to
build with this kind of investing in
mind you actually have to build a back
tester and test it against actual data
and see not only how accurate were we in
our predictions but what was the actual
outcome as far as making investments on
those predictions because those numbers
could be totally different we could find
that this strategy is you know sixty
percent accurate but it loses everything
in a month or we could find that even
though it's sixty percent accurate the
losers so to speak are fairly losers and
the winners are massive winners we just
don't know it
so anyways those are some things to
think about moving into the future
anyway if you guys have any questions or
comments on this video please feel free
to leave them below otherwise as always
thanks for watching things for all this
forth and the subscriptions and the
donations and until the next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>