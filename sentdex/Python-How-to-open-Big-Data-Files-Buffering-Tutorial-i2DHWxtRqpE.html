<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Python: How to open Big Data Files Buffering Tutorial | Coder Coacher - Coaching Coders</title><meta content="Python: How to open Big Data Files Buffering Tutorial - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Python: How to open Big Data Files Buffering Tutorial</b></h2><h5 class="post__date">2013-12-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/i2DHWxtRqpE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">everybody what is going on welcome to
another python tutorial sorry it's been
a little bit since I put out a you know
pure Python tutorials been about couple
weeks I've been super busy with algo and
automated trading of Bitcoin I actually
already have one investor and another
one he's interested that's been going
really well we've been having some great
results there so actually a lot of my
attention and focus has kind of gone
that way plus we had the holidays it's
things has just been pretty busy so
hopefully you guys all had are still
having some great holidays also I do
have a gift for you guys and this one
actually comes from someone named Igor
vassal chicag sorry if I mispronounced
your name I don't think he'll be
watching this video anyways but yes it
comes from him looks like he actually
works for EMC Corp which is pretty much
the definition of Big Data so it's
fitting he passed us some pretty great
info information on what we're going to
be talking about today which is
buffering so all of the videos and quote
unquote Big Data videos that I've ever
put on here are all really considering
file sizes that as single computers
amount of RAM is going to be able to
handle
so most of like the data files that I
use that I consider big are better put
probably large may be you know three
gigs is pretty much the biggest one I've
ever really messed around with and
that's that's three gigs is a pretty
nice stock output file that's that's
your tick data right there
so the question though is how would you
open up a file that is far greater than
say then your RAM right so let's say a
hundred gigabytes or a terabyte or also
how should you open up a file that's two
gigabytes even so without you know
because you don't have to read the whole
file into memory so even if if you don't
have like a huge file you can at least
save some memory by not reading
literally everything into memory
immediately so far only really one video
in this series with machine learning the
one where we did the pattern recognition
that was the only video that really
required that we use the full amount of
data to be read into memory
since it referenced all of the data
constantly to like make all of the
patterns but you want to you know
necessarily have to reference all of the
data either we just chose to but most of
the time you should be able to read uh
you know like a large amount of data
into memory in chunks right to make any
of the changes that you need to make or
perform analysis or whatever so to do
this we utilize buffering so what is
buffering well the idea of buffering is
to like ration the amount of input from
a source so you can think of it like in
a day you might eat you might be able to
eat you know 2,500 calories but you want
to be able to consume that much in one
sitting or you shouldn't be able to ah
some people can anyway you shouldn't be
able to uh you have to buffer right and
eat maybe 500 here 750 there etc right
your computer is the same so it just
kind of makes sense to do this buffering
right so you want it yeah back to the
food example you wouldn't really you
want to open up the fridge and take out
all of the food at once
you can't possibly eat all of the food
so why would you take it all out at once
because you're just going to put it all
back because you're not gonna be able to
even reference that you know so that's
where the buffering comes in right you
open the fridge which gives you access
to make let's say 15 sandwiches but you
just grab the stuff necessary for one
sandwich you make one sandwich and then
when you're done consuming and digesting
one of those sandwiches you're set to do
another one right so let's do that with
your programming and opening up of a
file so what I've got here is a couple
of files I'll just show them to you guys
we have a file I've called big data's
and it is 50 gigabytes so just a little
bit more than my RAM I've got 16 gigs of
RAM here we go you total and installed
here and I'll bring this over when we
start reading it because in theory well
we would max out our RAM but also show
you guys as we read this 2.47 gigabyte
file you won't even notice a change in
the memory at all so we'll be doing that
now so those are the files that we'll
we'll use and as you can see both of
them basically big data is just a bunch
of these like stacked on top of each
other basically but they're Bay this
just tick data for gbp/usd
4x so let's go back to our tutorial here
and let's go ahead and get started so we
don't actually need to import anything
but what we will do is we'll say the
output file equals open and we're going
to open up file we're just going to call
it example output dot txt and we want to
open that with the intention to appendix
since we're going to be doing this in
chunks right so let me bump this up just
in case we need the space and now what
do we want to do well we're gonna say
with open and what do we want to open
now because that's our output file but
what do we actually want to read right
we're going to read off what we'll get
to this one at the end but first let's
just read this file right here so this
is within my RAM but I'll show you why
it still matters and why you would want
to use this even if you're using files
within your memory so we're going to say
with open gbp/usd underscore standard
dot CSV that's the name of that file
what do we want to do well with open you
have three parameters that you can in
theory put in the first one you must
have the second one you don't have to
have but you would have you know either
append read write whatever but then
there's a third parameter that we've
never covered and that would be
buffering that's the buffering parameter
now if you had you know like you say
okay we want to open it with read then
for buffering you could just straight up
like put in a value but for now we'll
just leave the second parameter empty
and we're just going to say buffering
equals and then here um let me just put
it in and we'll put two million bytes
the way this works is if you put a
number one there it means it's going to
buffer by line so it's going to line
buffered when it if you put just one any
other positive number you'll get a
buffer of that size in bytes so here
we've got two million bytes that we're
going to buffer by but then you can also
if you could put like no parameter or a
negative parameter in there it's just
going to use system defaults so it's
going to attempt to pretty much just
open it up
now so we'll make that smaller now the
idea here is you would want to make this
number as big as possible so this will
literally only buffer by two million
bytes right so that basically translates
right to 2,000 kilobytes or two
megabytes so very tiny usage of RAM
right we could go by 20 megabytes if we
really want it but I'll just show you
this tiny tiny buffering amount now the
next thing that we want to do and
obviously the larger you make this
buffer the the more efficient it's going
to be generally but for now we'll just
leave it pretty low just so you guys can
see there's pretty much no impact on RAM
at all so you would open that and then
we're going to say as f so with opening
this file and we're going to just say as
f you know as f for file what do we want
to do what we're gonna say for line in F
we want to do something right so like um
let's just say we do want to perform
some sort of analysis on here
and our analysis well actually here's
what we'll do we'll actually just modify
the file so this file right here this
gbpusd file it is about 2.5 gigabytes
but we could probably knock some of that
file size down by just removing gbpusd
we know it's gbp/usd it says it in the
file name so we already know what we're
dealing with so there's it's not totally
necessary that we leave that little bit
of text there so we could already knock
down some file size just by doing that
you can also perform analysis you could
you know you could append a moving
average to the end or something like
that
but for now let's just let's remove
gbp/usd and see how much you know space
that we save just by doing that
so let's come back here and so we're
gonna say for line in F what do we want
to do well we're going to say save line
equals and then we're going to say line
dot replace and then we just want to
replace gbp/usd and then also a comma
like within the quotes but we want to do
that and replace it with replace it with
nothing and the reason we want to do the
comma is because it's comma separated
here and so we really want to get rid of
why can't really highlight it but we
want to get rid of all this the reason
also I'm not opening this up in notepad
as I literally can't it's too big to be
opened up in nope
anyway moving on now uh coming back here
save loan replies because obviously if
you had it in notepad you could run this
function in notepad pretty much with the
ctrl H you know find a replace function
there anyway um well obviously like I
was saying you could you could do like a
moving average or something else like
that on this this data or any or other
form of analysis really or you could
save it to I don't know a database which
would make a whole lot of sense anyway
moving on out dot write or actually
output cut right and what do we want to
write to this output file which is this
example output text which we're up
opening with the intention to append
what do we want to write well we want to
write that new lines so save line and
then I'm basically once we're all done
with this loop basically right here uh
we need to start just Bank my Mike we
need to do output close and we're going
to close out of the output file so
that's pretty much it now we can go
ahead and save it and then we'll run it
and this will actually our buffer size
is pretty small maybe what I'll do is
we'll run this one and it probably going
to take like a minute or so just to get
through all this at two megabytes a line
re for each buffer but anyway the next
thing I'll do is maybe we'll add a zero
to this and see how much quicker it goes
I don't really want to stay here and
just Lowell the whole time so maybe I'll
pause it but then you guys won't get a
feel for how long it took mm I guess
I'll pause it
alright it is all done let's go look at
it uh here's our example output
so we knocked off point four point four
four gigabytes right so four hundred and
forty megabytes got knocked off of this
thing that's pretty good I would say so
uh what I want to do wonder if I can do
this yeah okay so it was created two
minutes ago modified one minute ago so
that tells you it that process took
about a minute to run through sounds
about right
so now let's go ahead
let's go back to our script where is it
and then we could say instead you know
that uh we could add really we gonna -
let's add two more zeros so 20 megabytes
- now it's 200 megabyte buffer oh I
forgot to show you guys my ram - I'll
bring that over on this one so we'll go
ahead and run that this one probably
make my ram bump a little bit but not
not as much as it 2 gigabytes so anyways
let's go ahead and save that uh we're
currently 49 percent memory so we got
we'll run it and bring over the memory
so you saw it jump from up 49 to 51
which makes sense it's 200 megabytes
this time that we're running but
naturally not too much else is going on
right from 49 to 51 on a 16 gigs of ram
that's not too shabby so we're still
waiting I'm hoping this one will finish
quicker but we'll see and that's the
kind of stuff that you'll probably find
a very like kind of like what we were
showing with compression there's
probably a very nice sweet spot
depending on a lot of factors that I
probably can't even explain but at least
like within compression the once you get
past a certain point it just doesn't
make much sense to spend any more
processing time compressing you know
past a certain point yeah this one's
still taking a while this one might end
up actually even taking a minute to uh
to happen so it might not make much
sense to use 200 megabytes at all
I guess I'll pause it alright so that
one finished honestly it seems to me
like that took just as much time uh if I
change the file name so I guess we can't
check you'll just have to take my word
for it that pretty much took a minute I
would say so
anyway didn't really seem like we saved
too much by making the buffer like huge
so now what we want to do is the next
thing I want to do is you show you guys
so now what we want to do just to show
you guys that it's friggin possible
we're gonna go ahead
and access this big data's file now this
one will definitely pause on I just want
to show you guys that it's possible so
I'm just going to make a copy basically
a big data's file now and then just show
you guys how long it took I guess we'll
do the created and then modified since
it creates the file immediately cuz it
opens it with the intention to append
and then you guys can see it project you
might want to know but I like ten
minutes or something to do it but the
point is that it can be done and the
other thing well actually here's what
I'll do for you guys this will make it
easier so what we're going to do is it's
literally called big data's text right
so it'll just call this example put two
and then we'll say big data's and it's
actually die txt or txt and we'll leave
the buffering there for line in F we can
literally just let's just say we want to
print out the line so this is the next
thing - it's like when you start wanting
to like perform analysis it takes a
while just to read that stuff into
memory and then you can start doing your
analysis whereas here you'll see in a
second this is gonna start doing
pretty quick so even though well we
opened it up as what 200 megabytes list
I guess we'll leave it as 20 that's
pretty small so let's save that and now
it's going to print out the line so it's
gonna spam the crap out of us
let's go ahead and run it and drag it
over as you can see we're already just
spitting out I mean this happened
instantly because of the buffer we only
had to open 20 megabytes not well I
can't even get this to move I can't even
get it to stop this is brutal
hopefully my mic is still working cuz
break it anyway I like couldn't even
like click the X button now it's pretty
funny uh
so anyways there you go I mean we just
opened up a 50 gigabyte sized file
pretty much instantly using buffering
just because we didn't actually open up
50 gigs we opened up 20 megabytes so
that should be enough I guess I'll copy
it just just the curiosity in me I made
this giant ass file so I really want to
know how long is it going to take to
make a copy of this file so we might as
well actually just find out I'll make an
example output 3 we won't print the line
and I'm trying to stop if I really want
to leave it at 20 or if I should make it
bigger I think we'll just leave it at 20
megabytes honestly uh so save that uh
and I think I'll just actually run this
prompt so yeah so anyway we'll go ahead
and get it started there's the file out
where's it example 3 so ok so that's
that I guess what I'll do is I'll just
pause this and then whenever it's done
I'll show you guys how long that
actually took to make a copy of that
file
but anyway stay tuned alright guys that
actually took a lot longer than I
thought I do I forgot that we were
making that edit to the the file but we
did that as well so as you can see we
actually you know if you had a 50
gigabyte stock file that was spitting
out this you know tiny bit of text on
every line well you almost saved 9
gigabytes that sounds pretty nice anyway
this actually took more like 30 minutes
so let's click on properties here uh so
it was created 34 minutes ago and it was
last modified 6 minutes ago so it
actually took you know 28 minutes to
actually finish the job but anyway as
that was happening there was really you
know no change to memory and it was able
to go through this 49 you know almost 50
gigabyte file with relative ease
obviously it took a while but it did it
so anyway that's going to conclude the
buffering tutorial video in kind of you
know the points to why you might want to
do that
again thanks to Igor for showing me how
to do that hopefully you guys learn
something new as always thanks for
watching thanks for all the support in
the subscriptions and until next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>