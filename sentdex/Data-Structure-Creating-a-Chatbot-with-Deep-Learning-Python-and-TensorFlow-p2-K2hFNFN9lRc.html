<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Data Structure - Creating a Chatbot with Deep Learning, Python, and TensorFlow p.2 | Coder Coacher - Coaching Coders</title><meta content="Data Structure - Creating a Chatbot with Deep Learning, Python, and TensorFlow p.2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Data Structure - Creating a Chatbot with Deep Learning, Python, and TensorFlow p.2</b></h2><h5 class="post__date">2017-11-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/K2hFNFN9lRc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what's going on everybody welcome to
part two of our chat bot with Python and
tensorflow tutorial series in this
tutorial we're going to be doing is
beginning to build our database that's
going to store our basically our parent
comments - they're paired best reply
comments so the reason why we really
want to do something like this is
because well first of all a lot of these
files are way way way too big for us to
just like read into RAM and then create
the training files from even just
individual months but chances are you're
gonna want to eventually if you wanted
to create a really nice chat bot you're
gonna be wanting to work on many months
of data so maybe possibly billions of
comments you do have that your disposal
so when that's the case we probably want
to have some sort of database now for
the purposes here just to keep things
simple we don't deal with my sequel
servers or any other big database server
type thing I'm just gonna use SQLite
it'll help us get the job done but you
can feel free to use pretty much
whatever you want but I'm gonna use
SQLite here now before we get too deep I
just want to address kind of what what
all our data should be looking like so I
want to bring up here this is basically
if you downloaded the reddit data and
you know extract it it should look
something like this you should have
years you know basically 2007 to 2015
again bigquery does have data all the
way up to recent like you know last
month whatever that would be and also if
you do go that route just know that your
formats going to be totally different
than ours so you'll have to adapt what
you're doing if you want to go that way
but possibly if someone does share some
way to officially pull bigquery I'll
probably append that to the end of this
tutorial series because there's there's
also multiple models that I'm working on
with chatbots so I also just I'm pretty
confident that there will be some follow
up videos anyways enough that if you
click on any of these normally you'll
just have all these compressed files but
if you extract them it looks like this
basically
and then these files contain just a
bunch of samples each sample looks long
this alright so this is just one sample
as you can see there's a bunch of data
here it's obviously a JSON it's key and
value though so yeah you know there's
there's a lot of first of all wasted
information here so just putting into a
database will severely decrease the size
of this data right you just have one
column name and then all the data like
you're basically you know this much data
becomes just this right that makes more
sense also we don't need all of these we
don't need like link ID for example we
don't really need name we might be
interested and created we're probably
not interested in when it was received
author flare we probably don't care
about you might we probably don't and so
on obviously we do care about like
things like score and ups and downs and
maybe if they were gilded or not or
stuff like that we might care about
those especially like if trying to make
some sort of a very specific bot same
thing with like the subreddit or
something like that if you want it again
to create some sort of really specific
type of chat bot for now I want it to be
a fairly general but I care about at
least score one thing to note though is
I'm fairly confident score is
miscalculated downs are always zero so
score is always miscalculated if I
recall right I can't remember if that's
truly the case but anyway it's really
quick to test I forget all I know is
that take it with a grain of salt
because it's improper anyway I'm pretty
sure it's the case that downs are always
zero but I can't remember if you can
take ups and then score you know
basically ups - the actual score would
equal the downs or if score also always
equals ups I can't remember but anyway
just know there's some sort of flaw
there anyway let's continue so working
in Python now what I'm gonna go ahead
and do is we're just gonna start
building out the code that we're going
to be using here so let's go ahead and
import sqlite3 for our database import
JSON and then we'll go from date/time
import date time and really SQLite
obviously database JSON to read that
format basically and then date time
we're really just going to use this to
output where we are as we're kind of
outputting just some some logging
information just so we know where we are
as you might imagine going through these
huge files can take a lot of time so
sometimes I just like to put simple
outputs that kind of tell us where we
are at that at the time moving along
we're gonna say time frame I'm gonna say
we're going to use 2015 Oh 5 so remember
the format of the files when you
download them basically so we're gonna
basically be grabbing this one they all
have RC I don't know what our C stands
for us probably not release candidate
but it's reddit comments maybe I don't
know anyway I don't know what it stands
for but anyways they all have that same
format obviously this is May of 2015 so
this is the one that we want
alternatively you could take lists of
time frames and then iterate through
them build the database the same way I'm
about to build the database so once
we've done that also I'm gonna have SQL
transaction we're gonna have this
because you don't want to be in
specially like when you know you're
gonna be working with like millions of
rows you don't want to insert rows one
by one if you don't have to that's
really inefficient instead you want to
build up a big transaction and then do
it all at once and it will be just gobs
faster so that's what we're going to use
that for now what we're gonna do is
build out the connection that's going to
be SQLite 3 dot connect we're gonna
connect to something database not seeing
the database that would still work
though taht format and in time frame so
this will just be a database called
whatever the month and year is again
alternatively if you wanted what you
probably could do is like this well for
example probably what we're in a color
table is like parent reply or something
like that instead you could actually
make the database parent reply and then
each table name could be the the month
or something to me I don't really think
the month and year is all that valuable
like there's no real reason why you
would separate those out so I'm not
really gonna do that but you could if
you wanted anyway then we're gonna
define our cursor so that's just
connection dots cursor okay now we're
gonna go ahead and use creator table so
it's fine creates table
and then this is just going to be your
typical see to execute create table it
not exists and the tables to be parent
reply and then we're gonna have all of
our columns so first of all we're gonna
have parents ID and this or this is
gonna be text type and then also it'll
be our primary key yeah this is gonna
run way off the screen I think you can
get away with a triple quote here we're
gonna find out just so I don't have to
run everything off the screen so much
we'll see how it goes
so yeah so parent ID now we're going to
need the comment comment ID and that
again
that's going to be a text and a not a
primary key but it should be unique
unique and then we're gonna have parent
&amp;amp; parent will be also text text type and
then we're gonna have the comment itself
so the reply comment will be text type
I'd also like to go ahead and log the
subreddit just simply because I do kind
of see in the future that's gonna be a
useful thing to be tracking different
subreddits have different ways of
talking and if you want a smarter
soundings chatbot you could go with more
scientific and engineering types of
subreddits if you wanted a more
nevermind I'm not gonna get myself in
trouble well we'll stop at that anyway
you could get different types of
chatbots the unix time that's just gonna
be an integer and then finally we'll go
ahead and take the score which also
should be an int okay so with that we've
got our query and of course I did just
run it off the screen anyway but yeah so
with that we should create the table if
it doesn't exist so then what we do at
the end here is if
we'll just start our main loop here our
main chunk I guess maybe name equals
main let's go to create table so this
will just create the table if it doesn't
exist the other thing to note is if the
database doesn't exist when you attempt
to connect to it it creates a database
that's why we didn't have to create any
database that's obviously just SQLite
and then finally this obviously will
only create the table if it doesn't
exist
and so it's relatively cheap to run it
so we'll go ahead and run that so that's
all for now what we're gonna do is in
the next tutorial we'll actually start
working through I'm not sure if we'll be
able to insert any of the data too much
because there's a lot of cleaning up of
the data and stuff but yeah in the next
tutorial we'll at least start buffering
through the data and start kind of
cleaning up that data and get it ready
at least to insert it into the database
anyways if you have any questions
comments concerns whatever feel free to
leave them below otherwise I will see
you in the next tutorial</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>