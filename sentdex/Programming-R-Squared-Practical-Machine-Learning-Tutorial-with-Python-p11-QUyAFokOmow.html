<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Programming R Squared - Practical Machine Learning Tutorial with Python p.11 | Coder Coacher - Coaching Coders</title><meta content="Programming R Squared - Practical Machine Learning Tutorial with Python p.11 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Programming R Squared - Practical Machine Learning Tutorial with Python p.11</b></h2><h5 class="post__date">2016-04-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QUyAFokOmow" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody and welcome to part 11
of our machine learning tutorial series
in this video we're going to be building
on the last one which is where we
learned how to calculate the r-squared
value or the coefficient of
determination value and this value is
the it's the value of how good of a fit
is our best fit line okay so that is the
equation now how do we actually go about
calculating it so a big part of this
equation is actually squared error so
we're going to create a new function
that calculates squared error so we're
just going to add it down here and so
this will be defined squared error and
the squared error is the difference
between the Y's original or a ridge will
say and the Y's line so recall that
squared error is the distance between
whatever line is in question and the
points it's the amount of y distance
that's the error and then we square that
error so so we need the actual points in
the actual spot on the Y line so that is
that so then what we're going to say is
the let's actually here what we need to
do is return the sum of the let's see
some of the Y's line - the Y's original
orig okay squared so that that would be
your squared error for the entire the
entire line and in you know this this
equation is relatively simple but I want
to give it a function of squared error
just so I think it's a little easier to
call upon but feel free to to do what
you want but of course
you can get the original data points by
just wise original and then you can get
the line because we know what MX + B or
I mean well we know it MX + B R but we
got M and B already here so we would
just plug in MX + B to get the wide line
of any y original point so anyway in our
case that's all we are plotting since we
created our regression line only using
the X's for X in X's anyways so that's
our squared error now we need to
calculate coefficient of determination
which again is just 1 minus the squared
error of the Y hat line divided by the
squared error of the mean of the Y's so
we can calculate that define coefficient
of determination that's wise Ridge and
then wise line that should be a comma we
calculate that by saying the y mean line
equals the mean of actually what we need
to do is brackets this is mean wise orig
for y in wise orig so let um make our y
mean line that's just it's just it will
make a a single value and each value is
just the mean of Y for every Y that we
have in the original line so that's our
y mean line squared error of the
regression line is equal to I'm just
going to copy and paste rather than
typing this out so copy that paste and
then we're going to say the squared
error Y mean equals squared error wise
original and then instead of wise line
it's the y mean line and then finally we
just return one minus and then that
would be 1 minus the squared error of
the regression line divided by the
squared error
of the mean line right one - squared of
Russian divided by the squared error of
the mean line great so there's our
coefficient of determination so now all
we would have to do is we might say
something like we might come down I
don't know here we could say R squared
or you could call it coefficient of
determination equals coefficient of
determination and then you might have
something like that's wise regression
line so that's the Y's original that's
the line we're curious about and we want
to know the r-squared value of that
regression line so we could print R
squared
save and run it and the value we get
here is 0.58 so just as a know if the
regression line was if the VAT let's say
the regression line is as good as the y
mean then our value here would be zero
right to be one - basically a whole
number one right so you know anything
you know like you can't just say
anything about 50% is more accurate
anything about zero means the regression
line was more accurate now you kind of
have to make your own determination of
what kind of coefficient of
determination line you're looking for in
this case we get point five eight which
is obviously it's significantly more
accurate because you know to get point
five eight the equation would have to be
0.42 so to be 0.42 that would be
basically like 42 out of 100 so the
squared error is much less right so
anyways squared error and coefficient of
determination is not the only
calculation of how accurate the best fit
line is but it is a calculation of how
good of a fit the best fit line is so in
the next tutorial what we're going to do
is build some sample data or in tests
are everything we've got so far all our
algorithm and all that there's a lot of
math that's involved here it's basic
math but it's a lot of math involved
we need to have some sort of way to
figure out if everything is right like
0.58 something could be totally wrong
here we wouldn't really have any way to
figure out how it's wrong other than
maybe doing it by hand or something like
that so in the next tutorial we're gonna
be talking about testing all of our
assumptions and sample data and stuff
like that if you have questions comments
leave them below otherwise until next
time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>