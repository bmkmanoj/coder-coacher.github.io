<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>R Squared Theory - Practical Machine Learning Tutorial with Python p.10 | Coder Coacher - Coaching Coders</title><meta content="R Squared Theory - Practical Machine Learning Tutorial with Python p.10 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>R Squared Theory - Practical Machine Learning Tutorial with Python p.10</b></h2><h5 class="post__date">2016-04-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-fgYp74SNtk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody and welcome to part 10
of our machine learning tutorial series
in this part what we're going to be
talking about is we've been talking
about linear regression and we've got to
the point where we could calculate the
best fit line in our Python code but now
the question is how good of a fit is our
best fit line how do we determine the
accuracy right so the way that we
determine accuracy is through r-squared
or the coefficient of determination and
the coefficient of determination is
calculated using what's known as squared
error so first we need to figure out
what the heck squared error is and then
we can calculate R squared or the
coefficient of determination
so to exemplify this consider you know
you've got two graphs and then you've
got some plots on those graphs and then
what you want to do is draw the best fit
line okay so something like like this
and then I have no idea something like
this right and if I asked you which one
is a better fit you would say the the
one on the right and then if I asked why
is that the best fit you might think for
a moment but you would probably come up
with well the the dots are closer to the
line on the one on the right as they are
closer than they are the one on the Left
anyways now of course we don't have any
ticks on our axes here and so I might
say that the one on the Left were
actually zoomed in really far and
they're actually much closer so you
don't really know but but really it's
it's how good of the fit is it how good
a the fit is the best fit line how good
if your fit is your model to your data
set so it's very relative to your data
set and you'll see more why in just a
moment so we know it's the distance so
so so what how do we actually calculate
this well we use squared error so we've
got a graph here and then we got some
data points so beautiful data points and
we have our best fit line and the way
that we calculate squared error is we
say the error is the distance between
the point and the law and the best fit
line and then what we say is it's not
just error we want to square that value
so we want to do
squared error is you know e squared okay
so you might ask why are we squaring it
right well in this case the distance
right in one case the distance might be
positive in another case the distance
might be negative so one reason why we
square it is so that we're only dealing
with positive values you might then ask
why is it a squared and not like
absolute value of e well we want to
square it because what have you had a
point that was like way out here that
would be an outlier and your linear data
set should not have an outlier because
we only want to do linear regression on
linear data okay that only makes sense
so we square the error because we want
to we want to penalize for outliers so
then you might ask well why not um using
^ 4 or 6 or 18 for that matter you could
use these other ones if you want to
penalize for outliers you can use a
bigger day a bigger value there if you
want to penalize even heavier for
outliers it's just so happens the
standard is going to be squared error
and if you're not using squared error
and maybe you're you're publishing
something publicly either in a paper or
maybe you've got some data some sort of
module in Python or something you'd want
to alert people to the fact that you are
not doing it the way that most people do
it okay so that is squared error now how
do we calculate the coefficient of
determination or R squared so R squared
is calculating the following so R
squared equals and it is one minus and
it's one minus the squared error and
generally you're going to see squared
error denoted as s e so it's the squared
error of the Y hat line what the heck is
the Y hat line remember Y hat best-fit
regression line all the same thing
/ the squared error of the mean of the
why that's the mean of the Y's of your
data set so so what might that actually
look like the mean of your wise might be
that so it's just a simple straight line
and what we're trying to do is compare
the accuracy of that line to the
accuracy of like the best fit line and
honestly the best fit line is almost
certainly going to be better than the
mean of the Y's but we want it to be
like way better okay so looking at R
squared and the calculation of R squared
what what's like a what's a good value
right like what do we think might be a
good value versus what do we think might
be a bad value so let's consider a value
like let's say R squared equals um zero
point eight how would we arrive at zero
point eight well we would know that in
order for R squared to be zero point
eight it would have to be the squared
error of the Y hat line divided by the
squared error of the mean of the Y's
would have to be like this equation here
would have to be equal to zero point two
like that's that's the only way we could
get two to one - what is zero point
eight so how what would be an example of
this this equation here being zero point
two well we would find that we would
need the squared error let's say of Y
maybe maybe the squared error of the Y
hat line is two and the squared error of
the mean of the Y's is ten okay equals
so if that was the case we were saying
you know the squared error of the Y hat
line is actually significantly lower
than the squared error of the mean of
the Y
is that a good thing or a bad thing well
that's a pretty good thing we would
prefer it to be even lower than that but
you know that's pretty good so that
means this data is probably pretty
linear right so it's it's so an
r-squared of 0.8 is is pretty good what
if your r-squared was like 0.3 for
example so if R squared for example was
0.3 how would we arrive maybe at that
equation well we would need the squared
error divided by R the squared error of
the Y hat divided by the square root of
the mean of the Y's we would need that
to be 0.7 right and we could get that by
you know 7 over 10 and now the squared
error of the Y hat is a lot closer to
the squared error of the mean of the Y's
so obviously this is this is more
negative so we want the R squared value
to be high how high is kind of
determined by you but the accuracy in
this case of our model is let's say we
call it 0.8 that is the R squared value
so it's not a percent accuracy is it is
the R squared it's the coefficient of
determination that is the value so now
that we know what the calculation for R
squared is and we know what squared
error is and we know how to calculate
the Y hat line we've already done that
we know how to calculate the mean of the
Y's we haven't done that necessarily
actually we have done that cuz that was
part of our our best fit line
calculation so we've done that we know
how to do everything here so we can
definitely calculate this in Python so
that is what we are going to be doing in
the next video if you have questions
comments concerns up to this point
please feel free leaving below otherwise
as always thanks for watching thanks for
all the support and subscriptions and
until next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>