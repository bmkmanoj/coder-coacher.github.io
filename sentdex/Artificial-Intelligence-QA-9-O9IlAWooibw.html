<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Artificial Intelligence - Q&amp;A #9 | Coder Coacher - Coaching Coders</title><meta content="Artificial Intelligence - Q&amp;A #9 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Artificial Intelligence - Q&amp;A #9</b></h2><h5 class="post__date">2016-12-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/O9IlAWooibw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what's going on everybody welcome to Q&amp;amp;A
number nine this kid a is all about a I
this is the last Q&amp;amp;A of 2016 last video
my channel for 2016 and it's only
appropriate to talk about AI I think a
it's going to be big deal in 2017 not
necessarily because of any advancements
in AI specifically but more so the
impact of the just all the way up to the
current advancements in AI right now so
a lot of questions on a I generally stem
initially at least from the question of
is AI a threat to to people in general
okay
so first this kind of like teardown
response to what we should think about
AI and what the threats of AI are really
we have to kind of break it down to
almost like a tree argument so first of
all the question is AI threat obviously
you can just say yes or no to this
question if you say no the problem is we
really just don't know with AI so I
think it's really hard to hold the
stance that no AI could not be a threat
we just don't understand AI we don't
know what's coming with AI so you pretty
much have to be in the camp of yes
now most a lot of people are in yes
because as humans we fear what we don't
know but we also it's rightfully so we
really just don't know what AI will
bring so AI in the current sense I mean
there's nothing to fear but the the fear
is when we get to something like
artificial general intelligence which is
like intelligence that's on par with a
human and then you've got artificial
super intelligence or ASI and this is
something that's beyond our intelligence
so these two things are kind of I think
that you've got AI right now which is
like weak AI you've got strong AI which
is like really truly intelligent AI
because right now kind of what we have
is just brute forcing and fitting to
problems that are you know infinitely
dimensional but all we're doing is just
fitting to infinitely dimensional
problems really with AI today so so
let's say your answer to the AI threat
is no well
you're done here I guess but you're also
probably just stupid is AI threat if
your answer is yes then we have to start
thinking about okay well what can we do
about this threat of AI so a lot of
people don't know we don't really know
what we can do about it but the naive
approaches say is there some way we
could restrict AI or restrict the
development of AI well especially like
maybe a GI we could come up with some
sort of system that would restrict the
AGI artificial general intelligence so
intelligence that's on par with a human
we could we could probably devise a
system that would restrain an AGI but
could we devise a system that would
restrain an ASI and artificial
superintelligence I think it takes a
little bit of hubris to think that we
could somehow restrict a si so if and
when a si comes around really that's
just going to be kind of a crapshoot
like who knows and to think that somehow
we could restrict a si I think it's
probably a mistake or at least there's
no way it could happen so then you've
got place restrictions on AI use as in
people using AI companies using a
government's using AI that kind of stuff
well the problem with this is AI is so
powerful that everybody wants to do it
everybody wants to use AI so if say the
US government says you guys you can't
use AI anymore well the other countries
are getting to you they I so AI is still
going to advanced and because it's so
powerful it would just be silly to try
to restrict AI also AI is an idea it's
it's just math it's it's a lot like
encryption where countries will say X Y
Z encryption is bad
so asymmetrical encryption for example
that's that's banned you can't use it
well that's just law all right law
doesn't stop you from using it so and if
anything all it does is stop you know
people who are following who are willing
to follow the law stops them from using
it but it doesn't stop a criminal from
using it so the same thing is true with
AI what is it really the greatest idea
to be to tell to basically have all the
law-abiding citizens the actual people
who are a part of society tell them no
you cannot use AI and then what's left
is just the the outliers the criminals
who would be working with AI that people
that don't care about the law so I think
that's a bad idea - so restricting the
use of AI for people and companies and
governments is also probably a mistake
especially when it comes to something
like artificial superintelligence where
it's like a winner-take-all scenario the
first person to reach artificial
superintelligence is the victor it's
very hard to conceive of a way that one
person one entity could reach artificial
super intelligence and if that entity
didn't want anyone else to reach it it's
hard to see how anybody could avoid that
situation so so so again coming back to
the original question is AI threat no
well you're stupid
yes okay well what can we do about it
which could we restrict it some somehow
either restrict its use or restrict
restrict the actual software itself
somehow so there are ways you can fool
AI but for the most part you know
probably not especially a si artificial
super intelligence we are not super
intelligence so how we would think about
it's almost like you know consider the
difference between like an ant and you
okay can you think of ways the ants
might devise a way to thwart something
you want to do you know no it's just
you're you're just on a different level
of intelligence so to think that we
could somehow restrict an artificial
super intelligence I think is just silly
and then also I think it's just a bad
idea to restrict it via law or something
like that regulation now the other
option you have is pretty much the
opposite of restriction and that's
- just decentralize it because really
while AI alone is a threat I don't know
how we can protect ourselves from that
threat other than to to make sure that
not just one human or one small group or
entity or country organization whatever
has that technology so the best thing we
can do is decentralize that technology
through I think open software like
tensorflow Theano that kind of stuff
open AI is a great one just just the
decentralization of just knowledge
concepts and lowering the barriers to
entry to just working with this stuff so
I think that's that's it because you
know AI is is really neither good nor
evil inherently and it's it's not even
self-centered it's none of those things
but humans by just evolution we are
self-centered we want to protect
ourselves first and all this so one you
know AI alone is likely not a threat or
it's I guess it has it's just neither
good nor evil but it's probably a threat
but but AI in the hands of a few is
almost certainly a threat in my opinion
so just some more examples here uh like
i thought i think it was sam harris that
made the example of like it comparing an
ant to a human and we're you know if you
know as an ant walks along the pavement
or something you know you'll probably
like you'll take you'll take steps to
avoid stepping on the ant but if the ant
is in your house you're probably going
to just exterminate it like that's your
first choice it's like let's just
exterminate it so in terms of like an
artificial superintelligence it's
probably not just going to one day just
be like let's just kill humans for fun
it's probably going to do that but if
we're getting in the way of some sort of
major objective of the artificial
superintelligence that it's it's
conceivable that it would decide let's
just exterminate the humans but like if
at least for me if ants were in my house
and if i could communicate with those
ants and tell them hey you need
go or I'm gonna kill you I would do that
like I would I would try it to give them
like an eviction notice but I can't
because they can't communicate with me
but but on the other hand like with
larger animals like dogs for example we
can't communicate perfectly with dogs
but we can teach dogs we can train dogs
we can tell dogs and show dogs what we
like and dislike and I think that with
like an artificial superintelligence
that would possibly be possible so it
doesn't mean that artificial
superintelligence would deem it worthy
to save the humans but there you go
so at least for me I think that's kind
of how how the argument kind of breaks
down with with AI and whether or not AI
is a threat and then there's this kind
of all this question that comes next
which is how far away is AI I think this
one's hard I think you know there's some
some believers in the whole singularity
like Ray Kurzweil I just I can't get
behind the idea of a singularity fully
because unless it was like a
mathematical breakthrough it's possible
like with AI some sort of mathematical
breakthrough happens or maybe a physical
breakthrough with like components and
hardware which would probably still be a
mathematical breakthrough maybe with
that we could see something like a
singularity but I just don't think
that's what's going to happen I think
that you know let's because that the
argument is like basically if we could
make an artificial general intelligence
something as smart as a human then
because it's software it can just be
infinitely copied right well that's not
really true like let's say you come up
with a great neural network that detects
cats in video what what did you need for
that well you needed it a big GPU so can
you just infinitely scale your your cat
detector no because you need the
hardware and you need the power you need
all these things to also be in balance
so the only way I think a singularity
could occur because like right now today
an artificial general intelligence was
created just by stacking a bunch of GPUs
together
well it wouldn't be in theory it could
be infinitely scalable but in practice
it would not be because we would run out
of power in both in hardware and now
actual power to power these things so
could you make you know seven billion of
these AG eyes no you wouldn't be able to
scale it that fast also the argument
because that because the argument goes
so even though I'm gonna have to just
raise my hand and disagree with the
whole AGI infinite scaling as soon as
AGI is created if AGI that well the
argument is that if the with AGI you
could scale it infinitely be human
intelligence so it's the equivalent of
all the humans possible and if if it's
possible that we would ever create an
ASI then then an infinitely scalable AG
I could create the ASI okay sure I guess
maybe but that that arguments also
flawed just simply because stacking of
intelligence does not necessarily mean
an increase of intelligence right so the
stacking of intelligence say so you take
one dog you put a dog in a room and then
you take five dogs and put five dogs in
a room is there really that much of a
difference in intelligence I mean some
social constructs might actually form
and there might be a slight change in
dynamics but overall collectively did
will the dogs reach a new peak
intelligence probably not what do we
take a hundred thousand dogs but a
hundred thousand dogs in a room are we
gonna get like some new evolved dog oh I
don't think so okay all right that seems
crazy but for some reason we think that
it will if we took a GI and we took a
billion a gi's or ten billion or a
hundred billion somewhere along those
lines it will produce an ASI maybe maybe
that will but maybe not like we really
just that we don't know so I think
that's kind of a bad argument and so but
that's that's what the whole singularity
pretty much hinges on is when we reach
AGI it will be infinitely duplicatable
two bookable anyway it'll be infinitely
um scaled and bam but just like that
overnight whaat
I know you just want unless it was like
a mathematical breakthrough that on
current on a current GPU you could like
have like a billion AG eyes or something
like that then sure you might see
singularity maybe but but still even
even today the intelligence that we have
these neural networks they don't do
anything they just do kind of what we
tell them they don't really actually
they don't think for themselves at all
and then they can they can do tasks like
with reinforcement learning or something
but but it's they're not going to come
up with new and novel things without
being guided to try to come up with new
and novel things so getting back to the
question how far away are we really it's
unclear right it could be tomorrow or it
could be like in a hundred years or it
could be never right
asi might not actually be achievable at
all we really just don't know but if it
is achievable will certainly reach it
because again going back to the whole
should we restrict AI it just won't work
because AI progress is just simply going
to happen we are just going to simply
continue improving on GPUs it may not
always be at the rate of Moore's Law the
whole double every two years that's
probably not going to continue forever
but maybe it will or maybe it will
increase so no matter what happens it's
going to keep continuing and no matter
how scared people are or whatever it
doesn't matter
steps will continue to be taken so
instead what we have to do is think
about what can we do to ease the blow we
can't stop asi from deciding that humans
are bad for the planet earth and to just
exterminate us that really is never like
you're just not going to outsmart ASI so
what can you do I think again as I said
before I think the whole
decentralization make sure it's not just
one group that has artificial
superintelligence right what stops a bad
guy with a si a good guy with a si hey
anyway let the fight begin
No so there's that but also even now
there's even larger threats that no
one's talking about
at least I don't see people talking
about every was like orient about how do
we stop an ASI like that's a that's a
deep philosophical question anybody who
claims they have the answer that is just
B s you you can't no right because we
have general intelligence so using
general intelligence stops super
intelligence not going to happen
so on the chances that this goes
smoothly we instead have to think about
what's what kind of transitions are we
going to go through and already today we
have serious problems that are coming so
the number one I think it's either one
of the largest or it's actually the
largest especially probably the last
year it's the largest job in the United
States is commercial driver
so it's truck driver taxis uber driver
lifts whatever all these things
commercial driver but what's happening
and what happened in 2016 and what's
been leading up to 2016 is just
self-driving cars and uber auto all
these companies are trying Google of
course are making self-driving cars that
I suppose Tesla Apple's trying to get in
the mix self-driving cars are coming and
commercial delivery has already taken
place that goes auto they did it it's
over it's that battles lost so all these
people that were doing commercial truck
drivers have to go somewhere else now I
used to kind of always think like Oh big
deal
this this this sort of transition has
always occurred throughout history where
like one group of workers just simply
transitioned to another career but now
it's getting hard because maybe you can
but I can't think of a single career
that cannot be replaced by robotics and
AI I can't think of one right all of
them could be replaced now there might
be a demand for for human-made things
right man-made objects or man-made art
or stuff like that kind of like made in
the USA products versus if you're in the
United States that's a big deal to some
people but not everyone not everyone
cares about that and if people don't
have money
they don't care so I think like what the
bigger question is you know not worrying
about how do we restrict something we
can't fundamentally restrict instead
it's a question of if this all goes well
what are we going to do with ourselves
because all the jobs can be replaced
every job can be replaced and again you
could say well the government could
restrict companies from automating
cashier jobs or something like that so
at least that stores people could work
but it would almost have to be the case
that all countries did this or something
okay it's really that's not an option I
don't think it's not a long-term
solution to this problem and so I think
the real challenge is figuring out with
companies like say Auto for example as
Auto cuts all of these jobs for truck
drivers is Auto doing anything I'm not
saying they have to I'm not saying it's
there their job that's not the argument
I'm making I'm just simply asking a
question are they going are they also
simultaneously working to try to solve
the problem of these displaced truck
drivers because sure they could go try
to be a cashier at Walmart well walmart
already has automated checkout lines
could they stock shelves at Walmart well
what Walmart doesn't do it yet but
Amazon's already stocking shelves
automatically and automatics shelf
stocking is that's like that's old
technology right that's coming it's
going to be cheaper and as a company is
it fair to restrict a company and say
you must hire humans right I'm not sure
that's fair either
and like I said I'm not sure that Auto
should be in charge of solving this
problem or other companies making
self-driving cars or any other
automation technology but if they aren't
going to do it who's going to do it and
if no one does it then we will end up
with a situation where like five
companies rule the entire globe
basically of services and jobs and make
all of the money have all of the AI and
that's something you want to avoid and
how you avoid that
that to me is the main problem the main
problem is not how do we stop a eye from
killing us it's not going to be the AI
I just don't think it's going to be AI
that kills us it or restricts us or
enslaves us it's going to be humans the
humans are the ones that are evil and
self-centered and a lust for power and
all this kind of stuff as humans that do
that so an ASI may not even be possible
but what is possible is the automation
of every job on this planet that's
what's possible and that's what's
happening already it's already happening
and the question is how are we going to
handle that how are we going to handle
that transition because I don't know I
don't have the answer to that one that's
the good question</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>