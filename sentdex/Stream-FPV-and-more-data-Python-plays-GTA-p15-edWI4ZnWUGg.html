<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Stream, FPV, and more data - Python plays GTA p.15 | Coder Coacher - Coaching Coders</title><meta content="Stream, FPV, and more data - Python plays GTA p.15 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/sentdex/">sentdex</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Stream, FPV, and more data - Python plays GTA p.15</b></h2><h5 class="post__date">2017-05-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/edWI4ZnWUGg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what is going on everybody and welcome
to part 15 of the Python plays Grand
Theft Auto 5 and does a self-driving car
series first thing you'll probably
notice here is we are now streaming so
if you want to watch the AI I my goal is
to stream this 24/7 live at least that's
the goal I'll talk about that in a
moment
looks like we're about to go swimming
however anyway yeah so twitch TV /
syntax and you can watch it stream I
have been having some issues with
getting it to stream at a nice constant
bitrate so actually right now what
you're looking at is actually the stream
using my phone's internet which is
really depressing I mean my phone
cellular data is performing better than
my internet so yeah anyway so yeah
that's that also one interesting thing
you'll get to see here in a moment is
one of the reasons why we can actually
stream this 24/7 is if the the player
doesn't move enough in a certain amount
of time they will it'll just be
teleported out to a random out of 10
coordinates basically that I've chosen
so it'll pretty much run 24/7 even if it
gets itself into a really bad situation
sometimes you'll find yourself in
someone's like backyard or something and
there's really no way you would ever get
out of that backyard so this kind of
helps correct for situations like that
where you literally the car could never
drive out so anyways that's that's that
probably the biggest thing you'll notice
from the actual AI itself is it's now a
first-person view so I'm so pretty
confident we could have done it in a
third-person view but I ended up
changing to a first-person view just
because that's really more likely to be
the situation for a self-driving car
it's not going to have some sort of
drone flying behind in third person so
yeah so that's that also the the AI now
has its own computer now so that's the
new machine that just runs the AI now
there's no way I could stream all this
on my main computer and actually get any
work done ever so I actually ended up
building this and putting it all
together and then trim the model the
whole time I was
town for a few days in New York so what
you see here is the results of about
four days of training now interestingly
enough this is this the GPU here is a
Titan X Pascal the GPU I have in my main
machine is actually a Titan X Maxwell
and over the course of four days they
trained the model in about the same
amount of time there's really no
statistically significant difference in
how far each one got they were basically
the same which is kind of strange I
don't know if it's a bad GPU or if this
one's like super good and I just don't
know it um but yeah that's kind of odd
that they would be the same speed I was
using tensorflow and Kiev learn on top
so it could also be some sort of
software related issue so anyways I
think that's about it as far as like the
major changes it's still just a
convolutional neural network so every
action is based on a single frame it
just looks at a frame and it makes it it
makes a movement choice I did try in the
past on one of the older models that was
a little more sporadic what I would do
is I would take the previous five
rolling frames take the prediction from
those and then do the average prediction
which ever or the mode rather prediction
and that actually works pretty well for
that model but for this model actually I
am constantly every single prediction is
its own there's no there's no mode
there's no nothing it's all just raw
whatever the prediction is it does it so
the fact that it works at all and
actually seems to kind of at times drive
through traffic pretty well avoid things
follow lanes that kind of stuff is
incredible to me like it I wouldn't have
thought it would do this the other thing
I've seen it do a lot of is it'll like
engage in a turn it will starts going
sideways and sliding basically drifting
or power sliding through a turn and it
will catch the turn and continue I did
not think that would be possible but
somehow it does that and I wonder if
it's just cuz its reaction times are
just so amazing that it can just get
away with it not in the same way a human
can but it just does it because it can
react so fast I'm not really sure but
anyway yes so I mean I'm overall I'm
like super impressed with
who with this a is now I'm not really
sure if just more training data would
make it even better or if we have to
make the model a little more complex but
to be honest I mean the AI already
acts way better than I would have ever
imagined
with such rudimentary kind of rules
basically it's just going off frames it
doesn't know historically what what it's
been doing it doesn't know its movements
doesn't know historical frames so I mean
that's just nuts to me anyway so moving
forward I'm contemplating adding some
recurrent layers possibly the other
thing is it's interesting it normally
doesn't actually do this one of the
older models used to do this all the
time that's why I did the average but
normally it actually doesn't what's all
like that so it's kind of odd that it's
doing it now of course because I'm
filming now but that's kind of the
reason why I actually did the random or
the the mode of movements anyway moving
on to the future um you know some people
were also making you know asking like
when's the next video coming out on that
wall they're just going to take a little
longer to come out of between videos
because I'm at the point now where the
model takes this model took four days
and it also took multiple days to
collect the data for the model and in
the future models are probably take more
like a week or two weeks or even a month
right as we continue to get more and
more training data it's only going to
take longer to keep making changes and
maybe the model is no good like maybe it
doesn't actually work better than this
or whatever so it's really hard for me
to put out videos as fast as I had been
and that's kind of why I wanted to put
up the stream just because you can
pretty much see what the AI is doing all
the time now so so yeah the other thing
I'm interested in doing here is
collecting data from the stream right
now I'm just running the stream I'm
trying to get to the stream to the point
where it can just run 24/7 period and
run smoothly that it's not a pain but
just to watch it
we're frustrating to watch it and we're
almost there just not quite yet and once
I get that my plan is to start
collecting data from the stream as it's
running not really from the stream but
from the computer that's turning it from
there collecting that data as its
streaming and validating it are we
moving you know you can do pretty easy
motion detection so are we moving
and then possibly overlaying optical
flow because with optical flow I'm
curious if we could actually circumvent
doing recurrent on any recurrent layers
and just simply adding optical flow to
the frames if that would if that would
be enough and I think probably a
recurrent layers would be good but the
performance would suffer both in
training and then also just in testing I
think we'd suffer a lot in a frame rate
but it would probably perform better but
with optical flow we get exactly the
same performance we're getting but it's
just a little bit more data per image
that I think would probably be pretty
useful to the AI as its learning so I'm
curious to try that and both can use
optical flow to train but and also to
validate data we can use optical flow to
figure out are we moving did we just
make a really abrupt you know Direction
change like did we just flash into
something basically so we can we can use
it kind of for both of those things
anyway that's all for now
if you have questions comments whatever
you can leave them below also I have
them swing me pull requests on github I
don't know what I'm going to be able to
get to all of them but hopefully next
week probably the week basically when I
release this video I'm going to be going
through all of those there's one at
least that I really want to get into
which is like a more granular control
which after seeing this model I'm not
positive it's necessary I thought it was
necessary when I had the models with
much less training data but after I've
seen this model I'm not sure it's going
to be necessary so I really don't know
at this point but I still want to check
it out anyway because it would be good
for any open pure open CV model it would
definitely work better anyway other than
that I think that's really all I want to
add if I'm forgetting something or if
you've got any questions feel free to
ask below if you want updates on what's
going on or whatever you can always just
just come to twitch.tv slash synthetics
pretty much all day I'll have this on
one of my monitors and so I'll be here
to chat if you've got questions or
whatever I think that's it
I'm probably forgetting something but
that's it that's all for now
questions commenting below otherwise</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>