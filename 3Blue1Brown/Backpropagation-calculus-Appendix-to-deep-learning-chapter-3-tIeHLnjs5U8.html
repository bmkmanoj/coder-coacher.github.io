<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Backpropagation calculus | Appendix to deep learning chapter 3 | Coder Coacher - Coaching Coders</title><meta content="Backpropagation calculus | Appendix to deep learning chapter 3 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/3Blue1Brown/">3Blue1Brown</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Backpropagation calculus | Appendix to deep learning chapter 3</b></h2><h5 class="post__date">2017-11-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/tIeHLnjs5U8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the Hardison here is that you've watched
part three giving an intuitive
walkthrough of the backpropagation
algorithm here we get a little bit more
formal and dive into the relevant
calculus it's normal for this to be at
least a little confusing so the mantra
to regularly pause and ponder certainly
applies as much here as anywhere else
our main goal is to show how people in
machine learning commonly think about
the chain rule from calculus in the
context of networks which has kind of a
different feel from how most
introductory calculus courses approach
the subject but those of you
uncomfortable with the relevant calculus
I do have a whole series on the topic
let's just start off with an extremely
simple network one where each layer has
a single neuron in it so this particular
network is determined by three weights
and three biases and our goal is to
understand how sensitive the cost
function is to these variables that way
we know which adjustments to those terms
is going to cause the most efficient
decrease to the cost function and we're
just going to focus on the connection
between the last two neurons let's label
the activation of that last neuron with
a superscript L indicating which layer
it's in so the activation of the
previous neuron is a l minus one these
are not exponents they're just a way of
indexing what we're talking about since
I want to save subscripts for different
indices later on now let's say that the
value we want this last activation to be
for a given training example is why for
example Y might be zero or one so the
cost of this simple network for a single
training example is al minus y squared
will denote the cost of that one
training example as C zero
as a reminder this last activation is
determined by a weight which I'm going
to call WL times the previous neurons
activation plus some bias which I'll
call BL and then you pump that through
some special nonlinear function like the
sigmoid or aralia it's actually going to
make things easier for us if we give a
special name to this weighted sum like Z
with the same superscript as the
relevant activations so this is a lot of
terms any way that you might
conceptualize it is that the weight the
previous action and the bias altogether
are used to compute Z which in turn lets
us compute a which finally along with a
constant Y lets us compute the cost and
of course al minus 1 is influenced by
its own weight and bias and such but
we're not going to focus on that right
now now all of these are just numbers
right and it can be nice to think of
each one is having its own little number
line our first goal is to understand how
sensitive the cost function is to small
changes in our weight WL or phrase
differently what is the derivative of C
with respect to WL when you see this del
W term think of it as meaning some tiny
nudge to W like a change by 0.01 and
think of this del C term as meaning
whatever the resulting nudge to the cost
is what we want is their ratio
conceptually this tiny nudge to WL
causes some nudge to ZL which in turn
causes some nudge to Al which directly
influences the cost so we break things
up by first looking at the ratio of a
tiny change to ZL to this tiny change W
that is the derivative of Z L with
respect to W L likewise you then
consider the ratio of the change to a l
- the tiny change in ZL that caused it
as well as the ratio between the final
nudge to C and this intermediate nudge -
al this right here is the chain rule
where multiplying together these three
ratios gives us the sensitivity of C to
small changes in WL
so on screen right now there's kind of a
lot of symbols and take a moment to just
make sure it's clear what they all are
because now we're going to compute the
relevant derivatives the derivative of C
with respect to Al works out to be 2
times al - why
notice this means that its size is
proportional to the difference between
the network's output and the thing that
we want it to be so if that output was
very different even slight changes stand
to have a big impact on the final cost
function the derivative of al with
respect to Z L is just the derivative of
our sigmoid function or whatever
non-linearity you choose to use and the
derivative of ZL with respect to W L in
this case comes out just to be a L minus
1 now I don't know about you but I think
it's easy to get stuck head down in the
formulas without taking a moment to sit
back and remind yourself of what they
all actually mean in the case of this
last derivative the amount that that
small nudge - the weight influenced the
last layer depends on how strong the
previous neuron is remember this is
where that neurons that fire together
wire together idea comes in and all of
this is the derivative with respect to
WL only of the cost for a specific
single training example since the full
cost function involves averaging
together all those costs across many
different training examples its
derivative requires averaging this
expression that we found over all
training examples and of course that is
just one component of the gradient
vector which itself is built up from the
partial derivatives of the cost function
with respect to all those weights and
biases
but even though that's just one of the
many partial derivatives we need it's
more than 50% of the work the
sensitivity to the bias for example is
almost identical we just need to change
out this del Z del W term for a del Z
del B and if you look at the relevant
formula that derivative comes out to be
one also and this is where the idea of
propagating backwards comes in you can
see how sensitive this cost function is
to the activation of the previous layer
namely this initial derivative in the
chain rule expression the sensitivity of
Z to the previous activation comes out
to be the weight WL and again even
though we're not going to be able to
directly influence that previous layer
activation it's helpful to keep track of
because now we can just keep iterating
this same chain rule idea backwards to
see how sensitive the cost function is
to previous weights and previous biases
and you might think that this is an
overly simple example since all layers
just have one neuron and that things are
going to get exponentially more
complicated for a real network but
honestly not that much changes when we
give the layers multiple neurons really
it's just a few more indices to keep
track of rather than the activation of a
given layer simply being al it's also
going to have a subscript indicating
which neuron of that layer it is let's
go ahead and use the letter K to index
the layer L minus 1 and J to index the
layer L for the cost again we look at
what the desired output is but this time
we add up the squares of the differences
between these last layer activations and
the desired output that is you take a
sum over al J minus YJ squared since
there's a lot more weights each one has
to have a couple more indices to keep
track of where it is so let's call the
weight of the edge connecting this calf
neuron to the jth neuron WL JK
those indices might feel a little
backwards at first but it lines up with
how you'd index the weight matrix that I
talked about in the part
video just as before it's still nice to
give a name to the relevant weighted sum
like Z so that the activation of the
last layer is just your special function
like the sigmoid applied to Z you can
kind of see what I mean right where all
of these are essentially the same
equations that we had before in the one
neuron per layer case it's just that it
looks a little more complicated and
indeed the chain rule derivative
expression describing how sensitive the
cost is to a specific weight looks
essentially the same I'll leave it to
you to pause and think about each of
those terms if you want what does change
here though is the derivative of the
cost with respect to one of the
activations in the layer L minus one in
this case the difference is that the
neuron influences the cost function
through multiple different paths that is
on the one hand it influences a l0 which
plays a role in the cost function but it
also has an influence on a l1 which also
plays a role in the cost function and
you have to add those up and that well
that's pretty much it
once you know how sensitive the cost
function is to the activations in this
second to last layer you can just repeat
the process for all the weights and
biases feeding into that layer so pat
yourself on the back if all of this
makes sense
you have now looked deep into the heart
of backpropagation the workhorse behind
how neural networks learn these chain
rule expressions give you the
derivatives that determine each
component in the gradient that helps
minimize the cost of the network by
repeatedly stepping downhill if you sit
back and think about all that this is a
lot of layers of complexity to wrap your
mind around so don't worry if it takes
time for your mind to digest it all
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>