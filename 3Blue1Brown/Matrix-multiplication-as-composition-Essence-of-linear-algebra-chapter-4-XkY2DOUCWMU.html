<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Matrix multiplication as composition | Essence of linear algebra, chapter 4 | Coder Coacher - Coaching Coders</title><meta content="Matrix multiplication as composition | Essence of linear algebra, chapter 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/3Blue1Brown/">3Blue1Brown</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Matrix multiplication as composition | Essence of linear algebra, chapter 4</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XkY2DOUCWMU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">everyone where we last left off I showed
what linear transformations look like
and how to represent them using matrices
this is worth a quick recap because it's
just really important but of course if
this feels like more than just a recap
go back and watch the full video
technically speaking linear
transformations are functions with
vectors as inputs and vectors as outputs
but I showed last time how we can think
about them visually as smooshing around
space in such a way that gridlines stay
parallel and evenly spaced and so that
the origin remains fixed the key
takeaway was that a linear
transformation is completely determined
by where it takes the basis vectors of
the space which for two dimensions means
I hat and J hat this is because any
other vector could be described as a
linear combination of those basis
vectors a vector with coordinates X Y is
x times I hat plus y times J hat after
going through the transformation this
property that grid lines remain parallel
and evenly spaced has a wonderful
consequence the place where your vector
lands will be x times the transformed
version of I hat plus y times the
transformed version of J hat this means
if you keep a record of the coordinates
where I hat lands and the coordinates
where J hat lands you can compute that a
vector which starts at X Y must land on
x times the new coordinates of I hat
plus y times the new coordinates of J
hat the convention is to record the
coordinates of where I hat and J hat
land as the columns of a matrix and to
define this sum of the scaled versions
of those columns by x and y to be matrix
vector multiplication in this way a
matrix represents a specific linear
transformation and multiplying a matrix
by a vector is what it means
computationally to apply that
transformation to that vector
all right recap over on to the new stuff
times you find yourself wanting to
describe the effects of applying one
transformation and then another for
example maybe you want to describe what
happens when you first rotate the plane
ninety degrees counterclockwise then
apply a shear the overall effect here
from start to finish is another linear
transformation distinct from the
rotation and the shear this new linear
transformation is commonly called the
composition of the two separate
transformations we apply it and like any
linear transformation it can be
described with a matrix all of its own
by following I hat and J hat in this
example the ultimate landing spot for I
hat after both transformations is 1 1 so
let's make that the first column of a
matrix
likewise J hat ultimately ends up at the
location negative 1 0 so we make that
the second column of the matrix this new
matrix captures the overall effect of
applying a rotation then a shear but is
one single action rather than two
successive ones
here's one way to think about that new
matrix if you were to take some vector
and pump it through the rotation then
the shear the long way to compute where
it ends up is to first multiply it on
the left by the rotation matrix then
take whatever you get and multiply that
on the left by the shear matrix this is
numerically speaking what it means to
apply a rotation then a shear to a given
vector but whatever you get should be
the same as just applying this new
composition matrix that we just found by
that same vector no matter what vector
you chose since this new matrix is
supposed to capture the same overall
effect as the rotation then shear action
based on how things are written down
here I think it's reasonable to call
this new matrix the product of the
original two matrices don't you we can
think about how to compute that product
more generally in just a moment but it's
way too easy to get lost in the forest
of numbers always remember that
multiplying two matrices like this has
the geometric meaning of applying one
transformation than another one thing
that's kind of weird here is that this
has us reading from right to left
you first apply the transformation
represented by the matrix on the right
then you apply the transformation
represented by the matrix on the left
this stems from function notation since
we write functions on the left of
variables so every time you compose two
functions you always have to read it
right to left good news for the Hebrew
readers bad news for the rest of us
let's look at another example take the
matrix with columns 1 1 and negative 2 0
whose transformation looks like this and
let's call it m1 next take the matrix
with columns 0 1 &amp;amp; 2 0 whose
transformation looks like this
call that guy m2 the total effect of
applying m1 then m2 gives us a new
transformation
so let's find its matrix but this time
let's see if we can do it without
watching the animations and instead just
using the numerical entries in each
matrix first we need to figure out where
I hat goes after applying m1 the new
coordinates of I hat by definition are
given by that first column of m1 namely
1 1 to see what happens after applying
m2 multiply the matrix for m2 by that
vector 1 1
working it out the way that I described
last video you'll get the vector to 1
this will be the first column of the
composition matrix likewise to follow J
hat the second column of M 1 tells us
that it first lands on negative 2 0
then when we apply em to to that vector
you can work out the matrix vector
product to get 0 negative 2 which
becomes the second column of our
composition matrix let me talk through
that same process again but this time
I'll show variable entries in each
matrix just to show that the same line
of reasoning works for any matrices this
is more simple heavy and will require
some more room but it should be pretty
satisfying for anyone who has previously
been taught matrix multiplication the
more rote way to follow where I hat goes
start by looking at the first column of
the matrix on the right since this is
where I had initially lands multiplying
that column by the matrix on the left is
how you can tell where the intermediate
version of I hat ends up after applying
the second transformation so the first
column of the composition matrix will
always equal the left matrix times the
first column of the right matrix
likewise j-hat will always initially
land on the second column of the right
matrix
so multiplying the left matrix by this
second column will give its final
location and hence that's the second
column of the composition matrix
notice there's a lot of symbols here and
it's common to be taught this formula as
something to memorize along with a
certain algorithmic process to kind of
help remember it but I really do think
that before memorizing that process you
should get in the habit of thinking
about what matrix multiplication really
represents applying one transformation
after another trust me this will give
you a much better conceptual framework
that makes the properties of matrix
multiplication much easier to understand
for example here's a question does it
matter what order we put the two
matrices in when we multiply them well
let's think through a simple example
like the one from earlier take a shear
which fixes I hat and smushes J hat over
to the right and a 90-degree rotation if
you first do the shear then rotate we
can see that I hat ends up at 0 1 and J
hat ends up at negative 1 1 both are
generally pointing close together if you
first rotate then do this year
i hat ends up over at 1 1 and j hat is
off in a different direction at negative
1 0 and they're pointing you know
farther apart the overall effect here is
clearly different so evidently order
totally does matter
notice by thinking in terms of
transformations that's the kind of thing
that you can do in your head
by visualizing no matrix multiplication
necessary I remember when I first took
linear algebra there is this one
homework problem that asked us to prove
that matrix multiplication is
associative this means that if you have
three matrices a B and C and you
multiply them all together it shouldn't
matter if you first compute a times B
then multiply the result by C or if you
first multiply B times C then multiply
that result by a on the left in other
words it doesn't matter where you put
the parentheses now if you try to work
through this numerically like I did back
then it's horrible just horrible and
unenlightened for that matter but when
you think about matrix multiplication as
applying one transformation after
another this property is just trivial
can you see why what it's saying is that
if you first apply C then B then a it's
the same as applying C then B then a I
mean there's nothing to prove you're
just applying the same three things one
after the other
all in the same order this might feel
like cheating but it's not this is an
honest-to-goodness proof that matrix
multiplication is associative and even
better than that it's a good explanation
for why that property should be true I
really do encourage you to play around
more with this idea imagining two
different transformations thinking about
what happens when you apply one after
the other and then working out the
matrix product numerically trust me this
is the kind of playtime that really
makes the idea sink in
in the next video I'll start talking
about extending these ideas beyond just
two dimensions see you then
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>