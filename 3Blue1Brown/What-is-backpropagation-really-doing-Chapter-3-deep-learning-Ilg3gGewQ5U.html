<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What is backpropagation really doing? | Chapter 3, deep learning | Coder Coacher - Coaching Coders</title><meta content="What is backpropagation really doing? | Chapter 3, deep learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/3Blue1Brown/">3Blue1Brown</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What is backpropagation really doing? | Chapter 3, deep learning</b></h2><h5 class="post__date">2017-11-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ilg3gGewQ5U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">here we tackle backpropagation the core
algorithm behind how neural networks
learn after a quick recap for where we
are the first thing I'll do is an
intuitive walkthrough for what the
algorithm is actually doing without any
reference to the formulas then for those
of you who do want to dive into the math
the next video goes into the calculus
underlying all this if you watched the
last two videos or if you're just
jumping in with the appropriate
background you know what a neural
network is and how it feeds forward
information here we're doing the classic
example of recognizing handwritten
digits whose pixel values get fed into
the first layer of the network with 784
neurons and I've been showing a network
with two hidden layers having just 16
neurons each and an output layer of 10
neurons indicating which digit the
network is choosing as its answer I'm
also expecting you to understand
gradient descent as described in the
last video and how what we mean by
learning is that we want to find which
weights and biases minimize a certain
cost function as a quick reminder for
the cost of a single training example
what you do is take the output that the
network gives along with the output that
you wanted it to give and you just add
up the squares of the differences
between each component doing this for
all of your tens of thousands of
training examples and averaging the
results this gives you the total cost of
the network and as if that's not enough
to think about as described in the last
video the thing that we're looking for
is the negative gradient of this cost
function which tells you how you need to
change all of the weights and biases all
of these connections so as to most
efficiently decrease the cost
backpropagation
the topic of this video is an algorithm
for computing that crazy complicated
gradient and the one idea from the last
video that I really want you to hold
firmly in your mind right now is that
because thinking of the gradient vector
as a direction in 13000 dimensions is to
put it lightly beyond the scope of our
imaginations there's another way you can
think about it the magnitude of each
component here is telling you how
sensitive the cost function is to each
weight and bias for example let's say
you go through the process I'm about to
describe when you compute the negative
gradient and the component associated
with the weight on this edge here comes
out to be three point two while the
component associated with this edge here
comes out as zero point one the way you
would interpret that is that the cost of
the function is 32 times more sensitive
to changes in that first way so if you
were to wiggle that value just a little
bit it's gonna cause some change to the
cost and that change is 32 times greater
than what the same wiggle to that second
weight would give personally when I was
first learning about back propagation I
think the most confusing aspect was just
the notation and the index chasing of it
all but once you want what each part of
this algorithm is really doing each
individual effect that it's having is
actually pretty intuitive it's just that
there's a lot of little adjustments
getting layered on top of each other so
I'm gonna start things off here with a
complete disregard for the notation and
just step through those effects that
each training example is having on the
weights and biases because the cost
function involves averaging a certain
cost per example over all the tens of
thousands of training examples the way
that we adjust the weights and biases
for a single gradient descent step also
depends on every single example or
rather in principle it should but for
computational efficiency we're going to
do a little trick later to keep you from
needing to hit every single example for
every single step
another case right now all we're gonna
do is focus our attention on one single
example this image of a - what effect
should this one training example have on
how the weights and biases getage
let's say we're at a point where the
network is not well trained yet so the
activations in the output are gonna look
pretty random maybe something like 0.5
0.8 0.2 on and on now we can't directly
change those activations we only have
influence on the weights and biases but
it is helpful to keep track of which
adjustments we wish should take place to
that output layer and since we want it
to classify the image as a - we want
that third value to get nudged up while
all of the others get nudged down more
over the sizes of these nudges should be
proportional to how far away each
current value is from its target value
for example the increase to that number
two neurons activation is in a sense
more important than the decrease to the
number eight neuron which is already
pretty close to where it should be
so zooming in further let's focus just
on this one neuron the one whose
activation we wish to increase remember
that activation is defined as a certain
weighted sum of all of the activations
in the previous layer plus a bias which
has all been plugged into something like
the sigmoid squishy vacation function or
a rail ooh so there are three different
avenues that can team up together to
help increase that activation you can
increase the bias you can increase the
weights and you can change the
activations from the previous layer
focusing just on how the weights should
be adjusted notice how the weights
actually have differing levels of
influence the connections with the
brightest neurons from the preceding
layer have the biggest effect since
those weights are multiplied by larger
activation values so if you were to
increase one of those weights it
actually has a stronger influence on the
ultimate cost function then increasing
the weights of connections with dimmer
neurons at least as far as this one
training example is concerned remember
when we talked about gradient descent we
don't just care about whether each
component should get nudged up or down
we care about which ones give you the
most bang for your buck
this by the way is at least somewhat
reminiscent of a theory in neuroscience
for how biological networks of neurons
learn hebbian theory often summed up in
the phrase neurons that fire together
wire together here the biggest increases
to weights the biggest strengthening of
connections happens between neurons
which are the most active and the ones
which we wish to become more active in a
sense the neurons that are firing while
seeing it to get more strongly linked to
those firing when thinking about it - to
be clear I really am not in a position
to make statements one way or another
about whether artificial networks of
neurons behave anything like biological
brains and this fires together wire
together idea comes with a couple
meaningful asterisks but taken as a very
loose analogy I do find it interesting
to note anyway the third way that we can
help increase this neurons activation is
by changing all the activations in the
previous layer namely if everything
connected to that digit - neuron with a
positive weight got brighter and if
everything connected with a negative
weight got dimmer then that digit -
neuron would become more active and
similar to the weight changes you're
going to get the most bang for your buck
by seeking changes that are proportional
to the size of the corresponding weights
now of course we cannot directly
influence those activations we only have
control over the weights and biases but
just as with the last layer it's helpful
to just keep a note of what those
desired changes are but keep in mind
zooming out one step here this is only
what that digit - output neuron wants
remember we also want all of the other
neurons in the last layer to become less
active and each of those other output
neurons has its own thoughts about what
should happen to that second-to-last
layer so the desire of this digit -
neuron is added together with the
desires of all the other output neurons
for what should happen to this
second-to-last layer again in proportion
to the corresponding weights and in
proportion to how much each of those
neurons needs to change this right here
is where the idea of propagating
backwards come
by adding together all these desired
effects you basically get a list of
nudges that you want to happen to the
second-to-last layer and once you have
those you can recursively apply the same
process to the relevant weights and
biases that determine those values
repeating the same process I just walked
through and moving backwards through the
network and zooming out a bit further
remember that this is all just how a
single training example wishes to nudge
each one of those weights and biases if
we only listen to what that to wanted
the network would ultimately be
incentivized just to classify all images
as a two so what you do is you go
through this same back prop routine for
every other training example recording
how each of them would like to change
the weights and the biases and you
averaged together those desired changes
this collection here of the averaged
nudges to each weight and bias is
loosely speaking the negative gradient
of the cost function referenced in the
last video or at least something
proportional to it I say loosely
speaking only because I have yet to get
quantitatively precise about those
nudges but if you understood every
change that I just referenced why some
are proportionally bigger than others
and how they all need to be added
together you understand the mechanics
for what back propagation is actually
doing by the way in practice it takes
computers an extremely long time to add
up the influence of every single
training example every single gradient
descent step so here's what's commonly
done instead you randomly shuffle your
training data and then divide it into a
whole bunch of mini batches let's say
each one having 100 training examples
then you compute a step according to the
mini batch it's not going to be the
actual gradient of the cost function
which depends on all of the training
data not this tiny subset so it's not
the most efficient step downhill but
each mini batch does give you a pretty
good approximation and more importantly
it gives you a significant computational
speed up if you were to plot the
trajectory of your network under the
relevant cost surfer
it would be a little more like a drunk
man stumbling aimlessly down a hill but
taking quick steps rather than a
carefully calculating man determining
the exact downhill direction of each
step before taking a very slow and
careful step in that direction
this technique is referred to as
stochastic gradient descent there's kind
of a lot going on here so let's just sum
it up for ourselves shall we back
propagation is the algorithm for
determining how a single training
example would like to nudge the weights
and biases not just in terms of whether
they should go up or down but in terms
of what relative proportions to those
changes cause the most rapid decrease to
the cost a true gradient descent step
would involve doing this for all your
tens and thousands of training examples
and averaging the desired changes that
you get but that's computationally slow
so instead you randomly subdivide the
data into these mini batches and compute
each step with respect to a mini batch
repeatedly going through all of the mini
batches and making these adjustments you
will converge towards a local minimum of
the cost function which is to say your
network is going to end up doing a
really good job on the training examples
so with all of that said every line of
code that would go into implementing
back prop actually corresponds with
something that you have now seen at
least in informal terms but sometimes
knowing what the math does is only half
the battle
and just representing the damn thing is
where it gets all muddled and confusing
so for those of you who do want to go
deeper the next video goes through the
same ideas that were just presented here
but in terms of the underlying calculus
which should hopefully make it a little
more familiar as you see the topic in
other resources before that one thing
worth emphasizing is that for this
algorithm to work and this goes for all
sorts of machine learning beyond just
neural networks you need a lot of
training data in our case one thing that
makes handwritten digits such a nice
example is that there exists the amnesty
database with so many examples that have
been labeled by humans so a common
challenge that those of you working in
machine learning will be familiar with
is just getting the labeled training
data that you actually need whether
having people label tens of thousands of
images or whatever other data type you
might be dealing with in this actually
transitions really nicely to today's
extremely relevant sponsor CrowdFlower
which is a software platform where data
scientists and machine learning teams
can create training data they allow you
to upload text or audio or image data
and have it annotated by real people you
may have heard of the human-in-the-loop
approach before and this is essentially
what we're talking about here leveraging
human intelligence to train machine
intelligence they employ a whole bunch
of pretty smart quality control
mechanisms to keep the data clean and
accurate and they've helped to train
test and tune thousands of data and AI
projects and what's most fun there's
actually a free t-shirt in this for you
guys if you go to 3 B 1 B Co slash
CrowdFlower or follow the link on screen
and in the description you can create a
free account and run a project and
they'll send you a free shirt once
you've done the job and the shirt it's
actually pretty cool I quite like it so
thanks to CrowdFlower for supporting
this video and thank you also to
everyone on patreon helping support
these videos
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>